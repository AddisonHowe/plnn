Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r0', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1649250364

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.269292783159727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.269292783159727 | validation: 9.25000047861545]
	TIME [epoch: 54.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.67981696465387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.67981696465387 | validation: 8.744764122918287]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.893834202254986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.893834202254986 | validation: 8.281357470269354]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.613396514656591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.613396514656591 | validation: 8.007447771271735]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.29577994271113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.29577994271113 | validation: 7.891762060477897]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.125468018085843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.125468018085843 | validation: 7.944703229133144]
	TIME [epoch: 9.78 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.14328769922272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.14328769922272 | validation: 7.693322084587687]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.912189221461295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.912189221461295 | validation: 7.617800844910374]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.767989516947021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.767989516947021 | validation: 7.953162776209179]
	TIME [epoch: 9.78 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.846631491579902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.846631491579902 | validation: 7.406764192181396]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.6816228409524046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6816228409524046 | validation: 7.348005987375882]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.7762163770791135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7762163770791135 | validation: 7.331166278756357]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.597147988506616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.597147988506616 | validation: 7.281209244854954]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.75651981146235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.75651981146235 | validation: 7.412543835885267]
	TIME [epoch: 9.76 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.596553301985656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.596553301985656 | validation: 7.104102769728674]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.284552954266629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.284552954266629 | validation: 5.887189872182588]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.24341413889109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.24341413889109 | validation: 5.0630765204152794]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.144124962990061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.144124962990061 | validation: 4.13420381324817]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.456298015800512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.456298015800512 | validation: 3.1503961267041483]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4706356899107442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4706356899107442 | validation: 5.12977750627344]
	TIME [epoch: 9.75 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.550107878890238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.550107878890238 | validation: 5.5027671781971454]
	TIME [epoch: 9.77 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.088308992517363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.088308992517363 | validation: 3.125512784782815]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8005524703751634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8005524703751634 | validation: 6.226816857507684]
	TIME [epoch: 9.77 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.6667110560261085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6667110560261085 | validation: 3.104887791449178]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.402931440722844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.402931440722844 | validation: 3.5713543155042253]
	TIME [epoch: 9.77 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.468466245688666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.468466245688666 | validation: 3.2791137288815437]
	TIME [epoch: 9.76 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2792749455378534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2792749455378534 | validation: 3.0699792502514764]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1857518209181617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1857518209181617 | validation: 3.384607434274135]
	TIME [epoch: 9.78 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.495564616366155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.495564616366155 | validation: 5.639102945853673]
	TIME [epoch: 9.76 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.7020316318726865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7020316318726865 | validation: 3.2770620367648067]
	TIME [epoch: 9.76 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0944153961779493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0944153961779493 | validation: 3.4681919755921973]
	TIME [epoch: 9.78 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.533751797847175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.533751797847175 | validation: 7.019453869210383]
	TIME [epoch: 9.76 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.8877977285034655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8877977285034655 | validation: 3.574476396886709]
	TIME [epoch: 9.77 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.649909736329998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.649909736329998 | validation: 3.950920864811063]
	TIME [epoch: 9.76 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3751403370450994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3751403370450994 | validation: 2.9132291079491366]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.20800690732179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.20800690732179 | validation: 5.20998226894156]
	TIME [epoch: 9.75 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.894120061180879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.894120061180879 | validation: 3.701156723066573]
	TIME [epoch: 9.75 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.648915827018787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.648915827018787 | validation: 3.0438329751130806]
	TIME [epoch: 9.77 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.225276101381874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.225276101381874 | validation: 3.677701715855353]
	TIME [epoch: 9.76 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.256653498150155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.256653498150155 | validation: 3.314268028135888]
	TIME [epoch: 9.75 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.551971669342705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.551971669342705 | validation: 2.9540470687532627]
	TIME [epoch: 9.78 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2576808821871786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2576808821871786 | validation: 3.3761919371078988]
	TIME [epoch: 9.76 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.686095174061542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.686095174061542 | validation: 3.862965121513454]
	TIME [epoch: 9.75 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.83098991659748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.83098991659748 | validation: 3.5154207774291093]
	TIME [epoch: 9.78 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1560975190771585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1560975190771585 | validation: 3.082144651888118]
	TIME [epoch: 9.78 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1866311317300937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1866311317300937 | validation: 2.8457779190913834]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9380543313669727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9380543313669727 | validation: 2.920741540558842]
	TIME [epoch: 9.77 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6484107835441515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6484107835441515 | validation: 3.080938289958149]
	TIME [epoch: 9.76 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.037606152371714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.037606152371714 | validation: 2.8451773964491873]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.771218273963105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.771218273963105 | validation: 3.4217414213459483]
	TIME [epoch: 9.76 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.325268632210639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.325268632210639 | validation: 7.10762864554957]
	TIME [epoch: 9.77 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.286633306647221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.286633306647221 | validation: 6.199108306078601]
	TIME [epoch: 9.76 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.381619808648557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.381619808648557 | validation: 4.497442452665892]
	TIME [epoch: 9.75 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9395125938932694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9395125938932694 | validation: 3.197712182359406]
	TIME [epoch: 9.78 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.262521459943072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.262521459943072 | validation: 3.1656756899635297]
	TIME [epoch: 9.75 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.03898342591542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.03898342591542 | validation: 3.7149185251423478]
	TIME [epoch: 9.76 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1384527456134514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1384527456134514 | validation: 2.8528130859517047]
	TIME [epoch: 9.78 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0450232443804253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0450232443804253 | validation: 3.160931246279281]
	TIME [epoch: 9.77 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.114727572279606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.114727572279606 | validation: 3.7645288016798943]
	TIME [epoch: 9.76 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2267942165501204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2267942165501204 | validation: 2.904815203619477]
	TIME [epoch: 9.77 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.920290081321839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.920290081321839 | validation: 2.6991121822022697]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.811277879276836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.811277879276836 | validation: 2.7945055587193566]
	TIME [epoch: 9.75 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7645061921080236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7645061921080236 | validation: 2.6360106240588697]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9295054992692613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9295054992692613 | validation: 3.6676288149638134]
	TIME [epoch: 9.77 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0627575628711368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0627575628711368 | validation: 2.78976735780202]
	TIME [epoch: 9.74 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9305721262936597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9305721262936597 | validation: 2.701556277424653]
	TIME [epoch: 9.75 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8324728052580546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8324728052580546 | validation: 2.6851051457303248]
	TIME [epoch: 9.77 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8528667166115547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8528667166115547 | validation: 3.1001652011643865]
	TIME [epoch: 9.75 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.972545552430288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.972545552430288 | validation: 2.898393715477515]
	TIME [epoch: 9.74 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.02376651274896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.02376651274896 | validation: 4.76539004034549]
	TIME [epoch: 9.76 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.356068807892008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.356068807892008 | validation: 2.814690923530583]
	TIME [epoch: 9.75 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7295863579441506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7295863579441506 | validation: 2.6152673226752152]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5959628496604368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5959628496604368 | validation: 2.493722532164313]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5779365842499664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5779365842499664 | validation: 2.634882494072266]
	TIME [epoch: 9.74 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.651355417372966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.651355417372966 | validation: 3.6193703138608715]
	TIME [epoch: 9.74 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6132013419537463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6132013419537463 | validation: 3.174760215321038]
	TIME [epoch: 9.76 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7995448987583376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7995448987583376 | validation: 2.399275769050125]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5732489990227285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5732489990227285 | validation: 2.278125722421967]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8288733643775807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8288733643775807 | validation: 2.4153451020166528]
	TIME [epoch: 9.77 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5432702126642495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5432702126642495 | validation: 2.521752453450946]
	TIME [epoch: 9.78 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3762949530163153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3762949530163153 | validation: 2.2287274312292045]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7455808799477563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7455808799477563 | validation: 5.148995805811706]
	TIME [epoch: 9.76 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3789808850344913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3789808850344913 | validation: 2.8630882723568507]
	TIME [epoch: 9.78 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1630205684330717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1630205684330717 | validation: 2.545177378655671]
	TIME [epoch: 9.76 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2590171150099163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2590171150099163 | validation: 1.9330426471735211]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1399291600356705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1399291600356705 | validation: 2.614081869527738]
	TIME [epoch: 9.77 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.683259390574606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.683259390574606 | validation: 2.997422999893792]
	TIME [epoch: 9.75 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.723221008054519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.723221008054519 | validation: 2.149849499296627]
	TIME [epoch: 9.76 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4905737860380595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4905737860380595 | validation: 2.418723283521117]
	TIME [epoch: 9.77 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9489723419275866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9489723419275866 | validation: 2.932879786908758]
	TIME [epoch: 9.77 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4168694011008265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4168694011008265 | validation: 1.95726979728111]
	TIME [epoch: 9.76 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0016228166807677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0016228166807677 | validation: 2.553769962000819]
	TIME [epoch: 9.76 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.307701256778102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.307701256778102 | validation: 2.0243784376039042]
	TIME [epoch: 9.78 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1609452798561177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1609452798561177 | validation: 2.0057923499748678]
	TIME [epoch: 9.76 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.187497529052575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.187497529052575 | validation: 2.4001636516139304]
	TIME [epoch: 9.75 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9933497000823663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9933497000823663 | validation: 1.834007990032457]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7516684610382214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7516684610382214 | validation: 1.6630827962484591]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9023539498306472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9023539498306472 | validation: 1.5685708416357511]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6535769978073227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6535769978073227 | validation: 2.1109583547427877]
	TIME [epoch: 9.78 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6537462947915658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6537462947915658 | validation: 1.9780804954244724]
	TIME [epoch: 9.76 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6174244504545972		[learning rate: 0.0099806]
	Learning Rate: 0.00998063
	LOSS [training: 1.6174244504545972 | validation: 2.1067712143701005]
	TIME [epoch: 9.76 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4772794381823224		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 1.4772794381823224 | validation: 2.5311931073599148]
	TIME [epoch: 9.78 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.83043261596243		[learning rate: 0.0099324]
	Learning Rate: 0.00993236
	LOSS [training: 1.83043261596243 | validation: 1.2583593739911811]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.588178345619428		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 1.588178345619428 | validation: 5.086934685934834]
	TIME [epoch: 9.76 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3067778387299342		[learning rate: 0.0098843]
	Learning Rate: 0.00988433
	LOSS [training: 3.3067778387299342 | validation: 4.723962109443365]
	TIME [epoch: 9.78 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.153120921575749		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 4.153120921575749 | validation: 3.1067269983054002]
	TIME [epoch: 9.79 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1138050032264015		[learning rate: 0.0098365]
	Learning Rate: 0.00983653
	LOSS [training: 2.1138050032264015 | validation: 1.5985642056610112]
	TIME [epoch: 9.76 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.466708310435124		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 1.466708310435124 | validation: 1.4888079725059566]
	TIME [epoch: 9.75 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3843937833530657		[learning rate: 0.009789]
	Learning Rate: 0.00978897
	LOSS [training: 1.3843937833530657 | validation: 1.3817496795629682]
	TIME [epoch: 9.77 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4110035605271452		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 1.4110035605271452 | validation: 1.6529466625215832]
	TIME [epoch: 9.74 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.431515752900486		[learning rate: 0.0097416]
	Learning Rate: 0.00974163
	LOSS [training: 1.431515752900486 | validation: 1.7234444370562505]
	TIME [epoch: 9.75 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2104857553660784		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 1.2104857553660784 | validation: 1.3671135733108901]
	TIME [epoch: 9.77 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.15395921498351		[learning rate: 0.0096945]
	Learning Rate: 0.00969452
	LOSS [training: 1.15395921498351 | validation: 1.3455332430766676]
	TIME [epoch: 9.74 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0049267876656163		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 1.0049267876656163 | validation: 0.9242062724766424]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8497964382602738		[learning rate: 0.0096476]
	Learning Rate: 0.00964764
	LOSS [training: 0.8497964382602738 | validation: 1.0461610310205023]
	TIME [epoch: 9.78 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9410498406741808		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 0.9410498406741808 | validation: 0.9823598191253722]
	TIME [epoch: 9.75 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8786917286431724		[learning rate: 0.009601]
	Learning Rate: 0.00960098
	LOSS [training: 0.8786917286431724 | validation: 1.149277629898929]
	TIME [epoch: 9.75 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9356790302447529		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 0.9356790302447529 | validation: 0.8356448596039568]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8782377959176483		[learning rate: 0.0095546]
	Learning Rate: 0.00955456
	LOSS [training: 0.8782377959176483 | validation: 1.1616111451030149]
	TIME [epoch: 9.78 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8738223105721978		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 0.8738223105721978 | validation: 0.7168773444663998]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8647040154631925		[learning rate: 0.0095084]
	Learning Rate: 0.00950835
	LOSS [training: 0.8647040154631925 | validation: 0.7890565077541781]
	TIME [epoch: 9.76 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8592535034191388		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 0.8592535034191388 | validation: 0.7728811967200784]
	TIME [epoch: 9.78 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.720767978020377		[learning rate: 0.0094624]
	Learning Rate: 0.00946237
	LOSS [training: 0.720767978020377 | validation: 0.7483439275548225]
	TIME [epoch: 9.77 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0182872057155303		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 1.0182872057155303 | validation: 0.7988275488666665]
	TIME [epoch: 9.77 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7320825676371372		[learning rate: 0.0094166]
	Learning Rate: 0.00941661
	LOSS [training: 0.7320825676371372 | validation: 1.4164220249092268]
	TIME [epoch: 9.78 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9598678353435834		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 0.9598678353435834 | validation: 0.6412332823140808]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.885190040618061		[learning rate: 0.0093711]
	Learning Rate: 0.00937108
	LOSS [training: 1.885190040618061 | validation: 0.9936374241048869]
	TIME [epoch: 9.75 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.254866767087987		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 1.254866767087987 | validation: 0.8459263537188636]
	TIME [epoch: 9.77 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9573106703562196		[learning rate: 0.0093258]
	Learning Rate: 0.00932576
	LOSS [training: 0.9573106703562196 | validation: 0.6892473835241671]
	TIME [epoch: 9.76 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7972061055806241		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 0.7972061055806241 | validation: 0.7734595817674486]
	TIME [epoch: 9.76 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8125108948693116		[learning rate: 0.0092807]
	Learning Rate: 0.00928066
	LOSS [training: 0.8125108948693116 | validation: 1.2353186683211095]
	TIME [epoch: 9.77 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9079072869859152		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 0.9079072869859152 | validation: 1.0897051311025836]
	TIME [epoch: 9.78 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0902821313192106		[learning rate: 0.0092358]
	Learning Rate: 0.00923578
	LOSS [training: 1.0902821313192106 | validation: 0.764041187969799]
	TIME [epoch: 9.75 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4553882326374146		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 1.4553882326374146 | validation: 3.2843758520041932]
	TIME [epoch: 9.75 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.751095878152582		[learning rate: 0.0091911]
	Learning Rate: 0.00919112
	LOSS [training: 2.751095878152582 | validation: 2.9395429761287306]
	TIME [epoch: 9.78 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.037911206882545		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 2.037911206882545 | validation: 1.0722331488550507]
	TIME [epoch: 9.75 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0847665015330386		[learning rate: 0.0091467]
	Learning Rate: 0.00914667
	LOSS [training: 1.0847665015330386 | validation: 1.0297367046050439]
	TIME [epoch: 9.76 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.854601765480966		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 0.854601765480966 | validation: 1.0136006821038268]
	TIME [epoch: 9.77 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5992320934030595		[learning rate: 0.0091024]
	Learning Rate: 0.00910244
	LOSS [training: 1.5992320934030595 | validation: 0.9759383834645183]
	TIME [epoch: 9.76 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8606447482317705		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 0.8606447482317705 | validation: 0.6803253405691492]
	TIME [epoch: 9.75 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6770406201088048		[learning rate: 0.0090584]
	Learning Rate: 0.00905842
	LOSS [training: 0.6770406201088048 | validation: 0.9481002936899745]
	TIME [epoch: 9.78 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7288094160982312		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 0.7288094160982312 | validation: 0.7489883126407128]
	TIME [epoch: 9.75 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6735949292977391		[learning rate: 0.0090146]
	Learning Rate: 0.00901462
	LOSS [training: 0.6735949292977391 | validation: 0.7176976097447166]
	TIME [epoch: 9.75 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.899970852446209		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 0.899970852446209 | validation: 0.8089161841301773]
	TIME [epoch: 9.75 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7067241438084173		[learning rate: 0.008971]
	Learning Rate: 0.00897103
	LOSS [training: 0.7067241438084173 | validation: 0.6055686188826228]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.644799001927512		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 0.644799001927512 | validation: 0.8300084137872326]
	TIME [epoch: 9.76 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0315344392610766		[learning rate: 0.0089276]
	Learning Rate: 0.00892764
	LOSS [training: 1.0315344392610766 | validation: 0.7572285611349555]
	TIME [epoch: 9.76 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8020447526066464		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 0.8020447526066464 | validation: 0.6261532025808686]
	TIME [epoch: 9.78 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6255212644134289		[learning rate: 0.0088845]
	Learning Rate: 0.00888447
	LOSS [training: 0.6255212644134289 | validation: 0.8064315098902775]
	TIME [epoch: 9.77 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8386764064435344		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 0.8386764064435344 | validation: 0.5310009226178231]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0200388953834727		[learning rate: 0.0088415]
	Learning Rate: 0.00884151
	LOSS [training: 1.0200388953834727 | validation: 0.8309358498502895]
	TIME [epoch: 9.78 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7255333906081898		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 0.7255333906081898 | validation: 0.5971939439149696]
	TIME [epoch: 9.77 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7415028763901631		[learning rate: 0.0087988]
	Learning Rate: 0.00879875
	LOSS [training: 0.7415028763901631 | validation: 0.7489286128786218]
	TIME [epoch: 9.75 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6838607236013656		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 0.6838607236013656 | validation: 0.6151271332891466]
	TIME [epoch: 9.77 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5913106356837389		[learning rate: 0.0087562]
	Learning Rate: 0.0087562
	LOSS [training: 0.5913106356837389 | validation: 0.7640773059116203]
	TIME [epoch: 9.75 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5994566068991519		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 0.5994566068991519 | validation: 0.4923824793109801]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9431357781974095		[learning rate: 0.0087139]
	Learning Rate: 0.00871386
	LOSS [training: 0.9431357781974095 | validation: 0.5498168314620223]
	TIME [epoch: 9.77 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5928393096057992		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 0.5928393096057992 | validation: 0.531828567968923]
	TIME [epoch: 9.76 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5479500448720556		[learning rate: 0.0086717]
	Learning Rate: 0.00867172
	LOSS [training: 0.5479500448720556 | validation: 0.48725369333009283]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6755291105780528		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 0.6755291105780528 | validation: 0.8131643808065195]
	TIME [epoch: 9.76 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.667899089740055		[learning rate: 0.0086298]
	Learning Rate: 0.00862979
	LOSS [training: 0.667899089740055 | validation: 0.605070824485843]
	TIME [epoch: 9.77 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6010025992866741		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 0.6010025992866741 | validation: 0.627459538302715]
	TIME [epoch: 9.76 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5795772583674763		[learning rate: 0.0085881]
	Learning Rate: 0.00858805
	LOSS [training: 0.5795772583674763 | validation: 0.47706844366822365]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5897407380510273		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 0.5897407380510273 | validation: 0.4987702538019418]
	TIME [epoch: 9.78 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5967291424044947		[learning rate: 0.0085465]
	Learning Rate: 0.00854652
	LOSS [training: 0.5967291424044947 | validation: 0.5350352167424803]
	TIME [epoch: 9.75 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5756809155531171		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 0.5756809155531171 | validation: 0.463713647337479]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5516265853242533		[learning rate: 0.0085052]
	Learning Rate: 0.00850519
	LOSS [training: 0.5516265853242533 | validation: 0.8021845292379891]
	TIME [epoch: 9.78 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7464478382408266		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 0.7464478382408266 | validation: 0.7874881496699432]
	TIME [epoch: 9.77 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6511286362258264		[learning rate: 0.0084641]
	Learning Rate: 0.00846406
	LOSS [training: 0.6511286362258264 | validation: 0.5509923183044798]
	TIME [epoch: 9.77 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5760267625241846		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 0.5760267625241846 | validation: 0.48380749156612113]
	TIME [epoch: 9.76 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5729880175263492		[learning rate: 0.0084231]
	Learning Rate: 0.00842313
	LOSS [training: 0.5729880175263492 | validation: 0.7242361505876761]
	TIME [epoch: 9.75 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8252866420605673		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 0.8252866420605673 | validation: 0.5603639595720914]
	TIME [epoch: 9.74 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5562154833040647		[learning rate: 0.0083824]
	Learning Rate: 0.0083824
	LOSS [training: 0.5562154833040647 | validation: 0.5842204313359061]
	TIME [epoch: 9.76 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5236859813605446		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 0.5236859813605446 | validation: 0.5562969815155693]
	TIME [epoch: 9.76 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6203096494647491		[learning rate: 0.0083419]
	Learning Rate: 0.00834186
	LOSS [training: 0.6203096494647491 | validation: 0.5987490631457283]
	TIME [epoch: 9.75 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5497441887709875		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 0.5497441887709875 | validation: 0.4412100423536666]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5463444804962606		[learning rate: 0.0083015]
	Learning Rate: 0.00830153
	LOSS [training: 0.5463444804962606 | validation: 0.49014391429277726]
	TIME [epoch: 9.76 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6865356104703362		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 0.6865356104703362 | validation: 0.5987631424748834]
	TIME [epoch: 9.74 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5408748063954114		[learning rate: 0.0082614]
	Learning Rate: 0.00826138
	LOSS [training: 0.5408748063954114 | validation: 0.4461875526694155]
	TIME [epoch: 9.75 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5882136269423409		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.5882136269423409 | validation: 0.49281246635730264]
	TIME [epoch: 9.76 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5676225155825422		[learning rate: 0.0082214]
	Learning Rate: 0.00822143
	LOSS [training: 0.5676225155825422 | validation: 0.6442663480980493]
	TIME [epoch: 9.77 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5234374721404873		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 0.5234374721404873 | validation: 0.5297773611207477]
	TIME [epoch: 9.75 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5208086944755002		[learning rate: 0.0081817]
	Learning Rate: 0.00818167
	LOSS [training: 0.5208086944755002 | validation: 0.6187435190709073]
	TIME [epoch: 9.78 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5322493545214732		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 0.5322493545214732 | validation: 0.6237005433179655]
	TIME [epoch: 9.75 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5338481394677325		[learning rate: 0.0081421]
	Learning Rate: 0.00814211
	LOSS [training: 0.5338481394677325 | validation: 1.3480679101450608]
	TIME [epoch: 9.75 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.828239610575299		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 0.828239610575299 | validation: 0.5924562613258929]
	TIME [epoch: 9.75 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.033080208424197		[learning rate: 0.0081027]
	Learning Rate: 0.00810273
	LOSS [training: 1.033080208424197 | validation: 0.791606625503006]
	TIME [epoch: 9.76 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6109438691588126		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 0.6109438691588126 | validation: 0.6878362142203427]
	TIME [epoch: 9.76 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344412971043166		[learning rate: 0.0080636]
	Learning Rate: 0.00806355
	LOSS [training: 0.5344412971043166 | validation: 0.5350437539211812]
	TIME [epoch: 9.74 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5021825650633776		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 0.5021825650633776 | validation: 0.4314022977880771]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49786671036702695		[learning rate: 0.0080246]
	Learning Rate: 0.00802456
	LOSS [training: 0.49786671036702695 | validation: 0.44681824910947826]
	TIME [epoch: 9.78 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5143749136273492		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 0.5143749136273492 | validation: 0.483096532280657]
	TIME [epoch: 9.77 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5224697879676673		[learning rate: 0.0079858]
	Learning Rate: 0.00798575
	LOSS [training: 0.5224697879676673 | validation: 0.4308245924273307]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48496583523899395		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 0.48496583523899395 | validation: 0.5416005148923031]
	TIME [epoch: 9.77 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7751831389900417		[learning rate: 0.0079471]
	Learning Rate: 0.00794713
	LOSS [training: 0.7751831389900417 | validation: 0.4980262284510837]
	TIME [epoch: 9.78 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5287545729406314		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 0.5287545729406314 | validation: 0.4537045975691186]
	TIME [epoch: 9.78 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5096349116024109		[learning rate: 0.0079087]
	Learning Rate: 0.0079087
	LOSS [training: 0.5096349116024109 | validation: 0.4437835782480502]
	TIME [epoch: 9.78 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5086835007547675		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 0.5086835007547675 | validation: 0.7316794557310289]
	TIME [epoch: 9.77 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.552016770503684		[learning rate: 0.0078705]
	Learning Rate: 0.00787046
	LOSS [training: 0.552016770503684 | validation: 0.43859848961514203]
	TIME [epoch: 9.78 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4992888362833593		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 0.4992888362833593 | validation: 0.4331129377255375]
	TIME [epoch: 9.79 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5574698849031313		[learning rate: 0.0078324]
	Learning Rate: 0.0078324
	LOSS [training: 0.5574698849031313 | validation: 0.5291972086253043]
	TIME [epoch: 9.77 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4803766769271235		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 0.4803766769271235 | validation: 0.4529685883229212]
	TIME [epoch: 9.76 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4789319131156787		[learning rate: 0.0077945]
	Learning Rate: 0.00779452
	LOSS [training: 0.4789319131156787 | validation: 0.46994550084785747]
	TIME [epoch: 9.78 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4928353625234901		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 0.4928353625234901 | validation: 0.4357919530589193]
	TIME [epoch: 9.77 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5357651156778312		[learning rate: 0.0077568]
	Learning Rate: 0.00775683
	LOSS [training: 0.5357651156778312 | validation: 0.36962685028683545]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4016852030367016		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 0.4016852030367016 | validation: 0.38071922530507474]
	TIME [epoch: 9.79 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.782626814811803		[learning rate: 0.0077193]
	Learning Rate: 0.00771932
	LOSS [training: 1.782626814811803 | validation: 0.7284517315882232]
	TIME [epoch: 9.77 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5565973115406303		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 0.5565973115406303 | validation: 0.8724943364413544]
	TIME [epoch: 9.76 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6286573094667673		[learning rate: 0.007682]
	Learning Rate: 0.00768199
	LOSS [training: 0.6286573094667673 | validation: 0.46485099296078985]
	TIME [epoch: 9.79 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47253805563068807		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 0.47253805563068807 | validation: 0.7394969546641835]
	TIME [epoch: 9.77 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5950598646832417		[learning rate: 0.0076448]
	Learning Rate: 0.00764484
	LOSS [training: 0.5950598646832417 | validation: 0.42246490577030577]
	TIME [epoch: 9.78 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4486701328257481		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 0.4486701328257481 | validation: 0.4598168675573168]
	TIME [epoch: 9.77 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.830098912556296		[learning rate: 0.0076079]
	Learning Rate: 0.00760787
	LOSS [training: 1.830098912556296 | validation: 2.8233116579915456]
	TIME [epoch: 9.79 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.650472017699749		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 2.650472017699749 | validation: 2.721819097616143]
	TIME [epoch: 9.76 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5057746342107707		[learning rate: 0.0075711]
	Learning Rate: 0.00757108
	LOSS [training: 2.5057746342107707 | validation: 2.671572415081402]
	TIME [epoch: 9.77 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4997871272678154		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 2.4997871272678154 | validation: 2.6987462848517523]
	TIME [epoch: 9.79 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4868510957292975		[learning rate: 0.0075345]
	Learning Rate: 0.00753447
	LOSS [training: 2.4868510957292975 | validation: 2.6779414987385564]
	TIME [epoch: 9.77 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.630645061006685		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.630645061006685 | validation: 0.9868475578877376]
	TIME [epoch: 9.77 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.652999806177687		[learning rate: 0.007498]
	Learning Rate: 0.00749803
	LOSS [training: 0.652999806177687 | validation: 0.5071421599794046]
	TIME [epoch: 9.79 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46524423615735033		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 0.46524423615735033 | validation: 0.4766567016075114]
	TIME [epoch: 9.77 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.488043007447337		[learning rate: 0.0074618]
	Learning Rate: 0.00746177
	LOSS [training: 1.488043007447337 | validation: 0.45738275780241056]
	TIME [epoch: 9.76 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.478024574016713		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 0.478024574016713 | validation: 0.4750445060092308]
	TIME [epoch: 9.78 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4873946516490588		[learning rate: 0.0074257]
	Learning Rate: 0.00742569
	LOSS [training: 0.4873946516490588 | validation: 0.4984754708810089]
	TIME [epoch: 9.77 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4691579909597313		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 0.4691579909597313 | validation: 0.3727263194355394]
	TIME [epoch: 9.77 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44117379118051836		[learning rate: 0.0073898]
	Learning Rate: 0.00738978
	LOSS [training: 0.44117379118051836 | validation: 0.39720353657773205]
	TIME [epoch: 9.77 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4771998072387203		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 0.4771998072387203 | validation: 0.4039145921221145]
	TIME [epoch: 9.79 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42325653007767733		[learning rate: 0.007354]
	Learning Rate: 0.00735405
	LOSS [training: 0.42325653007767733 | validation: 0.41673141783881196]
	TIME [epoch: 9.77 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5524777049317369		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 0.5524777049317369 | validation: 0.4483816813055258]
	TIME [epoch: 9.77 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38375325633963076		[learning rate: 0.0073185]
	Learning Rate: 0.00731848
	LOSS [training: 0.38375325633963076 | validation: 0.32684322548225203]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4182581885468049		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 0.4182581885468049 | validation: 0.4088909686508002]
	TIME [epoch: 9.77 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.474246917667729		[learning rate: 0.0072831]
	Learning Rate: 0.00728309
	LOSS [training: 0.474246917667729 | validation: 0.4049238010172332]
	TIME [epoch: 9.76 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42698470673735117		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 0.42698470673735117 | validation: 0.338376911172873]
	TIME [epoch: 9.79 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45505781614199525		[learning rate: 0.0072479]
	Learning Rate: 0.00724787
	LOSS [training: 0.45505781614199525 | validation: 0.4720093281829298]
	TIME [epoch: 9.76 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5898489163672032		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 0.5898489163672032 | validation: 0.7569644149514563]
	TIME [epoch: 9.76 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5760092638828203		[learning rate: 0.0072128]
	Learning Rate: 0.00721282
	LOSS [training: 0.5760092638828203 | validation: 0.9036180166926114]
	TIME [epoch: 9.77 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.642960120390196		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 0.642960120390196 | validation: 0.5150470106433217]
	TIME [epoch: 9.75 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8908353600000275		[learning rate: 0.0071779]
	Learning Rate: 0.00717794
	LOSS [training: 0.8908353600000275 | validation: 0.8842571821041861]
	TIME [epoch: 9.75 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6614218288977058		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 0.6614218288977058 | validation: 0.48625253705842]
	TIME [epoch: 9.76 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5428788522523338		[learning rate: 0.0071432]
	Learning Rate: 0.00714323
	LOSS [training: 0.5428788522523338 | validation: 0.47625763118298153]
	TIME [epoch: 9.76 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4464512281072809		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 0.4464512281072809 | validation: 0.5693970422497049]
	TIME [epoch: 9.77 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47098223981893217		[learning rate: 0.0071087]
	Learning Rate: 0.00710869
	LOSS [training: 0.47098223981893217 | validation: 0.39649342162207546]
	TIME [epoch: 9.76 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4211462924994894		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 0.4211462924994894 | validation: 0.3333382279680334]
	TIME [epoch: 9.78 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.257881997776685		[learning rate: 0.0070743]
	Learning Rate: 0.00707431
	LOSS [training: 1.257881997776685 | validation: 1.3946072760137644]
	TIME [epoch: 9.76 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.919676294040254		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 0.919676294040254 | validation: 0.7634735488344615]
	TIME [epoch: 9.76 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5890397925615087		[learning rate: 0.0070401]
	Learning Rate: 0.0070401
	LOSS [training: 0.5890397925615087 | validation: 0.6235284772812191]
	TIME [epoch: 9.78 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47765696449624784		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.47765696449624784 | validation: 0.36967009005477885]
	TIME [epoch: 9.76 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36727706793093895		[learning rate: 0.0070061]
	Learning Rate: 0.00700606
	LOSS [training: 0.36727706793093895 | validation: 0.4105087948510169]
	TIME [epoch: 9.75 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4187582093933024		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 0.4187582093933024 | validation: 0.36179083196704553]
	TIME [epoch: 9.78 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41310210750797827		[learning rate: 0.0069722]
	Learning Rate: 0.00697218
	LOSS [training: 0.41310210750797827 | validation: 0.42360200242120655]
	TIME [epoch: 9.76 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4020731373522783		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 0.4020731373522783 | validation: 0.4028823568198986]
	TIME [epoch: 9.76 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46893492717795204		[learning rate: 0.0069385]
	Learning Rate: 0.00693846
	LOSS [training: 0.46893492717795204 | validation: 0.36080929201566336]
	TIME [epoch: 9.77 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40641684173638726		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.40641684173638726 | validation: 0.3849408793643059]
	TIME [epoch: 9.77 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4151722985703219		[learning rate: 0.0069049]
	Learning Rate: 0.00690491
	LOSS [training: 0.4151722985703219 | validation: 1.1340065111893578]
	TIME [epoch: 9.76 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8551051032712023		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 0.8551051032712023 | validation: 0.44799692182144685]
	TIME [epoch: 9.76 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5094784875311038		[learning rate: 0.0068715]
	Learning Rate: 0.00687152
	LOSS [training: 0.5094784875311038 | validation: 0.3733985361917085]
	TIME [epoch: 9.77 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.535048170076937		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.535048170076937 | validation: 0.6068312561732706]
	TIME [epoch: 9.76 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5692457517050871		[learning rate: 0.0068383]
	Learning Rate: 0.00683829
	LOSS [training: 0.5692457517050871 | validation: 0.8961046552162258]
	TIME [epoch: 9.76 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5410321066891928		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 0.5410321066891928 | validation: 0.3811816511555105]
	TIME [epoch: 9.78 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.677282616865748		[learning rate: 0.0068052]
	Learning Rate: 0.00680522
	LOSS [training: 0.677282616865748 | validation: 0.8255800200485588]
	TIME [epoch: 9.76 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6188080905109378		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.6188080905109378 | validation: 0.5928806015676156]
	TIME [epoch: 9.77 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4307831577085148		[learning rate: 0.0067723]
	Learning Rate: 0.00677231
	LOSS [training: 0.4307831577085148 | validation: 0.34542452981699256]
	TIME [epoch: 9.78 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47482727873061625		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.47482727873061625 | validation: 0.34103858913380364]
	TIME [epoch: 9.76 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3512412782305745		[learning rate: 0.0067396]
	Learning Rate: 0.00673956
	LOSS [training: 0.3512412782305745 | validation: 0.32093843679855427]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7911596101035935		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.7911596101035935 | validation: 0.6393463543508885]
	TIME [epoch: 9.77 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5111227839340299		[learning rate: 0.006707]
	Learning Rate: 0.00670697
	LOSS [training: 0.5111227839340299 | validation: 0.558889484734915]
	TIME [epoch: 9.78 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4559543417899749		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.4559543417899749 | validation: 0.4668960844522062]
	TIME [epoch: 9.76 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38240450598479175		[learning rate: 0.0066745]
	Learning Rate: 0.00667454
	LOSS [training: 0.38240450598479175 | validation: 0.4772583757438788]
	TIME [epoch: 9.77 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4770230587435241		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.4770230587435241 | validation: 0.4955852481312863]
	TIME [epoch: 9.77 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2330984300399408		[learning rate: 0.0066423]
	Learning Rate: 0.00664226
	LOSS [training: 1.2330984300399408 | validation: 1.0334188940248845]
	TIME [epoch: 9.76 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7404590516022774		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.7404590516022774 | validation: 0.39214112167912163]
	TIME [epoch: 9.76 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3747550721900104		[learning rate: 0.0066101]
	Learning Rate: 0.00661014
	LOSS [training: 0.3747550721900104 | validation: 0.34653312474848075]
	TIME [epoch: 9.78 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34645789584209585		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.34645789584209585 | validation: 0.3319877092257657]
	TIME [epoch: 9.76 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.390498570828106		[learning rate: 0.0065782]
	Learning Rate: 0.00657817
	LOSS [training: 0.390498570828106 | validation: 0.36557767655098744]
	TIME [epoch: 9.76 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.831251418284376		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.831251418284376 | validation: 0.5651119530795762]
	TIME [epoch: 9.77 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45691216935693346		[learning rate: 0.0065464]
	Learning Rate: 0.00654636
	LOSS [training: 0.45691216935693346 | validation: 0.3119432909992523]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3068818447934274		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 0.3068818447934274 | validation: 0.585615223003695]
	TIME [epoch: 9.76 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35648803481851365		[learning rate: 0.0065147]
	Learning Rate: 0.0065147
	LOSS [training: 0.35648803481851365 | validation: 0.6173917688835237]
	TIME [epoch: 9.77 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5049881052966781		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.5049881052966781 | validation: 0.3657459149159412]
	TIME [epoch: 9.76 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3477238430226811		[learning rate: 0.0064832]
	Learning Rate: 0.0064832
	LOSS [training: 0.3477238430226811 | validation: 0.3885169739400595]
	TIME [epoch: 9.76 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.360031735761812		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.360031735761812 | validation: 0.3820978058567087]
	TIME [epoch: 9.76 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3980513555457855		[learning rate: 0.0064518]
	Learning Rate: 0.00645185
	LOSS [training: 0.3980513555457855 | validation: 0.3735392185926068]
	TIME [epoch: 9.77 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3943148028219961		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.3943148028219961 | validation: 0.31036337772366707]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41319046046094526		[learning rate: 0.0064206]
	Learning Rate: 0.00642065
	LOSS [training: 0.41319046046094526 | validation: 0.4054957310906114]
	TIME [epoch: 9.76 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38779364911122427		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.38779364911122427 | validation: 0.4540521324322068]
	TIME [epoch: 9.78 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39043474678305656		[learning rate: 0.0063896]
	Learning Rate: 0.0063896
	LOSS [training: 0.39043474678305656 | validation: 0.33864845232003526]
	TIME [epoch: 9.75 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4367790813446538		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.4367790813446538 | validation: 0.4035065392275059]
	TIME [epoch: 9.75 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5086977523730682		[learning rate: 0.0063587]
	Learning Rate: 0.0063587
	LOSS [training: 1.5086977523730682 | validation: 0.2567285064091359]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_287.pth
	Model improved!!!
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4463823298367461		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.4463823298367461 | validation: 0.3755470184130686]
	TIME [epoch: 9.76 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36708678404616435		[learning rate: 0.006328]
	Learning Rate: 0.00632795
	LOSS [training: 0.36708678404616435 | validation: 0.34593183954515566]
	TIME [epoch: 9.76 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37092831374550916		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.37092831374550916 | validation: 0.3452639472708586]
	TIME [epoch: 9.77 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35942445144450835		[learning rate: 0.0062974]
	Learning Rate: 0.00629735
	LOSS [training: 0.35942445144450835 | validation: 0.6746330730102613]
	TIME [epoch: 9.76 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43514853035807394		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.43514853035807394 | validation: 0.40262213752960896]
	TIME [epoch: 9.76 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38900893402275033		[learning rate: 0.0062669]
	Learning Rate: 0.0062669
	LOSS [training: 0.38900893402275033 | validation: 0.37145130223085987]
	TIME [epoch: 9.77 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4094582097464704		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.4094582097464704 | validation: 0.34734819610280715]
	TIME [epoch: 9.77 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36814275466263124		[learning rate: 0.0062366]
	Learning Rate: 0.00623659
	LOSS [training: 0.36814275466263124 | validation: 0.31470682408738226]
	TIME [epoch: 9.77 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.402541617023018		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 1.402541617023018 | validation: 1.0923182082772243]
	TIME [epoch: 9.76 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9817882232912337		[learning rate: 0.0062064]
	Learning Rate: 0.00620643
	LOSS [training: 0.9817882232912337 | validation: 0.549727202260039]
	TIME [epoch: 9.78 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4112241519282458		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.4112241519282458 | validation: 0.3586402056731005]
	TIME [epoch: 9.76 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2994867546422458		[learning rate: 0.0061764]
	Learning Rate: 0.00617642
	LOSS [training: 0.2994867546422458 | validation: 0.33818080604203893]
	TIME [epoch: 9.76 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0931905893605216		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 1.0931905893605216 | validation: 1.0379562383181995]
	TIME [epoch: 9.77 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6504000090927502		[learning rate: 0.0061466]
	Learning Rate: 0.00614655
	LOSS [training: 0.6504000090927502 | validation: 0.38454576624633163]
	TIME [epoch: 9.76 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43555060385238936		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.43555060385238936 | validation: 0.4056807852627756]
	TIME [epoch: 9.75 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45145882791360104		[learning rate: 0.0061168]
	Learning Rate: 0.00611683
	LOSS [training: 0.45145882791360104 | validation: 0.40556534799935223]
	TIME [epoch: 9.77 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4428782641053345		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.4428782641053345 | validation: 0.6752290498632937]
	TIME [epoch: 9.76 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4909139946139947		[learning rate: 0.0060872]
	Learning Rate: 0.00608725
	LOSS [training: 2.4909139946139947 | validation: 2.5192569464641084]
	TIME [epoch: 9.76 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0545023645224287		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 1.0545023645224287 | validation: 0.49346458762165674]
	TIME [epoch: 9.77 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39660141279308436		[learning rate: 0.0060578]
	Learning Rate: 0.00605781
	LOSS [training: 0.39660141279308436 | validation: 0.5572350808581158]
	TIME [epoch: 9.78 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.591905357910069		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.591905357910069 | validation: 0.3986744579074295]
	TIME [epoch: 9.75 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4231364826688594		[learning rate: 0.0060285]
	Learning Rate: 0.00602852
	LOSS [training: 0.4231364826688594 | validation: 0.40285378353249657]
	TIME [epoch: 9.75 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37779892480777655		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 0.37779892480777655 | validation: 0.36947219265231973]
	TIME [epoch: 9.78 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41226769507196037		[learning rate: 0.0059994]
	Learning Rate: 0.00599936
	LOSS [training: 0.41226769507196037 | validation: 1.5301768901954063]
	TIME [epoch: 9.76 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6879598957285625		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 0.6879598957285625 | validation: 0.5954710706376349]
	TIME [epoch: 9.76 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7719053489806454		[learning rate: 0.0059704]
	Learning Rate: 0.00597035
	LOSS [training: 0.7719053489806454 | validation: 0.8334424432469696]
	TIME [epoch: 9.78 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5788113878046252		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.5788113878046252 | validation: 0.2841524938074889]
	TIME [epoch: 9.76 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4038520382889049		[learning rate: 0.0059415]
	Learning Rate: 0.00594148
	LOSS [training: 0.4038520382889049 | validation: 0.35360606412184437]
	TIME [epoch: 9.76 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6062611384681186		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.6062611384681186 | validation: 0.42715649603988554]
	TIME [epoch: 9.77 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3905874275722468		[learning rate: 0.0059127]
	Learning Rate: 0.00591275
	LOSS [training: 0.3905874275722468 | validation: 0.3027224075687287]
	TIME [epoch: 9.76 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.477823163607164		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.477823163607164 | validation: 0.4506038729548487]
	TIME [epoch: 9.76 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4472638205460414		[learning rate: 0.0058842]
	Learning Rate: 0.00588416
	LOSS [training: 0.4472638205460414 | validation: 0.3364426060566551]
	TIME [epoch: 9.76 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.395833703677891		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.395833703677891 | validation: 0.33778403940023066]
	TIME [epoch: 9.77 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38519534259822275		[learning rate: 0.0058557]
	Learning Rate: 0.0058557
	LOSS [training: 0.38519534259822275 | validation: 0.41659843881412373]
	TIME [epoch: 9.77 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4667262063669303		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.4667262063669303 | validation: 0.38348193519996865]
	TIME [epoch: 9.76 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4080742757367261		[learning rate: 0.0058274]
	Learning Rate: 0.00582738
	LOSS [training: 0.4080742757367261 | validation: 0.46228970220620713]
	TIME [epoch: 9.78 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4316541690761043		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.4316541690761043 | validation: 0.4981601725319354]
	TIME [epoch: 9.76 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45396956996680754		[learning rate: 0.0057992]
	Learning Rate: 0.0057992
	LOSS [training: 0.45396956996680754 | validation: 0.41706869910972727]
	TIME [epoch: 9.76 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4007510701610461		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.4007510701610461 | validation: 0.3568391923381454]
	TIME [epoch: 9.77 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37309275296874456		[learning rate: 0.0057712]
	Learning Rate: 0.00577116
	LOSS [training: 0.37309275296874456 | validation: 0.5568932396268045]
	TIME [epoch: 9.77 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4546111625575301		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.4546111625575301 | validation: 0.3538593884327444]
	TIME [epoch: 9.76 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3890920732903509		[learning rate: 0.0057433]
	Learning Rate: 0.00574325
	LOSS [training: 0.3890920732903509 | validation: 0.4097389253550191]
	TIME [epoch: 9.77 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.443183343305879		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.443183343305879 | validation: 0.31875695401227494]
	TIME [epoch: 9.75 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9780851625086935		[learning rate: 0.0057155]
	Learning Rate: 0.00571548
	LOSS [training: 0.9780851625086935 | validation: 0.6825740470574203]
	TIME [epoch: 9.75 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8493079384530968		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.8493079384530968 | validation: 1.386991027650129]
	TIME [epoch: 9.76 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3709849231749383		[learning rate: 0.0056878]
	Learning Rate: 0.00568784
	LOSS [training: 1.3709849231749383 | validation: 0.9407276429663536]
	TIME [epoch: 9.76 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7937605457998886		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.7937605457998886 | validation: 0.5788078483933725]
	TIME [epoch: 9.76 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5154938311142987		[learning rate: 0.0056603]
	Learning Rate: 0.00566033
	LOSS [training: 0.5154938311142987 | validation: 0.4707225373327718]
	TIME [epoch: 9.76 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36836311170261127		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.36836311170261127 | validation: 0.45609758679247975]
	TIME [epoch: 9.78 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49304092618537804		[learning rate: 0.005633]
	Learning Rate: 0.00563296
	LOSS [training: 0.49304092618537804 | validation: 0.7101755522784546]
	TIME [epoch: 9.76 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.774563432381177		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.774563432381177 | validation: 1.17375346840325]
	TIME [epoch: 9.76 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.702266103208552		[learning rate: 0.0056057]
	Learning Rate: 0.00560572
	LOSS [training: 0.702266103208552 | validation: 0.2791521504626759]
	TIME [epoch: 9.79 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26813833649614		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.26813833649614 | validation: 0.4981664743289916]
	TIME [epoch: 9.75 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3883007633949168		[learning rate: 0.0055786]
	Learning Rate: 0.00557861
	LOSS [training: 0.3883007633949168 | validation: 0.37696590074430975]
	TIME [epoch: 9.75 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3274305985755845		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.3274305985755845 | validation: 0.3804456363976352]
	TIME [epoch: 9.77 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3827198672211175		[learning rate: 0.0055516]
	Learning Rate: 0.00555164
	LOSS [training: 0.3827198672211175 | validation: 0.3136734230415033]
	TIME [epoch: 9.75 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3553382944008793		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.3553382944008793 | validation: 0.4156654954454787]
	TIME [epoch: 9.75 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45183978182736356		[learning rate: 0.0055248]
	Learning Rate: 0.00552479
	LOSS [training: 0.45183978182736356 | validation: 1.4019542797833873]
	TIME [epoch: 9.77 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6811827822848671		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.6811827822848671 | validation: 0.446108172110085]
	TIME [epoch: 9.77 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42098595587054827		[learning rate: 0.0054981]
	Learning Rate: 0.00549807
	LOSS [training: 0.42098595587054827 | validation: 0.3644179807323746]
	TIME [epoch: 9.75 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39229146255135866		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.39229146255135866 | validation: 4.000207699982871]
	TIME [epoch: 9.76 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.540034703541413		[learning rate: 0.0054715]
	Learning Rate: 0.00547149
	LOSS [training: 1.540034703541413 | validation: 0.3334803509986922]
	TIME [epoch: 9.77 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.361297361570797		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.361297361570797 | validation: 0.34025337883391943]
	TIME [epoch: 9.76 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38284427533392984		[learning rate: 0.005445]
	Learning Rate: 0.00544503
	LOSS [training: 0.38284427533392984 | validation: 0.33057027111067355]
	TIME [epoch: 9.75 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40633173697071134		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.40633173697071134 | validation: 0.33327211785481603]
	TIME [epoch: 9.78 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40070837607434473		[learning rate: 0.0054187]
	Learning Rate: 0.0054187
	LOSS [training: 0.40070837607434473 | validation: 0.33782311924574815]
	TIME [epoch: 9.75 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3617242255485747		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.3617242255485747 | validation: 0.3098518452991932]
	TIME [epoch: 9.75 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3512000338780183		[learning rate: 0.0053925]
	Learning Rate: 0.00539249
	LOSS [training: 0.3512000338780183 | validation: 0.3421868325254264]
	TIME [epoch: 9.77 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37184684600938417		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.37184684600938417 | validation: 0.386004425054753]
	TIME [epoch: 9.75 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38573965189647896		[learning rate: 0.0053664]
	Learning Rate: 0.00536641
	LOSS [training: 0.38573965189647896 | validation: 0.3775799901895664]
	TIME [epoch: 9.75 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.438462260453492		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.438462260453492 | validation: 0.31070365998662886]
	TIME [epoch: 9.75 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5372227169515121		[learning rate: 0.0053405]
	Learning Rate: 0.00534046
	LOSS [training: 0.5372227169515121 | validation: 0.5899543696311796]
	TIME [epoch: 9.76 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5237936523764598		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.5237936523764598 | validation: 1.8159405120397072]
	TIME [epoch: 9.75 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.289405582217651		[learning rate: 0.0053146]
	Learning Rate: 0.00531464
	LOSS [training: 1.289405582217651 | validation: 1.2831094951017858]
	TIME [epoch: 9.75 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6651332948870925		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.6651332948870925 | validation: 0.37476923465734213]
	TIME [epoch: 9.77 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5291838260711396		[learning rate: 0.0052889]
	Learning Rate: 0.00528894
	LOSS [training: 0.5291838260711396 | validation: 0.5426430597147437]
	TIME [epoch: 9.75 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4148169263440125		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.4148169263440125 | validation: 0.3902541221708636]
	TIME [epoch: 9.75 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5251377852770613		[learning rate: 0.0052634]
	Learning Rate: 0.00526336
	LOSS [training: 0.5251377852770613 | validation: 0.4690448148702393]
	TIME [epoch: 9.77 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42593483963801637		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.42593483963801637 | validation: 0.25131121482792224]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27475011811499506		[learning rate: 0.0052379]
	Learning Rate: 0.00523791
	LOSS [training: 0.27475011811499506 | validation: 0.22928755016077695]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28473687518755697		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.28473687518755697 | validation: 0.3890751007489493]
	TIME [epoch: 9.78 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41108328961806545		[learning rate: 0.0052126]
	Learning Rate: 0.00521258
	LOSS [training: 0.41108328961806545 | validation: 0.3566574062964127]
	TIME [epoch: 9.76 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.345426414923257		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.345426414923257 | validation: 0.33774712641230137]
	TIME [epoch: 9.75 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.324253809499299		[learning rate: 0.0051874]
	Learning Rate: 0.00518737
	LOSS [training: 0.324253809499299 | validation: 0.3543499736480901]
	TIME [epoch: 9.75 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3412744490922798		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.3412744490922798 | validation: 0.3562465420468914]
	TIME [epoch: 9.77 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.354797786683541		[learning rate: 0.0051623]
	Learning Rate: 0.00516229
	LOSS [training: 0.354797786683541 | validation: 0.34592465386256166]
	TIME [epoch: 9.75 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34717908215144516		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.34717908215144516 | validation: 0.32731324560936353]
	TIME [epoch: 9.75 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35574791103125547		[learning rate: 0.0051373]
	Learning Rate: 0.00513732
	LOSS [training: 0.35574791103125547 | validation: 0.32171102481638714]
	TIME [epoch: 9.77 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3765342783493385		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.3765342783493385 | validation: 0.4230850589583294]
	TIME [epoch: 9.75 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3908560053930251		[learning rate: 0.0051125]
	Learning Rate: 0.00511248
	LOSS [training: 0.3908560053930251 | validation: 0.33841110730789564]
	TIME [epoch: 9.75 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31194533910993427		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.31194533910993427 | validation: 0.4059829129666454]
	TIME [epoch: 9.77 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36094768946942396		[learning rate: 0.0050878]
	Learning Rate: 0.00508776
	LOSS [training: 0.36094768946942396 | validation: 0.41101982578225893]
	TIME [epoch: 9.75 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3538153527376874		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.3538153527376874 | validation: 0.3394442736211823]
	TIME [epoch: 9.75 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4074638193261443		[learning rate: 0.0050632]
	Learning Rate: 0.00506315
	LOSS [training: 0.4074638193261443 | validation: 0.44364519753430337]
	TIME [epoch: 9.77 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3924914476028447		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.3924914476028447 | validation: 0.4911543101293057]
	TIME [epoch: 9.76 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34045582063294366		[learning rate: 0.0050387]
	Learning Rate: 0.00503867
	LOSS [training: 0.34045582063294366 | validation: 0.25379113620664373]
	TIME [epoch: 9.75 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3038553373307294		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.3038553373307294 | validation: 0.49646606835821455]
	TIME [epoch: 9.75 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38327612199914196		[learning rate: 0.0050143]
	Learning Rate: 0.0050143
	LOSS [training: 0.38327612199914196 | validation: 0.3617196309090068]
	TIME [epoch: 9.77 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42910624810825687		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.42910624810825687 | validation: 0.2595247304678703]
	TIME [epoch: 9.76 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32120008467206274		[learning rate: 0.0049901]
	Learning Rate: 0.00499005
	LOSS [training: 0.32120008467206274 | validation: 0.3631370842933492]
	TIME [epoch: 9.75 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34249776108563595		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.34249776108563595 | validation: 0.3011734397351158]
	TIME [epoch: 9.77 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44294753845884155		[learning rate: 0.0049659]
	Learning Rate: 0.00496592
	LOSS [training: 0.44294753845884155 | validation: 0.29828468789854357]
	TIME [epoch: 9.75 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29255864917886854		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.29255864917886854 | validation: 0.3107356016826854]
	TIME [epoch: 9.75 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3471571002832398		[learning rate: 0.0049419]
	Learning Rate: 0.00494191
	LOSS [training: 0.3471571002832398 | validation: 0.26137634400212606]
	TIME [epoch: 9.77 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31028162141526955		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.31028162141526955 | validation: 0.2961819709325676]
	TIME [epoch: 9.75 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29587602785969214		[learning rate: 0.004918]
	Learning Rate: 0.00491801
	LOSS [training: 0.29587602785969214 | validation: 0.48088581289196203]
	TIME [epoch: 9.75 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37920865179592955		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.37920865179592955 | validation: 0.28344068144245943]
	TIME [epoch: 9.77 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3233233479664689		[learning rate: 0.0048942]
	Learning Rate: 0.00489423
	LOSS [training: 0.3233233479664689 | validation: 0.32331605515665773]
	TIME [epoch: 9.75 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43639770370550657		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.43639770370550657 | validation: 0.7579416832775602]
	TIME [epoch: 9.75 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5133886035316177		[learning rate: 0.0048706]
	Learning Rate: 0.00487056
	LOSS [training: 0.5133886035316177 | validation: 0.44340678373749465]
	TIME [epoch: 9.74 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35098272538638325		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.35098272538638325 | validation: 0.2851051589650059]
	TIME [epoch: 9.77 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3199428126839875		[learning rate: 0.004847]
	Learning Rate: 0.00484701
	LOSS [training: 0.3199428126839875 | validation: 0.45422438773304247]
	TIME [epoch: 9.74 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39034162805087164		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.39034162805087164 | validation: 0.32274653050393276]
	TIME [epoch: 9.75 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3329404673223986		[learning rate: 0.0048236]
	Learning Rate: 0.00482357
	LOSS [training: 0.3329404673223986 | validation: 0.4836550683147682]
	TIME [epoch: 9.77 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3929632664704362		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.3929632664704362 | validation: 0.3043719574582386]
	TIME [epoch: 9.75 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.10670116975555		[learning rate: 0.0048002]
	Learning Rate: 0.00480024
	LOSS [training: 1.10670116975555 | validation: 1.603850170646877]
	TIME [epoch: 9.75 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8378912264806594		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.8378912264806594 | validation: 0.6750564116471911]
	TIME [epoch: 9.77 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45284601554249065		[learning rate: 0.004777]
	Learning Rate: 0.00477703
	LOSS [training: 0.45284601554249065 | validation: 0.25985161173184923]
	TIME [epoch: 9.75 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3268146492790008		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.3268146492790008 | validation: 0.3096837525062959]
	TIME [epoch: 9.75 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27957901466681434		[learning rate: 0.0047539]
	Learning Rate: 0.00475393
	LOSS [training: 0.27957901466681434 | validation: 0.28240785683475833]
	TIME [epoch: 9.76 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34607975407266955		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.34607975407266955 | validation: 0.34673718570267315]
	TIME [epoch: 9.75 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3776739630648135		[learning rate: 0.0047309]
	Learning Rate: 0.00473094
	LOSS [training: 0.3776739630648135 | validation: 0.33044043746109014]
	TIME [epoch: 9.75 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3833388405363559		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.3833388405363559 | validation: 0.328684945205935]
	TIME [epoch: 9.75 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33935669111344857		[learning rate: 0.0047081]
	Learning Rate: 0.00470806
	LOSS [training: 0.33935669111344857 | validation: 0.29132882597995763]
	TIME [epoch: 9.77 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33188016550359467		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.33188016550359467 | validation: 0.32340981311030315]
	TIME [epoch: 9.75 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39393682533265495		[learning rate: 0.0046853]
	Learning Rate: 0.00468529
	LOSS [training: 0.39393682533265495 | validation: 0.39827058890138217]
	TIME [epoch: 9.75 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40297677969605294		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.40297677969605294 | validation: 0.3260179423771707]
	TIME [epoch: 9.77 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3163962031642734		[learning rate: 0.0046626]
	Learning Rate: 0.00466264
	LOSS [training: 0.3163962031642734 | validation: 0.32635735254037573]
	TIME [epoch: 9.75 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3876766632633087		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.3876766632633087 | validation: 0.294489658617039]
	TIME [epoch: 9.75 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2822768098676981		[learning rate: 0.0046401]
	Learning Rate: 0.00464009
	LOSS [training: 0.2822768098676981 | validation: 0.435817766549132]
	TIME [epoch: 9.76 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3390025488341905		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.3390025488341905 | validation: 0.23656840586273148]
	TIME [epoch: 9.75 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26258929630442335		[learning rate: 0.0046177]
	Learning Rate: 0.00461765
	LOSS [training: 0.26258929630442335 | validation: 0.8135208194201999]
	TIME [epoch: 9.75 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5588298238025624		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.5588298238025624 | validation: 0.29036281554589555]
	TIME [epoch: 9.76 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.332796807878894		[learning rate: 0.0045953]
	Learning Rate: 0.00459532
	LOSS [training: 0.332796807878894 | validation: 0.3042841470977207]
	TIME [epoch: 9.75 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2890293233732291		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.2890293233732291 | validation: 0.22299159127518978]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3091689496323648		[learning rate: 0.0045731]
	Learning Rate: 0.0045731
	LOSS [training: 0.3091689496323648 | validation: 0.5031879761913177]
	TIME [epoch: 9.75 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36650576723216355		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.36650576723216355 | validation: 0.25180972212101876]
	TIME [epoch: 9.77 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2818056914935571		[learning rate: 0.004551]
	Learning Rate: 0.00455098
	LOSS [training: 0.2818056914935571 | validation: 0.3661752758362929]
	TIME [epoch: 9.76 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43011490033220723		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.43011490033220723 | validation: 0.314628368184341]
	TIME [epoch: 9.75 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30078267302354555		[learning rate: 0.004529]
	Learning Rate: 0.00452898
	LOSS [training: 0.30078267302354555 | validation: 0.4635146052976666]
	TIME [epoch: 9.78 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3675269965004805		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.3675269965004805 | validation: 0.8566939939846102]
	TIME [epoch: 9.75 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7543618665159113		[learning rate: 0.0045071]
	Learning Rate: 0.00450707
	LOSS [training: 0.7543618665159113 | validation: 0.4136704816137838]
	TIME [epoch: 9.75 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5286557832261385		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.5286557832261385 | validation: 1.021613672180703]
	TIME [epoch: 9.77 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7483022485161408		[learning rate: 0.0044853]
	Learning Rate: 0.00448528
	LOSS [training: 0.7483022485161408 | validation: 0.6766108443132711]
	TIME [epoch: 9.74 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7122687316359494		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.7122687316359494 | validation: 0.7421109813975321]
	TIME [epoch: 9.74 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5483228454973805		[learning rate: 0.0044636]
	Learning Rate: 0.00446359
	LOSS [training: 0.5483228454973805 | validation: 0.4170504735040966]
	TIME [epoch: 9.76 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31520355381946297		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.31520355381946297 | validation: 0.2256871789084163]
	TIME [epoch: 9.76 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2947974409498029		[learning rate: 0.004442]
	Learning Rate: 0.004442
	LOSS [training: 0.2947974409498029 | validation: 0.38214653365766316]
	TIME [epoch: 9.75 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36502814379459286		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.36502814379459286 | validation: 0.3546655755213206]
	TIME [epoch: 9.76 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38723522269225463		[learning rate: 0.0044205]
	Learning Rate: 0.00442052
	LOSS [training: 0.38723522269225463 | validation: 0.3853073711217985]
	TIME [epoch: 9.77 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3412716728073715		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.3412716728073715 | validation: 0.36302131241450497]
	TIME [epoch: 9.75 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3301231048697285		[learning rate: 0.0043991]
	Learning Rate: 0.00439915
	LOSS [training: 0.3301231048697285 | validation: 0.48596914461054597]
	TIME [epoch: 9.75 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4447146748958971		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.4447146748958971 | validation: 0.764769648971371]
	TIME [epoch: 9.77 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7628255406746424		[learning rate: 0.0043779]
	Learning Rate: 0.00437787
	LOSS [training: 0.7628255406746424 | validation: 0.550079614170067]
	TIME [epoch: 9.75 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39963380180331265		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.39963380180331265 | validation: 0.2851407393426342]
	TIME [epoch: 9.75 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2747549301841191		[learning rate: 0.0043567]
	Learning Rate: 0.0043567
	LOSS [training: 0.2747549301841191 | validation: 0.2946619038267862]
	TIME [epoch: 9.77 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2656238192442019		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.2656238192442019 | validation: 0.26277136797223155]
	TIME [epoch: 9.76 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23036817724616446		[learning rate: 0.0043356]
	Learning Rate: 0.00433563
	LOSS [training: 0.23036817724616446 | validation: 0.19518278270283732]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26863920443625566		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.26863920443625566 | validation: 0.28014928045004645]
	TIME [epoch: 9.76 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3107085214020728		[learning rate: 0.0043147]
	Learning Rate: 0.00431467
	LOSS [training: 0.3107085214020728 | validation: 0.40488881790813763]
	TIME [epoch: 9.75 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29886487385076543		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.29886487385076543 | validation: 0.20472744158963388]
	TIME [epoch: 9.75 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2454451916287419		[learning rate: 0.0042938]
	Learning Rate: 0.0042938
	LOSS [training: 0.2454451916287419 | validation: 0.3116339119024691]
	TIME [epoch: 9.74 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34104627204084015		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.34104627204084015 | validation: 0.42645905880967205]
	TIME [epoch: 9.76 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37037685393163666		[learning rate: 0.004273]
	Learning Rate: 0.00427304
	LOSS [training: 0.37037685393163666 | validation: 0.26448675586895815]
	TIME [epoch: 9.75 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25849696844931697		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.25849696844931697 | validation: 0.25452241057157693]
	TIME [epoch: 9.75 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3025260290467664		[learning rate: 0.0042524]
	Learning Rate: 0.00425238
	LOSS [training: 0.3025260290467664 | validation: 0.23028298390504717]
	TIME [epoch: 9.76 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2833677703359035		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.2833677703359035 | validation: 0.3252197136198753]
	TIME [epoch: 9.73 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2713603380110712		[learning rate: 0.0042318]
	Learning Rate: 0.00423181
	LOSS [training: 0.2713603380110712 | validation: 0.21690496507033807]
	TIME [epoch: 9.74 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2702857103633988		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.2702857103633988 | validation: 0.2363375215119872]
	TIME [epoch: 9.77 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27790936490909013		[learning rate: 0.0042113]
	Learning Rate: 0.00421135
	LOSS [training: 0.27790936490909013 | validation: 0.2622975355369709]
	TIME [epoch: 9.74 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2574295230106086		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.2574295230106086 | validation: 0.5056705227688925]
	TIME [epoch: 9.74 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6122160906194161		[learning rate: 0.004191]
	Learning Rate: 0.00419098
	LOSS [training: 0.6122160906194161 | validation: 0.5754929025130847]
	TIME [epoch: 9.76 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4042636900714028		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.4042636900714028 | validation: 0.27488245955914925]
	TIME [epoch: 9.75 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32222276999944377		[learning rate: 0.0041707]
	Learning Rate: 0.00417071
	LOSS [training: 0.32222276999944377 | validation: 0.3396913745058658]
	TIME [epoch: 9.74 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29223108157420186		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.29223108157420186 | validation: 0.2327100094380244]
	TIME [epoch: 9.75 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2287093306951542		[learning rate: 0.0041505]
	Learning Rate: 0.00415055
	LOSS [training: 0.2287093306951542 | validation: 0.3726369064180409]
	TIME [epoch: 9.76 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35495446555832816		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.35495446555832816 | validation: 0.3826868727578471]
	TIME [epoch: 9.74 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3496781908984316		[learning rate: 0.0041305]
	Learning Rate: 0.00413047
	LOSS [training: 0.3496781908984316 | validation: 0.32324003249880207]
	TIME [epoch: 9.74 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32480138527851565		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.32480138527851565 | validation: 0.3092351126475919]
	TIME [epoch: 9.77 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35351232743334343		[learning rate: 0.0041105]
	Learning Rate: 0.0041105
	LOSS [training: 0.35351232743334343 | validation: 0.3247405198499498]
	TIME [epoch: 9.75 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34085391341817395		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.34085391341817395 | validation: 0.3901292392037605]
	TIME [epoch: 9.75 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35668386740973246		[learning rate: 0.0040906]
	Learning Rate: 0.00409062
	LOSS [training: 0.35668386740973246 | validation: 0.3142194225166832]
	TIME [epoch: 9.77 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3368964374842934		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.3368964374842934 | validation: 0.6076207556692231]
	TIME [epoch: 9.75 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4836413606308687		[learning rate: 0.0040708]
	Learning Rate: 0.00407084
	LOSS [training: 0.4836413606308687 | validation: 0.32060636175308527]
	TIME [epoch: 9.74 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39059054358220247		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.39059054358220247 | validation: 0.6066378241558217]
	TIME [epoch: 9.76 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4322827588754179		[learning rate: 0.0040512]
	Learning Rate: 0.00405116
	LOSS [training: 0.4322827588754179 | validation: 0.4198712902770535]
	TIME [epoch: 9.75 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3835371104573768		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.3835371104573768 | validation: 0.32386625536074876]
	TIME [epoch: 9.75 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29998820181528424		[learning rate: 0.0040316]
	Learning Rate: 0.00403157
	LOSS [training: 0.29998820181528424 | validation: 0.4836816828364535]
	TIME [epoch: 9.75 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37890072331421454		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.37890072331421454 | validation: 0.27539547734789993]
	TIME [epoch: 9.76 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26076242116849296		[learning rate: 0.0040121]
	Learning Rate: 0.00401207
	LOSS [training: 0.26076242116849296 | validation: 0.26297494193696525]
	TIME [epoch: 9.75 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37400421209974766		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.37400421209974766 | validation: 0.30031663668343384]
	TIME [epoch: 9.74 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3025692513659936		[learning rate: 0.0039927]
	Learning Rate: 0.00399267
	LOSS [training: 0.3025692513659936 | validation: 0.3830948654750809]
	TIME [epoch: 9.76 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32501136950414394		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.32501136950414394 | validation: 0.3749650689825373]
	TIME [epoch: 9.75 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29130330422458867		[learning rate: 0.0039734]
	Learning Rate: 0.00397336
	LOSS [training: 0.29130330422458867 | validation: 0.28145014359509174]
	TIME [epoch: 9.75 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27664343417023796		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.27664343417023796 | validation: 0.35086665116904675]
	TIME [epoch: 9.76 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2815039117338069		[learning rate: 0.0039541]
	Learning Rate: 0.00395415
	LOSS [training: 0.2815039117338069 | validation: 0.2788060145256503]
	TIME [epoch: 9.76 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28693086080923463		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.28693086080923463 | validation: 0.3441577892030483]
	TIME [epoch: 9.75 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33397556655671135		[learning rate: 0.003935]
	Learning Rate: 0.00393502
	LOSS [training: 0.33397556655671135 | validation: 0.3472159401931652]
	TIME [epoch: 9.76 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33733759823195814		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.33733759823195814 | validation: 0.3494221396706614]
	TIME [epoch: 9.74 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3405558491040067		[learning rate: 0.003916]
	Learning Rate: 0.00391599
	LOSS [training: 0.3405558491040067 | validation: 0.2955867041724114]
	TIME [epoch: 9.75 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31763181505983595		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.31763181505983595 | validation: 0.28026146117310546]
	TIME [epoch: 9.75 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34320292569950933		[learning rate: 0.0038971]
	Learning Rate: 0.00389706
	LOSS [training: 0.34320292569950933 | validation: 0.6643643324598679]
	TIME [epoch: 9.76 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44274938738209235		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.44274938738209235 | validation: 0.4340717714828826]
	TIME [epoch: 9.75 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34852548779157855		[learning rate: 0.0038782]
	Learning Rate: 0.00387821
	LOSS [training: 0.34852548779157855 | validation: 0.28856925318948506]
	TIME [epoch: 9.74 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.276066181946109		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.276066181946109 | validation: 0.3324075344296745]
	TIME [epoch: 9.78 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3154115450523346		[learning rate: 0.0038595]
	Learning Rate: 0.00385946
	LOSS [training: 0.3154115450523346 | validation: 0.3000356680011219]
	TIME [epoch: 9.75 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27004718997264215		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.27004718997264215 | validation: 0.2829440093754317]
	TIME [epoch: 9.74 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25123858537759247		[learning rate: 0.0038408]
	Learning Rate: 0.00384079
	LOSS [training: 0.25123858537759247 | validation: 0.24411763297856262]
	TIME [epoch: 9.76 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2981960472692948		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.2981960472692948 | validation: 0.28890632143038236]
	TIME [epoch: 9.74 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30995819560388604		[learning rate: 0.0038222]
	Learning Rate: 0.00382222
	LOSS [training: 0.30995819560388604 | validation: 0.28967349398482595]
	TIME [epoch: 9.74 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2660594975270174		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.2660594975270174 | validation: 0.2407368382519615]
	TIME [epoch: 9.75 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27922480849013875		[learning rate: 0.0038037]
	Learning Rate: 0.00380374
	LOSS [training: 0.27922480849013875 | validation: 0.5730232459437885]
	TIME [epoch: 9.75 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.652488502562864		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.652488502562864 | validation: 1.3249835116110216]
	TIME [epoch: 9.75 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5759838806522555		[learning rate: 0.0037853]
	Learning Rate: 0.00378534
	LOSS [training: 0.5759838806522555 | validation: 0.339752929702886]
	TIME [epoch: 9.74 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32560509807411214		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.32560509807411214 | validation: 0.6187702964488606]
	TIME [epoch: 9.75 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.098873529696994		[learning rate: 0.003767]
	Learning Rate: 0.00376704
	LOSS [training: 1.098873529696994 | validation: 0.2917349688546797]
	TIME [epoch: 9.73 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26651482123043857		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.26651482123043857 | validation: 0.5612759205331286]
	TIME [epoch: 9.74 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4918669504665941		[learning rate: 0.0037488]
	Learning Rate: 0.00374882
	LOSS [training: 0.4918669504665941 | validation: 0.30488749565850204]
	TIME [epoch: 9.76 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4292335046043064		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.4292335046043064 | validation: 0.3283062691946722]
	TIME [epoch: 9.75 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3142713722301683		[learning rate: 0.0037307]
	Learning Rate: 0.00373069
	LOSS [training: 0.3142713722301683 | validation: 0.2498180765669151]
	TIME [epoch: 9.74 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2895999873015114		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.2895999873015114 | validation: 0.3119307485062111]
	TIME [epoch: 9.76 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24261401120723		[learning rate: 0.0037127]
	Learning Rate: 0.00371265
	LOSS [training: 0.24261401120723 | validation: 0.22774512551862722]
	TIME [epoch: 9.74 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27616798357499783		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.27616798357499783 | validation: 0.27457718761810923]
	TIME [epoch: 9.74 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3252072146888093		[learning rate: 0.0036947]
	Learning Rate: 0.0036947
	LOSS [training: 0.3252072146888093 | validation: 0.47677323441000946]
	TIME [epoch: 9.75 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31776173352379383		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.31776173352379383 | validation: 0.21811478441044807]
	TIME [epoch: 9.76 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2324107545141027		[learning rate: 0.0036768]
	Learning Rate: 0.00367683
	LOSS [training: 0.2324107545141027 | validation: 0.28520678468441435]
	TIME [epoch: 9.75 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25968841765630857		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.25968841765630857 | validation: 0.22152648537215172]
	TIME [epoch: 9.75 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23417378655469673		[learning rate: 0.0036591]
	Learning Rate: 0.00365905
	LOSS [training: 0.23417378655469673 | validation: 0.21496324491640348]
	TIME [epoch: 9.75 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2722872074053477		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.2722872074053477 | validation: 0.2779950170090657]
	TIME [epoch: 9.73 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28421120241305964		[learning rate: 0.0036414]
	Learning Rate: 0.00364136
	LOSS [training: 0.28421120241305964 | validation: 0.2466442014022014]
	TIME [epoch: 9.74 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2596934766888075		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.2596934766888075 | validation: 0.28666048360364543]
	TIME [epoch: 9.77 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2618888895313403		[learning rate: 0.0036237]
	Learning Rate: 0.00362375
	LOSS [training: 0.2618888895313403 | validation: 0.2358790510120933]
	TIME [epoch: 9.75 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.230981687824183		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.230981687824183 | validation: 0.18343165963605296]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1918788753138502		[learning rate: 0.0036062]
	Learning Rate: 0.00360622
	LOSS [training: 0.1918788753138502 | validation: 0.2338013244168036]
	TIME [epoch: 9.77 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.358412961340732		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.358412961340732 | validation: 0.7066446144551966]
	TIME [epoch: 9.74 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34368460815614804		[learning rate: 0.0035888]
	Learning Rate: 0.00358878
	LOSS [training: 0.34368460815614804 | validation: 0.29329788307141635]
	TIME [epoch: 9.75 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26696936363122864		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.26696936363122864 | validation: 0.1871196398953736]
	TIME [epoch: 9.77 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18595065138343594		[learning rate: 0.0035714]
	Learning Rate: 0.00357143
	LOSS [training: 0.18595065138343594 | validation: 0.22486769895450956]
	TIME [epoch: 9.75 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20507075755442722		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.20507075755442722 | validation: 0.17425598775637627]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_526.pth
	Model improved!!!
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1767318739523293		[learning rate: 0.0035542]
	Learning Rate: 0.00355416
	LOSS [training: 0.1767318739523293 | validation: 0.14401544062556695]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31667192153484713		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.31667192153484713 | validation: 0.5789842100972443]
	TIME [epoch: 9.76 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42212150085561007		[learning rate: 0.003537]
	Learning Rate: 0.00353697
	LOSS [training: 0.42212150085561007 | validation: 0.3415856363148905]
	TIME [epoch: 9.75 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34999905130321507		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.34999905130321507 | validation: 0.19390743938787885]
	TIME [epoch: 9.75 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19395096926917604		[learning rate: 0.0035199]
	Learning Rate: 0.00351987
	LOSS [training: 0.19395096926917604 | validation: 0.18229954987613753]
	TIME [epoch: 9.78 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16405791450787152		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.16405791450787152 | validation: 0.17129460442236308]
	TIME [epoch: 9.76 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22264053916402043		[learning rate: 0.0035028]
	Learning Rate: 0.00350285
	LOSS [training: 0.22264053916402043 | validation: 0.37964120939589535]
	TIME [epoch: 9.75 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4338309991388984		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.4338309991388984 | validation: 0.36673644018874724]
	TIME [epoch: 9.77 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3323208445835347		[learning rate: 0.0034859]
	Learning Rate: 0.00348591
	LOSS [training: 0.3323208445835347 | validation: 0.8311255181490818]
	TIME [epoch: 9.76 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8608162840126752		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.8608162840126752 | validation: 0.25680406106687254]
	TIME [epoch: 9.75 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23735215799796072		[learning rate: 0.003469]
	Learning Rate: 0.00346905
	LOSS [training: 0.23735215799796072 | validation: 0.22773123642907497]
	TIME [epoch: 9.77 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20921048923628094		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.20921048923628094 | validation: 0.20166637586771388]
	TIME [epoch: 9.75 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2133615925508904		[learning rate: 0.0034523]
	Learning Rate: 0.00345227
	LOSS [training: 0.2133615925508904 | validation: 0.235259465236571]
	TIME [epoch: 9.75 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26492048885007596		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.26492048885007596 | validation: 0.6694541799919215]
	TIME [epoch: 9.77 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4107204960203072		[learning rate: 0.0034356]
	Learning Rate: 0.00343558
	LOSS [training: 0.4107204960203072 | validation: 0.21913594146498233]
	TIME [epoch: 9.75 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2451435492774127		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.2451435492774127 | validation: 0.2473386456586954]
	TIME [epoch: 9.74 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23870117567874066		[learning rate: 0.003419]
	Learning Rate: 0.00341897
	LOSS [training: 0.23870117567874066 | validation: 0.25576174268859025]
	TIME [epoch: 9.75 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21304219945619374		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.21304219945619374 | validation: 0.1807797876512963]
	TIME [epoch: 9.77 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20867719474349444		[learning rate: 0.0034024]
	Learning Rate: 0.00340243
	LOSS [training: 0.20867719474349444 | validation: 0.2975664040996738]
	TIME [epoch: 9.75 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2536970038854851		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.2536970038854851 | validation: 0.2536201324439596]
	TIME [epoch: 9.74 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24389847699773623		[learning rate: 0.003386]
	Learning Rate: 0.00338598
	LOSS [training: 0.24389847699773623 | validation: 0.61211763332802]
	TIME [epoch: 9.78 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8101821134533598		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.8101821134533598 | validation: 0.5693244040726642]
	TIME [epoch: 9.76 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.288074104431868		[learning rate: 0.0033696]
	Learning Rate: 0.0033696
	LOSS [training: 0.288074104431868 | validation: 0.21347360815060198]
	TIME [epoch: 9.75 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19784963112106796		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.19784963112106796 | validation: 0.19914143247293983]
	TIME [epoch: 9.78 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2102663194713949		[learning rate: 0.0033533]
	Learning Rate: 0.00335331
	LOSS [training: 0.2102663194713949 | validation: 0.25000005092519784]
	TIME [epoch: 9.76 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28238414770558745		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.28238414770558745 | validation: 0.25028325710643406]
	TIME [epoch: 9.76 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30444985996087215		[learning rate: 0.0033371]
	Learning Rate: 0.00333709
	LOSS [training: 0.30444985996087215 | validation: 0.2306191545243998]
	TIME [epoch: 9.77 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22833459734662204		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.22833459734662204 | validation: 0.337806850956099]
	TIME [epoch: 9.75 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3147536293827503		[learning rate: 0.003321]
	Learning Rate: 0.00332096
	LOSS [training: 0.3147536293827503 | validation: 0.3489761343072985]
	TIME [epoch: 9.75 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27273973483717706		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.27273973483717706 | validation: 0.30477737639197683]
	TIME [epoch: 9.75 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3278822787903902		[learning rate: 0.0033049]
	Learning Rate: 0.0033049
	LOSS [training: 0.3278822787903902 | validation: 0.21802231875772504]
	TIME [epoch: 9.79 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26538228694146093		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.26538228694146093 | validation: 0.2570804783317098]
	TIME [epoch: 9.76 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28985591230040914		[learning rate: 0.0032889]
	Learning Rate: 0.00328891
	LOSS [training: 0.28985591230040914 | validation: 0.34605006831792795]
	TIME [epoch: 9.74 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38705966928663005		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.38705966928663005 | validation: 0.4091461262404629]
	TIME [epoch: 9.77 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3524499417000598		[learning rate: 0.003273]
	Learning Rate: 0.00327301
	LOSS [training: 0.3524499417000598 | validation: 0.30272569778694813]
	TIME [epoch: 9.76 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2843602073197388		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.2843602073197388 | validation: 0.3133754671736171]
	TIME [epoch: 9.74 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3546809719615704		[learning rate: 0.0032572]
	Learning Rate: 0.00325718
	LOSS [training: 0.3546809719615704 | validation: 0.41678268292709875]
	TIME [epoch: 9.76 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2893428403629804		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.2893428403629804 | validation: 0.3262404373105433]
	TIME [epoch: 9.75 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26917163438854474		[learning rate: 0.0032414]
	Learning Rate: 0.00324143
	LOSS [training: 0.26917163438854474 | validation: 0.2819244611605835]
	TIME [epoch: 9.76 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3444110017966878		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.3444110017966878 | validation: 0.4889562799547942]
	TIME [epoch: 9.77 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3908957128417428		[learning rate: 0.0032258]
	Learning Rate: 0.00322576
	LOSS [training: 0.3908957128417428 | validation: 0.32816992323218025]
	TIME [epoch: 9.75 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2811282404149965		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.2811282404149965 | validation: 0.32635800013974275]
	TIME [epoch: 9.74 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28746102300290205		[learning rate: 0.0032102]
	Learning Rate: 0.00321016
	LOSS [training: 0.28746102300290205 | validation: 0.2777727060196214]
	TIME [epoch: 9.76 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3077594789350193		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.3077594789350193 | validation: 0.39121457268264187]
	TIME [epoch: 9.78 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37983756236248134		[learning rate: 0.0031946]
	Learning Rate: 0.00319463
	LOSS [training: 0.37983756236248134 | validation: 0.35278922834643917]
	TIME [epoch: 9.75 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3260618242254091		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.3260618242254091 | validation: 0.2662390195099591]
	TIME [epoch: 9.76 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24220269159409447		[learning rate: 0.0031792]
	Learning Rate: 0.00317918
	LOSS [training: 0.24220269159409447 | validation: 0.23938799034582103]
	TIME [epoch: 9.76 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2938484143305374		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.2938484143305374 | validation: 0.2871834927076187]
	TIME [epoch: 9.75 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2756478101202116		[learning rate: 0.0031638]
	Learning Rate: 0.00316381
	LOSS [training: 0.2756478101202116 | validation: 0.2735050409009789]
	TIME [epoch: 9.75 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2626856836162523		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.2626856836162523 | validation: 0.26500664587692724]
	TIME [epoch: 9.76 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3295407776260203		[learning rate: 0.0031485]
	Learning Rate: 0.00314851
	LOSS [training: 0.3295407776260203 | validation: 0.3613829730328623]
	TIME [epoch: 9.76 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3570333086514168		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.3570333086514168 | validation: 0.46238465128788264]
	TIME [epoch: 9.75 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5091374055738951		[learning rate: 0.0031333]
	Learning Rate: 0.00313329
	LOSS [training: 0.5091374055738951 | validation: 0.5496791675616436]
	TIME [epoch: 9.77 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7184353395520453		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.7184353395520453 | validation: 0.8364752055303595]
	TIME [epoch: 9.76 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5327182620914425		[learning rate: 0.0031181]
	Learning Rate: 0.00311813
	LOSS [training: 0.5327182620914425 | validation: 0.28722255589001]
	TIME [epoch: 9.75 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3463918478553372		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.3463918478553372 | validation: 0.3161350097607982]
	TIME [epoch: 9.74 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3284381237390599		[learning rate: 0.0031031]
	Learning Rate: 0.00310305
	LOSS [training: 0.3284381237390599 | validation: 0.31762538109160643]
	TIME [epoch: 9.77 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30588864914902003		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.30588864914902003 | validation: 0.27205910303574604]
	TIME [epoch: 9.74 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2981114229667453		[learning rate: 0.003088]
	Learning Rate: 0.00308805
	LOSS [training: 0.2981114229667453 | validation: 0.33843042357971903]
	TIME [epoch: 9.75 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3812172896250331		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.3812172896250331 | validation: 0.3328647561075767]
	TIME [epoch: 9.78 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28904762953064994		[learning rate: 0.0030731]
	Learning Rate: 0.00307312
	LOSS [training: 0.28904762953064994 | validation: 0.29772704599032473]
	TIME [epoch: 9.77 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3063976971305475		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.3063976971305475 | validation: 0.2684758284192093]
	TIME [epoch: 9.76 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2723041861170329		[learning rate: 0.0030583]
	Learning Rate: 0.00305825
	LOSS [training: 0.2723041861170329 | validation: 0.2735136610577897]
	TIME [epoch: 9.78 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2349845053230418		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.2349845053230418 | validation: 0.24014187302765977]
	TIME [epoch: 9.75 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25455973322180425		[learning rate: 0.0030435]
	Learning Rate: 0.00304347
	LOSS [training: 0.25455973322180425 | validation: 0.29614464747508357]
	TIME [epoch: 9.75 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24198798858222825		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.24198798858222825 | validation: 0.25923169401012797]
	TIME [epoch: 9.77 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2381416764323349		[learning rate: 0.0030287]
	Learning Rate: 0.00302875
	LOSS [training: 0.2381416764323349 | validation: 0.2148476774996003]
	TIME [epoch: 9.76 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24576035545468308		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.24576035545468308 | validation: 0.30401252397831563]
	TIME [epoch: 9.75 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31170638887801316		[learning rate: 0.0030141]
	Learning Rate: 0.0030141
	LOSS [training: 0.31170638887801316 | validation: 0.24494438100833585]
	TIME [epoch: 9.75 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2167339858375566		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.2167339858375566 | validation: 0.3673151021636211]
	TIME [epoch: 9.77 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3733110131429126		[learning rate: 0.0029995]
	Learning Rate: 0.00299953
	LOSS [training: 0.3733110131429126 | validation: 0.5069546613239001]
	TIME [epoch: 9.76 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3094106280766792		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.3094106280766792 | validation: 0.23933706290968956]
	TIME [epoch: 9.76 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3292710347540508		[learning rate: 0.002985]
	Learning Rate: 0.00298502
	LOSS [training: 0.3292710347540508 | validation: 0.28279119912127565]
	TIME [epoch: 9.77 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2653536470095527		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.2653536470095527 | validation: 0.26911617597213117]
	TIME [epoch: 9.76 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.299231337374123		[learning rate: 0.0029706]
	Learning Rate: 0.00297059
	LOSS [training: 0.299231337374123 | validation: 0.31270874324072767]
	TIME [epoch: 9.76 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2090207773436333		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.2090207773436333 | validation: 0.18623298971919483]
	TIME [epoch: 9.78 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19209320555315873		[learning rate: 0.0029562]
	Learning Rate: 0.00295622
	LOSS [training: 0.19209320555315873 | validation: 0.18351830968401622]
	TIME [epoch: 9.76 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1746132644671162		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.1746132644671162 | validation: 0.18938409134436562]
	TIME [epoch: 9.76 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17264559982348965		[learning rate: 0.0029419]
	Learning Rate: 0.00294192
	LOSS [training: 0.17264559982348965 | validation: 0.2852897878499769]
	TIME [epoch: 9.78 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28244913550634754		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.28244913550634754 | validation: 0.22018306422747297]
	TIME [epoch: 9.75 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23465038808431404		[learning rate: 0.0029277]
	Learning Rate: 0.0029277
	LOSS [training: 0.23465038808431404 | validation: 0.41687702686015987]
	TIME [epoch: 9.76 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41695334167831427		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.41695334167831427 | validation: 0.4172442005840683]
	TIME [epoch: 9.76 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.324342788010523		[learning rate: 0.0029135]
	Learning Rate: 0.00291354
	LOSS [training: 0.324342788010523 | validation: 0.2458238693686759]
	TIME [epoch: 9.77 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23926276882383898		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.23926276882383898 | validation: 0.23364857169829717]
	TIME [epoch: 9.76 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30193816248231775		[learning rate: 0.0028995]
	Learning Rate: 0.00289945
	LOSS [training: 0.30193816248231775 | validation: 0.34120129330703897]
	TIME [epoch: 9.75 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35111334956161816		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.35111334956161816 | validation: 0.3275182260601758]
	TIME [epoch: 9.76 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3357620722525513		[learning rate: 0.0028854]
	Learning Rate: 0.00288543
	LOSS [training: 0.3357620722525513 | validation: 0.31327815156735095]
	TIME [epoch: 9.75 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3137450649635735		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.3137450649635735 | validation: 0.3208074281616565]
	TIME [epoch: 9.77 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29945137651781567		[learning rate: 0.0028715]
	Learning Rate: 0.00287148
	LOSS [training: 0.29945137651781567 | validation: 0.27066290034673]
	TIME [epoch: 9.78 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26260166603914503		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.26260166603914503 | validation: 0.26081943224990156]
	TIME [epoch: 9.75 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27885230466525135		[learning rate: 0.0028576]
	Learning Rate: 0.00285759
	LOSS [training: 0.27885230466525135 | validation: 0.2760140185130957]
	TIME [epoch: 9.75 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2861036341303585		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.2861036341303585 | validation: 0.3756982759004606]
	TIME [epoch: 9.78 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3437628406242429		[learning rate: 0.0028438]
	Learning Rate: 0.00284377
	LOSS [training: 0.3437628406242429 | validation: 0.27357141114729566]
	TIME [epoch: 9.76 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3040655279270744		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.3040655279270744 | validation: 0.3372231006003436]
	TIME [epoch: 9.75 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2663750370721466		[learning rate: 0.00283]
	Learning Rate: 0.00283002
	LOSS [training: 0.2663750370721466 | validation: 0.27211690188657056]
	TIME [epoch: 9.76 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31768048541935995		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.31768048541935995 | validation: 0.35069257938826054]
	TIME [epoch: 9.78 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31149441791507215		[learning rate: 0.0028163]
	Learning Rate: 0.00281633
	LOSS [training: 0.31149441791507215 | validation: 0.30405921909165395]
	TIME [epoch: 9.76 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2948531858420071		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.2948531858420071 | validation: 0.30918792059693156]
	TIME [epoch: 9.76 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2934703505042048		[learning rate: 0.0028027]
	Learning Rate: 0.00280272
	LOSS [training: 0.2934703505042048 | validation: 0.2684629121070267]
	TIME [epoch: 9.78 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2816933948471324		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.2816933948471324 | validation: 0.2763330383528543]
	TIME [epoch: 9.75 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27335084748527183		[learning rate: 0.0027892]
	Learning Rate: 0.00278916
	LOSS [training: 0.27335084748527183 | validation: 0.30145646304642965]
	TIME [epoch: 9.75 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2999847468814847		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.2999847468814847 | validation: 0.2979585614091561]
	TIME [epoch: 9.77 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29794359763335554		[learning rate: 0.0027757]
	Learning Rate: 0.00277567
	LOSS [training: 0.29794359763335554 | validation: 0.28211676348708753]
	TIME [epoch: 9.75 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29689515646405484		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.29689515646405484 | validation: 0.36183380056443704]
	TIME [epoch: 9.75 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3243790976505588		[learning rate: 0.0027623]
	Learning Rate: 0.00276225
	LOSS [training: 0.3243790976505588 | validation: 0.28574345454788913]
	TIME [epoch: 9.78 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2643709278578006		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.2643709278578006 | validation: 0.2629501102029602]
	TIME [epoch: 9.75 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31168044318751137		[learning rate: 0.0027489]
	Learning Rate: 0.00274889
	LOSS [training: 0.31168044318751137 | validation: 0.3506726263408463]
	TIME [epoch: 9.76 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3086598126224491		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.3086598126224491 | validation: 0.2531278810803412]
	TIME [epoch: 9.76 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2694724441606094		[learning rate: 0.0027356]
	Learning Rate: 0.0027356
	LOSS [training: 0.2694724441606094 | validation: 0.2853364440030276]
	TIME [epoch: 9.78 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26871939482322815		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.26871939482322815 | validation: 0.2645456588310493]
	TIME [epoch: 9.76 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.269749736821281		[learning rate: 0.0027224]
	Learning Rate: 0.00272237
	LOSS [training: 0.269749736821281 | validation: 0.26709443473157757]
	TIME [epoch: 9.75 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2891530992559289		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.2891530992559289 | validation: 0.27076336718676464]
	TIME [epoch: 9.77 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25793016621344234		[learning rate: 0.0027092]
	Learning Rate: 0.00270921
	LOSS [training: 0.25793016621344234 | validation: 0.24817229109061714]
	TIME [epoch: 9.76 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26808320063898206		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.26808320063898206 | validation: 0.3563937775957557]
	TIME [epoch: 9.76 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2948472936926302		[learning rate: 0.0026961]
	Learning Rate: 0.00269611
	LOSS [training: 0.2948472936926302 | validation: 0.24037827633308623]
	TIME [epoch: 9.78 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26731247538649205		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.26731247538649205 | validation: 0.2895380478860864]
	TIME [epoch: 9.76 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25556397524054636		[learning rate: 0.0026831]
	Learning Rate: 0.00268307
	LOSS [training: 0.25556397524054636 | validation: 0.2663703417391449]
	TIME [epoch: 9.75 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26312317413161174		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.26312317413161174 | validation: 0.24511890309130643]
	TIME [epoch: 9.78 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24911163995413893		[learning rate: 0.0026701]
	Learning Rate: 0.00267009
	LOSS [training: 0.24911163995413893 | validation: 0.24454482191039303]
	TIME [epoch: 9.76 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23502395828079098		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.23502395828079098 | validation: 0.2824042411913047]
	TIME [epoch: 9.76 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27806008485688094		[learning rate: 0.0026572]
	Learning Rate: 0.00265718
	LOSS [training: 0.27806008485688094 | validation: 0.25398494644362546]
	TIME [epoch: 9.77 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21872415572059584		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.21872415572059584 | validation: 0.25581752507995625]
	TIME [epoch: 9.76 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27401006440295045		[learning rate: 0.0026443]
	Learning Rate: 0.00264433
	LOSS [training: 0.27401006440295045 | validation: 0.27107907550976784]
	TIME [epoch: 9.76 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2364697404654223		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.2364697404654223 | validation: 0.23784215838787476]
	TIME [epoch: 9.75 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2929391850822677		[learning rate: 0.0026315]
	Learning Rate: 0.00263154
	LOSS [training: 0.2929391850822677 | validation: 0.22978260744364176]
	TIME [epoch: 9.77 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2525060640699932		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.2525060640699932 | validation: 0.23245707938286375]
	TIME [epoch: 9.75 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2460906129916014		[learning rate: 0.0026188]
	Learning Rate: 0.00261882
	LOSS [training: 0.2460906129916014 | validation: 0.2553711604891571]
	TIME [epoch: 9.75 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2996959842493744		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.2996959842493744 | validation: 0.3262396356236982]
	TIME [epoch: 9.77 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2831421405611617		[learning rate: 0.0026062]
	Learning Rate: 0.00260615
	LOSS [training: 0.2831421405611617 | validation: 0.2847842370860319]
	TIME [epoch: 9.75 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30774396608902793		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.30774396608902793 | validation: 0.29405203155855786]
	TIME [epoch: 9.75 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2756059223059274		[learning rate: 0.0025936]
	Learning Rate: 0.00259355
	LOSS [training: 0.2756059223059274 | validation: 0.27018653810531973]
	TIME [epoch: 9.76 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24981299257426387		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.24981299257426387 | validation: 0.28354847901467817]
	TIME [epoch: 9.75 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.65461471866466		[learning rate: 0.002581]
	Learning Rate: 0.00258101
	LOSS [training: 0.65461471866466 | validation: 0.4596911045810087]
	TIME [epoch: 9.76 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3473625517654489		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.3473625517654489 | validation: 0.30313018246886475]
	TIME [epoch: 9.77 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3296874227138698		[learning rate: 0.0025685]
	Learning Rate: 0.00256853
	LOSS [training: 0.3296874227138698 | validation: 0.31127958872767686]
	TIME [epoch: 9.77 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2910234862019688		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.2910234862019688 | validation: 0.25982715261952016]
	TIME [epoch: 9.75 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23085453798202646		[learning rate: 0.0025561]
	Learning Rate: 0.00255611
	LOSS [training: 0.23085453798202646 | validation: 0.22855742251827102]
	TIME [epoch: 9.74 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25311231295539205		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.25311231295539205 | validation: 0.2804945733511003]
	TIME [epoch: 9.77 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2721788290472789		[learning rate: 0.0025437]
	Learning Rate: 0.00254375
	LOSS [training: 0.2721788290472789 | validation: 0.32107708467407375]
	TIME [epoch: 9.76 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24262008522358208		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.24262008522358208 | validation: 0.32704705493115377]
	TIME [epoch: 9.75 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3165928782998422		[learning rate: 0.0025314]
	Learning Rate: 0.00253144
	LOSS [training: 0.3165928782998422 | validation: 0.2367071017608565]
	TIME [epoch: 9.77 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24020084170404252		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.24020084170404252 | validation: 0.2591209895706555]
	TIME [epoch: 9.76 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2233060182368379		[learning rate: 0.0025192]
	Learning Rate: 0.0025192
	LOSS [training: 0.2233060182368379 | validation: 0.21930046921832705]
	TIME [epoch: 9.77 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23070132145161032		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.23070132145161032 | validation: 0.26942159911331925]
	TIME [epoch: 9.78 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3198840644682404		[learning rate: 0.002507]
	Learning Rate: 0.00250702
	LOSS [training: 0.3198840644682404 | validation: 0.2613798526223948]
	TIME [epoch: 9.77 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2582468259641118		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.2582468259641118 | validation: 0.27135829469715533]
	TIME [epoch: 9.75 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30722273779918285		[learning rate: 0.0024949]
	Learning Rate: 0.0024949
	LOSS [training: 0.30722273779918285 | validation: 0.2743764575333519]
	TIME [epoch: 9.77 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23316949019219893		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.23316949019219893 | validation: 0.28904075172339416]
	TIME [epoch: 9.77 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2297363551116558		[learning rate: 0.0024828]
	Learning Rate: 0.00248283
	LOSS [training: 0.2297363551116558 | validation: 0.22311779881006655]
	TIME [epoch: 9.76 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20382483866557025		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.20382483866557025 | validation: 0.21222182522654098]
	TIME [epoch: 9.75 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22430784029672624		[learning rate: 0.0024708]
	Learning Rate: 0.00247083
	LOSS [training: 0.22430784029672624 | validation: 0.21189606366366065]
	TIME [epoch: 9.78 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2572235282529604		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.2572235282529604 | validation: 0.22676542167388325]
	TIME [epoch: 9.75 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20118331023425728		[learning rate: 0.0024589]
	Learning Rate: 0.00245888
	LOSS [training: 0.20118331023425728 | validation: 0.21375548347048146]
	TIME [epoch: 9.76 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2267384836295908		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.2267384836295908 | validation: 0.2863417987620059]
	TIME [epoch: 9.78 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25292458689757225		[learning rate: 0.002447]
	Learning Rate: 0.00244699
	LOSS [training: 0.25292458689757225 | validation: 0.25704009289512386]
	TIME [epoch: 9.75 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29417652675150674		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.29417652675150674 | validation: 0.36268774726232234]
	TIME [epoch: 9.76 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3650812683631516		[learning rate: 0.0024352]
	Learning Rate: 0.00243515
	LOSS [training: 0.3650812683631516 | validation: 0.34910840092921364]
	TIME [epoch: 9.77 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2985653682682462		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.2985653682682462 | validation: 0.2771130318409532]
	TIME [epoch: 9.75 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28732997021937084		[learning rate: 0.0024234]
	Learning Rate: 0.00242338
	LOSS [training: 0.28732997021937084 | validation: 0.2643527167716209]
	TIME [epoch: 9.75 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2640014572576203		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.2640014572576203 | validation: 0.23328343137128646]
	TIME [epoch: 9.75 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2306755944398839		[learning rate: 0.0024117]
	Learning Rate: 0.00241166
	LOSS [training: 0.2306755944398839 | validation: 0.24808561851499675]
	TIME [epoch: 9.76 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22228249559491364		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.22228249559491364 | validation: 0.22385008877241602]
	TIME [epoch: 9.74 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24626995286571848		[learning rate: 0.0024]
	Learning Rate: 0.0024
	LOSS [training: 0.24626995286571848 | validation: 0.2698063991399857]
	TIME [epoch: 9.76 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2479801736409446		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.2479801736409446 | validation: 0.2598741216246963]
	TIME [epoch: 9.77 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2524322210558318		[learning rate: 0.0023884]
	Learning Rate: 0.00238839
	LOSS [training: 0.2524322210558318 | validation: 0.2484215812884243]
	TIME [epoch: 9.75 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.320683772446398		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.320683772446398 | validation: 0.35807340876028904]
	TIME [epoch: 9.74 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3242753089005195		[learning rate: 0.0023768]
	Learning Rate: 0.00237684
	LOSS [training: 0.3242753089005195 | validation: 0.2633884052484279]
	TIME [epoch: 9.77 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41835747295596776		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.41835747295596776 | validation: 0.2381371097258966]
	TIME [epoch: 9.74 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2680704080568816		[learning rate: 0.0023653]
	Learning Rate: 0.00236535
	LOSS [training: 0.2680704080568816 | validation: 0.25376555436160914]
	TIME [epoch: 9.75 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23123133818460442		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.23123133818460442 | validation: 0.22051053626309255]
	TIME [epoch: 9.77 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25260505514067033		[learning rate: 0.0023539]
	Learning Rate: 0.00235391
	LOSS [training: 0.25260505514067033 | validation: 0.3269097491037838]
	TIME [epoch: 9.75 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2736890112591398		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.2736890112591398 | validation: 0.2577070365825615]
	TIME [epoch: 9.75 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24083564057832824		[learning rate: 0.0023425]
	Learning Rate: 0.00234252
	LOSS [training: 0.24083564057832824 | validation: 0.22453853721734732]
	TIME [epoch: 9.76 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2349708049738232		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.2349708049738232 | validation: 0.20460568329419243]
	TIME [epoch: 9.76 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27749107066366535		[learning rate: 0.0023312]
	Learning Rate: 0.0023312
	LOSS [training: 0.27749107066366535 | validation: 0.25486230388423026]
	TIME [epoch: 9.75 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23779273763991632		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.23779273763991632 | validation: 0.26817815859079386]
	TIME [epoch: 9.75 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2721459996936584		[learning rate: 0.0023199]
	Learning Rate: 0.00231992
	LOSS [training: 0.2721459996936584 | validation: 0.2591785261268113]
	TIME [epoch: 9.78 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2504220457431197		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.2504220457431197 | validation: 0.24583363008586595]
	TIME [epoch: 9.76 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2532642706133839		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.2532642706133839 | validation: 0.23708854497934012]
	TIME [epoch: 9.74 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2410299921550457		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.2410299921550457 | validation: 0.2573197508042518]
	TIME [epoch: 9.77 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2687390022837356		[learning rate: 0.0022975]
	Learning Rate: 0.00229754
	LOSS [training: 0.2687390022837356 | validation: 0.30156870466703567]
	TIME [epoch: 9.75 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3008064641902989		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.3008064641902989 | validation: 0.252742501773079]
	TIME [epoch: 9.77 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32899239575317274		[learning rate: 0.0022864]
	Learning Rate: 0.00228643
	LOSS [training: 0.32899239575317274 | validation: 0.2725302968032792]
	TIME [epoch: 9.77 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26329169579771416		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.26329169579771416 | validation: 0.25346211714521977]
	TIME [epoch: 9.77 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2750729954116598		[learning rate: 0.0022754]
	Learning Rate: 0.00227537
	LOSS [training: 0.2750729954116598 | validation: 0.2546470379826652]
	TIME [epoch: 9.75 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26224483090037004		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.26224483090037004 | validation: 0.2612906909951629]
	TIME [epoch: 9.77 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2386225096184953		[learning rate: 0.0022644]
	Learning Rate: 0.00226437
	LOSS [training: 0.2386225096184953 | validation: 0.2204345318800459]
	TIME [epoch: 9.76 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2421994558118759		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.2421994558118759 | validation: 0.29347128086314855]
	TIME [epoch: 9.76 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27836876513913617		[learning rate: 0.0022534]
	Learning Rate: 0.00225342
	LOSS [training: 0.27836876513913617 | validation: 0.26850611235149496]
	TIME [epoch: 9.76 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26239180398461964		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.26239180398461964 | validation: 0.2603734300955779]
	TIME [epoch: 9.78 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27956781940393804		[learning rate: 0.0022425]
	Learning Rate: 0.00224252
	LOSS [training: 0.27956781940393804 | validation: 0.3135064630248878]
	TIME [epoch: 9.76 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3108829885844725		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.3108829885844725 | validation: 0.25892123960467667]
	TIME [epoch: 9.76 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28621539892300535		[learning rate: 0.0022317]
	Learning Rate: 0.00223168
	LOSS [training: 0.28621539892300535 | validation: 0.24835090764367124]
	TIME [epoch: 9.77 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2755198296857702		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.2755198296857702 | validation: 0.28694142164238823]
	TIME [epoch: 9.76 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27082104155412645		[learning rate: 0.0022209]
	Learning Rate: 0.00222089
	LOSS [training: 0.27082104155412645 | validation: 0.25878543451816605]
	TIME [epoch: 9.76 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2634818889674877		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.2634818889674877 | validation: 0.23792766743850471]
	TIME [epoch: 9.78 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3225322911312333		[learning rate: 0.0022101]
	Learning Rate: 0.00221015
	LOSS [training: 0.3225322911312333 | validation: 0.31637467400907676]
	TIME [epoch: 9.76 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30142372161146547		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.30142372161146547 | validation: 0.27526942846524644]
	TIME [epoch: 9.76 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2884509870884883		[learning rate: 0.0021995]
	Learning Rate: 0.00219946
	LOSS [training: 0.2884509870884883 | validation: 0.269200488972977]
	TIME [epoch: 9.77 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2590147713488482		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.2590147713488482 | validation: 0.2790099243634814]
	TIME [epoch: 9.77 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28299798936326187		[learning rate: 0.0021888]
	Learning Rate: 0.00218882
	LOSS [training: 0.28299798936326187 | validation: 0.30081840922007996]
	TIME [epoch: 9.75 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27708806962173177		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.27708806962173177 | validation: 0.2629149788928725]
	TIME [epoch: 9.76 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2442895127583608		[learning rate: 0.0021782]
	Learning Rate: 0.00217824
	LOSS [training: 0.2442895127583608 | validation: 0.190006867794476]
	TIME [epoch: 9.77 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19986633143285532		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.19986633143285532 | validation: 0.2561113680691859]
	TIME [epoch: 9.76 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20619730237988182		[learning rate: 0.0021677]
	Learning Rate: 0.0021677
	LOSS [training: 0.20619730237988182 | validation: 0.2074048184776116]
	TIME [epoch: 9.76 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21496179344579502		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.21496179344579502 | validation: 0.3386419702930431]
	TIME [epoch: 9.77 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3128083246993042		[learning rate: 0.0021572]
	Learning Rate: 0.00215722
	LOSS [training: 0.3128083246993042 | validation: 0.38801707599537566]
	TIME [epoch: 9.75 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2922389377944827		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.2922389377944827 | validation: 0.33948230599979967]
	TIME [epoch: 9.76 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26264037912488747		[learning rate: 0.0021468]
	Learning Rate: 0.00214679
	LOSS [training: 0.26264037912488747 | validation: 0.2526142569706557]
	TIME [epoch: 9.77 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20263560950195014		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.20263560950195014 | validation: 0.21149252202493407]
	TIME [epoch: 9.77 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24778551534138749		[learning rate: 0.0021364]
	Learning Rate: 0.00213641
	LOSS [training: 0.24778551534138749 | validation: 0.4619467796231348]
	TIME [epoch: 9.76 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5228051045133761		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.5228051045133761 | validation: 0.4351880332251896]
	TIME [epoch: 9.77 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3423393447272797		[learning rate: 0.0021261]
	Learning Rate: 0.00212608
	LOSS [training: 0.3423393447272797 | validation: 0.2412595795875489]
	TIME [epoch: 9.77 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20343710691061023		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.20343710691061023 | validation: 0.1727003891844529]
	TIME [epoch: 9.75 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18835909924209043		[learning rate: 0.0021158]
	Learning Rate: 0.0021158
	LOSS [training: 0.18835909924209043 | validation: 0.16481920983593817]
	TIME [epoch: 9.76 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1822397927646104		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.1822397927646104 | validation: 0.4134922467049463]
	TIME [epoch: 9.78 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5193444074794565		[learning rate: 0.0021056]
	Learning Rate: 0.00210556
	LOSS [training: 0.5193444074794565 | validation: 0.5429728056147632]
	TIME [epoch: 9.76 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36634210743691575		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.36634210743691575 | validation: 0.23070157303893982]
	TIME [epoch: 9.76 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26540790837902284		[learning rate: 0.0020954]
	Learning Rate: 0.00209538
	LOSS [training: 0.26540790837902284 | validation: 0.4901613513865186]
	TIME [epoch: 9.78 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4730139504059756		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.4730139504059756 | validation: 0.6214416425918577]
	TIME [epoch: 9.76 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39446143318452176		[learning rate: 0.0020852]
	Learning Rate: 0.00208525
	LOSS [training: 0.39446143318452176 | validation: 0.24959403636136387]
	TIME [epoch: 9.76 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.287880992146829		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.287880992146829 | validation: 0.33995199933874]
	TIME [epoch: 9.77 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32059682540316875		[learning rate: 0.0020752]
	Learning Rate: 0.00207517
	LOSS [training: 0.32059682540316875 | validation: 0.3339032825083528]
	TIME [epoch: 9.76 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3510135230833729		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.3510135230833729 | validation: 0.5612098985419265]
	TIME [epoch: 9.76 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45363121715621385		[learning rate: 0.0020651]
	Learning Rate: 0.00206513
	LOSS [training: 0.45363121715621385 | validation: 0.4251956684474263]
	TIME [epoch: 9.77 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31118322740704885		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.31118322740704885 | validation: 0.35790704413424335]
	TIME [epoch: 9.77 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38324969662723135		[learning rate: 0.0020551]
	Learning Rate: 0.00205514
	LOSS [training: 0.38324969662723135 | validation: 0.3357074278418275]
	TIME [epoch: 9.76 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43257922347986566		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.43257922347986566 | validation: 0.35916529669263414]
	TIME [epoch: 9.76 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27583960927741963		[learning rate: 0.0020452]
	Learning Rate: 0.0020452
	LOSS [training: 0.27583960927741963 | validation: 0.26110506371670317]
	TIME [epoch: 9.78 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23216417486998706		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.23216417486998706 | validation: 0.2323075877333647]
	TIME [epoch: 9.76 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20634881748142603		[learning rate: 0.0020353]
	Learning Rate: 0.00203531
	LOSS [training: 0.20634881748142603 | validation: 0.2258630687441815]
	TIME [epoch: 9.75 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2209428899817421		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.2209428899817421 | validation: 0.21115450997722604]
	TIME [epoch: 9.78 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2575883725131634		[learning rate: 0.0020255]
	Learning Rate: 0.00202547
	LOSS [training: 0.2575883725131634 | validation: 0.3525703606807028]
	TIME [epoch: 9.75 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2555989387719896		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.2555989387719896 | validation: 0.24421493440555167]
	TIME [epoch: 9.76 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24850206024430627		[learning rate: 0.0020157]
	Learning Rate: 0.00201568
	LOSS [training: 0.24850206024430627 | validation: 0.33266622355922776]
	TIME [epoch: 9.78 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38008415401442025		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.38008415401442025 | validation: 0.5636233066123599]
	TIME [epoch: 9.75 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39372501061318155		[learning rate: 0.0020059]
	Learning Rate: 0.00200593
	LOSS [training: 0.39372501061318155 | validation: 0.4418976318097019]
	TIME [epoch: 9.76 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3743589416351497		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.3743589416351497 | validation: 0.39933299892604396]
	TIME [epoch: 9.76 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.438487747461641		[learning rate: 0.0019962]
	Learning Rate: 0.00199623
	LOSS [training: 0.438487747461641 | validation: 0.48349745402916283]
	TIME [epoch: 9.75 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34437751158824276		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.34437751158824276 | validation: 0.3411328311651354]
	TIME [epoch: 9.75 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2843074090790424		[learning rate: 0.0019866]
	Learning Rate: 0.00198658
	LOSS [training: 0.2843074090790424 | validation: 0.30770722118010746]
	TIME [epoch: 9.74 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33063782891557797		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.33063782891557797 | validation: 0.37669920591093586]
	TIME [epoch: 9.77 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26304986101751854		[learning rate: 0.001977]
	Learning Rate: 0.00197697
	LOSS [training: 0.26304986101751854 | validation: 0.24675762160311657]
	TIME [epoch: 9.75 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28602570902613317		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.28602570902613317 | validation: 0.30029291171227335]
	TIME [epoch: 9.74 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2536943246281911		[learning rate: 0.0019674]
	Learning Rate: 0.00196741
	LOSS [training: 0.2536943246281911 | validation: 0.2764576852300581]
	TIME [epoch: 9.76 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31318466350222		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.31318466350222 | validation: 0.4178295895172144]
	TIME [epoch: 9.76 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33224368028568474		[learning rate: 0.0019579]
	Learning Rate: 0.0019579
	LOSS [training: 0.33224368028568474 | validation: 0.5953885388586541]
	TIME [epoch: 9.77 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45971600876418944		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.45971600876418944 | validation: 0.3626450915750313]
	TIME [epoch: 9.76 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2834840424682163		[learning rate: 0.0019484]
	Learning Rate: 0.00194843
	LOSS [training: 0.2834840424682163 | validation: 0.3756157385392174]
	TIME [epoch: 9.74 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2748280533645274		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.2748280533645274 | validation: 0.4086634757925194]
	TIME [epoch: 9.75 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5002287998088895		[learning rate: 0.001939]
	Learning Rate: 0.00193901
	LOSS [training: 0.5002287998088895 | validation: 0.5528362967587331]
	TIME [epoch: 9.77 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.419564249675856		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.419564249675856 | validation: 0.460618594267846]
	TIME [epoch: 9.77 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5563893840257426		[learning rate: 0.0019296]
	Learning Rate: 0.00192963
	LOSS [training: 0.5563893840257426 | validation: 0.5524030704348479]
	TIME [epoch: 9.76 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3154677720545289		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.3154677720545289 | validation: 0.2984240811648049]
	TIME [epoch: 9.76 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2890320569739543		[learning rate: 0.0019203]
	Learning Rate: 0.0019203
	LOSS [training: 0.2890320569739543 | validation: 0.308004228833398]
	TIME [epoch: 9.76 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27885958865716903		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.27885958865716903 | validation: 0.20851645738495414]
	TIME [epoch: 9.74 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24657621860982343		[learning rate: 0.001911]
	Learning Rate: 0.00191101
	LOSS [training: 0.24657621860982343 | validation: 0.3513194566406165]
	TIME [epoch: 9.75 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3860807768074044		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.3860807768074044 | validation: 0.4372581165447608]
	TIME [epoch: 9.78 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3572373577953226		[learning rate: 0.0019018]
	Learning Rate: 0.00190177
	LOSS [training: 0.3572373577953226 | validation: 0.39113750633809247]
	TIME [epoch: 9.76 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36558694543388787		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.36558694543388787 | validation: 0.2589499337374306]
	TIME [epoch: 9.76 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20680680120834244		[learning rate: 0.0018926]
	Learning Rate: 0.00189257
	LOSS [training: 0.20680680120834244 | validation: 0.17223400651238258]
	TIME [epoch: 9.84 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16550725280486728		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.16550725280486728 | validation: 0.15912128124248548]
	TIME [epoch: 9.77 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16751018723659247		[learning rate: 0.0018834]
	Learning Rate: 0.00188342
	LOSS [training: 0.16751018723659247 | validation: 0.188000142199548]
	TIME [epoch: 9.75 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18218589017342968		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.18218589017342968 | validation: 0.21173700414508873]
	TIME [epoch: 9.77 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26633722421643713		[learning rate: 0.0018743]
	Learning Rate: 0.00187431
	LOSS [training: 0.26633722421643713 | validation: 0.24912453628644562]
	TIME [epoch: 9.76 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2693514081054188		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.2693514081054188 | validation: 0.3134377187026879]
	TIME [epoch: 9.76 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2672927331518303		[learning rate: 0.0018652]
	Learning Rate: 0.00186525
	LOSS [training: 0.2672927331518303 | validation: 0.2728421552870035]
	TIME [epoch: 9.76 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25395817719436004		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.25395817719436004 | validation: 0.2301626355911298]
	TIME [epoch: 9.77 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22004259517265826		[learning rate: 0.0018562]
	Learning Rate: 0.00185623
	LOSS [training: 0.22004259517265826 | validation: 0.3010307023036215]
	TIME [epoch: 9.75 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.287884057638117		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.287884057638117 | validation: 0.3421514442090768]
	TIME [epoch: 9.76 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3479910084483337		[learning rate: 0.0018473]
	Learning Rate: 0.00184725
	LOSS [training: 0.3479910084483337 | validation: 0.2906000070962289]
	TIME [epoch: 9.77 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28217291800793154		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.28217291800793154 | validation: 0.26082002217724753]
	TIME [epoch: 9.74 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23363358811006182		[learning rate: 0.0018383]
	Learning Rate: 0.00183832
	LOSS [training: 0.23363358811006182 | validation: 0.2526958858585177]
	TIME [epoch: 9.74 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2257425815863871		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.2257425815863871 | validation: 0.183471006162175]
	TIME [epoch: 9.77 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20348488075947482		[learning rate: 0.0018294]
	Learning Rate: 0.00182943
	LOSS [training: 0.20348488075947482 | validation: 0.22847537025524034]
	TIME [epoch: 9.76 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21001288017042702		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.21001288017042702 | validation: 0.24716631881449316]
	TIME [epoch: 9.74 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23845223216858735		[learning rate: 0.0018206]
	Learning Rate: 0.00182058
	LOSS [training: 0.23845223216858735 | validation: 0.2713238061784882]
	TIME [epoch: 9.76 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2504530548890836		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.2504530548890836 | validation: 0.23465976115298573]
	TIME [epoch: 9.76 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21605285843521652		[learning rate: 0.0018118]
	Learning Rate: 0.00181178
	LOSS [training: 0.21605285843521652 | validation: 0.2167145444339554]
	TIME [epoch: 9.75 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2115791146295188		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.2115791146295188 | validation: 0.2664748182751969]
	TIME [epoch: 9.75 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29392003397793565		[learning rate: 0.001803]
	Learning Rate: 0.00180302
	LOSS [training: 0.29392003397793565 | validation: 0.3040890344444632]
	TIME [epoch: 9.78 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30208280456471026		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.30208280456471026 | validation: 0.282897377123541]
	TIME [epoch: 9.76 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.272385450395898		[learning rate: 0.0017943]
	Learning Rate: 0.0017943
	LOSS [training: 0.272385450395898 | validation: 0.2785792952304326]
	TIME [epoch: 9.75 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28615620823476945		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.28615620823476945 | validation: 0.28139997897614594]
	TIME [epoch: 9.77 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26811244064724166		[learning rate: 0.0017856]
	Learning Rate: 0.00178562
	LOSS [training: 0.26811244064724166 | validation: 0.2590661510959105]
	TIME [epoch: 9.74 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26919450166468967		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.26919450166468967 | validation: 0.26776276432062873]
	TIME [epoch: 9.75 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.275195207841698		[learning rate: 0.001777]
	Learning Rate: 0.00177699
	LOSS [training: 0.275195207841698 | validation: 0.25073984682796946]
	TIME [epoch: 9.76 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2591613060681553		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.2591613060681553 | validation: 0.2418240720905961]
	TIME [epoch: 9.75 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2710782220619666		[learning rate: 0.0017684]
	Learning Rate: 0.00176839
	LOSS [training: 0.2710782220619666 | validation: 0.2584271327095033]
	TIME [epoch: 9.75 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26112451059761266		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.26112451059761266 | validation: 0.24728014272626986]
	TIME [epoch: 9.77 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26392125732761096		[learning rate: 0.0017598]
	Learning Rate: 0.00175984
	LOSS [training: 0.26392125732761096 | validation: 0.23924719252447865]
	TIME [epoch: 9.76 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2459494903805896		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.2459494903805896 | validation: 0.24457817575755697]
	TIME [epoch: 9.76 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2524299551549137		[learning rate: 0.0017513]
	Learning Rate: 0.00175133
	LOSS [training: 0.2524299551549137 | validation: 0.2465726529378093]
	TIME [epoch: 9.77 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24509922362684308		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.24509922362684308 | validation: 0.21292218308695163]
	TIME [epoch: 9.77 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2566359310335696		[learning rate: 0.0017429]
	Learning Rate: 0.00174286
	LOSS [training: 0.2566359310335696 | validation: 0.2241255406851401]
	TIME [epoch: 9.76 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19927438320526464		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.19927438320526464 | validation: 0.1862172697883392]
	TIME [epoch: 9.76 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21633469710192155		[learning rate: 0.0017344]
	Learning Rate: 0.00173443
	LOSS [training: 0.21633469710192155 | validation: 0.3113793359368803]
	TIME [epoch: 9.77 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33009945332770274		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.33009945332770274 | validation: 0.30473816295549705]
	TIME [epoch: 9.75 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34391185819506076		[learning rate: 0.001726]
	Learning Rate: 0.00172605
	LOSS [training: 0.34391185819506076 | validation: 0.2878648580970868]
	TIME [epoch: 9.76 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2734614307515591		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.2734614307515591 | validation: 0.2458519100925648]
	TIME [epoch: 9.77 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22763011643071324		[learning rate: 0.0017177]
	Learning Rate: 0.0017177
	LOSS [training: 0.22763011643071324 | validation: 0.18299492310912524]
	TIME [epoch: 9.75 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1769065972880706		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.1769065972880706 | validation: 0.1745846241141308]
	TIME [epoch: 9.75 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1862164640858904		[learning rate: 0.0017094]
	Learning Rate: 0.00170939
	LOSS [training: 0.1862164640858904 | validation: 0.17055555473827774]
	TIME [epoch: 9.77 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18746651803563236		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.18746651803563236 | validation: 0.23080538609672985]
	TIME [epoch: 9.76 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19419117066799968		[learning rate: 0.0017011]
	Learning Rate: 0.00170113
	LOSS [training: 0.19419117066799968 | validation: 0.20667970711929382]
	TIME [epoch: 9.75 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21265458045418167		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.21265458045418167 | validation: 0.22407155046165847]
	TIME [epoch: 9.75 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23960659091664632		[learning rate: 0.0016929]
	Learning Rate: 0.0016929
	LOSS [training: 0.23960659091664632 | validation: 0.2284058999964232]
	TIME [epoch: 9.77 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2062745953031758		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.2062745953031758 | validation: 0.20696512733276937]
	TIME [epoch: 9.75 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24209375291830634		[learning rate: 0.0016847]
	Learning Rate: 0.00168471
	LOSS [training: 0.24209375291830634 | validation: 0.24519463395241015]
	TIME [epoch: 9.75 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24834785558190786		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.24834785558190786 | validation: 0.24723675792702218]
	TIME [epoch: 9.78 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2709784225889351		[learning rate: 0.0016766]
	Learning Rate: 0.00167657
	LOSS [training: 0.2709784225889351 | validation: 0.24738723547722083]
	TIME [epoch: 9.77 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21346912179034847		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.21346912179034847 | validation: 0.21085738153210684]
	TIME [epoch: 9.76 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23542319697555394		[learning rate: 0.0016685]
	Learning Rate: 0.00166846
	LOSS [training: 0.23542319697555394 | validation: 0.2847313956803896]
	TIME [epoch: 9.77 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27506360621700854		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.27506360621700854 | validation: 0.2577483963334756]
	TIME [epoch: 9.76 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2625441923645192		[learning rate: 0.0016604]
	Learning Rate: 0.00166039
	LOSS [training: 0.2625441923645192 | validation: 0.2686919333050598]
	TIME [epoch: 9.75 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34181986445374796		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.34181986445374796 | validation: 0.28879228844707777]
	TIME [epoch: 9.76 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3168228569787632		[learning rate: 0.0016524]
	Learning Rate: 0.00165236
	LOSS [training: 0.3168228569787632 | validation: 0.3271259197022529]
	TIME [epoch: 9.74 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35875523650899555		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.35875523650899555 | validation: 0.34255819589113834]
	TIME [epoch: 9.74 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34148828525986913		[learning rate: 0.0016444]
	Learning Rate: 0.00164437
	LOSS [training: 0.34148828525986913 | validation: 0.2300716824597817]
	TIME [epoch: 9.74 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24202133244206742		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.24202133244206742 | validation: 0.2566918159201172]
	TIME [epoch: 9.78 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2602819555289388		[learning rate: 0.0016364]
	Learning Rate: 0.00163642
	LOSS [training: 0.2602819555289388 | validation: 0.2233965147758522]
	TIME [epoch: 9.74 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26823660298753926		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.26823660298753926 | validation: 0.27318321687791836]
	TIME [epoch: 9.76 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2749791277297309		[learning rate: 0.0016285]
	Learning Rate: 0.00162851
	LOSS [training: 0.2749791277297309 | validation: 0.24493208238614814]
	TIME [epoch: 9.78 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28208059080968795		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.28208059080968795 | validation: 0.28239461283445166]
	TIME [epoch: 9.76 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2606028330831503		[learning rate: 0.0016206]
	Learning Rate: 0.00162063
	LOSS [training: 0.2606028330831503 | validation: 0.26416974201544874]
	TIME [epoch: 9.75 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28314862806888313		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.28314862806888313 | validation: 0.2916696391213205]
	TIME [epoch: 9.76 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24569894347809978		[learning rate: 0.0016128]
	Learning Rate: 0.00161279
	LOSS [training: 0.24569894347809978 | validation: 0.2076720814948284]
	TIME [epoch: 9.75 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27658456912250157		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.27658456912250157 | validation: 0.36904527827852174]
	TIME [epoch: 9.76 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3568613239808115		[learning rate: 0.001605]
	Learning Rate: 0.001605
	LOSS [training: 0.3568613239808115 | validation: 0.2722510967692387]
	TIME [epoch: 9.78 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2344712046811454		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.2344712046811454 | validation: 0.1710697674521402]
	TIME [epoch: 9.76 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20970063102529474		[learning rate: 0.0015972]
	Learning Rate: 0.00159723
	LOSS [training: 0.20970063102529474 | validation: 0.21479255404754857]
	TIME [epoch: 9.76 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21222826962283703		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.21222826962283703 | validation: 0.19459976834254705]
	TIME [epoch: 9.76 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19073060753509066		[learning rate: 0.0015895]
	Learning Rate: 0.00158951
	LOSS [training: 0.19073060753509066 | validation: 0.17752273167189322]
	TIME [epoch: 9.77 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2006305252292985		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.2006305252292985 | validation: 0.16005228493250404]
	TIME [epoch: 9.75 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.172585989821386		[learning rate: 0.0015818]
	Learning Rate: 0.00158182
	LOSS [training: 0.172585989821386 | validation: 0.15099751830106586]
	TIME [epoch: 9.75 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1788905254498843		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.1788905254498843 | validation: 0.21455876465077275]
	TIME [epoch: 9.76 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17643892424695612		[learning rate: 0.0015742]
	Learning Rate: 0.00157417
	LOSS [training: 0.17643892424695612 | validation: 0.1879830306742167]
	TIME [epoch: 9.75 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17088007628621113		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.17088007628621113 | validation: 0.22063317627650755]
	TIME [epoch: 9.75 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17520117817397182		[learning rate: 0.0015666]
	Learning Rate: 0.00156656
	LOSS [training: 0.17520117817397182 | validation: 0.14880558662168317]
	TIME [epoch: 9.77 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16028451522118084		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.16028451522118084 | validation: 0.14795175636869934]
	TIME [epoch: 9.74 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17726697001520822		[learning rate: 0.001559]
	Learning Rate: 0.00155899
	LOSS [training: 0.17726697001520822 | validation: 0.3077702477844283]
	TIME [epoch: 9.74 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27117833020832627		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.27117833020832627 | validation: 0.2543562362438853]
	TIME [epoch: 9.77 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19141847745127497		[learning rate: 0.0015514]
	Learning Rate: 0.00155145
	LOSS [training: 0.19141847745127497 | validation: 0.17419373557240314]
	TIME [epoch: 9.76 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19748623329275988		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.19748623329275988 | validation: 0.20351912237260122]
	TIME [epoch: 9.74 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23335670601291433		[learning rate: 0.0015439]
	Learning Rate: 0.00154394
	LOSS [training: 0.23335670601291433 | validation: 0.21801217620001262]
	TIME [epoch: 9.75 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2221184298700293		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.2221184298700293 | validation: 0.17249269728189898]
	TIME [epoch: 9.75 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22039383170182916		[learning rate: 0.0015365]
	Learning Rate: 0.00153648
	LOSS [training: 0.22039383170182916 | validation: 0.2528976181396565]
	TIME [epoch: 9.74 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2573715108198972		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.2573715108198972 | validation: 0.21431059282531856]
	TIME [epoch: 9.75 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21097876730708648		[learning rate: 0.001529]
	Learning Rate: 0.00152905
	LOSS [training: 0.21097876730708648 | validation: 0.1997105864814938]
	TIME [epoch: 9.76 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22126508112910429		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.22126508112910429 | validation: 0.22740925287885083]
	TIME [epoch: 9.74 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21121751162125965		[learning rate: 0.0015217]
	Learning Rate: 0.00152165
	LOSS [training: 0.21121751162125965 | validation: 0.1898171464217469]
	TIME [epoch: 9.75 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2048223820960363		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.2048223820960363 | validation: 0.19816253478674978]
	TIME [epoch: 9.77 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2060332647111187		[learning rate: 0.0015143]
	Learning Rate: 0.00151429
	LOSS [training: 0.2060332647111187 | validation: 0.17713761743661013]
	TIME [epoch: 9.75 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1912894079212814		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.1912894079212814 | validation: 0.18094133039467422]
	TIME [epoch: 9.73 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18837639214787566		[learning rate: 0.001507]
	Learning Rate: 0.00150697
	LOSS [training: 0.18837639214787566 | validation: 0.1977324309299334]
	TIME [epoch: 9.76 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2176907169173082		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.2176907169173082 | validation: 0.2625884781049142]
	TIME [epoch: 9.76 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2549625307468423		[learning rate: 0.0014997]
	Learning Rate: 0.00149968
	LOSS [training: 0.2549625307468423 | validation: 0.26597427616842484]
	TIME [epoch: 9.75 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20215841108014243		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.20215841108014243 | validation: 0.18838272550311455]
	TIME [epoch: 9.75 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16072641899316226		[learning rate: 0.0014924]
	Learning Rate: 0.00149243
	LOSS [training: 0.16072641899316226 | validation: 0.17403546521562016]
	TIME [epoch: 9.77 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14980881468988266		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.14980881468988266 | validation: 0.15393149293606648]
	TIME [epoch: 9.74 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16794028250517518		[learning rate: 0.0014852]
	Learning Rate: 0.00148522
	LOSS [training: 0.16794028250517518 | validation: 0.20422283530373722]
	TIME [epoch: 9.75 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19073704463295654		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.19073704463295654 | validation: 0.1734538348763782]
	TIME [epoch: 9.78 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19591181322701293		[learning rate: 0.001478]
	Learning Rate: 0.00147803
	LOSS [training: 0.19591181322701293 | validation: 0.2064003776044368]
	TIME [epoch: 9.75 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16906772817521365		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.16906772817521365 | validation: 0.17945960655264237]
	TIME [epoch: 9.74 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1481330200305073		[learning rate: 0.0014709]
	Learning Rate: 0.00147089
	LOSS [training: 0.1481330200305073 | validation: 0.17128730597916192]
	TIME [epoch: 9.76 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17357156211759045		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.17357156211759045 | validation: 0.17768098096777732]
	TIME [epoch: 9.76 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17621558018896658		[learning rate: 0.0014638]
	Learning Rate: 0.00146377
	LOSS [training: 0.17621558018896658 | validation: 0.22406222517704077]
	TIME [epoch: 9.75 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23134734373588364		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.23134734373588364 | validation: 0.2442565358096648]
	TIME [epoch: 9.76 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23599201905742354		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.23599201905742354 | validation: 0.24653784371027226]
	TIME [epoch: 9.75 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23688097518693155		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.23688097518693155 | validation: 0.23981129581217786]
	TIME [epoch: 9.74 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2232213676468347		[learning rate: 0.0014497]
	Learning Rate: 0.00144965
	LOSS [training: 0.2232213676468347 | validation: 0.2048949742721267]
	TIME [epoch: 9.76 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23112570518383935		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.23112570518383935 | validation: 0.2228480490049454]
	TIME [epoch: 9.76 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21390196181687796		[learning rate: 0.0014426]
	Learning Rate: 0.00144264
	LOSS [training: 0.21390196181687796 | validation: 0.21609814592067936]
	TIME [epoch: 9.74 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20069969160836085		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.20069969160836085 | validation: 0.2228535731801762]
	TIME [epoch: 9.75 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23531215412278944		[learning rate: 0.0014357]
	Learning Rate: 0.00143566
	LOSS [training: 0.23531215412278944 | validation: 0.26410974701803824]
	TIME [epoch: 9.75 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2951691348015585		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.2951691348015585 | validation: 0.3263248115121496]
	TIME [epoch: 9.75 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29867492635012705		[learning rate: 0.0014287]
	Learning Rate: 0.00142872
	LOSS [training: 0.29867492635012705 | validation: 0.2631283921448424]
	TIME [epoch: 9.75 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24810713054186206		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.24810713054186206 | validation: 0.2861627194007011]
	TIME [epoch: 9.77 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25502011152499315		[learning rate: 0.0014218]
	Learning Rate: 0.00142181
	LOSS [training: 0.25502011152499315 | validation: 0.2263381890217217]
	TIME [epoch: 9.74 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2313254217379792		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.2313254217379792 | validation: 0.2447459064970432]
	TIME [epoch: 9.75 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24351182075109518		[learning rate: 0.0014149]
	Learning Rate: 0.00141494
	LOSS [training: 0.24351182075109518 | validation: 0.2535613429309604]
	TIME [epoch: 9.75 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2521109924075937		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.2521109924075937 | validation: 0.22128617595173286]
	TIME [epoch: 9.74 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22532052213932702		[learning rate: 0.0014081]
	Learning Rate: 0.00140809
	LOSS [training: 0.22532052213932702 | validation: 0.2169522709110643]
	TIME [epoch: 9.75 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1885628464310985		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.1885628464310985 | validation: 0.16564394108075312]
	TIME [epoch: 9.74 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16117077791312917		[learning rate: 0.0014013]
	Learning Rate: 0.00140128
	LOSS [training: 0.16117077791312917 | validation: 0.18800104047133373]
	TIME [epoch: 9.76 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543020041811204		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.1543020041811204 | validation: 0.13517203647005044]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_912.pth
	Model improved!!!
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1348902296284026		[learning rate: 0.0013945]
	Learning Rate: 0.00139451
	LOSS [training: 0.1348902296284026 | validation: 0.13463526963015096]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_913.pth
	Model improved!!!
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14190920185685013		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.14190920185685013 | validation: 0.14566448878673258]
	TIME [epoch: 9.77 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13591556829858686		[learning rate: 0.0013878]
	Learning Rate: 0.00138776
	LOSS [training: 0.13591556829858686 | validation: 0.14414306224876441]
	TIME [epoch: 9.76 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13728046349952422		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.13728046349952422 | validation: 0.1441898312403308]
	TIME [epoch: 9.75 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16759145712638074		[learning rate: 0.0013811]
	Learning Rate: 0.00138105
	LOSS [training: 0.16759145712638074 | validation: 0.16615292774445142]
	TIME [epoch: 9.77 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14616638075189994		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.14616638075189994 | validation: 0.1439332468024244]
	TIME [epoch: 9.73 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14091894447271114		[learning rate: 0.0013744]
	Learning Rate: 0.00137437
	LOSS [training: 0.14091894447271114 | validation: 0.1616797743975808]
	TIME [epoch: 9.74 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16619588057186013		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.16619588057186013 | validation: 0.1728423261803067]
	TIME [epoch: 9.76 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18684505759447537		[learning rate: 0.0013677]
	Learning Rate: 0.00136773
	LOSS [training: 0.18684505759447537 | validation: 0.18157061983536196]
	TIME [epoch: 9.74 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18183998387876849		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.18183998387876849 | validation: 0.21280411793744372]
	TIME [epoch: 9.74 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22932939611007502		[learning rate: 0.0013611]
	Learning Rate: 0.00136111
	LOSS [training: 0.22932939611007502 | validation: 0.20748903699590052]
	TIME [epoch: 9.76 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20894078341698252		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.20894078341698252 | validation: 0.2176561624829416]
	TIME [epoch: 9.75 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18949527329151883		[learning rate: 0.0013545]
	Learning Rate: 0.00135453
	LOSS [training: 0.18949527329151883 | validation: 0.18137632694355987]
	TIME [epoch: 9.73 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1800592960936757		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.1800592960936757 | validation: 0.19958200204486973]
	TIME [epoch: 9.75 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18377316086314463		[learning rate: 0.001348]
	Learning Rate: 0.00134798
	LOSS [training: 0.18377316086314463 | validation: 0.178954202611022]
	TIME [epoch: 9.76 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1740613165713414		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.1740613165713414 | validation: 0.2125998163480602]
	TIME [epoch: 9.74 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25909211428820755		[learning rate: 0.0013415]
	Learning Rate: 0.00134146
	LOSS [training: 0.25909211428820755 | validation: 0.3027008096649378]
	TIME [epoch: 9.74 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2693953882083887		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.2693953882083887 | validation: 0.22536992684436308]
	TIME [epoch: 9.77 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20577194069747629		[learning rate: 0.001335]
	Learning Rate: 0.00133498
	LOSS [training: 0.20577194069747629 | validation: 0.18898301054591707]
	TIME [epoch: 9.74 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1720995854688552		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.1720995854688552 | validation: 0.16549765378349304]
	TIME [epoch: 9.74 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15080546500152642		[learning rate: 0.0013285]
	Learning Rate: 0.00132852
	LOSS [training: 0.15080546500152642 | validation: 0.15145438264130406]
	TIME [epoch: 9.76 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14563228184365368		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.14563228184365368 | validation: 0.16779389572833295]
	TIME [epoch: 9.76 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15360200337542762		[learning rate: 0.0013221]
	Learning Rate: 0.0013221
	LOSS [training: 0.15360200337542762 | validation: 0.15115515250527925]
	TIME [epoch: 9.74 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13065690013183556		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.13065690013183556 | validation: 0.14073433200827298]
	TIME [epoch: 9.74 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1380253935300782		[learning rate: 0.0013157]
	Learning Rate: 0.0013157
	LOSS [training: 0.1380253935300782 | validation: 0.15307691140527596]
	TIME [epoch: 9.74 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13350821915740185		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.13350821915740185 | validation: 0.12340164204893257]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_938.pth
	Model improved!!!
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13317558491227072		[learning rate: 0.0013093]
	Learning Rate: 0.00130934
	LOSS [training: 0.13317558491227072 | validation: 0.13743330448878302]
	TIME [epoch: 9.75 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14175758718761916		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.14175758718761916 | validation: 0.154354937320066]
	TIME [epoch: 9.75 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13957815703713364		[learning rate: 0.001303]
	Learning Rate: 0.00130301
	LOSS [training: 0.13957815703713364 | validation: 0.14067675415201708]
	TIME [epoch: 9.74 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14596229401051447		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.14596229401051447 | validation: 0.19837370202830984]
	TIME [epoch: 9.73 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20847175506105015		[learning rate: 0.0012967]
	Learning Rate: 0.00129671
	LOSS [training: 0.20847175506105015 | validation: 0.16308570367738626]
	TIME [epoch: 9.76 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15219009843240563		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.15219009843240563 | validation: 0.14700942271209574]
	TIME [epoch: 9.73 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512790096831837		[learning rate: 0.0012904]
	Learning Rate: 0.00129044
	LOSS [training: 0.1512790096831837 | validation: 0.1584082241102499]
	TIME [epoch: 9.73 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515222540079383		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.1515222540079383 | validation: 0.17327017158133057]
	TIME [epoch: 9.75 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15688308275357093		[learning rate: 0.0012842]
	Learning Rate: 0.0012842
	LOSS [training: 0.15688308275357093 | validation: 0.1691380628030267]
	TIME [epoch: 9.74 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14763766738196732		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.14763766738196732 | validation: 0.1455334929657146]
	TIME [epoch: 9.74 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14616418215151133		[learning rate: 0.001278]
	Learning Rate: 0.00127799
	LOSS [training: 0.14616418215151133 | validation: 0.16110927367785563]
	TIME [epoch: 9.73 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15447642886355228		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.15447642886355228 | validation: 0.18179540346989462]
	TIME [epoch: 9.76 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1882768875603417		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.1882768875603417 | validation: 0.1715175218565257]
	TIME [epoch: 9.74 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1680323086119459		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.1680323086119459 | validation: 0.16413965836120256]
	TIME [epoch: 9.73 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14073683192700392		[learning rate: 0.0012657]
	Learning Rate: 0.00126566
	LOSS [training: 0.14073683192700392 | validation: 0.1639716405233338]
	TIME [epoch: 9.75 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14609831760266237		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.14609831760266237 | validation: 0.16510490422058582]
	TIME [epoch: 9.73 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13587589703960343		[learning rate: 0.0012595]
	Learning Rate: 0.00125954
	LOSS [training: 0.13587589703960343 | validation: 0.1508246975216316]
	TIME [epoch: 9.73 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14106645372868226		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.14106645372868226 | validation: 0.13891952212278807]
	TIME [epoch: 9.75 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13063683149887315		[learning rate: 0.0012534]
	Learning Rate: 0.00125344
	LOSS [training: 0.13063683149887315 | validation: 0.1507949228861604]
	TIME [epoch: 9.73 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1359645129385135		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.1359645129385135 | validation: 0.1315051534183225]
	TIME [epoch: 9.73 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12130254254790773		[learning rate: 0.0012474]
	Learning Rate: 0.00124738
	LOSS [training: 0.12130254254790773 | validation: 0.13844522707172494]
	TIME [epoch: 9.75 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1304613708246937		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.1304613708246937 | validation: 0.14027276731173846]
	TIME [epoch: 9.74 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17172034002514275		[learning rate: 0.0012414]
	Learning Rate: 0.00124135
	LOSS [training: 0.17172034002514275 | validation: 0.20752468597177895]
	TIME [epoch: 9.73 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1887108580627341		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.1887108580627341 | validation: 0.18265773977733638]
	TIME [epoch: 9.73 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18552501068033775		[learning rate: 0.0012353]
	Learning Rate: 0.00123535
	LOSS [training: 0.18552501068033775 | validation: 0.18239342707331832]
	TIME [epoch: 9.75 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16558190960097266		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.16558190960097266 | validation: 0.1497345858993888]
	TIME [epoch: 9.73 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17650928716505473		[learning rate: 0.0012294]
	Learning Rate: 0.00122937
	LOSS [training: 0.17650928716505473 | validation: 0.19785895529199812]
	TIME [epoch: 9.73 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18014525600002979		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.18014525600002979 | validation: 0.1988485448528089]
	TIME [epoch: 9.75 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21418051102723212		[learning rate: 0.0012234]
	Learning Rate: 0.00122343
	LOSS [training: 0.21418051102723212 | validation: 0.20301010038014825]
	TIME [epoch: 9.73 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19137045767933875		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.19137045767933875 | validation: 0.1636075011296532]
	TIME [epoch: 9.74 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17027269705635434		[learning rate: 0.0012175]
	Learning Rate: 0.00121751
	LOSS [training: 0.17027269705635434 | validation: 0.16577627260245606]
	TIME [epoch: 9.75 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15254589136475954		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.15254589136475954 | validation: 0.15028700418996213]
	TIME [epoch: 9.75 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15116329923807437		[learning rate: 0.0012116]
	Learning Rate: 0.00121163
	LOSS [training: 0.15116329923807437 | validation: 0.13685763251289765]
	TIME [epoch: 9.74 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1372580925363933		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.1372580925363933 | validation: 0.1880537942004384]
	TIME [epoch: 9.74 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22821403010586722		[learning rate: 0.0012058]
	Learning Rate: 0.00120577
	LOSS [training: 0.22821403010586722 | validation: 0.3492318731658744]
	TIME [epoch: 9.74 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2703815222307122		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.2703815222307122 | validation: 0.29667485924865555]
	TIME [epoch: 9.73 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2177909215531769		[learning rate: 0.0011999]
	Learning Rate: 0.00119994
	LOSS [training: 0.2177909215531769 | validation: 0.24971083581611425]
	TIME [epoch: 9.74 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26303117360726175		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.26303117360726175 | validation: 0.5831799802970821]
	TIME [epoch: 9.76 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3833118479416626		[learning rate: 0.0011941]
	Learning Rate: 0.00119413
	LOSS [training: 0.3833118479416626 | validation: 0.30143363225275077]
	TIME [epoch: 9.73 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17349807051729482		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.17349807051729482 | validation: 0.19852582903217963]
	TIME [epoch: 9.73 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15712335431532146		[learning rate: 0.0011884]
	Learning Rate: 0.00118836
	LOSS [training: 0.15712335431532146 | validation: 0.14951250620880735]
	TIME [epoch: 9.75 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1435084676536598		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.1435084676536598 | validation: 0.18274801031390747]
	TIME [epoch: 9.74 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15364550894452306		[learning rate: 0.0011826]
	Learning Rate: 0.00118261
	LOSS [training: 0.15364550894452306 | validation: 0.2173235974189278]
	TIME [epoch: 9.73 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14578316491776933		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.14578316491776933 | validation: 0.13097044126553248]
	TIME [epoch: 9.75 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14815818061847422		[learning rate: 0.0011769]
	Learning Rate: 0.00117689
	LOSS [training: 0.14815818061847422 | validation: 0.2753352410891607]
	TIME [epoch: 9.74 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18392126015895366		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.18392126015895366 | validation: 0.13144475019240612]
	TIME [epoch: 9.74 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1625622110211013		[learning rate: 0.0011712]
	Learning Rate: 0.0011712
	LOSS [training: 0.1625622110211013 | validation: 0.25994694449528677]
	TIME [epoch: 9.74 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22011708205371772		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.22011708205371772 | validation: 0.27618833508260954]
	TIME [epoch: 9.74 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.328967916805872		[learning rate: 0.0011655]
	Learning Rate: 0.00116554
	LOSS [training: 0.328967916805872 | validation: 0.399946244182695]
	TIME [epoch: 9.74 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31070260293620716		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.31070260293620716 | validation: 0.5239192889530823]
	TIME [epoch: 9.73 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41028777292271074		[learning rate: 0.0011599]
	Learning Rate: 0.0011599
	LOSS [training: 0.41028777292271074 | validation: 0.4135199296713185]
	TIME [epoch: 9.75 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27594097218215613		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.27594097218215613 | validation: 0.20208374733134762]
	TIME [epoch: 9.73 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27556527968414546		[learning rate: 0.0011543]
	Learning Rate: 0.00115429
	LOSS [training: 0.27556527968414546 | validation: 0.3754276672872904]
	TIME [epoch: 9.73 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33348046899002937		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.33348046899002937 | validation: 0.3843673681905302]
	TIME [epoch: 9.75 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27771268130668253		[learning rate: 0.0011487]
	Learning Rate: 0.00114871
	LOSS [training: 0.27771268130668253 | validation: 0.31065689179831774]
	TIME [epoch: 9.73 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3040408236350023		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.3040408236350023 | validation: 0.23560250671882124]
	TIME [epoch: 9.73 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1732591720876339		[learning rate: 0.0011432]
	Learning Rate: 0.00114316
	LOSS [training: 0.1732591720876339 | validation: 0.13258514592763862]
	TIME [epoch: 9.75 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13434556223467542		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.13434556223467542 | validation: 0.10543694107219058]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_996.pth
	Model improved!!!
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13219108095984902		[learning rate: 0.0011376]
	Learning Rate: 0.00113763
	LOSS [training: 0.13219108095984902 | validation: 0.2021041249181478]
	TIME [epoch: 9.74 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2544006283501809		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.2544006283501809 | validation: 0.3137223872793026]
	TIME [epoch: 9.75 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28654163471143346		[learning rate: 0.0011321]
	Learning Rate: 0.00113213
	LOSS [training: 0.28654163471143346 | validation: 0.3562801989330516]
	TIME [epoch: 9.75 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2755640850311575		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.2755640850311575 | validation: 0.23648472329040995]
	TIME [epoch: 9.73 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19885391595113683		[learning rate: 0.0011267]
	Learning Rate: 0.00112665
	LOSS [training: 0.19885391595113683 | validation: 0.19551938496696855]
	TIME [epoch: 9.74 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1528456723677422		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.1528456723677422 | validation: 0.14583648027397972]
	TIME [epoch: 9.75 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14291064275790186		[learning rate: 0.0011212]
	Learning Rate: 0.0011212
	LOSS [training: 0.14291064275790186 | validation: 0.16126978077116533]
	TIME [epoch: 9.74 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12884669924187625		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.12884669924187625 | validation: 0.09453616116214082]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1004.pth
	Model improved!!!
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12273175792901074		[learning rate: 0.0011158]
	Learning Rate: 0.00111578
	LOSS [training: 0.12273175792901074 | validation: 0.17761263691565113]
	TIME [epoch: 9.75 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23348896678324316		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.23348896678324316 | validation: 0.28653453529701856]
	TIME [epoch: 9.73 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18082037776590815		[learning rate: 0.0011104]
	Learning Rate: 0.00111039
	LOSS [training: 0.18082037776590815 | validation: 0.17863124779548215]
	TIME [epoch: 9.73 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16154999737635994		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.16154999737635994 | validation: 0.17186136910850255]
	TIME [epoch: 9.75 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1466269488490795		[learning rate: 0.001105]
	Learning Rate: 0.00110502
	LOSS [training: 0.1466269488490795 | validation: 0.1484157518950984]
	TIME [epoch: 9.73 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13901234990371297		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.13901234990371297 | validation: 0.17741720384901427]
	TIME [epoch: 9.73 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15370534683526751		[learning rate: 0.0010997]
	Learning Rate: 0.00109967
	LOSS [training: 0.15370534683526751 | validation: 0.15629912142027297]
	TIME [epoch: 9.74 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12636131294416758		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.12636131294416758 | validation: 0.12153977503736567]
	TIME [epoch: 9.74 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12381253063480291		[learning rate: 0.0010944]
	Learning Rate: 0.00109435
	LOSS [training: 0.12381253063480291 | validation: 0.11913799473221995]
	TIME [epoch: 9.73 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1400427623738347		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.1400427623738347 | validation: 0.13473428383794203]
	TIME [epoch: 9.73 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.133887330447549		[learning rate: 0.0010891]
	Learning Rate: 0.00108906
	LOSS [training: 0.133887330447549 | validation: 0.14834939952323964]
	TIME [epoch: 9.75 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12488679437323205		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.12488679437323205 | validation: 0.12094387162769091]
	TIME [epoch: 9.74 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14260796875310372		[learning rate: 0.0010838]
	Learning Rate: 0.0010838
	LOSS [training: 0.14260796875310372 | validation: 0.19525735947250525]
	TIME [epoch: 9.73 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17835763417013606		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.17835763417013606 | validation: 0.16668543833209412]
	TIME [epoch: 9.75 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15295650186085188		[learning rate: 0.0010786]
	Learning Rate: 0.00107855
	LOSS [training: 0.15295650186085188 | validation: 0.2558546202418889]
	TIME [epoch: 9.73 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49050378844467446		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.49050378844467446 | validation: 0.9367438570441087]
	TIME [epoch: 9.73 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5768118371865163		[learning rate: 0.0010733]
	Learning Rate: 0.00107334
	LOSS [training: 0.5768118371865163 | validation: 0.4904762554602809]
	TIME [epoch: 9.75 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3457267746315774		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.3457267746315774 | validation: 0.2288660985232533]
	TIME [epoch: 9.73 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1707573274453473		[learning rate: 0.0010681]
	Learning Rate: 0.00106815
	LOSS [training: 0.1707573274453473 | validation: 0.14877530720024182]
	TIME [epoch: 9.73 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15224158942273305		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.15224158942273305 | validation: 0.1476946408264049]
	TIME [epoch: 9.74 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14094721192862697		[learning rate: 0.001063]
	Learning Rate: 0.00106298
	LOSS [training: 0.14094721192862697 | validation: 0.1365438860120747]
	TIME [epoch: 9.73 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15245207142384323		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.15245207142384323 | validation: 0.14940757375327454]
	TIME [epoch: 9.73 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14650644032635424		[learning rate: 0.0010578]
	Learning Rate: 0.00105784
	LOSS [training: 0.14650644032635424 | validation: 0.14899605757855977]
	TIME [epoch: 9.73 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14268420537946414		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.14268420537946414 | validation: 0.20045609747109697]
	TIME [epoch: 9.74 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19245483115017709		[learning rate: 0.0010527]
	Learning Rate: 0.00105273
	LOSS [training: 0.19245483115017709 | validation: 0.20938582608603498]
	TIME [epoch: 9.72 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22237572643926065		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.22237572643926065 | validation: 0.29521015166360925]
	TIME [epoch: 9.73 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25799933939458547		[learning rate: 0.0010476]
	Learning Rate: 0.00104764
	LOSS [training: 0.25799933939458547 | validation: 0.2293275628372275]
	TIME [epoch: 9.74 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21446456477091552		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.21446456477091552 | validation: 0.234021809925432]
	TIME [epoch: 9.73 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1971334041731573		[learning rate: 0.0010426]
	Learning Rate: 0.00104257
	LOSS [training: 0.1971334041731573 | validation: 0.16468049538827223]
	TIME [epoch: 9.73 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16046790829544827		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.16046790829544827 | validation: 0.17035627007441156]
	TIME [epoch: 9.74 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16120464399380147		[learning rate: 0.0010375]
	Learning Rate: 0.00103753
	LOSS [training: 0.16120464399380147 | validation: 0.14619910173687994]
	TIME [epoch: 9.73 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14570934918944806		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.14570934918944806 | validation: 0.13038767650703306]
	TIME [epoch: 9.72 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13871586957569215		[learning rate: 0.0010325]
	Learning Rate: 0.00103251
	LOSS [training: 0.13871586957569215 | validation: 0.13495648116936723]
	TIME [epoch: 9.75 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13034483374478484		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.13034483374478484 | validation: 0.13595718118784]
	TIME [epoch: 9.74 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.136289213255839		[learning rate: 0.0010275]
	Learning Rate: 0.00102752
	LOSS [training: 0.136289213255839 | validation: 0.15265503968013727]
	TIME [epoch: 9.73 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16966794618002817		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.16966794618002817 | validation: 0.18543890327614612]
	TIME [epoch: 9.73 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16354338564149623		[learning rate: 0.0010225]
	Learning Rate: 0.00102255
	LOSS [training: 0.16354338564149623 | validation: 0.1310722390459495]
	TIME [epoch: 9.75 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11986013252576047		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.11986013252576047 | validation: 0.11166370398380356]
	TIME [epoch: 9.73 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12152557352173614		[learning rate: 0.0010176]
	Learning Rate: 0.0010176
	LOSS [training: 0.12152557352173614 | validation: 0.12743547009701575]
	TIME [epoch: 9.72 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1671550226028553		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.1671550226028553 | validation: 0.24335045719690926]
	TIME [epoch: 9.74 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17657499038429253		[learning rate: 0.0010127]
	Learning Rate: 0.00101268
	LOSS [training: 0.17657499038429253 | validation: 0.2094848038846895]
	TIME [epoch: 9.73 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15994697105746158		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.15994697105746158 | validation: 0.1123480885160932]
	TIME [epoch: 9.72 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10185574641107983		[learning rate: 0.0010078]
	Learning Rate: 0.00100779
	LOSS [training: 0.10185574641107983 | validation: 0.10618302231122612]
	TIME [epoch: 9.75 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10388444707177076		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.10388444707177076 | validation: 0.09943140004652362]
	TIME [epoch: 9.73 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11030104225097173		[learning rate: 0.0010029]
	Learning Rate: 0.00100291
	LOSS [training: 0.11030104225097173 | validation: 0.10776312332111655]
	TIME [epoch: 9.72 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12816504086924763		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.12816504086924763 | validation: 0.19712434286576092]
	TIME [epoch: 9.75 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15230622512302522		[learning rate: 0.00099806]
	Learning Rate: 0.000998063
	LOSS [training: 0.15230622512302522 | validation: 0.14725852969737824]
	TIME [epoch: 9.73 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1527344672442097		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.1527344672442097 | validation: 0.1503695122946359]
	TIME [epoch: 9.73 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13630641464918775		[learning rate: 0.00099324]
	Learning Rate: 0.000993237
	LOSS [training: 0.13630641464918775 | validation: 0.1582303575790197]
	TIME [epoch: 9.73 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1556751217461198		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.1556751217461198 | validation: 0.15842718533787747]
	TIME [epoch: 9.74 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14539141199449732		[learning rate: 0.00098843]
	Learning Rate: 0.000988433
	LOSS [training: 0.14539141199449732 | validation: 0.12814226388785915]
	TIME [epoch: 9.73 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1708766901438165		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.1708766901438165 | validation: 0.2910691282400206]
	TIME [epoch: 9.74 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21650114472098628		[learning rate: 0.00098365]
	Learning Rate: 0.000983653
	LOSS [training: 0.21650114472098628 | validation: 0.30886748735461]
	TIME [epoch: 9.75 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2881312274157507		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.2881312274157507 | validation: 0.3773258811568125]
	TIME [epoch: 9.73 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22984817463007534		[learning rate: 0.0009789]
	Learning Rate: 0.000978897
	LOSS [training: 0.22984817463007534 | validation: 0.15195046310039215]
	TIME [epoch: 9.72 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12708488838345205		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.12708488838345205 | validation: 0.11475943024954637]
	TIME [epoch: 9.75 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1186319778418603		[learning rate: 0.00097416]
	Learning Rate: 0.000974163
	LOSS [training: 0.1186319778418603 | validation: 0.1059183469789352]
	TIME [epoch: 9.73 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11132530037598383		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.11132530037598383 | validation: 0.11057872059326113]
	TIME [epoch: 9.73 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12484864233072357		[learning rate: 0.00096945]
	Learning Rate: 0.000969452
	LOSS [training: 0.12484864233072357 | validation: 0.11630469340214607]
	TIME [epoch: 9.74 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11307074317835368		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.11307074317835368 | validation: 0.09743296032124008]
	TIME [epoch: 9.74 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11082081536606106		[learning rate: 0.00096476]
	Learning Rate: 0.000964764
	LOSS [training: 0.11082081536606106 | validation: 0.2020902903238835]
	TIME [epoch: 9.73 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16282039446769814		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.16282039446769814 | validation: 0.1518287857354289]
	TIME [epoch: 9.74 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10865038025482117		[learning rate: 0.0009601]
	Learning Rate: 0.000960098
	LOSS [training: 0.10865038025482117 | validation: 0.08428699130281073]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1067.pth
	Model improved!!!
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0821287534056481		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.0821287534056481 | validation: 0.09832229486201823]
	TIME [epoch: 9.74 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07929741997664921		[learning rate: 0.00095546]
	Learning Rate: 0.000955456
	LOSS [training: 0.07929741997664921 | validation: 0.09905186780039028]
	TIME [epoch: 9.73 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10590890471762907		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.10590890471762907 | validation: 0.13275541070579935]
	TIME [epoch: 9.76 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12925078719808866		[learning rate: 0.00095084]
	Learning Rate: 0.000950835
	LOSS [training: 0.12925078719808866 | validation: 0.1093720367852276]
	TIME [epoch: 9.73 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09713887843437399		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.09713887843437399 | validation: 0.11740730893380526]
	TIME [epoch: 9.72 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11865238526637482		[learning rate: 0.00094624]
	Learning Rate: 0.000946237
	LOSS [training: 0.11865238526637482 | validation: 0.1411633999988448]
	TIME [epoch: 9.75 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1432246219625522		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.1432246219625522 | validation: 0.132335027523681]
	TIME [epoch: 9.74 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13022807940971878		[learning rate: 0.00094166]
	Learning Rate: 0.000941661
	LOSS [training: 0.13022807940971878 | validation: 0.14060121754246058]
	TIME [epoch: 9.73 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13781227004902327		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.13781227004902327 | validation: 0.14276094989229438]
	TIME [epoch: 9.75 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14704377862484935		[learning rate: 0.00093711]
	Learning Rate: 0.000937108
	LOSS [training: 0.14704377862484935 | validation: 0.1351667875816418]
	TIME [epoch: 9.74 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1422821454889554		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.1422821454889554 | validation: 0.10895322009172835]
	TIME [epoch: 9.73 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1148868583934037		[learning rate: 0.00093258]
	Learning Rate: 0.000932576
	LOSS [training: 0.1148868583934037 | validation: 0.10538893491878312]
	TIME [epoch: 9.73 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11243233537801407		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.11243233537801407 | validation: 0.12898632453611883]
	TIME [epoch: 9.75 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15135380541119295		[learning rate: 0.00092807]
	Learning Rate: 0.000928066
	LOSS [training: 0.15135380541119295 | validation: 0.15027168512636596]
	TIME [epoch: 9.73 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1399044237989177		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.1399044237989177 | validation: 0.13531620116058224]
	TIME [epoch: 9.73 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15184773055363915		[learning rate: 0.00092358]
	Learning Rate: 0.000923578
	LOSS [training: 0.15184773055363915 | validation: 0.129083585796978]
	TIME [epoch: 9.75 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1327036581276248		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.1327036581276248 | validation: 0.1352727705194332]
	TIME [epoch: 9.73 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1438147514028007		[learning rate: 0.00091911]
	Learning Rate: 0.000919112
	LOSS [training: 0.1438147514028007 | validation: 0.19873339772805756]
	TIME [epoch: 9.73 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1860962767728486		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.1860962767728486 | validation: 0.22660608125647905]
	TIME [epoch: 9.75 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1664361317618378		[learning rate: 0.00091467]
	Learning Rate: 0.000914667
	LOSS [training: 0.1664361317618378 | validation: 0.2541356074663132]
	TIME [epoch: 9.74 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18322498313806876		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.18322498313806876 | validation: 0.18140995266228532]
	TIME [epoch: 9.73 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1767928072705373		[learning rate: 0.00091024]
	Learning Rate: 0.000910244
	LOSS [training: 0.1767928072705373 | validation: 0.2390513642569876]
	TIME [epoch: 9.74 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16159001275601156		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.16159001275601156 | validation: 0.13459566869937542]
	TIME [epoch: 9.74 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15158076482444205		[learning rate: 0.00090584]
	Learning Rate: 0.000905843
	LOSS [training: 0.15158076482444205 | validation: 0.18516098395706615]
	TIME [epoch: 9.72 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2006813149031955		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.2006813149031955 | validation: 0.18483821124821656]
	TIME [epoch: 9.73 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15602239332068513		[learning rate: 0.00090146]
	Learning Rate: 0.000901462
	LOSS [training: 0.15602239332068513 | validation: 0.12368662967218684]
	TIME [epoch: 9.75 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11643964129251512		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.11643964129251512 | validation: 0.11508565569636066]
	TIME [epoch: 9.73 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13146172507963078		[learning rate: 0.0008971]
	Learning Rate: 0.000897103
	LOSS [training: 0.13146172507963078 | validation: 0.11796221630310783]
	TIME [epoch: 9.73 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10702741782016911		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.10702741782016911 | validation: 0.10460569031823026]
	TIME [epoch: 9.74 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17661520135303638		[learning rate: 0.00089276]
	Learning Rate: 0.000892764
	LOSS [training: 0.17661520135303638 | validation: 0.18440881538177642]
	TIME [epoch: 9.72 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1488135987246951		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.1488135987246951 | validation: 0.13504814857904665]
	TIME [epoch: 9.73 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1151496424591781		[learning rate: 0.00088845]
	Learning Rate: 0.000888447
	LOSS [training: 0.1151496424591781 | validation: 0.09541909594672598]
	TIME [epoch: 9.75 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09561139094397605		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.09561139094397605 | validation: 0.0738814312641168]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1100.pth
	Model improved!!!
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08357962324954075		[learning rate: 0.00088415]
	Learning Rate: 0.000884151
	LOSS [training: 0.08357962324954075 | validation: 0.09629521798018836]
	TIME [epoch: 9.73 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09063138170980257		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.09063138170980257 | validation: 0.08830095992643414]
	TIME [epoch: 9.76 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09120154006262517		[learning rate: 0.00087988]
	Learning Rate: 0.000879875
	LOSS [training: 0.09120154006262517 | validation: 0.0897925591155985]
	TIME [epoch: 9.75 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0966663584591195		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.0966663584591195 | validation: 0.0914116718974266]
	TIME [epoch: 9.73 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08923559896496225		[learning rate: 0.00087562]
	Learning Rate: 0.00087562
	LOSS [training: 0.08923559896496225 | validation: 0.08305399189883712]
	TIME [epoch: 9.74 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10102853267355918		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.10102853267355918 | validation: 0.10899825341594797]
	TIME [epoch: 9.75 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10890470344032673		[learning rate: 0.00087139]
	Learning Rate: 0.000871386
	LOSS [training: 0.10890470344032673 | validation: 0.13890502813198602]
	TIME [epoch: 9.74 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1202429090610243		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.1202429090610243 | validation: 0.1368159280614259]
	TIME [epoch: 9.74 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1156253413297392		[learning rate: 0.00086717]
	Learning Rate: 0.000867172
	LOSS [training: 0.1156253413297392 | validation: 0.11116288395055358]
	TIME [epoch: 9.76 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12761202899448176		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.12761202899448176 | validation: 0.14756230241982213]
	TIME [epoch: 9.75 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12086396313243959		[learning rate: 0.00086298]
	Learning Rate: 0.000862979
	LOSS [training: 0.12086396313243959 | validation: 0.10545043878317341]
	TIME [epoch: 9.75 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12672240028683932		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.12672240028683932 | validation: 0.2455109490587538]
	TIME [epoch: 9.76 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1649395475103878		[learning rate: 0.00085881]
	Learning Rate: 0.000858805
	LOSS [training: 0.1649395475103878 | validation: 0.10909788921808758]
	TIME [epoch: 9.74 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09820048848001851		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.09820048848001851 | validation: 0.10867900137913519]
	TIME [epoch: 9.74 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11455448868544434		[learning rate: 0.00085465]
	Learning Rate: 0.000854652
	LOSS [training: 0.11455448868544434 | validation: 0.1141249230346445]
	TIME [epoch: 9.75 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12363739012087956		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.12363739012087956 | validation: 0.1863368259170395]
	TIME [epoch: 9.74 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13257358766118063		[learning rate: 0.00085052]
	Learning Rate: 0.000850519
	LOSS [training: 0.13257358766118063 | validation: 0.10679118241751014]
	TIME [epoch: 9.74 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08892332849966264		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.08892332849966264 | validation: 0.09529671014932363]
	TIME [epoch: 9.75 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10224971893312987		[learning rate: 0.00084641]
	Learning Rate: 0.000846406
	LOSS [training: 0.10224971893312987 | validation: 0.12181817478984497]
	TIME [epoch: 9.76 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1092758227643312		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.1092758227643312 | validation: 0.09114875271364482]
	TIME [epoch: 9.74 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08970972445192832		[learning rate: 0.00084231]
	Learning Rate: 0.000842313
	LOSS [training: 0.08970972445192832 | validation: 0.07397360268566147]
	TIME [epoch: 9.75 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0704842532035267		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.0704842532035267 | validation: 0.05437786721399514]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1122.pth
	Model improved!!!
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06106236693264534		[learning rate: 0.00083824]
	Learning Rate: 0.00083824
	LOSS [training: 0.06106236693264534 | validation: 0.06920100926857269]
	TIME [epoch: 9.74 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06909853220262704		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.06909853220262704 | validation: 0.07086814732048391]
	TIME [epoch: 9.74 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09553981903003952		[learning rate: 0.00083419]
	Learning Rate: 0.000834187
	LOSS [training: 0.09553981903003952 | validation: 0.10182959945027499]
	TIME [epoch: 9.76 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08857866154112204		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.08857866154112204 | validation: 0.09658665836334004]
	TIME [epoch: 9.74 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08654076446238423		[learning rate: 0.00083015]
	Learning Rate: 0.000830152
	LOSS [training: 0.08654076446238423 | validation: 0.07064714160751556]
	TIME [epoch: 9.74 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08106959882809872		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.08106959882809872 | validation: 0.08920244581218072]
	TIME [epoch: 9.75 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07821619507581459		[learning rate: 0.00082614]
	Learning Rate: 0.000826138
	LOSS [training: 0.07821619507581459 | validation: 0.08316105122779643]
	TIME [epoch: 9.74 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07926454580759608		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.07926454580759608 | validation: 0.08467715108418573]
	TIME [epoch: 9.73 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08132916572785157		[learning rate: 0.00082214]
	Learning Rate: 0.000822143
	LOSS [training: 0.08132916572785157 | validation: 0.11750469683373775]
	TIME [epoch: 9.75 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.084780676631345		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.084780676631345 | validation: 0.09179748043359112]
	TIME [epoch: 9.76 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08843995778821026		[learning rate: 0.00081817]
	Learning Rate: 0.000818167
	LOSS [training: 0.08843995778821026 | validation: 0.08846995859117898]
	TIME [epoch: 9.74 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08197087575492437		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.08197087575492437 | validation: 0.08348725890577334]
	TIME [epoch: 9.74 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09090343133453356		[learning rate: 0.00081421]
	Learning Rate: 0.000814211
	LOSS [training: 0.09090343133453356 | validation: 0.09087666089900587]
	TIME [epoch: 9.75 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09824082431546702		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.09824082431546702 | validation: 0.12006215512222838]
	TIME [epoch: 9.74 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10781026219631658		[learning rate: 0.00081027]
	Learning Rate: 0.000810273
	LOSS [training: 0.10781026219631658 | validation: 0.16634903487291297]
	TIME [epoch: 9.73 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1651209546350647		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.1651209546350647 | validation: 0.15742703986500703]
	TIME [epoch: 9.76 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10928572097664976		[learning rate: 0.00080636]
	Learning Rate: 0.000806355
	LOSS [training: 0.10928572097664976 | validation: 0.0990788592670311]
	TIME [epoch: 9.74 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09778036419301757		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.09778036419301757 | validation: 0.0903947567444401]
	TIME [epoch: 9.73 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09587277259923717		[learning rate: 0.00080246]
	Learning Rate: 0.000802456
	LOSS [training: 0.09587277259923717 | validation: 0.09539402631349997]
	TIME [epoch: 9.74 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08254496944065307		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.08254496944065307 | validation: 0.0858573834537916]
	TIME [epoch: 9.74 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08745860707884193		[learning rate: 0.00079858]
	Learning Rate: 0.000798575
	LOSS [training: 0.08745860707884193 | validation: 0.09186470571927022]
	TIME [epoch: 9.74 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08869631956964938		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.08869631956964938 | validation: 0.07767316233268129]
	TIME [epoch: 9.75 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0764852139392713		[learning rate: 0.00079471]
	Learning Rate: 0.000794713
	LOSS [training: 0.0764852139392713 | validation: 0.0727413097953158]
	TIME [epoch: 9.75 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09602569192604972		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.09602569192604972 | validation: 0.16641753350289978]
	TIME [epoch: 9.73 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13945479310500924		[learning rate: 0.00079087]
	Learning Rate: 0.00079087
	LOSS [training: 0.13945479310500924 | validation: 0.13427435183580572]
	TIME [epoch: 9.74 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10721126995347952		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.10721126995347952 | validation: 0.09744536365189374]
	TIME [epoch: 9.76 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08648148008873328		[learning rate: 0.00078705]
	Learning Rate: 0.000787046
	LOSS [training: 0.08648148008873328 | validation: 0.11607458097660116]
	TIME [epoch: 9.75 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09226161760539044		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.09226161760539044 | validation: 0.0936875355849725]
	TIME [epoch: 9.73 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0938154615516092		[learning rate: 0.00078324]
	Learning Rate: 0.00078324
	LOSS [training: 0.0938154615516092 | validation: 0.09697428062603596]
	TIME [epoch: 9.76 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09166100442832992		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.09166100442832992 | validation: 0.09118728204936424]
	TIME [epoch: 9.73 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1018972451434701		[learning rate: 0.00077945]
	Learning Rate: 0.000779452
	LOSS [training: 0.1018972451434701 | validation: 0.08626267382655702]
	TIME [epoch: 9.74 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09506446974191426		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.09506446974191426 | validation: 0.12476730156502559]
	TIME [epoch: 9.76 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1054509544645956		[learning rate: 0.00077568]
	Learning Rate: 0.000775683
	LOSS [training: 0.1054509544645956 | validation: 0.11531677492215384]
	TIME [epoch: 9.74 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10463869220569304		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.10463869220569304 | validation: 0.14706572730905462]
	TIME [epoch: 9.75 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14166294056431586		[learning rate: 0.00077193]
	Learning Rate: 0.000771932
	LOSS [training: 0.14166294056431586 | validation: 0.20974317603368278]
	TIME [epoch: 9.74 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15229097500809152		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.15229097500809152 | validation: 0.1597261399948059]
	TIME [epoch: 9.74 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12862398478768972		[learning rate: 0.0007682]
	Learning Rate: 0.000768199
	LOSS [training: 0.12862398478768972 | validation: 0.13500490465888967]
	TIME [epoch: 9.75 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11612541773590775		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.11612541773590775 | validation: 0.14267344440092278]
	TIME [epoch: 9.73 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11448566619430425		[learning rate: 0.00076448]
	Learning Rate: 0.000764484
	LOSS [training: 0.11448566619430425 | validation: 0.1086527856855839]
	TIME [epoch: 9.75 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11198282217150765		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.11198282217150765 | validation: 0.11109538545116633]
	TIME [epoch: 9.74 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11744035017405385		[learning rate: 0.00076079]
	Learning Rate: 0.000760787
	LOSS [training: 0.11744035017405385 | validation: 0.12128039976072126]
	TIME [epoch: 9.74 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11028682056223801		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.11028682056223801 | validation: 0.12239466431867879]
	TIME [epoch: 9.76 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11975934828010379		[learning rate: 0.00075711]
	Learning Rate: 0.000757108
	LOSS [training: 0.11975934828010379 | validation: 0.10923225184261526]
	TIME [epoch: 9.73 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11432289519187928		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.11432289519187928 | validation: 0.1011976378015836]
	TIME [epoch: 9.73 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10648528632511485		[learning rate: 0.00075345]
	Learning Rate: 0.000753447
	LOSS [training: 0.10648528632511485 | validation: 0.1115602512407326]
	TIME [epoch: 9.74 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15503785081783514		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.15503785081783514 | validation: 0.19614146624073686]
	TIME [epoch: 9.74 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1885374402617727		[learning rate: 0.0007498]
	Learning Rate: 0.000749803
	LOSS [training: 0.1885374402617727 | validation: 0.1809888011862695]
	TIME [epoch: 9.74 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16466559282184712		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.16466559282184712 | validation: 0.156095066158436]
	TIME [epoch: 9.74 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14277581229478456		[learning rate: 0.00074618]
	Learning Rate: 0.000746177
	LOSS [training: 0.14277581229478456 | validation: 0.11445664566688785]
	TIME [epoch: 9.75 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12263296055552524		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.12263296055552524 | validation: 0.11033721224983556]
	TIME [epoch: 9.74 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.121480995872661		[learning rate: 0.00074257]
	Learning Rate: 0.000742569
	LOSS [training: 0.121480995872661 | validation: 0.12522367529620418]
	TIME [epoch: 9.74 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12362608069265775		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.12362608069265775 | validation: 0.09991576689983578]
	TIME [epoch: 9.76 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11028369139383556		[learning rate: 0.00073898]
	Learning Rate: 0.000738978
	LOSS [training: 0.11028369139383556 | validation: 0.09458852441637877]
	TIME [epoch: 9.73 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10827678292648127		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.10827678292648127 | validation: 0.10005903753410408]
	TIME [epoch: 9.73 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10691767125164413		[learning rate: 0.0007354]
	Learning Rate: 0.000735405
	LOSS [training: 0.10691767125164413 | validation: 0.11577276044366155]
	TIME [epoch: 9.74 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11385161460479262		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.11385161460479262 | validation: 0.1298088420433017]
	TIME [epoch: 9.74 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12012954143137415		[learning rate: 0.00073185]
	Learning Rate: 0.000731848
	LOSS [training: 0.12012954143137415 | validation: 0.10263720296948715]
	TIME [epoch: 9.73 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11533652444990836		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.11533652444990836 | validation: 0.13629044131528809]
	TIME [epoch: 9.75 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13924501852257168		[learning rate: 0.00072831]
	Learning Rate: 0.000728309
	LOSS [training: 0.13924501852257168 | validation: 0.11480391075141615]
	TIME [epoch: 9.74 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12474527539553552		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.12474527539553552 | validation: 0.1640201103797427]
	TIME [epoch: 9.71 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12149832657545057		[learning rate: 0.00072479]
	Learning Rate: 0.000724787
	LOSS [training: 0.12149832657545057 | validation: 0.10815568666898248]
	TIME [epoch: 9.73 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10226908917911423		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.10226908917911423 | validation: 0.1107051663908542]
	TIME [epoch: 9.74 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09472198822047666		[learning rate: 0.00072128]
	Learning Rate: 0.000721282
	LOSS [training: 0.09472198822047666 | validation: 0.09522934042392742]
	TIME [epoch: 9.73 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08997631412866182		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.08997631412866182 | validation: 0.08041232396782196]
	TIME [epoch: 9.73 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09794957762413543		[learning rate: 0.00071779]
	Learning Rate: 0.000717794
	LOSS [training: 0.09794957762413543 | validation: 0.09374143163631896]
	TIME [epoch: 9.75 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09359358756546643		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.09359358756546643 | validation: 0.0848205146212808]
	TIME [epoch: 9.74 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11282508244569392		[learning rate: 0.00071432]
	Learning Rate: 0.000714323
	LOSS [training: 0.11282508244569392 | validation: 0.11830167820134524]
	TIME [epoch: 9.74 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09505387750721943		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.09505387750721943 | validation: 0.07534392653562565]
	TIME [epoch: 9.75 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07428198925446902		[learning rate: 0.00071087]
	Learning Rate: 0.000710869
	LOSS [training: 0.07428198925446902 | validation: 0.07684059790246993]
	TIME [epoch: 9.72 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07389617637433334		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.07389617637433334 | validation: 0.07417660581386885]
	TIME [epoch: 9.73 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07257034960876554		[learning rate: 0.00070743]
	Learning Rate: 0.000707431
	LOSS [training: 0.07257034960876554 | validation: 0.07884620549501756]
	TIME [epoch: 9.74 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06692471797535418		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.06692471797535418 | validation: 0.07956287916218273]
	TIME [epoch: 9.74 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07713301141203921		[learning rate: 0.00070401]
	Learning Rate: 0.00070401
	LOSS [training: 0.07713301141203921 | validation: 0.07823933607923393]
	TIME [epoch: 9.74 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07344152060600626		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.07344152060600626 | validation: 0.06917695034930026]
	TIME [epoch: 9.74 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08597360034390958		[learning rate: 0.00070061]
	Learning Rate: 0.000700606
	LOSS [training: 0.08597360034390958 | validation: 0.08778702232674535]
	TIME [epoch: 9.73 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09408943673902415		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.09408943673902415 | validation: 0.10061449033675005]
	TIME [epoch: 9.73 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10429047278737313		[learning rate: 0.00069722]
	Learning Rate: 0.000697218
	LOSS [training: 0.10429047278737313 | validation: 0.09114060932419843]
	TIME [epoch: 9.73 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09363918801954788		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.09363918801954788 | validation: 0.09135539590094376]
	TIME [epoch: 9.75 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07880488065142528		[learning rate: 0.00069385]
	Learning Rate: 0.000693846
	LOSS [training: 0.07880488065142528 | validation: 0.07762448965832695]
	TIME [epoch: 9.73 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08464462874329486		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.08464462874329486 | validation: 0.09347586865874612]
	TIME [epoch: 9.73 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08580829681035364		[learning rate: 0.00069049]
	Learning Rate: 0.000690491
	LOSS [training: 0.08580829681035364 | validation: 0.09402495737610837]
	TIME [epoch: 9.74 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0798608137467388		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.0798608137467388 | validation: 0.12145942679203092]
	TIME [epoch: 9.73 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10301715057829663		[learning rate: 0.00068715]
	Learning Rate: 0.000687152
	LOSS [training: 0.10301715057829663 | validation: 0.1302304050801507]
	TIME [epoch: 9.72 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.151969441028201		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.151969441028201 | validation: 0.16513559979947687]
	TIME [epoch: 9.73 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15719974616905533		[learning rate: 0.00068383]
	Learning Rate: 0.000683829
	LOSS [training: 0.15719974616905533 | validation: 0.12696918471886645]
	TIME [epoch: 9.72 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14589453848522424		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.14589453848522424 | validation: 0.10703928984793565]
	TIME [epoch: 9.72 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11800996815428695		[learning rate: 0.00068052]
	Learning Rate: 0.000680522
	LOSS [training: 0.11800996815428695 | validation: 0.09608985263387036]
	TIME [epoch: 9.74 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0972644357570707		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.0972644357570707 | validation: 0.08640539090362916]
	TIME [epoch: 9.75 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08323235695999266		[learning rate: 0.00067723]
	Learning Rate: 0.000677231
	LOSS [training: 0.08323235695999266 | validation: 0.10377449249743836]
	TIME [epoch: 9.74 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09317801337612233		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.09317801337612233 | validation: 0.10406198625991767]
	TIME [epoch: 9.73 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09469532744711348		[learning rate: 0.00067396]
	Learning Rate: 0.000673956
	LOSS [training: 0.09469532744711348 | validation: 0.08816347172765233]
	TIME [epoch: 9.75 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0960264091812921		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.0960264091812921 | validation: 0.11483315576375054]
	TIME [epoch: 9.74 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10115464317565406		[learning rate: 0.0006707]
	Learning Rate: 0.000670697
	LOSS [training: 0.10115464317565406 | validation: 0.10021764122110152]
	TIME [epoch: 9.73 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11028750366453195		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.11028750366453195 | validation: 0.11735668604699477]
	TIME [epoch: 9.75 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11594038308580237		[learning rate: 0.00066745]
	Learning Rate: 0.000667454
	LOSS [training: 0.11594038308580237 | validation: 0.12192674774602129]
	TIME [epoch: 9.73 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10941538539949672		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.10941538539949672 | validation: 0.13746402129995786]
	TIME [epoch: 9.74 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12737813568233555		[learning rate: 0.00066423]
	Learning Rate: 0.000664226
	LOSS [training: 0.12737813568233555 | validation: 0.15177692786913316]
	TIME [epoch: 9.74 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12553411335463596		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.12553411335463596 | validation: 0.13919780328445344]
	TIME [epoch: 9.73 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12805246043664847		[learning rate: 0.00066101]
	Learning Rate: 0.000661014
	LOSS [training: 0.12805246043664847 | validation: 0.1748620457342208]
	TIME [epoch: 9.73 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17124815325457238		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.17124815325457238 | validation: 0.15946533893663886]
	TIME [epoch: 9.75 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14274053511669282		[learning rate: 0.00065782]
	Learning Rate: 0.000657817
	LOSS [training: 0.14274053511669282 | validation: 0.20906445196429993]
	TIME [epoch: 9.74 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19399198965540143		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.19399198965540143 | validation: 0.20198774283277118]
	TIME [epoch: 9.73 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13074519669493706		[learning rate: 0.00065464]
	Learning Rate: 0.000654636
	LOSS [training: 0.13074519669493706 | validation: 0.12969570473745862]
	TIME [epoch: 9.73 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11537554653453694		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.11537554653453694 | validation: 0.1098761461550531]
	TIME [epoch: 9.75 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0965987429445595		[learning rate: 0.00065147]
	Learning Rate: 0.000651471
	LOSS [training: 0.0965987429445595 | validation: 0.10589251593707884]
	TIME [epoch: 9.73 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12022747274883869		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.12022747274883869 | validation: 0.1360589652751878]
	TIME [epoch: 9.74 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10684510026299676		[learning rate: 0.00064832]
	Learning Rate: 0.00064832
	LOSS [training: 0.10684510026299676 | validation: 0.0900166773523436]
	TIME [epoch: 9.75 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09687012283095968		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.09687012283095968 | validation: 0.09709392978698234]
	TIME [epoch: 9.74 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11936391308096943		[learning rate: 0.00064519]
	Learning Rate: 0.000645185
	LOSS [training: 0.11936391308096943 | validation: 0.1468404496274793]
	TIME [epoch: 9.73 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13733983002630798		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.13733983002630798 | validation: 0.1495815467572958]
	TIME [epoch: 9.75 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12637760713974228		[learning rate: 0.00064206]
	Learning Rate: 0.000642065
	LOSS [training: 0.12637760713974228 | validation: 0.14092762575983386]
	TIME [epoch: 9.73 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11512707267674263		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.11512707267674263 | validation: 0.10923699284908846]
	TIME [epoch: 9.75 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1012485496663229		[learning rate: 0.00063896]
	Learning Rate: 0.00063896
	LOSS [training: 0.1012485496663229 | validation: 0.0982373621579789]
	TIME [epoch: 9.74 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10322107113938357		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.10322107113938357 | validation: 0.12498439629176641]
	TIME [epoch: 9.74 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1304358822991238		[learning rate: 0.00063587]
	Learning Rate: 0.00063587
	LOSS [training: 0.1304358822991238 | validation: 0.203189575756818]
	TIME [epoch: 9.74 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1712626952924371		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.1712626952924371 | validation: 0.17148468728783267]
	TIME [epoch: 9.73 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15022131625954388		[learning rate: 0.0006328]
	Learning Rate: 0.000632795
	LOSS [training: 0.15022131625954388 | validation: 0.20354376847914182]
	TIME [epoch: 9.75 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2005061452409076		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.2005061452409076 | validation: 0.3246903347288307]
	TIME [epoch: 9.73 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26177042565517006		[learning rate: 0.00062974]
	Learning Rate: 0.000629735
	LOSS [training: 0.26177042565517006 | validation: 0.2704598168587474]
	TIME [epoch: 9.73 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2297628272223454		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.2297628272223454 | validation: 0.3261325274833058]
	TIME [epoch: 9.74 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2641120782109394		[learning rate: 0.00062669]
	Learning Rate: 0.00062669
	LOSS [training: 0.2641120782109394 | validation: 0.30408661228667827]
	TIME [epoch: 9.73 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19611890559856054		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.19611890559856054 | validation: 0.1415856675923463]
	TIME [epoch: 9.73 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11966213284653397		[learning rate: 0.00062366]
	Learning Rate: 0.000623659
	LOSS [training: 0.11966213284653397 | validation: 0.11987394196193316]
	TIME [epoch: 9.75 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10262281365020157		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.10262281365020157 | validation: 0.09422776797593241]
	TIME [epoch: 9.73 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09726510341880053		[learning rate: 0.00062064]
	Learning Rate: 0.000620643
	LOSS [training: 0.09726510341880053 | validation: 0.09549909356462619]
	TIME [epoch: 9.74 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10646788773838634		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.10646788773838634 | validation: 0.11680571770584912]
	TIME [epoch: 9.73 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10967915655823743		[learning rate: 0.00061764]
	Learning Rate: 0.000617642
	LOSS [training: 0.10967915655823743 | validation: 0.11471426433845963]
	TIME [epoch: 9.74 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13286079958648067		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.13286079958648067 | validation: 0.18682146006592487]
	TIME [epoch: 9.72 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17331733692061418		[learning rate: 0.00061466]
	Learning Rate: 0.000614655
	LOSS [training: 0.17331733692061418 | validation: 0.25552584323853417]
	TIME [epoch: 9.73 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17338259753973334		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.17338259753973334 | validation: 0.1770707971061394]
	TIME [epoch: 9.76 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13813498587859868		[learning rate: 0.00061168]
	Learning Rate: 0.000611683
	LOSS [training: 0.13813498587859868 | validation: 0.12105932478048988]
	TIME [epoch: 9.74 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11760272040027431		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.11760272040027431 | validation: 0.09301978378400494]
	TIME [epoch: 9.73 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11306074314248304		[learning rate: 0.00060872]
	Learning Rate: 0.000608725
	LOSS [training: 0.11306074314248304 | validation: 0.15986253809169534]
	TIME [epoch: 9.74 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17107845060807716		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.17107845060807716 | validation: 0.26994117970530296]
	TIME [epoch: 9.73 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2209465749399966		[learning rate: 0.00060578]
	Learning Rate: 0.000605781
	LOSS [training: 0.2209465749399966 | validation: 0.19319100417506932]
	TIME [epoch: 9.73 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15752777880003338		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.15752777880003338 | validation: 0.19290278706987743]
	TIME [epoch: 9.75 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.200123905402133		[learning rate: 0.00060285]
	Learning Rate: 0.000602852
	LOSS [training: 0.200123905402133 | validation: 0.3044827522887588]
	TIME [epoch: 9.73 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26510313193107354		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.26510313193107354 | validation: 0.297015035783651]
	TIME [epoch: 9.73 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21423711567139173		[learning rate: 0.00059994]
	Learning Rate: 0.000599936
	LOSS [training: 0.21423711567139173 | validation: 0.24389680641691883]
	TIME [epoch: 9.74 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19957389496283073		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.19957389496283073 | validation: 0.2469878764134289]
	TIME [epoch: 9.75 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21555327905123073		[learning rate: 0.00059704]
	Learning Rate: 0.000597035
	LOSS [training: 0.21555327905123073 | validation: 0.24160307909748724]
	TIME [epoch: 9.73 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1802680031154468		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.1802680031154468 | validation: 0.25744739081096]
	TIME [epoch: 9.73 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2127402960900048		[learning rate: 0.00059415]
	Learning Rate: 0.000594148
	LOSS [training: 0.2127402960900048 | validation: 0.19128098765318174]
	TIME [epoch: 9.75 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14641196911307713		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.14641196911307713 | validation: 0.13257162851370058]
	TIME [epoch: 9.74 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12319943010030814		[learning rate: 0.00059128]
	Learning Rate: 0.000591275
	LOSS [training: 0.12319943010030814 | validation: 0.14328200489728135]
	TIME [epoch: 9.73 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11798243569033247		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.11798243569033247 | validation: 0.10682076153680957]
	TIME [epoch: 9.76 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1393037208964803		[learning rate: 0.00058842]
	Learning Rate: 0.000588416
	LOSS [training: 0.1393037208964803 | validation: 0.19995239393245506]
	TIME [epoch: 9.74 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1396557125214235		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.1396557125214235 | validation: 0.10613790374728867]
	TIME [epoch: 9.74 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11016309975819212		[learning rate: 0.00058557]
	Learning Rate: 0.00058557
	LOSS [training: 0.11016309975819212 | validation: 0.11763468763531919]
	TIME [epoch: 9.75 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12907510580080872		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.12907510580080872 | validation: 0.11432826167412667]
	TIME [epoch: 9.74 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11207196814620235		[learning rate: 0.00058274]
	Learning Rate: 0.000582738
	LOSS [training: 0.11207196814620235 | validation: 0.10808859729785858]
	TIME [epoch: 9.73 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09980828549664382		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.09980828549664382 | validation: 0.12173783972340604]
	TIME [epoch: 9.74 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1071145547368397		[learning rate: 0.00057992]
	Learning Rate: 0.00057992
	LOSS [training: 0.1071145547368397 | validation: 0.14889547981910434]
	TIME [epoch: 9.75 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11284262289227928		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.11284262289227928 | validation: 0.11213293448937642]
	TIME [epoch: 9.75 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10230908770866806		[learning rate: 0.00057712]
	Learning Rate: 0.000577116
	LOSS [training: 0.10230908770866806 | validation: 0.11430607524000301]
	TIME [epoch: 9.73 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10306405666325147		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.10306405666325147 | validation: 0.10934761236017825]
	TIME [epoch: 9.75 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09880703372168394		[learning rate: 0.00057433]
	Learning Rate: 0.000574325
	LOSS [training: 0.09880703372168394 | validation: 0.10737323635091148]
	TIME [epoch: 9.74 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09623477574095966		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.09623477574095966 | validation: 0.09635317337782054]
	TIME [epoch: 9.74 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1051991996498454		[learning rate: 0.00057155]
	Learning Rate: 0.000571548
	LOSS [training: 0.1051991996498454 | validation: 0.09803446741437971]
	TIME [epoch: 9.75 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10330657232827807		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.10330657232827807 | validation: 0.09189932844706127]
	TIME [epoch: 9.74 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09605780335156375		[learning rate: 0.00056878]
	Learning Rate: 0.000568784
	LOSS [training: 0.09605780335156375 | validation: 0.09595654500218792]
	TIME [epoch: 9.74 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.096098656132961		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.096098656132961 | validation: 0.09483255286768069]
	TIME [epoch: 9.75 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09374886524231976		[learning rate: 0.00056603]
	Learning Rate: 0.000566033
	LOSS [training: 0.09374886524231976 | validation: 0.10228151647714788]
	TIME [epoch: 9.74 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0986253984977651		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.0986253984977651 | validation: 0.10761411523449764]
	TIME [epoch: 9.73 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10481147373897773		[learning rate: 0.0005633]
	Learning Rate: 0.000563296
	LOSS [training: 0.10481147373897773 | validation: 0.09952519329489384]
	TIME [epoch: 9.73 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1045570515363951		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.1045570515363951 | validation: 0.10850855842577188]
	TIME [epoch: 9.75 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11560070256152499		[learning rate: 0.00056057]
	Learning Rate: 0.000560572
	LOSS [training: 0.11560070256152499 | validation: 0.11905995078754308]
	TIME [epoch: 9.73 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10045433723111455		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.10045433723111455 | validation: 0.10129500117205115]
	TIME [epoch: 9.74 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1035235409830038		[learning rate: 0.00055786]
	Learning Rate: 0.000557861
	LOSS [training: 0.1035235409830038 | validation: 0.10114315222846491]
	TIME [epoch: 9.76 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09785433698831122		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.09785433698831122 | validation: 0.10683050674686424]
	TIME [epoch: 9.75 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10309427081360423		[learning rate: 0.00055516]
	Learning Rate: 0.000555164
	LOSS [training: 0.10309427081360423 | validation: 0.09156551398417662]
	TIME [epoch: 9.72 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10307708997701284		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.10307708997701284 | validation: 0.17330659202211066]
	TIME [epoch: 9.74 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12892508056986335		[learning rate: 0.00055248]
	Learning Rate: 0.000552479
	LOSS [training: 0.12892508056986335 | validation: 0.13399515495380626]
	TIME [epoch: 9.73 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10665593174982801		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.10665593174982801 | validation: 0.11563557958183719]
	TIME [epoch: 9.73 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10679353228742867		[learning rate: 0.00054981]
	Learning Rate: 0.000549807
	LOSS [training: 0.10679353228742867 | validation: 0.10678718901405092]
	TIME [epoch: 9.76 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10475692785651555		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.10475692785651555 | validation: 0.10432966622660846]
	TIME [epoch: 9.74 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10381251264407995		[learning rate: 0.00054715]
	Learning Rate: 0.000547149
	LOSS [training: 0.10381251264407995 | validation: 0.1035110952639477]
	TIME [epoch: 9.74 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09710383423377575		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.09710383423377575 | validation: 0.09804986831583991]
	TIME [epoch: 9.75 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10556872074480268		[learning rate: 0.0005445]
	Learning Rate: 0.000544503
	LOSS [training: 0.10556872074480268 | validation: 0.0881361907852766]
	TIME [epoch: 9.75 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09869162706217756		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.09869162706217756 | validation: 0.11347289744281457]
	TIME [epoch: 9.73 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09846684007483139		[learning rate: 0.00054187]
	Learning Rate: 0.000541869
	LOSS [training: 0.09846684007483139 | validation: 0.09716609814376456]
	TIME [epoch: 9.74 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08760920424026916		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.08760920424026916 | validation: 0.06991031154201116]
	TIME [epoch: 9.75 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08579234017621393		[learning rate: 0.00053925]
	Learning Rate: 0.000539249
	LOSS [training: 0.08579234017621393 | validation: 0.09726294037374934]
	TIME [epoch: 9.74 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10026105779376535		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.10026105779376535 | validation: 0.09039551758219769]
	TIME [epoch: 9.73 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09603839730254411		[learning rate: 0.00053664]
	Learning Rate: 0.000536641
	LOSS [training: 0.09603839730254411 | validation: 0.090408589624757]
	TIME [epoch: 9.75 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08291002206627371		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.08291002206627371 | validation: 0.09133498538781364]
	TIME [epoch: 9.74 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08536319940856743		[learning rate: 0.00053405]
	Learning Rate: 0.000534046
	LOSS [training: 0.08536319940856743 | validation: 0.08349300285038552]
	TIME [epoch: 9.73 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08399198614038342		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.08399198614038342 | validation: 0.08907922981127403]
	TIME [epoch: 9.75 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08224004623467361		[learning rate: 0.00053146]
	Learning Rate: 0.000531464
	LOSS [training: 0.08224004623467361 | validation: 0.07350381349592618]
	TIME [epoch: 9.74 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08741115324025321		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.08741115324025321 | validation: 0.10101888599945678]
	TIME [epoch: 9.73 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09180710895002617		[learning rate: 0.00052889]
	Learning Rate: 0.000528894
	LOSS [training: 0.09180710895002617 | validation: 0.08159472337735768]
	TIME [epoch: 9.73 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09173595160561981		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.09173595160561981 | validation: 0.11544502775094202]
	TIME [epoch: 9.75 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09768028448984109		[learning rate: 0.00052634]
	Learning Rate: 0.000526336
	LOSS [training: 0.09768028448984109 | validation: 0.09777634247102392]
	TIME [epoch: 9.74 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08892920873262289		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.08892920873262289 | validation: 0.09118382590802282]
	TIME [epoch: 9.73 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08665706890393894		[learning rate: 0.00052379]
	Learning Rate: 0.000523791
	LOSS [training: 0.08665706890393894 | validation: 0.08684581872112772]
	TIME [epoch: 9.76 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08233071843300975		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.08233071843300975 | validation: 0.08700331151293171]
	TIME [epoch: 9.73 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08365362226091269		[learning rate: 0.00052126]
	Learning Rate: 0.000521258
	LOSS [training: 0.08365362226091269 | validation: 0.0873965264121167]
	TIME [epoch: 9.73 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0809595114758109		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.0809595114758109 | validation: 0.07803385856051326]
	TIME [epoch: 9.76 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07706059793525968		[learning rate: 0.00051874]
	Learning Rate: 0.000518737
	LOSS [training: 0.07706059793525968 | validation: 0.08494189656356756]
	TIME [epoch: 9.73 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0929111616082275		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.0929111616082275 | validation: 0.11688309455112955]
	TIME [epoch: 9.73 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09407969432882723		[learning rate: 0.00051623]
	Learning Rate: 0.000516229
	LOSS [training: 0.09407969432882723 | validation: 0.09839559890989229]
	TIME [epoch: 9.76 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08654862848737752		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.08654862848737752 | validation: 0.08875584421399253]
	TIME [epoch: 9.74 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0846822712343672		[learning rate: 0.00051373]
	Learning Rate: 0.000513732
	LOSS [training: 0.0846822712343672 | validation: 0.08414124337024699]
	TIME [epoch: 9.73 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08317108280003471		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.08317108280003471 | validation: 0.08577835915278538]
	TIME [epoch: 9.74 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0806042242692819		[learning rate: 0.00051125]
	Learning Rate: 0.000511248
	LOSS [training: 0.0806042242692819 | validation: 0.0979913987496732]
	TIME [epoch: 9.74 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0812579534060714		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.0812579534060714 | validation: 0.07925871004695992]
	TIME [epoch: 9.73 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08827592982608799		[learning rate: 0.00050878]
	Learning Rate: 0.000508776
	LOSS [training: 0.08827592982608799 | validation: 0.09181219751828437]
	TIME [epoch: 9.75 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09561929049588615		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.09561929049588615 | validation: 0.11244389859976098]
	TIME [epoch: 9.77 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09387725016501855		[learning rate: 0.00050632]
	Learning Rate: 0.000506315
	LOSS [training: 0.09387725016501855 | validation: 0.09306627103338727]
	TIME [epoch: 9.73 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08621729515754675		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.08621729515754675 | validation: 0.09232658815483895]
	TIME [epoch: 9.73 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09201484292712862		[learning rate: 0.00050387]
	Learning Rate: 0.000503867
	LOSS [training: 0.09201484292712862 | validation: 0.07867707025335843]
	TIME [epoch: 9.76 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07923088324130004		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.07923088324130004 | validation: 0.08658613474030229]
	TIME [epoch: 9.74 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07785900337287725		[learning rate: 0.00050143]
	Learning Rate: 0.00050143
	LOSS [training: 0.07785900337287725 | validation: 0.07861640169922947]
	TIME [epoch: 9.75 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07216886560925607		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.07216886560925607 | validation: 0.08933540017852484]
	TIME [epoch: 9.75 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08260517095348044		[learning rate: 0.00049901]
	Learning Rate: 0.000499005
	LOSS [training: 0.08260517095348044 | validation: 0.09094213993611674]
	TIME [epoch: 9.75 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08079229834453931		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.08079229834453931 | validation: 0.09525525747207429]
	TIME [epoch: 9.74 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07882414972633553		[learning rate: 0.00049659]
	Learning Rate: 0.000496592
	LOSS [training: 0.07882414972633553 | validation: 0.10072059517368546]
	TIME [epoch: 9.74 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08351232760817415		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.08351232760817415 | validation: 0.07530962996226906]
	TIME [epoch: 9.76 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07871724958155787		[learning rate: 0.00049419]
	Learning Rate: 0.000494191
	LOSS [training: 0.07871724958155787 | validation: 0.0896237036319134]
	TIME [epoch: 9.74 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07842231380657656		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.07842231380657656 | validation: 0.08123996800127337]
	TIME [epoch: 9.73 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0803794603678756		[learning rate: 0.0004918]
	Learning Rate: 0.000491801
	LOSS [training: 0.0803794603678756 | validation: 0.0775167969916439]
	TIME [epoch: 9.77 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08430207034548898		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.08430207034548898 | validation: 0.10012242227937364]
	TIME [epoch: 9.75 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08587570661010643		[learning rate: 0.00048942]
	Learning Rate: 0.000489423
	LOSS [training: 0.08587570661010643 | validation: 0.08321274059213994]
	TIME [epoch: 9.74 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08534257930553783		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.08534257930553783 | validation: 0.11918663263912298]
	TIME [epoch: 9.75 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07777606887018514		[learning rate: 0.00048706]
	Learning Rate: 0.000487056
	LOSS [training: 0.07777606887018514 | validation: 0.11321965248267407]
	TIME [epoch: 9.74 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09632890713527796		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.09632890713527796 | validation: 0.10330412237601781]
	TIME [epoch: 9.74 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08734897234952463		[learning rate: 0.0004847]
	Learning Rate: 0.000484701
	LOSS [training: 0.08734897234952463 | validation: 0.09626419295102931]
	TIME [epoch: 9.76 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09725108862910334		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.09725108862910334 | validation: 0.0916296369543547]
	TIME [epoch: 9.74 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08846080970883519		[learning rate: 0.00048236]
	Learning Rate: 0.000482357
	LOSS [training: 0.08846080970883519 | validation: 0.06803065620165943]
	TIME [epoch: 9.74 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08207092616791656		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.08207092616791656 | validation: 0.074607474955214]
	TIME [epoch: 9.74 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08148546320027159		[learning rate: 0.00048002]
	Learning Rate: 0.000480024
	LOSS [training: 0.08148546320027159 | validation: 0.08097956402295836]
	TIME [epoch: 9.75 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06989191775868359		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.06989191775868359 | validation: 0.08306647196677666]
	TIME [epoch: 9.75 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08256648084497219		[learning rate: 0.0004777]
	Learning Rate: 0.000477703
	LOSS [training: 0.08256648084497219 | validation: 0.0905523302277717]
	TIME [epoch: 9.74 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0939566516606019		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.0939566516606019 | validation: 0.11376611217049981]
	TIME [epoch: 9.76 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0861866521928942		[learning rate: 0.00047539]
	Learning Rate: 0.000475393
	LOSS [training: 0.0861866521928942 | validation: 0.07124436120343491]
	TIME [epoch: 9.74 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07364533076426844		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.07364533076426844 | validation: 0.08706249295399238]
	TIME [epoch: 9.73 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08073150275641942		[learning rate: 0.00047309]
	Learning Rate: 0.000473094
	LOSS [training: 0.08073150275641942 | validation: 0.07993391991944754]
	TIME [epoch: 9.76 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0802176707953888		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.0802176707953888 | validation: 0.08220292203880795]
	TIME [epoch: 9.73 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08448221434283018		[learning rate: 0.00047081]
	Learning Rate: 0.000470806
	LOSS [training: 0.08448221434283018 | validation: 0.08199540316347516]
	TIME [epoch: 9.73 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0769279027039343		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.0769279027039343 | validation: 0.07081736871796253]
	TIME [epoch: 9.76 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07804374020815823		[learning rate: 0.00046853]
	Learning Rate: 0.000468529
	LOSS [training: 0.07804374020815823 | validation: 0.073528582846326]
	TIME [epoch: 9.75 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08010373366649416		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.08010373366649416 | validation: 0.061252001687794703]
	TIME [epoch: 9.74 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06962288792141348		[learning rate: 0.00046626]
	Learning Rate: 0.000466264
	LOSS [training: 0.06962288792141348 | validation: 0.06333266863470483]
	TIME [epoch: 9.75 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07483341384033962		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.07483341384033962 | validation: 0.07930337487481527]
	TIME [epoch: 9.76 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07471651344471557		[learning rate: 0.00046401]
	Learning Rate: 0.000464009
	LOSS [training: 0.07471651344471557 | validation: 0.06643246070250833]
	TIME [epoch: 9.75 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07013860506281215		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.07013860506281215 | validation: 0.0724587623239614]
	TIME [epoch: 9.75 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07320008248342218		[learning rate: 0.00046177]
	Learning Rate: 0.000461765
	LOSS [training: 0.07320008248342218 | validation: 0.06587721263803296]
	TIME [epoch: 9.76 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06821146404371706		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.06821146404371706 | validation: 0.06306593399349616]
	TIME [epoch: 9.74 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05775438422114		[learning rate: 0.00045953]
	Learning Rate: 0.000459532
	LOSS [training: 0.05775438422114 | validation: 0.06720260611462957]
	TIME [epoch: 9.74 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060822135513409835		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.060822135513409835 | validation: 0.06700483279636163]
	TIME [epoch: 9.76 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06271893649445967		[learning rate: 0.00045731]
	Learning Rate: 0.00045731
	LOSS [training: 0.06271893649445967 | validation: 0.06525006228834208]
	TIME [epoch: 9.74 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06452097011743581		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.06452097011743581 | validation: 0.054013380911100625]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1374.pth
	Model improved!!!
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05848154567784948		[learning rate: 0.0004551]
	Learning Rate: 0.000455098
	LOSS [training: 0.05848154567784948 | validation: 0.053954636630914744]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1375.pth
	Model improved!!!
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06692704133851735		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.06692704133851735 | validation: 0.05994721842719864]
	TIME [epoch: 9.75 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06938784020463655		[learning rate: 0.0004529]
	Learning Rate: 0.000452898
	LOSS [training: 0.06938784020463655 | validation: 0.0646737950884584]
	TIME [epoch: 9.75 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0786441267980574		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.0786441267980574 | validation: 0.07092664846543797]
	TIME [epoch: 9.76 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06739974160332007		[learning rate: 0.00045071]
	Learning Rate: 0.000450708
	LOSS [training: 0.06739974160332007 | validation: 0.07342004573215473]
	TIME [epoch: 9.74 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05902976987313772		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.05902976987313772 | validation: 0.06725445055165623]
	TIME [epoch: 9.75 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05939088065133445		[learning rate: 0.00044853]
	Learning Rate: 0.000448528
	LOSS [training: 0.05939088065133445 | validation: 0.04700560285734895]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1381.pth
	Model improved!!!
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054624954341496855		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.054624954341496855 | validation: 0.060602025725412643]
	TIME [epoch: 9.77 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056429851186142466		[learning rate: 0.00044636]
	Learning Rate: 0.000446359
	LOSS [training: 0.056429851186142466 | validation: 0.0683005816412005]
	TIME [epoch: 9.75 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05623398730452008		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.05623398730452008 | validation: 0.053124668550573295]
	TIME [epoch: 9.74 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05261108862028807		[learning rate: 0.0004442]
	Learning Rate: 0.0004442
	LOSS [training: 0.05261108862028807 | validation: 0.05874630348175927]
	TIME [epoch: 9.77 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04930387745085756		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.04930387745085756 | validation: 0.05321153209140965]
	TIME [epoch: 9.75 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04797269553409939		[learning rate: 0.00044205]
	Learning Rate: 0.000442052
	LOSS [training: 0.04797269553409939 | validation: 0.05136709257700588]
	TIME [epoch: 9.75 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060426175335522136		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.060426175335522136 | validation: 0.05722891817223325]
	TIME [epoch: 9.77 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05384180040451488		[learning rate: 0.00043991]
	Learning Rate: 0.000439915
	LOSS [training: 0.05384180040451488 | validation: 0.059381642902156175]
	TIME [epoch: 9.74 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05208398799983745		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.05208398799983745 | validation: 0.0497071996003724]
	TIME [epoch: 9.74 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0574104843542956		[learning rate: 0.00043779]
	Learning Rate: 0.000437787
	LOSS [training: 0.0574104843542956 | validation: 0.04424766848670574]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1391.pth
	Model improved!!!
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055877925208111065		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.055877925208111065 | validation: 0.05152345762889386]
	TIME [epoch: 9.76 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059341999882517926		[learning rate: 0.00043567]
	Learning Rate: 0.00043567
	LOSS [training: 0.059341999882517926 | validation: 0.06283823376202642]
	TIME [epoch: 9.75 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05959358962377176		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.05959358962377176 | validation: 0.0646533559392605]
	TIME [epoch: 9.77 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05932885658215788		[learning rate: 0.00043356]
	Learning Rate: 0.000433563
	LOSS [training: 0.05932885658215788 | validation: 0.054041242666731375]
	TIME [epoch: 9.76 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06331504551134329		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.06331504551134329 | validation: 0.06278406420090585]
	TIME [epoch: 9.76 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057502155385881236		[learning rate: 0.00043147]
	Learning Rate: 0.000431467
	LOSS [training: 0.057502155385881236 | validation: 0.056995471276146466]
	TIME [epoch: 9.76 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06007526992378592		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.06007526992378592 | validation: 0.053536261441787955]
	TIME [epoch: 9.77 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05688204565880868		[learning rate: 0.00042938]
	Learning Rate: 0.00042938
	LOSS [training: 0.05688204565880868 | validation: 0.07126176789416556]
	TIME [epoch: 9.75 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07156939015692146		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.07156939015692146 | validation: 0.09145123491412363]
	TIME [epoch: 9.76 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07965811511648827		[learning rate: 0.0004273]
	Learning Rate: 0.000427304
	LOSS [training: 0.07965811511648827 | validation: 0.06635041060275336]
	TIME [epoch: 9.77 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060511461846567804		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.060511461846567804 | validation: 0.06433095567971982]
	TIME [epoch: 9.75 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06142702401078243		[learning rate: 0.00042524]
	Learning Rate: 0.000425238
	LOSS [training: 0.06142702401078243 | validation: 0.05440257005787724]
	TIME [epoch: 9.76 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056314035186588805		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.056314035186588805 | validation: 0.06892646863641046]
	TIME [epoch: 9.77 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059118814781442264		[learning rate: 0.00042318]
	Learning Rate: 0.000423181
	LOSS [training: 0.059118814781442264 | validation: 0.07108488657023872]
	TIME [epoch: 9.75 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06239825298866675		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.06239825298866675 | validation: 0.05232206361114988]
	TIME [epoch: 9.75 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058875156005830265		[learning rate: 0.00042113]
	Learning Rate: 0.000421135
	LOSS [training: 0.058875156005830265 | validation: 0.0509868374860775]
	TIME [epoch: 9.77 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05387853179018892		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.05387853179018892 | validation: 0.0596683975633912]
	TIME [epoch: 9.75 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056750420753320575		[learning rate: 0.0004191]
	Learning Rate: 0.000419098
	LOSS [training: 0.056750420753320575 | validation: 0.05745385616042891]
	TIME [epoch: 9.75 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06312952364356958		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.06312952364356958 | validation: 0.08088088181959599]
	TIME [epoch: 9.77 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08583572939483412		[learning rate: 0.00041707]
	Learning Rate: 0.000417072
	LOSS [training: 0.08583572939483412 | validation: 0.10540458567530026]
	TIME [epoch: 9.75 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07283405460291256		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.07283405460291256 | validation: 0.10372944826206601]
	TIME [epoch: 9.75 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09238878641219572		[learning rate: 0.00041505]
	Learning Rate: 0.000415055
	LOSS [training: 0.09238878641219572 | validation: 0.09479121887178472]
	TIME [epoch: 9.76 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08239704297405681		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.08239704297405681 | validation: 0.07818670881473258]
	TIME [epoch: 9.75 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07083631619286154		[learning rate: 0.00041305]
	Learning Rate: 0.000413048
	LOSS [training: 0.07083631619286154 | validation: 0.060248211788714964]
	TIME [epoch: 9.75 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06543920732375005		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.06543920732375005 | validation: 0.06118182565058417]
	TIME [epoch: 9.77 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0665034227962934		[learning rate: 0.00041105]
	Learning Rate: 0.00041105
	LOSS [training: 0.0665034227962934 | validation: 0.061480350602668765]
	TIME [epoch: 9.75 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06362311180820704		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.06362311180820704 | validation: 0.05591489220977251]
	TIME [epoch: 9.75 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06842676250352635		[learning rate: 0.00040906]
	Learning Rate: 0.000409062
	LOSS [training: 0.06842676250352635 | validation: 0.07360791479913675]
	TIME [epoch: 9.76 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0749245050658642		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.0749245050658642 | validation: 0.07152717345018926]
	TIME [epoch: 9.75 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06396628724028254		[learning rate: 0.00040708]
	Learning Rate: 0.000407084
	LOSS [training: 0.06396628724028254 | validation: 0.058265291663768884]
	TIME [epoch: 9.75 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06867552065440771		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.06867552065440771 | validation: 0.06143392950695144]
	TIME [epoch: 9.77 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06303430243896042		[learning rate: 0.00040512]
	Learning Rate: 0.000405116
	LOSS [training: 0.06303430243896042 | validation: 0.06513922287975762]
	TIME [epoch: 9.75 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.068669076902345		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.068669076902345 | validation: 0.07513102739835574]
	TIME [epoch: 9.75 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06881971667356804		[learning rate: 0.00040316]
	Learning Rate: 0.000403157
	LOSS [training: 0.06881971667356804 | validation: 0.07387676458386272]
	TIME [epoch: 9.76 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07168746066609095		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.07168746066609095 | validation: 0.06029449681577823]
	TIME [epoch: 9.75 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06988672093579298		[learning rate: 0.00040121]
	Learning Rate: 0.000401207
	LOSS [training: 0.06988672093579298 | validation: 0.0631689540010735]
	TIME [epoch: 9.76 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06286602362658116		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.06286602362658116 | validation: 0.051499525744233006]
	TIME [epoch: 9.77 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05075210333486328		[learning rate: 0.00039927]
	Learning Rate: 0.000399267
	LOSS [training: 0.05075210333486328 | validation: 0.05793961925843751]
	TIME [epoch: 9.75 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05415918786406171		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.05415918786406171 | validation: 0.06641205263072612]
	TIME [epoch: 9.75 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060660188358917844		[learning rate: 0.00039734]
	Learning Rate: 0.000397336
	LOSS [training: 0.060660188358917844 | validation: 0.05587590321428536]
	TIME [epoch: 9.77 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058257991976937096		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.058257991976937096 | validation: 0.0613258502051795]
	TIME [epoch: 9.76 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05589102006498915		[learning rate: 0.00039541]
	Learning Rate: 0.000395415
	LOSS [training: 0.05589102006498915 | validation: 0.05554488195836487]
	TIME [epoch: 9.75 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05279204028048031		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.05279204028048031 | validation: 0.05095426867222088]
	TIME [epoch: 9.76 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043964967715631076		[learning rate: 0.0003935]
	Learning Rate: 0.000393502
	LOSS [training: 0.043964967715631076 | validation: 0.03789566123586189]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1435.pth
	Model improved!!!
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048471837466037254		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.048471837466037254 | validation: 0.0519805788220898]
	TIME [epoch: 9.75 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05191666565721479		[learning rate: 0.0003916]
	Learning Rate: 0.000391599
	LOSS [training: 0.05191666565721479 | validation: 0.06857783761748591]
	TIME [epoch: 9.76 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04957594855796932		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.04957594855796932 | validation: 0.05712544399957738]
	TIME [epoch: 9.76 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04997604357352369		[learning rate: 0.00038971]
	Learning Rate: 0.000389706
	LOSS [training: 0.04997604357352369 | validation: 0.07552264557074204]
	TIME [epoch: 9.75 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05472591663384557		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.05472591663384557 | validation: 0.054174954484383024]
	TIME [epoch: 9.74 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05843471514676104		[learning rate: 0.00038782]
	Learning Rate: 0.000387821
	LOSS [training: 0.05843471514676104 | validation: 0.08606741667338358]
	TIME [epoch: 9.77 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08939224149956262		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.08939224149956262 | validation: 0.1067017916811881]
	TIME [epoch: 9.75 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10000219074528571		[learning rate: 0.00038595]
	Learning Rate: 0.000385946
	LOSS [training: 0.10000219074528571 | validation: 0.11859115930193587]
	TIME [epoch: 9.75 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09566993089808004		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.09566993089808004 | validation: 0.10056219398613747]
	TIME [epoch: 9.76 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07615060221838053		[learning rate: 0.00038408]
	Learning Rate: 0.000384079
	LOSS [training: 0.07615060221838053 | validation: 0.09540570421191774]
	TIME [epoch: 9.75 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06385575996768403		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.06385575996768403 | validation: 0.0661450261932524]
	TIME [epoch: 9.74 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04705644291419691		[learning rate: 0.00038222]
	Learning Rate: 0.000382222
	LOSS [training: 0.04705644291419691 | validation: 0.05908918153505075]
	TIME [epoch: 9.77 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05318977721106631		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.05318977721106631 | validation: 0.042894608767782554]
	TIME [epoch: 9.75 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04055139625354514		[learning rate: 0.00038037]
	Learning Rate: 0.000380374
	LOSS [training: 0.04055139625354514 | validation: 0.05158852865079205]
	TIME [epoch: 9.75 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04880261275792213		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.04880261275792213 | validation: 0.049444977716282854]
	TIME [epoch: 9.76 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05153451285836075		[learning rate: 0.00037853]
	Learning Rate: 0.000378534
	LOSS [training: 0.05153451285836075 | validation: 0.06266179288028668]
	TIME [epoch: 9.75 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05047742197220081		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.05047742197220081 | validation: 0.05011780104041742]
	TIME [epoch: 9.74 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04390481794733523		[learning rate: 0.0003767]
	Learning Rate: 0.000376704
	LOSS [training: 0.04390481794733523 | validation: 0.05332067220990993]
	TIME [epoch: 9.75 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05575069900565246		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.05575069900565246 | validation: 0.06658820990301811]
	TIME [epoch: 9.75 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0584009118056784		[learning rate: 0.00037488]
	Learning Rate: 0.000374882
	LOSS [training: 0.0584009118056784 | validation: 0.09588007135969415]
	TIME [epoch: 9.75 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07758290586825467		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.07758290586825467 | validation: 0.08526545979659626]
	TIME [epoch: 9.77 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07725846385454455		[learning rate: 0.00037307]
	Learning Rate: 0.000373069
	LOSS [training: 0.07725846385454455 | validation: 0.1103276549195978]
	TIME [epoch: 9.74 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08077793890091063		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.08077793890091063 | validation: 0.09775184069593663]
	TIME [epoch: 9.75 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07309172323706983		[learning rate: 0.00037127]
	Learning Rate: 0.000371265
	LOSS [training: 0.07309172323706983 | validation: 0.0715698663904338]
	TIME [epoch: 9.76 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05623703485221824		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.05623703485221824 | validation: 0.06956114685147415]
	TIME [epoch: 9.74 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058708554367303614		[learning rate: 0.00036947]
	Learning Rate: 0.00036947
	LOSS [training: 0.058708554367303614 | validation: 0.08487644423762504]
	TIME [epoch: 9.75 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06734286728928592		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.06734286728928592 | validation: 0.08137558379472766]
	TIME [epoch: 9.75 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07763609672536333		[learning rate: 0.00036768]
	Learning Rate: 0.000367683
	LOSS [training: 0.07763609672536333 | validation: 0.07398505869371612]
	TIME [epoch: 9.75 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05838446350044226		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.05838446350044226 | validation: 0.05384904758288112]
	TIME [epoch: 9.74 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053215554570008726		[learning rate: 0.00036591]
	Learning Rate: 0.000365905
	LOSS [training: 0.053215554570008726 | validation: 0.04051549943247311]
	TIME [epoch: 9.75 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04662260089290714		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.04662260089290714 | validation: 0.050540324995985354]
	TIME [epoch: 9.75 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044035882762058706		[learning rate: 0.00036414]
	Learning Rate: 0.000364136
	LOSS [training: 0.044035882762058706 | validation: 0.07108494805177241]
	TIME [epoch: 9.75 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06147634195504246		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.06147634195504246 | validation: 0.06333893685204585]
	TIME [epoch: 9.76 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061483708874612464		[learning rate: 0.00036237]
	Learning Rate: 0.000362375
	LOSS [training: 0.061483708874612464 | validation: 0.09434121565184174]
	TIME [epoch: 9.75 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09032338844010639		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.09032338844010639 | validation: 0.10865016747826566]
	TIME [epoch: 9.75 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08817323075110924		[learning rate: 0.00036062]
	Learning Rate: 0.000360622
	LOSS [training: 0.08817323075110924 | validation: 0.11278783062339556]
	TIME [epoch: 9.75 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08069953200024825		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.08069953200024825 | validation: 0.125317742781704]
	TIME [epoch: 9.75 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1086565187386916		[learning rate: 0.00035888]
	Learning Rate: 0.000358878
	LOSS [training: 0.1086565187386916 | validation: 0.1835771305054349]
	TIME [epoch: 9.75 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16770950408926102		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.16770950408926102 | validation: 0.23969652898391172]
	TIME [epoch: 9.75 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19629572625235886		[learning rate: 0.00035714]
	Learning Rate: 0.000357143
	LOSS [training: 0.19629572625235886 | validation: 0.22960547840290296]
	TIME [epoch: 9.75 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16364482689939175		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.16364482689939175 | validation: 0.17342794937901146]
	TIME [epoch: 9.74 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1219447141037681		[learning rate: 0.00035542]
	Learning Rate: 0.000355416
	LOSS [training: 0.1219447141037681 | validation: 0.12360160173212452]
	TIME [epoch: 9.74 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10020924538923084		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.10020924538923084 | validation: 0.16658646090709428]
	TIME [epoch: 9.76 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12359161895211346		[learning rate: 0.0003537]
	Learning Rate: 0.000353697
	LOSS [training: 0.12359161895211346 | validation: 0.14040366659199405]
	TIME [epoch: 9.75 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10923664873703032		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.10923664873703032 | validation: 0.1277427322390174]
	TIME [epoch: 9.74 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1061704138330222		[learning rate: 0.00035199]
	Learning Rate: 0.000351987
	LOSS [training: 0.1061704138330222 | validation: 0.1696820032257071]
	TIME [epoch: 9.75 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11459800958846691		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.11459800958846691 | validation: 0.1385051251003379]
	TIME [epoch: 9.73 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09631331176829702		[learning rate: 0.00035028]
	Learning Rate: 0.000350285
	LOSS [training: 0.09631331176829702 | validation: 0.10312141351743832]
	TIME [epoch: 9.74 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08082536963743148		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.08082536963743148 | validation: 0.09178546279811815]
	TIME [epoch: 9.76 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06018357312499965		[learning rate: 0.00034859]
	Learning Rate: 0.000348591
	LOSS [training: 0.06018357312499965 | validation: 0.06918458733622171]
	TIME [epoch: 9.74 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05229174488137188		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.05229174488137188 | validation: 0.054573746898713756]
	TIME [epoch: 9.74 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051324685348653476		[learning rate: 0.0003469]
	Learning Rate: 0.000346905
	LOSS [training: 0.051324685348653476 | validation: 0.05878004175198397]
	TIME [epoch: 9.78 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04711951304493518		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.04711951304493518 | validation: 0.04997958698805741]
	TIME [epoch: 9.74 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04928944122784971		[learning rate: 0.00034523]
	Learning Rate: 0.000345227
	LOSS [training: 0.04928944122784971 | validation: 0.05876646053981851]
	TIME [epoch: 9.74 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053005605718156136		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.053005605718156136 | validation: 0.05072417471904675]
	TIME [epoch: 9.76 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04519344970339406		[learning rate: 0.00034356]
	Learning Rate: 0.000343558
	LOSS [training: 0.04519344970339406 | validation: 0.07084997703150675]
	TIME [epoch: 9.74 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05906651978694322		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.05906651978694322 | validation: 0.08418613155110415]
	TIME [epoch: 9.74 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053308593697728224		[learning rate: 0.0003419]
	Learning Rate: 0.000341897
	LOSS [training: 0.053308593697728224 | validation: 0.049544530631155846]
	TIME [epoch: 9.76 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0551745552374779		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.0551745552374779 | validation: 0.07745817499769278]
	TIME [epoch: 9.74 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061289656294000495		[learning rate: 0.00034024]
	Learning Rate: 0.000340243
	LOSS [training: 0.061289656294000495 | validation: 0.05985190229398333]
	TIME [epoch: 9.74 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053563485113635775		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.053563485113635775 | validation: 0.06908613836493123]
	TIME [epoch: 9.75 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056508813659978285		[learning rate: 0.0003386]
	Learning Rate: 0.000338598
	LOSS [training: 0.056508813659978285 | validation: 0.055224446162175256]
	TIME [epoch: 9.74 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059498315248914746		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.059498315248914746 | validation: 0.0702437974474706]
	TIME [epoch: 9.74 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048254332829799726		[learning rate: 0.00033696]
	Learning Rate: 0.00033696
	LOSS [training: 0.048254332829799726 | validation: 0.04340288932564792]
	TIME [epoch: 9.76 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04295250620269505		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.04295250620269505 | validation: 0.05699375396350012]
	TIME [epoch: 9.74 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04232951949634898		[learning rate: 0.00033533]
	Learning Rate: 0.000335331
	LOSS [training: 0.04232951949634898 | validation: 0.051243738193203575]
	TIME [epoch: 9.74 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04455055502724514		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.04455055502724514 | validation: 0.060713053137764636]
	TIME [epoch: 9.76 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03751227582985196		[learning rate: 0.00033371]
	Learning Rate: 0.000333709
	LOSS [training: 0.03751227582985196 | validation: 0.04906618040295704]
	TIME [epoch: 9.74 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03846275813832127		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.03846275813832127 | validation: 0.04675834296181497]
	TIME [epoch: 9.74 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040076549488524106		[learning rate: 0.0003321]
	Learning Rate: 0.000332096
	LOSS [training: 0.040076549488524106 | validation: 0.03824478416758991]
	TIME [epoch: 9.74 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0489351798517935		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.0489351798517935 | validation: 0.05359514432676218]
	TIME [epoch: 9.74 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04227259133268611		[learning rate: 0.00033049]
	Learning Rate: 0.00033049
	LOSS [training: 0.04227259133268611 | validation: 0.031799694810752184]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1507.pth
	Model improved!!!
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03663138315855545		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.03663138315855545 | validation: 0.05436822305347807]
	TIME [epoch: 9.76 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048286355770840214		[learning rate: 0.00032889]
	Learning Rate: 0.000328891
	LOSS [training: 0.048286355770840214 | validation: 0.06159827781090108]
	TIME [epoch: 9.74 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056749204084971416		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.056749204084971416 | validation: 0.061943137090133396]
	TIME [epoch: 9.74 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041613926000553525		[learning rate: 0.0003273]
	Learning Rate: 0.000327301
	LOSS [training: 0.041613926000553525 | validation: 0.06340787369815244]
	TIME [epoch: 9.74 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045347294219033385		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.045347294219033385 | validation: 0.06061972834634229]
	TIME [epoch: 9.75 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04791439635309166		[learning rate: 0.00032572]
	Learning Rate: 0.000325718
	LOSS [training: 0.04791439635309166 | validation: 0.05185850988347724]
	TIME [epoch: 9.74 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05012425081211722		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.05012425081211722 | validation: 0.05497370765607316]
	TIME [epoch: 9.74 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05563302274990593		[learning rate: 0.00032414]
	Learning Rate: 0.000324143
	LOSS [training: 0.05563302274990593 | validation: 0.059579201573634076]
	TIME [epoch: 9.75 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045402798805674605		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.045402798805674605 | validation: 0.058929677254605455]
	TIME [epoch: 9.75 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046485931870358134		[learning rate: 0.00032258]
	Learning Rate: 0.000322576
	LOSS [training: 0.046485931870358134 | validation: 0.047851020602177545]
	TIME [epoch: 9.74 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039804711002567314		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.039804711002567314 | validation: 0.046465294188422705]
	TIME [epoch: 9.75 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041037952014566434		[learning rate: 0.00032102]
	Learning Rate: 0.000321016
	LOSS [training: 0.041037952014566434 | validation: 0.052762899900584394]
	TIME [epoch: 9.74 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05283076729819665		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.05283076729819665 | validation: 0.04524366974150352]
	TIME [epoch: 9.73 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0420559486326472		[learning rate: 0.00031946]
	Learning Rate: 0.000319463
	LOSS [training: 0.0420559486326472 | validation: 0.04878673141351023]
	TIME [epoch: 9.75 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046492271120470684		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.046492271120470684 | validation: 0.04630343877320545]
	TIME [epoch: 9.74 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047101010541448086		[learning rate: 0.00031792]
	Learning Rate: 0.000317918
	LOSS [training: 0.047101010541448086 | validation: 0.03434961396609791]
	TIME [epoch: 9.73 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03473327913202953		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.03473327913202953 | validation: 0.030451250290248828]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1524.pth
	Model improved!!!
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039911955096872634		[learning rate: 0.00031638]
	Learning Rate: 0.000316381
	LOSS [training: 0.039911955096872634 | validation: 0.04020522161177042]
	TIME [epoch: 9.74 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037188667127054244		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.037188667127054244 | validation: 0.05023692893453651]
	TIME [epoch: 9.74 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04167963584513122		[learning rate: 0.00031485]
	Learning Rate: 0.000314851
	LOSS [training: 0.04167963584513122 | validation: 0.04470783335754854]
	TIME [epoch: 9.77 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03867046311999998		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.03867046311999998 | validation: 0.03972536009397684]
	TIME [epoch: 9.75 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0423772151586425		[learning rate: 0.00031333]
	Learning Rate: 0.000313329
	LOSS [training: 0.0423772151586425 | validation: 0.046045390069031404]
	TIME [epoch: 9.75 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04227224679710033		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.04227224679710033 | validation: 0.047580769132890895]
	TIME [epoch: 9.77 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03671906342636619		[learning rate: 0.00031181]
	Learning Rate: 0.000311813
	LOSS [training: 0.03671906342636619 | validation: 0.03205312491180174]
	TIME [epoch: 9.74 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03201852891291412		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.03201852891291412 | validation: 0.039033759375884984]
	TIME [epoch: 9.74 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03658881198172689		[learning rate: 0.00031031]
	Learning Rate: 0.000310305
	LOSS [training: 0.03658881198172689 | validation: 0.04073468080359693]
	TIME [epoch: 9.76 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044127723449233366		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.044127723449233366 | validation: 0.048825165320204277]
	TIME [epoch: 9.74 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05930914161551054		[learning rate: 0.0003088]
	Learning Rate: 0.000308805
	LOSS [training: 0.05930914161551054 | validation: 0.06948886724634472]
	TIME [epoch: 9.74 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04536311465270479		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.04536311465270479 | validation: 0.052249395358844306]
	TIME [epoch: 9.76 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04693504771296765		[learning rate: 0.00030731]
	Learning Rate: 0.000307312
	LOSS [training: 0.04693504771296765 | validation: 0.0671957066565252]
	TIME [epoch: 9.75 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053039423065380245		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.053039423065380245 | validation: 0.0659643586461698]
	TIME [epoch: 9.75 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05635947723727508		[learning rate: 0.00030583]
	Learning Rate: 0.000305826
	LOSS [training: 0.05635947723727508 | validation: 0.056123907493042885]
	TIME [epoch: 9.76 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04165371607035631		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.04165371607035631 | validation: 0.046945150565593945]
	TIME [epoch: 9.75 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03759318936373647		[learning rate: 0.00030435]
	Learning Rate: 0.000304347
	LOSS [training: 0.03759318936373647 | validation: 0.025440253509720893]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1541.pth
	Model improved!!!
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030525017586001697		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.030525017586001697 | validation: 0.03933487610347023]
	TIME [epoch: 9.78 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0284944093385525		[learning rate: 0.00030287]
	Learning Rate: 0.000302875
	LOSS [training: 0.0284944093385525 | validation: 0.042001227018770335]
	TIME [epoch: 9.75 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04107871325164839		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.04107871325164839 | validation: 0.04956343812013778]
	TIME [epoch: 9.74 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0476749375541736		[learning rate: 0.00030141]
	Learning Rate: 0.00030141
	LOSS [training: 0.0476749375541736 | validation: 0.06548339115633837]
	TIME [epoch: 9.76 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06518611271236494		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.06518611271236494 | validation: 0.08169399786868377]
	TIME [epoch: 9.75 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05970847282096423		[learning rate: 0.00029995]
	Learning Rate: 0.000299953
	LOSS [training: 0.05970847282096423 | validation: 0.061297061597824096]
	TIME [epoch: 9.75 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04600045004708414		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.04600045004708414 | validation: 0.039841576114480054]
	TIME [epoch: 9.76 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03761978187776854		[learning rate: 0.0002985]
	Learning Rate: 0.000298502
	LOSS [training: 0.03761978187776854 | validation: 0.06105422318009054]
	TIME [epoch: 9.76 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04528314174533306		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.04528314174533306 | validation: 0.05254585516882746]
	TIME [epoch: 9.76 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041727408118173236		[learning rate: 0.00029706]
	Learning Rate: 0.000297059
	LOSS [training: 0.041727408118173236 | validation: 0.05466763438909252]
	TIME [epoch: 9.76 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04057761210170348		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.04057761210170348 | validation: 0.056953578600272774]
	TIME [epoch: 9.76 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044494134901191126		[learning rate: 0.00029562]
	Learning Rate: 0.000295622
	LOSS [training: 0.044494134901191126 | validation: 0.06268546637403474]
	TIME [epoch: 9.75 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04240822862390477		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.04240822862390477 | validation: 0.051993795863270055]
	TIME [epoch: 9.75 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04756051969591694		[learning rate: 0.00029419]
	Learning Rate: 0.000294193
	LOSS [training: 0.04756051969591694 | validation: 0.03699352437042173]
	TIME [epoch: 9.76 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039809563088790176		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.039809563088790176 | validation: 0.05893198727503478]
	TIME [epoch: 9.75 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03694996642071159		[learning rate: 0.00029277]
	Learning Rate: 0.00029277
	LOSS [training: 0.03694996642071159 | validation: 0.04545307303079268]
	TIME [epoch: 9.76 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033493014619782456		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.033493014619782456 | validation: 0.04807257634873938]
	TIME [epoch: 9.77 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033835532991443894		[learning rate: 0.00029135]
	Learning Rate: 0.000291354
	LOSS [training: 0.033835532991443894 | validation: 0.037703061792803395]
	TIME [epoch: 9.75 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034985281272531164		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.034985281272531164 | validation: 0.043574064987024354]
	TIME [epoch: 9.75 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03627351297271804		[learning rate: 0.00028995]
	Learning Rate: 0.000289945
	LOSS [training: 0.03627351297271804 | validation: 0.043171462936764396]
	TIME [epoch: 9.77 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04583139167291263		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.04583139167291263 | validation: 0.041824598832359235]
	TIME [epoch: 9.76 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03994803929362209		[learning rate: 0.00028854]
	Learning Rate: 0.000288543
	LOSS [training: 0.03994803929362209 | validation: 0.03579228519452516]
	TIME [epoch: 9.75 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0351405348358518		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.0351405348358518 | validation: 0.03960756092580068]
	TIME [epoch: 9.77 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027205439812028255		[learning rate: 0.00028715]
	Learning Rate: 0.000287148
	LOSS [training: 0.027205439812028255 | validation: 0.05086487732998214]
	TIME [epoch: 9.75 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03882921712897306		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.03882921712897306 | validation: 0.04786537187250556]
	TIME [epoch: 9.74 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04258055859212579		[learning rate: 0.00028576]
	Learning Rate: 0.000285759
	LOSS [training: 0.04258055859212579 | validation: 0.042212905320846414]
	TIME [epoch: 9.76 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03978326407943951		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.03978326407943951 | validation: 0.04914054855500271]
	TIME [epoch: 9.75 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03086587311857635		[learning rate: 0.00028438]
	Learning Rate: 0.000284377
	LOSS [training: 0.03086587311857635 | validation: 0.06171799033692125]
	TIME [epoch: 9.74 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035480907425451055		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.035480907425451055 | validation: 0.045153438025612225]
	TIME [epoch: 9.76 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050075295597589664		[learning rate: 0.000283]
	Learning Rate: 0.000283002
	LOSS [training: 0.050075295597589664 | validation: 0.044520406622256356]
	TIME [epoch: 9.75 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031842317166375755		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.031842317166375755 | validation: 0.052780265857206195]
	TIME [epoch: 9.75 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029517521427550097		[learning rate: 0.00028163]
	Learning Rate: 0.000281633
	LOSS [training: 0.029517521427550097 | validation: 0.06639865063577192]
	TIME [epoch: 9.76 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03543838656635949		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.03543838656635949 | validation: 0.052015427751333866]
	TIME [epoch: 9.75 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04030461345801053		[learning rate: 0.00028027]
	Learning Rate: 0.000280272
	LOSS [training: 0.04030461345801053 | validation: 0.05606165866348526]
	TIME [epoch: 9.75 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046229139105423235		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.046229139105423235 | validation: 0.04571861895773274]
	TIME [epoch: 9.77 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03801637280141327		[learning rate: 0.00027892]
	Learning Rate: 0.000278916
	LOSS [training: 0.03801637280141327 | validation: 0.04972160984382077]
	TIME [epoch: 9.74 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046871752635962445		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.046871752635962445 | validation: 0.04608429125484984]
	TIME [epoch: 9.74 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04073750993739791		[learning rate: 0.00027757]
	Learning Rate: 0.000277567
	LOSS [training: 0.04073750993739791 | validation: 0.027396291480361407]
	TIME [epoch: 9.76 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03669749730790471		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.03669749730790471 | validation: 0.03487615037269966]
	TIME [epoch: 9.75 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037160986181952835		[learning rate: 0.00027623]
	Learning Rate: 0.000276225
	LOSS [training: 0.037160986181952835 | validation: 0.034210139985892535]
	TIME [epoch: 9.75 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03715671276722402		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.03715671276722402 | validation: 0.0380755141375957]
	TIME [epoch: 9.76 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031932743559720395		[learning rate: 0.00027489]
	Learning Rate: 0.000274889
	LOSS [training: 0.031932743559720395 | validation: 0.04173483801121655]
	TIME [epoch: 9.75 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028597213211734647		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.028597213211734647 | validation: 0.03758029558608968]
	TIME [epoch: 9.74 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031223098188742644		[learning rate: 0.00027356]
	Learning Rate: 0.00027356
	LOSS [training: 0.031223098188742644 | validation: 0.05003622609632315]
	TIME [epoch: 9.76 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031619327942640926		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.031619327942640926 | validation: 0.03457893359441799]
	TIME [epoch: 9.76 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03646608229673497		[learning rate: 0.00027224]
	Learning Rate: 0.000272237
	LOSS [training: 0.03646608229673497 | validation: 0.04495851595543613]
	TIME [epoch: 9.75 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033643097715509565		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.033643097715509565 | validation: 0.04804266896144238]
	TIME [epoch: 9.76 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030206864870607995		[learning rate: 0.00027092]
	Learning Rate: 0.000270921
	LOSS [training: 0.030206864870607995 | validation: 0.044749466531586485]
	TIME [epoch: 9.75 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03616689114714515		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.03616689114714515 | validation: 0.03771417449276834]
	TIME [epoch: 9.75 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03490400433082702		[learning rate: 0.00026961]
	Learning Rate: 0.000269611
	LOSS [training: 0.03490400433082702 | validation: 0.03306704289928144]
	TIME [epoch: 9.75 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033251673652093264		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.033251673652093264 | validation: 0.029056403097180637]
	TIME [epoch: 9.77 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031679285712707006		[learning rate: 0.00026831]
	Learning Rate: 0.000268307
	LOSS [training: 0.031679285712707006 | validation: 0.036927183848729686]
	TIME [epoch: 9.75 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0365584055030727		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.0365584055030727 | validation: 0.03798750422033986]
	TIME [epoch: 9.75 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03719867340594181		[learning rate: 0.00026701]
	Learning Rate: 0.000267009
	LOSS [training: 0.03719867340594181 | validation: 0.03250417357809214]
	TIME [epoch: 9.76 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04726751158007799		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.04726751158007799 | validation: 0.05200204264678773]
	TIME [epoch: 9.75 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053469391025558276		[learning rate: 0.00026572]
	Learning Rate: 0.000265718
	LOSS [training: 0.053469391025558276 | validation: 0.05104527461648928]
	TIME [epoch: 9.75 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037424660097919504		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.037424660097919504 | validation: 0.03980437249599075]
	TIME [epoch: 9.76 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04610818722375861		[learning rate: 0.00026443]
	Learning Rate: 0.000264433
	LOSS [training: 0.04610818722375861 | validation: 0.05073139062697269]
	TIME [epoch: 9.74 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042698532430589284		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.042698532430589284 | validation: 0.03906180828393886]
	TIME [epoch: 9.74 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03730391659217579		[learning rate: 0.00026315]
	Learning Rate: 0.000263154
	LOSS [training: 0.03730391659217579 | validation: 0.029978322562528456]
	TIME [epoch: 9.76 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0332674884406449		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.0332674884406449 | validation: 0.03333527289706242]
	TIME [epoch: 9.75 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030861144534945584		[learning rate: 0.00026188]
	Learning Rate: 0.000261882
	LOSS [training: 0.030861144534945584 | validation: 0.03880187978830911]
	TIME [epoch: 9.74 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03997583124596059		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.03997583124596059 | validation: 0.0471777989072297]
	TIME [epoch: 9.76 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0362829769926636		[learning rate: 0.00026062]
	Learning Rate: 0.000260615
	LOSS [training: 0.0362829769926636 | validation: 0.050807088388181855]
	TIME [epoch: 9.75 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035045454493970715		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.035045454493970715 | validation: 0.050503887795776255]
	TIME [epoch: 9.75 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042260318482364174		[learning rate: 0.00025936]
	Learning Rate: 0.000259355
	LOSS [training: 0.042260318482364174 | validation: 0.03553097740871413]
	TIME [epoch: 9.75 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044967072210226854		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.044967072210226854 | validation: 0.047692679115287184]
	TIME [epoch: 9.75 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04183884416399737		[learning rate: 0.0002581]
	Learning Rate: 0.000258101
	LOSS [training: 0.04183884416399737 | validation: 0.04425117587981978]
	TIME [epoch: 9.75 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04364032866623234		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.04364032866623234 | validation: 0.04935380707234908]
	TIME [epoch: 9.76 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037808000620008844		[learning rate: 0.00025685]
	Learning Rate: 0.000256853
	LOSS [training: 0.037808000620008844 | validation: 0.03677135698998191]
	TIME [epoch: 9.74 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033632110925892175		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.033632110925892175 | validation: 0.03745429599576916]
	TIME [epoch: 9.73 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048710614754919286		[learning rate: 0.00025561]
	Learning Rate: 0.000255611
	LOSS [training: 0.048710614754919286 | validation: 0.045862875804194]
	TIME [epoch: 9.75 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057706447177660866		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.057706447177660866 | validation: 0.04138836052197073]
	TIME [epoch: 9.75 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04326173834562282		[learning rate: 0.00025437]
	Learning Rate: 0.000254375
	LOSS [training: 0.04326173834562282 | validation: 0.04096770383172046]
	TIME [epoch: 9.75 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042503986195980725		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.042503986195980725 | validation: 0.037211073343565035]
	TIME [epoch: 9.77 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039710283965330086		[learning rate: 0.00025314]
	Learning Rate: 0.000253144
	LOSS [training: 0.039710283965330086 | validation: 0.042023761138083364]
	TIME [epoch: 9.76 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050495805421340356		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.050495805421340356 | validation: 0.043849053895882104]
	TIME [epoch: 9.75 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042489392650970806		[learning rate: 0.00025192]
	Learning Rate: 0.00025192
	LOSS [training: 0.042489392650970806 | validation: 0.04927961943935996]
	TIME [epoch: 9.77 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03495850421671885		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.03495850421671885 | validation: 0.03738825002115314]
	TIME [epoch: 9.75 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04775541763763252		[learning rate: 0.0002507]
	Learning Rate: 0.000250702
	LOSS [training: 0.04775541763763252 | validation: 0.04237653530816275]
	TIME [epoch: 9.75 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0541646192474425		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.0541646192474425 | validation: 0.05195403835269289]
	TIME [epoch: 9.76 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05217793866805527		[learning rate: 0.00024949]
	Learning Rate: 0.00024949
	LOSS [training: 0.05217793866805527 | validation: 0.06999980981620162]
	TIME [epoch: 9.75 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061442747535838546		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.061442747535838546 | validation: 0.054957849560338445]
	TIME [epoch: 9.73 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04320117417505341		[learning rate: 0.00024828]
	Learning Rate: 0.000248283
	LOSS [training: 0.04320117417505341 | validation: 0.06112737351049893]
	TIME [epoch: 9.74 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04852372899762249		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.04852372899762249 | validation: 0.05457370178620503]
	TIME [epoch: 9.76 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050734130920383466		[learning rate: 0.00024708]
	Learning Rate: 0.000247083
	LOSS [training: 0.050734130920383466 | validation: 0.0520154127038027]
	TIME [epoch: 9.73 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050462907372148855		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.050462907372148855 | validation: 0.04003788812584727]
	TIME [epoch: 9.74 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03739121241363098		[learning rate: 0.00024589]
	Learning Rate: 0.000245888
	LOSS [training: 0.03739121241363098 | validation: 0.04483489051721959]
	TIME [epoch: 9.76 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04860415567124305		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.04860415567124305 | validation: 0.05603054075991864]
	TIME [epoch: 9.74 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05382029146277998		[learning rate: 0.0002447]
	Learning Rate: 0.000244699
	LOSS [training: 0.05382029146277998 | validation: 0.05525803875804749]
	TIME [epoch: 9.74 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04033039417019172		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.04033039417019172 | validation: 0.05802834473790588]
	TIME [epoch: 9.76 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048719233102278325		[learning rate: 0.00024352]
	Learning Rate: 0.000243515
	LOSS [training: 0.048719233102278325 | validation: 0.0550563998675383]
	TIME [epoch: 9.73 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03990709416685064		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.03990709416685064 | validation: 0.059422444205421074]
	TIME [epoch: 9.74 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04911749709544934		[learning rate: 0.00024234]
	Learning Rate: 0.000242338
	LOSS [training: 0.04911749709544934 | validation: 0.060250725968196445]
	TIME [epoch: 9.75 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051351224970813514		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.051351224970813514 | validation: 0.04344058530341331]
	TIME [epoch: 9.73 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03784979843322554		[learning rate: 0.00024117]
	Learning Rate: 0.000241166
	LOSS [training: 0.03784979843322554 | validation: 0.04675715643783723]
	TIME [epoch: 9.73 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03366902679901611		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.03366902679901611 | validation: 0.049107775826196284]
	TIME [epoch: 9.76 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031479475144351884		[learning rate: 0.00024]
	Learning Rate: 0.00024
	LOSS [training: 0.031479475144351884 | validation: 0.041983329609979685]
	TIME [epoch: 9.75 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04293074895183796		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.04293074895183796 | validation: 0.0484431723681501]
	TIME [epoch: 9.73 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03929509374387476		[learning rate: 0.00023884]
	Learning Rate: 0.000238839
	LOSS [training: 0.03929509374387476 | validation: 0.03348067711719001]
	TIME [epoch: 9.75 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03278790545016764		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.03278790545016764 | validation: 0.041828583809829796]
	TIME [epoch: 9.74 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048087592753694244		[learning rate: 0.00023768]
	Learning Rate: 0.000237684
	LOSS [training: 0.048087592753694244 | validation: 0.03673452736715073]
	TIME [epoch: 9.73 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038258110067985365		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.038258110067985365 | validation: 0.04137004984939052]
	TIME [epoch: 9.75 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03253076480386157		[learning rate: 0.00023653]
	Learning Rate: 0.000236535
	LOSS [training: 0.03253076480386157 | validation: 0.033547588535678664]
	TIME [epoch: 9.74 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02892988997699738		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.02892988997699738 | validation: 0.026994426248169584]
	TIME [epoch: 9.74 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03326894151592189		[learning rate: 0.00023539]
	Learning Rate: 0.000235391
	LOSS [training: 0.03326894151592189 | validation: 0.03301122460283873]
	TIME [epoch: 9.76 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028857584824467496		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.028857584824467496 | validation: 0.042995212845495914]
	TIME [epoch: 9.73 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027250213682014253		[learning rate: 0.00023425]
	Learning Rate: 0.000234252
	LOSS [training: 0.027250213682014253 | validation: 0.018121640444247803]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1649.pth
	Model improved!!!
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025164730513662865		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.025164730513662865 | validation: 0.038570297804178644]
	TIME [epoch: 9.76 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0334976281042436		[learning rate: 0.00023312]
	Learning Rate: 0.00023312
	LOSS [training: 0.0334976281042436 | validation: 0.03693244352259935]
	TIME [epoch: 9.73 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02807172850390008		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.02807172850390008 | validation: 0.025776930940222542]
	TIME [epoch: 9.73 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029164582722038424		[learning rate: 0.00023199]
	Learning Rate: 0.000231992
	LOSS [training: 0.029164582722038424 | validation: 0.043385726802615356]
	TIME [epoch: 9.75 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025845160425166665		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.025845160425166665 | validation: 0.03138137316373117]
	TIME [epoch: 9.73 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03280985773895545		[learning rate: 0.00023087]
	Learning Rate: 0.00023087
	LOSS [training: 0.03280985773895545 | validation: 0.030143391235444003]
	TIME [epoch: 9.73 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0313411262219517		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.0313411262219517 | validation: 0.03341258561541656]
	TIME [epoch: 9.74 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035968836772217		[learning rate: 0.00022975]
	Learning Rate: 0.000229754
	LOSS [training: 0.035968836772217 | validation: 0.036057929459018964]
	TIME [epoch: 9.73 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035445105715333415		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.035445105715333415 | validation: 0.028521032607275638]
	TIME [epoch: 9.73 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033200469948663505		[learning rate: 0.00022864]
	Learning Rate: 0.000228643
	LOSS [training: 0.033200469948663505 | validation: 0.03748956030353576]
	TIME [epoch: 9.74 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03099789013251611		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.03099789013251611 | validation: 0.04726534952016748]
	TIME [epoch: 9.73 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03621347802865446		[learning rate: 0.00022754]
	Learning Rate: 0.000227537
	LOSS [training: 0.03621347802865446 | validation: 0.04439876531373438]
	TIME [epoch: 9.74 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0299471296447291		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.0299471296447291 | validation: 0.04266288548386574]
	TIME [epoch: 9.73 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03413038613220269		[learning rate: 0.00022644]
	Learning Rate: 0.000226437
	LOSS [training: 0.03413038613220269 | validation: 0.03916773451938465]
	TIME [epoch: 9.74 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04095374322435257		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.04095374322435257 | validation: 0.032946870285022446]
	TIME [epoch: 9.74 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04315731102347765		[learning rate: 0.00022534]
	Learning Rate: 0.000225342
	LOSS [training: 0.04315731102347765 | validation: 0.027414321315231846]
	TIME [epoch: 9.74 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02678560777231757		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.02678560777231757 | validation: 0.04004399635256485]
	TIME [epoch: 9.75 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03308113789658398		[learning rate: 0.00022425]
	Learning Rate: 0.000224252
	LOSS [training: 0.03308113789658398 | validation: 0.029364767863937106]
	TIME [epoch: 9.74 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04079856711757929		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.04079856711757929 | validation: 0.04561061569293011]
	TIME [epoch: 9.74 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03889771898831693		[learning rate: 0.00022317]
	Learning Rate: 0.000223168
	LOSS [training: 0.03889771898831693 | validation: 0.05331184112084282]
	TIME [epoch: 9.74 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04341694886653462		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.04341694886653462 | validation: 0.04315739907857136]
	TIME [epoch: 9.73 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02722544042191391		[learning rate: 0.00022209]
	Learning Rate: 0.000222089
	LOSS [training: 0.02722544042191391 | validation: 0.03378757120775782]
	TIME [epoch: 9.73 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03248533943687539		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.03248533943687539 | validation: 0.037429215824030075]
	TIME [epoch: 9.75 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03187859638994273		[learning rate: 0.00022101]
	Learning Rate: 0.000221015
	LOSS [training: 0.03187859638994273 | validation: 0.0394468377827746]
	TIME [epoch: 9.75 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03899182181251185		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.03899182181251185 | validation: 0.03483682849293059]
	TIME [epoch: 9.75 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032300585748780385		[learning rate: 0.00021995]
	Learning Rate: 0.000219946
	LOSS [training: 0.032300585748780385 | validation: 0.03199235320481848]
	TIME [epoch: 9.76 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0330880109947125		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.0330880109947125 | validation: 0.03635249459091579]
	TIME [epoch: 9.74 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03535566765607174		[learning rate: 0.00021888]
	Learning Rate: 0.000218882
	LOSS [training: 0.03535566765607174 | validation: 0.04230540195280776]
	TIME [epoch: 9.73 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0374227605107174		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.0374227605107174 | validation: 0.05223872045621015]
	TIME [epoch: 9.76 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043640628377258864		[learning rate: 0.00021782]
	Learning Rate: 0.000217824
	LOSS [training: 0.043640628377258864 | validation: 0.056542488117077586]
	TIME [epoch: 9.74 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04828142182198319		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.04828142182198319 | validation: 0.05383408134445126]
	TIME [epoch: 9.73 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035180516190914876		[learning rate: 0.00021677]
	Learning Rate: 0.00021677
	LOSS [training: 0.035180516190914876 | validation: 0.04337339245749841]
	TIME [epoch: 9.75 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03763950833090478		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.03763950833090478 | validation: 0.03852567431299506]
	TIME [epoch: 9.74 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030718331684809808		[learning rate: 0.00021572]
	Learning Rate: 0.000215722
	LOSS [training: 0.030718331684809808 | validation: 0.045613708324895585]
	TIME [epoch: 9.73 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036195390078778866		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.036195390078778866 | validation: 0.03679032447702131]
	TIME [epoch: 9.76 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03944037172179439		[learning rate: 0.00021468]
	Learning Rate: 0.000214679
	LOSS [training: 0.03944037172179439 | validation: 0.045636442463661914]
	TIME [epoch: 9.74 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04381486273903337		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.04381486273903337 | validation: 0.05762887594768854]
	TIME [epoch: 9.75 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052148763200896286		[learning rate: 0.00021364]
	Learning Rate: 0.000213641
	LOSS [training: 0.052148763200896286 | validation: 0.05668482230479182]
	TIME [epoch: 9.75 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061394764811775096		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.061394764811775096 | validation: 0.06503577494836488]
	TIME [epoch: 9.74 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047577902560729225		[learning rate: 0.00021261]
	Learning Rate: 0.000212608
	LOSS [training: 0.047577902560729225 | validation: 0.034766427934280905]
	TIME [epoch: 9.73 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045551649161242574		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.045551649161242574 | validation: 0.04054889136728988]
	TIME [epoch: 9.76 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03707078663520971		[learning rate: 0.00021158]
	Learning Rate: 0.00021158
	LOSS [training: 0.03707078663520971 | validation: 0.04015975463926699]
	TIME [epoch: 9.74 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04074929671268986		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.04074929671268986 | validation: 0.04417914853172993]
	TIME [epoch: 9.74 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04848849029861602		[learning rate: 0.00021056]
	Learning Rate: 0.000210556
	LOSS [training: 0.04848849029861602 | validation: 0.0556156092794879]
	TIME [epoch: 9.75 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05508446955279789		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.05508446955279789 | validation: 0.05647041110259543]
	TIME [epoch: 9.73 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050747665527557786		[learning rate: 0.00020954]
	Learning Rate: 0.000209538
	LOSS [training: 0.050747665527557786 | validation: 0.05340986704694795]
	TIME [epoch: 9.73 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04624229919462186		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.04624229919462186 | validation: 0.05676649686373383]
	TIME [epoch: 9.75 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03488916263607336		[learning rate: 0.00020852]
	Learning Rate: 0.000208525
	LOSS [training: 0.03488916263607336 | validation: 0.049793308283000666]
	TIME [epoch: 9.74 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026332765146024083		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.026332765146024083 | validation: 0.04060893912672864]
	TIME [epoch: 9.73 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03550831821435947		[learning rate: 0.00020752]
	Learning Rate: 0.000207516
	LOSS [training: 0.03550831821435947 | validation: 0.04699183391030161]
	TIME [epoch: 9.74 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04345834002806763		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.04345834002806763 | validation: 0.045685609004602855]
	TIME [epoch: 9.74 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04066638833694848		[learning rate: 0.00020651]
	Learning Rate: 0.000206513
	LOSS [training: 0.04066638833694848 | validation: 0.05249516841390193]
	TIME [epoch: 9.73 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040923304302960664		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.040923304302960664 | validation: 0.03816803912728478]
	TIME [epoch: 9.72 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04152973110465041		[learning rate: 0.00020551]
	Learning Rate: 0.000205514
	LOSS [training: 0.04152973110465041 | validation: 0.051864333682112566]
	TIME [epoch: 9.74 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03792525545866806		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.03792525545866806 | validation: 0.03197746390021987]
	TIME [epoch: 9.73 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04017566814251845		[learning rate: 0.00020452]
	Learning Rate: 0.000204521
	LOSS [training: 0.04017566814251845 | validation: 0.04004225076322491]
	TIME [epoch: 9.74 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03172924390607518		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.03172924390607518 | validation: 0.04379706494948552]
	TIME [epoch: 9.75 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03711497597494356		[learning rate: 0.00020353]
	Learning Rate: 0.000203531
	LOSS [training: 0.03711497597494356 | validation: 0.028424574617301152]
	TIME [epoch: 9.73 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03154431464625293		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.03154431464625293 | validation: 0.030506870929358016]
	TIME [epoch: 9.73 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02785341673993247		[learning rate: 0.00020255]
	Learning Rate: 0.000202547
	LOSS [training: 0.02785341673993247 | validation: 0.04314549176277253]
	TIME [epoch: 9.75 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035024342007299175		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.035024342007299175 | validation: 0.04870549594098098]
	TIME [epoch: 9.73 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03638177786069966		[learning rate: 0.00020157]
	Learning Rate: 0.000201568
	LOSS [training: 0.03638177786069966 | validation: 0.059191236473853354]
	TIME [epoch: 9.74 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03921638669732299		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.03921638669732299 | validation: 0.04708488155600828]
	TIME [epoch: 9.75 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037977936065747384		[learning rate: 0.00020059]
	Learning Rate: 0.000200593
	LOSS [training: 0.037977936065747384 | validation: 0.03966614467789982]
	TIME [epoch: 9.72 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03435488976133099		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.03435488976133099 | validation: 0.0612895888890108]
	TIME [epoch: 9.73 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035923784490043596		[learning rate: 0.00019962]
	Learning Rate: 0.000199623
	LOSS [training: 0.035923784490043596 | validation: 0.03544863762345123]
	TIME [epoch: 9.75 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03616107494124135		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.03616107494124135 | validation: 0.05184172061081949]
	TIME [epoch: 9.73 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029416871351283513		[learning rate: 0.00019866]
	Learning Rate: 0.000198658
	LOSS [training: 0.029416871351283513 | validation: 0.05672312172898652]
	TIME [epoch: 9.73 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04501455361481062		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.04501455361481062 | validation: 0.0630433034070221]
	TIME [epoch: 9.75 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045882432530447534		[learning rate: 0.0001977]
	Learning Rate: 0.000197697
	LOSS [training: 0.045882432530447534 | validation: 0.06352056452503954]
	TIME [epoch: 9.73 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043905517871685965		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.043905517871685965 | validation: 0.05483172521767649]
	TIME [epoch: 9.73 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038905465639010414		[learning rate: 0.00019674]
	Learning Rate: 0.000196741
	LOSS [training: 0.038905465639010414 | validation: 0.046702370200113544]
	TIME [epoch: 9.75 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03630646588935045		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.03630646588935045 | validation: 0.05148655950291919]
	TIME [epoch: 9.73 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04719136263481506		[learning rate: 0.00019579]
	Learning Rate: 0.00019579
	LOSS [training: 0.04719136263481506 | validation: 0.04963353480818439]
	TIME [epoch: 9.74 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046117458759741804		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.046117458759741804 | validation: 0.05769260272488974]
	TIME [epoch: 9.76 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04597930848715463		[learning rate: 0.00019484]
	Learning Rate: 0.000194843
	LOSS [training: 0.04597930848715463 | validation: 0.07025949507622535]
	TIME [epoch: 9.73 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04166289303525344		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.04166289303525344 | validation: 0.035273753545846456]
	TIME [epoch: 9.74 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03421391046235953		[learning rate: 0.0001939]
	Learning Rate: 0.000193901
	LOSS [training: 0.03421391046235953 | validation: 0.04812423346160714]
	TIME [epoch: 9.74 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03640582245043628		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.03640582245043628 | validation: 0.03004877598154093]
	TIME [epoch: 9.74 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033779100551590564		[learning rate: 0.00019296]
	Learning Rate: 0.000192963
	LOSS [training: 0.033779100551590564 | validation: 0.047343287544905216]
	TIME [epoch: 9.73 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03590955764146812		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.03590955764146812 | validation: 0.0432757196450855]
	TIME [epoch: 9.74 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03630394086677996		[learning rate: 0.00019203]
	Learning Rate: 0.00019203
	LOSS [training: 0.03630394086677996 | validation: 0.05343926873571354]
	TIME [epoch: 9.73 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02830099785058947		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.02830099785058947 | validation: 0.05130169755476527]
	TIME [epoch: 9.73 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029944137715186715		[learning rate: 0.0001911]
	Learning Rate: 0.000191101
	LOSS [training: 0.029944137715186715 | validation: 0.03132031598219221]
	TIME [epoch: 9.75 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029972243811319632		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.029972243811319632 | validation: 0.025074459416925175]
	TIME [epoch: 9.73 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03337409360312462		[learning rate: 0.00019018]
	Learning Rate: 0.000190177
	LOSS [training: 0.03337409360312462 | validation: 0.02815314909611451]
	TIME [epoch: 9.72 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022778271523133522		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.022778271523133522 | validation: 0.03678660567039965]
	TIME [epoch: 9.74 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024432677602894675		[learning rate: 0.00018926]
	Learning Rate: 0.000189257
	LOSS [training: 0.024432677602894675 | validation: 0.03306545076177062]
	TIME [epoch: 9.74 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024166089551415956		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.024166089551415956 | validation: 0.035014227873527155]
	TIME [epoch: 9.74 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023894197282618868		[learning rate: 0.00018834]
	Learning Rate: 0.000188342
	LOSS [training: 0.023894197282618868 | validation: 0.034363569165718144]
	TIME [epoch: 9.73 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026064571068728067		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.026064571068728067 | validation: 0.02983872510948563]
	TIME [epoch: 9.76 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027095579391375156		[learning rate: 0.00018743]
	Learning Rate: 0.000187431
	LOSS [training: 0.027095579391375156 | validation: 0.03203164599726161]
	TIME [epoch: 9.74 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03160202848830882		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.03160202848830882 | validation: 0.027802525420685703]
	TIME [epoch: 9.74 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029917879903948962		[learning rate: 0.00018652]
	Learning Rate: 0.000186525
	LOSS [training: 0.029917879903948962 | validation: 0.027519211086873135]
	TIME [epoch: 9.75 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029645517627462342		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.029645517627462342 | validation: 0.031215830491409868]
	TIME [epoch: 9.74 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02710878758868146		[learning rate: 0.00018562]
	Learning Rate: 0.000185623
	LOSS [training: 0.02710878758868146 | validation: 0.01870894491041081]
	TIME [epoch: 9.74 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03238526260627379		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.03238526260627379 | validation: 0.03769266453025525]
	TIME [epoch: 9.75 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030870317357133675		[learning rate: 0.00018473]
	Learning Rate: 0.000184725
	LOSS [training: 0.030870317357133675 | validation: 0.03671044423635438]
	TIME [epoch: 9.74 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03296780191641095		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.03296780191641095 | validation: 0.027197593637753176]
	TIME [epoch: 9.73 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028012198842224445		[learning rate: 0.00018383]
	Learning Rate: 0.000183832
	LOSS [training: 0.028012198842224445 | validation: 0.04034780929030449]
	TIME [epoch: 9.76 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029358289255763302		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.029358289255763302 | validation: 0.03741057279872078]
	TIME [epoch: 9.75 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02728799572504445		[learning rate: 0.00018294]
	Learning Rate: 0.000182943
	LOSS [training: 0.02728799572504445 | validation: 0.03257162882730219]
	TIME [epoch: 9.74 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021641519564844204		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.021641519564844204 | validation: 0.032652269838881705]
	TIME [epoch: 9.76 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027062088606585967		[learning rate: 0.00018206]
	Learning Rate: 0.000182058
	LOSS [training: 0.027062088606585967 | validation: 0.0366165082440989]
	TIME [epoch: 9.74 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03105308576297832		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.03105308576297832 | validation: 0.03980860352885514]
	TIME [epoch: 9.74 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023239620020527936		[learning rate: 0.00018118]
	Learning Rate: 0.000181178
	LOSS [training: 0.023239620020527936 | validation: 0.0328340547283605]
	TIME [epoch: 9.76 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027780845586551216		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.027780845586551216 | validation: 0.02983628034669635]
	TIME [epoch: 9.75 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026911998627982558		[learning rate: 0.0001803]
	Learning Rate: 0.000180302
	LOSS [training: 0.026911998627982558 | validation: 0.046199636375338776]
	TIME [epoch: 9.74 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03545954932649027		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.03545954932649027 | validation: 0.05235042124914456]
	TIME [epoch: 9.75 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029318574745361536		[learning rate: 0.00017943]
	Learning Rate: 0.00017943
	LOSS [training: 0.029318574745361536 | validation: 0.05484956971528931]
	TIME [epoch: 9.73 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036353585561967036		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.036353585561967036 | validation: 0.05347211602556346]
	TIME [epoch: 9.74 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03242214492955099		[learning rate: 0.00017856]
	Learning Rate: 0.000178562
	LOSS [training: 0.03242214492955099 | validation: 0.043625770928886]
	TIME [epoch: 9.75 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03287728543628162		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.03287728543628162 | validation: 0.036886257397725476]
	TIME [epoch: 9.74 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03193925544467505		[learning rate: 0.0001777]
	Learning Rate: 0.000177699
	LOSS [training: 0.03193925544467505 | validation: 0.04325231957684087]
	TIME [epoch: 9.74 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035271418816704765		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.035271418816704765 | validation: 0.05877834519692355]
	TIME [epoch: 9.75 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04580380605887776		[learning rate: 0.00017684]
	Learning Rate: 0.000176839
	LOSS [training: 0.04580380605887776 | validation: 0.05428373158100052]
	TIME [epoch: 9.74 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05117523935847269		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.05117523935847269 | validation: 0.060143139422399586]
	TIME [epoch: 9.74 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04740660227686779		[learning rate: 0.00017598]
	Learning Rate: 0.000175984
	LOSS [training: 0.04740660227686779 | validation: 0.05836335778932848]
	TIME [epoch: 9.75 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0409795754692079		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.0409795754692079 | validation: 0.045748252410178145]
	TIME [epoch: 9.73 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032807872793293294		[learning rate: 0.00017513]
	Learning Rate: 0.000175133
	LOSS [training: 0.032807872793293294 | validation: 0.048909822507757855]
	TIME [epoch: 9.75 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03352693770893944		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.03352693770893944 | validation: 0.06611715701419905]
	TIME [epoch: 9.76 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04790720179015416		[learning rate: 0.00017429]
	Learning Rate: 0.000174286
	LOSS [training: 0.04790720179015416 | validation: 0.0704495643685008]
	TIME [epoch: 9.73 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05168318430930465		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.05168318430930465 | validation: 0.057951518137849885]
	TIME [epoch: 9.74 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05134093011314787		[learning rate: 0.00017344]
	Learning Rate: 0.000173443
	LOSS [training: 0.05134093011314787 | validation: 0.07172420339381622]
	TIME [epoch: 9.74 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06577019766414859		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.06577019766414859 | validation: 0.09239654432625855]
	TIME [epoch: 9.75 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06811185870237157		[learning rate: 0.0001726]
	Learning Rate: 0.000172605
	LOSS [training: 0.06811185870237157 | validation: 0.06061494968240451]
	TIME [epoch: 9.73 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056621489578731275		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.056621489578731275 | validation: 0.06736778025425412]
	TIME [epoch: 9.74 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054734724139463155		[learning rate: 0.00017177]
	Learning Rate: 0.00017177
	LOSS [training: 0.054734724139463155 | validation: 0.08202602072732033]
	TIME [epoch: 9.75 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06471439508453286		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.06471439508453286 | validation: 0.08986494315885979]
	TIME [epoch: 9.74 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06755316605586738		[learning rate: 0.00017094]
	Learning Rate: 0.000170939
	LOSS [training: 0.06755316605586738 | validation: 0.07527371744668251]
	TIME [epoch: 9.73 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05868575506712851		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.05868575506712851 | validation: 0.07282268483452922]
	TIME [epoch: 9.75 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05740402382292846		[learning rate: 0.00017011]
	Learning Rate: 0.000170113
	LOSS [training: 0.05740402382292846 | validation: 0.07233870479106051]
	TIME [epoch: 9.74 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04931520828581858		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.04931520828581858 | validation: 0.0917192475701623]
	TIME [epoch: 9.74 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04955014832373735		[learning rate: 0.00016929]
	Learning Rate: 0.00016929
	LOSS [training: 0.04955014832373735 | validation: 0.06695570985909802]
	TIME [epoch: 9.75 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04819064069017852		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.04819064069017852 | validation: 0.06945400850378364]
	TIME [epoch: 9.74 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04424169792652336		[learning rate: 0.00016847]
	Learning Rate: 0.000168471
	LOSS [training: 0.04424169792652336 | validation: 0.06740473347863052]
	TIME [epoch: 9.73 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04466795895697363		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.04466795895697363 | validation: 0.04848581590096077]
	TIME [epoch: 9.75 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039184910622852745		[learning rate: 0.00016766]
	Learning Rate: 0.000167657
	LOSS [training: 0.039184910622852745 | validation: 0.05559404412901715]
	TIME [epoch: 9.73 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039600964217395056		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.039600964217395056 | validation: 0.0641556373609292]
	TIME [epoch: 9.73 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04675619360322643		[learning rate: 0.00016685]
	Learning Rate: 0.000166846
	LOSS [training: 0.04675619360322643 | validation: 0.06211800642658508]
	TIME [epoch: 9.75 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041685166022025294		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.041685166022025294 | validation: 0.05496582461505762]
	TIME [epoch: 9.73 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04365641063752331		[learning rate: 0.00016604]
	Learning Rate: 0.000166039
	LOSS [training: 0.04365641063752331 | validation: 0.058084147303902434]
	TIME [epoch: 9.74 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04786139985518034		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.04786139985518034 | validation: 0.04724802078507181]
	TIME [epoch: 9.76 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03880675088962343		[learning rate: 0.00016524]
	Learning Rate: 0.000165236
	LOSS [training: 0.03880675088962343 | validation: 0.05327150617005254]
	TIME [epoch: 9.74 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0370014022353551		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.0370014022353551 | validation: 0.052832686086644945]
	TIME [epoch: 9.73 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04171880519603424		[learning rate: 0.00016444]
	Learning Rate: 0.000164437
	LOSS [training: 0.04171880519603424 | validation: 0.05281879118933395]
	TIME [epoch: 9.75 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04240603872283845		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.04240603872283845 | validation: 0.06193026152803361]
	TIME [epoch: 9.73 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03796131680564489		[learning rate: 0.00016364]
	Learning Rate: 0.000163642
	LOSS [training: 0.03796131680564489 | validation: 0.05380942625713498]
	TIME [epoch: 9.73 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0413450881200639		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.0413450881200639 | validation: 0.055538981507293014]
	TIME [epoch: 9.76 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036809710651804516		[learning rate: 0.00016285]
	Learning Rate: 0.000162851
	LOSS [training: 0.036809710651804516 | validation: 0.045626098141827026]
	TIME [epoch: 9.74 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042648761115560464		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.042648761115560464 | validation: 0.05331278555416193]
	TIME [epoch: 9.73 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03171801986116825		[learning rate: 0.00016206]
	Learning Rate: 0.000162063
	LOSS [training: 0.03171801986116825 | validation: 0.0539074074795678]
	TIME [epoch: 9.75 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03539846979394583		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.03539846979394583 | validation: 0.039634279856668106]
	TIME [epoch: 9.73 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029758907433440618		[learning rate: 0.00016128]
	Learning Rate: 0.000161279
	LOSS [training: 0.029758907433440618 | validation: 0.04368942100269108]
	TIME [epoch: 9.75 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02380012655519871		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.02380012655519871 | validation: 0.04413795994532121]
	TIME [epoch: 9.76 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023985005013979824		[learning rate: 0.0001605]
	Learning Rate: 0.000160499
	LOSS [training: 0.023985005013979824 | validation: 0.039056322656490526]
	TIME [epoch: 9.75 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03216383506888703		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.03216383506888703 | validation: 0.04250329755863203]
	TIME [epoch: 9.75 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03174854817872984		[learning rate: 0.00015972]
	Learning Rate: 0.000159723
	LOSS [training: 0.03174854817872984 | validation: 0.0433212766021981]
	TIME [epoch: 9.75 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03394352371371484		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.03394352371371484 | validation: 0.05195727319239556]
	TIME [epoch: 9.74 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0381867312523589		[learning rate: 0.00015895]
	Learning Rate: 0.000158951
	LOSS [training: 0.0381867312523589 | validation: 0.04484080920225193]
	TIME [epoch: 9.74 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03377728290579048		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.03377728290579048 | validation: 0.03799760164046869]
	TIME [epoch: 9.75 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04151492329100713		[learning rate: 0.00015818]
	Learning Rate: 0.000158182
	LOSS [training: 0.04151492329100713 | validation: 0.04602002276694631]
	TIME [epoch: 9.75 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031984416067688134		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.031984416067688134 | validation: 0.03137115815120097]
	TIME [epoch: 9.73 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03856791377326707		[learning rate: 0.00015742]
	Learning Rate: 0.000157417
	LOSS [training: 0.03856791377326707 | validation: 0.04526357975217853]
	TIME [epoch: 9.74 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04023766148316643		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.04023766148316643 | validation: 0.05338601105131387]
	TIME [epoch: 9.75 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03469793239322856		[learning rate: 0.00015666]
	Learning Rate: 0.000156656
	LOSS [training: 0.03469793239322856 | validation: 0.03925625249568124]
	TIME [epoch: 9.74 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03918142706729162		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.03918142706729162 | validation: 0.03715998311280666]
	TIME [epoch: 9.74 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03363201015600014		[learning rate: 0.0001559]
	Learning Rate: 0.000155899
	LOSS [training: 0.03363201015600014 | validation: 0.04120328956427838]
	TIME [epoch: 9.75 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0312769930132664		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.0312769930132664 | validation: 0.02941837785945639]
	TIME [epoch: 9.75 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03934691730673192		[learning rate: 0.00015514]
	Learning Rate: 0.000155145
	LOSS [training: 0.03934691730673192 | validation: 0.04395128068288857]
	TIME [epoch: 9.74 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03742777769358406		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.03742777769358406 | validation: 0.0226295758879167]
	TIME [epoch: 9.76 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03699644351745558		[learning rate: 0.00015439]
	Learning Rate: 0.000154394
	LOSS [training: 0.03699644351745558 | validation: 0.03936468075979242]
	TIME [epoch: 9.75 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04004797522403314		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.04004797522403314 | validation: 0.041393716724978075]
	TIME [epoch: 9.74 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04156221527652916		[learning rate: 0.00015365]
	Learning Rate: 0.000153648
	LOSS [training: 0.04156221527652916 | validation: 0.027764618741784344]
	TIME [epoch: 9.75 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04107318355683874		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.04107318355683874 | validation: 0.04035596362277409]
	TIME [epoch: 9.74 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03419136579373723		[learning rate: 0.0001529]
	Learning Rate: 0.000152905
	LOSS [training: 0.03419136579373723 | validation: 0.032511882989123525]
	TIME [epoch: 9.75 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03228071349222648		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.03228071349222648 | validation: 0.029250984539930122]
	TIME [epoch: 9.75 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033618159394965166		[learning rate: 0.00015217]
	Learning Rate: 0.000152165
	LOSS [training: 0.033618159394965166 | validation: 0.04321424175187548]
	TIME [epoch: 9.74 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035605250769700655		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.035605250769700655 | validation: 0.03449012183509899]
	TIME [epoch: 9.74 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032709838715747876		[learning rate: 0.00015143]
	Learning Rate: 0.00015143
	LOSS [training: 0.032709838715747876 | validation: 0.05905241323066628]
	TIME [epoch: 9.76 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03765310796944891		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.03765310796944891 | validation: 0.0361417178413172]
	TIME [epoch: 9.74 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03710266521649206		[learning rate: 0.0001507]
	Learning Rate: 0.000150697
	LOSS [training: 0.03710266521649206 | validation: 0.02700192816199129]
	TIME [epoch: 9.73 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033816081930654635		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.033816081930654635 | validation: 0.052039343814768095]
	TIME [epoch: 9.76 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03068353013892715		[learning rate: 0.00014997]
	Learning Rate: 0.000149968
	LOSS [training: 0.03068353013892715 | validation: 0.049753264235091306]
	TIME [epoch: 9.74 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031224219403060267		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.031224219403060267 | validation: 0.04519500076346811]
	TIME [epoch: 9.73 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03148043302334639		[learning rate: 0.00014924]
	Learning Rate: 0.000149243
	LOSS [training: 0.03148043302334639 | validation: 0.03956838799380853]
	TIME [epoch: 9.75 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03438388813736339		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.03438388813736339 | validation: 0.050602818389924455]
	TIME [epoch: 9.73 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034512303253752735		[learning rate: 0.00014852]
	Learning Rate: 0.000148522
	LOSS [training: 0.034512303253752735 | validation: 0.036481524738278114]
	TIME [epoch: 9.73 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033455268139309435		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.033455268139309435 | validation: 0.039735237278118375]
	TIME [epoch: 9.75 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027029806422279784		[learning rate: 0.0001478]
	Learning Rate: 0.000147803
	LOSS [training: 0.027029806422279784 | validation: 0.032308254332550176]
	TIME [epoch: 9.73 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03031976041698678		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.03031976041698678 | validation: 0.023825367606665086]
	TIME [epoch: 9.74 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028830513808946183		[learning rate: 0.00014709]
	Learning Rate: 0.000147089
	LOSS [training: 0.028830513808946183 | validation: 0.02433466823430579]
	TIME [epoch: 9.74 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028017740182357465		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.028017740182357465 | validation: 0.03484705133472305]
	TIME [epoch: 9.74 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021435028154915627		[learning rate: 0.00014638]
	Learning Rate: 0.000146377
	LOSS [training: 0.021435028154915627 | validation: 0.031094397603433774]
	TIME [epoch: 9.73 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028874321739259697		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.028874321739259697 | validation: 0.034284717000225645]
	TIME [epoch: 9.74 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02788109471273259		[learning rate: 0.00014567]
	Learning Rate: 0.000145669
	LOSS [training: 0.02788109471273259 | validation: 0.03714163263353746]
	TIME [epoch: 9.73 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03175476099434835		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.03175476099434835 | validation: 0.045228580621294354]
	TIME [epoch: 9.73 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029631040738915815		[learning rate: 0.00014497]
	Learning Rate: 0.000144965
	LOSS [training: 0.029631040738915815 | validation: 0.05002043719645803]
	TIME [epoch: 9.73 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03548003193325998		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.03548003193325998 | validation: 0.04807340143864106]
	TIME [epoch: 9.74 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038928329200899406		[learning rate: 0.00014426]
	Learning Rate: 0.000144264
	LOSS [training: 0.038928329200899406 | validation: 0.05537150645676182]
	TIME [epoch: 9.73 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03445399297898609		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.03445399297898609 | validation: 0.03637696183778136]
	TIME [epoch: 9.74 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03939215473937484		[learning rate: 0.00014357]
	Learning Rate: 0.000143566
	LOSS [training: 0.03939215473937484 | validation: 0.0522097286470189]
	TIME [epoch: 9.75 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029261357762443353		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.029261357762443353 | validation: 0.04874175519729843]
	TIME [epoch: 9.74 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02969491908953218		[learning rate: 0.00014287]
	Learning Rate: 0.000142872
	LOSS [training: 0.02969491908953218 | validation: 0.043860915107027935]
	TIME [epoch: 9.73 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03113529398207397		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.03113529398207397 | validation: 0.03209531550507088]
	TIME [epoch: 9.75 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03316337599597782		[learning rate: 0.00014218]
	Learning Rate: 0.000142181
	LOSS [training: 0.03316337599597782 | validation: 0.026643593069544523]
	TIME [epoch: 9.73 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02697158389376057		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.02697158389376057 | validation: 0.026902182044861764]
	TIME [epoch: 9.73 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028821469601941707		[learning rate: 0.00014149]
	Learning Rate: 0.000141494
	LOSS [training: 0.028821469601941707 | validation: 0.030689716537137885]
	TIME [epoch: 9.75 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029866093074109527		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.029866093074109527 | validation: 0.03273754979039174]
	TIME [epoch: 9.74 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02269949073249432		[learning rate: 0.00014081]
	Learning Rate: 0.000140809
	LOSS [training: 0.02269949073249432 | validation: 0.03205128994748204]
	TIME [epoch: 9.73 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022230101746978932		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.022230101746978932 | validation: 0.0339413961492872]
	TIME [epoch: 9.75 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02874144247215994		[learning rate: 0.00014013]
	Learning Rate: 0.000140128
	LOSS [training: 0.02874144247215994 | validation: 0.02765809986905503]
	TIME [epoch: 9.73 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024147717815075187		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.024147717815075187 | validation: 0.03460648468527058]
	TIME [epoch: 9.73 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029710859925025583		[learning rate: 0.00013945]
	Learning Rate: 0.000139451
	LOSS [training: 0.029710859925025583 | validation: 0.03319809844510128]
	TIME [epoch: 9.75 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025841440886696286		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.025841440886696286 | validation: 0.035569141368886746]
	TIME [epoch: 9.74 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029085514755998076		[learning rate: 0.00013878]
	Learning Rate: 0.000138776
	LOSS [training: 0.029085514755998076 | validation: 0.04263281378165438]
	TIME [epoch: 9.74 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03834602219898776		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.03834602219898776 | validation: 0.04834184464743514]
	TIME [epoch: 9.76 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03732614368787559		[learning rate: 0.00013811]
	Learning Rate: 0.000138105
	LOSS [training: 0.03732614368787559 | validation: 0.047817412548649435]
	TIME [epoch: 9.75 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032417778812249984		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.032417778812249984 | validation: 0.048752294395692654]
	TIME [epoch: 9.74 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033425485208326555		[learning rate: 0.00013744]
	Learning Rate: 0.000137437
	LOSS [training: 0.033425485208326555 | validation: 0.04943207746333104]
	TIME [epoch: 9.76 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03849821206855716		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.03849821206855716 | validation: 0.04876445432724008]
	TIME [epoch: 9.75 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04031055391282205		[learning rate: 0.00013677]
	Learning Rate: 0.000136773
	LOSS [training: 0.04031055391282205 | validation: 0.043052928639301644]
	TIME [epoch: 9.74 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0426306750796838		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.0426306750796838 | validation: 0.04545062210672171]
	TIME [epoch: 9.75 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04159546596039827		[learning rate: 0.00013611]
	Learning Rate: 0.000136111
	LOSS [training: 0.04159546596039827 | validation: 0.0496282126506606]
	TIME [epoch: 9.74 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04139042615785263		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.04139042615785263 | validation: 0.03918273404711267]
	TIME [epoch: 9.74 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04466275228824658		[learning rate: 0.00013545]
	Learning Rate: 0.000135453
	LOSS [training: 0.04466275228824658 | validation: 0.06253087693720472]
	TIME [epoch: 9.75 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04496797887940007		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.04496797887940007 | validation: 0.0580193051198261]
	TIME [epoch: 9.75 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04045004493029193		[learning rate: 0.0001348]
	Learning Rate: 0.000134798
	LOSS [training: 0.04045004493029193 | validation: 0.048014349767113024]
	TIME [epoch: 9.75 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04128138489245685		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.04128138489245685 | validation: 0.04470492386548742]
	TIME [epoch: 9.75 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033756349966429754		[learning rate: 0.00013415]
	Learning Rate: 0.000134146
	LOSS [training: 0.033756349966429754 | validation: 0.0344431079816719]
	TIME [epoch: 9.73 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03276127776588401		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.03276127776588401 | validation: 0.048116822729317374]
	TIME [epoch: 9.74 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03537003016602798		[learning rate: 0.0001335]
	Learning Rate: 0.000133498
	LOSS [training: 0.03537003016602798 | validation: 0.047508114392287554]
	TIME [epoch: 9.74 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039516219192293374		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.039516219192293374 | validation: 0.05476896037872178]
	TIME [epoch: 9.76 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03580211606762294		[learning rate: 0.00013285]
	Learning Rate: 0.000132852
	LOSS [training: 0.03580211606762294 | validation: 0.054077590597014925]
	TIME [epoch: 9.74 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038309185551883285		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.038309185551883285 | validation: 0.04178561531844254]
	TIME [epoch: 9.76 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030185358153659934		[learning rate: 0.00013221]
	Learning Rate: 0.00013221
	LOSS [training: 0.030185358153659934 | validation: 0.041445184467605756]
	TIME [epoch: 9.76 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03360326632065995		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.03360326632065995 | validation: 0.04971939044112851]
	TIME [epoch: 9.75 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026121524706499873		[learning rate: 0.00013157]
	Learning Rate: 0.00013157
	LOSS [training: 0.026121524706499873 | validation: 0.04992232783349809]
	TIME [epoch: 9.74 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03455956950021923		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.03455956950021923 | validation: 0.039756655974709794]
	TIME [epoch: 9.77 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02704200280434387		[learning rate: 0.00013093]
	Learning Rate: 0.000130934
	LOSS [training: 0.02704200280434387 | validation: 0.034191429768037095]
	TIME [epoch: 9.73 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028085366054689913		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.028085366054689913 | validation: 0.04232424356112798]
	TIME [epoch: 9.74 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031470115759170414		[learning rate: 0.0001303]
	Learning Rate: 0.000130301
	LOSS [training: 0.031470115759170414 | validation: 0.032235008579221555]
	TIME [epoch: 9.77 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027341811444826235		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.027341811444826235 | validation: 0.044727837793533835]
	TIME [epoch: 9.74 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022274624595244197		[learning rate: 0.00012967]
	Learning Rate: 0.000129671
	LOSS [training: 0.022274624595244197 | validation: 0.03521161027868086]
	TIME [epoch: 9.74 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026689248242746953		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.026689248242746953 | validation: 0.0294805828714902]
	TIME [epoch: 9.77 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027434422681318783		[learning rate: 0.00012904]
	Learning Rate: 0.000129044
	LOSS [training: 0.027434422681318783 | validation: 0.03391446750746587]
	TIME [epoch: 9.74 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022791458463598608		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.022791458463598608 | validation: 0.034230375636773294]
	TIME [epoch: 9.75 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02539646220720763		[learning rate: 0.00012842]
	Learning Rate: 0.00012842
	LOSS [training: 0.02539646220720763 | validation: 0.027423166337441476]
	TIME [epoch: 9.76 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024999318258523483		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.024999318258523483 | validation: 0.042690775618874695]
	TIME [epoch: 9.75 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033004229299813025		[learning rate: 0.0001278]
	Learning Rate: 0.000127799
	LOSS [training: 0.033004229299813025 | validation: 0.02571609722879184]
	TIME [epoch: 9.75 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025229484465998087		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.025229484465998087 | validation: 0.03398116271504542]
	TIME [epoch: 9.75 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0273058023125086		[learning rate: 0.00012718]
	Learning Rate: 0.000127181
	LOSS [training: 0.0273058023125086 | validation: 0.0332268132409456]
	TIME [epoch: 9.74 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031231978351455907		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.031231978351455907 | validation: 0.04191310280994066]
	TIME [epoch: 9.75 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026195779412226457		[learning rate: 0.00012657]
	Learning Rate: 0.000126566
	LOSS [training: 0.026195779412226457 | validation: 0.042946061074550464]
	TIME [epoch: 9.76 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02853480937960328		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.02853480937960328 | validation: 0.04502604444848157]
	TIME [epoch: 9.75 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029444695481480692		[learning rate: 0.00012595]
	Learning Rate: 0.000125954
	LOSS [training: 0.029444695481480692 | validation: 0.03855488212284747]
	TIME [epoch: 9.73 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027603796162241206		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.027603796162241206 | validation: 0.03926049524044612]
	TIME [epoch: 9.75 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03138658462873985		[learning rate: 0.00012534]
	Learning Rate: 0.000125345
	LOSS [training: 0.03138658462873985 | validation: 0.04668612657510792]
	TIME [epoch: 9.75 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027961602295932753		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.027961602295932753 | validation: 0.03381690986089253]
	TIME [epoch: 9.74 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03042763282960679		[learning rate: 0.00012474]
	Learning Rate: 0.000124738
	LOSS [training: 0.03042763282960679 | validation: 0.03501058485095333]
	TIME [epoch: 9.76 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03504114035222018		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.03504114035222018 | validation: 0.04975843328603867]
	TIME [epoch: 9.73 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03305197890372424		[learning rate: 0.00012414]
	Learning Rate: 0.000124135
	LOSS [training: 0.03305197890372424 | validation: 0.04475858354973001]
	TIME [epoch: 9.74 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029179701372359822		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.029179701372359822 | validation: 0.03132179423346337]
	TIME [epoch: 9.75 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03260800176146753		[learning rate: 0.00012353]
	Learning Rate: 0.000123535
	LOSS [training: 0.03260800176146753 | validation: 0.05310430887208763]
	TIME [epoch: 9.74 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03631276456612514		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.03631276456612514 | validation: 0.035310368276466685]
	TIME [epoch: 9.74 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030400304964454138		[learning rate: 0.00012294]
	Learning Rate: 0.000122937
	LOSS [training: 0.030400304964454138 | validation: 0.04240913285685188]
	TIME [epoch: 9.75 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030583649059608958		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.030583649059608958 | validation: 0.0335214509779211]
	TIME [epoch: 9.75 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029715005400826333		[learning rate: 0.00012234]
	Learning Rate: 0.000122343
	LOSS [training: 0.029715005400826333 | validation: 0.028613294661683497]
	TIME [epoch: 9.73 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026555282762932297		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.026555282762932297 | validation: 0.03280513370735254]
	TIME [epoch: 9.74 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025900335738753093		[learning rate: 0.00012175]
	Learning Rate: 0.000121751
	LOSS [training: 0.025900335738753093 | validation: 0.04113150953585849]
	TIME [epoch: 9.75 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0314747000973906		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.0314747000973906 | validation: 0.034536127853557794]
	TIME [epoch: 9.74 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030728379115338		[learning rate: 0.00012116]
	Learning Rate: 0.000121163
	LOSS [training: 0.030728379115338 | validation: 0.027220729977156452]
	TIME [epoch: 9.75 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0347155982914014		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.0347155982914014 | validation: 0.03381964426931337]
	TIME [epoch: 9.75 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037508267535971994		[learning rate: 0.00012058]
	Learning Rate: 0.000120577
	LOSS [training: 0.037508267535971994 | validation: 0.03756643879206309]
	TIME [epoch: 9.73 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02342822229101386		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.02342822229101386 | validation: 0.04083144542738817]
	TIME [epoch: 9.74 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028338378601490403		[learning rate: 0.00011999]
	Learning Rate: 0.000119994
	LOSS [training: 0.028338378601490403 | validation: 0.033017423335421875]
	TIME [epoch: 9.76 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03194911183061558		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.03194911183061558 | validation: 0.023960513738472588]
	TIME [epoch: 9.74 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029075659727690877		[learning rate: 0.00011941]
	Learning Rate: 0.000119413
	LOSS [training: 0.029075659727690877 | validation: 0.025640197282210054]
	TIME [epoch: 9.74 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02912638164510293		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.02912638164510293 | validation: 0.028320568836801053]
	TIME [epoch: 9.75 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028170550270708073		[learning rate: 0.00011884]
	Learning Rate: 0.000118836
	LOSS [training: 0.028170550270708073 | validation: 0.03234563630863301]
	TIME [epoch: 9.72 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03303418179792293		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.03303418179792293 | validation: 0.026444085071938288]
	TIME [epoch: 9.73 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030105187338212814		[learning rate: 0.00011826]
	Learning Rate: 0.000118261
	LOSS [training: 0.030105187338212814 | validation: 0.03064015923201882]
	TIME [epoch: 9.75 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023162453794926423		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.023162453794926423 | validation: 0.027788605350342777]
	TIME [epoch: 9.73 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02585217182259033		[learning rate: 0.00011769]
	Learning Rate: 0.000117689
	LOSS [training: 0.02585217182259033 | validation: 0.03560326824519478]
	TIME [epoch: 9.73 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030782077197674097		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.030782077197674097 | validation: 0.02288751400531504]
	TIME [epoch: 9.75 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031417448596054054		[learning rate: 0.00011712]
	Learning Rate: 0.00011712
	LOSS [training: 0.031417448596054054 | validation: 0.034357483230164666]
	TIME [epoch: 9.75 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03015518135492328		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.03015518135492328 | validation: 0.02186497123070005]
	TIME [epoch: 9.75 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0293888615488616		[learning rate: 0.00011655]
	Learning Rate: 0.000116554
	LOSS [training: 0.0293888615488616 | validation: 0.02247799829710689]
	TIME [epoch: 9.75 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029145376937030492		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.029145376937030492 | validation: 0.03325550954502339]
	TIME [epoch: 9.74 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023604669978709646		[learning rate: 0.00011599]
	Learning Rate: 0.00011599
	LOSS [training: 0.023604669978709646 | validation: 0.028179783545796075]
	TIME [epoch: 9.74 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024640599705775777		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.024640599705775777 | validation: 0.031311988039531585]
	TIME [epoch: 9.76 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02342436512430801		[learning rate: 0.00011543]
	Learning Rate: 0.000115429
	LOSS [training: 0.02342436512430801 | validation: 0.03116948979135623]
	TIME [epoch: 9.74 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019602751647334084		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.019602751647334084 | validation: 0.03204897810471426]
	TIME [epoch: 9.73 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025812010906184353		[learning rate: 0.00011487]
	Learning Rate: 0.000114871
	LOSS [training: 0.025812010906184353 | validation: 0.03415056808846293]
	TIME [epoch: 9.75 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025921316742154827		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.025921316742154827 | validation: 0.025055709919375727]
	TIME [epoch: 9.76 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026209962307883715		[learning rate: 0.00011432]
	Learning Rate: 0.000114316
	LOSS [training: 0.026209962307883715 | validation: 0.023669364136583295]
	TIME [epoch: 9.75 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024020787635373072		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.024020787635373072 | validation: 0.04471577968293967]
	TIME [epoch: 9.76 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027447033425508992		[learning rate: 0.00011376]
	Learning Rate: 0.000113763
	LOSS [training: 0.027447033425508992 | validation: 0.035405844360025314]
	TIME [epoch: 9.75 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024725345607685585		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.024725345607685585 | validation: 0.027834638876450015]
	TIME [epoch: 9.74 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031669565996672394		[learning rate: 0.00011321]
	Learning Rate: 0.000113213
	LOSS [training: 0.031669565996672394 | validation: 0.020124097655082416]
	TIME [epoch: 9.75 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029551778571453795		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.029551778571453795 | validation: 0.03898754812291136]
	TIME [epoch: 9.75 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03104662876637084		[learning rate: 0.00011267]
	Learning Rate: 0.000112665
	LOSS [training: 0.03104662876637084 | validation: 0.03672705016352764]
	TIME [epoch: 9.73 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03278108708783525		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.03278108708783525 | validation: 0.035685852747606175]
	TIME [epoch: 9.74 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040527651359106985		[learning rate: 0.00011212]
	Learning Rate: 0.00011212
	LOSS [training: 0.040527651359106985 | validation: 0.03456509950404923]
	TIME [epoch: 9.74 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03172242231822871		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.03172242231822871 | validation: 0.017917691482650457]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240219_183144/states/model_tr_study6_1954.pth
	Model improved!!!
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03212058040611784		[learning rate: 0.00011158]
	Learning Rate: 0.000111578
	LOSS [training: 0.03212058040611784 | validation: 0.03504835686731064]
	TIME [epoch: 9.76 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040508067766285155		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.040508067766285155 | validation: 0.03251468446120713]
	TIME [epoch: 9.8 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03768466717214612		[learning rate: 0.00011104]
	Learning Rate: 0.000111039
	LOSS [training: 0.03768466717214612 | validation: 0.046874505760365184]
	TIME [epoch: 9.77 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03980526711815987		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.03980526711815987 | validation: 0.0501690994186843]
	TIME [epoch: 9.77 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04287869166547879		[learning rate: 0.0001105]
	Learning Rate: 0.000110502
	LOSS [training: 0.04287869166547879 | validation: 0.05519599208786174]
	TIME [epoch: 9.76 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03693459886054362		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.03693459886054362 | validation: 0.03881135229769258]
	TIME [epoch: 9.75 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034056768001655566		[learning rate: 0.00010997]
	Learning Rate: 0.000109967
	LOSS [training: 0.034056768001655566 | validation: 0.03356998217001256]
	TIME [epoch: 9.77 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03142211148571542		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.03142211148571542 | validation: 0.038972818827607086]
	TIME [epoch: 9.77 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036197737928457055		[learning rate: 0.00010944]
	Learning Rate: 0.000109435
	LOSS [training: 0.036197737928457055 | validation: 0.03754001102852344]
	TIME [epoch: 9.74 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04228355541222091		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.04228355541222091 | validation: 0.0422810597002981]
	TIME [epoch: 9.76 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030893321225347874		[learning rate: 0.00010891]
	Learning Rate: 0.000108906
	LOSS [training: 0.030893321225347874 | validation: 0.045987741983107816]
	TIME [epoch: 9.77 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03583294295125104		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.03583294295125104 | validation: 0.03486900823439298]
	TIME [epoch: 9.75 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03213360802107165		[learning rate: 0.00010838]
	Learning Rate: 0.00010838
	LOSS [training: 0.03213360802107165 | validation: 0.03827282402221728]
	TIME [epoch: 9.74 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03860483399223681		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.03860483399223681 | validation: 0.038681247271192765]
	TIME [epoch: 9.76 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03382870358186661		[learning rate: 0.00010786]
	Learning Rate: 0.000107855
	LOSS [training: 0.03382870358186661 | validation: 0.0355563631989036]
	TIME [epoch: 9.74 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029351628294607097		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.029351628294607097 | validation: 0.018216963988874336]
	TIME [epoch: 9.75 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031573980631798934		[learning rate: 0.00010733]
	Learning Rate: 0.000107334
	LOSS [training: 0.031573980631798934 | validation: 0.025196640499223346]
	TIME [epoch: 9.76 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03561942524899281		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.03561942524899281 | validation: 0.030654499006186102]
	TIME [epoch: 9.75 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033898312216661425		[learning rate: 0.00010681]
	Learning Rate: 0.000106815
	LOSS [training: 0.033898312216661425 | validation: 0.03383565722308265]
	TIME [epoch: 9.73 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0291558004875758		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.0291558004875758 | validation: 0.03358226757496463]
	TIME [epoch: 9.75 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02499433040475828		[learning rate: 0.0001063]
	Learning Rate: 0.000106298
	LOSS [training: 0.02499433040475828 | validation: 0.03241980255680074]
	TIME [epoch: 9.73 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018927409355905495		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.018927409355905495 | validation: 0.02201928630036203]
	TIME [epoch: 9.74 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030441263590292263		[learning rate: 0.00010578]
	Learning Rate: 0.000105784
	LOSS [training: 0.030441263590292263 | validation: 0.03406858573664729]
	TIME [epoch: 9.74 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028104211775545174		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.028104211775545174 | validation: 0.03263139658798339]
	TIME [epoch: 9.74 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029234551131333174		[learning rate: 0.00010527]
	Learning Rate: 0.000105273
	LOSS [training: 0.029234551131333174 | validation: 0.044593210172809476]
	TIME [epoch: 9.75 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033132686474305936		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.033132686474305936 | validation: 0.03602954319146133]
	TIME [epoch: 9.76 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027940343623484055		[learning rate: 0.00010476]
	Learning Rate: 0.000104764
	LOSS [training: 0.027940343623484055 | validation: 0.029420310493086417]
	TIME [epoch: 9.74 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03174313337574559		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.03174313337574559 | validation: 0.035596930747657574]
	TIME [epoch: 9.74 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031194172665860588		[learning rate: 0.00010426]
	Learning Rate: 0.000104257
	LOSS [training: 0.031194172665860588 | validation: 0.025192664145341572]
	TIME [epoch: 9.76 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024507854650716743		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.024507854650716743 | validation: 0.03217506925885246]
	TIME [epoch: 9.73 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02757630627226202		[learning rate: 0.00010375]
	Learning Rate: 0.000103753
	LOSS [training: 0.02757630627226202 | validation: 0.0358727523198019]
	TIME [epoch: 9.72 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02366060225539609		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.02366060225539609 | validation: 0.029578978075947573]
	TIME [epoch: 9.75 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026455401855496212		[learning rate: 0.00010325]
	Learning Rate: 0.000103251
	LOSS [training: 0.026455401855496212 | validation: 0.04336081629171258]
	TIME [epoch: 9.73 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025341082092909584		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.025341082092909584 | validation: 0.019697354405030138]
	TIME [epoch: 9.74 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030550123241406553		[learning rate: 0.00010275]
	Learning Rate: 0.000102752
	LOSS [training: 0.030550123241406553 | validation: 0.035972631003926954]
	TIME [epoch: 9.74 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030085874899847997		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.030085874899847997 | validation: 0.029847015212705046]
	TIME [epoch: 9.74 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02523115237842912		[learning rate: 0.00010225]
	Learning Rate: 0.000102255
	LOSS [training: 0.02523115237842912 | validation: 0.04412641281487624]
	TIME [epoch: 9.73 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026901559782037215		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.026901559782037215 | validation: 0.0285131674061135]
	TIME [epoch: 9.75 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02462409128593253		[learning rate: 0.00010176]
	Learning Rate: 0.00010176
	LOSS [training: 0.02462409128593253 | validation: 0.042734677773187624]
	TIME [epoch: 9.72 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02943968739691688		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.02943968739691688 | validation: 0.028216676623142315]
	TIME [epoch: 9.73 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03374324870056594		[learning rate: 0.00010127]
	Learning Rate: 0.000101268
	LOSS [training: 0.03374324870056594 | validation: 0.03914059336609357]
	TIME [epoch: 9.74 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032657688128958716		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.032657688128958716 | validation: 0.037303523579523996]
	TIME [epoch: 9.74 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024050111042230603		[learning rate: 0.00010078]
	Learning Rate: 0.000100779
	LOSS [training: 0.024050111042230603 | validation: 0.034713308530455705]
	TIME [epoch: 9.72 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030479453056427325		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.030479453056427325 | validation: 0.042140718029661954]
	TIME [epoch: 9.72 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036178893088633396		[learning rate: 0.00010029]
	Learning Rate: 0.000100291
	LOSS [training: 0.036178893088633396 | validation: 0.04674322681865701]
	TIME [epoch: 9.75 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03153301376085195		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.03153301376085195 | validation: 0.04081660052182757]
	TIME [epoch: 9.75 sec]
Finished training in 19637.367 seconds.
