Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r1', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 178220930

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 5/5] avg loss: 9.11700545361702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.11700545361702 | validation: 10.099712560570785]
	TIME [epoch: 49.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 5/5] avg loss: 9.0825490582903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.0825490582903 | validation: 9.220107069839166]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 5/5] avg loss: 8.35570212509862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.35570212509862 | validation: 9.005062535895243]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 5/5] avg loss: 7.624670156583844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.624670156583844 | validation: 8.340812851115718]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 5/5] avg loss: 7.188763588327726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.188763588327726 | validation: 7.99149075170078]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 5/5] avg loss: 6.911208953407375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.911208953407375 | validation: 7.776424166042005]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 5/5] avg loss: 6.677464535617489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.677464535617489 | validation: 7.777019366330833]
	TIME [epoch: 10.4 sec]
EPOCH 8/500:
	Training over batches...
		[batch 5/5] avg loss: 6.57473064769852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.57473064769852 | validation: 7.435316774877025]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 5/5] avg loss: 6.539976232250849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.539976232250849 | validation: 7.321752731707224]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 5/5] avg loss: 6.365133665231577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.365133665231577 | validation: 7.222998112715447]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 5/5] avg loss: 6.28232091165744		[learning rate: 0.0099625]
	Learning Rate: 0.00996248
	LOSS [training: 6.28232091165744 | validation: 7.193708017480406]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 5/5] avg loss: 6.357412773646181		[learning rate: 0.0099158]
	Learning Rate: 0.00991577
	LOSS [training: 6.357412773646181 | validation: 7.183317674350091]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 5/5] avg loss: 6.2583200673510735		[learning rate: 0.0098693]
	Learning Rate: 0.00986928
	LOSS [training: 6.2583200673510735 | validation: 7.1147873951300005]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 5/5] avg loss: 6.187395196170493		[learning rate: 0.009823]
	Learning Rate: 0.00982302
	LOSS [training: 6.187395196170493 | validation: 7.089221065018745]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 5/5] avg loss: 6.171035519030544		[learning rate: 0.009777]
	Learning Rate: 0.00977696
	LOSS [training: 6.171035519030544 | validation: 7.061554651306659]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 5/5] avg loss: 6.216223384476312		[learning rate: 0.0097311]
	Learning Rate: 0.00973113
	LOSS [training: 6.216223384476312 | validation: 7.082616104522947]
	TIME [epoch: 10.4 sec]
EPOCH 17/500:
	Training over batches...
		[batch 5/5] avg loss: 6.14286221265265		[learning rate: 0.0096855]
	Learning Rate: 0.00968551
	LOSS [training: 6.14286221265265 | validation: 7.0650185066526525]
	TIME [epoch: 10.4 sec]
EPOCH 18/500:
	Training over batches...
		[batch 5/5] avg loss: 6.122582150604482		[learning rate: 0.0096401]
	Learning Rate: 0.0096401
	LOSS [training: 6.122582150604482 | validation: 7.015406239739557]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 5/5] avg loss: 6.250629791640646		[learning rate: 0.0095949]
	Learning Rate: 0.00959491
	LOSS [training: 6.250629791640646 | validation: 6.992862259635594]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 5/5] avg loss: 6.066129244271132		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 6.066129244271132 | validation: 7.00440973459386]
	TIME [epoch: 10.4 sec]
EPOCH 21/500:
	Training over batches...
		[batch 5/5] avg loss: 5.782155628648101		[learning rate: 0.0095052]
	Learning Rate: 0.00950515
	LOSS [training: 5.782155628648101 | validation: 6.3054145600265565]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 5/5] avg loss: 5.048512670943863		[learning rate: 0.0094606]
	Learning Rate: 0.00946059
	LOSS [training: 5.048512670943863 | validation: 5.222519124878156]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 5/5] avg loss: 4.491985757990927		[learning rate: 0.0094162]
	Learning Rate: 0.00941624
	LOSS [training: 4.491985757990927 | validation: 4.492841256690869]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 5/5] avg loss: 4.230715736797015		[learning rate: 0.0093721]
	Learning Rate: 0.0093721
	LOSS [training: 4.230715736797015 | validation: 4.222143520787426]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 5/5] avg loss: 3.768003893399399		[learning rate: 0.0093282]
	Learning Rate: 0.00932816
	LOSS [training: 3.768003893399399 | validation: 5.788725433220758]
	TIME [epoch: 10.4 sec]
EPOCH 26/500:
	Training over batches...
		[batch 5/5] avg loss: 6.101915661458207		[learning rate: 0.0092844]
	Learning Rate: 0.00928443
	LOSS [training: 6.101915661458207 | validation: 5.60086759357908]
	TIME [epoch: 10.4 sec]
EPOCH 27/500:
	Training over batches...
		[batch 5/5] avg loss: 4.131820311488194		[learning rate: 0.0092409]
	Learning Rate: 0.0092409
	LOSS [training: 4.131820311488194 | validation: 3.839798124250596]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5491168580368333		[learning rate: 0.0091976]
	Learning Rate: 0.00919758
	LOSS [training: 3.5491168580368333 | validation: 3.483570764178352]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5521988825827107		[learning rate: 0.0091545]
	Learning Rate: 0.00915446
	LOSS [training: 3.5521988825827107 | validation: 4.728751977511483]
	TIME [epoch: 10.4 sec]
EPOCH 30/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9455692492821344		[learning rate: 0.0091115]
	Learning Rate: 0.00911154
	LOSS [training: 3.9455692492821344 | validation: 3.8157800483867605]
	TIME [epoch: 10.4 sec]
EPOCH 31/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4834046068635374		[learning rate: 0.0090688]
	Learning Rate: 0.00906882
	LOSS [training: 3.4834046068635374 | validation: 3.3091628253241847]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 5/5] avg loss: 3.56217369355124		[learning rate: 0.0090263]
	Learning Rate: 0.00902631
	LOSS [training: 3.56217369355124 | validation: 3.3095374452958493]
	TIME [epoch: 10.4 sec]
EPOCH 33/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3998987562013645		[learning rate: 0.008984]
	Learning Rate: 0.00898399
	LOSS [training: 3.3998987562013645 | validation: 3.3516522478143163]
	TIME [epoch: 10.4 sec]
EPOCH 34/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3245933557364333		[learning rate: 0.0089419]
	Learning Rate: 0.00894187
	LOSS [training: 3.3245933557364333 | validation: 3.6434875509221456]
	TIME [epoch: 10.4 sec]
EPOCH 35/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3472294479935605		[learning rate: 0.0089]
	Learning Rate: 0.00889995
	LOSS [training: 3.3472294479935605 | validation: 3.1220639444122926]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 5/5] avg loss: 3.291778863427097		[learning rate: 0.0088582]
	Learning Rate: 0.00885823
	LOSS [training: 3.291778863427097 | validation: 3.3679719418830643]
	TIME [epoch: 10.4 sec]
EPOCH 37/500:
	Training over batches...
		[batch 5/5] avg loss: 3.242154543958288		[learning rate: 0.0088167]
	Learning Rate: 0.0088167
	LOSS [training: 3.242154543958288 | validation: 3.207307111975232]
	TIME [epoch: 10.3 sec]
EPOCH 38/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5289698646951835		[learning rate: 0.0087754]
	Learning Rate: 0.00877537
	LOSS [training: 3.5289698646951835 | validation: 3.4233575645038936]
	TIME [epoch: 10.4 sec]
EPOCH 39/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1878823425964478		[learning rate: 0.0087342]
	Learning Rate: 0.00873423
	LOSS [training: 3.1878823425964478 | validation: 3.778159856123923]
	TIME [epoch: 10.4 sec]
EPOCH 40/500:
	Training over batches...
		[batch 5/5] avg loss: 4.551205425737787		[learning rate: 0.0086933]
	Learning Rate: 0.00869328
	LOSS [training: 4.551205425737787 | validation: 4.836855720018186]
	TIME [epoch: 10.4 sec]
EPOCH 41/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6532831749274663		[learning rate: 0.0086525]
	Learning Rate: 0.00865253
	LOSS [training: 3.6532831749274663 | validation: 3.1678447655823674]
	TIME [epoch: 10.4 sec]
EPOCH 42/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2379873704439093		[learning rate: 0.008612]
	Learning Rate: 0.00861196
	LOSS [training: 3.2379873704439093 | validation: 2.8829940201494435]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0681005009705786		[learning rate: 0.0085716]
	Learning Rate: 0.00857159
	LOSS [training: 3.0681005009705786 | validation: 4.499534708654285]
	TIME [epoch: 10.4 sec]
EPOCH 44/500:
	Training over batches...
		[batch 5/5] avg loss: 3.412611695940897		[learning rate: 0.0085314]
	Learning Rate: 0.0085314
	LOSS [training: 3.412611695940897 | validation: 3.040674012865113]
	TIME [epoch: 10.4 sec]
EPOCH 45/500:
	Training over batches...
		[batch 5/5] avg loss: 2.9488778001602034		[learning rate: 0.0084914]
	Learning Rate: 0.00849141
	LOSS [training: 2.9488778001602034 | validation: 2.7800522601189632]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_45.pth
	Model improved!!!
EPOCH 46/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8817873207252998		[learning rate: 0.0084516]
	Learning Rate: 0.0084516
	LOSS [training: 2.8817873207252998 | validation: 2.6472809036735447]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8729273610485455		[learning rate: 0.008412]
	Learning Rate: 0.00841197
	LOSS [training: 2.8729273610485455 | validation: 2.9133592089145544]
	TIME [epoch: 10.4 sec]
EPOCH 48/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0364648045662346		[learning rate: 0.0083725]
	Learning Rate: 0.00837254
	LOSS [training: 3.0364648045662346 | validation: 2.616186583313846]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_48.pth
	Model improved!!!
EPOCH 49/500:
	Training over batches...
		[batch 5/5] avg loss: 2.580648347167334		[learning rate: 0.0083333]
	Learning Rate: 0.00833329
	LOSS [training: 2.580648347167334 | validation: 2.5982913269917707]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 5/5] avg loss: 2.71551775738084		[learning rate: 0.0082942]
	Learning Rate: 0.00829422
	LOSS [training: 2.71551775738084 | validation: 2.338019324933625]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_50.pth
	Model improved!!!
EPOCH 51/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2371094778326728		[learning rate: 0.0082553]
	Learning Rate: 0.00825533
	LOSS [training: 3.2371094778326728 | validation: 2.4024405335443366]
	TIME [epoch: 10.3 sec]
EPOCH 52/500:
	Training over batches...
		[batch 5/5] avg loss: 5.62534512620049		[learning rate: 0.0082166]
	Learning Rate: 0.00821663
	LOSS [training: 5.62534512620049 | validation: 5.4957634171076375]
	TIME [epoch: 10.3 sec]
EPOCH 53/500:
	Training over batches...
		[batch 5/5] avg loss: 4.528607474769014		[learning rate: 0.0081781]
	Learning Rate: 0.00817811
	LOSS [training: 4.528607474769014 | validation: 3.937282682632642]
	TIME [epoch: 10.4 sec]
EPOCH 54/500:
	Training over batches...
		[batch 5/5] avg loss: 4.411979602831922		[learning rate: 0.0081398]
	Learning Rate: 0.00813977
	LOSS [training: 4.411979602831922 | validation: 2.856953298107354]
	TIME [epoch: 10.3 sec]
EPOCH 55/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6569768033955494		[learning rate: 0.0081016]
	Learning Rate: 0.00810161
	LOSS [training: 2.6569768033955494 | validation: 2.2541606565377994]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_55.pth
	Model improved!!!
EPOCH 56/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4067290160477333		[learning rate: 0.0080636]
	Learning Rate: 0.00806363
	LOSS [training: 2.4067290160477333 | validation: 2.262037568432405]
	TIME [epoch: 10.4 sec]
EPOCH 57/500:
	Training over batches...
		[batch 5/5] avg loss: 2.618717735436367		[learning rate: 0.0080258]
	Learning Rate: 0.00802583
	LOSS [training: 2.618717735436367 | validation: 2.2780312617236214]
	TIME [epoch: 10.4 sec]
EPOCH 58/500:
	Training over batches...
		[batch 5/5] avg loss: 2.309245846402023		[learning rate: 0.0079882]
	Learning Rate: 0.0079882
	LOSS [training: 2.309245846402023 | validation: 2.615339466587091]
	TIME [epoch: 10.4 sec]
EPOCH 59/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3135343120968295		[learning rate: 0.0079508]
	Learning Rate: 0.00795075
	LOSS [training: 2.3135343120968295 | validation: 1.9817089229414222]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 5/5] avg loss: 2.82936737321795		[learning rate: 0.0079135]
	Learning Rate: 0.00791348
	LOSS [training: 2.82936737321795 | validation: 2.1781335870126286]
	TIME [epoch: 10.4 sec]
EPOCH 61/500:
	Training over batches...
		[batch 5/5] avg loss: 2.24078231080366		[learning rate: 0.0078764]
	Learning Rate: 0.00787638
	LOSS [training: 2.24078231080366 | validation: 2.260866978682583]
	TIME [epoch: 10.4 sec]
EPOCH 62/500:
	Training over batches...
		[batch 5/5] avg loss: 2.235557270180741		[learning rate: 0.0078395]
	Learning Rate: 0.00783945
	LOSS [training: 2.235557270180741 | validation: 1.8829690243956239]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6550844570241763		[learning rate: 0.0078027]
	Learning Rate: 0.0078027
	LOSS [training: 2.6550844570241763 | validation: 2.204926240431795]
	TIME [epoch: 10.4 sec]
EPOCH 64/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1668696709338593		[learning rate: 0.0077661]
	Learning Rate: 0.00776612
	LOSS [training: 2.1668696709338593 | validation: 2.015555907277803]
	TIME [epoch: 10.4 sec]
EPOCH 65/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9399579968285778		[learning rate: 0.0077297]
	Learning Rate: 0.00772971
	LOSS [training: 1.9399579968285778 | validation: 1.6954821359934744]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7510961812223313		[learning rate: 0.0076935]
	Learning Rate: 0.00769347
	LOSS [training: 1.7510961812223313 | validation: 1.6703553659785046]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_66.pth
	Model improved!!!
EPOCH 67/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7830261132839174		[learning rate: 0.0076574]
	Learning Rate: 0.0076574
	LOSS [training: 1.7830261132839174 | validation: 1.67355693103624]
	TIME [epoch: 10.4 sec]
EPOCH 68/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6133837174278163		[learning rate: 0.0076215]
	Learning Rate: 0.00762151
	LOSS [training: 1.6133837174278163 | validation: 1.5701183863645827]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_68.pth
	Model improved!!!
EPOCH 69/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9243421953071373		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 1.9243421953071373 | validation: 1.6924861332420473]
	TIME [epoch: 10.4 sec]
EPOCH 70/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5943348659708168		[learning rate: 0.0075502]
	Learning Rate: 0.00755021
	LOSS [training: 1.5943348659708168 | validation: 1.2972353026799797]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_70.pth
	Model improved!!!
EPOCH 71/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4082986242315187		[learning rate: 0.0075148]
	Learning Rate: 0.00751482
	LOSS [training: 1.4082986242315187 | validation: 1.1746506841155313]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_71.pth
	Model improved!!!
EPOCH 72/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4923722613020567		[learning rate: 0.0074796]
	Learning Rate: 0.00747959
	LOSS [training: 1.4923722613020567 | validation: 1.1852551024290248]
	TIME [epoch: 10.4 sec]
EPOCH 73/500:
	Training over batches...
		[batch 5/5] avg loss: 1.222582322045658		[learning rate: 0.0074445]
	Learning Rate: 0.00744452
	LOSS [training: 1.222582322045658 | validation: 1.1873964540601458]
	TIME [epoch: 10.4 sec]
EPOCH 74/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1135237410881664		[learning rate: 0.0074096]
	Learning Rate: 0.00740962
	LOSS [training: 1.1135237410881664 | validation: 0.8982584840537703]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_74.pth
	Model improved!!!
EPOCH 75/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0684285515268752		[learning rate: 0.0073749]
	Learning Rate: 0.00737488
	LOSS [training: 1.0684285515268752 | validation: 1.0350623397941445]
	TIME [epoch: 10.4 sec]
EPOCH 76/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9959791215563236		[learning rate: 0.0073403]
	Learning Rate: 0.00734031
	LOSS [training: 0.9959791215563236 | validation: 0.8714541551675034]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_76.pth
	Model improved!!!
EPOCH 77/500:
	Training over batches...
		[batch 5/5] avg loss: 1.000313904608294		[learning rate: 0.0073059]
	Learning Rate: 0.00730589
	LOSS [training: 1.000313904608294 | validation: 1.0188331341457206]
	TIME [epoch: 10.4 sec]
EPOCH 78/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9429487677085012		[learning rate: 0.0072716]
	Learning Rate: 0.00727164
	LOSS [training: 0.9429487677085012 | validation: 1.166971310371161]
	TIME [epoch: 10.4 sec]
EPOCH 79/500:
	Training over batches...
		[batch 5/5] avg loss: 1.511314616114579		[learning rate: 0.0072376]
	Learning Rate: 0.00723755
	LOSS [training: 1.511314616114579 | validation: 0.8677695985971456]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_79.pth
	Model improved!!!
EPOCH 80/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9728479741007916		[learning rate: 0.0072036]
	Learning Rate: 0.00720362
	LOSS [training: 0.9728479741007916 | validation: 0.761130571568664]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_80.pth
	Model improved!!!
EPOCH 81/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7180400176758792		[learning rate: 0.0071699]
	Learning Rate: 0.00716985
	LOSS [training: 0.7180400176758792 | validation: 0.7114732976276028]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_81.pth
	Model improved!!!
EPOCH 82/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7372210839037517		[learning rate: 0.0071362]
	Learning Rate: 0.00713624
	LOSS [training: 0.7372210839037517 | validation: 0.6919642317348327]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_82.pth
	Model improved!!!
EPOCH 83/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8706523516819281		[learning rate: 0.0071028]
	Learning Rate: 0.00710278
	LOSS [training: 0.8706523516819281 | validation: 0.8598917742778008]
	TIME [epoch: 10.3 sec]
EPOCH 84/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8385320178077705		[learning rate: 0.0070695]
	Learning Rate: 0.00706948
	LOSS [training: 0.8385320178077705 | validation: 0.7469293899034992]
	TIME [epoch: 10.4 sec]
EPOCH 85/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8425864305493829		[learning rate: 0.0070363]
	Learning Rate: 0.00703634
	LOSS [training: 0.8425864305493829 | validation: 0.6889277784430519]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_85.pth
	Model improved!!!
EPOCH 86/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6358496552207223		[learning rate: 0.0070034]
	Learning Rate: 0.00700335
	LOSS [training: 0.6358496552207223 | validation: 0.8359987065565769]
	TIME [epoch: 10.4 sec]
EPOCH 87/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7952183432183962		[learning rate: 0.0069705]
	Learning Rate: 0.00697052
	LOSS [training: 0.7952183432183962 | validation: 2.385223905409038]
	TIME [epoch: 10.4 sec]
EPOCH 88/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2857667518175315		[learning rate: 0.0069378]
	Learning Rate: 0.00693784
	LOSS [training: 1.2857667518175315 | validation: 0.7791077661529947]
	TIME [epoch: 10.3 sec]
EPOCH 89/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7190244975789933		[learning rate: 0.0069053]
	Learning Rate: 0.00690532
	LOSS [training: 0.7190244975789933 | validation: 0.9047551653117077]
	TIME [epoch: 10.4 sec]
EPOCH 90/500:
	Training over batches...
		[batch 5/5] avg loss: 1.034243569657273		[learning rate: 0.0068729]
	Learning Rate: 0.00687294
	LOSS [training: 1.034243569657273 | validation: 0.6532632374743649]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_90.pth
	Model improved!!!
EPOCH 91/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6810103941738763		[learning rate: 0.0068407]
	Learning Rate: 0.00684072
	LOSS [training: 0.6810103941738763 | validation: 0.8852596442868454]
	TIME [epoch: 10.3 sec]
EPOCH 92/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7407318744802198		[learning rate: 0.0068087]
	Learning Rate: 0.00680865
	LOSS [training: 0.7407318744802198 | validation: 1.9466229380344369]
	TIME [epoch: 10.4 sec]
EPOCH 93/500:
	Training over batches...
		[batch 5/5] avg loss: 1.687392092391245		[learning rate: 0.0067767]
	Learning Rate: 0.00677673
	LOSS [training: 1.687392092391245 | validation: 0.6579067080854387]
	TIME [epoch: 10.4 sec]
EPOCH 94/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9306265767533922		[learning rate: 0.006745]
	Learning Rate: 0.00674496
	LOSS [training: 0.9306265767533922 | validation: 0.6052615389873965]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_94.pth
	Model improved!!!
EPOCH 95/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7263779227217242		[learning rate: 0.0067133]
	Learning Rate: 0.00671334
	LOSS [training: 0.7263779227217242 | validation: 0.8789254297224411]
	TIME [epoch: 10.4 sec]
EPOCH 96/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7734216017694022		[learning rate: 0.0066819]
	Learning Rate: 0.00668187
	LOSS [training: 0.7734216017694022 | validation: 0.5793032179140195]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_96.pth
	Model improved!!!
EPOCH 97/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7556937268066181		[learning rate: 0.0066505]
	Learning Rate: 0.00665054
	LOSS [training: 0.7556937268066181 | validation: 0.7615413311487472]
	TIME [epoch: 10.4 sec]
EPOCH 98/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8038605609175375		[learning rate: 0.0066194]
	Learning Rate: 0.00661936
	LOSS [training: 0.8038605609175375 | validation: 0.949941817302638]
	TIME [epoch: 10.4 sec]
EPOCH 99/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8049910231923281		[learning rate: 0.0065883]
	Learning Rate: 0.00658833
	LOSS [training: 0.8049910231923281 | validation: 0.7354260676946447]
	TIME [epoch: 10.3 sec]
EPOCH 100/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6766673150013108		[learning rate: 0.0065574]
	Learning Rate: 0.00655745
	LOSS [training: 0.6766673150013108 | validation: 0.6112713058390518]
	TIME [epoch: 10.3 sec]
EPOCH 101/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6362106038483087		[learning rate: 0.0065267]
	Learning Rate: 0.0065267
	LOSS [training: 0.6362106038483087 | validation: 1.1250751399792367]
	TIME [epoch: 10.4 sec]
EPOCH 102/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9685547730487369		[learning rate: 0.0064961]
	Learning Rate: 0.0064961
	LOSS [training: 0.9685547730487369 | validation: 1.0794581101463607]
	TIME [epoch: 10.4 sec]
EPOCH 103/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0085620429891042		[learning rate: 0.0064657]
	Learning Rate: 0.00646565
	LOSS [training: 1.0085620429891042 | validation: 0.7934437240009291]
	TIME [epoch: 10.3 sec]
EPOCH 104/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8863207548398433		[learning rate: 0.0064353]
	Learning Rate: 0.00643534
	LOSS [training: 0.8863207548398433 | validation: 2.9594706156319384]
	TIME [epoch: 10.4 sec]
EPOCH 105/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2365065221852258		[learning rate: 0.0064052]
	Learning Rate: 0.00640517
	LOSS [training: 1.2365065221852258 | validation: 1.0937147009048085]
	TIME [epoch: 10.4 sec]
EPOCH 106/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0250807651676432		[learning rate: 0.0063751]
	Learning Rate: 0.00637514
	LOSS [training: 1.0250807651676432 | validation: 0.9345287950077881]
	TIME [epoch: 10.4 sec]
EPOCH 107/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7161685527352595		[learning rate: 0.0063453]
	Learning Rate: 0.00634525
	LOSS [training: 0.7161685527352595 | validation: 0.6372836106169107]
	TIME [epoch: 10.3 sec]
EPOCH 108/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7193597726778185		[learning rate: 0.0063155]
	Learning Rate: 0.00631551
	LOSS [training: 0.7193597726778185 | validation: 0.730723585056151]
	TIME [epoch: 10.3 sec]
EPOCH 109/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8085902053979556		[learning rate: 0.0062859]
	Learning Rate: 0.0062859
	LOSS [training: 0.8085902053979556 | validation: 0.6311460960110534]
	TIME [epoch: 10.4 sec]
EPOCH 110/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0726158976765923		[learning rate: 0.0062564]
	Learning Rate: 0.00625643
	LOSS [training: 1.0726158976765923 | validation: 1.1212742894062486]
	TIME [epoch: 10.3 sec]
EPOCH 111/500:
	Training over batches...
		[batch 5/5] avg loss: 1.165779931838032		[learning rate: 0.0062271]
	Learning Rate: 0.0062271
	LOSS [training: 1.165779931838032 | validation: 0.7023092712196791]
	TIME [epoch: 10.3 sec]
EPOCH 112/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6687443558118847		[learning rate: 0.0061979]
	Learning Rate: 0.0061979
	LOSS [training: 0.6687443558118847 | validation: 0.5682374966219653]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_112.pth
	Model improved!!!
EPOCH 113/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6727442702298567		[learning rate: 0.0061688]
	Learning Rate: 0.00616885
	LOSS [training: 0.6727442702298567 | validation: 0.9144525405479544]
	TIME [epoch: 10.4 sec]
EPOCH 114/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6546254368710949		[learning rate: 0.0061399]
	Learning Rate: 0.00613993
	LOSS [training: 0.6546254368710949 | validation: 0.7854413527529989]
	TIME [epoch: 10.3 sec]
EPOCH 115/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6289908167760483		[learning rate: 0.0061111]
	Learning Rate: 0.00611114
	LOSS [training: 0.6289908167760483 | validation: 0.5488694087570702]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_115.pth
	Model improved!!!
EPOCH 116/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6303372694494869		[learning rate: 0.0060825]
	Learning Rate: 0.00608249
	LOSS [training: 0.6303372694494869 | validation: 0.6492918397831126]
	TIME [epoch: 10.3 sec]
EPOCH 117/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5184604164339617		[learning rate: 0.006054]
	Learning Rate: 0.00605398
	LOSS [training: 0.5184604164339617 | validation: 0.48426069132349214]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_117.pth
	Model improved!!!
EPOCH 118/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6762894749058826		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.6762894749058826 | validation: 0.8179584072582478]
	TIME [epoch: 10.4 sec]
EPOCH 119/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0641822809790313		[learning rate: 0.0059973]
	Learning Rate: 0.00599735
	LOSS [training: 1.0641822809790313 | validation: 1.0671073764135515]
	TIME [epoch: 10.4 sec]
EPOCH 120/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8845781494923693		[learning rate: 0.0059692]
	Learning Rate: 0.00596923
	LOSS [training: 0.8845781494923693 | validation: 0.9340868760061306]
	TIME [epoch: 10.4 sec]
EPOCH 121/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7983200724537203		[learning rate: 0.0059412]
	Learning Rate: 0.00594125
	LOSS [training: 0.7983200724537203 | validation: 0.5485825762013035]
	TIME [epoch: 10.3 sec]
EPOCH 122/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2039324465623717		[learning rate: 0.0059134]
	Learning Rate: 0.00591339
	LOSS [training: 1.2039324465623717 | validation: 0.6779436302956166]
	TIME [epoch: 10.3 sec]
EPOCH 123/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8007749651881		[learning rate: 0.0058857]
	Learning Rate: 0.00588567
	LOSS [training: 0.8007749651881 | validation: 0.6723795235027389]
	TIME [epoch: 10.4 sec]
EPOCH 124/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9405793883631259		[learning rate: 0.0058581]
	Learning Rate: 0.00585808
	LOSS [training: 0.9405793883631259 | validation: 0.6617230080490092]
	TIME [epoch: 10.4 sec]
EPOCH 125/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7392738448001628		[learning rate: 0.0058306]
	Learning Rate: 0.00583061
	LOSS [training: 0.7392738448001628 | validation: 0.8417198702668764]
	TIME [epoch: 10.4 sec]
EPOCH 126/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0430972971012724		[learning rate: 0.0058033]
	Learning Rate: 0.00580328
	LOSS [training: 1.0430972971012724 | validation: 0.7960078146647409]
	TIME [epoch: 10.3 sec]
EPOCH 127/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0643796668853338		[learning rate: 0.0057761]
	Learning Rate: 0.00577607
	LOSS [training: 1.0643796668853338 | validation: 0.7655784619943486]
	TIME [epoch: 10.4 sec]
EPOCH 128/500:
	Training over batches...
		[batch 5/5] avg loss: 0.729934232222485		[learning rate: 0.005749]
	Learning Rate: 0.00574899
	LOSS [training: 0.729934232222485 | validation: 0.8664647763253318]
	TIME [epoch: 10.4 sec]
EPOCH 129/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8432108124438141		[learning rate: 0.005722]
	Learning Rate: 0.00572204
	LOSS [training: 0.8432108124438141 | validation: 0.6740580166918536]
	TIME [epoch: 10.3 sec]
EPOCH 130/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6971423215903081		[learning rate: 0.0056952]
	Learning Rate: 0.00569522
	LOSS [training: 0.6971423215903081 | validation: 0.6806162894870045]
	TIME [epoch: 10.4 sec]
EPOCH 131/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6725310448362942		[learning rate: 0.0056685]
	Learning Rate: 0.00566852
	LOSS [training: 0.6725310448362942 | validation: 0.7604692228463553]
	TIME [epoch: 10.4 sec]
EPOCH 132/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7927019290525		[learning rate: 0.0056419]
	Learning Rate: 0.00564194
	LOSS [training: 0.7927019290525 | validation: 0.7750253837525216]
	TIME [epoch: 10.3 sec]
EPOCH 133/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6164494989297367		[learning rate: 0.0056155]
	Learning Rate: 0.00561549
	LOSS [training: 0.6164494989297367 | validation: 0.9239089792620553]
	TIME [epoch: 10.4 sec]
EPOCH 134/500:
	Training over batches...
		[batch 5/5] avg loss: 0.624172059813261		[learning rate: 0.0055892]
	Learning Rate: 0.00558916
	LOSS [training: 0.624172059813261 | validation: 0.5118392336691121]
	TIME [epoch: 10.4 sec]
EPOCH 135/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5737870900570177		[learning rate: 0.005563]
	Learning Rate: 0.00556296
	LOSS [training: 0.5737870900570177 | validation: 0.6923268778213604]
	TIME [epoch: 10.4 sec]
EPOCH 136/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7322664892861577		[learning rate: 0.0055369]
	Learning Rate: 0.00553688
	LOSS [training: 0.7322664892861577 | validation: 0.7463333381804363]
	TIME [epoch: 10.3 sec]
EPOCH 137/500:
	Training over batches...
		[batch 5/5] avg loss: 0.652303491746517		[learning rate: 0.0055109]
	Learning Rate: 0.00551092
	LOSS [training: 0.652303491746517 | validation: 0.5185289086702026]
	TIME [epoch: 10.3 sec]
EPOCH 138/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5582929772536909		[learning rate: 0.0054851]
	Learning Rate: 0.00548509
	LOSS [training: 0.5582929772536909 | validation: 0.9007593964355541]
	TIME [epoch: 10.4 sec]
EPOCH 139/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7496846696372638		[learning rate: 0.0054594]
	Learning Rate: 0.00545937
	LOSS [training: 0.7496846696372638 | validation: 0.85536741480767]
	TIME [epoch: 10.4 sec]
EPOCH 140/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8192788613513826		[learning rate: 0.0054338]
	Learning Rate: 0.00543378
	LOSS [training: 0.8192788613513826 | validation: 0.8724344113025921]
	TIME [epoch: 10.3 sec]
EPOCH 141/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7761355157449449		[learning rate: 0.0054083]
	Learning Rate: 0.00540831
	LOSS [training: 0.7761355157449449 | validation: 0.7524859382888434]
	TIME [epoch: 10.4 sec]
EPOCH 142/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7056371366011087		[learning rate: 0.005383]
	Learning Rate: 0.00538295
	LOSS [training: 0.7056371366011087 | validation: 0.7560609352471869]
	TIME [epoch: 10.4 sec]
EPOCH 143/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8642119384434		[learning rate: 0.0053577]
	Learning Rate: 0.00535771
	LOSS [training: 0.8642119384434 | validation: 0.6868840620858919]
	TIME [epoch: 10.4 sec]
EPOCH 144/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6454371073833943		[learning rate: 0.0053326]
	Learning Rate: 0.0053326
	LOSS [training: 0.6454371073833943 | validation: 0.7964144035586054]
	TIME [epoch: 10.4 sec]
EPOCH 145/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7435471847391562		[learning rate: 0.0053076]
	Learning Rate: 0.0053076
	LOSS [training: 0.7435471847391562 | validation: 1.3387846535555354]
	TIME [epoch: 10.4 sec]
EPOCH 146/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7564183702172492		[learning rate: 0.0052827]
	Learning Rate: 0.00528271
	LOSS [training: 0.7564183702172492 | validation: 0.7270570832998489]
	TIME [epoch: 10.4 sec]
EPOCH 147/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7832741854347798		[learning rate: 0.0052579]
	Learning Rate: 0.00525795
	LOSS [training: 0.7832741854347798 | validation: 0.6285478861166099]
	TIME [epoch: 10.3 sec]
EPOCH 148/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6695190668767435		[learning rate: 0.0052333]
	Learning Rate: 0.0052333
	LOSS [training: 0.6695190668767435 | validation: 0.7319996379443545]
	TIME [epoch: 10.3 sec]
EPOCH 149/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6827326852896355		[learning rate: 0.0052088]
	Learning Rate: 0.00520876
	LOSS [training: 0.6827326852896355 | validation: 0.7783389433361547]
	TIME [epoch: 10.4 sec]
EPOCH 150/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7174131582133875		[learning rate: 0.0051843]
	Learning Rate: 0.00518434
	LOSS [training: 0.7174131582133875 | validation: 0.7286787244659337]
	TIME [epoch: 10.4 sec]
EPOCH 151/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7452411310494791		[learning rate: 0.00516]
	Learning Rate: 0.00516004
	LOSS [training: 0.7452411310494791 | validation: 0.7703481396838631]
	TIME [epoch: 10.4 sec]
EPOCH 152/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9660159804505071		[learning rate: 0.0051358]
	Learning Rate: 0.00513585
	LOSS [training: 0.9660159804505071 | validation: 0.9170026329468135]
	TIME [epoch: 10.4 sec]
EPOCH 153/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7007348325396051		[learning rate: 0.0051118]
	Learning Rate: 0.00511177
	LOSS [training: 0.7007348325396051 | validation: 0.6552182852696454]
	TIME [epoch: 10.4 sec]
EPOCH 154/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7084314732140622		[learning rate: 0.0050878]
	Learning Rate: 0.00508781
	LOSS [training: 0.7084314732140622 | validation: 0.4880129024252332]
	TIME [epoch: 10.3 sec]
EPOCH 155/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6540613533675801		[learning rate: 0.005064]
	Learning Rate: 0.00506395
	LOSS [training: 0.6540613533675801 | validation: 0.6238913915647681]
	TIME [epoch: 10.3 sec]
EPOCH 156/500:
	Training over batches...
		[batch 5/5] avg loss: 0.610673584049806		[learning rate: 0.0050402]
	Learning Rate: 0.00504021
	LOSS [training: 0.610673584049806 | validation: 0.5665768188424544]
	TIME [epoch: 10.4 sec]
EPOCH 157/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6003893681133139		[learning rate: 0.0050166]
	Learning Rate: 0.00501658
	LOSS [training: 0.6003893681133139 | validation: 0.6676238569721241]
	TIME [epoch: 10.4 sec]
EPOCH 158/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6029989846640891		[learning rate: 0.0049931]
	Learning Rate: 0.00499307
	LOSS [training: 0.6029989846640891 | validation: 0.8019829077228423]
	TIME [epoch: 10.3 sec]
EPOCH 159/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6205622581945931		[learning rate: 0.0049697]
	Learning Rate: 0.00496966
	LOSS [training: 0.6205622581945931 | validation: 0.7946959841214039]
	TIME [epoch: 10.3 sec]
EPOCH 160/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6347416521668184		[learning rate: 0.0049464]
	Learning Rate: 0.00494636
	LOSS [training: 0.6347416521668184 | validation: 0.5740571312833993]
	TIME [epoch: 10.4 sec]
EPOCH 161/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6696414667037687		[learning rate: 0.0049232]
	Learning Rate: 0.00492317
	LOSS [training: 0.6696414667037687 | validation: 0.6307327060132863]
	TIME [epoch: 10.3 sec]
EPOCH 162/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7740017866037293		[learning rate: 0.0049001]
	Learning Rate: 0.00490009
	LOSS [training: 0.7740017866037293 | validation: 0.9137571591876182]
	TIME [epoch: 10.3 sec]
EPOCH 163/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7543116999326026		[learning rate: 0.0048771]
	Learning Rate: 0.00487712
	LOSS [training: 0.7543116999326026 | validation: 1.0304324942091032]
	TIME [epoch: 10.4 sec]
EPOCH 164/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9670550564351377		[learning rate: 0.0048543]
	Learning Rate: 0.00485425
	LOSS [training: 0.9670550564351377 | validation: 3.5739612450713674]
	TIME [epoch: 10.4 sec]
EPOCH 165/500:
	Training over batches...
		[batch 5/5] avg loss: 1.227361265307834		[learning rate: 0.0048315]
	Learning Rate: 0.0048315
	LOSS [training: 1.227361265307834 | validation: 0.7947714119827404]
	TIME [epoch: 10.4 sec]
EPOCH 166/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7250197504552628		[learning rate: 0.0048088]
	Learning Rate: 0.00480885
	LOSS [training: 0.7250197504552628 | validation: 0.8626134284992842]
	TIME [epoch: 10.3 sec]
EPOCH 167/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7159179733255583		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 0.7159179733255583 | validation: 0.8329853403110903]
	TIME [epoch: 10.4 sec]
EPOCH 168/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6699000143720888		[learning rate: 0.0047639]
	Learning Rate: 0.00476386
	LOSS [training: 0.6699000143720888 | validation: 0.6981875228610092]
	TIME [epoch: 10.4 sec]
EPOCH 169/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6063022025049093		[learning rate: 0.0047415]
	Learning Rate: 0.00474153
	LOSS [training: 0.6063022025049093 | validation: 0.6739376353763226]
	TIME [epoch: 10.3 sec]
EPOCH 170/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7258240186322034		[learning rate: 0.0047193]
	Learning Rate: 0.0047193
	LOSS [training: 0.7258240186322034 | validation: 0.7788347598425428]
	TIME [epoch: 10.4 sec]
EPOCH 171/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6643817930430613		[learning rate: 0.0046972]
	Learning Rate: 0.00469718
	LOSS [training: 0.6643817930430613 | validation: 0.625417656604006]
	TIME [epoch: 10.4 sec]
EPOCH 172/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5900459778526157		[learning rate: 0.0046752]
	Learning Rate: 0.00467515
	LOSS [training: 0.5900459778526157 | validation: 0.6708244380561129]
	TIME [epoch: 10.4 sec]
EPOCH 173/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5984960753035434		[learning rate: 0.0046532]
	Learning Rate: 0.00465324
	LOSS [training: 0.5984960753035434 | validation: 0.5603843400140085]
	TIME [epoch: 10.3 sec]
EPOCH 174/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5437397633439113		[learning rate: 0.0046314]
	Learning Rate: 0.00463142
	LOSS [training: 0.5437397633439113 | validation: 0.5409295900509682]
	TIME [epoch: 10.3 sec]
EPOCH 175/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5616578615722737		[learning rate: 0.0046097]
	Learning Rate: 0.00460971
	LOSS [training: 0.5616578615722737 | validation: 0.5439030490214354]
	TIME [epoch: 10.4 sec]
EPOCH 176/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5247330909345728		[learning rate: 0.0045881]
	Learning Rate: 0.0045881
	LOSS [training: 0.5247330909345728 | validation: 0.5427533818115738]
	TIME [epoch: 10.3 sec]
EPOCH 177/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5457690289711176		[learning rate: 0.0045666]
	Learning Rate: 0.00456659
	LOSS [training: 0.5457690289711176 | validation: 0.6525140268982582]
	TIME [epoch: 10.4 sec]
EPOCH 178/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6674054885521875		[learning rate: 0.0045452]
	Learning Rate: 0.00454518
	LOSS [training: 0.6674054885521875 | validation: 1.6062053782952024]
	TIME [epoch: 10.4 sec]
EPOCH 179/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4184990655503154		[learning rate: 0.0045239]
	Learning Rate: 0.00452387
	LOSS [training: 1.4184990655503154 | validation: 0.7152390000983815]
	TIME [epoch: 10.4 sec]
EPOCH 180/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5603764572740385		[learning rate: 0.0045027]
	Learning Rate: 0.00450266
	LOSS [training: 0.5603764572740385 | validation: 0.590612592930771]
	TIME [epoch: 10.3 sec]
EPOCH 181/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6023788813856732		[learning rate: 0.0044816]
	Learning Rate: 0.00448155
	LOSS [training: 0.6023788813856732 | validation: 0.6179380426400919]
	TIME [epoch: 10.3 sec]
EPOCH 182/500:
	Training over batches...
		[batch 5/5] avg loss: 0.626433371343548		[learning rate: 0.0044605]
	Learning Rate: 0.00446054
	LOSS [training: 0.626433371343548 | validation: 0.5801872352957378]
	TIME [epoch: 10.4 sec]
EPOCH 183/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5882287308735834		[learning rate: 0.0044396]
	Learning Rate: 0.00443963
	LOSS [training: 0.5882287308735834 | validation: 0.6864164257235095]
	TIME [epoch: 10.4 sec]
EPOCH 184/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7072630973497643		[learning rate: 0.0044188]
	Learning Rate: 0.00441882
	LOSS [training: 0.7072630973497643 | validation: 0.6305671568020815]
	TIME [epoch: 10.3 sec]
EPOCH 185/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1723172510678423		[learning rate: 0.0043981]
	Learning Rate: 0.0043981
	LOSS [training: 1.1723172510678423 | validation: 0.6139966564807965]
	TIME [epoch: 10.4 sec]
EPOCH 186/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5035425488262746		[learning rate: 0.0043775]
	Learning Rate: 0.00437748
	LOSS [training: 0.5035425488262746 | validation: 0.5301314189199908]
	TIME [epoch: 10.4 sec]
EPOCH 187/500:
	Training over batches...
		[batch 5/5] avg loss: 0.47328206767046865		[learning rate: 0.004357]
	Learning Rate: 0.00435696
	LOSS [training: 0.47328206767046865 | validation: 0.5802812917654916]
	TIME [epoch: 10.3 sec]
EPOCH 188/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5924595048937472		[learning rate: 0.0043365]
	Learning Rate: 0.00433654
	LOSS [training: 0.5924595048937472 | validation: 0.8374029895088466]
	TIME [epoch: 10.4 sec]
EPOCH 189/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6922731715671852		[learning rate: 0.0043162]
	Learning Rate: 0.0043162
	LOSS [training: 0.6922731715671852 | validation: 0.5041268980364135]
	TIME [epoch: 10.4 sec]
EPOCH 190/500:
	Training over batches...
		[batch 5/5] avg loss: 0.68114617522319		[learning rate: 0.004296]
	Learning Rate: 0.00429597
	LOSS [training: 0.68114617522319 | validation: 0.5660288471947575]
	TIME [epoch: 10.4 sec]
EPOCH 191/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5449713229439537		[learning rate: 0.0042758]
	Learning Rate: 0.00427583
	LOSS [training: 0.5449713229439537 | validation: 0.869457579378218]
	TIME [epoch: 10.3 sec]
EPOCH 192/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6635766414735257		[learning rate: 0.0042558]
	Learning Rate: 0.00425578
	LOSS [training: 0.6635766414735257 | validation: 0.6633712134982224]
	TIME [epoch: 10.4 sec]
EPOCH 193/500:
	Training over batches...
		[batch 5/5] avg loss: 0.588866061051619		[learning rate: 0.0042358]
	Learning Rate: 0.00423583
	LOSS [training: 0.588866061051619 | validation: 3.8140583790279927]
	TIME [epoch: 10.4 sec]
EPOCH 194/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1928996461858477		[learning rate: 0.004216]
	Learning Rate: 0.00421597
	LOSS [training: 1.1928996461858477 | validation: 0.6948709078823734]
	TIME [epoch: 10.3 sec]
EPOCH 195/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5839260808744026		[learning rate: 0.0041962]
	Learning Rate: 0.00419621
	LOSS [training: 0.5839260808744026 | validation: 0.619027394281176]
	TIME [epoch: 10.3 sec]
EPOCH 196/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8078294485238274		[learning rate: 0.0041765]
	Learning Rate: 0.00417654
	LOSS [training: 0.8078294485238274 | validation: 1.075818999448417]
	TIME [epoch: 10.3 sec]
EPOCH 197/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7163783453719201		[learning rate: 0.004157]
	Learning Rate: 0.00415696
	LOSS [training: 0.7163783453719201 | validation: 0.7204074937594948]
	TIME [epoch: 10.4 sec]
EPOCH 198/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5841275124635532		[learning rate: 0.0041375]
	Learning Rate: 0.00413747
	LOSS [training: 0.5841275124635532 | validation: 0.5936910208684525]
	TIME [epoch: 10.3 sec]
EPOCH 199/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5358265090860078		[learning rate: 0.0041181]
	Learning Rate: 0.00411807
	LOSS [training: 0.5358265090860078 | validation: 0.5969461505162021]
	TIME [epoch: 10.3 sec]
EPOCH 200/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6366137608683178		[learning rate: 0.0040988]
	Learning Rate: 0.00409877
	LOSS [training: 0.6366137608683178 | validation: 0.7243494427631594]
	TIME [epoch: 10.4 sec]
EPOCH 201/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8574855446672528		[learning rate: 0.0040795]
	Learning Rate: 0.00407955
	LOSS [training: 0.8574855446672528 | validation: 0.6203129875947739]
	TIME [epoch: 10.3 sec]
EPOCH 202/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5278272604984411		[learning rate: 0.0040604]
	Learning Rate: 0.00406042
	LOSS [training: 0.5278272604984411 | validation: 0.8001921067339822]
	TIME [epoch: 10.3 sec]
EPOCH 203/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9503507387240319		[learning rate: 0.0040414]
	Learning Rate: 0.00404139
	LOSS [training: 0.9503507387240319 | validation: 0.5514697135424261]
	TIME [epoch: 10.3 sec]
EPOCH 204/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5045336138632986		[learning rate: 0.0040224]
	Learning Rate: 0.00402244
	LOSS [training: 0.5045336138632986 | validation: 0.5637443917692323]
	TIME [epoch: 10.4 sec]
EPOCH 205/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4579498519194396		[learning rate: 0.0040036]
	Learning Rate: 0.00400358
	LOSS [training: 0.4579498519194396 | validation: 0.556330650164169]
	TIME [epoch: 10.4 sec]
EPOCH 206/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4700158849708216		[learning rate: 0.0039848]
	Learning Rate: 0.00398481
	LOSS [training: 0.4700158849708216 | validation: 0.4972442962375102]
	TIME [epoch: 10.3 sec]
EPOCH 207/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4429619124924143		[learning rate: 0.0039661]
	Learning Rate: 0.00396613
	LOSS [training: 0.4429619124924143 | validation: 0.630045890825232]
	TIME [epoch: 10.3 sec]
EPOCH 208/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6330981791656489		[learning rate: 0.0039475]
	Learning Rate: 0.00394754
	LOSS [training: 0.6330981791656489 | validation: 0.5141539363640484]
	TIME [epoch: 10.4 sec]
EPOCH 209/500:
	Training over batches...
		[batch 5/5] avg loss: 0.535030581024593		[learning rate: 0.003929]
	Learning Rate: 0.00392903
	LOSS [training: 0.535030581024593 | validation: 0.7707829726897996]
	TIME [epoch: 10.3 sec]
EPOCH 210/500:
	Training over batches...
		[batch 5/5] avg loss: 0.49018160151913204		[learning rate: 0.0039106]
	Learning Rate: 0.00391061
	LOSS [training: 0.49018160151913204 | validation: 0.7244127027489082]
	TIME [epoch: 10.3 sec]
EPOCH 211/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8042861653985043		[learning rate: 0.0038923]
	Learning Rate: 0.00389228
	LOSS [training: 0.8042861653985043 | validation: 0.5488549086025637]
	TIME [epoch: 10.4 sec]
EPOCH 212/500:
	Training over batches...
		[batch 5/5] avg loss: 0.420023303135275		[learning rate: 0.003874]
	Learning Rate: 0.00387403
	LOSS [training: 0.420023303135275 | validation: 0.5025182130404318]
	TIME [epoch: 10.3 sec]
EPOCH 213/500:
	Training over batches...
		[batch 5/5] avg loss: 0.39654008238588634		[learning rate: 0.0038559]
	Learning Rate: 0.00385587
	LOSS [training: 0.39654008238588634 | validation: 0.6482581167345984]
	TIME [epoch: 10.3 sec]
EPOCH 214/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5491892219479813		[learning rate: 0.0038378]
	Learning Rate: 0.00383779
	LOSS [training: 0.5491892219479813 | validation: 0.6283436805869933]
	TIME [epoch: 10.3 sec]
EPOCH 215/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5008462552449474		[learning rate: 0.0038198]
	Learning Rate: 0.0038198
	LOSS [training: 0.5008462552449474 | validation: 0.47998267070844786]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_215.pth
	Model improved!!!
EPOCH 216/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6544622117382344		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 0.6544622117382344 | validation: 0.46554881998369413]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_216.pth
	Model improved!!!
EPOCH 217/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5535837222708226		[learning rate: 0.0037841]
	Learning Rate: 0.00378407
	LOSS [training: 0.5535837222708226 | validation: 0.7266458665995217]
	TIME [epoch: 10.4 sec]
EPOCH 218/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5254786320803155		[learning rate: 0.0037663]
	Learning Rate: 0.00376633
	LOSS [training: 0.5254786320803155 | validation: 0.5987678773129613]
	TIME [epoch: 10.4 sec]
EPOCH 219/500:
	Training over batches...
		[batch 5/5] avg loss: 0.566804350124531		[learning rate: 0.0037487]
	Learning Rate: 0.00374867
	LOSS [training: 0.566804350124531 | validation: 0.5775092616171128]
	TIME [epoch: 10.4 sec]
EPOCH 220/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5176846860494373		[learning rate: 0.0037311]
	Learning Rate: 0.0037311
	LOSS [training: 0.5176846860494373 | validation: 0.6123084536452652]
	TIME [epoch: 10.3 sec]
EPOCH 221/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5430891396470334		[learning rate: 0.0037136]
	Learning Rate: 0.00371361
	LOSS [training: 0.5430891396470334 | validation: 0.9253388811417422]
	TIME [epoch: 10.4 sec]
EPOCH 222/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6458917107396236		[learning rate: 0.0036962]
	Learning Rate: 0.0036962
	LOSS [training: 0.6458917107396236 | validation: 0.6529766194873465]
	TIME [epoch: 10.4 sec]
EPOCH 223/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6484092409706332		[learning rate: 0.0036789]
	Learning Rate: 0.00367887
	LOSS [training: 0.6484092409706332 | validation: 0.5695272781098042]
	TIME [epoch: 10.4 sec]
EPOCH 224/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5372751584337134		[learning rate: 0.0036616]
	Learning Rate: 0.00366162
	LOSS [training: 0.5372751584337134 | validation: 0.6628851684417819]
	TIME [epoch: 10.4 sec]
EPOCH 225/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8139286823760197		[learning rate: 0.0036445]
	Learning Rate: 0.00364446
	LOSS [training: 0.8139286823760197 | validation: 0.5497805925282601]
	TIME [epoch: 10.4 sec]
EPOCH 226/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5114146472298101		[learning rate: 0.0036274]
	Learning Rate: 0.00362737
	LOSS [training: 0.5114146472298101 | validation: 0.5276190811901347]
	TIME [epoch: 10.4 sec]
EPOCH 227/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48750922349261916		[learning rate: 0.0036104]
	Learning Rate: 0.00361036
	LOSS [training: 0.48750922349261916 | validation: 0.6606694844620644]
	TIME [epoch: 10.4 sec]
EPOCH 228/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5108724689683941		[learning rate: 0.0035934]
	Learning Rate: 0.00359344
	LOSS [training: 0.5108724689683941 | validation: 0.4519499808100359]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_228.pth
	Model improved!!!
EPOCH 229/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5563459937068298		[learning rate: 0.0035766]
	Learning Rate: 0.00357659
	LOSS [training: 0.5563459937068298 | validation: 0.5231773344699611]
	TIME [epoch: 10.3 sec]
EPOCH 230/500:
	Training over batches...
		[batch 5/5] avg loss: 0.47080452942104356		[learning rate: 0.0035598]
	Learning Rate: 0.00355982
	LOSS [training: 0.47080452942104356 | validation: 0.5561895966664029]
	TIME [epoch: 10.4 sec]
EPOCH 231/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5183381151324044		[learning rate: 0.0035431]
	Learning Rate: 0.00354314
	LOSS [training: 0.5183381151324044 | validation: 0.4915056826395633]
	TIME [epoch: 10.3 sec]
EPOCH 232/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46392072380211813		[learning rate: 0.0035265]
	Learning Rate: 0.00352652
	LOSS [training: 0.46392072380211813 | validation: 0.36566177227577984]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_232.pth
	Model improved!!!
EPOCH 233/500:
	Training over batches...
		[batch 5/5] avg loss: 0.37642242980477925		[learning rate: 0.00351]
	Learning Rate: 0.00350999
	LOSS [training: 0.37642242980477925 | validation: 0.4523567266328084]
	TIME [epoch: 10.3 sec]
EPOCH 234/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5320137460780001		[learning rate: 0.0034935]
	Learning Rate: 0.00349354
	LOSS [training: 0.5320137460780001 | validation: 0.5104220092742696]
	TIME [epoch: 10.4 sec]
EPOCH 235/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5086376953774423		[learning rate: 0.0034772]
	Learning Rate: 0.00347716
	LOSS [training: 0.5086376953774423 | validation: 0.48036486263172734]
	TIME [epoch: 10.3 sec]
EPOCH 236/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4655335655739748		[learning rate: 0.0034609]
	Learning Rate: 0.00346086
	LOSS [training: 0.4655335655739748 | validation: 0.4508781759003022]
	TIME [epoch: 10.3 sec]
EPOCH 237/500:
	Training over batches...
		[batch 5/5] avg loss: 0.42839282041459514		[learning rate: 0.0034446]
	Learning Rate: 0.00344463
	LOSS [training: 0.42839282041459514 | validation: 0.5649698802104509]
	TIME [epoch: 10.3 sec]
EPOCH 238/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4996983912780496		[learning rate: 0.0034285]
	Learning Rate: 0.00342848
	LOSS [training: 0.4996983912780496 | validation: 0.5189353009084579]
	TIME [epoch: 10.4 sec]
EPOCH 239/500:
	Training over batches...
		[batch 5/5] avg loss: 0.43370484451935176		[learning rate: 0.0034124]
	Learning Rate: 0.00341241
	LOSS [training: 0.43370484451935176 | validation: 0.45291153329770717]
	TIME [epoch: 10.3 sec]
EPOCH 240/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4941763253174326		[learning rate: 0.0033964]
	Learning Rate: 0.00339641
	LOSS [training: 0.4941763253174326 | validation: 0.4771917502730766]
	TIME [epoch: 10.3 sec]
EPOCH 241/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4563617242127481		[learning rate: 0.0033805]
	Learning Rate: 0.00338049
	LOSS [training: 0.4563617242127481 | validation: 0.828497776595613]
	TIME [epoch: 10.3 sec]
EPOCH 242/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4740822576840903		[learning rate: 0.0033646]
	Learning Rate: 0.00336464
	LOSS [training: 0.4740822576840903 | validation: 0.39714193722370267]
	TIME [epoch: 10.4 sec]
EPOCH 243/500:
	Training over batches...
		[batch 5/5] avg loss: 0.40998456136796235		[learning rate: 0.0033489]
	Learning Rate: 0.00334887
	LOSS [training: 0.40998456136796235 | validation: 0.4602178453636624]
	TIME [epoch: 10.3 sec]
EPOCH 244/500:
	Training over batches...
		[batch 5/5] avg loss: 0.37794859676689496		[learning rate: 0.0033332]
	Learning Rate: 0.00333317
	LOSS [training: 0.37794859676689496 | validation: 0.5316708797364222]
	TIME [epoch: 10.3 sec]
EPOCH 245/500:
	Training over batches...
		[batch 5/5] avg loss: 0.41860664016732363		[learning rate: 0.0033175]
	Learning Rate: 0.00331754
	LOSS [training: 0.41860664016732363 | validation: 0.4603550283969886]
	TIME [epoch: 10.4 sec]
EPOCH 246/500:
	Training over batches...
		[batch 5/5] avg loss: 0.42356719253104214		[learning rate: 0.003302]
	Learning Rate: 0.00330199
	LOSS [training: 0.42356719253104214 | validation: 0.43773639765562294]
	TIME [epoch: 10.3 sec]
EPOCH 247/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4108374490364614		[learning rate: 0.0032865]
	Learning Rate: 0.00328651
	LOSS [training: 0.4108374490364614 | validation: 0.3991625161525457]
	TIME [epoch: 10.3 sec]
EPOCH 248/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3919387328437509		[learning rate: 0.0032711]
	Learning Rate: 0.0032711
	LOSS [training: 0.3919387328437509 | validation: 0.46287664016961627]
	TIME [epoch: 10.3 sec]
EPOCH 249/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4161703698543661		[learning rate: 0.0032558]
	Learning Rate: 0.00325576
	LOSS [training: 0.4161703698543661 | validation: 0.600063299183121]
	TIME [epoch: 10.4 sec]
EPOCH 250/500:
	Training over batches...
		[batch 5/5] avg loss: 0.41930896669748013		[learning rate: 0.0032405]
	Learning Rate: 0.0032405
	LOSS [training: 0.41930896669748013 | validation: 0.6195159663682686]
	TIME [epoch: 10.3 sec]
EPOCH 251/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48591900632011953		[learning rate: 0.0032253]
	Learning Rate: 0.00322531
	LOSS [training: 0.48591900632011953 | validation: 0.5865643886164695]
	TIME [epoch: 10.3 sec]
EPOCH 252/500:
	Training over batches...
		[batch 5/5] avg loss: 0.43882922960969256		[learning rate: 0.0032102]
	Learning Rate: 0.00321019
	LOSS [training: 0.43882922960969256 | validation: 0.4493226026480648]
	TIME [epoch: 10.3 sec]
EPOCH 253/500:
	Training over batches...
		[batch 5/5] avg loss: 0.402043302153834		[learning rate: 0.0031951]
	Learning Rate: 0.00319514
	LOSS [training: 0.402043302153834 | validation: 0.3813395532528192]
	TIME [epoch: 10.4 sec]
EPOCH 254/500:
	Training over batches...
		[batch 5/5] avg loss: 0.35141326079934077		[learning rate: 0.0031802]
	Learning Rate: 0.00318016
	LOSS [training: 0.35141326079934077 | validation: 0.43606997271956943]
	TIME [epoch: 10.3 sec]
EPOCH 255/500:
	Training over batches...
		[batch 5/5] avg loss: 0.34700808014535106		[learning rate: 0.0031653]
	Learning Rate: 0.00316525
	LOSS [training: 0.34700808014535106 | validation: 0.4017015749251035]
	TIME [epoch: 10.3 sec]
EPOCH 256/500:
	Training over batches...
		[batch 5/5] avg loss: 0.47081620682118397		[learning rate: 0.0031504]
	Learning Rate: 0.00315041
	LOSS [training: 0.47081620682118397 | validation: 0.646619713884164]
	TIME [epoch: 10.4 sec]
EPOCH 257/500:
	Training over batches...
		[batch 5/5] avg loss: 0.551957980433055		[learning rate: 0.0031356]
	Learning Rate: 0.00313564
	LOSS [training: 0.551957980433055 | validation: 0.5634042155188561]
	TIME [epoch: 10.4 sec]
EPOCH 258/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4547237332302291		[learning rate: 0.0031209]
	Learning Rate: 0.00312094
	LOSS [training: 0.4547237332302291 | validation: 0.4811477161272705]
	TIME [epoch: 10.3 sec]
EPOCH 259/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48094435864602125		[learning rate: 0.0031063]
	Learning Rate: 0.00310631
	LOSS [training: 0.48094435864602125 | validation: 0.4106281001091365]
	TIME [epoch: 10.3 sec]
EPOCH 260/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3539737841611932		[learning rate: 0.0030917]
	Learning Rate: 0.00309175
	LOSS [training: 0.3539737841611932 | validation: 0.6452698157450404]
	TIME [epoch: 10.4 sec]
EPOCH 261/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45712434180235906		[learning rate: 0.0030773]
	Learning Rate: 0.00307725
	LOSS [training: 0.45712434180235906 | validation: 0.4721217942039294]
	TIME [epoch: 10.3 sec]
EPOCH 262/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4132785516551157		[learning rate: 0.0030628]
	Learning Rate: 0.00306283
	LOSS [training: 0.4132785516551157 | validation: 0.4455119551486746]
	TIME [epoch: 10.3 sec]
EPOCH 263/500:
	Training over batches...
		[batch 5/5] avg loss: 0.43365865347963084		[learning rate: 0.0030485]
	Learning Rate: 0.00304847
	LOSS [training: 0.43365865347963084 | validation: 0.49573273565620013]
	TIME [epoch: 10.4 sec]
EPOCH 264/500:
	Training over batches...
		[batch 5/5] avg loss: 0.42852963561736035		[learning rate: 0.0030342]
	Learning Rate: 0.00303418
	LOSS [training: 0.42852963561736035 | validation: 0.43941255403797985]
	TIME [epoch: 10.4 sec]
EPOCH 265/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4518540860711626		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.4518540860711626 | validation: 0.4602180813785907]
	TIME [epoch: 10.3 sec]
EPOCH 266/500:
	Training over batches...
		[batch 5/5] avg loss: 0.40505435175149695		[learning rate: 0.0030058]
	Learning Rate: 0.00300579
	LOSS [training: 0.40505435175149695 | validation: 0.5528609707410574]
	TIME [epoch: 10.3 sec]
EPOCH 267/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9859554511283332		[learning rate: 0.0029917]
	Learning Rate: 0.0029917
	LOSS [training: 0.9859554511283332 | validation: 0.5526438665975055]
	TIME [epoch: 10.3 sec]
EPOCH 268/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3923965084207538		[learning rate: 0.0029777]
	Learning Rate: 0.00297768
	LOSS [training: 0.3923965084207538 | validation: 0.3927442265291762]
	TIME [epoch: 10.3 sec]
EPOCH 269/500:
	Training over batches...
		[batch 5/5] avg loss: 0.35770605014562945		[learning rate: 0.0029637]
	Learning Rate: 0.00296372
	LOSS [training: 0.35770605014562945 | validation: 0.6228377460516963]
	TIME [epoch: 10.3 sec]
EPOCH 270/500:
	Training over batches...
		[batch 5/5] avg loss: 0.36817553513303397		[learning rate: 0.0029498]
	Learning Rate: 0.00294982
	LOSS [training: 0.36817553513303397 | validation: 0.34289836315755395]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_270.pth
	Model improved!!!
EPOCH 271/500:
	Training over batches...
		[batch 5/5] avg loss: 0.850138620287203		[learning rate: 0.002936]
	Learning Rate: 0.00293599
	LOSS [training: 0.850138620287203 | validation: 0.7388589833437417]
	TIME [epoch: 10.4 sec]
EPOCH 272/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6731735130236648		[learning rate: 0.0029222]
	Learning Rate: 0.00292223
	LOSS [training: 0.6731735130236648 | validation: 0.5175486455309375]
	TIME [epoch: 10.3 sec]
EPOCH 273/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46059165495990195		[learning rate: 0.0029085]
	Learning Rate: 0.00290853
	LOSS [training: 0.46059165495990195 | validation: 0.40966909374749166]
	TIME [epoch: 10.3 sec]
EPOCH 274/500:
	Training over batches...
		[batch 5/5] avg loss: 0.40494685163492816		[learning rate: 0.0028949]
	Learning Rate: 0.00289489
	LOSS [training: 0.40494685163492816 | validation: 0.5314023449388825]
	TIME [epoch: 10.3 sec]
EPOCH 275/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6121797733371475		[learning rate: 0.0028813]
	Learning Rate: 0.00288132
	LOSS [training: 0.6121797733371475 | validation: 0.6582686322999273]
	TIME [epoch: 10.4 sec]
EPOCH 276/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0160158723436479		[learning rate: 0.0028678]
	Learning Rate: 0.00286781
	LOSS [training: 1.0160158723436479 | validation: 0.6270993308049366]
	TIME [epoch: 10.3 sec]
EPOCH 277/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5021806916707232		[learning rate: 0.0028544]
	Learning Rate: 0.00285437
	LOSS [training: 0.5021806916707232 | validation: 0.3315016088377178]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_277.pth
	Model improved!!!
EPOCH 278/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5704973721224448		[learning rate: 0.002841]
	Learning Rate: 0.00284099
	LOSS [training: 0.5704973721224448 | validation: 0.5678646687647885]
	TIME [epoch: 10.4 sec]
EPOCH 279/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46829158445482333		[learning rate: 0.0028277]
	Learning Rate: 0.00282767
	LOSS [training: 0.46829158445482333 | validation: 0.5114620954623935]
	TIME [epoch: 10.4 sec]
EPOCH 280/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6228092769001882		[learning rate: 0.0028144]
	Learning Rate: 0.00281441
	LOSS [training: 0.6228092769001882 | validation: 0.4470224232873612]
	TIME [epoch: 10.3 sec]
EPOCH 281/500:
	Training over batches...
		[batch 5/5] avg loss: 0.65516828859835		[learning rate: 0.0028012]
	Learning Rate: 0.00280122
	LOSS [training: 0.65516828859835 | validation: 0.8256000426022331]
	TIME [epoch: 10.3 sec]
EPOCH 282/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6993329209081732		[learning rate: 0.0027881]
	Learning Rate: 0.00278809
	LOSS [training: 0.6993329209081732 | validation: 0.4967115072782834]
	TIME [epoch: 10.3 sec]
EPOCH 283/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9014810025841719		[learning rate: 0.002775]
	Learning Rate: 0.00277501
	LOSS [training: 0.9014810025841719 | validation: 0.913746349772383]
	TIME [epoch: 10.4 sec]
EPOCH 284/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3433142636908073		[learning rate: 0.002762]
	Learning Rate: 0.002762
	LOSS [training: 1.3433142636908073 | validation: 0.88293815753886]
	TIME [epoch: 10.3 sec]
EPOCH 285/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9676281137018817		[learning rate: 0.0027491]
	Learning Rate: 0.00274906
	LOSS [training: 0.9676281137018817 | validation: 0.4443317535400142]
	TIME [epoch: 10.3 sec]
EPOCH 286/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5175611227990203		[learning rate: 0.0027362]
	Learning Rate: 0.00273617
	LOSS [training: 0.5175611227990203 | validation: 0.4535609442126778]
	TIME [epoch: 10.4 sec]
EPOCH 287/500:
	Training over batches...
		[batch 5/5] avg loss: 0.40778857442400246		[learning rate: 0.0027233]
	Learning Rate: 0.00272334
	LOSS [training: 0.40778857442400246 | validation: 0.4451188605081083]
	TIME [epoch: 10.4 sec]
EPOCH 288/500:
	Training over batches...
		[batch 5/5] avg loss: 0.31539070934476954		[learning rate: 0.0027106]
	Learning Rate: 0.00271057
	LOSS [training: 0.31539070934476954 | validation: 0.3118027863133541]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_288.pth
	Model improved!!!
EPOCH 289/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3026389697229668		[learning rate: 0.0026979]
	Learning Rate: 0.00269787
	LOSS [training: 0.3026389697229668 | validation: 0.3447308883471949]
	TIME [epoch: 10.3 sec]
EPOCH 290/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3271108439087347		[learning rate: 0.0026852]
	Learning Rate: 0.00268522
	LOSS [training: 0.3271108439087347 | validation: 0.35917791344860517]
	TIME [epoch: 10.4 sec]
EPOCH 291/500:
	Training over batches...
		[batch 5/5] avg loss: 0.32753654509458424		[learning rate: 0.0026726]
	Learning Rate: 0.00267263
	LOSS [training: 0.32753654509458424 | validation: 0.2647628448996738]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_291.pth
	Model improved!!!
EPOCH 292/500:
	Training over batches...
		[batch 5/5] avg loss: 0.27160859377307545		[learning rate: 0.0026601]
	Learning Rate: 0.0026601
	LOSS [training: 0.27160859377307545 | validation: 0.43117635611615185]
	TIME [epoch: 10.3 sec]
EPOCH 293/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3803519900689783		[learning rate: 0.0026476]
	Learning Rate: 0.00264763
	LOSS [training: 0.3803519900689783 | validation: 0.48053547537063246]
	TIME [epoch: 10.3 sec]
EPOCH 294/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5370609086504167		[learning rate: 0.0026352]
	Learning Rate: 0.00263522
	LOSS [training: 0.5370609086504167 | validation: 0.6726233457968792]
	TIME [epoch: 10.4 sec]
EPOCH 295/500:
	Training over batches...
		[batch 5/5] avg loss: 0.526164969096224		[learning rate: 0.0026229]
	Learning Rate: 0.00262286
	LOSS [training: 0.526164969096224 | validation: 0.33828740927663303]
	TIME [epoch: 10.3 sec]
EPOCH 296/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3111001151387779		[learning rate: 0.0026106]
	Learning Rate: 0.00261057
	LOSS [training: 0.3111001151387779 | validation: 0.35646183890174543]
	TIME [epoch: 10.3 sec]
EPOCH 297/500:
	Training over batches...
		[batch 5/5] avg loss: 0.30927752821510507		[learning rate: 0.0025983]
	Learning Rate: 0.00259833
	LOSS [training: 0.30927752821510507 | validation: 0.30687959970779455]
	TIME [epoch: 10.3 sec]
EPOCH 298/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2516464666578164		[learning rate: 0.0025861]
	Learning Rate: 0.00258615
	LOSS [training: 0.2516464666578164 | validation: 0.26438729015018014]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_298.pth
	Model improved!!!
EPOCH 299/500:
	Training over batches...
		[batch 5/5] avg loss: 0.35479499086900795		[learning rate: 0.002574]
	Learning Rate: 0.00257402
	LOSS [training: 0.35479499086900795 | validation: 0.30394212250301594]
	TIME [epoch: 10.3 sec]
EPOCH 300/500:
	Training over batches...
		[batch 5/5] avg loss: 0.279059184889661		[learning rate: 0.002562]
	Learning Rate: 0.00256195
	LOSS [training: 0.279059184889661 | validation: 0.352654836896985]
	TIME [epoch: 10.3 sec]
EPOCH 301/500:
	Training over batches...
		[batch 5/5] avg loss: 0.39683411765651255		[learning rate: 0.0025499]
	Learning Rate: 0.00254994
	LOSS [training: 0.39683411765651255 | validation: 0.3877799935872932]
	TIME [epoch: 10.3 sec]
EPOCH 302/500:
	Training over batches...
		[batch 5/5] avg loss: 0.31049281078973806		[learning rate: 0.002538]
	Learning Rate: 0.00253799
	LOSS [training: 0.31049281078973806 | validation: 0.2751100238023911]
	TIME [epoch: 10.4 sec]
EPOCH 303/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3162139458529672		[learning rate: 0.0025261]
	Learning Rate: 0.00252609
	LOSS [training: 0.3162139458529672 | validation: 0.27349163231576806]
	TIME [epoch: 10.4 sec]
EPOCH 304/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24598603376475428		[learning rate: 0.0025142]
	Learning Rate: 0.00251425
	LOSS [training: 0.24598603376475428 | validation: 0.24729584954361675]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_304.pth
	Model improved!!!
EPOCH 305/500:
	Training over batches...
		[batch 5/5] avg loss: 0.23158946689213472		[learning rate: 0.0025025]
	Learning Rate: 0.00250246
	LOSS [training: 0.23158946689213472 | validation: 0.24832201579716107]
	TIME [epoch: 10.4 sec]
EPOCH 306/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20435588955872452		[learning rate: 0.0024907]
	Learning Rate: 0.00249073
	LOSS [training: 0.20435588955872452 | validation: 0.34018177432021207]
	TIME [epoch: 10.4 sec]
EPOCH 307/500:
	Training over batches...
		[batch 5/5] avg loss: 0.25538863490521163		[learning rate: 0.0024791]
	Learning Rate: 0.00247905
	LOSS [training: 0.25538863490521163 | validation: 0.2121995421024726]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_307.pth
	Model improved!!!
EPOCH 308/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2757836271567232		[learning rate: 0.0024674]
	Learning Rate: 0.00246743
	LOSS [training: 0.2757836271567232 | validation: 0.3032128909975775]
	TIME [epoch: 10.3 sec]
EPOCH 309/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3571694277969078		[learning rate: 0.0024559]
	Learning Rate: 0.00245586
	LOSS [training: 0.3571694277969078 | validation: 0.24566807844436958]
	TIME [epoch: 10.3 sec]
EPOCH 310/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2048517705126498		[learning rate: 0.0024443]
	Learning Rate: 0.00244435
	LOSS [training: 0.2048517705126498 | validation: 0.23809238704434157]
	TIME [epoch: 10.4 sec]
EPOCH 311/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21087314687765635		[learning rate: 0.0024329]
	Learning Rate: 0.00243289
	LOSS [training: 0.21087314687765635 | validation: 0.21606149529065896]
	TIME [epoch: 10.3 sec]
EPOCH 312/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21407178676543293		[learning rate: 0.0024215]
	Learning Rate: 0.00242148
	LOSS [training: 0.21407178676543293 | validation: 0.41483395421425684]
	TIME [epoch: 10.3 sec]
EPOCH 313/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2931901826413599		[learning rate: 0.0024101]
	Learning Rate: 0.00241013
	LOSS [training: 0.2931901826413599 | validation: 0.30758165633969137]
	TIME [epoch: 10.3 sec]
EPOCH 314/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46774818420165853		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.46774818420165853 | validation: 1.0138971651437312]
	TIME [epoch: 10.3 sec]
EPOCH 315/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45610003906172264		[learning rate: 0.0023876]
	Learning Rate: 0.00238759
	LOSS [training: 0.45610003906172264 | validation: 0.23479926483006222]
	TIME [epoch: 10.3 sec]
EPOCH 316/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4142556286789708		[learning rate: 0.0023764]
	Learning Rate: 0.00237639
	LOSS [training: 0.4142556286789708 | validation: 0.6572326713711574]
	TIME [epoch: 10.3 sec]
EPOCH 317/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6495433537370319		[learning rate: 0.0023653]
	Learning Rate: 0.00236525
	LOSS [training: 0.6495433537370319 | validation: 0.35625894658008816]
	TIME [epoch: 10.4 sec]
EPOCH 318/500:
	Training over batches...
		[batch 5/5] avg loss: 0.33876557728331597		[learning rate: 0.0023542]
	Learning Rate: 0.00235416
	LOSS [training: 0.33876557728331597 | validation: 0.5741283170085025]
	TIME [epoch: 10.4 sec]
EPOCH 319/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6270857057751019		[learning rate: 0.0023431]
	Learning Rate: 0.00234313
	LOSS [training: 0.6270857057751019 | validation: 0.4005130929884196]
	TIME [epoch: 10.4 sec]
EPOCH 320/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3376812724361085		[learning rate: 0.0023321]
	Learning Rate: 0.00233214
	LOSS [training: 0.3376812724361085 | validation: 0.17600956623906258]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_320.pth
	Model improved!!!
EPOCH 321/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17941972071948273		[learning rate: 0.0023212]
	Learning Rate: 0.00232121
	LOSS [training: 0.17941972071948273 | validation: 0.1767308589699694]
	TIME [epoch: 10.4 sec]
EPOCH 322/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7438603869081815		[learning rate: 0.0023103]
	Learning Rate: 0.00231033
	LOSS [training: 0.7438603869081815 | validation: 0.38178399321149853]
	TIME [epoch: 10.4 sec]
EPOCH 323/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4291292949181801		[learning rate: 0.0022995]
	Learning Rate: 0.0022995
	LOSS [training: 0.4291292949181801 | validation: 0.13404031001236175]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_323.pth
	Model improved!!!
EPOCH 324/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3462294972391304		[learning rate: 0.0022887]
	Learning Rate: 0.00228872
	LOSS [training: 0.3462294972391304 | validation: 0.4586971069396373]
	TIME [epoch: 10.4 sec]
EPOCH 325/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2603544552949395		[learning rate: 0.002278]
	Learning Rate: 0.00227799
	LOSS [training: 0.2603544552949395 | validation: 0.1622197818133006]
	TIME [epoch: 10.4 sec]
EPOCH 326/500:
	Training over batches...
		[batch 5/5] avg loss: 0.32749078500595297		[learning rate: 0.0022673]
	Learning Rate: 0.00226731
	LOSS [training: 0.32749078500595297 | validation: 0.17579411496581604]
	TIME [epoch: 10.3 sec]
EPOCH 327/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19201363734870142		[learning rate: 0.0022567]
	Learning Rate: 0.00225668
	LOSS [training: 0.19201363734870142 | validation: 0.2999309702261096]
	TIME [epoch: 10.3 sec]
EPOCH 328/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4558209171910842		[learning rate: 0.0022461]
	Learning Rate: 0.0022461
	LOSS [training: 0.4558209171910842 | validation: 0.1918430661472354]
	TIME [epoch: 10.3 sec]
EPOCH 329/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2656651586281543		[learning rate: 0.0022356]
	Learning Rate: 0.00223557
	LOSS [training: 0.2656651586281543 | validation: 0.1371280765565297]
	TIME [epoch: 10.4 sec]
EPOCH 330/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21093362213947428		[learning rate: 0.0022251]
	Learning Rate: 0.00222509
	LOSS [training: 0.21093362213947428 | validation: 0.13214927352629274]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_330.pth
	Model improved!!!
EPOCH 331/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2061802656218225		[learning rate: 0.0022147]
	Learning Rate: 0.00221466
	LOSS [training: 0.2061802656218225 | validation: 0.25455598071262114]
	TIME [epoch: 10.4 sec]
EPOCH 332/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2299369133547362		[learning rate: 0.0022043]
	Learning Rate: 0.00220427
	LOSS [training: 0.2299369133547362 | validation: 0.17520740598404713]
	TIME [epoch: 10.4 sec]
EPOCH 333/500:
	Training over batches...
		[batch 5/5] avg loss: 0.223098753921865		[learning rate: 0.0021939]
	Learning Rate: 0.00219394
	LOSS [training: 0.223098753921865 | validation: 0.22740356853669255]
	TIME [epoch: 10.4 sec]
EPOCH 334/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20989173765578095		[learning rate: 0.0021837]
	Learning Rate: 0.00218365
	LOSS [training: 0.20989173765578095 | validation: 0.21195730468988763]
	TIME [epoch: 10.3 sec]
EPOCH 335/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2509104194587288		[learning rate: 0.0021734]
	Learning Rate: 0.00217342
	LOSS [training: 0.2509104194587288 | validation: 0.24368249458734803]
	TIME [epoch: 10.3 sec]
EPOCH 336/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20767534135903426		[learning rate: 0.0021632]
	Learning Rate: 0.00216323
	LOSS [training: 0.20767534135903426 | validation: 0.14608159162765894]
	TIME [epoch: 10.4 sec]
EPOCH 337/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22740948988706028		[learning rate: 0.0021531]
	Learning Rate: 0.00215309
	LOSS [training: 0.22740948988706028 | validation: 0.1908338570030959]
	TIME [epoch: 10.4 sec]
EPOCH 338/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18207444028642786		[learning rate: 0.002143]
	Learning Rate: 0.00214299
	LOSS [training: 0.18207444028642786 | validation: 0.19409718829591968]
	TIME [epoch: 10.3 sec]
EPOCH 339/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1752222840132942		[learning rate: 0.0021329]
	Learning Rate: 0.00213294
	LOSS [training: 0.1752222840132942 | validation: 0.16630002197221835]
	TIME [epoch: 10.3 sec]
EPOCH 340/500:
	Training over batches...
		[batch 5/5] avg loss: 0.23456282488077038		[learning rate: 0.0021229]
	Learning Rate: 0.00212294
	LOSS [training: 0.23456282488077038 | validation: 0.36160333158012054]
	TIME [epoch: 10.4 sec]
EPOCH 341/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5866117725306801		[learning rate: 0.002113]
	Learning Rate: 0.00211299
	LOSS [training: 0.5866117725306801 | validation: 0.1962218136520715]
	TIME [epoch: 10.3 sec]
EPOCH 342/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22446408231826967		[learning rate: 0.0021031]
	Learning Rate: 0.00210309
	LOSS [training: 0.22446408231826967 | validation: 0.2794083069031705]
	TIME [epoch: 10.3 sec]
EPOCH 343/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19220650218301394		[learning rate: 0.0020932]
	Learning Rate: 0.00209323
	LOSS [training: 0.19220650218301394 | validation: 0.22724175907618435]
	TIME [epoch: 10.3 sec]
EPOCH 344/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20351315570541045		[learning rate: 0.0020834]
	Learning Rate: 0.00208341
	LOSS [training: 0.20351315570541045 | validation: 0.24346587060850247]
	TIME [epoch: 10.4 sec]
EPOCH 345/500:
	Training over batches...
		[batch 5/5] avg loss: 0.159826122223671		[learning rate: 0.0020736]
	Learning Rate: 0.00207365
	LOSS [training: 0.159826122223671 | validation: 0.22472202793426277]
	TIME [epoch: 10.3 sec]
EPOCH 346/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2709673644101659		[learning rate: 0.0020639]
	Learning Rate: 0.00206392
	LOSS [training: 0.2709673644101659 | validation: 0.30106530190753544]
	TIME [epoch: 10.3 sec]
EPOCH 347/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3373425882456788		[learning rate: 0.0020542]
	Learning Rate: 0.00205425
	LOSS [training: 0.3373425882456788 | validation: 0.24336109830081434]
	TIME [epoch: 10.3 sec]
EPOCH 348/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2252906844879184		[learning rate: 0.0020446]
	Learning Rate: 0.00204462
	LOSS [training: 0.2252906844879184 | validation: 0.30887189126475606]
	TIME [epoch: 10.4 sec]
EPOCH 349/500:
	Training over batches...
		[batch 5/5] avg loss: 0.25260197092594167		[learning rate: 0.002035]
	Learning Rate: 0.00203503
	LOSS [training: 0.25260197092594167 | validation: 0.27266725266210545]
	TIME [epoch: 10.3 sec]
EPOCH 350/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18332443418870156		[learning rate: 0.0020255]
	Learning Rate: 0.00202549
	LOSS [training: 0.18332443418870156 | validation: 0.2802732682711968]
	TIME [epoch: 10.3 sec]
EPOCH 351/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22635812156264845		[learning rate: 0.002016]
	Learning Rate: 0.002016
	LOSS [training: 0.22635812156264845 | validation: 0.162460730153256]
	TIME [epoch: 10.4 sec]
EPOCH 352/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1816573015878895		[learning rate: 0.0020065]
	Learning Rate: 0.00200655
	LOSS [training: 0.1816573015878895 | validation: 0.1539523154262383]
	TIME [epoch: 10.3 sec]
EPOCH 353/500:
	Training over batches...
		[batch 5/5] avg loss: 0.25704385025803267		[learning rate: 0.0019971]
	Learning Rate: 0.00199714
	LOSS [training: 0.25704385025803267 | validation: 0.2351959018627676]
	TIME [epoch: 10.4 sec]
EPOCH 354/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22689726958036732		[learning rate: 0.0019878]
	Learning Rate: 0.00198778
	LOSS [training: 0.22689726958036732 | validation: 0.37961661782078265]
	TIME [epoch: 10.4 sec]
EPOCH 355/500:
	Training over batches...
		[batch 5/5] avg loss: 0.37462175988233215		[learning rate: 0.0019785]
	Learning Rate: 0.00197846
	LOSS [training: 0.37462175988233215 | validation: 0.24722378126080657]
	TIME [epoch: 10.4 sec]
EPOCH 356/500:
	Training over batches...
		[batch 5/5] avg loss: 0.23743821655388947		[learning rate: 0.0019692]
	Learning Rate: 0.00196918
	LOSS [training: 0.23743821655388947 | validation: 0.33159628651959533]
	TIME [epoch: 10.3 sec]
EPOCH 357/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18576330159732182		[learning rate: 0.0019599]
	Learning Rate: 0.00195995
	LOSS [training: 0.18576330159732182 | validation: 0.20582198549684144]
	TIME [epoch: 10.3 sec]
EPOCH 358/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21854409267535124		[learning rate: 0.0019508]
	Learning Rate: 0.00195076
	LOSS [training: 0.21854409267535124 | validation: 0.2057742574328002]
	TIME [epoch: 10.4 sec]
EPOCH 359/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22133524405076116		[learning rate: 0.0019416]
	Learning Rate: 0.00194162
	LOSS [training: 0.22133524405076116 | validation: 0.27596097947312137]
	TIME [epoch: 10.3 sec]
EPOCH 360/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3402598744588867		[learning rate: 0.0019325]
	Learning Rate: 0.00193251
	LOSS [training: 0.3402598744588867 | validation: 0.19693261754848956]
	TIME [epoch: 10.3 sec]
EPOCH 361/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1910203599056185		[learning rate: 0.0019235]
	Learning Rate: 0.00192345
	LOSS [training: 0.1910203599056185 | validation: 0.2004494533494735]
	TIME [epoch: 10.3 sec]
EPOCH 362/500:
	Training over batches...
		[batch 5/5] avg loss: 0.26019015162791204		[learning rate: 0.0019144]
	Learning Rate: 0.00191444
	LOSS [training: 0.26019015162791204 | validation: 0.3560128730986646]
	TIME [epoch: 10.3 sec]
EPOCH 363/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3552607221365625		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.3552607221365625 | validation: 0.3497863038291231]
	TIME [epoch: 10.3 sec]
EPOCH 364/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3398819685903655		[learning rate: 0.0018965]
	Learning Rate: 0.00189653
	LOSS [training: 0.3398819685903655 | validation: 0.33222173783488473]
	TIME [epoch: 10.3 sec]
EPOCH 365/500:
	Training over batches...
		[batch 5/5] avg loss: 0.302764435701956		[learning rate: 0.0018876]
	Learning Rate: 0.00188764
	LOSS [training: 0.302764435701956 | validation: 0.3217561033814269]
	TIME [epoch: 10.3 sec]
EPOCH 366/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2946392588319438		[learning rate: 0.0018788]
	Learning Rate: 0.00187879
	LOSS [training: 0.2946392588319438 | validation: 0.32090964455208365]
	TIME [epoch: 10.4 sec]
EPOCH 367/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2948354183836181		[learning rate: 0.00187]
	Learning Rate: 0.00186998
	LOSS [training: 0.2948354183836181 | validation: 0.24517059774306801]
	TIME [epoch: 10.3 sec]
EPOCH 368/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2570838749445433		[learning rate: 0.0018612]
	Learning Rate: 0.00186121
	LOSS [training: 0.2570838749445433 | validation: 0.17127868891351877]
	TIME [epoch: 10.3 sec]
EPOCH 369/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3101795176327118		[learning rate: 0.0018525]
	Learning Rate: 0.00185249
	LOSS [training: 0.3101795176327118 | validation: 0.2237023853427376]
	TIME [epoch: 10.4 sec]
EPOCH 370/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2337816810222643		[learning rate: 0.0018438]
	Learning Rate: 0.0018438
	LOSS [training: 0.2337816810222643 | validation: 0.23712180904493657]
	TIME [epoch: 10.3 sec]
EPOCH 371/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18581763038964902		[learning rate: 0.0018352]
	Learning Rate: 0.00183516
	LOSS [training: 0.18581763038964902 | validation: 0.19722840492632598]
	TIME [epoch: 10.3 sec]
EPOCH 372/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5195978405949615		[learning rate: 0.0018266]
	Learning Rate: 0.00182655
	LOSS [training: 0.5195978405949615 | validation: 0.3826784188456837]
	TIME [epoch: 10.3 sec]
EPOCH 373/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21211785774502906		[learning rate: 0.001818]
	Learning Rate: 0.00181799
	LOSS [training: 0.21211785774502906 | validation: 0.09150875794629132]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_373.pth
	Model improved!!!
EPOCH 374/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12216589361413284		[learning rate: 0.0018095]
	Learning Rate: 0.00180947
	LOSS [training: 0.12216589361413284 | validation: 0.17618434225057292]
	TIME [epoch: 10.3 sec]
EPOCH 375/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1943083959431801		[learning rate: 0.001801]
	Learning Rate: 0.00180099
	LOSS [training: 0.1943083959431801 | validation: 0.08692115568399686]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_375.pth
	Model improved!!!
EPOCH 376/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1486058509014807		[learning rate: 0.0017925]
	Learning Rate: 0.00179254
	LOSS [training: 0.1486058509014807 | validation: 0.32521291554055354]
	TIME [epoch: 10.4 sec]
EPOCH 377/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24469656647038346		[learning rate: 0.0017841]
	Learning Rate: 0.00178414
	LOSS [training: 0.24469656647038346 | validation: 0.28524247523781426]
	TIME [epoch: 10.4 sec]
EPOCH 378/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2724628544265725		[learning rate: 0.0017758]
	Learning Rate: 0.00177577
	LOSS [training: 0.2724628544265725 | validation: 0.20513128501503325]
	TIME [epoch: 10.4 sec]
EPOCH 379/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2777797903332373		[learning rate: 0.0017674]
	Learning Rate: 0.00176745
	LOSS [training: 0.2777797903332373 | validation: 0.4836363622022012]
	TIME [epoch: 10.3 sec]
EPOCH 380/500:
	Training over batches...
		[batch 5/5] avg loss: 0.36641286000355067		[learning rate: 0.0017592]
	Learning Rate: 0.00175916
	LOSS [training: 0.36641286000355067 | validation: 0.13604252229472658]
	TIME [epoch: 10.3 sec]
EPOCH 381/500:
	Training over batches...
		[batch 5/5] avg loss: 0.10647221639765003		[learning rate: 0.0017509]
	Learning Rate: 0.00175092
	LOSS [training: 0.10647221639765003 | validation: 0.11553156811451512]
	TIME [epoch: 10.4 sec]
EPOCH 382/500:
	Training over batches...
		[batch 5/5] avg loss: 0.09776094038388858		[learning rate: 0.0017427]
	Learning Rate: 0.00174271
	LOSS [training: 0.09776094038388858 | validation: 0.06616737102645347]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_382.pth
	Model improved!!!
EPOCH 383/500:
	Training over batches...
		[batch 5/5] avg loss: 0.14388021103683282		[learning rate: 0.0017345]
	Learning Rate: 0.00173454
	LOSS [training: 0.14388021103683282 | validation: 0.22581704760107665]
	TIME [epoch: 10.3 sec]
EPOCH 384/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18987891478917457		[learning rate: 0.0017264]
	Learning Rate: 0.00172641
	LOSS [training: 0.18987891478917457 | validation: 0.11676685891763786]
	TIME [epoch: 10.3 sec]
EPOCH 385/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12000192909642475		[learning rate: 0.0017183]
	Learning Rate: 0.00171831
	LOSS [training: 0.12000192909642475 | validation: 0.1448531360272582]
	TIME [epoch: 10.3 sec]
EPOCH 386/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12829519433965866		[learning rate: 0.0017103]
	Learning Rate: 0.00171026
	LOSS [training: 0.12829519433965866 | validation: 0.1335648927084039]
	TIME [epoch: 10.3 sec]
EPOCH 387/500:
	Training over batches...
		[batch 5/5] avg loss: 0.11359092166134618		[learning rate: 0.0017022]
	Learning Rate: 0.00170224
	LOSS [training: 0.11359092166134618 | validation: 0.21880485609170258]
	TIME [epoch: 10.3 sec]
EPOCH 388/500:
	Training over batches...
		[batch 5/5] avg loss: 0.14642585168763028		[learning rate: 0.0016943]
	Learning Rate: 0.00169426
	LOSS [training: 0.14642585168763028 | validation: 0.15965262173412056]
	TIME [epoch: 10.4 sec]
EPOCH 389/500:
	Training over batches...
		[batch 5/5] avg loss: 0.10147393883891102		[learning rate: 0.0016863]
	Learning Rate: 0.00168632
	LOSS [training: 0.10147393883891102 | validation: 0.07006363565191354]
	TIME [epoch: 10.3 sec]
EPOCH 390/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12771165593385608		[learning rate: 0.0016784]
	Learning Rate: 0.00167841
	LOSS [training: 0.12771165593385608 | validation: 0.12725863665312737]
	TIME [epoch: 10.3 sec]
EPOCH 391/500:
	Training over batches...
		[batch 5/5] avg loss: 0.10263137348842348		[learning rate: 0.0016705]
	Learning Rate: 0.00167054
	LOSS [training: 0.10263137348842348 | validation: 0.07152627876114917]
	TIME [epoch: 10.3 sec]
EPOCH 392/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12705371794349962		[learning rate: 0.0016627]
	Learning Rate: 0.00166271
	LOSS [training: 0.12705371794349962 | validation: 0.2253422436025162]
	TIME [epoch: 10.4 sec]
EPOCH 393/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20938570957751157		[learning rate: 0.0016549]
	Learning Rate: 0.00165491
	LOSS [training: 0.20938570957751157 | validation: 0.14695029101083715]
	TIME [epoch: 10.3 sec]
EPOCH 394/500:
	Training over batches...
		[batch 5/5] avg loss: 0.14518343824455238		[learning rate: 0.0016472]
	Learning Rate: 0.00164716
	LOSS [training: 0.14518343824455238 | validation: 0.09344635646010353]
	TIME [epoch: 10.3 sec]
EPOCH 395/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15084683073353328		[learning rate: 0.0016394]
	Learning Rate: 0.00163943
	LOSS [training: 0.15084683073353328 | validation: 0.34252824107689545]
	TIME [epoch: 10.3 sec]
EPOCH 396/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4035087297071295		[learning rate: 0.0016317]
	Learning Rate: 0.00163175
	LOSS [training: 0.4035087297071295 | validation: 0.32571620714788324]
	TIME [epoch: 10.4 sec]
EPOCH 397/500:
	Training over batches...
		[batch 5/5] avg loss: 0.23214321908830815		[learning rate: 0.0016241]
	Learning Rate: 0.0016241
	LOSS [training: 0.23214321908830815 | validation: 0.2536001577264856]
	TIME [epoch: 10.3 sec]
EPOCH 398/500:
	Training over batches...
		[batch 5/5] avg loss: 0.28223419763135577		[learning rate: 0.0016165]
	Learning Rate: 0.00161648
	LOSS [training: 0.28223419763135577 | validation: 0.18140480021818725]
	TIME [epoch: 10.3 sec]
EPOCH 399/500:
	Training over batches...
		[batch 5/5] avg loss: 0.09381484440654154		[learning rate: 0.0016089]
	Learning Rate: 0.00160891
	LOSS [training: 0.09381484440654154 | validation: 0.16451598249971341]
	TIME [epoch: 10.4 sec]
EPOCH 400/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2564551625257284		[learning rate: 0.0016014]
	Learning Rate: 0.00160136
	LOSS [training: 0.2564551625257284 | validation: 0.17418700582457297]
	TIME [epoch: 10.3 sec]
EPOCH 401/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1248916940210413		[learning rate: 0.0015939]
	Learning Rate: 0.00159386
	LOSS [training: 0.1248916940210413 | validation: 0.0855246125552849]
	TIME [epoch: 10.4 sec]
EPOCH 402/500:
	Training over batches...
		[batch 5/5] avg loss: 0.13606383846694203		[learning rate: 0.0015864]
	Learning Rate: 0.00158638
	LOSS [training: 0.13606383846694203 | validation: 0.19833681565953282]
	TIME [epoch: 10.3 sec]
EPOCH 403/500:
	Training over batches...
		[batch 5/5] avg loss: 0.23320390061999824		[learning rate: 0.0015789]
	Learning Rate: 0.00157895
	LOSS [training: 0.23320390061999824 | validation: 0.08723680675656578]
	TIME [epoch: 10.4 sec]
EPOCH 404/500:
	Training over batches...
		[batch 5/5] avg loss: 0.14502615408784847		[learning rate: 0.0015715]
	Learning Rate: 0.00157154
	LOSS [training: 0.14502615408784847 | validation: 0.2600619560386068]
	TIME [epoch: 10.3 sec]
EPOCH 405/500:
	Training over batches...
		[batch 5/5] avg loss: 0.26898196626863075		[learning rate: 0.0015642]
	Learning Rate: 0.00156418
	LOSS [training: 0.26898196626863075 | validation: 0.11450985024633135]
	TIME [epoch: 10.3 sec]
EPOCH 406/500:
	Training over batches...
		[batch 5/5] avg loss: 0.0841626172836186		[learning rate: 0.0015568]
	Learning Rate: 0.00155684
	LOSS [training: 0.0841626172836186 | validation: 0.05798872309353641]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240214_194920/states/model_tr_study6_406.pth
	Model improved!!!
EPOCH 407/500:
	Training over batches...
		[batch 5/5] avg loss: 0.07573333363165316		[learning rate: 0.0015495]
	Learning Rate: 0.00154954
	LOSS [training: 0.07573333363165316 | validation: 0.0967199334737544]
	TIME [epoch: 10.4 sec]
EPOCH 408/500:
	Training over batches...
		[batch 5/5] avg loss: 0.11520921190697116		[learning rate: 0.0015423]
	Learning Rate: 0.00154228
	LOSS [training: 0.11520921190697116 | validation: 0.07350257536503657]
	TIME [epoch: 10.3 sec]
EPOCH 409/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12123896092783551		[learning rate: 0.001535]
	Learning Rate: 0.00153505
	LOSS [training: 0.12123896092783551 | validation: 0.07082826791542995]
	TIME [epoch: 10.3 sec]
EPOCH 410/500:
	Training over batches...
		[batch 5/5] avg loss: 0.10871107726631965		[learning rate: 0.0015279]
	Learning Rate: 0.00152785
	LOSS [training: 0.10871107726631965 | validation: 0.08089532976293068]
	TIME [epoch: 10.3 sec]
EPOCH 411/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1472262632467039		[learning rate: 0.0015207]
	Learning Rate: 0.00152069
	LOSS [training: 0.1472262632467039 | validation: 0.2245835155635739]
	TIME [epoch: 10.4 sec]
EPOCH 412/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3131658607006777		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.3131658607006777 | validation: 0.10929172307154154]
	TIME [epoch: 10.3 sec]
EPOCH 413/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1627123085755661		[learning rate: 0.0015065]
	Learning Rate: 0.00150647
	LOSS [training: 0.1627123085755661 | validation: 0.16740040486063482]
	TIME [epoch: 10.3 sec]
EPOCH 414/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2203555556538177		[learning rate: 0.0014994]
	Learning Rate: 0.0014994
	LOSS [training: 0.2203555556538177 | validation: 0.22676816422047189]
	TIME [epoch: 10.3 sec]
EPOCH 415/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3179747547685493		[learning rate: 0.0014924]
	Learning Rate: 0.00149237
	LOSS [training: 0.3179747547685493 | validation: 0.2840142793018398]
	TIME [epoch: 10.3 sec]
EPOCH 416/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18358605725983373		[learning rate: 0.0014854]
	Learning Rate: 0.00148538
	LOSS [training: 0.18358605725983373 | validation: 0.15497007931968282]
	TIME [epoch: 10.3 sec]
EPOCH 417/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15688077424257413		[learning rate: 0.0014784]
	Learning Rate: 0.00147841
	LOSS [training: 0.15688077424257413 | validation: 0.18089052284255489]
	TIME [epoch: 10.3 sec]
EPOCH 418/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17329691068462283		[learning rate: 0.0014715]
	Learning Rate: 0.00147148
	LOSS [training: 0.17329691068462283 | validation: 0.22177012284386904]
	TIME [epoch: 10.4 sec]
EPOCH 419/500:
	Training over batches...
		[batch 5/5] avg loss: 0.13267999374880382		[learning rate: 0.0014646]
	Learning Rate: 0.00146458
	LOSS [training: 0.13267999374880382 | validation: 0.2691734670206078]
	TIME [epoch: 10.3 sec]
EPOCH 420/500:
	Training over batches...
		[batch 5/5] avg loss: 0.37087042460354613		[learning rate: 0.0014577]
	Learning Rate: 0.00145772
	LOSS [training: 0.37087042460354613 | validation: 0.42939104134667333]
	TIME [epoch: 10.3 sec]
EPOCH 421/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3217793478117851		[learning rate: 0.0014509]
	Learning Rate: 0.00145088
	LOSS [training: 0.3217793478117851 | validation: 0.16229409131483774]
	TIME [epoch: 10.3 sec]
EPOCH 422/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1361437944057388		[learning rate: 0.0014441]
	Learning Rate: 0.00144408
	LOSS [training: 0.1361437944057388 | validation: 0.15381434652329654]
	TIME [epoch: 10.4 sec]
EPOCH 423/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12512947746334474		[learning rate: 0.0014373]
	Learning Rate: 0.00143731
	LOSS [training: 0.12512947746334474 | validation: 0.1619772464838826]
	TIME [epoch: 10.3 sec]
EPOCH 424/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15174875374843533		[learning rate: 0.0014306]
	Learning Rate: 0.00143057
	LOSS [training: 0.15174875374843533 | validation: 0.08971517730881087]
	TIME [epoch: 10.3 sec]
EPOCH 425/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12644287132108803		[learning rate: 0.0014239]
	Learning Rate: 0.00142387
	LOSS [training: 0.12644287132108803 | validation: 0.19413566980761424]
	TIME [epoch: 10.4 sec]
EPOCH 426/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15489762804926835		[learning rate: 0.0014172]
	Learning Rate: 0.00141719
	LOSS [training: 0.15489762804926835 | validation: 0.14637776715123402]
	TIME [epoch: 10.3 sec]
EPOCH 427/500:
	Training over batches...
		[batch 5/5] avg loss: 0.10715868150079019		[learning rate: 0.0014105]
	Learning Rate: 0.00141055
	LOSS [training: 0.10715868150079019 | validation: 0.06525909871720666]
	TIME [epoch: 10.3 sec]
EPOCH 428/500:
	Training over batches...
		[batch 5/5] avg loss: 0.11679667001452318		[learning rate: 0.0014039]
	Learning Rate: 0.00140393
	LOSS [training: 0.11679667001452318 | validation: 0.15238219003671552]
	TIME [epoch: 10.3 sec]
EPOCH 429/500:
	Training over batches...
		[batch 5/5] avg loss: 0.16099135537394174		[learning rate: 0.0013974]
	Learning Rate: 0.00139735
	LOSS [training: 0.16099135537394174 | validation: 0.17005468124046935]
	TIME [epoch: 10.4 sec]
EPOCH 430/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2520263481586765		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.2520263481586765 | validation: 0.11019496052842835]
	TIME [epoch: 10.3 sec]
EPOCH 431/500:
	Training over batches...
		[batch 5/5] avg loss: 0.14152432619917182		[learning rate: 0.0013843]
	Learning Rate: 0.00138428
	LOSS [training: 0.14152432619917182 | validation: 0.1622002135505876]
	TIME [epoch: 10.3 sec]
EPOCH 432/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12763865825526502		[learning rate: 0.0013778]
	Learning Rate: 0.00137779
	LOSS [training: 0.12763865825526502 | validation: 0.3647308206968542]
	TIME [epoch: 10.3 sec]
EPOCH 433/500:
	Training over batches...
		[batch 5/5] avg loss: 0.27609573296129813		[learning rate: 0.0013713]
	Learning Rate: 0.00137133
	LOSS [training: 0.27609573296129813 | validation: 0.17989140142461404]
	TIME [epoch: 10.4 sec]
EPOCH 434/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12499428927387121		[learning rate: 0.0013649]
	Learning Rate: 0.0013649
	LOSS [training: 0.12499428927387121 | validation: 0.12351859055008642]
	TIME [epoch: 10.3 sec]
EPOCH 435/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21937779044801795		[learning rate: 0.0013585]
	Learning Rate: 0.0013585
	LOSS [training: 0.21937779044801795 | validation: 0.32195281386171354]
	TIME [epoch: 10.3 sec]
EPOCH 436/500:
	Training over batches...
		[batch 5/5] avg loss: 0.36484575277626075		[learning rate: 0.0013521]
	Learning Rate: 0.00135214
	LOSS [training: 0.36484575277626075 | validation: 0.26325166614966017]
	TIME [epoch: 10.4 sec]
EPOCH 437/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2815941896221321		[learning rate: 0.0013458]
	Learning Rate: 0.0013458
	LOSS [training: 1.2815941896221321 | validation: 1.4316307512492872]
	TIME [epoch: 10.4 sec]
EPOCH 438/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1580797891509937		[learning rate: 0.0013395]
	Learning Rate: 0.00133949
	LOSS [training: 2.1580797891509937 | validation: 1.4654509824153024]
	TIME [epoch: 10.3 sec]
EPOCH 439/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9339169248032615		[learning rate: 0.0013332]
	Learning Rate: 0.00133321
	LOSS [training: 1.9339169248032615 | validation: 1.1646602630515188]
	TIME [epoch: 10.3 sec]
EPOCH 440/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2124197836976789		[learning rate: 0.001327]
	Learning Rate: 0.00132696
	LOSS [training: 1.2124197836976789 | validation: 0.18043671729506575]
	TIME [epoch: 10.4 sec]
EPOCH 441/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18657939299817466		[learning rate: 0.0013207]
	Learning Rate: 0.00132074
	LOSS [training: 0.18657939299817466 | validation: 0.3624273549513755]
	TIME [epoch: 10.3 sec]
EPOCH 442/500:
	Training over batches...
		[batch 5/5] avg loss: 0.30813261874978753		[learning rate: 0.0013145]
	Learning Rate: 0.00131454
	LOSS [training: 0.30813261874978753 | validation: 0.18181958200156967]
	TIME [epoch: 10.3 sec]
EPOCH 443/500:
	Training over batches...
		[batch 5/5] avg loss: 0.16203939318270313		[learning rate: 0.0013084]
	Learning Rate: 0.00130838
	LOSS [training: 0.16203939318270313 | validation: 0.26724226230153525]
	TIME [epoch: 10.4 sec]
EPOCH 444/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1668039323143374		[learning rate: 0.0013022]
	Learning Rate: 0.00130225
	LOSS [training: 0.1668039323143374 | validation: 0.1308447454169732]
	TIME [epoch: 10.4 sec]
EPOCH 445/500:
	Training over batches...
		[batch 5/5] avg loss: 0.14051077109398694		[learning rate: 0.0012961]
	Learning Rate: 0.00129614
	LOSS [training: 0.14051077109398694 | validation: 0.16374824495819598]
	TIME [epoch: 10.3 sec]
EPOCH 446/500:
	Training over batches...
		[batch 5/5] avg loss: 0.14563775624062042		[learning rate: 0.0012901]
	Learning Rate: 0.00129007
	LOSS [training: 0.14563775624062042 | validation: 0.25795664623172315]
	TIME [epoch: 10.3 sec]
EPOCH 447/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20884643107684733		[learning rate: 0.001284]
	Learning Rate: 0.00128402
	LOSS [training: 0.20884643107684733 | validation: 0.22783298082721648]
	TIME [epoch: 10.4 sec]
EPOCH 448/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19727683664490625		[learning rate: 0.001278]
	Learning Rate: 0.001278
	LOSS [training: 0.19727683664490625 | validation: 0.14931583076008437]
	TIME [epoch: 10.3 sec]
EPOCH 449/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15657284502144345		[learning rate: 0.001272]
	Learning Rate: 0.00127201
	LOSS [training: 0.15657284502144345 | validation: 0.24740994934292468]
	TIME [epoch: 10.3 sec]
EPOCH 450/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20551718558330473		[learning rate: 0.001266]
	Learning Rate: 0.00126604
	LOSS [training: 0.20551718558330473 | validation: 0.170098429360738]
	TIME [epoch: 10.3 sec]
EPOCH 451/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17473006843548922		[learning rate: 0.0012601]
	Learning Rate: 0.00126011
	LOSS [training: 0.17473006843548922 | validation: 0.26356329498385267]
	TIME [epoch: 10.3 sec]
EPOCH 452/500:
	Training over batches...
		[batch 5/5] avg loss: 0.27189457392090677		[learning rate: 0.0012542]
	Learning Rate: 0.0012542
	LOSS [training: 0.27189457392090677 | validation: 0.24660161237510658]
	TIME [epoch: 10.3 sec]
EPOCH 453/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18261349599960858		[learning rate: 0.0012483]
	Learning Rate: 0.00124832
	LOSS [training: 0.18261349599960858 | validation: 0.10172791414888505]
	TIME [epoch: 10.3 sec]
EPOCH 454/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18446800944847905		[learning rate: 0.0012425]
	Learning Rate: 0.00124247
	LOSS [training: 0.18446800944847905 | validation: 0.1547539819210118]
	TIME [epoch: 10.3 sec]
EPOCH 455/500:
	Training over batches...
		[batch 5/5] avg loss: 0.14484021131857885		[learning rate: 0.0012366]
	Learning Rate: 0.00123664
	LOSS [training: 0.14484021131857885 | validation: 0.19934569896428808]
	TIME [epoch: 10.4 sec]
EPOCH 456/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1532379270977858		[learning rate: 0.0012308]
	Learning Rate: 0.00123085
	LOSS [training: 0.1532379270977858 | validation: 0.1543517855972747]
	TIME [epoch: 10.3 sec]
EPOCH 457/500:
	Training over batches...
		[batch 5/5] avg loss: 0.13095916557814977		[learning rate: 0.0012251]
	Learning Rate: 0.00122508
	LOSS [training: 0.13095916557814977 | validation: 0.1426090978520444]
	TIME [epoch: 10.3 sec]
EPOCH 458/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1212953152144145		[learning rate: 0.0012193]
	Learning Rate: 0.00121933
	LOSS [training: 0.1212953152144145 | validation: 0.15123195393887595]
	TIME [epoch: 10.4 sec]
EPOCH 459/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12078434782832463		[learning rate: 0.0012136]
	Learning Rate: 0.00121362
	LOSS [training: 0.12078434782832463 | validation: 0.1405654408654343]
	TIME [epoch: 10.3 sec]
EPOCH 460/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3446968955531113		[learning rate: 0.0012079]
	Learning Rate: 0.00120793
	LOSS [training: 0.3446968955531113 | validation: 0.1125304908699879]
	TIME [epoch: 10.3 sec]
EPOCH 461/500:
	Training over batches...
		[batch 5/5] avg loss: 0.10422291004177786		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.10422291004177786 | validation: 0.14302277865610397]
	TIME [epoch: 10.3 sec]
EPOCH 462/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1299034843834645		[learning rate: 0.0011966]
	Learning Rate: 0.00119663
	LOSS [training: 0.1299034843834645 | validation: 0.06371777237033104]
	TIME [epoch: 10.4 sec]
EPOCH 463/500:
	Training over batches...
		[batch 5/5] avg loss: 0.10587441466290878		[learning rate: 0.001191]
	Learning Rate: 0.00119102
	LOSS [training: 0.10587441466290878 | validation: 0.1960133770591952]
	TIME [epoch: 10.3 sec]
EPOCH 464/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19492089910428104		[learning rate: 0.0011854]
	Learning Rate: 0.00118543
	LOSS [training: 0.19492089910428104 | validation: 0.0807217059782878]
	TIME [epoch: 10.3 sec]
EPOCH 465/500:
	Training over batches...
		[batch 5/5] avg loss: 0.13385321014465196		[learning rate: 0.0011799]
	Learning Rate: 0.00117988
	LOSS [training: 0.13385321014465196 | validation: 0.08822604648545923]
	TIME [epoch: 10.3 sec]
EPOCH 466/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17651685111146181		[learning rate: 0.0011743]
	Learning Rate: 0.00117435
	LOSS [training: 0.17651685111146181 | validation: 0.1665190409935529]
	TIME [epoch: 10.4 sec]
EPOCH 467/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1728158862374798		[learning rate: 0.0011688]
	Learning Rate: 0.00116884
	LOSS [training: 0.1728158862374798 | validation: 0.2763138975334414]
	TIME [epoch: 10.3 sec]
EPOCH 468/500:
	Training over batches...
		[batch 5/5] avg loss: 0.16149190507890782		[learning rate: 0.0011634]
	Learning Rate: 0.00116336
	LOSS [training: 0.16149190507890782 | validation: 0.08621099333560471]
	TIME [epoch: 10.3 sec]
EPOCH 469/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12537734718101795		[learning rate: 0.0011579]
	Learning Rate: 0.00115791
	LOSS [training: 0.12537734718101795 | validation: 0.23783863671210248]
	TIME [epoch: 10.4 sec]
EPOCH 470/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19000657386324935		[learning rate: 0.0011525]
	Learning Rate: 0.00115248
	LOSS [training: 0.19000657386324935 | validation: 0.14027075510441106]
	TIME [epoch: 10.3 sec]
EPOCH 471/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15837726239753522		[learning rate: 0.0011471]
	Learning Rate: 0.00114708
	LOSS [training: 0.15837726239753522 | validation: 0.08658439342744624]
	TIME [epoch: 10.3 sec]
EPOCH 472/500:
	Training over batches...
		[batch 5/5] avg loss: 0.11052745581969614		[learning rate: 0.0011417]
	Learning Rate: 0.0011417
	LOSS [training: 0.11052745581969614 | validation: 0.11459299441036526]
	TIME [epoch: 10.3 sec]
EPOCH 473/500:
	Training over batches...
		[batch 5/5] avg loss: 0.11879691498937354		[learning rate: 0.0011363]
	Learning Rate: 0.00113635
	LOSS [training: 0.11879691498937354 | validation: 0.10501221092254268]
	TIME [epoch: 10.4 sec]
EPOCH 474/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18101733660203695		[learning rate: 0.001131]
	Learning Rate: 0.00113102
	LOSS [training: 0.18101733660203695 | validation: 0.3901585026805378]
	TIME [epoch: 10.3 sec]
EPOCH 475/500:
	Training over batches...
		[batch 5/5] avg loss: 0.382833166549258		[learning rate: 0.0011257]
	Learning Rate: 0.00112572
	LOSS [training: 0.382833166549258 | validation: 0.2280505983844898]
	TIME [epoch: 10.3 sec]
EPOCH 476/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20457174262502403		[learning rate: 0.0011204]
	Learning Rate: 0.00112044
	LOSS [training: 0.20457174262502403 | validation: 0.1249334785425448]
	TIME [epoch: 10.3 sec]
EPOCH 477/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17649538161366962		[learning rate: 0.0011152]
	Learning Rate: 0.00111518
	LOSS [training: 0.17649538161366962 | validation: 0.10627906312647113]
	TIME [epoch: 10.3 sec]
EPOCH 478/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12234434401284355		[learning rate: 0.00111]
	Learning Rate: 0.00110996
	LOSS [training: 0.12234434401284355 | validation: 0.08006116884903315]
	TIME [epoch: 10.3 sec]
EPOCH 479/500:
	Training over batches...
		[batch 5/5] avg loss: 0.10183431497830278		[learning rate: 0.0011048]
	Learning Rate: 0.00110475
	LOSS [training: 0.10183431497830278 | validation: 0.08939298321001916]
	TIME [epoch: 10.3 sec]
EPOCH 480/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18131392316289832		[learning rate: 0.0010996]
	Learning Rate: 0.00109957
	LOSS [training: 0.18131392316289832 | validation: 0.08972051940012053]
	TIME [epoch: 10.4 sec]
EPOCH 481/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1154313301507817		[learning rate: 0.0010944]
	Learning Rate: 0.00109442
	LOSS [training: 0.1154313301507817 | validation: 0.12659324324188284]
	TIME [epoch: 10.4 sec]
EPOCH 482/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12847458981245927		[learning rate: 0.0010893]
	Learning Rate: 0.00108929
	LOSS [training: 0.12847458981245927 | validation: 0.1108992315633407]
	TIME [epoch: 10.3 sec]
EPOCH 483/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22717492892874658		[learning rate: 0.0010842]
	Learning Rate: 0.00108418
	LOSS [training: 0.22717492892874658 | validation: 0.20266729830142335]
	TIME [epoch: 10.3 sec]
EPOCH 484/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1891760520233286		[learning rate: 0.0010791]
	Learning Rate: 0.0010791
	LOSS [training: 0.1891760520233286 | validation: 0.09832991643432487]
	TIME [epoch: 10.4 sec]
EPOCH 485/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2173315312269001		[learning rate: 0.001074]
	Learning Rate: 0.00107404
	LOSS [training: 0.2173315312269001 | validation: 0.20932767953600795]
	TIME [epoch: 10.3 sec]
EPOCH 486/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22239976827071734		[learning rate: 0.001069]
	Learning Rate: 0.001069
	LOSS [training: 0.22239976827071734 | validation: 0.17572816142497943]
	TIME [epoch: 10.3 sec]
EPOCH 487/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22257142896446439		[learning rate: 0.001064]
	Learning Rate: 0.00106399
	LOSS [training: 0.22257142896446439 | validation: 0.11747409179680193]
	TIME [epoch: 10.3 sec]
EPOCH 488/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12880284227695504		[learning rate: 0.001059]
	Learning Rate: 0.001059
	LOSS [training: 0.12880284227695504 | validation: 0.15234744576981632]
	TIME [epoch: 10.3 sec]
EPOCH 489/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17491232474362595		[learning rate: 0.001054]
	Learning Rate: 0.00105404
	LOSS [training: 0.17491232474362595 | validation: 0.20723622754158896]
	TIME [epoch: 10.3 sec]
EPOCH 490/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17120721383160437		[learning rate: 0.0010491]
	Learning Rate: 0.0010491
	LOSS [training: 0.17120721383160437 | validation: 0.09978391412177728]
	TIME [epoch: 10.3 sec]
EPOCH 491/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1449996623977351		[learning rate: 0.0010442]
	Learning Rate: 0.00104418
	LOSS [training: 0.1449996623977351 | validation: 0.11365848771087347]
	TIME [epoch: 10.3 sec]
EPOCH 492/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18934874733043922		[learning rate: 0.0010393]
	Learning Rate: 0.00103929
	LOSS [training: 0.18934874733043922 | validation: 0.26429484674075937]
	TIME [epoch: 10.3 sec]
EPOCH 493/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24283436188878188		[learning rate: 0.0010344]
	Learning Rate: 0.00103441
	LOSS [training: 0.24283436188878188 | validation: 0.2081699644875959]
	TIME [epoch: 10.3 sec]
EPOCH 494/500:
	Training over batches...
		[batch 5/5] avg loss: 0.27418454910704515		[learning rate: 0.0010296]
	Learning Rate: 0.00102956
	LOSS [training: 0.27418454910704515 | validation: 0.2527580843408245]
	TIME [epoch: 10.3 sec]
EPOCH 495/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1838620568492133		[learning rate: 0.0010247]
	Learning Rate: 0.00102474
	LOSS [training: 0.1838620568492133 | validation: 0.13853432290971904]
	TIME [epoch: 10.4 sec]
EPOCH 496/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19397963918041597		[learning rate: 0.0010199]
	Learning Rate: 0.00101993
	LOSS [training: 0.19397963918041597 | validation: 0.18540289001282656]
	TIME [epoch: 10.3 sec]
EPOCH 497/500:
	Training over batches...
		[batch 5/5] avg loss: 0.30755014599996006		[learning rate: 0.0010152]
	Learning Rate: 0.00101515
	LOSS [training: 0.30755014599996006 | validation: 0.31113512283155176]
	TIME [epoch: 10.3 sec]
EPOCH 498/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2753117934888923		[learning rate: 0.0010104]
	Learning Rate: 0.00101039
	LOSS [training: 0.2753117934888923 | validation: 0.2296346685706672]
	TIME [epoch: 10.3 sec]
EPOCH 499/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2201678422444397		[learning rate: 0.0010057]
	Learning Rate: 0.00100565
	LOSS [training: 0.2201678422444397 | validation: 0.13522252636026913]
	TIME [epoch: 10.3 sec]
EPOCH 500/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19011271510173128		[learning rate: 0.0010009]
	Learning Rate: 0.00100094
	LOSS [training: 0.19011271510173128 | validation: 0.09481016646871272]
	TIME [epoch: 10.3 sec]
Finished training in 5243.992 seconds.
