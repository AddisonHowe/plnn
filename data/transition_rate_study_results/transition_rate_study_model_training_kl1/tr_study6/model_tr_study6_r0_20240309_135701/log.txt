Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r0', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4046832698

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.905209453202147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.905209453202147 | validation: 5.921014771878633]
	TIME [epoch: 112 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.03259439327644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.03259439327644 | validation: 5.159977283495087]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.110790926904994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.110790926904994 | validation: 4.804394096458217]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.916999821073322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.916999821073322 | validation: 4.6197612163048465]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.541576304365987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.541576304365987 | validation: 4.33557792983177]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3098648442922345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3098648442922345 | validation: 4.320836061223008]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.155715069609201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.155715069609201 | validation: 3.473390331750291]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.815573358826889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.815573358826889 | validation: 3.429082493092183]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6614680579841705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6614680579841705 | validation: 3.325520979875929]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5393798597728585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5393798597728585 | validation: 3.2043974382207563]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.46578482092451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.46578482092451 | validation: 3.190743615820378]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5822604792502615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5822604792502615 | validation: 3.141869705505351]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.462030469807084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.462030469807084 | validation: 3.1816161016952096]
	TIME [epoch: 24.8 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.318320603592157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.318320603592157 | validation: 3.1855102960210933]
	TIME [epoch: 24.8 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2779926623880398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2779926623880398 | validation: 3.0848405072770526]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.233344069876509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.233344069876509 | validation: 2.928137945548572]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.11005130261902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.11005130261902 | validation: 4.090703940503702]
	TIME [epoch: 24.8 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.823342822349451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.823342822349451 | validation: 2.9844197751669275]
	TIME [epoch: 24.8 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.304837116165824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.304837116165824 | validation: 2.9670040379644957]
	TIME [epoch: 24.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1217263416009495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1217263416009495 | validation: 3.145192577755245]
	TIME [epoch: 24.8 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1041295887729734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1041295887729734 | validation: 3.0631467665013723]
	TIME [epoch: 24.7 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9941842056101926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9941842056101926 | validation: 2.7070270352765546]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.217686157061856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.217686157061856 | validation: 4.595234527033175]
	TIME [epoch: 24.8 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6224962263059433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6224962263059433 | validation: 2.9253731054319103]
	TIME [epoch: 24.8 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9268776115902426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9268776115902426 | validation: 2.660355891885059]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.797161489807154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.797161489807154 | validation: 2.6006703675322878]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0827951652134007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0827951652134007 | validation: 4.0856640593422195]
	TIME [epoch: 24.7 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2983399891602376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2983399891602376 | validation: 2.761159811845764]
	TIME [epoch: 24.7 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.777153974114638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.777153974114638 | validation: 2.5657226685209884]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.705178324480932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.705178324480932 | validation: 2.4899415992888656]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7264838803732525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7264838803732525 | validation: 3.2565412953127657]
	TIME [epoch: 24.7 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7192245763586174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7192245763586174 | validation: 2.3416345570284487]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.873487244930304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.873487244930304 | validation: 3.5537300544153925]
	TIME [epoch: 24.7 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.071771886558784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.071771886558784 | validation: 7.609386431452028]
	TIME [epoch: 24.7 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.095661990059846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.095661990059846 | validation: 4.866204280490404]
	TIME [epoch: 24.7 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.107339453737518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.107339453737518 | validation: 4.234902288479368]
	TIME [epoch: 24.7 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.726822497810143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.726822497810143 | validation: 3.6344943967028165]
	TIME [epoch: 24.7 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.448928661039172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.448928661039172 | validation: 4.074227168479028]
	TIME [epoch: 24.7 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.112807187772434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.112807187772434 | validation: 4.2800207023457535]
	TIME [epoch: 24.7 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5994563259463805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5994563259463805 | validation: 4.704517237680476]
	TIME [epoch: 24.7 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.121948158507726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.121948158507726 | validation: 4.461225279178861]
	TIME [epoch: 24.7 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.970012015323084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.970012015323084 | validation: 3.8452180517745185]
	TIME [epoch: 24.7 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7523492127303317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7523492127303317 | validation: 3.391811448981201]
	TIME [epoch: 24.7 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4929498448896723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4929498448896723 | validation: 3.6294231226802665]
	TIME [epoch: 24.7 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3354993733762335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3354993733762335 | validation: 3.5756088040843435]
	TIME [epoch: 24.7 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.248229708822189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.248229708822189 | validation: 3.387983493358271]
	TIME [epoch: 24.7 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9757986151810583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9757986151810583 | validation: 2.5116979588510286]
	TIME [epoch: 24.7 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7038170548001847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7038170548001847 | validation: 3.1708956924967957]
	TIME [epoch: 24.7 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3507200329353095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3507200329353095 | validation: 3.176789631182399]
	TIME [epoch: 24.7 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.182760967949601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.182760967949601 | validation: 3.9092051691979783]
	TIME [epoch: 24.7 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.136895102683016		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.136895102683016 | validation: 5.173037675663738]
	TIME [epoch: 24.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.073752954151612		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.073752954151612 | validation: 3.4386422037519417]
	TIME [epoch: 24.7 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.173481716929215		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.173481716929215 | validation: 3.1763589609339506]
	TIME [epoch: 24.7 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.817594402266838		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.817594402266838 | validation: 2.6471177945263253]
	TIME [epoch: 24.7 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8794535391390585		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.8794535391390585 | validation: 4.805257062498648]
	TIME [epoch: 24.7 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.581203656657035		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.581203656657035 | validation: 3.3292241096245987]
	TIME [epoch: 24.7 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.224278107078681		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.224278107078681 | validation: 3.7058258548327228]
	TIME [epoch: 24.7 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9828162924360724		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.9828162924360724 | validation: 3.844855623910306]
	TIME [epoch: 24.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5783769232581197		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.5783769232581197 | validation: 3.8109040958185734]
	TIME [epoch: 24.7 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3312743582205946		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.3312743582205946 | validation: 3.5186671192872274]
	TIME [epoch: 24.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2367822555379826		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.2367822555379826 | validation: 3.581684333796586]
	TIME [epoch: 24.7 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3251216718142915		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.3251216718142915 | validation: 3.5162244721099554]
	TIME [epoch: 24.7 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2350894152689516		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.2350894152689516 | validation: 3.441592999953621]
	TIME [epoch: 24.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.174889392792987		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.174889392792987 | validation: 3.4063768246822286]
	TIME [epoch: 24.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1446497873556774		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.1446497873556774 | validation: 3.3388582350239235]
	TIME [epoch: 24.7 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0446570106592765		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.0446570106592765 | validation: 3.2809160189526416]
	TIME [epoch: 24.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0131537628867466		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.0131537628867466 | validation: 3.238210206852407]
	TIME [epoch: 24.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.60952249015311		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.60952249015311 | validation: 4.773071860056347]
	TIME [epoch: 24.7 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.61263379415783		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.61263379415783 | validation: 4.506164948867444]
	TIME [epoch: 24.7 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4964012605607944		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.4964012605607944 | validation: 3.1836175912194187]
	TIME [epoch: 24.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8794835288686444		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.8794835288686444 | validation: 3.4664856918577573]
	TIME [epoch: 24.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2678349839611145		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.2678349839611145 | validation: 3.4339978095098536]
	TIME [epoch: 24.7 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1618389820275388		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.1618389820275388 | validation: 3.385292283701815]
	TIME [epoch: 24.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.113129279509345		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.113129279509345 | validation: 3.3305779180774904]
	TIME [epoch: 24.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.070700530634548		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.070700530634548 | validation: 3.2822523749943717]
	TIME [epoch: 24.7 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.891649430919507		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.891649430919507 | validation: 3.303321479427733]
	TIME [epoch: 24.7 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7341375326528867		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.7341375326528867 | validation: 4.156985726872157]
	TIME [epoch: 24.7 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6111332179361684		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.6111332179361684 | validation: 4.021401168972516]
	TIME [epoch: 24.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3763356421871036		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.3763356421871036 | validation: 4.6511496741838485]
	TIME [epoch: 24.8 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4623724441762542		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.4623724441762542 | validation: 3.5789392713098436]
	TIME [epoch: 24.7 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3484000760064374		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.3484000760064374 | validation: 6.190335259123815]
	TIME [epoch: 24.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.242557053347941		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 5.242557053347941 | validation: 3.5041154735573445]
	TIME [epoch: 24.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2877525614891745		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.2877525614891745 | validation: 3.620219414592774]
	TIME [epoch: 24.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1670500482363915		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.1670500482363915 | validation: 3.2424225466333203]
	TIME [epoch: 24.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1673307548525744		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.1673307548525744 | validation: 3.4520579324265985]
	TIME [epoch: 24.7 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.116541001917968		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.116541001917968 | validation: 3.3876213217287905]
	TIME [epoch: 24.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.72767388039373		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 4.72767388039373 | validation: 6.653322398120672]
	TIME [epoch: 24.7 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.947337438754914		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 5.947337438754914 | validation: 5.362222828511597]
	TIME [epoch: 24.7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.965534410441004		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.965534410441004 | validation: 3.9556974889571657]
	TIME [epoch: 24.7 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4057838016744877		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.4057838016744877 | validation: 3.5751303676449617]
	TIME [epoch: 24.7 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1283839523564794		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.1283839523564794 | validation: 4.260798518381341]
	TIME [epoch: 24.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6275688282404968		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.6275688282404968 | validation: 4.045024132051678]
	TIME [epoch: 24.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4200055710635864		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.4200055710635864 | validation: 3.528886175389764]
	TIME [epoch: 24.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.180144398387197		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.180144398387197 | validation: 3.284564701026716]
	TIME [epoch: 24.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5536798844942545		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.5536798844942545 | validation: 2.243115042592944]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9435060204055155		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.9435060204055155 | validation: 2.1679683081142573]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8608251753869962		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.8608251753869962 | validation: 1.8864395280575637]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.191210224453264		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.191210224453264 | validation: 1.7399551711517192]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9842808412402022		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.9842808412402022 | validation: 2.3871925107591374]
	TIME [epoch: 24.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3130145965032054		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.3130145965032054 | validation: 3.743592980871207]
	TIME [epoch: 24.8 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2590970636290715		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.2590970636290715 | validation: 3.9148765118628024]
	TIME [epoch: 24.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2284215302850443		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.2284215302850443 | validation: 3.304681363167219]
	TIME [epoch: 24.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4577943605991304		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.4577943605991304 | validation: 3.1208038304780006]
	TIME [epoch: 24.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.079931170342323		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 4.079931170342323 | validation: 4.4439403699996936]
	TIME [epoch: 24.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9351968397603683		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.9351968397603683 | validation: 2.1428713143650056]
	TIME [epoch: 24.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0592913592134354		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.0592913592134354 | validation: 2.5454348936982147]
	TIME [epoch: 24.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6887578000145576		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.6887578000145576 | validation: 5.676965012876504]
	TIME [epoch: 24.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.089106316914164		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 4.089106316914164 | validation: 3.922922189974276]
	TIME [epoch: 24.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.48660821321726		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.48660821321726 | validation: 3.645874773270731]
	TIME [epoch: 24.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5782863014355613		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.5782863014355613 | validation: 3.9308062188258277]
	TIME [epoch: 24.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1408984456549227		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.1408984456549227 | validation: 3.834382894041291]
	TIME [epoch: 24.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5290991531210727		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.5290991531210727 | validation: 3.804635917349854]
	TIME [epoch: 24.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.401494943545926		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.401494943545926 | validation: 3.8603139814818275]
	TIME [epoch: 24.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3416141894470734		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.3416141894470734 | validation: 3.549550145677422]
	TIME [epoch: 24.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3581281081710737		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.3581281081710737 | validation: 3.6387614895556837]
	TIME [epoch: 24.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4972823356490497		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.4972823356490497 | validation: 3.7125902096283507]
	TIME [epoch: 24.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2668327661887018		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.2668327661887018 | validation: 3.432795543142788]
	TIME [epoch: 24.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.102711058455474		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.102711058455474 | validation: 3.4180760791292144]
	TIME [epoch: 24.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0702487045929687		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.0702487045929687 | validation: 3.3813009445111573]
	TIME [epoch: 24.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0190046623976445		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.0190046623976445 | validation: 3.3185959143993298]
	TIME [epoch: 24.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.984527301936976		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.984527301936976 | validation: 3.29834768476013]
	TIME [epoch: 24.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9368764841510235		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.9368764841510235 | validation: 3.249028013681229]
	TIME [epoch: 24.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.922297982982159		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.922297982982159 | validation: 3.2310935282946573]
	TIME [epoch: 24.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.899353549932616		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.899353549932616 | validation: 3.215284696736686]
	TIME [epoch: 24.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.918595386239872		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.918595386239872 | validation: 3.1935073006932932]
	TIME [epoch: 24.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.044857574486685		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.044857574486685 | validation: 3.27024871743046]
	TIME [epoch: 24.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9498683177593903		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.9498683177593903 | validation: 3.152383564718838]
	TIME [epoch: 24.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9012752289041184		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.9012752289041184 | validation: 3.2019134658456507]
	TIME [epoch: 24.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.858731230128383		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.858731230128383 | validation: 3.151057100087306]
	TIME [epoch: 24.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9214806381761673		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.9214806381761673 | validation: 3.203068788264514]
	TIME [epoch: 24.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.818051785112002		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.818051785112002 | validation: 3.2228655408899956]
	TIME [epoch: 24.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.890533027496525		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.890533027496525 | validation: 3.151450317705747]
	TIME [epoch: 24.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.886675786595373		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.886675786595373 | validation: 3.1667387821918203]
	TIME [epoch: 24.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9533212279459256		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 3.9533212279459256 | validation: 3.7456625865482467]
	TIME [epoch: 24.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2316242604218512		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.2316242604218512 | validation: 3.378289635119801]
	TIME [epoch: 24.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9826889016455853		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.9826889016455853 | validation: 3.1941107551865793]
	TIME [epoch: 24.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8510597177960446		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.8510597177960446 | validation: 3.262188911416024]
	TIME [epoch: 24.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3596777057610874		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 2.3596777057610874 | validation: 2.1112207511537298]
	TIME [epoch: 24.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.830406334367308		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.830406334367308 | validation: 3.203066259459316]
	TIME [epoch: 24.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.92597368412084		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.92597368412084 | validation: 3.2463039195118393]
	TIME [epoch: 24.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8695720758913583		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.8695720758913583 | validation: 3.154241361122436]
	TIME [epoch: 24.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.69826358456272		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.69826358456272 | validation: 2.369817395064933]
	TIME [epoch: 24.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054132127267408		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.054132127267408 | validation: 1.922582625443032]
	TIME [epoch: 24.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.799041299152237		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.799041299152237 | validation: 1.816276503535041]
	TIME [epoch: 24.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6906331296746837		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.6906331296746837 | validation: 2.222645597614873]
	TIME [epoch: 24.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.037302833474236		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.037302833474236 | validation: 3.6240082450668565]
	TIME [epoch: 24.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.199759104988426		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.199759104988426 | validation: 1.4745104653528482]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4144921889826556		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.4144921889826556 | validation: 1.5290563980244471]
	TIME [epoch: 24.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7432384886194345		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.7432384886194345 | validation: 1.5607812706158635]
	TIME [epoch: 24.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.417890832016752		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.417890832016752 | validation: 1.378064123976464]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2262762991879166		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.2262762991879166 | validation: 1.34384432091494]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.328171544614913		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.328171544614913 | validation: 1.3175467192833603]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2624371423921181		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.2624371423921181 | validation: 1.5056644672646626]
	TIME [epoch: 24.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2663515433014472		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.2663515433014472 | validation: 1.1240770565567375]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0696509972942705		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.0696509972942705 | validation: 1.060784436200066]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9272381133971388		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.9272381133971388 | validation: 1.062359873480014]
	TIME [epoch: 24.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1695951166435556		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.1695951166435556 | validation: 1.3447945696663712]
	TIME [epoch: 24.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1256796060599392		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.1256796060599392 | validation: 0.9951548224687704]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9561371198220626		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.9561371198220626 | validation: 1.053601158582398]
	TIME [epoch: 24.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9091669349598277		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.9091669349598277 | validation: 0.7860460707723309]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8939579537581928		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.8939579537581928 | validation: 0.8846922348432034]
	TIME [epoch: 24.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8387598338153035		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.8387598338153035 | validation: 0.6644689499620262]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055096816568327		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.7055096816568327 | validation: 0.8623816639599218]
	TIME [epoch: 24.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8315354034434875		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.8315354034434875 | validation: 1.4588623263834584]
	TIME [epoch: 24.8 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9961461529260096		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.9961461529260096 | validation: 1.1772974969189687]
	TIME [epoch: 24.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0073011242833905		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.0073011242833905 | validation: 0.870810681168617]
	TIME [epoch: 24.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8896336598813499		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.8896336598813499 | validation: 0.9664995623967076]
	TIME [epoch: 24.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9365744980671136		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.9365744980671136 | validation: 0.907483672142344]
	TIME [epoch: 24.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8176655979949338		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.8176655979949338 | validation: 0.8856640210478773]
	TIME [epoch: 24.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2436990329436128		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.2436990329436128 | validation: 0.909388942964233]
	TIME [epoch: 24.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9689981483798573		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.9689981483798573 | validation: 0.7691475517611622]
	TIME [epoch: 24.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.176803008901363		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.176803008901363 | validation: 0.9101845607674602]
	TIME [epoch: 24.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9783092980529281		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.9783092980529281 | validation: 1.034602739576491]
	TIME [epoch: 24.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8883922595998153		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.8883922595998153 | validation: 0.8126826915366229]
	TIME [epoch: 24.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.886209269841811		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.886209269841811 | validation: 1.3796313294239924]
	TIME [epoch: 24.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.123219573742905		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.123219573742905 | validation: 1.2959884795658188]
	TIME [epoch: 24.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031105085123862		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.031105085123862 | validation: 1.1080635581033658]
	TIME [epoch: 24.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8792756533670223		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.8792756533670223 | validation: 0.9199197810209819]
	TIME [epoch: 24.8 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8486957449792611		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.8486957449792611 | validation: 0.8321388688119171]
	TIME [epoch: 24.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0144450099696218		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.0144450099696218 | validation: 2.9255268005677806]
	TIME [epoch: 24.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.916378365382546		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.916378365382546 | validation: 3.2125345896692563]
	TIME [epoch: 24.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0864513604651496		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 3.0864513604651496 | validation: 3.1422114788454234]
	TIME [epoch: 24.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.918147183050864		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.918147183050864 | validation: 3.302577572601972]
	TIME [epoch: 24.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9833240553484237		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.9833240553484237 | validation: 3.2388829262317573]
	TIME [epoch: 24.8 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.429813250380042		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.429813250380042 | validation: 3.442577266525016]
	TIME [epoch: 24.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4181218065641676		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.4181218065641676 | validation: 3.485404254792843]
	TIME [epoch: 24.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1466325829035977		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.1466325829035977 | validation: 3.3780604603759334]
	TIME [epoch: 24.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.979607958325858		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 2.979607958325858 | validation: 3.272500519916121]
	TIME [epoch: 24.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.826676689149685		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.826676689149685 | validation: 2.662063521102248]
	TIME [epoch: 24.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1301112431421014		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 2.1301112431421014 | validation: 2.165261520783096]
	TIME [epoch: 24.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8196618767646906		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.8196618767646906 | validation: 1.3957693641124995]
	TIME [epoch: 24.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3244714243106692		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.3244714243106692 | validation: 1.4228526220114526]
	TIME [epoch: 24.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.045649661273854		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.045649661273854 | validation: 1.0417158909622355]
	TIME [epoch: 24.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.904904482479034		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.904904482479034 | validation: 0.8317909362291065]
	TIME [epoch: 24.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9026018988822991		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.9026018988822991 | validation: 1.2347430263626173]
	TIME [epoch: 24.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9563594838358109		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.9563594838358109 | validation: 0.7626212450533791]
	TIME [epoch: 24.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1063566397673534		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.1063566397673534 | validation: 0.973560029372932]
	TIME [epoch: 24.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9068112313722805		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.9068112313722805 | validation: 0.8273421535976812]
	TIME [epoch: 24.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7116014536247193		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.7116014536247193 | validation: 1.1602134426580408]
	TIME [epoch: 24.8 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9017642332174555		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.9017642332174555 | validation: 0.7948089177526909]
	TIME [epoch: 24.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8349594088591108		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.8349594088591108 | validation: 0.8372024707778922]
	TIME [epoch: 24.8 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7755545544687207		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.7755545544687207 | validation: 0.8722261188665685]
	TIME [epoch: 24.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7449220118533754		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.7449220118533754 | validation: 1.1475773743431432]
	TIME [epoch: 24.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257527733782032		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.257527733782032 | validation: 3.1152458878957225]
	TIME [epoch: 24.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.638949404045724		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.638949404045724 | validation: 2.0656507453967383]
	TIME [epoch: 24.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0997121556107996		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.0997121556107996 | validation: 0.973847637580858]
	TIME [epoch: 24.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7841547445154966		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.7841547445154966 | validation: 0.6326619590600909]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8285036160184773		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.8285036160184773 | validation: 0.6817707824532879]
	TIME [epoch: 24.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7134189900152292		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.7134189900152292 | validation: 0.7779170808845857]
	TIME [epoch: 24.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7781401227299963		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.7781401227299963 | validation: 0.7007246261399118]
	TIME [epoch: 24.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7676816610447421		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.7676816610447421 | validation: 1.886277183053295]
	TIME [epoch: 24.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6906987201450034		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.6906987201450034 | validation: 1.142184215889429]
	TIME [epoch: 24.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8308586025807385		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.8308586025807385 | validation: 1.4642131125162905]
	TIME [epoch: 24.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2275413571905867		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.2275413571905867 | validation: 0.733207732150523]
	TIME [epoch: 24.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6492966397075922		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.6492966397075922 | validation: 0.6276622975507303]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8671966725460916		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.8671966725460916 | validation: 1.0342153629087991]
	TIME [epoch: 24.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7646670426240975		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.7646670426240975 | validation: 0.8997016127322687]
	TIME [epoch: 24.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8105709595421519		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.8105709595421519 | validation: 0.7308410925691311]
	TIME [epoch: 24.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8123455972154716		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.8123455972154716 | validation: 1.111897849828982]
	TIME [epoch: 24.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8803417406442209		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.8803417406442209 | validation: 0.7590945787138983]
	TIME [epoch: 24.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6709133794160407		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.6709133794160407 | validation: 0.6168062624675993]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7057862802107916		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.7057862802107916 | validation: 0.7585161475484352]
	TIME [epoch: 24.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.751956384223761		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.751956384223761 | validation: 0.6346891499188131]
	TIME [epoch: 24.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6533170421029332		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.6533170421029332 | validation: 1.424733818228466]
	TIME [epoch: 24.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9833810962342566		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.9833810962342566 | validation: 0.5888836462841567]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.604689472286315		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.604689472286315 | validation: 1.0393786035966184]
	TIME [epoch: 24.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8829217940148104		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.8829217940148104 | validation: 0.5811379214654061]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5464671971146455		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.5464671971146455 | validation: 0.6779855595166681]
	TIME [epoch: 24.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4035422241466904		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.4035422241466904 | validation: 1.2881351767130684]
	TIME [epoch: 24.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7953061577123666		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.7953061577123666 | validation: 0.891950708371382]
	TIME [epoch: 24.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6697797262528449		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.6697797262528449 | validation: 0.779174179331278]
	TIME [epoch: 24.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6773329958752214		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.6773329958752214 | validation: 0.704614338612814]
	TIME [epoch: 24.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6006074429390305		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.6006074429390305 | validation: 0.6790774832121008]
	TIME [epoch: 24.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7264166781454531		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.7264166781454531 | validation: 0.7904722632028998]
	TIME [epoch: 24.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7468155776638165		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.7468155776638165 | validation: 0.7221103724248599]
	TIME [epoch: 24.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6771564223693408		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.6771564223693408 | validation: 0.5842083687754468]
	TIME [epoch: 24.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6462050055659783		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.6462050055659783 | validation: 0.7436400905443838]
	TIME [epoch: 24.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7317901401906624		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.7317901401906624 | validation: 0.7136896868035632]
	TIME [epoch: 24.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894232083382978		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.6894232083382978 | validation: 0.6020695122712856]
	TIME [epoch: 24.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5929571413441035		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.5929571413441035 | validation: 0.5505864441384459]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5698233150409305		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.5698233150409305 | validation: 0.46532001085491104]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5339392783685166		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.5339392783685166 | validation: 0.5711903252930991]
	TIME [epoch: 24.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5829109012419528		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.5829109012419528 | validation: 0.5399434750423694]
	TIME [epoch: 24.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5802197688402244		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.5802197688402244 | validation: 0.48329653889753865]
	TIME [epoch: 24.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47563075804551846		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.47563075804551846 | validation: 0.5669374263965644]
	TIME [epoch: 24.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5488671566936763		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.5488671566936763 | validation: 0.5083278931477876]
	TIME [epoch: 24.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.546309454294035		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.546309454294035 | validation: 0.477463882120918]
	TIME [epoch: 24.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6156388398480092		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.6156388398480092 | validation: 0.48577605666357077]
	TIME [epoch: 24.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860898312218341		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.6860898312218341 | validation: 0.9084369596855386]
	TIME [epoch: 24.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6901345469290717		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.6901345469290717 | validation: 0.5647757558942064]
	TIME [epoch: 24.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5904009247469846		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.5904009247469846 | validation: 0.5140078404256793]
	TIME [epoch: 24.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5914414956597658		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.5914414956597658 | validation: 0.5022274264942665]
	TIME [epoch: 24.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6257970661090875		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.6257970661090875 | validation: 0.5149166348209453]
	TIME [epoch: 24.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5687479982585034		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.5687479982585034 | validation: 0.8862960042039191]
	TIME [epoch: 24.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5618076966017799		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.5618076966017799 | validation: 0.5359188475087633]
	TIME [epoch: 24.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45956826242300175		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.45956826242300175 | validation: 0.8255787763268779]
	TIME [epoch: 24.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5609386013380827		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.5609386013380827 | validation: 0.4414641824320772]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5331238323014597		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.5331238323014597 | validation: 1.1044426982502544]
	TIME [epoch: 24.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8208188004149128		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.8208188004149128 | validation: 0.6223559291382729]
	TIME [epoch: 24.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5325238481327772		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.5325238481327772 | validation: 0.5699208618946373]
	TIME [epoch: 24.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5762722720721808		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.5762722720721808 | validation: 0.6070829251994588]
	TIME [epoch: 24.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6225219463951632		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.6225219463951632 | validation: 0.4518886358394014]
	TIME [epoch: 24.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4883781914292441		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.4883781914292441 | validation: 0.48304868542693497]
	TIME [epoch: 24.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49584559311423154		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.49584559311423154 | validation: 0.45116204456724446]
	TIME [epoch: 24.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49201635944258953		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.49201635944258953 | validation: 1.1463329618008817]
	TIME [epoch: 24.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6789680834010218		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.6789680834010218 | validation: 0.48335673387192635]
	TIME [epoch: 24.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5710528508792941		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.5710528508792941 | validation: 0.8742896107902444]
	TIME [epoch: 24.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7113900767044575		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.7113900767044575 | validation: 0.7270527069951372]
	TIME [epoch: 24.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5697642971790342		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.5697642971790342 | validation: 1.1851356086562084]
	TIME [epoch: 24.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7892023646448554		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.7892023646448554 | validation: 0.6849622900317226]
	TIME [epoch: 24.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5638598849193927		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.5638598849193927 | validation: 0.6573414893022266]
	TIME [epoch: 24.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8494902307515622		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.8494902307515622 | validation: 1.452299192097942]
	TIME [epoch: 24.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9242268285893115		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.9242268285893115 | validation: 0.5531376374777651]
	TIME [epoch: 24.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5406686176676335		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.5406686176676335 | validation: 0.500999289272936]
	TIME [epoch: 24.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5196097028206859		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.5196097028206859 | validation: 0.5268598796225417]
	TIME [epoch: 24.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4999679582718156		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.4999679582718156 | validation: 0.46643556865653735]
	TIME [epoch: 24.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4288151817469396		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.4288151817469396 | validation: 0.3909707707888183]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5838161514841727		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.5838161514841727 | validation: 0.453245846096766]
	TIME [epoch: 24.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4638566263372588		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.4638566263372588 | validation: 0.5683554856726579]
	TIME [epoch: 24.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.494999043865482		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.494999043865482 | validation: 0.4912483207742895]
	TIME [epoch: 24.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5189024844314369		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.5189024844314369 | validation: 0.4302666245210803]
	TIME [epoch: 24.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7548100836865568		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7548100836865568 | validation: 0.9101819849415929]
	TIME [epoch: 24.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6353312307997961		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.6353312307997961 | validation: 0.589060200563157]
	TIME [epoch: 24.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.57587105596739		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.57587105596739 | validation: 0.49895917494579606]
	TIME [epoch: 24.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6015513879450922		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.6015513879450922 | validation: 0.6955463241169385]
	TIME [epoch: 24.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5515105050668246		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.5515105050668246 | validation: 0.41214617841456486]
	TIME [epoch: 24.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579978150488707		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.5579978150488707 | validation: 0.6238745594845794]
	TIME [epoch: 24.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49640085426073444		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.49640085426073444 | validation: 0.5223509325778825]
	TIME [epoch: 24.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5047394706646018		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.5047394706646018 | validation: 0.5730806596386568]
	TIME [epoch: 24.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5501816281289558		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.5501816281289558 | validation: 0.6847968965093935]
	TIME [epoch: 24.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5776299176589426		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.5776299176589426 | validation: 0.48960398393778515]
	TIME [epoch: 24.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4842474519300869		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.4842474519300869 | validation: 0.43514666935553864]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4671164605307872		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.4671164605307872 | validation: 0.41832228185492676]
	TIME [epoch: 24.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44815278337565245		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.44815278337565245 | validation: 0.6143699292421505]
	TIME [epoch: 24.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5225310774433306		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.5225310774433306 | validation: 0.5472921696994786]
	TIME [epoch: 24.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4850113445949995		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.4850113445949995 | validation: 0.38999050409156405]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3706699670572905		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.3706699670572905 | validation: 0.3898087609275546]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_297.pth
	Model improved!!!
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.612657319207015		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.612657319207015 | validation: 0.6992480843624975]
	TIME [epoch: 24.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6180922534913726		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.6180922534913726 | validation: 0.47509569599019996]
	TIME [epoch: 24.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42888887472969567		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.42888887472969567 | validation: 0.5032621317620196]
	TIME [epoch: 24.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4234745703224523		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.4234745703224523 | validation: 0.5520102495055456]
	TIME [epoch: 24.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5086570372589245		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.5086570372589245 | validation: 0.4472196272656251]
	TIME [epoch: 24.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4708790521687365		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.4708790521687365 | validation: 0.5275465306097866]
	TIME [epoch: 24.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.483107979347893		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.483107979347893 | validation: 0.5756662953603372]
	TIME [epoch: 24.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5838024602615973		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.5838024602615973 | validation: 0.5143721898004301]
	TIME [epoch: 24.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.640753017403556		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.640753017403556 | validation: 0.37899240530474837]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6964291316081974		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.6964291316081974 | validation: 1.1385296269025629]
	TIME [epoch: 24.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6123444716221168		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.6123444716221168 | validation: 0.3941161924413672]
	TIME [epoch: 24.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4176046474051347		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.4176046474051347 | validation: 0.5444173681792142]
	TIME [epoch: 24.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6136266038883981		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.6136266038883981 | validation: 0.4519889868386127]
	TIME [epoch: 24.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4472972015952728		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.4472972015952728 | validation: 0.41050383957386916]
	TIME [epoch: 24.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072721895715822		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5072721895715822 | validation: 0.4887630731937365]
	TIME [epoch: 24.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282441371335544		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.7282441371335544 | validation: 1.144175894408394]
	TIME [epoch: 24.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9101218684510266		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.9101218684510266 | validation: 0.7388944938993279]
	TIME [epoch: 24.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7751492743205972		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.7751492743205972 | validation: 0.6025060010584798]
	TIME [epoch: 24.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.049265167694759		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.049265167694759 | validation: 0.8728003925219631]
	TIME [epoch: 24.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6511480895226229		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.6511480895226229 | validation: 0.53279984885761]
	TIME [epoch: 24.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5230700675173406		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.5230700675173406 | validation: 0.49069030091464144]
	TIME [epoch: 24.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4402543775977142		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.4402543775977142 | validation: 0.4653438486968103]
	TIME [epoch: 24.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4388242943331965		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.4388242943331965 | validation: 0.5218924796176165]
	TIME [epoch: 24.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6242200914918195		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6242200914918195 | validation: 0.5239383453500291]
	TIME [epoch: 24.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5139807287950867		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.5139807287950867 | validation: 0.5945434325602635]
	TIME [epoch: 24.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107806994193889		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.5107806994193889 | validation: 0.4462911940239911]
	TIME [epoch: 24.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5260641287144814		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.5260641287144814 | validation: 0.677099176865122]
	TIME [epoch: 24.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6028041234447067		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.6028041234447067 | validation: 0.38412231260978147]
	TIME [epoch: 24.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41891171856783505		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.41891171856783505 | validation: 0.6488882034425527]
	TIME [epoch: 24.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47998015390425935		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.47998015390425935 | validation: 0.580116865598062]
	TIME [epoch: 24.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5168940854312385		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.5168940854312385 | validation: 0.6164123742322325]
	TIME [epoch: 24.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5672996356371194		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.5672996356371194 | validation: 0.8648614689090002]
	TIME [epoch: 24.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6225020169513555		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.6225020169513555 | validation: 0.405964345847203]
	TIME [epoch: 24.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4047376519141366		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.4047376519141366 | validation: 0.42386281517596275]
	TIME [epoch: 24.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.460293195937369		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.460293195937369 | validation: 0.733775442278451]
	TIME [epoch: 24.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6161282379972944		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.6161282379972944 | validation: 0.41029614311629514]
	TIME [epoch: 24.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.586229824058073		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.586229824058073 | validation: 0.9926834415155179]
	TIME [epoch: 24.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8412843841039686		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.8412843841039686 | validation: 0.5753898860592342]
	TIME [epoch: 24.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5068693235033574		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.5068693235033574 | validation: 0.41553756265445063]
	TIME [epoch: 24.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3919229020230527		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.3919229020230527 | validation: 0.4593893688512417]
	TIME [epoch: 24.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.416461080220572		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.416461080220572 | validation: 0.4914273534157669]
	TIME [epoch: 24.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3997340468280954		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.3997340468280954 | validation: 0.5207517481990993]
	TIME [epoch: 24.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5238347203011633		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.5238347203011633 | validation: 0.4555548138588113]
	TIME [epoch: 24.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4714974185023654		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.4714974185023654 | validation: 0.5315521124434279]
	TIME [epoch: 24.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4328221373695886		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.4328221373695886 | validation: 0.7889451962315818]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844056950323416		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.6844056950323416 | validation: 0.5840252215848382]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5520403331890226		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5520403331890226 | validation: 0.368363416792739]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_344.pth
	Model improved!!!
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5181388748518724		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.5181388748518724 | validation: 0.4700267701256227]
	TIME [epoch: 24.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4798187239440779		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.4798187239440779 | validation: 0.7588050990279993]
	TIME [epoch: 24.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5062453395299973		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5062453395299973 | validation: 0.5513647615799017]
	TIME [epoch: 24.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5684893127275382		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.5684893127275382 | validation: 0.4162720739858139]
	TIME [epoch: 24.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49650795450119695		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.49650795450119695 | validation: 0.41524399072883766]
	TIME [epoch: 24.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3714154357367837		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.3714154357367837 | validation: 0.36505602637910023]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36113680515223845		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.36113680515223845 | validation: 0.32694550197353095]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_351.pth
	Model improved!!!
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34950878948626357		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.34950878948626357 | validation: 0.439554307438953]
	TIME [epoch: 24.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39344034037018216		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.39344034037018216 | validation: 0.35859395396713006]
	TIME [epoch: 24.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4420491398975913		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.4420491398975913 | validation: 0.5049623627663313]
	TIME [epoch: 24.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4015519043158384		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.4015519043158384 | validation: 0.3780892324248469]
	TIME [epoch: 24.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49613332403680577		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.49613332403680577 | validation: 0.5235525018964509]
	TIME [epoch: 24.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6691180715191978		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.6691180715191978 | validation: 0.6723986575243501]
	TIME [epoch: 24.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7617104118186809		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.7617104118186809 | validation: 0.8910358584987822]
	TIME [epoch: 24.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9375460475700772		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.9375460475700772 | validation: 0.8187692725270663]
	TIME [epoch: 24.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5881822562148903		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.5881822562148903 | validation: 0.43042169134520947]
	TIME [epoch: 24.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4361707387282601		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.4361707387282601 | validation: 0.5269939020928897]
	TIME [epoch: 24.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6089597433494051		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.6089597433494051 | validation: 0.660471640532418]
	TIME [epoch: 24.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6340803267805604		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.6340803267805604 | validation: 0.5876477217872499]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809734944886241		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.6809734944886241 | validation: 0.4938675585752191]
	TIME [epoch: 24.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43073928632224595		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.43073928632224595 | validation: 0.3943974440155803]
	TIME [epoch: 24.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3883131382646506		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.3883131382646506 | validation: 0.38532463877910134]
	TIME [epoch: 24.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40111553541557676		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.40111553541557676 | validation: 0.5479709794804299]
	TIME [epoch: 24.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6375901492077563		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.6375901492077563 | validation: 0.5554457524797638]
	TIME [epoch: 24.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46217275248122025		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.46217275248122025 | validation: 0.7095861642421446]
	TIME [epoch: 24.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0387384163218574		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.0387384163218574 | validation: 1.2276091070634143]
	TIME [epoch: 24.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9448174315451785		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.9448174315451785 | validation: 0.9462117887825013]
	TIME [epoch: 24.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8465262870092012		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.8465262870092012 | validation: 0.6580534564035567]
	TIME [epoch: 24.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.867471156971353		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.867471156971353 | validation: 1.3749234702304975]
	TIME [epoch: 24.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1670141611479943		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.1670141611479943 | validation: 1.167494076181247]
	TIME [epoch: 24.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2230212968644438		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.2230212968644438 | validation: 1.1895717141365816]
	TIME [epoch: 24.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0101221868902492		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.0101221868902492 | validation: 0.8398616106534444]
	TIME [epoch: 24.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.713704338236349		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.713704338236349 | validation: 0.6660056610173202]
	TIME [epoch: 24.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220160627252416		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.6220160627252416 | validation: 0.5300495756502062]
	TIME [epoch: 24.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5060012523945138		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.5060012523945138 | validation: 0.5956117614515061]
	TIME [epoch: 24.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.538043662566335		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.538043662566335 | validation: 0.48769333385515284]
	TIME [epoch: 24.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36878115815533963		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.36878115815533963 | validation: 0.4075476858771488]
	TIME [epoch: 24.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347325868817806		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.347325868817806 | validation: 0.4071844799882455]
	TIME [epoch: 24.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4197268477584861		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.4197268477584861 | validation: 0.756321766743163]
	TIME [epoch: 24.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290067530890414		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.7290067530890414 | validation: 0.65330694252765]
	TIME [epoch: 24.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4866067039493088		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.4866067039493088 | validation: 0.4260657658081324]
	TIME [epoch: 24.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5230211728004183		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.5230211728004183 | validation: 0.6196525451479624]
	TIME [epoch: 24.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4946089640689145		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.4946089640689145 | validation: 0.47340279955641684]
	TIME [epoch: 24.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373835585547127		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.373835585547127 | validation: 0.29961450037383075]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_388.pth
	Model improved!!!
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25825965517776783		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.25825965517776783 | validation: 0.3828776232636249]
	TIME [epoch: 24.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4157254448319182		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.4157254448319182 | validation: 0.49484354574531153]
	TIME [epoch: 24.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4768894952339692		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.4768894952339692 | validation: 0.6210935418974503]
	TIME [epoch: 24.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5139005617433362		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.5139005617433362 | validation: 0.49553472946396876]
	TIME [epoch: 24.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44824293916697305		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.44824293916697305 | validation: 0.4455117209084872]
	TIME [epoch: 24.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4163968867661172		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.4163968867661172 | validation: 0.38268451687336197]
	TIME [epoch: 24.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.345500917433136		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.345500917433136 | validation: 0.3735165167363694]
	TIME [epoch: 24.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35173632961291224		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.35173632961291224 | validation: 0.27765324935186075]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3700291728104832		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.3700291728104832 | validation: 0.5129372643798518]
	TIME [epoch: 24.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35249254242527905		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.35249254242527905 | validation: 0.2794174582426163]
	TIME [epoch: 24.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3912165318270237		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.3912165318270237 | validation: 0.40972982201374897]
	TIME [epoch: 24.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33855471593087694		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.33855471593087694 | validation: 0.348124967180366]
	TIME [epoch: 24.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3263044542788524		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.3263044542788524 | validation: 0.5601152797138508]
	TIME [epoch: 24.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7927700165262835		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.7927700165262835 | validation: 0.9325045921772196]
	TIME [epoch: 24.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5486696277563653		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.5486696277563653 | validation: 0.31863629204376326]
	TIME [epoch: 24.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36855538609439786		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.36855538609439786 | validation: 0.5195010317555034]
	TIME [epoch: 24.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3642013646190719		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.3642013646190719 | validation: 0.2900662201614568]
	TIME [epoch: 24.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2971421722982859		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.2971421722982859 | validation: 0.34548861772385975]
	TIME [epoch: 24.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42220151761960645		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.42220151761960645 | validation: 0.3303385057503394]
	TIME [epoch: 24.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.503049954893811		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.503049954893811 | validation: 0.6062160116715342]
	TIME [epoch: 24.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4822355385474152		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.4822355385474152 | validation: 0.38407440234348483]
	TIME [epoch: 24.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601149765243774		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.3601149765243774 | validation: 0.3557402362008122]
	TIME [epoch: 24.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.455265576593477		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.455265576593477 | validation: 0.6496027286944172]
	TIME [epoch: 24.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5837901872186152		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.5837901872186152 | validation: 0.4755736195193489]
	TIME [epoch: 24.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3695016489805841		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.3695016489805841 | validation: 0.35911698305440326]
	TIME [epoch: 24.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4909928712330387		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.4909928712330387 | validation: 0.45777237652947483]
	TIME [epoch: 24.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31586306064422953		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.31586306064422953 | validation: 0.26930163997779993]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3531727973261511		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.3531727973261511 | validation: 0.3242320107053706]
	TIME [epoch: 24.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36133576887940155		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.36133576887940155 | validation: 0.5017808042463219]
	TIME [epoch: 24.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3927721881699791		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.3927721881699791 | validation: 0.2742703783518066]
	TIME [epoch: 24.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373927887381438		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.373927887381438 | validation: 0.48223499407941517]
	TIME [epoch: 24.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43198454886536586		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.43198454886536586 | validation: 0.39298716388837907]
	TIME [epoch: 24.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3929811398739499		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.3929811398739499 | validation: 0.36440397680694275]
	TIME [epoch: 24.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4304570861026611		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.4304570861026611 | validation: 0.44286820350676226]
	TIME [epoch: 24.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108577920002988		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.3108577920002988 | validation: 0.227924865004614]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_423.pth
	Model improved!!!
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519296392679553		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.2519296392679553 | validation: 0.2792209847851772]
	TIME [epoch: 24.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29839341709794454		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.29839341709794454 | validation: 0.5995357814779168]
	TIME [epoch: 24.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220266169557843		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.6220266169557843 | validation: 0.4065782377674732]
	TIME [epoch: 24.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108231890848071		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.3108231890848071 | validation: 0.2705059853803951]
	TIME [epoch: 24.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29572124962581925		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.29572124962581925 | validation: 0.4815319473365851]
	TIME [epoch: 24.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5069302662508357		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.5069302662508357 | validation: 0.5370160941533468]
	TIME [epoch: 24.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41486314447800654		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.41486314447800654 | validation: 0.31419640606494936]
	TIME [epoch: 24.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29094933997692474		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.29094933997692474 | validation: 0.3042844760109664]
	TIME [epoch: 24.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3016703542090618		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.3016703542090618 | validation: 0.36247784956005197]
	TIME [epoch: 24.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6761624406051074		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.6761624406051074 | validation: 0.49462313752375514]
	TIME [epoch: 24.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42737666639329175		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.42737666639329175 | validation: 0.32172325855734557]
	TIME [epoch: 24.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4005880785257821		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.4005880785257821 | validation: 0.42041928323977235]
	TIME [epoch: 24.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3562675229167398		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.3562675229167398 | validation: 0.2760743994311391]
	TIME [epoch: 24.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31323902178937857		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.31323902178937857 | validation: 0.4161929282459271]
	TIME [epoch: 24.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.280855994348612		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.280855994348612 | validation: 0.2637540009046827]
	TIME [epoch: 24.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.270334179656033		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.270334179656033 | validation: 0.27185458461049]
	TIME [epoch: 24.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.375490543811199		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.375490543811199 | validation: 0.3674526662266454]
	TIME [epoch: 24.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28456626910133914		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.28456626910133914 | validation: 0.37177332934113383]
	TIME [epoch: 24.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2875613426852006		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.2875613426852006 | validation: 0.31571397092374687]
	TIME [epoch: 24.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2964959622434453		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.2964959622434453 | validation: 0.38057381899948795]
	TIME [epoch: 24.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489832164854996		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.3489832164854996 | validation: 0.32003094763408696]
	TIME [epoch: 24.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3625352490126412		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.3625352490126412 | validation: 0.4565400780033174]
	TIME [epoch: 24.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37880570299615496		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.37880570299615496 | validation: 0.3737139796208539]
	TIME [epoch: 24.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4137433809578317		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.4137433809578317 | validation: 0.4089848140134684]
	TIME [epoch: 24.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31715568349852374		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.31715568349852374 | validation: 0.35789971044194674]
	TIME [epoch: 24.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3412096650488135		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.3412096650488135 | validation: 0.34492746230514393]
	TIME [epoch: 24.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3590559298428768		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.3590559298428768 | validation: 0.3808554582812365]
	TIME [epoch: 24.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35180591596128824		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.35180591596128824 | validation: 0.3251487578878191]
	TIME [epoch: 24.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40570181731006		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.40570181731006 | validation: 0.49555322757774806]
	TIME [epoch: 24.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3823415052561927		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.3823415052561927 | validation: 0.34800407126231636]
	TIME [epoch: 24.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29783904300151076		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.29783904300151076 | validation: 0.30113756552242926]
	TIME [epoch: 24.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32869904223937974		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.32869904223937974 | validation: 0.2876139946601332]
	TIME [epoch: 24.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30225197107124196		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.30225197107124196 | validation: 0.2932881718717485]
	TIME [epoch: 24.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34364883178897965		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.34364883178897965 | validation: 0.6608481009172315]
	TIME [epoch: 24.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5434348083587586		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.5434348083587586 | validation: 0.5849428066967752]
	TIME [epoch: 24.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42551396812999115		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.42551396812999115 | validation: 0.38844965590615965]
	TIME [epoch: 24.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41328554593060207		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.41328554593060207 | validation: 0.5700522598904216]
	TIME [epoch: 24.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38711857517791326		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.38711857517791326 | validation: 0.30281096822830694]
	TIME [epoch: 24.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2831510719886138		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.2831510719886138 | validation: 0.37005998876287804]
	TIME [epoch: 24.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.466111112801351		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.466111112801351 | validation: 0.5689643734091991]
	TIME [epoch: 24.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.531650465278058		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.531650465278058 | validation: 0.5165038183010578]
	TIME [epoch: 24.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39707386743240575		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.39707386743240575 | validation: 0.5068898293073019]
	TIME [epoch: 24.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4066888117364184		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.4066888117364184 | validation: 0.2785191522114623]
	TIME [epoch: 24.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28139507253896384		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.28139507253896384 | validation: 0.30871009878032174]
	TIME [epoch: 24.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2999493515305065		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.2999493515305065 | validation: 0.30171631512059116]
	TIME [epoch: 24.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30017504433336306		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.30017504433336306 | validation: 0.5211850764640723]
	TIME [epoch: 24.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.522925651925278		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.522925651925278 | validation: 0.36034845884360894]
	TIME [epoch: 24.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3660436402901486		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.3660436402901486 | validation: 0.46469677269758236]
	TIME [epoch: 24.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3448777038446564		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.3448777038446564 | validation: 0.28687975050851494]
	TIME [epoch: 24.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923182273711278		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.2923182273711278 | validation: 0.2281994127910052]
	TIME [epoch: 24.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24673511656832525		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.24673511656832525 | validation: 0.37059190733209413]
	TIME [epoch: 24.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47116070853357794		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.47116070853357794 | validation: 0.38630248118129673]
	TIME [epoch: 24.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27567741059025885		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.27567741059025885 | validation: 0.30416074407578564]
	TIME [epoch: 24.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2986791213425667		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.2986791213425667 | validation: 0.2890140377615829]
	TIME [epoch: 24.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32375477614237436		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.32375477614237436 | validation: 0.4298179276145101]
	TIME [epoch: 24.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5325426412171138		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.5325426412171138 | validation: 0.42394039452216625]
	TIME [epoch: 24.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301252645357513		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.3301252645357513 | validation: 0.29411983819189097]
	TIME [epoch: 24.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30945695195452727		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.30945695195452727 | validation: 0.3720930239837446]
	TIME [epoch: 24.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29858982521963406		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.29858982521963406 | validation: 0.22110717879543593]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34914156567764826		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.34914156567764826 | validation: 0.5335542734775965]
	TIME [epoch: 24.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5363153170665934		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5363153170665934 | validation: 0.42532188859593945]
	TIME [epoch: 24.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925683458618477		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.2925683458618477 | validation: 0.2750242576670352]
	TIME [epoch: 24.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28557027510195687		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.28557027510195687 | validation: 0.3774808144287227]
	TIME [epoch: 24.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3176639150794054		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.3176639150794054 | validation: 0.3225461276057864]
	TIME [epoch: 24.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2996249577635726		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.2996249577635726 | validation: 0.29747828719623687]
	TIME [epoch: 24.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2728539851697031		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.2728539851697031 | validation: 0.29704894874798643]
	TIME [epoch: 24.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2996646376342707		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.2996646376342707 | validation: 0.35053046714254693]
	TIME [epoch: 24.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2594607944943642		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.2594607944943642 | validation: 0.23489606446272512]
	TIME [epoch: 24.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22027126177204906		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.22027126177204906 | validation: 0.24529799964166785]
	TIME [epoch: 24.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2884271984825669		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.2884271984825669 | validation: 0.24199925716023693]
	TIME [epoch: 24.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21191475656692846		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.21191475656692846 | validation: 0.17197667195760796]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21366355153656724		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.21366355153656724 | validation: 0.16483969946210755]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_495.pth
	Model improved!!!
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19899616268401227		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.19899616268401227 | validation: 0.19041429849388614]
	TIME [epoch: 24.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782581028091408		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.2782581028091408 | validation: 0.29115536226895555]
	TIME [epoch: 24.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27614311193261254		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.27614311193261254 | validation: 0.45025790708433683]
	TIME [epoch: 24.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3350364266322264		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.3350364266322264 | validation: 0.201597064543435]
	TIME [epoch: 24.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21898781314822724		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.21898781314822724 | validation: 0.28512278625948356]
	TIME [epoch: 24.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22597582183983195		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.22597582183983195 | validation: 0.201797273269926]
	TIME [epoch: 24.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22485431415894686		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.22485431415894686 | validation: 0.2947453871636847]
	TIME [epoch: 24.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24861355124388865		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.24861355124388865 | validation: 0.21529772505159117]
	TIME [epoch: 24.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17745580553866502		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.17745580553866502 | validation: 0.2954043514682762]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23228376381543472		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.23228376381543472 | validation: 0.2235463959746464]
	TIME [epoch: 24.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28937571459953665		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.28937571459953665 | validation: 0.3035133695570416]
	TIME [epoch: 24.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22718782682686467		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.22718782682686467 | validation: 0.22025396508206666]
	TIME [epoch: 24.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18175100797726573		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.18175100797726573 | validation: 0.17362639632402996]
	TIME [epoch: 24.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2508449718099023		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.2508449718099023 | validation: 0.5011672212864037]
	TIME [epoch: 24.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3943840366489374		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.3943840366489374 | validation: 0.3036090963026144]
	TIME [epoch: 24.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33559953663318465		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.33559953663318465 | validation: 0.38785322668287536]
	TIME [epoch: 24.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28156070907798003		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.28156070907798003 | validation: 0.300966728734436]
	TIME [epoch: 24.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2268142101460991		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.2268142101460991 | validation: 0.20160330539156002]
	TIME [epoch: 24.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38542098831583305		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.38542098831583305 | validation: 0.565994868636936]
	TIME [epoch: 24.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501524256324692		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.501524256324692 | validation: 0.6449693672565658]
	TIME [epoch: 24.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34754731317944815		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.34754731317944815 | validation: 0.25527157680551826]
	TIME [epoch: 24.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25066245849665925		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.25066245849665925 | validation: 0.18014679553020954]
	TIME [epoch: 24.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20511802091708278		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.20511802091708278 | validation: 0.31184726726495293]
	TIME [epoch: 24.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3833558160174077		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.3833558160174077 | validation: 0.2651260448060394]
	TIME [epoch: 24.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2786246913289279		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.2786246913289279 | validation: 0.23682315404733623]
	TIME [epoch: 24.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25287167862209536		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.25287167862209536 | validation: 0.4078508973001745]
	TIME [epoch: 24.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43918135374301964		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.43918135374301964 | validation: 0.5725023239931906]
	TIME [epoch: 24.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4188404058856219		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.4188404058856219 | validation: 0.30921665951183386]
	TIME [epoch: 24.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2751695267517797		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.2751695267517797 | validation: 0.3069672073779717]
	TIME [epoch: 24.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2163001216920158		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.2163001216920158 | validation: 0.18964307205822575]
	TIME [epoch: 24.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24040814781843545		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.24040814781843545 | validation: 0.35576738042378725]
	TIME [epoch: 24.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28351878759832494		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.28351878759832494 | validation: 0.1897749642760037]
	TIME [epoch: 24.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1815137879303244		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.1815137879303244 | validation: 0.23035595533776196]
	TIME [epoch: 24.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2845562811921031		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.2845562811921031 | validation: 0.37238682254406036]
	TIME [epoch: 24.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3441905393434268		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.3441905393434268 | validation: 0.292003355249478]
	TIME [epoch: 24.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3758504786347551		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.3758504786347551 | validation: 0.5694598302406382]
	TIME [epoch: 24.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49372088289413685		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.49372088289413685 | validation: 0.3143850129125018]
	TIME [epoch: 24.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41494990681840016		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.41494990681840016 | validation: 0.3272325742336257]
	TIME [epoch: 24.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2692613428245878		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.2692613428245878 | validation: 0.27145750171942346]
	TIME [epoch: 24.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32453697226807654		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.32453697226807654 | validation: 0.3228150908724841]
	TIME [epoch: 24.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5306242734409379		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.5306242734409379 | validation: 0.3564137198833815]
	TIME [epoch: 24.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3631448747134216		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.3631448747134216 | validation: 0.24333231855155776]
	TIME [epoch: 24.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23356170418222216		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.23356170418222216 | validation: 0.2644475865024806]
	TIME [epoch: 24.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.229704231834215		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.229704231834215 | validation: 0.3021638742619531]
	TIME [epoch: 24.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3825858741161061		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.3825858741161061 | validation: 0.5820095916396165]
	TIME [epoch: 24.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.348184549515224		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.348184549515224 | validation: 0.2379128896967059]
	TIME [epoch: 24.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584492585626351		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.2584492585626351 | validation: 0.29451059750773595]
	TIME [epoch: 24.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2563360040641961		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.2563360040641961 | validation: 0.22387826117053058]
	TIME [epoch: 24.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27831317673312095		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.27831317673312095 | validation: 0.2356154542048764]
	TIME [epoch: 24.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21685889394053373		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.21685889394053373 | validation: 0.23755090235667894]
	TIME [epoch: 24.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.232257192907393		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.232257192907393 | validation: 0.22542790904048526]
	TIME [epoch: 24.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22390277830783775		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.22390277830783775 | validation: 0.3278457662576603]
	TIME [epoch: 24.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37825944326992317		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.37825944326992317 | validation: 0.42069817529465126]
	TIME [epoch: 24.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35771217572806435		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.35771217572806435 | validation: 0.2593862197527493]
	TIME [epoch: 24.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21151580640890083		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.21151580640890083 | validation: 0.2417136671532408]
	TIME [epoch: 24.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259247715420868		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.259247715420868 | validation: 0.34169268552279475]
	TIME [epoch: 24.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38991382645189065		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.38991382645189065 | validation: 0.41551826124416047]
	TIME [epoch: 24.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36560236444251676		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.36560236444251676 | validation: 0.22899173400868233]
	TIME [epoch: 24.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2001033844946577		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.2001033844946577 | validation: 0.22590075280057634]
	TIME [epoch: 24.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2527733186364604		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.2527733186364604 | validation: 0.2144434317219912]
	TIME [epoch: 24.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15750987180722478		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.15750987180722478 | validation: 0.13962197018389355]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1763761083266761		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.1763761083266761 | validation: 0.1654083557013923]
	TIME [epoch: 24.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2172363588793185		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.2172363588793185 | validation: 0.31267254650908133]
	TIME [epoch: 24.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26388341931429204		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.26388341931429204 | validation: 0.2010897668822366]
	TIME [epoch: 24.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21336846747806237		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.21336846747806237 | validation: 0.15220743474533124]
	TIME [epoch: 24.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15010246951217693		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.15010246951217693 | validation: 0.15516916510383386]
	TIME [epoch: 24.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1770065668250482		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.1770065668250482 | validation: 0.19035321380058753]
	TIME [epoch: 24.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23639427624006176		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.23639427624006176 | validation: 0.32241514048816455]
	TIME [epoch: 24.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.393723259111864		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.393723259111864 | validation: 0.3675949817493225]
	TIME [epoch: 24.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.264935361778846		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.264935361778846 | validation: 0.24589695223156655]
	TIME [epoch: 24.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918088335680878		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.3918088335680878 | validation: 0.4254246859038517]
	TIME [epoch: 24.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3147075996181028		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.3147075996181028 | validation: 0.21299387668605504]
	TIME [epoch: 24.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2518931161973934		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.2518931161973934 | validation: 0.3607652653421232]
	TIME [epoch: 24.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30202631810746405		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.30202631810746405 | validation: 0.258937454322814]
	TIME [epoch: 24.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3655279241605829		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.3655279241605829 | validation: 0.6665947438965129]
	TIME [epoch: 24.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6655446797459563		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.6655446797459563 | validation: 0.8193518052821436]
	TIME [epoch: 24.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6579967875620287		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.6579967875620287 | validation: 0.37727863637657144]
	TIME [epoch: 24.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39657623009023013		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.39657623009023013 | validation: 0.4360161240791942]
	TIME [epoch: 24.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37323466789621845		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.37323466789621845 | validation: 0.2942452669608493]
	TIME [epoch: 24.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3355099764414165		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.3355099764414165 | validation: 0.5226803707134271]
	TIME [epoch: 24.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49754204453735895		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.49754204453735895 | validation: 0.46253977103310334]
	TIME [epoch: 24.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4201170698439381		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.4201170698439381 | validation: 0.4055411997416978]
	TIME [epoch: 24.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6419884773847107		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.6419884773847107 | validation: 1.065968917712946]
	TIME [epoch: 24.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8628873811391351		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.8628873811391351 | validation: 0.6505947170458385]
	TIME [epoch: 24.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4834056297195927		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.4834056297195927 | validation: 0.37922678020760886]
	TIME [epoch: 24.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32084062655339385		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.32084062655339385 | validation: 0.32434649985893366]
	TIME [epoch: 24.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933769389995069		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.2933769389995069 | validation: 0.2697483902123164]
	TIME [epoch: 24.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28578826652071204		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.28578826652071204 | validation: 0.2532922757966693]
	TIME [epoch: 24.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2276380885135526		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.2276380885135526 | validation: 0.21286764755007626]
	TIME [epoch: 24.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21835727671358773		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.21835727671358773 | validation: 0.24793420947544675]
	TIME [epoch: 24.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29430534045133017		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.29430534045133017 | validation: 0.35203234789499527]
	TIME [epoch: 24.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3220903063034707		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.3220903063034707 | validation: 0.35982785126640143]
	TIME [epoch: 24.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3962105913859516		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.3962105913859516 | validation: 0.2848245880347247]
	TIME [epoch: 24.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2969707678076458		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.2969707678076458 | validation: 0.34049675849782984]
	TIME [epoch: 24.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30228493280984325		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.30228493280984325 | validation: 0.28368781113841174]
	TIME [epoch: 24.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23914880663062651		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.23914880663062651 | validation: 0.30949259541075064]
	TIME [epoch: 24.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859176348281295		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.2859176348281295 | validation: 0.2549455760606908]
	TIME [epoch: 24.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23461851784445056		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.23461851784445056 | validation: 0.39265082154133424]
	TIME [epoch: 24.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4141507002838367		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.4141507002838367 | validation: 0.45296094983266727]
	TIME [epoch: 24.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49328626003120973		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.49328626003120973 | validation: 0.6784223661208202]
	TIME [epoch: 24.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4556150800983186		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.4556150800983186 | validation: 0.3352125610743009]
	TIME [epoch: 24.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2726505216719077		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.2726505216719077 | validation: 0.27981039299954225]
	TIME [epoch: 24.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3207780719198792		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.3207780719198792 | validation: 0.4763464962432299]
	TIME [epoch: 24.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45676993319135983		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.45676993319135983 | validation: 0.4108846323104989]
	TIME [epoch: 24.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2807515857508725		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2807515857508725 | validation: 0.258808606784335]
	TIME [epoch: 24.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858463071237319		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.2858463071237319 | validation: 0.30747624640936144]
	TIME [epoch: 24.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4093352024280702		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.4093352024280702 | validation: 0.46942386335406516]
	TIME [epoch: 24.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34802110284843085		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.34802110284843085 | validation: 0.24586110715494536]
	TIME [epoch: 24.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25725587430787783		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.25725587430787783 | validation: 0.24900337315173549]
	TIME [epoch: 24.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23721602555683008		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.23721602555683008 | validation: 0.2273131162519446]
	TIME [epoch: 24.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2222084702468349		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.2222084702468349 | validation: 0.29843269383459536]
	TIME [epoch: 24.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2801949608225861		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.2801949608225861 | validation: 0.22848347890727794]
	TIME [epoch: 24.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19524353544945205		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.19524353544945205 | validation: 0.17982141688020478]
	TIME [epoch: 24.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21571537165980864		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.21571537165980864 | validation: 0.1846460084978603]
	TIME [epoch: 24.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.187476252640787		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.187476252640787 | validation: 0.16715333054807205]
	TIME [epoch: 24.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17438017440052772		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.17438017440052772 | validation: 0.1850404024797529]
	TIME [epoch: 24.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21157238129681893		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.21157238129681893 | validation: 0.18331012431109947]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20408330622549062		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.20408330622549062 | validation: 0.23490939605050415]
	TIME [epoch: 24.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20437637024270286		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.20437637024270286 | validation: 0.18765942992285403]
	TIME [epoch: 24.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18023841802562607		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.18023841802562607 | validation: 0.17340662917497093]
	TIME [epoch: 24.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18701918550049573		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.18701918550049573 | validation: 0.2748511909794588]
	TIME [epoch: 24.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25336112626954393		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.25336112626954393 | validation: 0.27008003696258825]
	TIME [epoch: 24.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2152940114462063		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.2152940114462063 | validation: 0.1854852927117392]
	TIME [epoch: 24.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1793796591234956		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.1793796591234956 | validation: 0.20403997783349093]
	TIME [epoch: 24.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22150416860944377		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.22150416860944377 | validation: 0.23151413412733754]
	TIME [epoch: 24.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19393839957675585		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.19393839957675585 | validation: 0.22490509461297026]
	TIME [epoch: 24.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17351248192106547		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.17351248192106547 | validation: 0.1577260075691142]
	TIME [epoch: 24.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1691328014422046		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.1691328014422046 | validation: 0.19146383081902593]
	TIME [epoch: 24.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20131226312236386		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.20131226312236386 | validation: 0.2218630589426531]
	TIME [epoch: 24.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20925473819234314		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.20925473819234314 | validation: 0.20903561872397383]
	TIME [epoch: 24.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19592269200472745		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.19592269200472745 | validation: 0.1547572965193853]
	TIME [epoch: 24.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1695486172729671		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.1695486172729671 | validation: 0.1677888558604533]
	TIME [epoch: 24.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18540022758107014		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.18540022758107014 | validation: 0.2030406685953767]
	TIME [epoch: 24.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088109573913428		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.2088109573913428 | validation: 0.3304459021331516]
	TIME [epoch: 24.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29274468280610827		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.29274468280610827 | validation: 0.34760811291351235]
	TIME [epoch: 24.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2872858467184738		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.2872858467184738 | validation: 0.24765177905236024]
	TIME [epoch: 24.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20606110834964372		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.20606110834964372 | validation: 0.288795463202546]
	TIME [epoch: 24.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25210927852998444		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.25210927852998444 | validation: 0.21041626225636179]
	TIME [epoch: 24.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27676775416230237		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.27676775416230237 | validation: 0.39681998455922307]
	TIME [epoch: 24.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2814489694187013		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.2814489694187013 | validation: 0.2220563774293978]
	TIME [epoch: 24.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19894528710096387		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.19894528710096387 | validation: 0.21338963525540042]
	TIME [epoch: 24.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19142712347164767		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.19142712347164767 | validation: 0.22651444382124786]
	TIME [epoch: 24.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2877156583488588		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.2877156583488588 | validation: 0.5958938268625411]
	TIME [epoch: 24.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4043391100554074		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.4043391100554074 | validation: 0.2655741840318008]
	TIME [epoch: 24.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21678351103544896		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.21678351103544896 | validation: 0.18406635253830736]
	TIME [epoch: 24.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18021657029465774		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.18021657029465774 | validation: 0.21993242083415893]
	TIME [epoch: 24.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19909491045455485		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.19909491045455485 | validation: 0.2070915643711404]
	TIME [epoch: 24.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18720428013175608		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.18720428013175608 | validation: 0.18925478144242192]
	TIME [epoch: 24.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21221555057598823		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.21221555057598823 | validation: 0.25636321119281263]
	TIME [epoch: 24.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20825979949316306		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.20825979949316306 | validation: 0.1771277061872302]
	TIME [epoch: 24.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17388758661552522		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.17388758661552522 | validation: 0.21677797743876479]
	TIME [epoch: 24.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20888145484601997		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.20888145484601997 | validation: 0.2144561340574948]
	TIME [epoch: 24.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19059322411701207		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.19059322411701207 | validation: 0.2283984463070955]
	TIME [epoch: 24.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.226052681987509		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.226052681987509 | validation: 0.1630264136532424]
	TIME [epoch: 24.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1706675796414278		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.1706675796414278 | validation: 0.20461398450239204]
	TIME [epoch: 24.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20709472882878283		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.20709472882878283 | validation: 0.22842032617344196]
	TIME [epoch: 24.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16420747611571487		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.16420747611571487 | validation: 0.127459973736733]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_652.pth
	Model improved!!!
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332917010950499		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.1332917010950499 | validation: 0.2023059569498633]
	TIME [epoch: 24.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19026737527112011		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.19026737527112011 | validation: 0.146185501810193]
	TIME [epoch: 24.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601231559095175		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.1601231559095175 | validation: 0.2636132051852985]
	TIME [epoch: 24.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22077396329286098		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.22077396329286098 | validation: 0.17039317081557806]
	TIME [epoch: 24.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16773079772864008		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.16773079772864008 | validation: 0.16301200175888736]
	TIME [epoch: 24.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1982237519655732		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.1982237519655732 | validation: 0.2770129740872859]
	TIME [epoch: 24.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.229842624591396		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.229842624591396 | validation: 0.21961957386797903]
	TIME [epoch: 24.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1693151287025259		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.1693151287025259 | validation: 0.14941810110359993]
	TIME [epoch: 24.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17378448285881284		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.17378448285881284 | validation: 0.1753725346927584]
	TIME [epoch: 24.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16429679228910887		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.16429679228910887 | validation: 0.15300599634289408]
	TIME [epoch: 24.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15354737109761687		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.15354737109761687 | validation: 0.1354005007272953]
	TIME [epoch: 24.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15007798112560242		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.15007798112560242 | validation: 0.12286820078141439]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_664.pth
	Model improved!!!
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12414185210216142		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.12414185210216142 | validation: 0.1194507997526162]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_665.pth
	Model improved!!!
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16667621704591548		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.16667621704591548 | validation: 0.3786784826249205]
	TIME [epoch: 24.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39004106010230327		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.39004106010230327 | validation: 0.33233337900485566]
	TIME [epoch: 24.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19005658510842016		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.19005658510842016 | validation: 0.17378790800772315]
	TIME [epoch: 24.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1808517716664792		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.1808517716664792 | validation: 0.17554732278571972]
	TIME [epoch: 24.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.212928624056701		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.212928624056701 | validation: 0.26435765192623906]
	TIME [epoch: 24.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24667788197728294		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.24667788197728294 | validation: 0.18222984209142293]
	TIME [epoch: 24.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16698082713385043		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.16698082713385043 | validation: 0.21082513789628848]
	TIME [epoch: 24.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1727224848006798		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.1727224848006798 | validation: 0.1321521100833655]
	TIME [epoch: 24.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14810643794836947		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.14810643794836947 | validation: 0.1611050083772691]
	TIME [epoch: 24.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14127209725888148		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.14127209725888148 | validation: 0.19346234685095837]
	TIME [epoch: 24.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22145331352552428		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.22145331352552428 | validation: 0.25216757326320854]
	TIME [epoch: 24.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22043529013439822		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.22043529013439822 | validation: 0.23031869749109796]
	TIME [epoch: 24.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25928225175526837		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.25928225175526837 | validation: 0.37512104429882115]
	TIME [epoch: 24.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33993255597535554		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.33993255597535554 | validation: 0.4338594119924718]
	TIME [epoch: 24.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3815163249394301		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.3815163249394301 | validation: 0.24939614380995728]
	TIME [epoch: 24.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18101037775820783		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.18101037775820783 | validation: 0.14516884564607618]
	TIME [epoch: 24.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.218188414487477		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.218188414487477 | validation: 0.4109375387431484]
	TIME [epoch: 24.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32527619065636		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.32527619065636 | validation: 0.25332509895917865]
	TIME [epoch: 24.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20275497486573743		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.20275497486573743 | validation: 0.21418276882216794]
	TIME [epoch: 24.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1866489284065297		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.1866489284065297 | validation: 0.14667462156747088]
	TIME [epoch: 24.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14526198937582915		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.14526198937582915 | validation: 0.1763068139048045]
	TIME [epoch: 24.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520877478475287		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.1520877478475287 | validation: 0.14541233344254234]
	TIME [epoch: 24.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23098806248021336		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.23098806248021336 | validation: 0.4803251095587768]
	TIME [epoch: 24.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5395071077676962		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.5395071077676962 | validation: 0.46983842931552533]
	TIME [epoch: 24.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39112298996635575		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.39112298996635575 | validation: 0.3205971760710148]
	TIME [epoch: 24.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24405905093679103		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.24405905093679103 | validation: 0.18583419534215023]
	TIME [epoch: 24.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18144467377875076		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.18144467377875076 | validation: 0.15312439327151375]
	TIME [epoch: 24.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16635237139818415		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.16635237139818415 | validation: 0.25878100320240743]
	TIME [epoch: 24.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2221913643988197		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.2221913643988197 | validation: 0.26159293968110126]
	TIME [epoch: 24.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20942907247358478		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.20942907247358478 | validation: 0.2263245739467061]
	TIME [epoch: 24.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19878518865818207		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.19878518865818207 | validation: 0.18451589507929428]
	TIME [epoch: 24.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20733638011023192		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.20733638011023192 | validation: 0.33676377266348195]
	TIME [epoch: 24.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23942863033893375		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.23942863033893375 | validation: 0.23395062287512453]
	TIME [epoch: 24.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545574023431942		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.2545574023431942 | validation: 0.18487042332612943]
	TIME [epoch: 24.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.159648826100243		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.159648826100243 | validation: 0.22470146019827275]
	TIME [epoch: 24.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36470362764815933		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.36470362764815933 | validation: 0.5986985779645159]
	TIME [epoch: 24.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42738523746841844		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.42738523746841844 | validation: 0.2593731081677327]
	TIME [epoch: 24.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18369514964709494		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.18369514964709494 | validation: 0.21440777207322648]
	TIME [epoch: 24.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17802843137407515		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.17802843137407515 | validation: 0.1383753941951834]
	TIME [epoch: 24.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14495321743009149		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.14495321743009149 | validation: 0.17115649736507813]
	TIME [epoch: 24.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15785558414479986		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.15785558414479986 | validation: 0.2707223533742249]
	TIME [epoch: 24.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2385558943634528		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.2385558943634528 | validation: 0.20254710478408172]
	TIME [epoch: 24.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18763653601017266		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.18763653601017266 | validation: 0.2082176368994297]
	TIME [epoch: 24.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1917357898149545		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.1917357898149545 | validation: 0.18289339656621806]
	TIME [epoch: 24.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14942205239291892		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.14942205239291892 | validation: 0.18391665952125066]
	TIME [epoch: 24.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28529563203614616		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.28529563203614616 | validation: 0.3357267231927015]
	TIME [epoch: 24.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24934829102085948		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.24934829102085948 | validation: 0.20272146957974038]
	TIME [epoch: 24.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2405122076348834		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.2405122076348834 | validation: 0.27308249611814434]
	TIME [epoch: 24.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28215182502136027		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.28215182502136027 | validation: 0.2562246209024266]
	TIME [epoch: 24.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20695756575945812		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.20695756575945812 | validation: 0.19509671641327347]
	TIME [epoch: 24.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15476190346598115		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.15476190346598115 | validation: 0.10639016954394297]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_716.pth
	Model improved!!!
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15913656724714131		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.15913656724714131 | validation: 0.19953759943053279]
	TIME [epoch: 24.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14392660436805385		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.14392660436805385 | validation: 0.11522593189183955]
	TIME [epoch: 24.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12049440899356081		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.12049440899356081 | validation: 0.11200625015073669]
	TIME [epoch: 24.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14917806176757442		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.14917806176757442 | validation: 0.15090966619631285]
	TIME [epoch: 24.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15047630816625826		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.15047630816625826 | validation: 0.1562115914833877]
	TIME [epoch: 24.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438285220442802		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.1438285220442802 | validation: 0.19132581057175885]
	TIME [epoch: 24.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1991751712252274		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.1991751712252274 | validation: 0.1745389351949202]
	TIME [epoch: 24.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14841223991281244		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.14841223991281244 | validation: 0.1384363467414556]
	TIME [epoch: 24.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13517649281752475		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.13517649281752475 | validation: 0.09770946037153883]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_725.pth
	Model improved!!!
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11151535706713903		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.11151535706713903 | validation: 0.13147815248254408]
	TIME [epoch: 24.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16472834995816563		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.16472834995816563 | validation: 0.32107456588285843]
	TIME [epoch: 24.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42663431661398415		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.42663431661398415 | validation: 0.5520236665336623]
	TIME [epoch: 24.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4561134824235348		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.4561134824235348 | validation: 0.3599271644996344]
	TIME [epoch: 24.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29941630203033937		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.29941630203033937 | validation: 0.2955677647942107]
	TIME [epoch: 24.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2630469103045723		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.2630469103045723 | validation: 0.24665701108251334]
	TIME [epoch: 24.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1822141411481796		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.1822141411481796 | validation: 0.1445560083806867]
	TIME [epoch: 24.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14616423085837282		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.14616423085837282 | validation: 0.12660999549006496]
	TIME [epoch: 24.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1147360363628259		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.1147360363628259 | validation: 0.11207414169443722]
	TIME [epoch: 24.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1178840153774229		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.1178840153774229 | validation: 0.11005024865759491]
	TIME [epoch: 24.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11002619833009028		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.11002619833009028 | validation: 0.11136355535853713]
	TIME [epoch: 24.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11078251679111703		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.11078251679111703 | validation: 0.12844097941863442]
	TIME [epoch: 24.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1182140698341475		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.1182140698341475 | validation: 0.1252464018111018]
	TIME [epoch: 24.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12861866149426943		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.12861866149426943 | validation: 0.11842094455485391]
	TIME [epoch: 24.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1251157285176995		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.1251157285176995 | validation: 0.12645830839754105]
	TIME [epoch: 24.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14540717638669512		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.14540717638669512 | validation: 0.21824945708289067]
	TIME [epoch: 24.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19400485149607521		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.19400485149607521 | validation: 0.2145763148008746]
	TIME [epoch: 24.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1936368732221417		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.1936368732221417 | validation: 0.1823343831658083]
	TIME [epoch: 24.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19722921816405184		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.19722921816405184 | validation: 0.24641939905095514]
	TIME [epoch: 24.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.186162314065405		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.186162314065405 | validation: 0.15067076098026363]
	TIME [epoch: 24.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16266795767678202		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.16266795767678202 | validation: 0.1564512804790577]
	TIME [epoch: 24.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19958047913539123		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.19958047913539123 | validation: 0.19693051292974184]
	TIME [epoch: 24.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18863039166034137		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.18863039166034137 | validation: 0.15657427987010084]
	TIME [epoch: 24.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14065545122602424		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.14065545122602424 | validation: 0.13244837868905895]
	TIME [epoch: 24.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253673632970578		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.1253673632970578 | validation: 0.12707375436736287]
	TIME [epoch: 24.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14167247152671708		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.14167247152671708 | validation: 0.15783558474347661]
	TIME [epoch: 24.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14425853287244875		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.14425853287244875 | validation: 0.1535494926618627]
	TIME [epoch: 24.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13068590217183979		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.13068590217183979 | validation: 0.11007650745393814]
	TIME [epoch: 24.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11339009503441909		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.11339009503441909 | validation: 0.11476705672743708]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14196532063071993		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.14196532063071993 | validation: 0.1374609954077881]
	TIME [epoch: 24.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13266322661617433		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.13266322661617433 | validation: 0.13109940953241397]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11195463072499967		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.11195463072499967 | validation: 0.10235926929547663]
	TIME [epoch: 24.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14182713635412136		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.14182713635412136 | validation: 0.1505400483367714]
	TIME [epoch: 24.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14232588238774874		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.14232588238774874 | validation: 0.17332251255588915]
	TIME [epoch: 24.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19805740541880723		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.19805740541880723 | validation: 0.15641825484118843]
	TIME [epoch: 24.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14500250065797105		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.14500250065797105 | validation: 0.16599342412401336]
	TIME [epoch: 24.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15807678259717728		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.15807678259717728 | validation: 0.1899844664166308]
	TIME [epoch: 24.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.189916231199815		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.189916231199815 | validation: 0.2573416205005728]
	TIME [epoch: 24.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2250374260834072		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.2250374260834072 | validation: 0.32216226095869005]
	TIME [epoch: 24.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38652489362396686		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.38652489362396686 | validation: 0.5809065377284145]
	TIME [epoch: 24.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45845004707215864		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.45845004707215864 | validation: 0.40647585466561836]
	TIME [epoch: 24.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3200175708823204		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.3200175708823204 | validation: 0.23664817913636468]
	TIME [epoch: 24.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20516387088236146		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.20516387088236146 | validation: 0.16076504640522912]
	TIME [epoch: 24.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374092565567388		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.1374092565567388 | validation: 0.18647497026573798]
	TIME [epoch: 24.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13798355643721777		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.13798355643721777 | validation: 0.1024757972642389]
	TIME [epoch: 24.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10140846512197635		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.10140846512197635 | validation: 0.10854680736933321]
	TIME [epoch: 24.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1862361951055777		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.1862361951055777 | validation: 0.310654797747716]
	TIME [epoch: 24.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28599733838185254		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.28599733838185254 | validation: 0.2802468925053528]
	TIME [epoch: 24.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18420599817128627		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.18420599817128627 | validation: 0.10559760087656575]
	TIME [epoch: 24.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12180453446328023		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.12180453446328023 | validation: 0.17922967701492148]
	TIME [epoch: 24.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510118317713663		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.1510118317713663 | validation: 0.13527364146913307]
	TIME [epoch: 24.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11389368029025371		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.11389368029025371 | validation: 0.12059485331076142]
	TIME [epoch: 24.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12511321661182467		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.12511321661182467 | validation: 0.12073332490133501]
	TIME [epoch: 24.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11704103463748784		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.11704103463748784 | validation: 0.10824608231402312]
	TIME [epoch: 24.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12463204404069622		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.12463204404069622 | validation: 0.20047605610150926]
	TIME [epoch: 24.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2764479674062683		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.2764479674062683 | validation: 0.3471859399780741]
	TIME [epoch: 24.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2688728353436781		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.2688728353436781 | validation: 0.2877532686431583]
	TIME [epoch: 24.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21449533399687712		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.21449533399687712 | validation: 0.14248349844847308]
	TIME [epoch: 24.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13097227894386576		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.13097227894386576 | validation: 0.14607902252789928]
	TIME [epoch: 24.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12509060782042136		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.12509060782042136 | validation: 0.11600174575855501]
	TIME [epoch: 24.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10300284982157855		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.10300284982157855 | validation: 0.10250195796660411]
	TIME [epoch: 24.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11367568165119978		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.11367568165119978 | validation: 0.1497291687270705]
	TIME [epoch: 24.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15821625201939318		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.15821625201939318 | validation: 0.16310506429723576]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17731901302059128		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.17731901302059128 | validation: 0.2734553850941832]
	TIME [epoch: 24.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24304138769084382		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.24304138769084382 | validation: 0.17705766310983279]
	TIME [epoch: 24.8 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15346614564652256		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.15346614564652256 | validation: 0.14861137239195826]
	TIME [epoch: 24.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19199429365174084		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.19199429365174084 | validation: 0.3708276914200698]
	TIME [epoch: 24.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2603494707355785		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.2603494707355785 | validation: 0.16569108614163475]
	TIME [epoch: 24.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13051302182678087		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.13051302182678087 | validation: 0.11811096716510656]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252838339012751		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.1252838339012751 | validation: 0.10830969499679263]
	TIME [epoch: 24.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10872301327063565		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.10872301327063565 | validation: 0.09994228963469795]
	TIME [epoch: 24.8 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16360003265282907		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.16360003265282907 | validation: 0.33262133308736397]
	TIME [epoch: 24.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28081884751000835		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.28081884751000835 | validation: 0.17400633014820094]
	TIME [epoch: 24.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296238513309304		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.1296238513309304 | validation: 0.1122003713452385]
	TIME [epoch: 24.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10271602752025828		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.10271602752025828 | validation: 0.0961395611289662]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_800.pth
	Model improved!!!
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12037308628707834		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.12037308628707834 | validation: 0.11284365722225279]
	TIME [epoch: 24.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12580557346410615		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.12580557346410615 | validation: 0.09982018949468652]
	TIME [epoch: 24.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12386581911071044		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.12386581911071044 | validation: 0.1387214030517264]
	TIME [epoch: 24.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13597779897508083		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.13597779897508083 | validation: 0.12749515851997656]
	TIME [epoch: 24.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12171513376327953		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.12171513376327953 | validation: 0.11529830286165955]
	TIME [epoch: 24.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1084634533866797		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.1084634533866797 | validation: 0.09781811046574587]
	TIME [epoch: 24.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11378890714238984		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.11378890714238984 | validation: 0.11914281633600919]
	TIME [epoch: 24.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301781971633949		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.1301781971633949 | validation: 0.11829713687865052]
	TIME [epoch: 24.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11538733081152985		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.11538733081152985 | validation: 0.12140546079994849]
	TIME [epoch: 24.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11148733531567907		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.11148733531567907 | validation: 0.12413230041109906]
	TIME [epoch: 24.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11523392203471775		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.11523392203471775 | validation: 0.1283377260908003]
	TIME [epoch: 24.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488165421102535		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.1488165421102535 | validation: 0.16273150576667494]
	TIME [epoch: 24.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14612222640660344		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.14612222640660344 | validation: 0.15472341721645685]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12728201450525087		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.12728201450525087 | validation: 0.11519197900214968]
	TIME [epoch: 24.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13695092533025044		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.13695092533025044 | validation: 0.16125867137975308]
	TIME [epoch: 24.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12865356184890442		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.12865356184890442 | validation: 0.10977170272473917]
	TIME [epoch: 24.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10975038851979863		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.10975038851979863 | validation: 0.09617419654253295]
	TIME [epoch: 24.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10371871374906283		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.10371871374906283 | validation: 0.10286805654963695]
	TIME [epoch: 24.8 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10387166865757197		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.10387166865757197 | validation: 0.13110543325468846]
	TIME [epoch: 24.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1669064021684014		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.1669064021684014 | validation: 0.1501033558863097]
	TIME [epoch: 24.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16972325223304702		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.16972325223304702 | validation: 0.1558075608073617]
	TIME [epoch: 24.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15570238360457872		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.15570238360457872 | validation: 0.12104160112090644]
	TIME [epoch: 24.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14900787965954437		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.14900787965954437 | validation: 0.1983959592864759]
	TIME [epoch: 24.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1787380753543305		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.1787380753543305 | validation: 0.11760839852555627]
	TIME [epoch: 24.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13307045101159062		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.13307045101159062 | validation: 0.1766037878697195]
	TIME [epoch: 24.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16404064280439487		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.16404064280439487 | validation: 0.2052096739410341]
	TIME [epoch: 24.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16188877103562468		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.16188877103562468 | validation: 0.13463775900397573]
	TIME [epoch: 24.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11713719462865371		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.11713719462865371 | validation: 0.12196056823412775]
	TIME [epoch: 24.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10355516021573155		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.10355516021573155 | validation: 0.1182149056199231]
	TIME [epoch: 24.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13929712891074525		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.13929712891074525 | validation: 0.14997234277162402]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310041340444025		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.1310041340444025 | validation: 0.12749945129162307]
	TIME [epoch: 24.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11747129181205565		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.11747129181205565 | validation: 0.11191301459993376]
	TIME [epoch: 24.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10450946949639735		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.10450946949639735 | validation: 0.1008587412492199]
	TIME [epoch: 24.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1055596198951644		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.1055596198951644 | validation: 0.1127977408869604]
	TIME [epoch: 24.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11242958195675898		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.11242958195675898 | validation: 0.1773711237713385]
	TIME [epoch: 24.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14425239733345818		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.14425239733345818 | validation: 0.11568725406350966]
	TIME [epoch: 24.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10933754844996413		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.10933754844996413 | validation: 0.09141902105576208]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_837.pth
	Model improved!!!
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09246514562489112		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.09246514562489112 | validation: 0.09683072612511918]
	TIME [epoch: 24.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09043199971714537		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.09043199971714537 | validation: 0.09567539140560687]
	TIME [epoch: 24.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09961976499293138		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.09961976499293138 | validation: 0.09431402637112324]
	TIME [epoch: 24.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09637165309261442		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.09637165309261442 | validation: 0.08686965561127717]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_841.pth
	Model improved!!!
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10885582427590354		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.10885582427590354 | validation: 0.1560050468969303]
	TIME [epoch: 24.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13825545544480988		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.13825545544480988 | validation: 0.10482691500372722]
	TIME [epoch: 24.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11077535400051494		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.11077535400051494 | validation: 0.12429632410790062]
	TIME [epoch: 24.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11231887277880934		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.11231887277880934 | validation: 0.1307825456435024]
	TIME [epoch: 24.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11278879136843134		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.11278879136843134 | validation: 0.10774849220274055]
	TIME [epoch: 24.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12007864957979929		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.12007864957979929 | validation: 0.16504470466604332]
	TIME [epoch: 24.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20547381145475713		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.20547381145475713 | validation: 0.19543247882440531]
	TIME [epoch: 24.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1733709366334793		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.1733709366334793 | validation: 0.1343958705254488]
	TIME [epoch: 24.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11560459336857834		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.11560459336857834 | validation: 0.11420074793006296]
	TIME [epoch: 24.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11287794553594095		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.11287794553594095 | validation: 0.09927613028020328]
	TIME [epoch: 24.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10090183846402768		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.10090183846402768 | validation: 0.14565624859774526]
	TIME [epoch: 24.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15287081671668368		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.15287081671668368 | validation: 0.1736247011661155]
	TIME [epoch: 24.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15533938271782438		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.15533938271782438 | validation: 0.14874750547101112]
	TIME [epoch: 24.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11883215481906542		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.11883215481906542 | validation: 0.08615017190331413]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_855.pth
	Model improved!!!
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09401656386413003		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.09401656386413003 | validation: 0.16876742391851474]
	TIME [epoch: 24.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14461269687880307		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.14461269687880307 | validation: 0.1252950104058838]
	TIME [epoch: 24.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09856700919976705		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.09856700919976705 | validation: 0.10174709534078953]
	TIME [epoch: 24.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08899622632124685		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.08899622632124685 | validation: 0.09676696111531677]
	TIME [epoch: 24.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09619012988843162		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.09619012988843162 | validation: 0.07344723340616474]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_860.pth
	Model improved!!!
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10111693204653706		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.10111693204653706 | validation: 0.11479708682010685]
	TIME [epoch: 24.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10086466819524088		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.10086466819524088 | validation: 0.07768914324176722]
	TIME [epoch: 24.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07721463411346471		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.07721463411346471 | validation: 0.08118660510911345]
	TIME [epoch: 24.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08770844605552479		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.08770844605552479 | validation: 0.09572523668624974]
	TIME [epoch: 24.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09254294906366947		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.09254294906366947 | validation: 0.08591913077604957]
	TIME [epoch: 24.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08452225849242326		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.08452225849242326 | validation: 0.08624832685367341]
	TIME [epoch: 24.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09319208148470828		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.09319208148470828 | validation: 0.08287722553273945]
	TIME [epoch: 24.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07996052808817901		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.07996052808817901 | validation: 0.08038746562820552]
	TIME [epoch: 24.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07965514362623266		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.07965514362623266 | validation: 0.07073807431329886]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240309_135701/states/model_tr_study6_869.pth
	Model improved!!!
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07831519496940167		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.07831519496940167 | validation: 0.08264667580133402]
	TIME [epoch: 24.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08485017812764933		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.08485017812764933 | validation: 0.08736435062696772]
	TIME [epoch: 24.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0785003667272341		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.0785003667272341 | validation: 0.08145776635703963]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08168521171449282		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.08168521171449282 | validation: 0.10365974941663537]
	TIME [epoch: 24.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10431589017139488		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.10431589017139488 | validation: 0.14340932177091512]
	TIME [epoch: 24.8 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12104755213473382		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.12104755213473382 | validation: 0.11473849923897712]
	TIME [epoch: 24.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09639742445810559		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.09639742445810559 | validation: 0.11796655504149413]
	TIME [epoch: 24.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09908501395643986		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.09908501395643986 | validation: 0.08756208656292085]
	TIME [epoch: 24.8 sec]
EPOCH 878/2000:
	Training over batches...
