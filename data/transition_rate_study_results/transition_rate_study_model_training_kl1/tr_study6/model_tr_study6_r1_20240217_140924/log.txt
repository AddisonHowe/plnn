Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r1', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 161461668

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.981283463034842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.981283463034842 | validation: 10.067217140467768]
	TIME [epoch: 80.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.46179480378903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.46179480378903 | validation: 8.223685410262405]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.7003392452016985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.7003392452016985 | validation: 8.128192744005148]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.5040434620321665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.5040434620321665 | validation: 8.013090307817661]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.385686209295845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.385686209295845 | validation: 8.113464197094132]
	TIME [epoch: 9.46 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.346729985866732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.346729985866732 | validation: 7.9698141002244505]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.2064965232093074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.2064965232093074 | validation: 7.9955632557840115]
	TIME [epoch: 9.5 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.216138653491751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.216138653491751 | validation: 7.807272954672554]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.050052083286329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.050052083286329 | validation: 7.682374908336274]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.8692927648951585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8692927648951585 | validation: 7.81339198278037]
	TIME [epoch: 9.46 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.0963858565409454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.0963858565409454 | validation: 7.678164157967644]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.871981845847797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.871981845847797 | validation: 7.619199902520054]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.816606818009662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.816606818009662 | validation: 7.6088849347825]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.8245144776461615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8245144776461615 | validation: 7.659202887504346]
	TIME [epoch: 9.45 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.846831346223207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.846831346223207 | validation: 7.582440443621813]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.8256278044741565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8256278044741565 | validation: 7.540411015963939]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.762662539627814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.762662539627814 | validation: 7.566917661711795]
	TIME [epoch: 9.45 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.732465987444067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.732465987444067 | validation: 7.621166215010294]
	TIME [epoch: 9.47 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.8715055827301175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8715055827301175 | validation: 7.791278182679833]
	TIME [epoch: 9.46 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.791026994762492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.791026994762492 | validation: 7.581382499547736]
	TIME [epoch: 9.45 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.734919970661475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.734919970661475 | validation: 7.742703558856006]
	TIME [epoch: 9.45 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.927012487072491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.927012487072491 | validation: 7.971750632319929]
	TIME [epoch: 9.48 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.893496146838066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.893496146838066 | validation: 7.53652496102314]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.787285165953807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.787285165953807 | validation: 7.577639571733428]
	TIME [epoch: 9.47 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.862984812689729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.862984812689729 | validation: 7.523858943809748]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.7138328701698695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7138328701698695 | validation: 7.528288779145627]
	TIME [epoch: 9.49 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.722043504723315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.722043504723315 | validation: 7.527978717892316]
	TIME [epoch: 9.46 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.795379050554397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.795379050554397 | validation: 7.588270423796978]
	TIME [epoch: 9.46 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.7857699063684125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7857699063684125 | validation: 7.623630814909298]
	TIME [epoch: 9.46 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.750724306062826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.750724306062826 | validation: 7.565920868143648]
	TIME [epoch: 9.48 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.867851451255312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.867851451255312 | validation: 7.804710609353113]
	TIME [epoch: 9.46 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.798879031259537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.798879031259537 | validation: 7.544262847896743]
	TIME [epoch: 9.46 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.706623006260623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.706623006260623 | validation: 7.718919388627703]
	TIME [epoch: 9.46 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.748052571311815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.748052571311815 | validation: 7.593997306025683]
	TIME [epoch: 9.48 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.899219350121132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.899219350121132 | validation: 7.746283505353315]
	TIME [epoch: 9.46 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.822631548609782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.822631548609782 | validation: 7.628464994617886]
	TIME [epoch: 9.46 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.78366680720513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.78366680720513 | validation: 7.600160808421288]
	TIME [epoch: 9.47 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.729817757110112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.729817757110112 | validation: 7.586276490125053]
	TIME [epoch: 9.47 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.702842107443567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.702842107443567 | validation: 7.573851751778525]
	TIME [epoch: 9.46 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.744686847415461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.744686847415461 | validation: 7.536624953876327]
	TIME [epoch: 9.46 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.719534353607092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.719534353607092 | validation: 7.579409844716844]
	TIME [epoch: 9.49 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.695634177742127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.695634177742127 | validation: 7.640548359033586]
	TIME [epoch: 9.46 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.778951415778652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.778951415778652 | validation: 7.5670362983554575]
	TIME [epoch: 9.46 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.747982673749993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.747982673749993 | validation: 7.512540770927865]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.874643740168635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.874643740168635 | validation: 7.509719180654376]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.680650463948905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.680650463948905 | validation: 7.529560284322529]
	TIME [epoch: 9.47 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.683760167183207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.683760167183207 | validation: 7.55972657580729]
	TIME [epoch: 9.46 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.7106336984516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7106336984516 | validation: 7.598222233027029]
	TIME [epoch: 9.46 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.677173758427888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.677173758427888 | validation: 7.508415846155897]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.700089283125644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.700089283125644 | validation: 7.717036149035489]
	TIME [epoch: 9.47 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.742291372774457		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 6.742291372774457 | validation: 7.554841277988867]
	TIME [epoch: 9.46 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.87721905055744		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 6.87721905055744 | validation: 7.689408848084909]
	TIME [epoch: 9.46 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.792421015278295		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 6.792421015278295 | validation: 7.5333410369699845]
	TIME [epoch: 9.48 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.744260205697105		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 6.744260205697105 | validation: 7.6615456206347226]
	TIME [epoch: 9.47 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.721225263078821		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 6.721225263078821 | validation: 7.551592791282101]
	TIME [epoch: 9.46 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.71613940739461		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 6.71613940739461 | validation: 7.559398158101479]
	TIME [epoch: 9.48 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.707184366131294		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 6.707184366131294 | validation: 7.702037456523195]
	TIME [epoch: 9.47 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.766755564326386		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 6.766755564326386 | validation: 7.909250355815473]
	TIME [epoch: 9.46 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.887063492836786		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 6.887063492836786 | validation: 7.53598659689254]
	TIME [epoch: 9.46 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.65208741724383		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 6.65208741724383 | validation: 7.518984913359596]
	TIME [epoch: 9.48 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.701083298140565		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 6.701083298140565 | validation: 7.652149309008815]
	TIME [epoch: 9.46 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.711604240074301		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 6.711604240074301 | validation: 7.564460135127736]
	TIME [epoch: 9.47 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6937130045273845		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 6.6937130045273845 | validation: 7.514612144244958]
	TIME [epoch: 9.46 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.667791471680002		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 6.667791471680002 | validation: 7.5975391169314275]
	TIME [epoch: 9.49 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.69800771351089		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 6.69800771351089 | validation: 8.212054302351081]
	TIME [epoch: 9.46 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.960692275033563		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 6.960692275033563 | validation: 7.515629074844242]
	TIME [epoch: 9.46 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.667839643738799		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 6.667839643738799 | validation: 7.782558466104788]
	TIME [epoch: 9.46 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.757087763824335		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 6.757087763824335 | validation: 7.587364955248745]
	TIME [epoch: 9.49 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.679081821393725		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 6.679081821393725 | validation: 7.5069307143814745]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_69.pth
	Model improved!!!
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.724171339067434		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 6.724171339067434 | validation: 7.748082486003541]
	TIME [epoch: 9.47 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.781335828210574		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 6.781335828210574 | validation: 7.5391372399402306]
	TIME [epoch: 9.47 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.702622919389145		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 6.702622919389145 | validation: 7.491418107744222]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_72.pth
	Model improved!!!
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.620140380625109		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 6.620140380625109 | validation: 7.476022689710744]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_73.pth
	Model improved!!!
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.635855494571061		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 6.635855494571061 | validation: 7.488050781533609]
	TIME [epoch: 9.46 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.657004735007979		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 6.657004735007979 | validation: 7.59002516989616]
	TIME [epoch: 9.46 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.730239062162683		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 6.730239062162683 | validation: 7.487669268961968]
	TIME [epoch: 9.46 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.673217781288824		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 6.673217781288824 | validation: 7.480703798675541]
	TIME [epoch: 9.45 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.637220684211803		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 6.637220684211803 | validation: 7.5519888650877185]
	TIME [epoch: 9.45 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.712381612259904		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 6.712381612259904 | validation: 7.499166233601852]
	TIME [epoch: 9.48 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.7017629739137075		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 6.7017629739137075 | validation: 7.5004849780760035]
	TIME [epoch: 9.46 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.727517819925853		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 6.727517819925853 | validation: 7.49717753042501]
	TIME [epoch: 9.46 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6368891264639815		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 6.6368891264639815 | validation: 7.650235370153552]
	TIME [epoch: 9.45 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.690808329880743		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 6.690808329880743 | validation: 7.46618682713269]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_83.pth
	Model improved!!!
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.673775893080704		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 6.673775893080704 | validation: 7.486711530011421]
	TIME [epoch: 9.46 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6203195387819935		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 6.6203195387819935 | validation: 7.4438419855752045]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_85.pth
	Model improved!!!
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.64887748478437		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 6.64887748478437 | validation: 7.556324820108134]
	TIME [epoch: 9.45 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.711257447800452		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 6.711257447800452 | validation: 7.459341717420486]
	TIME [epoch: 9.48 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.746266570490979		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 6.746266570490979 | validation: 7.467430156922271]
	TIME [epoch: 9.45 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.607445227557648		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 6.607445227557648 | validation: 7.481878923784566]
	TIME [epoch: 9.45 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.640861660566569		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 6.640861660566569 | validation: 7.491464537957038]
	TIME [epoch: 9.45 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.692642025120437		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 6.692642025120437 | validation: 7.4927981164331925]
	TIME [epoch: 9.48 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.643698906200747		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 6.643698906200747 | validation: 7.49987185758991]
	TIME [epoch: 9.45 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.64885108423973		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 6.64885108423973 | validation: 7.540806655258966]
	TIME [epoch: 9.45 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.63587093875765		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 6.63587093875765 | validation: 7.4655437996869365]
	TIME [epoch: 9.47 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.680207348334524		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 6.680207348334524 | validation: 7.4800861127385305]
	TIME [epoch: 9.46 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.614617245751691		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 6.614617245751691 | validation: 7.443625435059326]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_96.pth
	Model improved!!!
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.605044247194994		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 6.605044247194994 | validation: 7.477030549697186]
	TIME [epoch: 9.46 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.575732488706751		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 6.575732488706751 | validation: 7.699032631805847]
	TIME [epoch: 9.48 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.608719678127601		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 6.608719678127601 | validation: 7.40087109545409]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_99.pth
	Model improved!!!
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.554263055393767		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 6.554263055393767 | validation: 7.431637489528034]
	TIME [epoch: 9.45 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.540659584704613		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 6.540659584704613 | validation: 7.61412460414389]
	TIME [epoch: 9.45 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.483163805668054		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 6.483163805668054 | validation: 7.203977193766045]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_102.pth
	Model improved!!!
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.247161865657164		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 6.247161865657164 | validation: 7.1777331428926265]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_103.pth
	Model improved!!!
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.154227108155107		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 6.154227108155107 | validation: 7.374439271979879]
	TIME [epoch: 9.45 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.280460323774062		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 6.280460323774062 | validation: 7.037994056013204]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_105.pth
	Model improved!!!
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.389582420308505		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 6.389582420308505 | validation: 7.047041434809121]
	TIME [epoch: 9.48 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.955063062886619		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 5.955063062886619 | validation: 7.398023096193562]
	TIME [epoch: 9.46 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.291414264203098		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 6.291414264203098 | validation: 7.082976886399798]
	TIME [epoch: 9.46 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.98263188972985		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 5.98263188972985 | validation: 7.427944668821549]
	TIME [epoch: 9.46 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.380628310335133		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 6.380628310335133 | validation: 7.09059045789024]
	TIME [epoch: 9.48 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.943129478176698		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 5.943129478176698 | validation: 6.7236485184816175]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_111.pth
	Model improved!!!
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.1454859644954025		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 6.1454859644954025 | validation: 6.738884226649831]
	TIME [epoch: 9.45 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.869748196990797		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 5.869748196990797 | validation: 7.0466852767148955]
	TIME [epoch: 9.47 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.009310904920819		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 7.009310904920819 | validation: 8.028354396777324]
	TIME [epoch: 9.47 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.661672849803333		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 6.661672849803333 | validation: 6.883265598440813]
	TIME [epoch: 9.45 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.8311550461542145		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 5.8311550461542145 | validation: 6.832562739082361]
	TIME [epoch: 9.45 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.025943469119559		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 6.025943469119559 | validation: 6.810865466632252]
	TIME [epoch: 9.48 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.3808057222506624		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 6.3808057222506624 | validation: 6.840614251374616]
	TIME [epoch: 9.46 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.275097924042034		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 6.275097924042034 | validation: 7.160550403520038]
	TIME [epoch: 9.45 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.664062524026521		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 6.664062524026521 | validation: 8.480859840202545]
	TIME [epoch: 9.45 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.029432522938866		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 7.029432522938866 | validation: 7.507402027710935]
	TIME [epoch: 9.47 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.538949699944679		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 6.538949699944679 | validation: 7.160981003462139]
	TIME [epoch: 9.45 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.617549621759738		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 6.617549621759738 | validation: 7.855769487989837]
	TIME [epoch: 9.45 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.730796410585745		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 6.730796410585745 | validation: 7.379244841816074]
	TIME [epoch: 9.45 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.440839213497168		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 6.440839213497168 | validation: 7.3473965017652985]
	TIME [epoch: 9.48 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.500078794154282		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 6.500078794154282 | validation: 7.0667434136633895]
	TIME [epoch: 9.45 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.5349958177115015		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 6.5349958177115015 | validation: 6.81057158839223]
	TIME [epoch: 9.45 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.169827268197993		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 6.169827268197993 | validation: 6.883923690449099]
	TIME [epoch: 9.45 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.354928796315166		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 6.354928796315166 | validation: 6.8985593838026285]
	TIME [epoch: 9.48 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.353088272702932		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 6.353088272702932 | validation: 7.209722705392501]
	TIME [epoch: 9.45 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.493188721078991		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 7.493188721078991 | validation: 8.554965432317331]
	TIME [epoch: 9.46 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.339402027288585		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 7.339402027288585 | validation: 7.670603860886399]
	TIME [epoch: 9.47 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.721009810593979		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 6.721009810593979 | validation: 7.387785413993143]
	TIME [epoch: 9.47 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.569583940968793		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 6.569583940968793 | validation: 7.302222205387306]
	TIME [epoch: 9.45 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.440909921554382		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 6.440909921554382 | validation: 7.2917381374116665]
	TIME [epoch: 9.45 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.510837322750871		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 6.510837322750871 | validation: 7.455343834021578]
	TIME [epoch: 9.47 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.705777252026936		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 6.705777252026936 | validation: 7.5582963891335115]
	TIME [epoch: 9.47 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.694621948833843		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 6.694621948833843 | validation: 7.552776532653493]
	TIME [epoch: 9.47 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.693371910252954		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 6.693371910252954 | validation: 7.546587346743008]
	TIME [epoch: 9.46 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.687755007990795		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 6.687755007990795 | validation: 7.566256150952096]
	TIME [epoch: 9.48 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6731799289469835		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 6.6731799289469835 | validation: 7.527507703342863]
	TIME [epoch: 9.46 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.691779880264177		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 6.691779880264177 | validation: 7.572716607156847]
	TIME [epoch: 9.46 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.672858337878753		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 6.672858337878753 | validation: 7.530132083804662]
	TIME [epoch: 9.45 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.648428729394413		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 6.648428729394413 | validation: 7.501280003310005]
	TIME [epoch: 9.48 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.658007232652397		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 6.658007232652397 | validation: 7.532278954126602]
	TIME [epoch: 9.46 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6433005671682634		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 6.6433005671682634 | validation: 7.484972004959761]
	TIME [epoch: 9.46 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6101148385572035		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 6.6101148385572035 | validation: 7.466943113800153]
	TIME [epoch: 9.46 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.555827246349774		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 6.555827246349774 | validation: 7.5984626249199385]
	TIME [epoch: 9.48 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.624502375426088		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 6.624502375426088 | validation: 7.493575132497748]
	TIME [epoch: 9.46 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.597932990441817		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 6.597932990441817 | validation: 7.415153296104815]
	TIME [epoch: 9.46 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.539433324605136		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 6.539433324605136 | validation: 7.489729668190261]
	TIME [epoch: 9.46 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.497363550574827		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 6.497363550574827 | validation: 7.174437111236628]
	TIME [epoch: 9.48 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.449719579014284		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 6.449719579014284 | validation: 7.251458899124491]
	TIME [epoch: 9.46 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.394496030220304		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 6.394496030220304 | validation: 6.489475288759826]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_154.pth
	Model improved!!!
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.835923556967068		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 5.835923556967068 | validation: 5.484511068611558]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_155.pth
	Model improved!!!
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.689691589799361		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 4.689691589799361 | validation: 3.9218034995414537]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_156.pth
	Model improved!!!
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.1604373829334		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 4.1604373829334 | validation: 3.741311801474392]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_157.pth
	Model improved!!!
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.937198759934932		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 3.937198759934932 | validation: 3.4233235560999646]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_158.pth
	Model improved!!!
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8588793532974095		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 3.8588793532974095 | validation: 3.141226940529204]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_159.pth
	Model improved!!!
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7307475121781417		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 3.7307475121781417 | validation: 3.3485954795491]
	TIME [epoch: 9.46 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.012266163037376		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 4.012266163037376 | validation: 3.2069501669496976]
	TIME [epoch: 9.45 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5392206393819285		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 3.5392206393819285 | validation: 3.0467943480398834]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_162.pth
	Model improved!!!
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.532934628638779		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 3.532934628638779 | validation: 2.986150353957163]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_163.pth
	Model improved!!!
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.461183833625352		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 3.461183833625352 | validation: 3.210018024428573]
	TIME [epoch: 9.46 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5182335563123077		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 3.5182335563123077 | validation: 2.9342414681230515]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_165.pth
	Model improved!!!
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4616529578450814		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 3.4616529578450814 | validation: 3.2164467866780058]
	TIME [epoch: 9.45 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.499180497539908		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 3.499180497539908 | validation: 3.149756574244052]
	TIME [epoch: 9.47 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5151846542172693		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 3.5151846542172693 | validation: 3.1361390879107605]
	TIME [epoch: 9.44 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6644798636408353		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 3.6644798636408353 | validation: 3.0300767581313495]
	TIME [epoch: 9.45 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5048084344937123		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 3.5048084344937123 | validation: 2.9822786631821523]
	TIME [epoch: 9.45 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5015332320481702		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 3.5015332320481702 | validation: 2.875928221840735]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_171.pth
	Model improved!!!
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5194761881510948		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 3.5194761881510948 | validation: 2.9297807059039123]
	TIME [epoch: 9.46 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.54911805215554		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 3.54911805215554 | validation: 3.2742588597430022]
	TIME [epoch: 9.46 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9194808533893357		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 3.9194808533893357 | validation: 3.299605319894918]
	TIME [epoch: 9.49 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5599788340536285		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 3.5599788340536285 | validation: 3.0984621420218157]
	TIME [epoch: 9.46 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.499088727423014		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 3.499088727423014 | validation: 2.9380835408333223]
	TIME [epoch: 9.46 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5395276538438396		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 3.5395276538438396 | validation: 2.871429423148236]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_177.pth
	Model improved!!!
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4392659858548384		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 3.4392659858548384 | validation: 2.9992314725454947]
	TIME [epoch: 9.49 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.595932435853162		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 3.595932435853162 | validation: 2.9577424577635933]
	TIME [epoch: 9.47 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.402808303231616		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 3.402808303231616 | validation: 3.031233902778895]
	TIME [epoch: 9.46 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.520227626481065		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 3.520227626481065 | validation: 2.930383078288983]
	TIME [epoch: 9.47 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4897411452846505		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 3.4897411452846505 | validation: 3.058409068005633]
	TIME [epoch: 9.49 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4940740743116883		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 3.4940740743116883 | validation: 2.967992569256264]
	TIME [epoch: 9.47 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4287007481490006		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 3.4287007481490006 | validation: 2.988861848775057]
	TIME [epoch: 9.47 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5150596510858554		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 3.5150596510858554 | validation: 2.9435381118534902]
	TIME [epoch: 9.47 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.512635006108141		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 3.512635006108141 | validation: 3.0881431164560618]
	TIME [epoch: 9.49 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.570273415778439		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 3.570273415778439 | validation: 2.9019177541761803]
	TIME [epoch: 9.47 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4330733283605275		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 3.4330733283605275 | validation: 2.9737183049255034]
	TIME [epoch: 9.47 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.801356535902884		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 3.801356535902884 | validation: 2.963866650045507]
	TIME [epoch: 9.48 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3995483525451995		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 3.3995483525451995 | validation: 3.3112299385366284]
	TIME [epoch: 9.48 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.431186747420616		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 3.431186747420616 | validation: 3.450726546164413]
	TIME [epoch: 9.46 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7174514417365914		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 3.7174514417365914 | validation: 2.8732674984004842]
	TIME [epoch: 9.46 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4876225972956134		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 3.4876225972956134 | validation: 2.911211382855206]
	TIME [epoch: 9.49 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4255743862784613		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 3.4255743862784613 | validation: 2.8866138282434735]
	TIME [epoch: 9.47 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.34822036579365		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 3.34822036579365 | validation: 2.9089684142760928]
	TIME [epoch: 9.46 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4553101816098652		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 3.4553101816098652 | validation: 2.860760838568174]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_196.pth
	Model improved!!!
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3760863415504714		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 3.3760863415504714 | validation: 3.0722861374898787]
	TIME [epoch: 9.49 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4537045916974654		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 3.4537045916974654 | validation: 2.969654324665685]
	TIME [epoch: 9.46 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3586067670937867		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 3.3586067670937867 | validation: 3.3287413948022198]
	TIME [epoch: 9.46 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.630943733166485		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 3.630943733166485 | validation: 3.509721796761155]
	TIME [epoch: 9.46 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.164203067577711		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 5.164203067577711 | validation: 6.08401065776873]
	TIME [epoch: 9.49 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.790013304148859		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 4.790013304148859 | validation: 3.416057572579185]
	TIME [epoch: 9.46 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.251564726318172		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 4.251564726318172 | validation: 4.72125753586449]
	TIME [epoch: 9.46 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.364682692373636		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 4.364682692373636 | validation: 3.52008745671407]
	TIME [epoch: 9.46 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.0038379018198595		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 5.0038379018198595 | validation: 3.9653877750913673]
	TIME [epoch: 9.49 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.020064255777615		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 4.020064255777615 | validation: 2.858787794530581]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_206.pth
	Model improved!!!
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4462667109669267		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 3.4462667109669267 | validation: 2.871083023331504]
	TIME [epoch: 9.46 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.288369916896742		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 3.288369916896742 | validation: 2.7614333827140345]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_208.pth
	Model improved!!!
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.209219249784187		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 3.209219249784187 | validation: 3.4470020520653315]
	TIME [epoch: 9.47 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.308701052803992		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 3.308701052803992 | validation: 2.8037153947246654]
	TIME [epoch: 9.46 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.58086528349639		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 3.58086528349639 | validation: 2.686642527832114]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_211.pth
	Model improved!!!
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.532308941035815		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 3.532308941035815 | validation: 2.8334827017512088]
	TIME [epoch: 9.49 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.305369337376915		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 3.305369337376915 | validation: 2.7181681476707995]
	TIME [epoch: 9.46 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8360947327966217		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 3.8360947327966217 | validation: 3.024422931261852]
	TIME [epoch: 9.47 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4400250621820425		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 3.4400250621820425 | validation: 2.773366033151671]
	TIME [epoch: 9.47 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2618978067606137		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 3.2618978067606137 | validation: 3.2259806055662215]
	TIME [epoch: 9.49 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2706573156747765		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 3.2706573156747765 | validation: 2.8691850259703897]
	TIME [epoch: 9.47 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1761407670569453		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 3.1761407670569453 | validation: 2.60486221187412]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_218.pth
	Model improved!!!
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2703983916830004		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 3.2703983916830004 | validation: 3.1931859398194646]
	TIME [epoch: 9.46 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2373913371514496		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 3.2373913371514496 | validation: 2.824934504514672]
	TIME [epoch: 9.49 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.107765097507502		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 3.107765097507502 | validation: 2.694350082354242]
	TIME [epoch: 9.46 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2818000211776495		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 3.2818000211776495 | validation: 2.603939479685847]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_222.pth
	Model improved!!!
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.087703501285897		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 3.087703501285897 | validation: 2.685007231148715]
	TIME [epoch: 9.46 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0836279650285134		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 3.0836279650285134 | validation: 2.5389642559303427]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_224.pth
	Model improved!!!
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.363520190657789		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 3.363520190657789 | validation: 3.144370544072576]
	TIME [epoch: 9.46 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.304960539274238		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 3.304960539274238 | validation: 2.5278808796377694]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_226.pth
	Model improved!!!
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0558419631962055		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 3.0558419631962055 | validation: 2.946880983523792]
	TIME [epoch: 9.47 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.279947449160556		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 3.279947449160556 | validation: 2.617707792511376]
	TIME [epoch: 9.46 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.100835260240882		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 3.100835260240882 | validation: 2.5741447055833886]
	TIME [epoch: 9.45 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2795342663782647		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 3.2795342663782647 | validation: 2.7621038849490023]
	TIME [epoch: 9.46 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.167960401256348		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 3.167960401256348 | validation: 3.0127405417314272]
	TIME [epoch: 9.48 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1668984464214427		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 3.1668984464214427 | validation: 2.5402709117780953]
	TIME [epoch: 9.46 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0476580570665393		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 3.0476580570665393 | validation: 2.532939476265575]
	TIME [epoch: 9.45 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2723047542948698		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 3.2723047542948698 | validation: 2.5904037865103]
	TIME [epoch: 9.45 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1780415210160604		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 3.1780415210160604 | validation: 2.5013061079074936]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_235.pth
	Model improved!!!
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1686961308558614		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 3.1686961308558614 | validation: 2.4837891203571365]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_236.pth
	Model improved!!!
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0686741617784006		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 3.0686741617784006 | validation: 2.546517847462248]
	TIME [epoch: 9.46 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.593342941688789		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 3.593342941688789 | validation: 4.823450356885644]
	TIME [epoch: 9.45 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.343578067224006		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 4.343578067224006 | validation: 3.6828110518372377]
	TIME [epoch: 9.47 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.951658730070347		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 3.951658730070347 | validation: 3.6521753650390663]
	TIME [epoch: 9.46 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8843543480758163		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 3.8843543480758163 | validation: 3.8469387313007872]
	TIME [epoch: 9.45 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.787572118450376		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 3.787572118450376 | validation: 3.0732011030075195]
	TIME [epoch: 9.46 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.245479269829322		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 3.245479269829322 | validation: 2.710389478710681]
	TIME [epoch: 9.47 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1028472955241186		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 3.1028472955241186 | validation: 2.79314025943814]
	TIME [epoch: 9.45 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0551793830899086		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 3.0551793830899086 | validation: 3.2044534800911366]
	TIME [epoch: 9.45 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.382079352324183		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 3.382079352324183 | validation: 2.8231141091564744]
	TIME [epoch: 9.46 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.190053065953461		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 3.190053065953461 | validation: 2.8615778968132437]
	TIME [epoch: 9.46 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2127326641858893		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 3.2127326641858893 | validation: 2.7751387840979285]
	TIME [epoch: 9.45 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2465696781468836		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 3.2465696781468836 | validation: 2.8904422134987615]
	TIME [epoch: 9.45 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2246415916660545		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 3.2246415916660545 | validation: 3.267667605325345]
	TIME [epoch: 9.48 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.24093938342385		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 3.24093938342385 | validation: 2.6978084498433628]
	TIME [epoch: 9.45 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.193521077850252		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 3.193521077850252 | validation: 2.828834666737713]
	TIME [epoch: 9.45 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1515962454404365		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 3.1515962454404365 | validation: 3.0322549365473415]
	TIME [epoch: 9.45 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.220449244402721		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 3.220449244402721 | validation: 2.7575687652753653]
	TIME [epoch: 9.47 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1894809005565725		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 3.1894809005565725 | validation: 2.919990503792933]
	TIME [epoch: 9.45 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2279470841971176		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 3.2279470841971176 | validation: 2.731426868112869]
	TIME [epoch: 9.45 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2628030062810587		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 3.2628030062810587 | validation: 2.829534210722199]
	TIME [epoch: 9.45 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.160920891737825		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 3.160920891737825 | validation: 3.362239140661437]
	TIME [epoch: 9.48 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.405704211428916		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 3.405704211428916 | validation: 2.7208529142653743]
	TIME [epoch: 9.45 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5076204144549585		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 3.5076204144549585 | validation: 3.1438131775251055]
	TIME [epoch: 9.45 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.28247770510731		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 3.28247770510731 | validation: 3.213174444002046]
	TIME [epoch: 9.46 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.290194406931647		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 3.290194406931647 | validation: 2.606897316025575]
	TIME [epoch: 9.47 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0936285708642215		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 3.0936285708642215 | validation: 2.725842619409545]
	TIME [epoch: 9.45 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0153018390287873		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 3.0153018390287873 | validation: 2.643998661666938]
	TIME [epoch: 9.46 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.29494827261299		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 3.29494827261299 | validation: 3.8617599519482275]
	TIME [epoch: 9.46 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4717228670283276		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 3.4717228670283276 | validation: 2.6615930428539105]
	TIME [epoch: 9.46 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.163609140461604		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 3.163609140461604 | validation: 2.597290535981496]
	TIME [epoch: 9.45 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3225502556586632		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 3.3225502556586632 | validation: 2.6235503628755588]
	TIME [epoch: 9.46 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.121275650997603		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 3.121275650997603 | validation: 2.857960734107867]
	TIME [epoch: 9.48 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1593732923359945		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 3.1593732923359945 | validation: 2.5865324490701975]
	TIME [epoch: 9.46 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.088738292271682		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 3.088738292271682 | validation: 3.3513132551066502]
	TIME [epoch: 9.45 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1337724726171965		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 3.1337724726171965 | validation: 2.479745615309603]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_272.pth
	Model improved!!!
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.928658133464474		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 2.928658133464474 | validation: 2.5991449227059276]
	TIME [epoch: 9.47 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1179557082178193		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 3.1179557082178193 | validation: 2.8403011197996775]
	TIME [epoch: 9.45 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.145872860631013		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 3.145872860631013 | validation: 2.8062820806938675]
	TIME [epoch: 9.45 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0217669043739432		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 3.0217669043739432 | validation: 2.449631653329228]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_276.pth
	Model improved!!!
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8551486423159544		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 2.8551486423159544 | validation: 2.7869249428295753]
	TIME [epoch: 9.47 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0711890983250263		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 3.0711890983250263 | validation: 2.622655787464648]
	TIME [epoch: 9.46 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0646712331025676		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 3.0646712331025676 | validation: 2.3423962881313587]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_279.pth
	Model improved!!!
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9668777273448503		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 2.9668777273448503 | validation: 2.6209707525630415]
	TIME [epoch: 9.45 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9634454489178017		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 2.9634454489178017 | validation: 2.473740613209613]
	TIME [epoch: 9.48 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.065842754115161		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 3.065842754115161 | validation: 2.957624605898894]
	TIME [epoch: 9.45 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9966112626858687		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 2.9966112626858687 | validation: 2.5484013909717986]
	TIME [epoch: 9.45 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.919951978752372		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 2.919951978752372 | validation: 2.829476431291047]
	TIME [epoch: 9.46 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.019543514158153		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 3.019543514158153 | validation: 2.514694491090842]
	TIME [epoch: 9.46 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.896494106797778		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 2.896494106797778 | validation: 2.79994237006349]
	TIME [epoch: 9.46 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.914031265796535		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 2.914031265796535 | validation: 2.4953026989500153]
	TIME [epoch: 9.45 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.936928280045695		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 2.936928280045695 | validation: 2.612830465538089]
	TIME [epoch: 9.47 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.884820508926358		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 2.884820508926358 | validation: 2.299185110602125]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_289.pth
	Model improved!!!
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8275254090368014		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 2.8275254090368014 | validation: 3.2600488849220417]
	TIME [epoch: 9.45 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3277187817360927		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 3.3277187817360927 | validation: 2.5607209208581376]
	TIME [epoch: 9.45 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.151783469958995		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 3.151783469958995 | validation: 3.0413376235746354]
	TIME [epoch: 9.47 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.028125567256976		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 3.028125567256976 | validation: 2.1359890527292325]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_293.pth
	Model improved!!!
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6577353024973616		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 2.6577353024973616 | validation: 2.3907174486172313]
	TIME [epoch: 9.46 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7245890121726086		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 2.7245890121726086 | validation: 2.125145751956217]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_295.pth
	Model improved!!!
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.829590280815532		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 2.829590280815532 | validation: 2.2550681042081338]
	TIME [epoch: 9.48 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.784869974724705		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 2.784869974724705 | validation: 2.4510358635357825]
	TIME [epoch: 9.45 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7751637690759736		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 2.7751637690759736 | validation: 2.2652038030023816]
	TIME [epoch: 9.45 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0753053702799726		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 3.0753053702799726 | validation: 2.607293913093895]
	TIME [epoch: 9.45 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0034191223785807		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 3.0034191223785807 | validation: 2.382703444730809]
	TIME [epoch: 9.47 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.745825801286607		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 2.745825801286607 | validation: 2.385616206078078]
	TIME [epoch: 9.45 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.84953610608447		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 2.84953610608447 | validation: 2.4027200525688874]
	TIME [epoch: 9.45 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.908078004777795		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 2.908078004777795 | validation: 2.5394751403935794]
	TIME [epoch: 9.46 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.893313810631117		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 2.893313810631117 | validation: 2.8967563913957695]
	TIME [epoch: 9.46 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.942477566523523		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 2.942477566523523 | validation: 2.4535944983805487]
	TIME [epoch: 9.45 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7198520265182076		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 2.7198520265182076 | validation: 2.3709857425172576]
	TIME [epoch: 9.45 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6550891136707047		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 2.6550891136707047 | validation: 2.515198378580151]
	TIME [epoch: 9.46 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.22910798621961		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 3.22910798621961 | validation: 3.2948820154263565]
	TIME [epoch: 9.46 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.249033771802612		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 3.249033771802612 | validation: 2.49044734631314]
	TIME [epoch: 9.45 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7234987661500267		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 2.7234987661500267 | validation: 2.341360883745616]
	TIME [epoch: 9.45 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7012597106081677		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 2.7012597106081677 | validation: 2.380662627580288]
	TIME [epoch: 9.47 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7397109934697497		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 2.7397109934697497 | validation: 2.3641454320852646]
	TIME [epoch: 9.45 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.771120205565068		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 2.771120205565068 | validation: 2.6186004249588404]
	TIME [epoch: 9.45 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.701097921775636		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 2.701097921775636 | validation: 2.2974857943697873]
	TIME [epoch: 9.44 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6953940572952377		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 2.6953940572952377 | validation: 2.6315739767717474]
	TIME [epoch: 9.47 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8692493770364154		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 2.8692493770364154 | validation: 2.2928866466297975]
	TIME [epoch: 9.45 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.815873931651197		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 2.815873931651197 | validation: 2.4390675752018556]
	TIME [epoch: 9.45 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.797304304631311		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 2.797304304631311 | validation: 2.2778340909119796]
	TIME [epoch: 9.45 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.786618729955412		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 2.786618729955412 | validation: 2.516441514679388]
	TIME [epoch: 9.47 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5884728060697912		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 2.5884728060697912 | validation: 2.412404355683386]
	TIME [epoch: 9.45 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.577700936958225		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 2.577700936958225 | validation: 2.334417693224883]
	TIME [epoch: 9.45 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.659473717044867		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 2.659473717044867 | validation: 2.590892262090897]
	TIME [epoch: 9.45 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7060264664380873		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 2.7060264664380873 | validation: 2.738341353336469]
	TIME [epoch: 9.47 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8338225574878178		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 2.8338225574878178 | validation: 2.418002239738308]
	TIME [epoch: 9.45 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5520946641188704		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 2.5520946641188704 | validation: 2.2155209102033617]
	TIME [epoch: 9.45 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5973346627091525		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 2.5973346627091525 | validation: 2.7027767487115173]
	TIME [epoch: 9.46 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9280007453618397		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 2.9280007453618397 | validation: 2.342715992114575]
	TIME [epoch: 9.46 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.767076320425296		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 2.767076320425296 | validation: 2.3463887742892973]
	TIME [epoch: 9.45 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6621271184849573		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 2.6621271184849573 | validation: 2.558579800840272]
	TIME [epoch: 9.45 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.521545964035543		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 2.521545964035543 | validation: 2.0626843368011265]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_330.pth
	Model improved!!!
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.280836281020575		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 2.280836281020575 | validation: 2.2401963154355613]
	TIME [epoch: 9.46 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4050911957651655		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 2.4050911957651655 | validation: 1.7717222083001845]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_332.pth
	Model improved!!!
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5046785869874433		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 2.5046785869874433 | validation: 2.2270285297160455]
	TIME [epoch: 9.45 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5731171522082277		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 2.5731171522082277 | validation: 2.103653792047905]
	TIME [epoch: 9.47 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.74768992606105		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 2.74768992606105 | validation: 2.5175924154877105]
	TIME [epoch: 9.46 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.842461101473093		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 2.842461101473093 | validation: 2.2177730536690583]
	TIME [epoch: 9.45 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.504210741060637		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 2.504210741060637 | validation: 2.151998504305321]
	TIME [epoch: 9.45 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8604103449920903		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 2.8604103449920903 | validation: 2.1424361688465137]
	TIME [epoch: 9.48 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5870957343891328		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 2.5870957343891328 | validation: 2.239919883470838]
	TIME [epoch: 9.45 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5863139239146324		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 2.5863139239146324 | validation: 1.9793444111373735]
	TIME [epoch: 9.45 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.377269104106555		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 2.377269104106555 | validation: 1.8358017281271901]
	TIME [epoch: 9.45 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.326657179043351		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 2.326657179043351 | validation: 1.8136437920895827]
	TIME [epoch: 9.48 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2883266500985053		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 2.2883266500985053 | validation: 1.8264678866605]
	TIME [epoch: 9.45 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2649295051274323		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 2.2649295051274323 | validation: 1.7755475554420284]
	TIME [epoch: 9.45 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2121746688122874		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 2.2121746688122874 | validation: 2.0020106967779703]
	TIME [epoch: 9.46 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.388171254238773		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 2.388171254238773 | validation: 2.3866464987286653]
	TIME [epoch: 9.47 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.47081142817766		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 2.47081142817766 | validation: 2.0938471631567683]
	TIME [epoch: 9.45 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2567245823023327		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 2.2567245823023327 | validation: 2.121146758076419]
	TIME [epoch: 9.45 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.340605993163877		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 2.340605993163877 | validation: 1.8725256754315462]
	TIME [epoch: 9.47 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3230425063827167		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 2.3230425063827167 | validation: 2.0322482119687817]
	TIME [epoch: 9.46 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1888600272836434		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 2.1888600272836434 | validation: 1.9890382071049972]
	TIME [epoch: 9.45 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1877594393696116		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 2.1877594393696116 | validation: 1.7202906143962102]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_352.pth
	Model improved!!!
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.168900418494562		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 2.168900418494562 | validation: 1.8424770659621146]
	TIME [epoch: 9.47 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.094543294245507		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 2.094543294245507 | validation: 1.86261656919725]
	TIME [epoch: 9.46 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3232330094399076		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 2.3232330094399076 | validation: 1.994188153153247]
	TIME [epoch: 9.45 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.27136002805795		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 2.27136002805795 | validation: 1.7796770994762063]
	TIME [epoch: 9.45 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0615739168314464		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 2.0615739168314464 | validation: 1.8207885140177726]
	TIME [epoch: 9.47 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1163844123073754		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 2.1163844123073754 | validation: 1.882668505063211]
	TIME [epoch: 9.45 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0834291925046315		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 2.0834291925046315 | validation: 1.7766527977080973]
	TIME [epoch: 9.46 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0638567989192103		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 2.0638567989192103 | validation: 2.2430460288343737]
	TIME [epoch: 9.46 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2345486721935357		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 2.2345486721935357 | validation: 1.7186368765831117]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_361.pth
	Model improved!!!
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0128110723573607		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 2.0128110723573607 | validation: 1.8937666636082162]
	TIME [epoch: 9.45 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0810916992151984		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 2.0810916992151984 | validation: 1.8073826377835227]
	TIME [epoch: 9.45 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3539118309591593		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 2.3539118309591593 | validation: 1.9544039079896265]
	TIME [epoch: 9.45 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.436898293238044		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 2.436898293238044 | validation: 1.9699819100713925]
	TIME [epoch: 9.47 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2587551171080174		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 2.2587551171080174 | validation: 2.0341782844672904]
	TIME [epoch: 9.45 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1844742157163877		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 2.1844742157163877 | validation: 1.7356832804846785]
	TIME [epoch: 9.45 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1139369567224016		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 2.1139369567224016 | validation: 1.7585582863985614]
	TIME [epoch: 9.46 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.039824149063416		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 2.039824149063416 | validation: 1.8074689921138865]
	TIME [epoch: 9.46 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9927785982568829		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 1.9927785982568829 | validation: 1.6427996304796448]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_370.pth
	Model improved!!!
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.012580919446102		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 2.012580919446102 | validation: 1.605284512842112]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_371.pth
	Model improved!!!
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0323791944815914		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 2.0323791944815914 | validation: 1.7014540857713865]
	TIME [epoch: 9.47 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.041993267748454		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 2.041993267748454 | validation: 1.7687828986500318]
	TIME [epoch: 9.46 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9333622561867607		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 1.9333622561867607 | validation: 1.7115267307713373]
	TIME [epoch: 9.45 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1197082983836184		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 2.1197082983836184 | validation: 1.633926912597609]
	TIME [epoch: 9.45 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2310067671099514		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 2.2310067671099514 | validation: 1.6851946796926964]
	TIME [epoch: 9.47 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9847941854443145		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 1.9847941854443145 | validation: 1.7820869836664792]
	TIME [epoch: 9.44 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9236846358307773		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 1.9236846358307773 | validation: 1.7533583902279215]
	TIME [epoch: 9.45 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9621742337040957		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 1.9621742337040957 | validation: 1.5603252365810047]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_379.pth
	Model improved!!!
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9241381144137903		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 1.9241381144137903 | validation: 1.8273104484840326]
	TIME [epoch: 9.47 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8591227549895837		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 1.8591227549895837 | validation: 1.645487495469579]
	TIME [epoch: 9.45 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.060790931413341		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 2.060790931413341 | validation: 1.7095854763147476]
	TIME [epoch: 9.45 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9754070343286312		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 1.9754070343286312 | validation: 1.5729295878000142]
	TIME [epoch: 9.45 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9154379370175878		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 1.9154379370175878 | validation: 1.586840943815073]
	TIME [epoch: 9.47 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.804649977407174		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 1.804649977407174 | validation: 1.5504360253526586]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_385.pth
	Model improved!!!
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.868969489464709		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 1.868969489464709 | validation: 1.6625088792240978]
	TIME [epoch: 9.45 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8097500721773396		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 1.8097500721773396 | validation: 1.9144571373673227]
	TIME [epoch: 9.46 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9496462381234572		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 1.9496462381234572 | validation: 1.6972128532054216]
	TIME [epoch: 9.47 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8383058063814155		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 1.8383058063814155 | validation: 1.676230529466173]
	TIME [epoch: 9.45 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8567333315826644		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 1.8567333315826644 | validation: 1.845090268022529]
	TIME [epoch: 9.44 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8492579072111794		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 1.8492579072111794 | validation: 1.8261322976711893]
	TIME [epoch: 9.47 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8650922359181077		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 1.8650922359181077 | validation: 1.5369356262329934]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_392.pth
	Model improved!!!
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.744715330532486		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 1.744715330532486 | validation: 1.6280410299042567]
	TIME [epoch: 9.46 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7724259383847092		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 1.7724259383847092 | validation: 1.624299311867561]
	TIME [epoch: 9.46 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8775245992102483		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 1.8775245992102483 | validation: 1.747109271592122]
	TIME [epoch: 9.49 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7294363804384063		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 1.7294363804384063 | validation: 1.6153056760369526]
	TIME [epoch: 9.46 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.868514216367041		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 1.868514216367041 | validation: 1.6674998401512307]
	TIME [epoch: 9.46 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.736013798177476		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 1.736013798177476 | validation: 1.8002056066729066]
	TIME [epoch: 9.47 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7275642441954424		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 1.7275642441954424 | validation: 1.4981242098782346]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_399.pth
	Model improved!!!
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.827737741097255		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 1.827737741097255 | validation: 1.5845110158007571]
	TIME [epoch: 9.47 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7872097896015422		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 1.7872097896015422 | validation: 1.5976469882441882]
	TIME [epoch: 9.47 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8278741917516883		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 1.8278741917516883 | validation: 1.542813732178332]
	TIME [epoch: 9.48 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.719644484603296		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 1.719644484603296 | validation: 1.5235280516472613]
	TIME [epoch: 9.48 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.92432650623794		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 1.92432650623794 | validation: 1.546531918746171]
	TIME [epoch: 9.46 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8005948892484167		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 1.8005948892484167 | validation: 1.4873792051471997]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_405.pth
	Model improved!!!
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7318738386631254		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 1.7318738386631254 | validation: 1.5814668104093983]
	TIME [epoch: 9.49 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7510261439374097		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 1.7510261439374097 | validation: 1.7028241242815803]
	TIME [epoch: 9.47 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8471186938329738		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 1.8471186938329738 | validation: 1.4364527117409522]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_408.pth
	Model improved!!!
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7364327857517938		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 1.7364327857517938 | validation: 1.5190739989496045]
	TIME [epoch: 9.46 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7451118544425626		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 1.7451118544425626 | validation: 1.4495949379506337]
	TIME [epoch: 9.49 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6744218459801878		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 1.6744218459801878 | validation: 1.515937871452323]
	TIME [epoch: 9.47 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6653964524451859		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 1.6653964524451859 | validation: 1.5387393758781347]
	TIME [epoch: 9.46 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7202558719458252		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 1.7202558719458252 | validation: 1.5417142200417835]
	TIME [epoch: 9.46 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6807548107293535		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 1.6807548107293535 | validation: 1.6531634153158934]
	TIME [epoch: 9.5 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7465946620529607		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 1.7465946620529607 | validation: 1.7971764459274908]
	TIME [epoch: 9.47 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7343877060580986		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 1.7343877060580986 | validation: 1.6186073629555962]
	TIME [epoch: 9.47 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6510498574546042		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 1.6510498574546042 | validation: 1.4454808453683672]
	TIME [epoch: 9.47 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.686822694927266		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 1.686822694927266 | validation: 1.4941270431213496]
	TIME [epoch: 9.49 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6868053720744325		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 1.6868053720744325 | validation: 1.5195539805422615]
	TIME [epoch: 9.47 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6948518439931983		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 1.6948518439931983 | validation: 1.4688971584950878]
	TIME [epoch: 9.47 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6861278291284436		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 1.6861278291284436 | validation: 1.428651714612352]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_421.pth
	Model improved!!!
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6281628853060006		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 1.6281628853060006 | validation: 1.6010261717767094]
	TIME [epoch: 9.48 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6171862281071534		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 1.6171862281071534 | validation: 1.5560382459493196]
	TIME [epoch: 9.47 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7325439517842613		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 1.7325439517842613 | validation: 1.4398199715458961]
	TIME [epoch: 9.47 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.689863050390226		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 1.689863050390226 | validation: 1.5843439200335943]
	TIME [epoch: 9.49 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.680634302877786		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 1.680634302877786 | validation: 1.5646119184402247]
	TIME [epoch: 9.47 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.674047244196284		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 1.674047244196284 | validation: 1.4602150434839638]
	TIME [epoch: 9.47 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5754413191618808		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 1.5754413191618808 | validation: 1.4801522952993167]
	TIME [epoch: 9.47 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5955508575695387		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 1.5955508575695387 | validation: 1.5055164627507578]
	TIME [epoch: 9.49 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5453810593607158		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 1.5453810593607158 | validation: 1.4828900471280002]
	TIME [epoch: 9.47 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5654162004951095		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 1.5654162004951095 | validation: 1.380241726375906]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_431.pth
	Model improved!!!
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5721552771002631		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 1.5721552771002631 | validation: 1.4798989024328852]
	TIME [epoch: 9.47 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7022495229931145		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 1.7022495229931145 | validation: 1.535546915425836]
	TIME [epoch: 9.5 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.540436286282706		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 1.540436286282706 | validation: 1.585955565775619]
	TIME [epoch: 9.48 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.649262542959138		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 1.649262542959138 | validation: 1.473693252206439]
	TIME [epoch: 9.48 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5635056078890819		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 1.5635056078890819 | validation: 1.4733574828721925]
	TIME [epoch: 9.47 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5672475806045694		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 1.5672475806045694 | validation: 1.3063373758610743]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_437.pth
	Model improved!!!
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5339441584838824		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 1.5339441584838824 | validation: 1.296033200806647]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_438.pth
	Model improved!!!
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.540547818688698		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 1.540547818688698 | validation: 1.347321091526593]
	TIME [epoch: 9.46 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5887135444902256		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 1.5887135444902256 | validation: 1.4802927081715427]
	TIME [epoch: 9.47 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.507176072282363		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 1.507176072282363 | validation: 1.36218180358133]
	TIME [epoch: 9.47 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4452887417867004		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 1.4452887417867004 | validation: 1.4037902110046576]
	TIME [epoch: 9.46 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4869055318076554		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 1.4869055318076554 | validation: 1.4606287432946763]
	TIME [epoch: 9.46 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4591043072636463		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 1.4591043072636463 | validation: 1.3916888346773835]
	TIME [epoch: 9.48 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.451217727902693		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 1.451217727902693 | validation: 1.2574264278646035]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_445.pth
	Model improved!!!
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6729521850709026		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 1.6729521850709026 | validation: 1.525303358214381]
	TIME [epoch: 9.47 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5620432137558207		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 1.5620432137558207 | validation: 1.3070402497285019]
	TIME [epoch: 9.46 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.525036888843593		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 1.525036888843593 | validation: 1.3115371475200543]
	TIME [epoch: 9.48 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4404980692407805		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 1.4404980692407805 | validation: 1.4231111808632728]
	TIME [epoch: 9.47 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.421757456348017		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 1.421757456348017 | validation: 1.3401352726583247]
	TIME [epoch: 9.46 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.478184878645761		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 1.478184878645761 | validation: 1.6460491916651063]
	TIME [epoch: 9.46 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5573319009951263		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 1.5573319009951263 | validation: 1.3110094619656054]
	TIME [epoch: 9.49 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.490718052415463		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 1.490718052415463 | validation: 1.371217244880026]
	TIME [epoch: 9.46 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5547103327958784		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 1.5547103327958784 | validation: 1.373738063476112]
	TIME [epoch: 9.45 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3777042463734455		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 1.3777042463734455 | validation: 1.553826066164727]
	TIME [epoch: 9.46 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.714450405210122		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 1.714450405210122 | validation: 1.484259387034518]
	TIME [epoch: 9.48 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5029074213812499		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 1.5029074213812499 | validation: 1.4140031484782534]
	TIME [epoch: 9.46 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.440882201862668		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 1.440882201862668 | validation: 1.4807726416137672]
	TIME [epoch: 9.46 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4969698961604672		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 1.4969698961604672 | validation: 1.31130538990524]
	TIME [epoch: 9.47 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4921687470887839		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 1.4921687470887839 | validation: 1.3940429831673173]
	TIME [epoch: 9.46 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.546928650546575		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 1.546928650546575 | validation: 1.5535822725760293]
	TIME [epoch: 9.46 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7596228984714402		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 1.7596228984714402 | validation: 1.2839798089821424]
	TIME [epoch: 9.45 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4260112965484848		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 1.4260112965484848 | validation: 1.3825070397896912]
	TIME [epoch: 9.47 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3761012407536883		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 1.3761012407536883 | validation: 1.2971402434791417]
	TIME [epoch: 9.46 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3894943225185126		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 1.3894943225185126 | validation: 1.3766809517853145]
	TIME [epoch: 9.46 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4057658058636489		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 1.4057658058636489 | validation: 1.2712766725763902]
	TIME [epoch: 9.46 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.501783277129884		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 1.501783277129884 | validation: 1.3982820760395749]
	TIME [epoch: 9.48 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4169629480054895		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 1.4169629480054895 | validation: 1.2214856176590354]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_468.pth
	Model improved!!!
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4521758445679631		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 1.4521758445679631 | validation: 1.4408126164470298]
	TIME [epoch: 9.45 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6030182613087525		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 1.6030182613087525 | validation: 1.3679636081662465]
	TIME [epoch: 9.45 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4502133503822523		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 1.4502133503822523 | validation: 1.2815120611555455]
	TIME [epoch: 9.47 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3868066720184595		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 1.3868066720184595 | validation: 1.4078440553931753]
	TIME [epoch: 9.46 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4505094914846839		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 1.4505094914846839 | validation: 1.2687429206887901]
	TIME [epoch: 9.45 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4781161835076215		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 1.4781161835076215 | validation: 1.4139690589884077]
	TIME [epoch: 9.45 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4499223885526615		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 1.4499223885526615 | validation: 1.6083748446486863]
	TIME [epoch: 9.48 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3574335929533514		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 1.3574335929533514 | validation: 1.4222725858560654]
	TIME [epoch: 9.45 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.342535909449371		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 1.342535909449371 | validation: 1.3606122521593562]
	TIME [epoch: 9.45 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4140183515106621		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 1.4140183515106621 | validation: 1.5190730816802727]
	TIME [epoch: 9.45 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6483390602312498		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 1.6483390602312498 | validation: 1.6075871045163082]
	TIME [epoch: 9.47 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4161512066524062		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 1.4161512066524062 | validation: 1.2535477427872441]
	TIME [epoch: 9.45 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6714147924120462		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 1.6714147924120462 | validation: 1.9666258434343815]
	TIME [epoch: 9.45 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6102014709886252		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 1.6102014709886252 | validation: 1.2566502205588455]
	TIME [epoch: 9.47 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4619955981931176		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 1.4619955981931176 | validation: 1.5923394612514596]
	TIME [epoch: 9.47 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.479293300655669		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 1.479293300655669 | validation: 1.3185884334765519]
	TIME [epoch: 9.45 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3915067668503498		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 1.3915067668503498 | validation: 1.5306534678545867]
	TIME [epoch: 9.46 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3819664648975079		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 1.3819664648975079 | validation: 1.3319835769227435]
	TIME [epoch: 9.47 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3516495082230024		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 1.3516495082230024 | validation: 1.5333905113101463]
	TIME [epoch: 9.46 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3909640102777596		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 1.3909640102777596 | validation: 1.260162116986444]
	TIME [epoch: 9.45 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.344835387681136		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 1.344835387681136 | validation: 1.3912939401385003]
	TIME [epoch: 9.45 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4800486674392446		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 1.4800486674392446 | validation: 1.4012153897068007]
	TIME [epoch: 9.47 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.595148299230114		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 1.595148299230114 | validation: 1.4667868054253868]
	TIME [epoch: 9.45 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4818707506897622		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 1.4818707506897622 | validation: 1.2743583306373656]
	TIME [epoch: 9.45 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4185063754488747		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 1.4185063754488747 | validation: 1.6271043918350685]
	TIME [epoch: 9.45 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4280670098789705		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 1.4280670098789705 | validation: 1.23265012830798]
	TIME [epoch: 9.48 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.444160576699344		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 1.444160576699344 | validation: 1.2514586633324798]
	TIME [epoch: 9.45 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4223919344050049		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 1.4223919344050049 | validation: 1.3449362992688847]
	TIME [epoch: 9.46 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4159266487107924		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 1.4159266487107924 | validation: 1.390196516527334]
	TIME [epoch: 9.45 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4658216808364106		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 1.4658216808364106 | validation: 1.269533648295965]
	TIME [epoch: 9.48 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3051125826581298		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 1.3051125826581298 | validation: 1.2579290679289858]
	TIME [epoch: 9.45 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3210432633312057		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 1.3210432633312057 | validation: 1.3821433846084892]
	TIME [epoch: 9.45 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4112544173635293		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 1.4112544173635293 | validation: 1.21670555503259]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_501.pth
	Model improved!!!
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3835974869902827		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 1.3835974869902827 | validation: 1.2801169584179177]
	TIME [epoch: 9.46 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.423439171252773		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 1.423439171252773 | validation: 1.4281425576192641]
	TIME [epoch: 9.45 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3050434815880687		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 1.3050434815880687 | validation: 1.299008607550937]
	TIME [epoch: 9.45 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3144334460205003		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 1.3144334460205003 | validation: 1.546748232654025]
	TIME [epoch: 9.47 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.456685960275301		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 1.456685960275301 | validation: 1.219492905466676]
	TIME [epoch: 9.45 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3153500238225988		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 1.3153500238225988 | validation: 1.5334838184927284]
	TIME [epoch: 9.44 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4408189263322664		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 1.4408189263322664 | validation: 1.1841741839746374]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_508.pth
	Model improved!!!
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3606722867544523		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 1.3606722867544523 | validation: 1.2167562441616968]
	TIME [epoch: 9.47 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3145096072596156		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 1.3145096072596156 | validation: 1.4738114069690857]
	TIME [epoch: 9.45 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3151728077891165		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 1.3151728077891165 | validation: 1.273969053692606]
	TIME [epoch: 9.45 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.348710424670107		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 1.348710424670107 | validation: 1.2885519324673975]
	TIME [epoch: 9.45 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2701543854621367		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 1.2701543854621367 | validation: 1.6574178442673242]
	TIME [epoch: 9.47 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.447210823307874		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 1.447210823307874 | validation: 1.244230138391121]
	TIME [epoch: 9.45 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4265765469013567		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 1.4265765469013567 | validation: 1.2376972595573368]
	TIME [epoch: 9.45 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2738137447623463		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 1.2738137447623463 | validation: 1.4628202343536887]
	TIME [epoch: 9.45 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4341601789732723		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 1.4341601789732723 | validation: 1.2502214923061044]
	TIME [epoch: 9.47 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3530147596303046		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 1.3530147596303046 | validation: 1.4256835650966133]
	TIME [epoch: 9.45 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.401847492963626		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 1.401847492963626 | validation: 1.2631069766631409]
	TIME [epoch: 9.45 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.320455854884624		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 1.320455854884624 | validation: 1.1631662078595255]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_520.pth
	Model improved!!!
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3947378444221425		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 1.3947378444221425 | validation: 1.262309165837944]
	TIME [epoch: 9.47 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3761713251033665		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 1.3761713251033665 | validation: 1.14776492390803]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_522.pth
	Model improved!!!
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2811133241212542		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 1.2811133241212542 | validation: 1.511571663494357]
	TIME [epoch: 9.45 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3435731083590423		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 1.3435731083590423 | validation: 1.3931826383518142]
	TIME [epoch: 9.47 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4095553808667411		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 1.4095553808667411 | validation: 1.3267582476304416]
	TIME [epoch: 9.45 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2933440448406952		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 1.2933440448406952 | validation: 1.351887577553916]
	TIME [epoch: 9.45 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4037471466762843		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 1.4037471466762843 | validation: 1.283953903773781]
	TIME [epoch: 9.45 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3321176936621029		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 1.3321176936621029 | validation: 1.276958197165612]
	TIME [epoch: 9.48 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3127420894004096		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 1.3127420894004096 | validation: 1.2797863305556516]
	TIME [epoch: 9.46 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.325565347621211		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 1.325565347621211 | validation: 1.380955607550555]
	TIME [epoch: 9.45 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2622895462562713		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 1.2622895462562713 | validation: 1.2756342155622875]
	TIME [epoch: 9.45 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2601886058629987		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 1.2601886058629987 | validation: 1.6369790690976442]
	TIME [epoch: 9.47 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4003801824045554		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 1.4003801824045554 | validation: 1.2018657359898315]
	TIME [epoch: 9.45 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3177636175948764		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 1.3177636175948764 | validation: 1.2674985650377992]
	TIME [epoch: 9.45 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3766753192241659		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 1.3766753192241659 | validation: 1.1949842750702806]
	TIME [epoch: 9.45 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3053767164961887		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 1.3053767164961887 | validation: 1.325107791154092]
	TIME [epoch: 9.47 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3520826269025628		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 1.3520826269025628 | validation: 1.1374016493661663]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_537.pth
	Model improved!!!
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.252302214794247		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 1.252302214794247 | validation: 1.2171772018901676]
	TIME [epoch: 9.46 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4270964068287264		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 1.4270964068287264 | validation: 1.3501829588928194]
	TIME [epoch: 9.46 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2663121820091923		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 1.2663121820091923 | validation: 1.4064305102262569]
	TIME [epoch: 9.47 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3244498254533656		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 1.3244498254533656 | validation: 1.3759678300999827]
	TIME [epoch: 9.45 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2632339603821592		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 1.2632339603821592 | validation: 1.3343266777206801]
	TIME [epoch: 9.45 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3899672011607132		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 1.3899672011607132 | validation: 1.2178494481942619]
	TIME [epoch: 9.46 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3824964587622037		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 1.3824964587622037 | validation: 1.3493651325906553]
	TIME [epoch: 9.46 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3484891870419564		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 1.3484891870419564 | validation: 1.1910289783171788]
	TIME [epoch: 9.45 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.337903917896209		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 1.337903917896209 | validation: 1.2811039074558819]
	TIME [epoch: 9.45 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2674540742716758		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 1.2674540742716758 | validation: 1.2098688660134025]
	TIME [epoch: 9.47 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.207739952704491		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 1.207739952704491 | validation: 1.2862815752464258]
	TIME [epoch: 9.45 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.282644585894182		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 1.282644585894182 | validation: 1.1466358052823398]
	TIME [epoch: 9.45 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.292639408603985		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 1.292639408603985 | validation: 1.2239697186970087]
	TIME [epoch: 9.45 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3627279934222616		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 1.3627279934222616 | validation: 1.3031034118372389]
	TIME [epoch: 9.47 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1942422605695093		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 1.1942422605695093 | validation: 1.5632285459891575]
	TIME [epoch: 9.45 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3474216517280677		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 1.3474216517280677 | validation: 1.0782458478378159]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_553.pth
	Model improved!!!
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2146621605338368		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 1.2146621605338368 | validation: 1.1264482178961885]
	TIME [epoch: 9.45 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2532621322095014		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 1.2532621322095014 | validation: 1.0904818398496148]
	TIME [epoch: 9.47 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3089856562803086		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 1.3089856562803086 | validation: 1.465037496719919]
	TIME [epoch: 9.46 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2521739998143075		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 1.2521739998143075 | validation: 1.2068170634909325]
	TIME [epoch: 9.45 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2174177435610016		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 1.2174177435610016 | validation: 1.130555002791014]
	TIME [epoch: 9.46 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2982794091779275		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 1.2982794091779275 | validation: 1.4364462512812577]
	TIME [epoch: 9.48 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3449969413799854		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 1.3449969413799854 | validation: 1.1908545961637642]
	TIME [epoch: 9.45 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2336754564878896		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 1.2336754564878896 | validation: 1.1571031928325797]
	TIME [epoch: 9.46 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2195347140356287		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 1.2195347140356287 | validation: 1.2043119206498276]
	TIME [epoch: 9.46 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2077065616998148		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 1.2077065616998148 | validation: 1.2882683804842907]
	TIME [epoch: 9.46 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.323503787636421		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 1.323503787636421 | validation: 1.147293766003342]
	TIME [epoch: 9.46 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2458865936229868		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 1.2458865936229868 | validation: 1.330838856828711]
	TIME [epoch: 9.45 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1945857865375966		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 1.1945857865375966 | validation: 1.126743024416328]
	TIME [epoch: 9.47 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1747503794203675		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 1.1747503794203675 | validation: 1.158089599860981]
	TIME [epoch: 9.45 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.24330836724889		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 1.24330836724889 | validation: 1.2542817978470568]
	TIME [epoch: 9.44 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.247224595005977		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 1.247224595005977 | validation: 1.129684314557018]
	TIME [epoch: 9.45 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2909061812086737		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 1.2909061812086737 | validation: 1.2289149767022656]
	TIME [epoch: 9.47 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1900363074780516		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 1.1900363074780516 | validation: 1.3412449558072348]
	TIME [epoch: 9.46 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2964229054307639		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 1.2964229054307639 | validation: 1.0706100638620837]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_572.pth
	Model improved!!!
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2025976553629412		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 1.2025976553629412 | validation: 1.1069554448218264]
	TIME [epoch: 9.46 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1754930965536965		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 1.1754930965536965 | validation: 1.1749006904845543]
	TIME [epoch: 9.47 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2349342088129192		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 1.2349342088129192 | validation: 1.0715839701932957]
	TIME [epoch: 9.45 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.22823758248437		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 1.22823758248437 | validation: 1.0882906666559495]
	TIME [epoch: 9.44 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2127553166725338		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 1.2127553166725338 | validation: 1.2670469839207992]
	TIME [epoch: 9.45 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2235996857701317		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 1.2235996857701317 | validation: 1.132036843117897]
	TIME [epoch: 9.47 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1579054071692472		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 1.1579054071692472 | validation: 1.4892012881294734]
	TIME [epoch: 9.45 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3141650174307349		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 1.3141650174307349 | validation: 1.1253211153642835]
	TIME [epoch: 9.45 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.218947511958358		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 1.218947511958358 | validation: 1.1242128059766923]
	TIME [epoch: 9.46 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1774509303002412		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 1.1774509303002412 | validation: 1.2777992969712744]
	TIME [epoch: 9.46 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1820109566060708		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 1.1820109566060708 | validation: 1.1529788161718142]
	TIME [epoch: 9.45 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2347646629323177		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 1.2347646629323177 | validation: 1.1200516633889466]
	TIME [epoch: 9.45 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.182631007834652		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 1.182631007834652 | validation: 1.068610302760012]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_585.pth
	Model improved!!!
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1314671687914843		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 1.1314671687914843 | validation: 1.377808807298377]
	TIME [epoch: 9.47 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2742130570655126		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 1.2742130570655126 | validation: 1.1517224868473444]
	TIME [epoch: 9.46 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1666514964190828		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 1.1666514964190828 | validation: 1.0820997831059487]
	TIME [epoch: 9.45 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1203554288238962		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 1.1203554288238962 | validation: 1.127602508749031]
	TIME [epoch: 9.47 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.103906812216222		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 1.103906812216222 | validation: 1.1299987151716415]
	TIME [epoch: 9.45 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2169031524399863		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 1.2169031524399863 | validation: 1.0902989057748023]
	TIME [epoch: 9.45 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2987159595166191		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 1.2987159595166191 | validation: 1.1736977074395227]
	TIME [epoch: 9.44 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1841413597749006		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 1.1841413597749006 | validation: 1.1837556398395028]
	TIME [epoch: 9.47 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2003145450742743		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 1.2003145450742743 | validation: 1.18303200508602]
	TIME [epoch: 9.46 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1536228004373899		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 1.1536228004373899 | validation: 1.3651053350219684]
	TIME [epoch: 9.45 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2219826404837808		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 1.2219826404837808 | validation: 1.2886282287095554]
	TIME [epoch: 9.45 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1818318848946332		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 1.1818318848946332 | validation: 1.1115638329557007]
	TIME [epoch: 9.47 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.153470383933986		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 1.153470383933986 | validation: 1.2227128317893934]
	TIME [epoch: 9.45 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2432999710175332		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 1.2432999710175332 | validation: 1.3073362229259433]
	TIME [epoch: 9.44 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1884074137965452		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 1.1884074137965452 | validation: 1.173115954153791]
	TIME [epoch: 9.46 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1532168592869414		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 1.1532168592869414 | validation: 1.1652998726605197]
	TIME [epoch: 9.47 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1403973534915288		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 1.1403973534915288 | validation: 1.1464010134608946]
	TIME [epoch: 9.45 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2353658138471482		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 1.2353658138471482 | validation: 1.110099250610193]
	TIME [epoch: 9.45 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.166732139500732		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 1.166732139500732 | validation: 1.1624709357072234]
	TIME [epoch: 9.46 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1570524035433039		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 1.1570524035433039 | validation: 1.1627249077430584]
	TIME [epoch: 9.46 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1462482328572936		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 1.1462482328572936 | validation: 1.0873036987437275]
	TIME [epoch: 9.45 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2479400615650484		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 1.2479400615650484 | validation: 1.111113460522407]
	TIME [epoch: 9.45 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1839080918100944		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 1.1839080918100944 | validation: 1.3288416502080498]
	TIME [epoch: 9.47 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.174867446480104		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 1.174867446480104 | validation: 1.0655022556601967]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_609.pth
	Model improved!!!
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0928247483333153		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 1.0928247483333153 | validation: 1.1166093908207548]
	TIME [epoch: 9.44 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2346737749605983		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 1.2346737749605983 | validation: 1.1652970584474676]
	TIME [epoch: 9.45 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.13901521932753		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 1.13901521932753 | validation: 1.2283952225474186]
	TIME [epoch: 9.47 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2193875208784308		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 1.2193875208784308 | validation: 1.177270750374303]
	TIME [epoch: 9.45 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1164567644183663		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 1.1164567644183663 | validation: 1.0464254528850239]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_614.pth
	Model improved!!!
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0988380926911394		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 1.0988380926911394 | validation: 1.1942571734859697]
	TIME [epoch: 9.44 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.165918151363177		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 1.165918151363177 | validation: 1.0698399159677496]
	TIME [epoch: 9.47 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0800220474551827		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 1.0800220474551827 | validation: 1.2020735445419823]
	TIME [epoch: 9.45 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.115684975678484		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 1.115684975678484 | validation: 1.0141281827989632]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_618.pth
	Model improved!!!
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0954295205698275		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 1.0954295205698275 | validation: 1.0397586533795875]
	TIME [epoch: 9.45 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0833056367207177		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 1.0833056367207177 | validation: 1.0582073710974802]
	TIME [epoch: 9.47 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0888553971897088		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 1.0888553971897088 | validation: 1.096214743060902]
	TIME [epoch: 9.44 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1039610965325408		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 1.1039610965325408 | validation: 1.0351974972954074]
	TIME [epoch: 9.44 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1732919831329096		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 1.1732919831329096 | validation: 1.1712656515147888]
	TIME [epoch: 9.46 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1332554280571387		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 1.1332554280571387 | validation: 1.082381497908709]
	TIME [epoch: 9.46 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1108885260015298		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 1.1108885260015298 | validation: 1.0343645719878922]
	TIME [epoch: 9.45 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.081959079385709		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 1.081959079385709 | validation: 1.128424452790074]
	TIME [epoch: 9.44 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.096940104302318		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 1.096940104302318 | validation: 1.1332596649084747]
	TIME [epoch: 9.46 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1332961310164635		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 1.1332961310164635 | validation: 1.06234887828948]
	TIME [epoch: 9.45 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.049624157884231		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 1.049624157884231 | validation: 1.1830626711871082]
	TIME [epoch: 9.45 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1254228072288361		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 1.1254228072288361 | validation: 1.2880961885541649]
	TIME [epoch: 9.44 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1019325432273601		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 1.1019325432273601 | validation: 1.1679942909785759]
	TIME [epoch: 9.47 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0753845056076483		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 1.0753845056076483 | validation: 1.1648345102017457]
	TIME [epoch: 9.45 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0639127380079156		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 1.0639127380079156 | validation: 1.0411109583888385]
	TIME [epoch: 9.44 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1861571534679896		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 1.1861571534679896 | validation: 1.1708879834809343]
	TIME [epoch: 9.45 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0863457326756478		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 1.0863457326756478 | validation: 0.9963151741393327]
	TIME [epoch: 9.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_635.pth
	Model improved!!!
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0194685935592667		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 1.0194685935592667 | validation: 1.279647410869869]
	TIME [epoch: 9.45 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1385665340642994		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 1.1385665340642994 | validation: 1.0226483222097715]
	TIME [epoch: 9.45 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0195952901222005		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 1.0195952901222005 | validation: 1.2141998017418005]
	TIME [epoch: 9.44 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1007168415098325		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 1.1007168415098325 | validation: 1.078723254228732]
	TIME [epoch: 9.47 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0365541326146368		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 1.0365541326146368 | validation: 1.055605066666459]
	TIME [epoch: 9.45 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0445342227401535		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 1.0445342227401535 | validation: 1.0593408210424333]
	TIME [epoch: 9.45 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0115776728871206		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 1.0115776728871206 | validation: 1.057023189833186]
	TIME [epoch: 9.46 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0027257062525121		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 1.0027257062525121 | validation: 1.0280685056527294]
	TIME [epoch: 9.46 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0250639547220755		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 1.0250639547220755 | validation: 1.0415979316580894]
	TIME [epoch: 9.45 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0689042819975711		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 1.0689042819975711 | validation: 1.3217862842488382]
	TIME [epoch: 9.44 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0814574727442288		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 1.0814574727442288 | validation: 1.0339533874503635]
	TIME [epoch: 9.47 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0978902708202158		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 1.0978902708202158 | validation: 1.1732626583675478]
	TIME [epoch: 9.45 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0700998397301746		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 1.0700998397301746 | validation: 1.0665604591059017]
	TIME [epoch: 9.44 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.031517548348264		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 1.031517548348264 | validation: 0.9565248433069763]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_649.pth
	Model improved!!!
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.038095366292807		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 1.038095366292807 | validation: 0.9210568354389542]
	TIME [epoch: 9.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_650.pth
	Model improved!!!
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.017689190286634		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 1.017689190286634 | validation: 0.9536002908612244]
	TIME [epoch: 9.46 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0309596755025117		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 1.0309596755025117 | validation: 1.0214211009157017]
	TIME [epoch: 9.45 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0133667697241289		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 1.0133667697241289 | validation: 1.071380290563977]
	TIME [epoch: 9.45 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0178472957893354		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 1.0178472957893354 | validation: 0.983284686612966]
	TIME [epoch: 9.47 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0193959534054418		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 1.0193959534054418 | validation: 1.0805114831435865]
	TIME [epoch: 9.45 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0400422306603987		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 1.0400422306603987 | validation: 1.015030246736678]
	TIME [epoch: 9.45 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9833420844121441		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 0.9833420844121441 | validation: 1.2224493887603394]
	TIME [epoch: 9.44 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0516221394728298		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 1.0516221394728298 | validation: 0.9913802086732907]
	TIME [epoch: 9.47 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9605861499546521		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 0.9605861499546521 | validation: 0.8868877905141274]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_659.pth
	Model improved!!!
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9862483337038721		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 0.9862483337038721 | validation: 0.9083196313789778]
	TIME [epoch: 9.45 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9872637852488015		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 0.9872637852488015 | validation: 1.0139344627283209]
	TIME [epoch: 9.46 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0047338291190744		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 1.0047338291190744 | validation: 1.0926538042457048]
	TIME [epoch: 9.45 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0989632017527438		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 1.0989632017527438 | validation: 0.9873504862751042]
	TIME [epoch: 9.45 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9824042105371047		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 0.9824042105371047 | validation: 1.0384249473725935]
	TIME [epoch: 9.45 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9990953459733684		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 0.9990953459733684 | validation: 1.192553386962094]
	TIME [epoch: 9.47 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1140217526198621		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 1.1140217526198621 | validation: 1.0731294824704594]
	TIME [epoch: 9.44 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9952172162172875		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 0.9952172162172875 | validation: 0.9393308247132859]
	TIME [epoch: 9.44 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9713746969585138		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 0.9713746969585138 | validation: 0.9336079178890185]
	TIME [epoch: 9.45 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0338407795290074		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 1.0338407795290074 | validation: 1.0387346602148646]
	TIME [epoch: 9.46 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.950786968903459		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 0.950786968903459 | validation: 0.8878374026554482]
	TIME [epoch: 9.44 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.034916318756023		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 1.034916318756023 | validation: 0.9939538470646434]
	TIME [epoch: 9.44 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0035147821973425		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 1.0035147821973425 | validation: 1.0335247638751501]
	TIME [epoch: 9.44 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.008988994383003		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 1.008988994383003 | validation: 0.9247537775579787]
	TIME [epoch: 9.46 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0017171264091584		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 1.0017171264091584 | validation: 0.8939774156592553]
	TIME [epoch: 9.45 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9789359422225663		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 0.9789359422225663 | validation: 1.073011868956451]
	TIME [epoch: 9.44 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1166433891433296		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 1.1166433891433296 | validation: 1.131869358774997]
	TIME [epoch: 9.45 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9349639826602971		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 0.9349639826602971 | validation: 1.0477185827644069]
	TIME [epoch: 9.47 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9855915810724772		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 0.9855915810724772 | validation: 0.9708849722545481]
	TIME [epoch: 9.44 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9687157236572244		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 0.9687157236572244 | validation: 0.9153016254762147]
	TIME [epoch: 9.44 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8980603022604277		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 0.8980603022604277 | validation: 0.9705372839086907]
	TIME [epoch: 9.45 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9315946526417405		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.9315946526417405 | validation: 1.0788293978893198]
	TIME [epoch: 9.46 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9732608913544704		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 0.9732608913544704 | validation: 0.9486919187483039]
	TIME [epoch: 9.44 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9453372790701394		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 0.9453372790701394 | validation: 0.8918071441323329]
	TIME [epoch: 9.45 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9398009305604693		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 0.9398009305604693 | validation: 0.979483490416058]
	TIME [epoch: 9.45 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9406712952968406		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 0.9406712952968406 | validation: 0.8934721315197066]
	TIME [epoch: 9.46 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.953062815879625		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 0.953062815879625 | validation: 1.426736579294932]
	TIME [epoch: 9.44 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.157860282328645		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 1.157860282328645 | validation: 0.9386528698106852]
	TIME [epoch: 9.44 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9625074934554801		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 0.9625074934554801 | validation: 1.063458015587641]
	TIME [epoch: 9.46 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9586249420750736		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 0.9586249420750736 | validation: 0.9307007361420868]
	TIME [epoch: 9.46 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9822371542039295		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 0.9822371542039295 | validation: 0.8905107557935591]
	TIME [epoch: 9.45 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8785539698067877		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 0.8785539698067877 | validation: 0.9536323239894714]
	TIME [epoch: 9.45 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9312650592368863		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 0.9312650592368863 | validation: 1.0492231248284585]
	TIME [epoch: 9.46 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9550288169528937		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 0.9550288169528937 | validation: 0.9310585155334983]
	TIME [epoch: 9.45 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9145226661525229		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 0.9145226661525229 | validation: 1.022402737300144]
	TIME [epoch: 9.45 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9469649384065517		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 0.9469649384065517 | validation: 1.0193244357103972]
	TIME [epoch: 9.44 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0306107705509528		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 1.0306107705509528 | validation: 0.9860317305248414]
	TIME [epoch: 9.46 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9539671114927362		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 0.9539671114927362 | validation: 0.9681210867918768]
	TIME [epoch: 9.45 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0033478465297334		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 1.0033478465297334 | validation: 0.9729866238047938]
	TIME [epoch: 9.44 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9458745300656496		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 0.9458745300656496 | validation: 1.4134971366280302]
	TIME [epoch: 9.44 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1919095099502444		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 1.1919095099502444 | validation: 0.9615008082650752]
	TIME [epoch: 9.47 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9828543398335668		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 0.9828543398335668 | validation: 0.9105617869378216]
	TIME [epoch: 9.45 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9103381152914259		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 0.9103381152914259 | validation: 1.03901274164396]
	TIME [epoch: 9.44 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0036077459097044		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 1.0036077459097044 | validation: 0.9516411950933644]
	TIME [epoch: 9.45 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9593578762286594		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 0.9593578762286594 | validation: 1.0379175061836239]
	TIME [epoch: 9.47 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9557590082636978		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 0.9557590082636978 | validation: 0.897717514220192]
	TIME [epoch: 9.44 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9539160185776809		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 0.9539160185776809 | validation: 0.9168394690884211]
	TIME [epoch: 9.44 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9417570310469545		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 0.9417570310469545 | validation: 0.8384798629120863]
	TIME [epoch: 9.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_707.pth
	Model improved!!!
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.889886369632214		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 0.889886369632214 | validation: 0.9616882174852677]
	TIME [epoch: 9.47 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8669937634563472		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 0.8669937634563472 | validation: 1.152512756568016]
	TIME [epoch: 9.46 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0360986249556592		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 1.0360986249556592 | validation: 0.9143204866114186]
	TIME [epoch: 9.46 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9033072365156366		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 0.9033072365156366 | validation: 0.8919538408679316]
	TIME [epoch: 9.48 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8943218602208182		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 0.8943218602208182 | validation: 0.8560864511038228]
	TIME [epoch: 9.46 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9911138594473664		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 0.9911138594473664 | validation: 0.9478520884537468]
	TIME [epoch: 9.46 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9193170708514007		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 0.9193170708514007 | validation: 0.9763213637281365]
	TIME [epoch: 9.46 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9536738403566554		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 0.9536738403566554 | validation: 0.97220962240592]
	TIME [epoch: 9.48 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9195362983997073		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 0.9195362983997073 | validation: 0.9976632143979092]
	TIME [epoch: 9.46 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0473907622111605		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 1.0473907622111605 | validation: 1.1682045763929798]
	TIME [epoch: 9.46 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9799063342687895		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 0.9799063342687895 | validation: 0.8498857801772138]
	TIME [epoch: 9.46 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.916153837229807		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.916153837229807 | validation: 0.9518381725638255]
	TIME [epoch: 9.48 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8870902527456836		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 0.8870902527456836 | validation: 0.9519648588460726]
	TIME [epoch: 9.46 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.921984907968967		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 0.921984907968967 | validation: 0.8886199317558761]
	TIME [epoch: 9.46 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9128329143039485		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 0.9128329143039485 | validation: 0.8915715207955413]
	TIME [epoch: 9.47 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9297543859440266		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 0.9297543859440266 | validation: 0.9381289064419758]
	TIME [epoch: 9.47 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8875174051737934		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 0.8875174051737934 | validation: 0.9391186826411511]
	TIME [epoch: 9.46 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9172697881560614		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 0.9172697881560614 | validation: 0.9123752719088395]
	TIME [epoch: 9.46 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0501271906717289		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 1.0501271906717289 | validation: 0.8464164697571976]
	TIME [epoch: 9.47 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8899386262929421		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 0.8899386262929421 | validation: 0.8757289427267559]
	TIME [epoch: 9.47 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9105015338242033		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 0.9105015338242033 | validation: 0.7923208506379635]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_728.pth
	Model improved!!!
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9605798689794461		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 0.9605798689794461 | validation: 0.9135772329723898]
	TIME [epoch: 9.45 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9126741412432271		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 0.9126741412432271 | validation: 0.9588693379527112]
	TIME [epoch: 9.48 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8699414153935823		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 0.8699414153935823 | validation: 0.893988731327052]
	TIME [epoch: 9.46 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.893190241540274		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 0.893190241540274 | validation: 0.8244743346995301]
	TIME [epoch: 9.45 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9017470467311212		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 0.9017470467311212 | validation: 0.9234318890007214]
	TIME [epoch: 9.46 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.961579236092672		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 0.961579236092672 | validation: 0.897539942527803]
	TIME [epoch: 9.48 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8414915215594612		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 0.8414915215594612 | validation: 1.0143555066021253]
	TIME [epoch: 9.46 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.936024448758436		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 0.936024448758436 | validation: 0.858194031935004]
	TIME [epoch: 9.46 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8615832188046066		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 0.8615832188046066 | validation: 0.8498556953515981]
	TIME [epoch: 9.45 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8822892088643259		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.8822892088643259 | validation: 0.9264247171811744]
	TIME [epoch: 9.48 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9274560674949232		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 0.9274560674949232 | validation: 0.8605095227113322]
	TIME [epoch: 9.46 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9340031072008719		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 0.9340031072008719 | validation: 0.9123087014270186]
	TIME [epoch: 9.45 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8832936417877086		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 0.8832936417877086 | validation: 0.9002091278886263]
	TIME [epoch: 9.46 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8740667380720831		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 0.8740667380720831 | validation: 0.9009807149657694]
	TIME [epoch: 9.48 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9398450766856339		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 0.9398450766856339 | validation: 0.9852801634523038]
	TIME [epoch: 9.45 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9670027185017338		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 0.9670027185017338 | validation: 1.200910328914526]
	TIME [epoch: 9.46 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0473569989733331		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 1.0473569989733331 | validation: 1.019859161906569]
	TIME [epoch: 9.47 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8994355154593409		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 0.8994355154593409 | validation: 0.9602170142053956]
	TIME [epoch: 9.47 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8852236122466086		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 0.8852236122466086 | validation: 1.0283044949997189]
	TIME [epoch: 9.46 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9152723931812788		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 0.9152723931812788 | validation: 0.8538118755927357]
	TIME [epoch: 9.45 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8909911724030195		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 0.8909911724030195 | validation: 0.805151650333202]
	TIME [epoch: 9.48 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9243239753558881		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 0.9243239753558881 | validation: 0.9632581873777415]
	TIME [epoch: 9.46 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.901234659511646		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 0.901234659511646 | validation: 0.798584453928047]
	TIME [epoch: 9.46 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.865214091381364		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 0.865214091381364 | validation: 0.9085445564147068]
	TIME [epoch: 9.46 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8949997797606818		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 0.8949997797606818 | validation: 0.8481638609489619]
	TIME [epoch: 9.48 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9140922160432592		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 0.9140922160432592 | validation: 0.9363757743096465]
	TIME [epoch: 9.46 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9478596567275541		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 0.9478596567275541 | validation: 0.8672946980797274]
	TIME [epoch: 9.45 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8738423701585614		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 0.8738423701585614 | validation: 0.8061359978435164]
	TIME [epoch: 9.46 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9298481033097357		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.9298481033097357 | validation: 0.9214393454460436]
	TIME [epoch: 9.48 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8817200490865114		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 0.8817200490865114 | validation: 0.9247474481221838]
	TIME [epoch: 9.46 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8642192219313942		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 0.8642192219313942 | validation: 0.9372654044400983]
	TIME [epoch: 9.46 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8690813263582768		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 0.8690813263582768 | validation: 0.9211152200924021]
	TIME [epoch: 9.46 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8596113038963145		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 0.8596113038963145 | validation: 0.8862248832265763]
	TIME [epoch: 9.48 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8693438073763		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 0.8693438073763 | validation: 0.8561086351260139]
	TIME [epoch: 9.46 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.902132747187802		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 0.902132747187802 | validation: 0.9478921200445264]
	TIME [epoch: 9.46 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8711778902428826		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 0.8711778902428826 | validation: 0.8354218949062756]
	TIME [epoch: 9.47 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.850838224556135		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 0.850838224556135 | validation: 0.9409020125504995]
	TIME [epoch: 9.47 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8739136088186165		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 0.8739136088186165 | validation: 0.9916659152091023]
	TIME [epoch: 9.46 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8977174229112954		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 0.8977174229112954 | validation: 0.7912517073412605]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_767.pth
	Model improved!!!
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.950016627912915		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 0.950016627912915 | validation: 1.2756234839648901]
	TIME [epoch: 9.48 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0294113864615482		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 1.0294113864615482 | validation: 0.9152091201942895]
	TIME [epoch: 9.46 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8805836429497773		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 0.8805836429497773 | validation: 0.7849705469211612]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_770.pth
	Model improved!!!
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.836733805482391		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 0.836733805482391 | validation: 0.7937689916522402]
	TIME [epoch: 9.45 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.867669398591912		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 0.867669398591912 | validation: 0.9250113506724493]
	TIME [epoch: 9.47 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8714236635932275		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 0.8714236635932275 | validation: 0.8339589915908266]
	TIME [epoch: 9.45 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8805294930403882		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 0.8805294930403882 | validation: 0.8550588651128157]
	TIME [epoch: 9.45 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8461048837211413		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 0.8461048837211413 | validation: 1.0007256303964107]
	TIME [epoch: 9.45 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.912129178653316		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.912129178653316 | validation: 0.8957766276754094]
	TIME [epoch: 9.48 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8995923154278092		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 0.8995923154278092 | validation: 1.0289146743902224]
	TIME [epoch: 9.45 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9159573018225358		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 0.9159573018225358 | validation: 0.8521151922689549]
	TIME [epoch: 9.49 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8874408098277773		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 0.8874408098277773 | validation: 0.8142888516483109]
	TIME [epoch: 9.48 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8786650325849695		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 0.8786650325849695 | validation: 0.8966075678118454]
	TIME [epoch: 9.49 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8378829220207475		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 0.8378829220207475 | validation: 0.8774734167711375]
	TIME [epoch: 9.47 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8497322216379409		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 0.8497322216379409 | validation: 0.7893038122083469]
	TIME [epoch: 9.47 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.914219360911958		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 0.914219360911958 | validation: 0.8304681742749361]
	TIME [epoch: 9.48 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8472280809701068		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 0.8472280809701068 | validation: 0.854457001742327]
	TIME [epoch: 9.48 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.852496450208678		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 0.852496450208678 | validation: 0.89951350751762]
	TIME [epoch: 9.47 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8617071515965176		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 0.8617071515965176 | validation: 0.8215642493956204]
	TIME [epoch: 9.47 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8322883688385211		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 0.8322883688385211 | validation: 0.8278566158817473]
	TIME [epoch: 9.48 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8213850793465879		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 0.8213850793465879 | validation: 0.8187949308021917]
	TIME [epoch: 9.47 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8460374158693984		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 0.8460374158693984 | validation: 0.7989004270100389]
	TIME [epoch: 9.46 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8627393527165849		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 0.8627393527165849 | validation: 0.9691757042954063]
	TIME [epoch: 9.46 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9156388171827163		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 0.9156388171827163 | validation: 0.8390651656119711]
	TIME [epoch: 9.48 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8283928112520851		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 0.8283928112520851 | validation: 0.8317011196084652]
	TIME [epoch: 9.46 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8706335923122601		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 0.8706335923122601 | validation: 0.8847954952155495]
	TIME [epoch: 9.46 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8547519071077725		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 0.8547519071077725 | validation: 0.9022334470885522]
	TIME [epoch: 9.45 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8280003669624791		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.8280003669624791 | validation: 0.8311599480733887]
	TIME [epoch: 9.48 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8252126258363551		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 0.8252126258363551 | validation: 0.8883889168708007]
	TIME [epoch: 9.47 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8714244539243033		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 0.8714244539243033 | validation: 0.9291713084127303]
	TIME [epoch: 9.46 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8614031652593791		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 0.8614031652593791 | validation: 0.8827335252059624]
	TIME [epoch: 9.45 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.821219614425517		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 0.821219614425517 | validation: 0.8400450613637321]
	TIME [epoch: 9.48 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8550804947540971		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 0.8550804947540971 | validation: 0.8614067186326532]
	TIME [epoch: 9.45 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8793996694492241		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 0.8793996694492241 | validation: 0.8047360716670393]
	TIME [epoch: 9.46 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8336291970531768		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 0.8336291970531768 | validation: 0.8437166498369988]
	TIME [epoch: 9.46 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8752655173466511		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 0.8752655173466511 | validation: 0.8805482477649034]
	TIME [epoch: 9.48 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8952378393221725		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 0.8952378393221725 | validation: 0.8192339690147502]
	TIME [epoch: 9.46 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8339476172786469		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 0.8339476172786469 | validation: 0.9154143781566836]
	TIME [epoch: 9.46 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8637896744932971		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 0.8637896744932971 | validation: 0.8581445525825051]
	TIME [epoch: 9.47 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.852986788947009		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 0.852986788947009 | validation: 0.8287670478213387]
	TIME [epoch: 9.47 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8930100978901081		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 0.8930100978901081 | validation: 0.8526841033349635]
	TIME [epoch: 9.46 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8473467157374266		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 0.8473467157374266 | validation: 0.8344822029926822]
	TIME [epoch: 9.45 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8726537538514523		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 0.8726537538514523 | validation: 0.849135740684845]
	TIME [epoch: 9.48 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8403910129397394		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 0.8403910129397394 | validation: 0.8025520563909013]
	TIME [epoch: 9.46 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8470046227808423		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 0.8470046227808423 | validation: 0.8579435105686193]
	TIME [epoch: 9.46 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8547200700012054		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 0.8547200700012054 | validation: 0.8825433213754715]
	TIME [epoch: 9.46 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8561291237165285		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.8561291237165285 | validation: 0.8543206897744265]
	TIME [epoch: 9.48 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.879111348196879		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 0.879111348196879 | validation: 0.8582554083968867]
	TIME [epoch: 9.46 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.844660782147902		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 0.844660782147902 | validation: 0.9987344013367837]
	TIME [epoch: 9.46 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8516407691032797		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 0.8516407691032797 | validation: 1.181967576855068]
	TIME [epoch: 9.45 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9565917692299519		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 0.9565917692299519 | validation: 0.8654633437179841]
	TIME [epoch: 9.48 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8432702064172227		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 0.8432702064172227 | validation: 0.8661241622305383]
	TIME [epoch: 9.46 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8459419917187174		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 0.8459419917187174 | validation: 0.7642783153629003]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_820.pth
	Model improved!!!
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8513727329493455		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 0.8513727329493455 | validation: 0.8969071710894064]
	TIME [epoch: 9.46 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8561441372194288		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 0.8561441372194288 | validation: 0.9260097188181052]
	TIME [epoch: 9.48 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9201780788196432		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 0.9201780788196432 | validation: 0.8132059895939469]
	TIME [epoch: 9.46 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8227468311666319		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 0.8227468311666319 | validation: 0.8265790107688009]
	TIME [epoch: 9.46 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8477264982083218		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 0.8477264982083218 | validation: 0.8848360251339975]
	TIME [epoch: 9.47 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8585951509955191		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 0.8585951509955191 | validation: 0.7653411621896309]
	TIME [epoch: 9.47 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8377314583693399		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 0.8377314583693399 | validation: 0.8436013288367806]
	TIME [epoch: 9.46 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8509619545498646		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 0.8509619545498646 | validation: 0.8569845626807245]
	TIME [epoch: 9.46 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8421656334993017		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 0.8421656334993017 | validation: 0.8192685218142977]
	TIME [epoch: 9.48 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8193212324589252		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 0.8193212324589252 | validation: 0.8117987761081772]
	TIME [epoch: 9.47 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8672610299425285		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 0.8672610299425285 | validation: 0.9489369786791271]
	TIME [epoch: 9.46 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8532993466342601		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 0.8532993466342601 | validation: 0.8644624725658067]
	TIME [epoch: 9.46 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8511203196587142		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.8511203196587142 | validation: 0.9695901370179313]
	TIME [epoch: 9.48 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8459472180584621		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 0.8459472180584621 | validation: 0.88021160023723]
	TIME [epoch: 9.47 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8816460148042916		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 0.8816460148042916 | validation: 0.84365593035898]
	TIME [epoch: 9.46 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8906786945692451		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 0.8906786945692451 | validation: 0.8965512580934976]
	TIME [epoch: 9.46 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8421591972534156		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 0.8421591972534156 | validation: 0.8685918738879919]
	TIME [epoch: 9.48 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8560728671745006		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 0.8560728671745006 | validation: 0.7587775482349999]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_838.pth
	Model improved!!!
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8143583600949457		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 0.8143583600949457 | validation: 0.8078059529323209]
	TIME [epoch: 9.46 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8192582917784508		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 0.8192582917784508 | validation: 0.864897279802966]
	TIME [epoch: 9.46 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8398077989079379		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 0.8398077989079379 | validation: 0.838380129147557]
	TIME [epoch: 9.48 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9018266049769187		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 0.9018266049769187 | validation: 0.9354298497668725]
	TIME [epoch: 9.46 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9622745987742436		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 0.9622745987742436 | validation: 0.8622517913309586]
	TIME [epoch: 9.46 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8311919577752949		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 0.8311919577752949 | validation: 0.7887958370298364]
	TIME [epoch: 9.47 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8624531874377507		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 0.8624531874377507 | validation: 0.7708995111504592]
	TIME [epoch: 9.47 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8758725028654935		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 0.8758725028654935 | validation: 0.8485071275705593]
	TIME [epoch: 9.45 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8691275389372561		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 0.8691275389372561 | validation: 0.8602455918533274]
	TIME [epoch: 9.45 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8118885032413102		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 0.8118885032413102 | validation: 0.8270355648856773]
	TIME [epoch: 9.47 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8440650913081591		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 0.8440650913081591 | validation: 0.9660836338683854]
	TIME [epoch: 9.46 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8421185986690514		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 0.8421185986690514 | validation: 0.8330658802378352]
	TIME [epoch: 9.46 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8664635498729962		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 0.8664635498729962 | validation: 0.8300244569005067]
	TIME [epoch: 9.46 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8976263288472557		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.8976263288472557 | validation: 0.8014098380533006]
	TIME [epoch: 9.48 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8295590587097547		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 0.8295590587097547 | validation: 0.8436432046220343]
	TIME [epoch: 9.46 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8217343427454677		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 0.8217343427454677 | validation: 0.9425953785389182]
	TIME [epoch: 9.45 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.858255848546613		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 0.858255848546613 | validation: 0.8180605378626825]
	TIME [epoch: 9.45 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8357239785783198		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 0.8357239785783198 | validation: 0.8564283375917282]
	TIME [epoch: 9.48 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8361412755890557		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 0.8361412755890557 | validation: 0.8325205354702433]
	TIME [epoch: 9.45 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8314163480059751		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 0.8314163480059751 | validation: 0.8581849080091289]
	TIME [epoch: 9.46 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8312879638716799		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 0.8312879638716799 | validation: 0.8865601548396734]
	TIME [epoch: 9.46 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8382997214734234		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 0.8382997214734234 | validation: 0.7626001607867247]
	TIME [epoch: 9.48 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8135223336763447		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 0.8135223336763447 | validation: 0.9679911099438789]
	TIME [epoch: 9.45 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8444364634332475		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 0.8444364634332475 | validation: 0.8155989297655968]
	TIME [epoch: 9.45 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8342651496613204		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 0.8342651496613204 | validation: 0.8186126366888187]
	TIME [epoch: 9.46 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8662693938330819		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 0.8662693938330819 | validation: 0.8187654266369109]
	TIME [epoch: 9.48 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8313540510304342		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 0.8313540510304342 | validation: 0.7936188805974947]
	TIME [epoch: 9.45 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8363633764324685		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 0.8363633764324685 | validation: 0.8120939240605987]
	TIME [epoch: 9.45 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.791793295475437		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 0.791793295475437 | validation: 0.875445391815365]
	TIME [epoch: 9.47 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8299048890821714		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 0.8299048890821714 | validation: 0.8180237635019176]
	TIME [epoch: 9.46 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8398859310136846		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 0.8398859310136846 | validation: 0.8265762093736325]
	TIME [epoch: 9.45 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9213623975519718		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 0.9213623975519718 | validation: 0.7944498908212431]
	TIME [epoch: 9.45 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8029984679862722		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.8029984679862722 | validation: 0.8779659100128788]
	TIME [epoch: 9.48 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8527185541689212		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 0.8527185541689212 | validation: 0.8560760754933346]
	TIME [epoch: 9.46 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.820754422495232		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 0.820754422495232 | validation: 0.8528538660694882]
	TIME [epoch: 9.45 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8287591285051464		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 0.8287591285051464 | validation: 0.7998064539292233]
	TIME [epoch: 9.45 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8402206342811052		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 0.8402206342811052 | validation: 0.9152603560159741]
	TIME [epoch: 9.47 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.825665052994513		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 0.825665052994513 | validation: 0.805354380833245]
	TIME [epoch: 9.46 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8815416055917442		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 0.8815416055917442 | validation: 0.7464794431732924]
	TIME [epoch: 9.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_877.pth
	Model improved!!!
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8398351600061116		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 0.8398351600061116 | validation: 1.0162344577595703]
	TIME [epoch: 9.45 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8653659922959888		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 0.8653659922959888 | validation: 0.7666618278057459]
	TIME [epoch: 9.47 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8275252658289087		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 0.8275252658289087 | validation: 0.9278734266773586]
	TIME [epoch: 9.45 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8541964670030087		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 0.8541964670030087 | validation: 0.8282377633250043]
	TIME [epoch: 9.45 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8361333953273349		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 0.8361333953273349 | validation: 0.8388777245736865]
	TIME [epoch: 9.45 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8224928310785874		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 0.8224928310785874 | validation: 0.802099657526849]
	TIME [epoch: 9.47 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8182564758770796		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 0.8182564758770796 | validation: 0.828135113134355]
	TIME [epoch: 9.45 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8406249397517863		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 0.8406249397517863 | validation: 0.84459503596589]
	TIME [epoch: 9.45 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8491757986653757		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 0.8491757986653757 | validation: 0.8883558625370372]
	TIME [epoch: 9.46 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.795384210239021		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 0.795384210239021 | validation: 0.7897615552045621]
	TIME [epoch: 9.46 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8083480256756715		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 0.8083480256756715 | validation: 0.8553283327712908]
	TIME [epoch: 9.45 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8475046930162486		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 0.8475046930162486 | validation: 0.8757054314117286]
	TIME [epoch: 9.45 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8447931554334671		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.8447931554334671 | validation: 0.8346691491713916]
	TIME [epoch: 9.47 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8154272031995179		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 0.8154272031995179 | validation: 0.7969012756707256]
	TIME [epoch: 9.45 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8230153298964193		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 0.8230153298964193 | validation: 0.827475455165065]
	TIME [epoch: 9.45 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7975084955449614		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 0.7975084955449614 | validation: 0.9177203063919932]
	TIME [epoch: 9.45 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8347810768581739		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 0.8347810768581739 | validation: 0.8469767251305013]
	TIME [epoch: 9.47 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8411392682764524		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 0.8411392682764524 | validation: 0.8387930405351953]
	TIME [epoch: 9.45 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8572636077233202		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 0.8572636077233202 | validation: 0.754096258556011]
	TIME [epoch: 9.45 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8048164012015508		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 0.8048164012015508 | validation: 0.9305717325040912]
	TIME [epoch: 9.45 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8728616756770137		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 0.8728616756770137 | validation: 0.8645459441686398]
	TIME [epoch: 9.47 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8080711846620524		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 0.8080711846620524 | validation: 0.863403099081338]
	TIME [epoch: 9.45 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8112942735139612		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 0.8112942735139612 | validation: 0.821463268566366]
	TIME [epoch: 9.45 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8475127346388118		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 0.8475127346388118 | validation: 0.8291161808435152]
	TIME [epoch: 9.44 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7918349993765521		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 0.7918349993765521 | validation: 0.8071530780457202]
	TIME [epoch: 9.47 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.816862965393166		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 0.816862965393166 | validation: 0.8863390702079312]
	TIME [epoch: 9.45 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8258031231252442		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 0.8258031231252442 | validation: 0.8761484091292138]
	TIME [epoch: 9.45 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8104532869229238		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 0.8104532869229238 | validation: 0.8149309429428577]
	TIME [epoch: 9.45 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8408229867476266		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 0.8408229867476266 | validation: 0.8276476919108825]
	TIME [epoch: 9.47 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8016501599749631		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 0.8016501599749631 | validation: 0.8159003643249532]
	TIME [epoch: 9.45 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.843148997409427		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 0.843148997409427 | validation: 0.8117163545809704]
	TIME [epoch: 9.45 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7996646558827489		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.7996646558827489 | validation: 0.8053426713171508]
	TIME [epoch: 9.46 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8270326934999334		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 0.8270326934999334 | validation: 0.7752488825183173]
	TIME [epoch: 9.46 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8411191109598409		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 0.8411191109598409 | validation: 0.7773022931499988]
	TIME [epoch: 9.45 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8357404967046274		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 0.8357404967046274 | validation: 0.7962144993156843]
	TIME [epoch: 9.45 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8381425708383292		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 0.8381425708383292 | validation: 0.795720443978415]
	TIME [epoch: 9.47 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7945137772450932		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 0.7945137772450932 | validation: 0.8245586067650302]
	TIME [epoch: 9.46 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8132631826324459		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 0.8132631826324459 | validation: 0.8195307884827088]
	TIME [epoch: 9.45 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8052182279696789		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 0.8052182279696789 | validation: 0.8462515059186919]
	TIME [epoch: 9.45 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8498184724779151		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 0.8498184724779151 | validation: 0.7912271135851158]
	TIME [epoch: 9.47 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8093338245232333		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 0.8093338245232333 | validation: 0.7698343784476441]
	TIME [epoch: 9.45 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8158780280057509		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 0.8158780280057509 | validation: 0.8052283044593161]
	TIME [epoch: 9.45 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8051826366619608		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 0.8051826366619608 | validation: 0.8360039330198807]
	TIME [epoch: 9.45 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8089841758864289		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 0.8089841758864289 | validation: 0.765768671192549]
	TIME [epoch: 9.47 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7902732380250985		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 0.7902732380250985 | validation: 0.8265496835659443]
	TIME [epoch: 9.45 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.796684443008997		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 0.796684443008997 | validation: 0.8028573671894965]
	TIME [epoch: 9.45 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8087594537768329		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 0.8087594537768329 | validation: 0.8136267102878812]
	TIME [epoch: 9.45 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8263359676082901		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 0.8263359676082901 | validation: 1.0082122488988556]
	TIME [epoch: 9.47 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8330904125113555		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 0.8330904125113555 | validation: 0.785508638182985]
	TIME [epoch: 9.45 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8310913813115505		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 0.8310913813115505 | validation: 0.7700025147334134]
	TIME [epoch: 9.45 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7947907525233556		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.7947907525233556 | validation: 0.8163065502313537]
	TIME [epoch: 9.46 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.807767009196407		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 0.807767009196407 | validation: 0.829420953869353]
	TIME [epoch: 9.46 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7906019652443896		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 0.7906019652443896 | validation: 0.797843269560496]
	TIME [epoch: 9.45 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8267360205190931		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 0.8267360205190931 | validation: 0.8013499014939559]
	TIME [epoch: 9.45 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8138383919265955		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 0.8138383919265955 | validation: 0.7912650830028952]
	TIME [epoch: 9.47 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8301908155115039		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 0.8301908155115039 | validation: 0.8586278103670262]
	TIME [epoch: 9.45 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8004256243282283		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 0.8004256243282283 | validation: 0.831897662899313]
	TIME [epoch: 9.45 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.826544887788993		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 0.826544887788993 | validation: 0.7739141206880501]
	TIME [epoch: 9.45 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8264174596030939		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 0.8264174596030939 | validation: 0.8093235247348328]
	TIME [epoch: 9.46 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8556429233006899		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 0.8556429233006899 | validation: 0.8196856069598073]
	TIME [epoch: 9.45 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8031468062266308		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 0.8031468062266308 | validation: 0.8091731818027817]
	TIME [epoch: 9.44 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8196878251500779		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 0.8196878251500779 | validation: 0.8504486857289875]
	TIME [epoch: 9.44 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.829028257364279		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 0.829028257364279 | validation: 0.8302806079400964]
	TIME [epoch: 9.47 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8151777685241595		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 0.8151777685241595 | validation: 0.8362557665300804]
	TIME [epoch: 9.45 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8162905248756651		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 0.8162905248756651 | validation: 0.7982074981197095]
	TIME [epoch: 9.44 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8138000110729123		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 0.8138000110729123 | validation: 0.8708633334747549]
	TIME [epoch: 9.44 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8128610769682837		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 0.8128610769682837 | validation: 0.815580012329833]
	TIME [epoch: 9.47 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8193725867964305		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 0.8193725867964305 | validation: 0.7847281289200885]
	TIME [epoch: 9.45 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.826919599755992		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 0.826919599755992 | validation: 0.7858522529100851]
	TIME [epoch: 9.45 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8375186036461031		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.8375186036461031 | validation: 0.8096887422454458]
	TIME [epoch: 9.45 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8059012072564264		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 0.8059012072564264 | validation: 0.7909422266467754]
	TIME [epoch: 9.46 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8051322310985569		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 0.8051322310985569 | validation: 0.8001698623831983]
	TIME [epoch: 9.45 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7924349328842345		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 0.7924349328842345 | validation: 0.8856947771014256]
	TIME [epoch: 9.45 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8248867893949473		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 0.8248867893949473 | validation: 0.793368473188373]
	TIME [epoch: 9.46 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8228368310295568		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 0.8228368310295568 | validation: 0.7614774702061766]
	TIME [epoch: 9.45 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8066987990743041		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 0.8066987990743041 | validation: 0.8563654686936638]
	TIME [epoch: 9.44 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8077961353815126		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 0.8077961353815126 | validation: 0.8599053852433716]
	TIME [epoch: 9.44 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7950620421980188		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 0.7950620421980188 | validation: 0.8747299767748418]
	TIME [epoch: 9.47 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8129299829049985		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 0.8129299829049985 | validation: 0.7509813189626888]
	TIME [epoch: 9.45 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8159846597393617		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 0.8159846597393617 | validation: 0.7481318043574294]
	TIME [epoch: 9.44 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7810907118020474		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 0.7810907118020474 | validation: 0.8209350177873913]
	TIME [epoch: 9.44 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.812399043378587		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 0.812399043378587 | validation: 0.8247092848954398]
	TIME [epoch: 9.47 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.82057117565059		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 0.82057117565059 | validation: 0.8227512701959312]
	TIME [epoch: 9.45 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7940775242939428		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 0.7940775242939428 | validation: 0.8133051320112717]
	TIME [epoch: 9.45 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8027137748485531		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 0.8027137748485531 | validation: 0.7862307905727761]
	TIME [epoch: 9.45 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7802733217303311		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 0.7802733217303311 | validation: 0.7662815218279111]
	TIME [epoch: 9.47 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7872684149913857		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 0.7872684149913857 | validation: 0.8115747284647737]
	TIME [epoch: 9.44 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8224559467363693		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 0.8224559467363693 | validation: 0.7702933022513355]
	TIME [epoch: 9.45 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.79971704719787		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.79971704719787 | validation: 0.7797806298175798]
	TIME [epoch: 9.45 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8339873547477101		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 0.8339873547477101 | validation: 0.8871124937396044]
	TIME [epoch: 9.47 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8179301930581101		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 0.8179301930581101 | validation: 0.805200185738043]
	TIME [epoch: 9.45 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8109630883772512		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 0.8109630883772512 | validation: 0.7899003991972323]
	TIME [epoch: 9.44 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7863443803187671		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 0.7863443803187671 | validation: 0.7523410465459438]
	TIME [epoch: 9.46 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8359729011413931		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 0.8359729011413931 | validation: 0.8120542752500148]
	TIME [epoch: 9.46 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7967630293688107		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 0.7967630293688107 | validation: 0.8477152087410329]
	TIME [epoch: 9.46 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8059939778051234		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 0.8059939778051234 | validation: 0.859437462882205]
	TIME [epoch: 9.44 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7842748907045519		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 0.7842748907045519 | validation: 0.8044357570512836]
	TIME [epoch: 9.46 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8586066973631578		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 0.8586066973631578 | validation: 0.8730278801492305]
	TIME [epoch: 9.44 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8335316639659889		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 0.8335316639659889 | validation: 0.8538136244194735]
	TIME [epoch: 9.44 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7984731334435796		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 0.7984731334435796 | validation: 0.7879609639240581]
	TIME [epoch: 9.43 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7865513789575613		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 0.7865513789575613 | validation: 0.8209524252896084]
	TIME [epoch: 9.47 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7992016692425781		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 0.7992016692425781 | validation: 0.817326881346178]
	TIME [epoch: 9.44 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7997468150121861		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 0.7997468150121861 | validation: 0.7911264112852132]
	TIME [epoch: 9.44 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7886380994924447		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 0.7886380994924447 | validation: 0.8043961076863465]
	TIME [epoch: 9.44 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8125835301139898		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 0.8125835301139898 | validation: 0.8144569558389703]
	TIME [epoch: 9.46 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7978628703699397		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 0.7978628703699397 | validation: 0.821317753147549]
	TIME [epoch: 9.45 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7925924425712585		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 0.7925924425712585 | validation: 0.7750609495605177]
	TIME [epoch: 9.45 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7928867851714215		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.7928867851714215 | validation: 0.9124239594881033]
	TIME [epoch: 9.44 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8230600293110601		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 0.8230600293110601 | validation: 0.8387534661049562]
	TIME [epoch: 9.46 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7848362116788253		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 0.7848362116788253 | validation: 0.8108293294546317]
	TIME [epoch: 9.44 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8148641902175008		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 0.8148641902175008 | validation: 0.8613634671165579]
	TIME [epoch: 9.44 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7937680513555981		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 0.7937680513555981 | validation: 0.8013418736401593]
	TIME [epoch: 9.44 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7953679541240641		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 0.7953679541240641 | validation: 0.7939232225352412]
	TIME [epoch: 9.46 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7911929491329134		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 0.7911929491329134 | validation: 0.83168711571764]
	TIME [epoch: 9.44 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7742278028411548		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 0.7742278028411548 | validation: 0.8103971127445522]
	TIME [epoch: 9.44 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7876077726824333		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 0.7876077726824333 | validation: 0.7993776214771227]
	TIME [epoch: 9.45 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8085224192772605		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 0.8085224192772605 | validation: 0.7354539532988307]
	TIME [epoch: 9.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_140924/states/model_tr_study6_994.pth
	Model improved!!!
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8059357494738814		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 0.8059357494738814 | validation: 0.7797054505221831]
	TIME [epoch: 9.44 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8453029715694192		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 0.8453029715694192 | validation: 0.8546292390196246]
	TIME [epoch: 9.44 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8255624673578138		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 0.8255624673578138 | validation: 0.7971952970368785]
	TIME [epoch: 9.47 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8003851849643933		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 0.8003851849643933 | validation: 0.7440368493403634]
	TIME [epoch: 9.45 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7867387457254563		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 0.7867387457254563 | validation: 0.8433427479480164]
	TIME [epoch: 9.44 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8044925195266923		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 0.8044925195266923 | validation: 0.8490540630065568]
	TIME [epoch: 9.44 sec]
Finished training in 9580.563 seconds.
