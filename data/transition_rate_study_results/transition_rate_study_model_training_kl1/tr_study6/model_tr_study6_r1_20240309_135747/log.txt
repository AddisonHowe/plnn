Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r1', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1026721074

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.463125150581625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.463125150581625 | validation: 7.335424528146308]
	TIME [epoch: 112 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.725235448459167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.725235448459167 | validation: 6.059748532781896]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.11596225815748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.11596225815748 | validation: 6.814904596724375]
	TIME [epoch: 24.9 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.522820684318014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.522820684318014 | validation: 5.338484202275861]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.237239244386509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.237239244386509 | validation: 4.4576660609007455]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.301388782680183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.301388782680183 | validation: 4.434161332532982]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.627831115149816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.627831115149816 | validation: 4.198416973110064]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.433615262354319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.433615262354319 | validation: 4.208604572053978]
	TIME [epoch: 25 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5039765298055885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5039765298055885 | validation: 4.279422959243899]
	TIME [epoch: 25 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3823934762167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3823934762167 | validation: 3.9547405106874933]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.053690847276611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.053690847276611 | validation: 3.737213369005991]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.891105635406308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.891105635406308 | validation: 3.608748974107426]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7754779003298964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7754779003298964 | validation: 3.689008247316373]
	TIME [epoch: 25 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.731234201921393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.731234201921393 | validation: 3.5111205371724328]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.736359607397594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.736359607397594 | validation: 3.661989292232275]
	TIME [epoch: 24.9 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7209923662380477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7209923662380477 | validation: 3.4037462676245265]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.625744687317152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.625744687317152 | validation: 3.468753999963041]
	TIME [epoch: 24.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.613003474065983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.613003474065983 | validation: 3.438403281095215]
	TIME [epoch: 24.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5521960988582704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5521960988582704 | validation: 3.397555377160909]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4754741746821582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4754741746821582 | validation: 3.290529921245375]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5361489125547667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5361489125547667 | validation: 3.3452500725848684]
	TIME [epoch: 24.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.488525145746059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.488525145746059 | validation: 3.209612021812227]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3747346991969716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3747346991969716 | validation: 3.1596963434372074]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4449774062361955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4449774062361955 | validation: 3.942574401003988]
	TIME [epoch: 24.9 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6549224685933392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6549224685933392 | validation: 3.1207976925071814]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2757242529008592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2757242529008592 | validation: 3.2816963363830904]
	TIME [epoch: 24.9 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.310317710345936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.310317710345936 | validation: 3.0652057900340495]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5241813068715047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5241813068715047 | validation: 2.932693313416339]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4748348426910782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4748348426910782 | validation: 6.951526842654639]
	TIME [epoch: 25 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.961290074663902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.961290074663902 | validation: 3.410005807343932]
	TIME [epoch: 25 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.234988057477453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.234988057477453 | validation: 2.934880492136768]
	TIME [epoch: 25 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.121104330513873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.121104330513873 | validation: 2.894685368717847]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9515614430281856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9515614430281856 | validation: 2.84605445474696]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1343273656749697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1343273656749697 | validation: 3.049039523629222]
	TIME [epoch: 25 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.043186596820271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.043186596820271 | validation: 2.7741219878627077]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.059416766233664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.059416766233664 | validation: 3.024300061750663]
	TIME [epoch: 25 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8038585134058716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8038585134058716 | validation: 2.5931050707323275]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7179536189194344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7179536189194344 | validation: 3.4050220317601134]
	TIME [epoch: 24.9 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.98899168669189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.98899168669189 | validation: 2.664084660615668]
	TIME [epoch: 25 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7185502488289446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7185502488289446 | validation: 2.473376773762835]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.570320755613826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.570320755613826 | validation: 2.326776415550273]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.621177358267448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.621177358267448 | validation: 2.740707092988948]
	TIME [epoch: 25 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.597561826949331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.597561826949331 | validation: 2.705225367212802]
	TIME [epoch: 25 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.639684596001519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.639684596001519 | validation: 2.334827798431416]
	TIME [epoch: 24.9 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3720298706236256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3720298706236256 | validation: 2.1594480849202227]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.227860793317117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.227860793317117 | validation: 2.085373013681336]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.21622421955362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.21622421955362 | validation: 2.4542986768154886]
	TIME [epoch: 24.9 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.466350531670411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.466350531670411 | validation: 2.6621747992565976]
	TIME [epoch: 24.9 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2940726229163015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2940726229163015 | validation: 1.8140158897819634]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066661805934858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.066661805934858 | validation: 1.6940713427526293]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8687149521821569		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.8687149521821569 | validation: 2.039827018975341]
	TIME [epoch: 24.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8251250034878836		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.8251250034878836 | validation: 1.567039164193264]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7953231528658147		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.7953231528658147 | validation: 2.8164387294937248]
	TIME [epoch: 24.9 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2252780892835746		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.2252780892835746 | validation: 1.5141585373611595]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1602627441966717		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.1602627441966717 | validation: 1.6816623209520425]
	TIME [epoch: 24.9 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7792652294584297		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.7792652294584297 | validation: 2.394140166617365]
	TIME [epoch: 25 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3823568446039323		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.3823568446039323 | validation: 2.34593897400232]
	TIME [epoch: 25 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1085750647347785		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.1085750647347785 | validation: 1.4260746479202078]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4972424960735102		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.4972424960735102 | validation: 1.2453947738542905]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.395636639255075		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.395636639255075 | validation: 1.1124707094486186]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.325650813877938		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.325650813877938 | validation: 1.3396689989292596]
	TIME [epoch: 25 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5552389919910208		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.5552389919910208 | validation: 1.62948206737615]
	TIME [epoch: 24.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4194420083549881		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.4194420083549881 | validation: 1.3878340698906015]
	TIME [epoch: 24.9 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5075859278862955		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.5075859278862955 | validation: 1.1589634819583705]
	TIME [epoch: 24.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3669914407640926		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.3669914407640926 | validation: 1.2202836806418935]
	TIME [epoch: 24.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3921660418517734		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.3921660418517734 | validation: 1.844859692074719]
	TIME [epoch: 24.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2638410848131074		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.2638410848131074 | validation: 1.7388723404607709]
	TIME [epoch: 25 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.916108545788284		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.916108545788284 | validation: 1.0465220393953423]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4493714047340571		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.4493714047340571 | validation: 1.2767233407540277]
	TIME [epoch: 24.9 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6647369259434075		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.6647369259434075 | validation: 1.391510387078357]
	TIME [epoch: 24.9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2234360171206888		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.2234360171206888 | validation: 0.8748561194262442]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2326490340810183		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.2326490340810183 | validation: 0.8940449071266133]
	TIME [epoch: 24.9 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1600483518490552		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.1600483518490552 | validation: 1.0267444357078086]
	TIME [epoch: 24.9 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0892825137653732		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.0892825137653732 | validation: 1.0813703504469034]
	TIME [epoch: 24.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0368606782058696		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.0368606782058696 | validation: 1.564336583377564]
	TIME [epoch: 24.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2158672960110832		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.2158672960110832 | validation: 1.1504625845738132]
	TIME [epoch: 25 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.018327495916593		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.018327495916593 | validation: 0.7441781699167045]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.303499828160664		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.303499828160664 | validation: 0.999879396293795]
	TIME [epoch: 25 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0755899145821666		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.0755899145821666 | validation: 0.8992147638538566]
	TIME [epoch: 25 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0263998513722723		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.0263998513722723 | validation: 0.8717076472232071]
	TIME [epoch: 24.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2588297291319328		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.2588297291319328 | validation: 1.0922066897509897]
	TIME [epoch: 25 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3473363333182176		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.3473363333182176 | validation: 1.0977143964196332]
	TIME [epoch: 25 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2107902037374643		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.2107902037374643 | validation: 1.728829688156619]
	TIME [epoch: 24.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.193448962702072		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.193448962702072 | validation: 0.9281527712933167]
	TIME [epoch: 24.9 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9979256713620441		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.9979256713620441 | validation: 1.5308228013532637]
	TIME [epoch: 25 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0303609468603234		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.0303609468603234 | validation: 0.8425553968434687]
	TIME [epoch: 25 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8200043515851918		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.8200043515851918 | validation: 0.7206228347246989]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.089805832033928		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.089805832033928 | validation: 0.7897089990302479]
	TIME [epoch: 25 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9050610808046753		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.9050610808046753 | validation: 0.7298624521165712]
	TIME [epoch: 25 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9347280812340837		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.9347280812340837 | validation: 0.7433012488128083]
	TIME [epoch: 25 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.957941280410346		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.957941280410346 | validation: 4.732330243185533]
	TIME [epoch: 25 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.841553699809362		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 6.841553699809362 | validation: 6.471766002402886]
	TIME [epoch: 25 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.071854744655229		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 7.071854744655229 | validation: 5.1661601397037975]
	TIME [epoch: 24.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.131571947870346		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 6.131571947870346 | validation: 4.5329230092784565]
	TIME [epoch: 25 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.647950287578569		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.647950287578569 | validation: 3.941911267453374]
	TIME [epoch: 25 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9909877206044917		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.9909877206044917 | validation: 2.033643370992123]
	TIME [epoch: 25 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5831830420677298		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.5831830420677298 | validation: 1.4375433508610433]
	TIME [epoch: 25 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.774155204875802		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.774155204875802 | validation: 1.243163540613403]
	TIME [epoch: 25 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4941642374656627		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.4941642374656627 | validation: 1.0985229456948655]
	TIME [epoch: 24.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2143588962605594		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.2143588962605594 | validation: 0.895352806080929]
	TIME [epoch: 25 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2364606185539933		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.2364606185539933 | validation: 2.8926002490967018]
	TIME [epoch: 25 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9384846301517806		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.9384846301517806 | validation: 1.095758212582094]
	TIME [epoch: 24.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.36586473267049		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.36586473267049 | validation: 1.3381868692547598]
	TIME [epoch: 25 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1281685248105495		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.1281685248105495 | validation: 1.346165749914167]
	TIME [epoch: 25 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.10887322227325		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.10887322227325 | validation: 0.7816780006429869]
	TIME [epoch: 24.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7896187182742702		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.7896187182742702 | validation: 2.2052819931305567]
	TIME [epoch: 25 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.064958705248326		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.064958705248326 | validation: 1.2383564591269696]
	TIME [epoch: 25 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9020843645773431		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.9020843645773431 | validation: 0.8535719951973296]
	TIME [epoch: 24.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7949798866441883		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.7949798866441883 | validation: 0.8768301606915845]
	TIME [epoch: 25 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9699095292081377		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.9699095292081377 | validation: 4.283870780573035]
	TIME [epoch: 25 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.284673573965882		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 4.284673573965882 | validation: 4.184896994739911]
	TIME [epoch: 25 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6589691140320624		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.6589691140320624 | validation: 2.746601945647161]
	TIME [epoch: 25 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.136425645356662		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.136425645356662 | validation: 2.2807263881009234]
	TIME [epoch: 25 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4762387325010178		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.4762387325010178 | validation: 1.0277823733981593]
	TIME [epoch: 24.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1510032054940231		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.1510032054940231 | validation: 0.9142362444391811]
	TIME [epoch: 25 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4949158279888826		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.4949158279888826 | validation: 1.1696771954056617]
	TIME [epoch: 25 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9642738158829884		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.9642738158829884 | validation: 0.8953888540296149]
	TIME [epoch: 25 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4361795726174664		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.4361795726174664 | validation: 2.9066420125958836]
	TIME [epoch: 25 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.709917239714872		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.709917239714872 | validation: 2.099394432930097]
	TIME [epoch: 25 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8219469427390707		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.8219469427390707 | validation: 1.0901848912949401]
	TIME [epoch: 24.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1318534535572375		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.1318534535572375 | validation: 1.1556789888773764]
	TIME [epoch: 25 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3818160969482185		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.3818160969482185 | validation: 1.4374425504893236]
	TIME [epoch: 25 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.033744384932022		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.033744384932022 | validation: 2.053976278662657]
	TIME [epoch: 24.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5379505735498054		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.5379505735498054 | validation: 1.143643285729088]
	TIME [epoch: 25 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2579673312926887		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.2579673312926887 | validation: 1.1447093456019553]
	TIME [epoch: 25 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1852630911325932		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.1852630911325932 | validation: 0.9629636075262918]
	TIME [epoch: 24.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9009804588198724		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.9009804588198724 | validation: 1.102434908814978]
	TIME [epoch: 24.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9685463374896999		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.9685463374896999 | validation: 1.887321809425095]
	TIME [epoch: 24.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6987491009655407		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.6987491009655407 | validation: 1.3043092967888126]
	TIME [epoch: 24.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1949709799883341		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.1949709799883341 | validation: 0.7513499601147379]
	TIME [epoch: 25 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9166003581623688		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.9166003581623688 | validation: 0.7267445504650766]
	TIME [epoch: 24.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7582102777260891		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.7582102777260891 | validation: 1.2624710637913965]
	TIME [epoch: 24.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9618055309911292		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.9618055309911292 | validation: 0.8125293627103213]
	TIME [epoch: 25 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2903680086912894		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.2903680086912894 | validation: 1.4099228451805832]
	TIME [epoch: 25 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4481315100171654		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.4481315100171654 | validation: 1.0663804824121963]
	TIME [epoch: 24.9 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8942274048184966		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.8942274048184966 | validation: 0.7947622271958176]
	TIME [epoch: 25 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7350472527270895		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.7350472527270895 | validation: 0.6401544944945544]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7655227887569056		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.7655227887569056 | validation: 0.672615563532155]
	TIME [epoch: 24.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.709892712448299		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.709892712448299 | validation: 0.620183519993135]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7545104622046634		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.7545104622046634 | validation: 0.6152306810666234]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6516614705819046		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.6516614705819046 | validation: 0.6122154239263236]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7710099172666242		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.7710099172666242 | validation: 3.8709182555844586]
	TIME [epoch: 25 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.06369758256474		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.06369758256474 | validation: 0.7606812416108634]
	TIME [epoch: 25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1711788203800464		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.1711788203800464 | validation: 0.9543636359062906]
	TIME [epoch: 25 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9723650442181043		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.9723650442181043 | validation: 0.6810912552016227]
	TIME [epoch: 25 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6456999928283218		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.6456999928283218 | validation: 0.7195654116599488]
	TIME [epoch: 25 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0665750796099795		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.0665750796099795 | validation: 0.9070042068461084]
	TIME [epoch: 24.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0245625123513062		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.0245625123513062 | validation: 1.1546371186344142]
	TIME [epoch: 24.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9268314920840366		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.9268314920840366 | validation: 0.6424357545378311]
	TIME [epoch: 25 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7918406044501567		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.7918406044501567 | validation: 0.922996048911155]
	TIME [epoch: 24.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0575024457702764		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.0575024457702764 | validation: 1.1831750946506931]
	TIME [epoch: 25 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9375506545711235		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.9375506545711235 | validation: 1.1622987416180164]
	TIME [epoch: 25 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9732163123855115		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.9732163123855115 | validation: 0.6675811483295334]
	TIME [epoch: 24.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8384573421699828		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.8384573421699828 | validation: 0.7106952719192918]
	TIME [epoch: 24.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8885825882075948		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.8885825882075948 | validation: 0.7564104243950952]
	TIME [epoch: 25 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8316806687559848		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.8316806687559848 | validation: 0.8117549949739196]
	TIME [epoch: 24.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7651279353476858		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.7651279353476858 | validation: 0.9597962954032773]
	TIME [epoch: 25 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9024061429749937		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.9024061429749937 | validation: 0.7852406041175313]
	TIME [epoch: 25 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8338574954546161		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.8338574954546161 | validation: 0.8315975294497013]
	TIME [epoch: 25 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8165096147383607		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.8165096147383607 | validation: 0.7191171789866677]
	TIME [epoch: 24.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0835303354530905		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.0835303354530905 | validation: 1.0069170111389065]
	TIME [epoch: 25 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9208591265339725		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.9208591265339725 | validation: 0.7109952987523136]
	TIME [epoch: 24.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252166633003589		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.7252166633003589 | validation: 0.605602528759624]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690682629240098		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.690682629240098 | validation: 1.2838616801657514]
	TIME [epoch: 25 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9268397832479356		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.9268397832479356 | validation: 0.8433765970548455]
	TIME [epoch: 24.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7521306503127176		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.7521306503127176 | validation: 3.3140059501874117]
	TIME [epoch: 25 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4508988393772806		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.4508988393772806 | validation: 2.8161353027862224]
	TIME [epoch: 25 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.246882418897213		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.246882418897213 | validation: 5.149725370382455]
	TIME [epoch: 24.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6632825434187755		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 4.6632825434187755 | validation: 1.7324117818401918]
	TIME [epoch: 25 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3853014128037213		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.3853014128037213 | validation: 1.5057994918425235]
	TIME [epoch: 25 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1615346026780304		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.1615346026780304 | validation: 0.6942145876068364]
	TIME [epoch: 25 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7373875532377461		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.7373875532377461 | validation: 0.7520470828548755]
	TIME [epoch: 25 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7463698468938389		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.7463698468938389 | validation: 0.9195496449334247]
	TIME [epoch: 25 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2445833655021579		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.2445833655021579 | validation: 0.7376843541605129]
	TIME [epoch: 24.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8755383023197181		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.8755383023197181 | validation: 1.1978955000195186]
	TIME [epoch: 25 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9446851131701659		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.9446851131701659 | validation: 0.6095775108579619]
	TIME [epoch: 25 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6313620721461282		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.6313620721461282 | validation: 0.6235555745749862]
	TIME [epoch: 25 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6603604104262711		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.6603604104262711 | validation: 0.5903557674935378]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7427783754623569		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.7427783754623569 | validation: 0.9172538426373776]
	TIME [epoch: 25 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9721783120039561		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.9721783120039561 | validation: 0.7836574426893225]
	TIME [epoch: 24.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7066365124310181		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.7066365124310181 | validation: 0.6196144932347842]
	TIME [epoch: 24.9 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6869922510125304		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.6869922510125304 | validation: 2.3882824106959517]
	TIME [epoch: 25 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.883921615457107		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.883921615457107 | validation: 2.573228424775343]
	TIME [epoch: 24.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9484014232480757		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.9484014232480757 | validation: 2.766135625755372]
	TIME [epoch: 24.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0132621722409034		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.0132621722409034 | validation: 2.596915845306946]
	TIME [epoch: 25 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9791494696126994		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.9791494696126994 | validation: 2.601701496405318]
	TIME [epoch: 24.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9442162455922283		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.9442162455922283 | validation: 2.5979299919040426]
	TIME [epoch: 24.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0023993169502092		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 3.0023993169502092 | validation: 2.5764596482424134]
	TIME [epoch: 25 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.994537780791827		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.994537780791827 | validation: 2.684825455193385]
	TIME [epoch: 24.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.00749679694823		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.00749679694823 | validation: 2.614591593645928]
	TIME [epoch: 24.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9487727489913436		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.9487727489913436 | validation: 2.6388149624395143]
	TIME [epoch: 25 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9192040904685936		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.9192040904685936 | validation: 2.8766059320202007]
	TIME [epoch: 24.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0533920456679957		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 3.0533920456679957 | validation: 2.4447395120514184]
	TIME [epoch: 24.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8031910897683643		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.8031910897683643 | validation: 2.4683097943605707]
	TIME [epoch: 25 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8340202919803508		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.8340202919803508 | validation: 2.5379369560436786]
	TIME [epoch: 24.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.845686049947714		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.845686049947714 | validation: 2.4348067978750847]
	TIME [epoch: 24.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.877583930353336		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.877583930353336 | validation: 2.563649323124946]
	TIME [epoch: 25 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.879296168773267		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.879296168773267 | validation: 2.4898438517291788]
	TIME [epoch: 24.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7869113606318154		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.7869113606318154 | validation: 2.4625287379469167]
	TIME [epoch: 24.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3690697033772996		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 3.3690697033772996 | validation: 3.0777414262165665]
	TIME [epoch: 25 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.098874395680623		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 3.098874395680623 | validation: 2.558899270671005]
	TIME [epoch: 24.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.88808560934751		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.88808560934751 | validation: 2.547649761177458]
	TIME [epoch: 24.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8956923319137573		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.8956923319137573 | validation: 2.5424368038635503]
	TIME [epoch: 25 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8797679229082274		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.8797679229082274 | validation: 2.612556773346596]
	TIME [epoch: 24.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223540674019006		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 3.223540674019006 | validation: 3.5671377707523595]
	TIME [epoch: 24.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7782269123845826		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 3.7782269123845826 | validation: 2.9388474331840904]
	TIME [epoch: 25 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0955155563557804		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 3.0955155563557804 | validation: 2.6407391295334297]
	TIME [epoch: 24.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9937588967106925		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.9937588967106925 | validation: 2.6159576495425596]
	TIME [epoch: 24.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9616736132739376		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.9616736132739376 | validation: 2.6200024360109637]
	TIME [epoch: 25 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9183472722677712		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.9183472722677712 | validation: 2.592742544423252]
	TIME [epoch: 25 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.912172589881687		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.912172589881687 | validation: 2.611039503073273]
	TIME [epoch: 24.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9426379435198324		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.9426379435198324 | validation: 2.6966622800213997]
	TIME [epoch: 25 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9321048180253344		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.9321048180253344 | validation: 2.468737367959673]
	TIME [epoch: 24.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.960840959171175		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.960840959171175 | validation: 2.488368466031135]
	TIME [epoch: 24.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8660025887544385		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.8660025887544385 | validation: 2.406243288148467]
	TIME [epoch: 25 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8799679461235623		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.8799679461235623 | validation: 2.828521947305914]
	TIME [epoch: 24.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0975376453923005		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 3.0975376453923005 | validation: 1.681967591300148]
	TIME [epoch: 24.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3637220949641953		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.3637220949641953 | validation: 0.9943136335003665]
	TIME [epoch: 25 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9915744902545234		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.9915744902545234 | validation: 0.9093144648543668]
	TIME [epoch: 24.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9714206943758354		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.9714206943758354 | validation: 0.8549152774606119]
	TIME [epoch: 24.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8231378188033969		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.8231378188033969 | validation: 0.6846247813725447]
	TIME [epoch: 25 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7794693252627534		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.7794693252627534 | validation: 0.7816385419227997]
	TIME [epoch: 24.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9641259403030437		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.9641259403030437 | validation: 1.1810308678476467]
	TIME [epoch: 24.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8704495324913738		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.8704495324913738 | validation: 0.5722028281914651]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5959685349666914		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.5959685349666914 | validation: 0.5772340151537916]
	TIME [epoch: 24.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6253388207981202		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.6253388207981202 | validation: 0.7093828860590088]
	TIME [epoch: 24.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7569251855432113		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.7569251855432113 | validation: 0.6975843007078709]
	TIME [epoch: 25 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5948377287918658		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.5948377287918658 | validation: 0.6066775025657037]
	TIME [epoch: 24.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7740220317267764		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.7740220317267764 | validation: 2.6873428422098415]
	TIME [epoch: 24.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.621316148635999		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.621316148635999 | validation: 3.40218452810622]
	TIME [epoch: 24.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4698317982593823		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 3.4698317982593823 | validation: 3.551058658290232]
	TIME [epoch: 24.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1021956511833517		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 3.1021956511833517 | validation: 2.3566366777665575]
	TIME [epoch: 24.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.599578264870459		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.599578264870459 | validation: 2.0119615057284492]
	TIME [epoch: 25 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7335484879073357		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.7335484879073357 | validation: 1.6378805527727998]
	TIME [epoch: 24.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4248301020483471		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.4248301020483471 | validation: 0.9156097686241933]
	TIME [epoch: 24.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8807807583294172		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.8807807583294172 | validation: 1.1511035995149175]
	TIME [epoch: 25 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9129614483766898		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.9129614483766898 | validation: 0.6873869345112182]
	TIME [epoch: 24.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9202226862713986		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.9202226862713986 | validation: 1.2292061857601098]
	TIME [epoch: 24.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9044021900110177		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.9044021900110177 | validation: 0.5802307408792072]
	TIME [epoch: 25 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245322466921834		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.7245322466921834 | validation: 0.8421153772909495]
	TIME [epoch: 24.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7105901446981284		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.7105901446981284 | validation: 0.6738937721531852]
	TIME [epoch: 24.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7322412180953237		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.7322412180953237 | validation: 0.8487679945777501]
	TIME [epoch: 25 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7913004481854559		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.7913004481854559 | validation: 0.6142525437406886]
	TIME [epoch: 24.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5906528678303099		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.5906528678303099 | validation: 0.6963857286072535]
	TIME [epoch: 24.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6378858543485368		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.6378858543485368 | validation: 0.5939211993809851]
	TIME [epoch: 25 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.610800156644333		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.610800156644333 | validation: 0.735103171695964]
	TIME [epoch: 24.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6325054999207201		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.6325054999207201 | validation: 0.4822468872204213]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.632403058182637		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.632403058182637 | validation: 0.83301860716087]
	TIME [epoch: 24.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.66240380072561		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.66240380072561 | validation: 0.4581725187265883]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851674071689028		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.6851674071689028 | validation: 0.680137868469935]
	TIME [epoch: 24.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5968733690271923		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.5968733690271923 | validation: 0.618236229903848]
	TIME [epoch: 25 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7327118380674571		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.7327118380674571 | validation: 0.5511364173395552]
	TIME [epoch: 24.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5665338428548715		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.5665338428548715 | validation: 0.46997492013067443]
	TIME [epoch: 24.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5750709557918576		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.5750709557918576 | validation: 0.44913238890159607]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.54672391933003		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.54672391933003 | validation: 0.3870573867113327]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.571920626455518		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.571920626455518 | validation: 0.8748054082209692]
	TIME [epoch: 24.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.880863810406491		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.880863810406491 | validation: 0.653075397326513]
	TIME [epoch: 24.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6504578920308948		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.6504578920308948 | validation: 0.5384589146894583]
	TIME [epoch: 25 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5268799551229553		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.5268799551229553 | validation: 0.6162321428551055]
	TIME [epoch: 24.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7137474295051517		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.7137474295051517 | validation: 0.6076902480924921]
	TIME [epoch: 24.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5647182869446665		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.5647182869446665 | validation: 0.48130123573128186]
	TIME [epoch: 24.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1218817350767936		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.1218817350767936 | validation: 1.0403152440109156]
	TIME [epoch: 24.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8014896773867192		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.8014896773867192 | validation: 0.539550588964464]
	TIME [epoch: 25 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5834053291381297		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.5834053291381297 | validation: 0.5438043981994614]
	TIME [epoch: 25 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5462188591771985		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.5462188591771985 | validation: 0.5326527644087891]
	TIME [epoch: 24.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6182141189944159		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.6182141189944159 | validation: 0.5275261793725916]
	TIME [epoch: 25 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46287003369118596		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.46287003369118596 | validation: 0.6657296525313049]
	TIME [epoch: 25 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6000644008867165		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.6000644008867165 | validation: 0.509209414293421]
	TIME [epoch: 24.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5357650836445498		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.5357650836445498 | validation: 0.6392041586331387]
	TIME [epoch: 25 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5247437003593107		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.5247437003593107 | validation: 1.1596709957046505]
	TIME [epoch: 24.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7241389479118596		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.7241389479118596 | validation: 0.5911502112086495]
	TIME [epoch: 24.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8102140746135449		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.8102140746135449 | validation: 1.2014270637387132]
	TIME [epoch: 24.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6715576166688934		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.6715576166688934 | validation: 0.7171251789414255]
	TIME [epoch: 24.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7650683568568334		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.7650683568568334 | validation: 0.539384552476075]
	TIME [epoch: 24.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6015601349043203		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.6015601349043203 | validation: 0.6308475079145077]
	TIME [epoch: 25 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5739238444802388		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.5739238444802388 | validation: 0.5261461851016017]
	TIME [epoch: 24.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44062469313175023		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.44062469313175023 | validation: 0.3996209717806136]
	TIME [epoch: 24.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6552861225525566		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.6552861225525566 | validation: 0.6768374499203125]
	TIME [epoch: 24.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48341117555371044		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.48341117555371044 | validation: 0.43708291904942004]
	TIME [epoch: 24.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44912793165694465		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.44912793165694465 | validation: 0.41307106191982884]
	TIME [epoch: 24.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7981178186825131		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.7981178186825131 | validation: 0.7097816838729714]
	TIME [epoch: 24.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195889262045277		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7195889262045277 | validation: 0.3927528279280454]
	TIME [epoch: 25 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42071744462118876		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.42071744462118876 | validation: 0.5470802094330159]
	TIME [epoch: 24.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46603686436869957		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.46603686436869957 | validation: 0.49098377732892473]
	TIME [epoch: 24.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7076718826302328		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.7076718826302328 | validation: 1.1727609318547179]
	TIME [epoch: 25 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.155920970203531		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.155920970203531 | validation: 0.5719247848336996]
	TIME [epoch: 24.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7577322620730822		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.7577322620730822 | validation: 0.6110256934812378]
	TIME [epoch: 24.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5726691751105578		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.5726691751105578 | validation: 0.5349965979620078]
	TIME [epoch: 24.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5024492147677766		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.5024492147677766 | validation: 0.7340330715312748]
	TIME [epoch: 24.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.816503796320063		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.816503796320063 | validation: 0.7147225031495953]
	TIME [epoch: 24.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5209116542823781		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.5209116542823781 | validation: 0.38691218875745675]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6202863866445126		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.6202863866445126 | validation: 0.5288791583610449]
	TIME [epoch: 24.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45646217829057734		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.45646217829057734 | validation: 0.4228401326911792]
	TIME [epoch: 24.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5264968484759994		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.5264968484759994 | validation: 0.5259062302270869]
	TIME [epoch: 24.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5185388882003724		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.5185388882003724 | validation: 0.365082554255237]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4440637126266579		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.4440637126266579 | validation: 0.4362714202405376]
	TIME [epoch: 25 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5484659153825762		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.5484659153825762 | validation: 0.5411338656071165]
	TIME [epoch: 25 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5584381602276572		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.5584381602276572 | validation: 0.7668699524239864]
	TIME [epoch: 25 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293170201040118		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.5293170201040118 | validation: 0.6656766348885006]
	TIME [epoch: 24.9 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6551026460809787		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.6551026460809787 | validation: 0.45212691097052016]
	TIME [epoch: 25 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5205225300549124		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.5205225300549124 | validation: 0.5293242292131006]
	TIME [epoch: 24.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5180540318897717		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.5180540318897717 | validation: 0.49285706014664954]
	TIME [epoch: 24.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817020172202644		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.6817020172202644 | validation: 0.7925106679297373]
	TIME [epoch: 25 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5306098148474641		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.5306098148474641 | validation: 0.42931832004395426]
	TIME [epoch: 24.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3737242780949558		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.3737242780949558 | validation: 0.47807018034877424]
	TIME [epoch: 24.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47226609632174715		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.47226609632174715 | validation: 0.4496582439789066]
	TIME [epoch: 25 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45383976653668046		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.45383976653668046 | validation: 0.537195170012804]
	TIME [epoch: 24.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5405426558962725		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.5405426558962725 | validation: 0.6478699739699303]
	TIME [epoch: 25 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8852843583995513		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.8852843583995513 | validation: 2.036572273679034]
	TIME [epoch: 25 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7203031163033213		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.7203031163033213 | validation: 0.5447640625097661]
	TIME [epoch: 24.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4319373697320035		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.4319373697320035 | validation: 0.359315643571914]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_311.pth
	Model improved!!!
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39471191087447094		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.39471191087447094 | validation: 0.5536049280541392]
	TIME [epoch: 25 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049977663496193		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.5049977663496193 | validation: 0.4955948774996813]
	TIME [epoch: 24.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5888921538926248		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.5888921538926248 | validation: 0.4973477059730499]
	TIME [epoch: 25 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5612855368324198		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.5612855368324198 | validation: 0.5547056919248433]
	TIME [epoch: 25 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4672826695708201		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.4672826695708201 | validation: 0.3613410991548864]
	TIME [epoch: 24.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5384362475981528		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.5384362475981528 | validation: 1.3135218149158125]
	TIME [epoch: 24.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7902712503776117		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 2.7902712503776117 | validation: 3.0181831442960276]
	TIME [epoch: 25 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213653890972189		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 3.213653890972189 | validation: 2.7621184658741265]
	TIME [epoch: 25 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9300958317207915		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 2.9300958317207915 | validation: 2.543129616783036]
	TIME [epoch: 25 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8649338539450064		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 2.8649338539450064 | validation: 2.5133718848483624]
	TIME [epoch: 25 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8542670149477143		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 2.8542670149477143 | validation: 2.481361755069742]
	TIME [epoch: 25 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.790519897058617		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 2.790519897058617 | validation: 2.5191536762042]
	TIME [epoch: 24.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.89031187395815		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 2.89031187395815 | validation: 1.95476538604254]
	TIME [epoch: 25 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5587358301965626		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.5587358301965626 | validation: 0.7551908895467463]
	TIME [epoch: 24.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7990599552054303		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.7990599552054303 | validation: 1.1477717317313236]
	TIME [epoch: 24.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8617536884091892		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.8617536884091892 | validation: 1.2317328477611884]
	TIME [epoch: 25 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9708124168573471		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.9708124168573471 | validation: 0.6541030712282655]
	TIME [epoch: 24.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6117495003382685		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6117495003382685 | validation: 0.50877162829152]
	TIME [epoch: 24.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5580738097747249		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.5580738097747249 | validation: 0.6269632548554317]
	TIME [epoch: 25 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5415053173577371		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5415053173577371 | validation: 0.5072486546751575]
	TIME [epoch: 25 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7666856503718951		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.7666856503718951 | validation: 0.70850295278633]
	TIME [epoch: 24.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6698206970755055		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.6698206970755055 | validation: 0.5919536628300547]
	TIME [epoch: 25 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6111629812930597		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.6111629812930597 | validation: 0.4588101703669091]
	TIME [epoch: 25 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252260204227821		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.7252260204227821 | validation: 0.6105777278646719]
	TIME [epoch: 24.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5563474765444434		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.5563474765444434 | validation: 0.4493335229351113]
	TIME [epoch: 25 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4738411441155616		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.4738411441155616 | validation: 0.4309624877513603]
	TIME [epoch: 24.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4711614743109055		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.4711614743109055 | validation: 0.6054248230025675]
	TIME [epoch: 24.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.503783962748745		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.503783962748745 | validation: 0.6181673384359128]
	TIME [epoch: 25 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7601966736783348		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.7601966736783348 | validation: 0.44927512098978817]
	TIME [epoch: 25 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4530912430518251		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.4530912430518251 | validation: 0.5093460316556717]
	TIME [epoch: 25 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5928820941449149		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.5928820941449149 | validation: 0.7049171921230319]
	TIME [epoch: 25 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5939738554242762		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.5939738554242762 | validation: 0.599442066754216]
	TIME [epoch: 25 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6673631429233837		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.6673631429233837 | validation: 0.534872756207863]
	TIME [epoch: 25 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5288489017582954		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.5288489017582954 | validation: 0.5319101923281734]
	TIME [epoch: 25 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5471543356727204		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.5471543356727204 | validation: 0.5281883413248323]
	TIME [epoch: 25 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490863841968264		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5490863841968264 | validation: 0.5312049735421766]
	TIME [epoch: 24.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4697448149553122		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.4697448149553122 | validation: 0.46160955106381824]
	TIME [epoch: 25 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42172292306815395		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.42172292306815395 | validation: 0.4197153886711014]
	TIME [epoch: 25 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47093015296481633		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.47093015296481633 | validation: 0.5593053971241778]
	TIME [epoch: 25 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4882301044638869		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.4882301044638869 | validation: 0.4704768339913487]
	TIME [epoch: 25 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4538157799480255		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.4538157799480255 | validation: 0.3705907353136071]
	TIME [epoch: 25 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4498968227152198		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.4498968227152198 | validation: 0.46099691622053934]
	TIME [epoch: 24.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4980602115969548		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.4980602115969548 | validation: 0.49240988674833175]
	TIME [epoch: 25 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48459858303493475		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.48459858303493475 | validation: 0.4516973330241562]
	TIME [epoch: 25 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6123985745634167		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.6123985745634167 | validation: 0.5982865629216925]
	TIME [epoch: 24.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.454336311428139		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.454336311428139 | validation: 0.43104166606813693]
	TIME [epoch: 25 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4254036377918667		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.4254036377918667 | validation: 0.4444974116130679]
	TIME [epoch: 25 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6393837468840503		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.6393837468840503 | validation: 0.5228536746134977]
	TIME [epoch: 25 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45141571558401944		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.45141571558401944 | validation: 0.6074675018644558]
	TIME [epoch: 25 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4693209560590757		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.4693209560590757 | validation: 0.5367778827855717]
	TIME [epoch: 25 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4525081547085788		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.4525081547085788 | validation: 0.43795623348664303]
	TIME [epoch: 25 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39881642592605415		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.39881642592605415 | validation: 0.35606511455445017]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_363.pth
	Model improved!!!
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4307379018682576		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.4307379018682576 | validation: 0.861988376007454]
	TIME [epoch: 25 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3796255818463923		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.3796255818463923 | validation: 1.1434429786857054]
	TIME [epoch: 24.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3956817232843148		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.3956817232843148 | validation: 1.024543522131074]
	TIME [epoch: 25 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8087516724437257		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.8087516724437257 | validation: 0.41537142297563684]
	TIME [epoch: 25 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47727039231104734		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.47727039231104734 | validation: 0.5135614657529365]
	TIME [epoch: 24.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819019485312444		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.6819019485312444 | validation: 0.5093541815097605]
	TIME [epoch: 25 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4963423552517632		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.4963423552517632 | validation: 0.5432698928818341]
	TIME [epoch: 25 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.668802266282659		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.668802266282659 | validation: 1.3779535594737826]
	TIME [epoch: 24.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3815074115000294		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.3815074115000294 | validation: 0.8124167705801122]
	TIME [epoch: 25 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7623808318529077		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.7623808318529077 | validation: 0.46311100553906615]
	TIME [epoch: 25 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5279188697240889		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.5279188697240889 | validation: 0.7763831513308326]
	TIME [epoch: 24.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9087293150444307		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.9087293150444307 | validation: 0.6141801988532136]
	TIME [epoch: 25 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6301152232295744		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.6301152232295744 | validation: 0.5898558300844162]
	TIME [epoch: 25 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.040051093722609		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.040051093722609 | validation: 1.355241125424205]
	TIME [epoch: 24.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.63082456397614		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.63082456397614 | validation: 1.436167998665143]
	TIME [epoch: 25 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6474586845351418		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.6474586845351418 | validation: 0.8315084775703677]
	TIME [epoch: 25 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0859020401202495		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.0859020401202495 | validation: 0.6701411698310265]
	TIME [epoch: 24.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6010445321990407		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.6010445321990407 | validation: 0.5000611091527264]
	TIME [epoch: 25 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141959168691186		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.5141959168691186 | validation: 0.6742010665698971]
	TIME [epoch: 25 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9212727254819835		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.9212727254819835 | validation: 0.9043275935093218]
	TIME [epoch: 24.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8195656722017166		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.8195656722017166 | validation: 0.46656211268923947]
	TIME [epoch: 25 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5478960273415192		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.5478960273415192 | validation: 0.4621159086308954]
	TIME [epoch: 25 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5054798877539701		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.5054798877539701 | validation: 0.47506398097356295]
	TIME [epoch: 24.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4243224423864916		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.4243224423864916 | validation: 0.39907875228078665]
	TIME [epoch: 25 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47378845628269517		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.47378845628269517 | validation: 0.40968723776471955]
	TIME [epoch: 25 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4041144775182068		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.4041144775182068 | validation: 0.5286377771824812]
	TIME [epoch: 25 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7840892731527378		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.7840892731527378 | validation: 0.5642355696424082]
	TIME [epoch: 25 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7229551627894919		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.7229551627894919 | validation: 0.407575517652387]
	TIME [epoch: 25 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36077420758171025		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.36077420758171025 | validation: 0.30011989150428264]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3274931495880488		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.3274931495880488 | validation: 0.3675796432170729]
	TIME [epoch: 25 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4268646295423404		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.4268646295423404 | validation: 0.37405423554697637]
	TIME [epoch: 24.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38376479328370655		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.38376479328370655 | validation: 0.4946518586302331]
	TIME [epoch: 24.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9208435423774042		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.9208435423774042 | validation: 1.4224528236537402]
	TIME [epoch: 25 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6667881731543195		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.6667881731543195 | validation: 1.6385845865451871]
	TIME [epoch: 24.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3106391744770383		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 2.3106391744770383 | validation: 2.358781475702094]
	TIME [epoch: 24.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3514837132857633		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 2.3514837132857633 | validation: 1.9193112182662884]
	TIME [epoch: 24.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7321381898802284		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.7321381898802284 | validation: 1.1197683660721005]
	TIME [epoch: 25 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8879556558541115		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.8879556558541115 | validation: 0.5689540114320611]
	TIME [epoch: 24.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5775938979320856		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.5775938979320856 | validation: 0.4275919868595635]
	TIME [epoch: 24.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45863969098354174		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.45863969098354174 | validation: 0.3770577709300329]
	TIME [epoch: 24.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44564959831970546		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.44564959831970546 | validation: 0.44221511919575257]
	TIME [epoch: 24.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44623393679728296		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.44623393679728296 | validation: 0.28459017089904826]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37896946886453853		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.37896946886453853 | validation: 0.5104379326616358]
	TIME [epoch: 24.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6696635526388593		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.6696635526388593 | validation: 0.5952161590518026]
	TIME [epoch: 24.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49514385696466207		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.49514385696466207 | validation: 0.25898477299072853]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30623370661492094		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.30623370661492094 | validation: 0.30444717756038353]
	TIME [epoch: 24.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36954549286338745		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.36954549286338745 | validation: 0.5071751870371588]
	TIME [epoch: 24.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44823549243139593		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.44823549243139593 | validation: 0.6270471061462445]
	TIME [epoch: 24.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9842050344270767		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.9842050344270767 | validation: 1.0886242836919575]
	TIME [epoch: 25 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9110340165700858		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.9110340165700858 | validation: 0.6904116721400452]
	TIME [epoch: 24.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5301853257078186		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.5301853257078186 | validation: 0.4676513634801161]
	TIME [epoch: 25 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.449027196172296		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.449027196172296 | validation: 0.36273333491980814]
	TIME [epoch: 25 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40367637856599137		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.40367637856599137 | validation: 0.3580457634516971]
	TIME [epoch: 24.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34152554016107767		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.34152554016107767 | validation: 0.2977252354596972]
	TIME [epoch: 25 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3884336627214025		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.3884336627214025 | validation: 0.5494997217761062]
	TIME [epoch: 25 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6522262533189286		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.6522262533189286 | validation: 0.6178361223868156]
	TIME [epoch: 24.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5939595349255354		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.5939595349255354 | validation: 0.5074576784651587]
	TIME [epoch: 25 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5343484446466854		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.5343484446466854 | validation: 0.4685845848133631]
	TIME [epoch: 24.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47148933665887105		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.47148933665887105 | validation: 0.3950096344690982]
	TIME [epoch: 24.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39650424310662863		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.39650424310662863 | validation: 0.314009087438226]
	TIME [epoch: 24.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4278436288141266		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.4278436288141266 | validation: 0.4176966823962643]
	TIME [epoch: 24.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38415827794746205		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.38415827794746205 | validation: 0.41117517023165073]
	TIME [epoch: 24.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3218056792228613		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.3218056792228613 | validation: 0.2219974683930962]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2638054140113145		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.2638054140113145 | validation: 0.2932254036440214]
	TIME [epoch: 25 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27783162722704224		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.27783162722704224 | validation: 0.24909650889196935]
	TIME [epoch: 24.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23408168509930796		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.23408168509930796 | validation: 0.25161237866890795]
	TIME [epoch: 24.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3095944047587481		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.3095944047587481 | validation: 0.21505324302662787]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_430.pth
	Model improved!!!
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24150431003180148		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.24150431003180148 | validation: 0.23226711926240193]
	TIME [epoch: 24.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30908441866408687		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.30908441866408687 | validation: 0.4496232708628304]
	TIME [epoch: 24.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.442074802690063		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.442074802690063 | validation: 0.27002321404762447]
	TIME [epoch: 24.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907452076535266		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.2907452076535266 | validation: 0.29435640145544406]
	TIME [epoch: 24.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3233441923767477		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.3233441923767477 | validation: 0.34106221860331315]
	TIME [epoch: 24.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.369198549733356		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.369198549733356 | validation: 0.38200138886708884]
	TIME [epoch: 24.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3479312421363847		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.3479312421363847 | validation: 0.30366642041166797]
	TIME [epoch: 24.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28408796965647354		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.28408796965647354 | validation: 0.22865731952335658]
	TIME [epoch: 24.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2447478466822704		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.2447478466822704 | validation: 0.2421731897338043]
	TIME [epoch: 24.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33025527941117866		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.33025527941117866 | validation: 0.37499101098679405]
	TIME [epoch: 24.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35623213035522716		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.35623213035522716 | validation: 0.22920738847801925]
	TIME [epoch: 24.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27354805040965635		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.27354805040965635 | validation: 0.31635473777955603]
	TIME [epoch: 24.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2967088522140048		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.2967088522140048 | validation: 0.2715998496936113]
	TIME [epoch: 24.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3033869466355995		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.3033869466355995 | validation: 0.2832418874932343]
	TIME [epoch: 24.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32349514208317115		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.32349514208317115 | validation: 0.2818157107669278]
	TIME [epoch: 24.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39134195562414753		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.39134195562414753 | validation: 0.5825578045245314]
	TIME [epoch: 24.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.751297912942637		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.751297912942637 | validation: 0.7354917921723557]
	TIME [epoch: 24.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.790363585512136		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.790363585512136 | validation: 0.5383815119723607]
	TIME [epoch: 24.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5681026165076495		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.5681026165076495 | validation: 0.44733024556198503]
	TIME [epoch: 24.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5264073529023017		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.5264073529023017 | validation: 0.5210592702439639]
	TIME [epoch: 24.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5859819976078717		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.5859819976078717 | validation: 0.526363852590061]
	TIME [epoch: 24.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4431273826690489		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.4431273826690489 | validation: 0.7422809437456738]
	TIME [epoch: 24.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5955146976074487		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.5955146976074487 | validation: 0.31790678470098244]
	TIME [epoch: 24.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36275011562103504		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.36275011562103504 | validation: 0.23895759056328203]
	TIME [epoch: 24.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35394748004972926		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.35394748004972926 | validation: 0.38969927711697594]
	TIME [epoch: 24.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4096234192523165		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.4096234192523165 | validation: 0.5141956212524614]
	TIME [epoch: 24.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5299015526669499		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.5299015526669499 | validation: 0.428000498181201]
	TIME [epoch: 25 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4293975930992485		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.4293975930992485 | validation: 0.5424869077543503]
	TIME [epoch: 24.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5216451096505565		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.5216451096505565 | validation: 0.49850275327248567]
	TIME [epoch: 24.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48261492522239047		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.48261492522239047 | validation: 0.4067987392538099]
	TIME [epoch: 24.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40046805255539725		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.40046805255539725 | validation: 0.37394523005418623]
	TIME [epoch: 24.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3094137290844481		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.3094137290844481 | validation: 0.2501663855472889]
	TIME [epoch: 24.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3067327982593986		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.3067327982593986 | validation: 0.3264533637474956]
	TIME [epoch: 25 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3207760167701027		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.3207760167701027 | validation: 0.3784713507396557]
	TIME [epoch: 24.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3142157766334951		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.3142157766334951 | validation: 0.369478677799219]
	TIME [epoch: 24.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.326838513865932		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.326838513865932 | validation: 0.47995963818858933]
	TIME [epoch: 24.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771085361287075		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.4771085361287075 | validation: 0.3338393716636663]
	TIME [epoch: 24.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34155629892524153		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.34155629892524153 | validation: 0.41914906163777105]
	TIME [epoch: 24.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3388535480312736		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.3388535480312736 | validation: 0.3033232273515465]
	TIME [epoch: 25 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24272163758550971		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.24272163758550971 | validation: 0.23275108867708497]
	TIME [epoch: 24.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44009429620801016		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.44009429620801016 | validation: 0.6305404473431123]
	TIME [epoch: 24.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832884478791807		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.6832884478791807 | validation: 0.9579441231268058]
	TIME [epoch: 25 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.689073139746069		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.689073139746069 | validation: 0.42219167748436703]
	TIME [epoch: 24.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.442827277634418		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.442827277634418 | validation: 0.3060298749508929]
	TIME [epoch: 24.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4291954131012811		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.4291954131012811 | validation: 0.4527853174562001]
	TIME [epoch: 24.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4021850662797804		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.4021850662797804 | validation: 0.2953127728729888]
	TIME [epoch: 24.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3299496138425209		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.3299496138425209 | validation: 0.31082419219247515]
	TIME [epoch: 24.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2991738006257306		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.2991738006257306 | validation: 0.23209665529613183]
	TIME [epoch: 25 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29975916286209425		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.29975916286209425 | validation: 0.24786489476671558]
	TIME [epoch: 24.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25722317855518184		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.25722317855518184 | validation: 0.23333916710042416]
	TIME [epoch: 24.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23865055081219255		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.23865055081219255 | validation: 0.23705210039995797]
	TIME [epoch: 25 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2347990639331006		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.2347990639331006 | validation: 0.28954102628678974]
	TIME [epoch: 25 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34996122366967036		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.34996122366967036 | validation: 0.2528867100533481]
	TIME [epoch: 24.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26196774855757193		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.26196774855757193 | validation: 0.2804985998857368]
	TIME [epoch: 25 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44758812057115915		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.44758812057115915 | validation: 0.679647179674262]
	TIME [epoch: 24.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.407882521869227		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.407882521869227 | validation: 0.28684190584973096]
	TIME [epoch: 24.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2803416155043539		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.2803416155043539 | validation: 0.20708552003592787]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_487.pth
	Model improved!!!
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22464821585954173		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.22464821585954173 | validation: 0.3059428110120397]
	TIME [epoch: 24.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46454255969043307		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.46454255969043307 | validation: 0.5872893080706725]
	TIME [epoch: 25 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677350672103172		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.5677350672103172 | validation: 0.3733636517248645]
	TIME [epoch: 25 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3074821537883658		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.3074821537883658 | validation: 0.30367575930070895]
	TIME [epoch: 25 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37918312938267806		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.37918312938267806 | validation: 0.40466539928951095]
	TIME [epoch: 25 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4125427209091288		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.4125427209091288 | validation: 0.5648539597161809]
	TIME [epoch: 24.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4571745141047895		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.4571745141047895 | validation: 0.33423404660954276]
	TIME [epoch: 25 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5700496582298787		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.5700496582298787 | validation: 0.5083425124362687]
	TIME [epoch: 24.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.555516623089434		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.555516623089434 | validation: 0.6791631512609319]
	TIME [epoch: 25 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6053382791643127		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.6053382791643127 | validation: 0.5450913140420067]
	TIME [epoch: 25 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6140114971521864		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.6140114971521864 | validation: 0.6932828621035821]
	TIME [epoch: 25 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6180172552638715		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.6180172552638715 | validation: 0.36819746947187854]
	TIME [epoch: 25 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32012609011892157		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.32012609011892157 | validation: 0.229506994234233]
	TIME [epoch: 25 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.276760437225264		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.276760437225264 | validation: 0.2819128151966712]
	TIME [epoch: 25 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44384174349528316		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.44384174349528316 | validation: 0.6900646864786525]
	TIME [epoch: 25 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542305713044064		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.542305713044064 | validation: 0.5000399072165542]
	TIME [epoch: 25 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4988464291469452		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.4988464291469452 | validation: 0.4224886377353987]
	TIME [epoch: 24.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39583734564426887		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.39583734564426887 | validation: 0.3045110342107478]
	TIME [epoch: 25 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3219673411345087		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.3219673411345087 | validation: 0.2842545099462498]
	TIME [epoch: 24.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3445471196380183		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.3445471196380183 | validation: 0.5096942693026252]
	TIME [epoch: 24.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3669015936712364		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.3669015936712364 | validation: 0.29680769764296694]
	TIME [epoch: 25 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2959699821472051		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.2959699821472051 | validation: 0.31362833610824065]
	TIME [epoch: 25 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3001953721293792		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.3001953721293792 | validation: 0.3791505946607251]
	TIME [epoch: 24.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31052004624900154		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.31052004624900154 | validation: 0.27222040810298653]
	TIME [epoch: 25 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42302404162458446		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.42302404162458446 | validation: 0.6067406622414449]
	TIME [epoch: 25 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6041106600559637		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.6041106600559637 | validation: 0.489886041205828]
	TIME [epoch: 24.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4511359306084566		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.4511359306084566 | validation: 0.35992689204235456]
	TIME [epoch: 25 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34472319124613365		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.34472319124613365 | validation: 0.37860263761501317]
	TIME [epoch: 25 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38468607143514266		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.38468607143514266 | validation: 0.37543066646646267]
	TIME [epoch: 25 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3782947167788738		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.3782947167788738 | validation: 0.30966877953131655]
	TIME [epoch: 24.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3166313610682554		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.3166313610682554 | validation: 0.39506560490260917]
	TIME [epoch: 25 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4042893235293653		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.4042893235293653 | validation: 0.3897006470736852]
	TIME [epoch: 24.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36126413780886607		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.36126413780886607 | validation: 0.3535137414776434]
	TIME [epoch: 25 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35266617462893146		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.35266617462893146 | validation: 0.32829584320090777]
	TIME [epoch: 25 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33065632622630414		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.33065632622630414 | validation: 0.34523585332211537]
	TIME [epoch: 25 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34867344161820163		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.34867344161820163 | validation: 0.27798586416852067]
	TIME [epoch: 25 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.303683711338906		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.303683711338906 | validation: 0.3086390309065678]
	TIME [epoch: 25 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32183039703936045		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.32183039703936045 | validation: 0.4190909074862757]
	TIME [epoch: 25 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3960805790118769		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.3960805790118769 | validation: 0.300117326152447]
	TIME [epoch: 25 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32066134307005284		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.32066134307005284 | validation: 0.29512213371208923]
	TIME [epoch: 25 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35759303148310734		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.35759303148310734 | validation: 0.33263969811580824]
	TIME [epoch: 25 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41582544465054805		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.41582544465054805 | validation: 0.5386128065536671]
	TIME [epoch: 25 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5601620181811174		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.5601620181811174 | validation: 0.5500228757619019]
	TIME [epoch: 25 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6579414588087666		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.6579414588087666 | validation: 0.5002845212597233]
	TIME [epoch: 24.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42294512952955055		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.42294512952955055 | validation: 0.341831453732389]
	TIME [epoch: 25 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3974539008929161		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.3974539008929161 | validation: 0.32414602782241037]
	TIME [epoch: 25 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30828895088231456		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.30828895088231456 | validation: 0.3034506838987482]
	TIME [epoch: 24.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3278962508120583		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.3278962508120583 | validation: 0.30605304552636464]
	TIME [epoch: 25 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3914195716082249		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.3914195716082249 | validation: 0.4439337120231881]
	TIME [epoch: 25 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41876141263351724		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.41876141263351724 | validation: 0.3599577581392778]
	TIME [epoch: 24.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2843429633850368		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.2843429633850368 | validation: 0.2600284061244437]
	TIME [epoch: 25 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35078332167222565		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.35078332167222565 | validation: 0.3283540550781457]
	TIME [epoch: 25 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3560438577013025		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.3560438577013025 | validation: 0.33443763172459684]
	TIME [epoch: 24.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4642041405019135		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.4642041405019135 | validation: 0.47923306217913214]
	TIME [epoch: 25 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4662291122519074		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.4662291122519074 | validation: 0.37639663423608055]
	TIME [epoch: 25 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42560493517096676		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.42560493517096676 | validation: 0.3466716644168375]
	TIME [epoch: 24.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3856782753408854		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.3856782753408854 | validation: 0.27487805761442863]
	TIME [epoch: 25 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2751233989442039		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.2751233989442039 | validation: 0.23262775490065576]
	TIME [epoch: 25 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2644514624653936		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.2644514624653936 | validation: 0.31554593544266296]
	TIME [epoch: 24.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2952984416458484		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.2952984416458484 | validation: 0.3757959221098306]
	TIME [epoch: 24.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3515278949918743		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.3515278949918743 | validation: 0.22063209198209285]
	TIME [epoch: 24.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25381828213621893		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.25381828213621893 | validation: 0.4432573386430613]
	TIME [epoch: 24.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4900829770649933		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.4900829770649933 | validation: 0.31087688499478866]
	TIME [epoch: 25 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3358207593118525		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.3358207593118525 | validation: 0.35840170850258873]
	TIME [epoch: 25 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4205904196602919		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.4205904196602919 | validation: 0.3106597868048803]
	TIME [epoch: 24.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766534949678956		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.2766534949678956 | validation: 0.2325675732053109]
	TIME [epoch: 24.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2619520313688538		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.2619520313688538 | validation: 0.32561534795293495]
	TIME [epoch: 24.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42774580624045366		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.42774580624045366 | validation: 0.3355326948940976]
	TIME [epoch: 24.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3737519574260323		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.3737519574260323 | validation: 0.2360966812533605]
	TIME [epoch: 24.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586104782057176		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.2586104782057176 | validation: 0.24142685904172922]
	TIME [epoch: 25 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2822554749957104		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.2822554749957104 | validation: 0.33101743712076453]
	TIME [epoch: 24.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45359325235182124		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.45359325235182124 | validation: 0.2922376268506572]
	TIME [epoch: 25 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36177444399757286		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.36177444399757286 | validation: 0.22174151261068012]
	TIME [epoch: 24.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3073955287236496		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.3073955287236496 | validation: 0.2647362696538299]
	TIME [epoch: 24.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26749667491598306		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.26749667491598306 | validation: 0.18434066979598573]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30124494386615513		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.30124494386615513 | validation: 0.33853223919981984]
	TIME [epoch: 24.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45033000585992533		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.45033000585992533 | validation: 0.39235769752178534]
	TIME [epoch: 24.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36583993734655446		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.36583993734655446 | validation: 0.34307946416914364]
	TIME [epoch: 25 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32825675269520704		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.32825675269520704 | validation: 0.21497215104056935]
	TIME [epoch: 25 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2642227299168004		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.2642227299168004 | validation: 0.35943182691547576]
	TIME [epoch: 24.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3496464800028112		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.3496464800028112 | validation: 0.4102688711234423]
	TIME [epoch: 25 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.414121425771219		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.414121425771219 | validation: 0.3902823376900855]
	TIME [epoch: 25 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41888959884654386		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.41888959884654386 | validation: 0.4051333546042116]
	TIME [epoch: 24.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4459084792729866		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.4459084792729866 | validation: 0.42585347681873537]
	TIME [epoch: 25 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3701077546503096		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.3701077546503096 | validation: 0.26727719305981157]
	TIME [epoch: 24.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3072595003089711		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.3072595003089711 | validation: 0.21826926127796725]
	TIME [epoch: 24.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543511538073901		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.3543511538073901 | validation: 0.28663281389062273]
	TIME [epoch: 24.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3110595399700883		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.3110595399700883 | validation: 0.349029366654631]
	TIME [epoch: 24.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3426419456730546		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.3426419456730546 | validation: 0.2685879477626707]
	TIME [epoch: 24.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22161739845504028		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.22161739845504028 | validation: 0.1818592574864845]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22326244765939918		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.22326244765939918 | validation: 0.3259822641959594]
	TIME [epoch: 24.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31267933726327174		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.31267933726327174 | validation: 0.2629812604793855]
	TIME [epoch: 24.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22452846364675716		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.22452846364675716 | validation: 0.1854704211400003]
	TIME [epoch: 24.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19188313172082944		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.19188313172082944 | validation: 0.19594084985873714]
	TIME [epoch: 24.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1906433449602896		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.1906433449602896 | validation: 0.28783274005050485]
	TIME [epoch: 24.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26926674146892693		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.26926674146892693 | validation: 0.22105505739558332]
	TIME [epoch: 24.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20171359530476918		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.20171359530476918 | validation: 0.16899180126273713]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_584.pth
	Model improved!!!
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2080810193384269		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.2080810193384269 | validation: 0.20940407286514792]
	TIME [epoch: 24.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24927626025949845		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.24927626025949845 | validation: 0.4216548033974873]
	TIME [epoch: 24.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34772700520776983		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.34772700520776983 | validation: 0.2609937572611906]
	TIME [epoch: 25 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2275549930034685		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.2275549930034685 | validation: 0.21898949137340754]
	TIME [epoch: 24.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21386963490608538		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.21386963490608538 | validation: 0.21495590705632175]
	TIME [epoch: 24.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25733829579743656		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.25733829579743656 | validation: 0.2577429820893696]
	TIME [epoch: 25 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2362370603083524		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.2362370603083524 | validation: 0.32609586122201634]
	TIME [epoch: 24.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3737190886393601		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.3737190886393601 | validation: 0.23207250085002593]
	TIME [epoch: 24.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20900966981946745		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.20900966981946745 | validation: 0.15858077706967205]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_593.pth
	Model improved!!!
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19475437391682685		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.19475437391682685 | validation: 0.2564709460025841]
	TIME [epoch: 24.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2783694619746957		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.2783694619746957 | validation: 0.20748091680508296]
	TIME [epoch: 24.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.203860487886167		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.203860487886167 | validation: 0.17738846120786467]
	TIME [epoch: 25 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19779016228433244		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.19779016228433244 | validation: 0.18591374925545673]
	TIME [epoch: 24.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21144545919829955		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.21144545919829955 | validation: 0.2331782109718405]
	TIME [epoch: 24.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30794061856633814		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.30794061856633814 | validation: 0.3929401310573322]
	TIME [epoch: 24.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4186350361331365		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.4186350361331365 | validation: 0.3732059881476317]
	TIME [epoch: 24.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40284500575631543		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.40284500575631543 | validation: 0.2764124299388751]
	TIME [epoch: 24.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2894031620717262		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.2894031620717262 | validation: 0.6114353694105877]
	TIME [epoch: 24.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9201550703978874		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.9201550703978874 | validation: 0.7976825362881245]
	TIME [epoch: 24.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7577035064357686		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.7577035064357686 | validation: 0.6535936306009791]
	TIME [epoch: 24.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5915578645095573		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.5915578645095573 | validation: 0.4011023654540873]
	TIME [epoch: 24.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3954762948809627		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.3954762948809627 | validation: 0.38142682744062]
	TIME [epoch: 24.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3236739563002785		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.3236739563002785 | validation: 0.24886850507569463]
	TIME [epoch: 24.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23415244776165808		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.23415244776165808 | validation: 0.22712572429460254]
	TIME [epoch: 24.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21474255248137872		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.21474255248137872 | validation: 0.21738121435912333]
	TIME [epoch: 24.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22046224915489127		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.22046224915489127 | validation: 0.21918199918077677]
	TIME [epoch: 25 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2695755649919013		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.2695755649919013 | validation: 0.4085365235826376]
	TIME [epoch: 25 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5801695194177461		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.5801695194177461 | validation: 0.43443528875241233]
	TIME [epoch: 24.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43107128608946704		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.43107128608946704 | validation: 0.5894780062472894]
	TIME [epoch: 24.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4634865062176168		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.4634865062176168 | validation: 0.35140177376611886]
	TIME [epoch: 25 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32716925734656666		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.32716925734656666 | validation: 0.29264117479282714]
	TIME [epoch: 24.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24076085969564312		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.24076085969564312 | validation: 0.21718944108801655]
	TIME [epoch: 25 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24002484145855973		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.24002484145855973 | validation: 0.21798413834803085]
	TIME [epoch: 25 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2301841200736856		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.2301841200736856 | validation: 0.21115860200140815]
	TIME [epoch: 24.9 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2607647500804467		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.2607647500804467 | validation: 0.32803767520800803]
	TIME [epoch: 24.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36412649302350186		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.36412649302350186 | validation: 0.2773086465231527]
	TIME [epoch: 25 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28781630044674594		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.28781630044674594 | validation: 0.3883213628434578]
	TIME [epoch: 24.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3948468596349601		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.3948468596349601 | validation: 0.3067171226434315]
	TIME [epoch: 24.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27732210832109466		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.27732210832109466 | validation: 0.22199077235902911]
	TIME [epoch: 24.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18473929603542505		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.18473929603542505 | validation: 0.14940322615346502]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_624.pth
	Model improved!!!
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838129530341948		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.1838129530341948 | validation: 0.19137862431830424]
	TIME [epoch: 24.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18497702039651115		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.18497702039651115 | validation: 0.20875486895258338]
	TIME [epoch: 24.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2199598456127188		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.2199598456127188 | validation: 0.23850442877985692]
	TIME [epoch: 24.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23494042739200094		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.23494042739200094 | validation: 0.3125107980109092]
	TIME [epoch: 24.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3674474722396227		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.3674474722396227 | validation: 0.431362267214857]
	TIME [epoch: 25 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44433620317317996		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.44433620317317996 | validation: 0.3338666074705429]
	TIME [epoch: 25 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3052423945047167		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.3052423945047167 | validation: 0.2236975187022874]
	TIME [epoch: 24.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21066245308890016		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.21066245308890016 | validation: 0.16626980366970875]
	TIME [epoch: 25 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17463746721684495		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.17463746721684495 | validation: 0.15893161760357244]
	TIME [epoch: 24.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2028247829348685		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.2028247829348685 | validation: 0.2938081522676626]
	TIME [epoch: 24.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25656467569068026		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.25656467569068026 | validation: 0.1900316976857411]
	TIME [epoch: 24.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.238629814897402		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.238629814897402 | validation: 0.2783177262597002]
	TIME [epoch: 25 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2593365582192156		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.2593365582192156 | validation: 0.2415489825309659]
	TIME [epoch: 24.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2581699727100118		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.2581699727100118 | validation: 0.13955274087746009]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_638.pth
	Model improved!!!
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16657977339618485		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.16657977339618485 | validation: 0.1617245467933856]
	TIME [epoch: 24.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16537415562631883		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.16537415562631883 | validation: 0.15926638185053663]
	TIME [epoch: 24.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2573266918185495		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.2573266918185495 | validation: 0.2977478101788262]
	TIME [epoch: 24.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3433926624383044		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.3433926624383044 | validation: 0.38306412705559967]
	TIME [epoch: 24.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3580694442422896		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.3580694442422896 | validation: 0.24208152708825836]
	TIME [epoch: 24.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23625224632393205		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.23625224632393205 | validation: 0.18084697049412626]
	TIME [epoch: 24.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17098708166850424		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.17098708166850424 | validation: 0.18079582509843026]
	TIME [epoch: 24.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3026146441838492		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.3026146441838492 | validation: 0.36218987195124897]
	TIME [epoch: 24.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36020446687711277		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.36020446687711277 | validation: 0.2374577834163224]
	TIME [epoch: 24.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23376207413016686		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.23376207413016686 | validation: 0.16813995920582328]
	TIME [epoch: 24.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15692914095117827		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.15692914095117827 | validation: 0.1664994401121007]
	TIME [epoch: 24.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3190599153735732		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.3190599153735732 | validation: 0.506307883881139]
	TIME [epoch: 24.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8097895579854479		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.8097895579854479 | validation: 1.0119413454202215]
	TIME [epoch: 24.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9801136573466193		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.9801136573466193 | validation: 0.6459276933776934]
	TIME [epoch: 24.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6453937145627766		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.6453937145627766 | validation: 0.3327023978737873]
	TIME [epoch: 24.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.290901434148631		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.290901434148631 | validation: 0.1619926752926034]
	TIME [epoch: 24.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17293145268453067		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.17293145268453067 | validation: 0.12555249571323482]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_655.pth
	Model improved!!!
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381555312025466		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.1381555312025466 | validation: 0.13245489095213586]
	TIME [epoch: 24.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17599277672120794		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.17599277672120794 | validation: 0.16925471392236083]
	TIME [epoch: 24.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15941683786971828		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.15941683786971828 | validation: 0.13465629052870953]
	TIME [epoch: 24.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14683341460234778		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.14683341460234778 | validation: 0.17707278104712423]
	TIME [epoch: 24.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1972446555208842		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.1972446555208842 | validation: 0.19431599165313643]
	TIME [epoch: 24.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1840621588393548		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.1840621588393548 | validation: 0.18434155980211944]
	TIME [epoch: 24.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.197088216790331		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.197088216790331 | validation: 0.2397341371623778]
	TIME [epoch: 24.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2068311880109961		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.2068311880109961 | validation: 0.21037769538367948]
	TIME [epoch: 24.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2468267910732082		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.2468267910732082 | validation: 0.3381892903013856]
	TIME [epoch: 24.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802574256974059		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.2802574256974059 | validation: 0.299872877050736]
	TIME [epoch: 24.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3317121019692234		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.3317121019692234 | validation: 0.29729377449252453]
	TIME [epoch: 24.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3053641603535466		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.3053641603535466 | validation: 0.2711794501344008]
	TIME [epoch: 24.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2559774049060881		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.2559774049060881 | validation: 0.2988110488701017]
	TIME [epoch: 24.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34254279927180853		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.34254279927180853 | validation: 0.3558806257364526]
	TIME [epoch: 24.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3139358848869267		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.3139358848869267 | validation: 0.25312160502495934]
	TIME [epoch: 24.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19984426901460228		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.19984426901460228 | validation: 0.18136361980986798]
	TIME [epoch: 24.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17517941640052445		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.17517941640052445 | validation: 0.17237201253262172]
	TIME [epoch: 24.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19952500026261333		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.19952500026261333 | validation: 0.16355150242275415]
	TIME [epoch: 24.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18194786670893753		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.18194786670893753 | validation: 0.21300409324582922]
	TIME [epoch: 24.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21060990736482904		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.21060990736482904 | validation: 0.1686544312450238]
	TIME [epoch: 24.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17961107887605526		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.17961107887605526 | validation: 0.17688065952750698]
	TIME [epoch: 24.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19103332965965064		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.19103332965965064 | validation: 0.1507609563211167]
	TIME [epoch: 24.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17760992560276193		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.17760992560276193 | validation: 0.18782017661512457]
	TIME [epoch: 24.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1974158406342969		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.1974158406342969 | validation: 0.15231922000657075]
	TIME [epoch: 24.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14826763707726648		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.14826763707726648 | validation: 0.16902705145311045]
	TIME [epoch: 24.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16363115189845068		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.16363115189845068 | validation: 0.13693351251181157]
	TIME [epoch: 24.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14384789590972452		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.14384789590972452 | validation: 0.17106827562117538]
	TIME [epoch: 24.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1615495383329996		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.1615495383329996 | validation: 0.17231477498684875]
	TIME [epoch: 24.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21675953746022014		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.21675953746022014 | validation: 0.2799587034722347]
	TIME [epoch: 24.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30483365581853034		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.30483365581853034 | validation: 0.3231561647918981]
	TIME [epoch: 24.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3457346673676924		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.3457346673676924 | validation: 0.297702879813193]
	TIME [epoch: 24.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2502478319763656		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.2502478319763656 | validation: 0.2076858378571089]
	TIME [epoch: 24.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1801893249016611		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.1801893249016611 | validation: 0.15409763581943944]
	TIME [epoch: 24.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1581105071487598		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.1581105071487598 | validation: 0.1630161853331774]
	TIME [epoch: 24.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19997550188162877		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.19997550188162877 | validation: 0.24963794751522586]
	TIME [epoch: 24.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24115868252376957		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.24115868252376957 | validation: 0.21623642526996706]
	TIME [epoch: 24.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2125559195821745		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.2125559195821745 | validation: 0.20410909338509342]
	TIME [epoch: 24.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20287103665741263		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.20287103665741263 | validation: 0.19056495471975143]
	TIME [epoch: 24.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17791025889334033		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.17791025889334033 | validation: 0.14064241353860996]
	TIME [epoch: 24.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15098755627129154		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.15098755627129154 | validation: 0.12528221029572353]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_695.pth
	Model improved!!!
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14897328612009245		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.14897328612009245 | validation: 0.14147531809110173]
	TIME [epoch: 24.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18847555130160923		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.18847555130160923 | validation: 0.19349330754148905]
	TIME [epoch: 24.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23235184077131604		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.23235184077131604 | validation: 0.18151098013280384]
	TIME [epoch: 24.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22775083191447246		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.22775083191447246 | validation: 0.2632825606700363]
	TIME [epoch: 24.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.287188010967285		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.287188010967285 | validation: 0.2886702103623408]
	TIME [epoch: 24.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2740118916056765		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.2740118916056765 | validation: 0.24495203209381103]
	TIME [epoch: 24.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24591322603671517		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.24591322603671517 | validation: 0.24053954864164276]
	TIME [epoch: 24.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24504173862099915		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.24504173862099915 | validation: 0.19758092372078287]
	TIME [epoch: 24.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1829077616415989		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.1829077616415989 | validation: 0.16357875502118827]
	TIME [epoch: 25 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20110904901302265		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.20110904901302265 | validation: 0.2319837466568626]
	TIME [epoch: 24.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18049187805373662		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.18049187805373662 | validation: 0.1575553707358781]
	TIME [epoch: 24.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19724278253267166		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.19724278253267166 | validation: 0.21809747418661726]
	TIME [epoch: 24.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21073909130201457		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.21073909130201457 | validation: 0.17454476249317594]
	TIME [epoch: 25 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1750141796469332		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.1750141796469332 | validation: 0.13564144215228183]
	TIME [epoch: 24.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15431131024802336		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.15431131024802336 | validation: 0.18577448378134892]
	TIME [epoch: 25 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1796455122170474		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.1796455122170474 | validation: 0.1577372026031312]
	TIME [epoch: 25 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1703977182051192		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.1703977182051192 | validation: 0.2658566936951991]
	TIME [epoch: 24.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26854684290609876		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.26854684290609876 | validation: 0.20768759477444543]
	TIME [epoch: 24.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24262977598545532		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.24262977598545532 | validation: 0.3086376316988244]
	TIME [epoch: 24.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3011963991677796		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.3011963991677796 | validation: 0.329796738081085]
	TIME [epoch: 24.9 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27914105702239533		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.27914105702239533 | validation: 0.2337492854284367]
	TIME [epoch: 24.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20869764350472772		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.20869764350472772 | validation: 0.2621622393192073]
	TIME [epoch: 25 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25088660715412014		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.25088660715412014 | validation: 0.2650402418779041]
	TIME [epoch: 24.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28024537513767817		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.28024537513767817 | validation: 0.3044206251815273]
	TIME [epoch: 24.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848831791388414		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.2848831791388414 | validation: 0.2657229587127815]
	TIME [epoch: 24.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24702841315470703		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.24702841315470703 | validation: 0.1952045355153882]
	TIME [epoch: 24.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24139040805152484		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.24139040805152484 | validation: 0.2508667802452439]
	TIME [epoch: 24.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20678342516880163		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.20678342516880163 | validation: 0.13938802900096078]
	TIME [epoch: 24.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14808313987443317		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.14808313987443317 | validation: 0.14090112270646069]
	TIME [epoch: 24.9 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15692014196919046		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.15692014196919046 | validation: 0.1500460075015287]
	TIME [epoch: 24.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15028515482204763		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.15028515482204763 | validation: 0.1808487230163877]
	TIME [epoch: 24.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1917739700638052		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.1917739700638052 | validation: 0.1828627563636784]
	TIME [epoch: 24.9 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20787479795228614		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.20787479795228614 | validation: 0.1963292037284977]
	TIME [epoch: 24.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1609901472752724		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.1609901472752724 | validation: 0.1561182186514688]
	TIME [epoch: 24.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16177879521822502		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.16177879521822502 | validation: 0.15571019455861823]
	TIME [epoch: 24.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15636512475036374		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.15636512475036374 | validation: 0.14353163973552063]
	TIME [epoch: 24.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19464467362257826		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.19464467362257826 | validation: 0.2543648665293071]
	TIME [epoch: 24.9 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20690275804545294		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.20690275804545294 | validation: 0.14801219676029498]
	TIME [epoch: 24.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14565744578133347		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.14565744578133347 | validation: 0.12779990785071432]
	TIME [epoch: 24.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17326273878111362		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.17326273878111362 | validation: 0.15587292374212885]
	TIME [epoch: 24.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19220495268027643		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.19220495268027643 | validation: 0.19928366363988084]
	TIME [epoch: 24.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19112562186331597		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.19112562186331597 | validation: 0.1723848620760425]
	TIME [epoch: 24.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21045805768164932		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.21045805768164932 | validation: 0.2267076107633001]
	TIME [epoch: 24.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22993115288793387		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.22993115288793387 | validation: 0.20967936002603046]
	TIME [epoch: 24.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25430382802037765		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.25430382802037765 | validation: 0.1787656469971559]
	TIME [epoch: 24.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15669029685125688		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.15669029685125688 | validation: 0.1812942580765721]
	TIME [epoch: 24.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19448320039154837		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.19448320039154837 | validation: 0.1675881633124348]
	TIME [epoch: 24.9 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20939388824750654		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.20939388824750654 | validation: 0.22142495380558905]
	TIME [epoch: 24.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2889041921885496		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.2889041921885496 | validation: 0.27234491957944096]
	TIME [epoch: 24.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29111905638401436		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.29111905638401436 | validation: 0.25789015884527877]
	TIME [epoch: 24.9 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2508505140269778		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.2508505140269778 | validation: 0.2024104674301482]
	TIME [epoch: 24.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2503833296783585		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.2503833296783585 | validation: 0.24366886320227896]
	TIME [epoch: 24.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23451450238880805		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.23451450238880805 | validation: 0.16210956117414804]
	TIME [epoch: 24.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635574864363164		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.1635574864363164 | validation: 0.1340887751702585]
	TIME [epoch: 25 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536711542180885		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.1536711542180885 | validation: 0.15102107314173263]
	TIME [epoch: 25 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16916876272627637		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.16916876272627637 | validation: 0.19605391951104476]
	TIME [epoch: 24.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2103821552709598		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.2103821552709598 | validation: 0.2508173391962097]
	TIME [epoch: 24.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22809284944544855		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.22809284944544855 | validation: 0.1578714995515459]
	TIME [epoch: 24.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15729500273957764		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.15729500273957764 | validation: 0.13930353138445475]
	TIME [epoch: 24.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16314541425105808		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.16314541425105808 | validation: 0.15672397271750757]
	TIME [epoch: 25 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2029197488595183		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.2029197488595183 | validation: 0.3264300183505054]
	TIME [epoch: 25 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3042577947915738		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.3042577947915738 | validation: 0.17892584333966385]
	TIME [epoch: 24.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21231363173045273		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.21231363173045273 | validation: 0.2020870772560496]
	TIME [epoch: 24.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19911490526981265		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.19911490526981265 | validation: 0.14557095117721525]
	TIME [epoch: 24.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16614419789381477		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.16614419789381477 | validation: 0.15074640253752902]
	TIME [epoch: 24.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1491890030018425		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.1491890030018425 | validation: 0.12056422589941956]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_761.pth
	Model improved!!!
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283566518924089		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.1283566518924089 | validation: 0.13364476731554675]
	TIME [epoch: 25 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15882067147774834		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.15882067147774834 | validation: 0.13199264962694587]
	TIME [epoch: 24.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460443288272467		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.1460443288272467 | validation: 0.18997312706563918]
	TIME [epoch: 25 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22338416637948633		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.22338416637948633 | validation: 0.30333987276109065]
	TIME [epoch: 25 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.334622795162836		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.334622795162836 | validation: 0.34821495941882935]
	TIME [epoch: 24.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3613455750988767		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.3613455750988767 | validation: 0.3052757300750195]
	TIME [epoch: 25 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30514076907097437		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.30514076907097437 | validation: 0.2845764270120957]
	TIME [epoch: 25 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3559424123340116		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.3559424123340116 | validation: 0.34920305741131075]
	TIME [epoch: 25 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3345593394622689		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.3345593394622689 | validation: 0.2747209523395344]
	TIME [epoch: 25 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2957092128129654		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.2957092128129654 | validation: 0.2564730897017589]
	TIME [epoch: 25 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3410287671058237		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.3410287671058237 | validation: 0.4363671980281001]
	TIME [epoch: 25 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4212674186619416		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.4212674186619416 | validation: 0.33388566102531314]
	TIME [epoch: 25 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3320694644543615		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.3320694644543615 | validation: 0.2567602105225685]
	TIME [epoch: 25 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2274235480756694		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.2274235480756694 | validation: 0.17503427511298614]
	TIME [epoch: 24.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18838259559843734		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.18838259559843734 | validation: 0.23419328761358138]
	TIME [epoch: 24.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25695693161717625		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.25695693161717625 | validation: 0.2438594578794448]
	TIME [epoch: 25 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2188474269825457		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.2188474269825457 | validation: 0.16259504307256087]
	TIME [epoch: 24.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15572205297867955		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.15572205297867955 | validation: 0.12415217115485713]
	TIME [epoch: 25 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14944072327351224		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.14944072327351224 | validation: 0.14305325423910287]
	TIME [epoch: 25 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753020247903563		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.13753020247903563 | validation: 0.1138730670935388]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_781.pth
	Model improved!!!
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13965154870733773		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.13965154870733773 | validation: 0.13130406453892607]
	TIME [epoch: 25 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16630347524716094		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.16630347524716094 | validation: 0.17514963766805727]
	TIME [epoch: 25 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1876196832865139		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.1876196832865139 | validation: 0.14880436323636945]
	TIME [epoch: 25 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464818089019772		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.1464818089019772 | validation: 0.1316374132908419]
	TIME [epoch: 25 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14147305768183624		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.14147305768183624 | validation: 0.12593577998767486]
	TIME [epoch: 25 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14539467462838818		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.14539467462838818 | validation: 0.12371233388450946]
	TIME [epoch: 25 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16546757228070896		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.16546757228070896 | validation: 0.19133178231226475]
	TIME [epoch: 25 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25912593102571013		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.25912593102571013 | validation: 0.19330411458361593]
	TIME [epoch: 25 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18213828125773934		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.18213828125773934 | validation: 0.12768079167608964]
	TIME [epoch: 25 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14084603092424203		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.14084603092424203 | validation: 0.1442810197673828]
	TIME [epoch: 25 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14254851301937244		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.14254851301937244 | validation: 0.14914004549723942]
	TIME [epoch: 25 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14852552627832705		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.14852552627832705 | validation: 0.14660014856982442]
	TIME [epoch: 24.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16524992869219854		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.16524992869219854 | validation: 0.17334050346320656]
	TIME [epoch: 25 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17065415212795115		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.17065415212795115 | validation: 0.14505867016108764]
	TIME [epoch: 25 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16837909230943204		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.16837909230943204 | validation: 0.2043806768932965]
	TIME [epoch: 25 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.220585138348177		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.220585138348177 | validation: 0.2305761224775204]
	TIME [epoch: 25 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20128873043865594		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.20128873043865594 | validation: 0.15303352507533174]
	TIME [epoch: 25 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14893528284501423		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.14893528284501423 | validation: 0.12031501484129412]
	TIME [epoch: 25 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13773894548415222		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.13773894548415222 | validation: 0.12563939204354146]
	TIME [epoch: 24.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13873082121929403		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.13873082121929403 | validation: 0.11544925313916923]
	TIME [epoch: 25 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325958286822046		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.1325958286822046 | validation: 0.13886602902917577]
	TIME [epoch: 25 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1909028052649277		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.1909028052649277 | validation: 0.21831167633331472]
	TIME [epoch: 25 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38683076083998646		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.38683076083998646 | validation: 0.4055390949909048]
	TIME [epoch: 25 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.387959908448606		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.387959908448606 | validation: 0.29081476931001043]
	TIME [epoch: 25 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30224305027380494		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.30224305027380494 | validation: 0.23560520677067393]
	TIME [epoch: 25 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31004211941034754		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.31004211941034754 | validation: 0.1963596037272407]
	TIME [epoch: 25 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20000760144788865		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.20000760144788865 | validation: 0.150814867590141]
	TIME [epoch: 25 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17568071038671146		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.17568071038671146 | validation: 0.1529844987829468]
	TIME [epoch: 25 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1679696987438811		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.1679696987438811 | validation: 0.14855802985050112]
	TIME [epoch: 25 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17181459412262273		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.17181459412262273 | validation: 0.1564387655901715]
	TIME [epoch: 25 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1757598684090306		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.1757598684090306 | validation: 0.18072838244093514]
	TIME [epoch: 24.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17163862512016456		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.17163862512016456 | validation: 0.12950693888518625]
	TIME [epoch: 25 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1434995619152698		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.1434995619152698 | validation: 0.13816622346850435]
	TIME [epoch: 25 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14724966355340402		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.14724966355340402 | validation: 0.16195706279908664]
	TIME [epoch: 25 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18011361331711828		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.18011361331711828 | validation: 0.19861051586435488]
	TIME [epoch: 24.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16845175441217702		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.16845175441217702 | validation: 0.15101467499083007]
	TIME [epoch: 25 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15634841814212808		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.15634841814212808 | validation: 0.17421153027428232]
	TIME [epoch: 25 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22037979453395928		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.22037979453395928 | validation: 0.2235525428966966]
	TIME [epoch: 24.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24450736485005675		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.24450736485005675 | validation: 0.214276027533884]
	TIME [epoch: 25 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20680739953892707		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.20680739953892707 | validation: 0.19864673102656785]
	TIME [epoch: 25 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19213300716035864		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.19213300716035864 | validation: 0.16205990174887003]
	TIME [epoch: 25 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19887421143638437		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.19887421143638437 | validation: 0.2126341594623928]
	TIME [epoch: 25 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19127002569525828		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.19127002569525828 | validation: 0.1479965524332731]
	TIME [epoch: 25 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2123936897673227		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.2123936897673227 | validation: 0.19373203935425978]
	TIME [epoch: 25 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18790580086493636		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.18790580086493636 | validation: 0.14876294975647286]
	TIME [epoch: 24.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18850094358396946		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.18850094358396946 | validation: 0.1884618933131463]
	TIME [epoch: 24.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20026406700940444		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.20026406700940444 | validation: 0.15828456479584052]
	TIME [epoch: 25 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17907357162265997		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.17907357162265997 | validation: 0.14382770949948406]
	TIME [epoch: 25 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14342066573935056		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.14342066573935056 | validation: 0.12573960358984648]
	TIME [epoch: 24.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16959457677330347		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.16959457677330347 | validation: 0.13082037994875376]
	TIME [epoch: 25 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14385757002984736		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.14385757002984736 | validation: 0.16821817284097074]
	TIME [epoch: 24.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14956105447644058		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.14956105447644058 | validation: 0.16159967295283786]
	TIME [epoch: 25 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15167104198797104		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.15167104198797104 | validation: 0.15295413333905972]
	TIME [epoch: 25 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16252625029472312		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.16252625029472312 | validation: 0.12973950597101486]
	TIME [epoch: 25 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335251083516311		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.1335251083516311 | validation: 0.1222712533896801]
	TIME [epoch: 25 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13572206534191344		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.13572206534191344 | validation: 0.13820263302108424]
	TIME [epoch: 25 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1579100926956758		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.1579100926956758 | validation: 0.14463685739971116]
	TIME [epoch: 25 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13985265819403214		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.13985265819403214 | validation: 0.14257905022927173]
	TIME [epoch: 25 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1739978323398294		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.1739978323398294 | validation: 0.13937357677973228]
	TIME [epoch: 25 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16047207872419597		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.16047207872419597 | validation: 0.1320613584512047]
	TIME [epoch: 25 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14576328586827592		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.14576328586827592 | validation: 0.12844840625722273]
	TIME [epoch: 24.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15034298166245993		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.15034298166245993 | validation: 0.11548016797806479]
	TIME [epoch: 25 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13205349868923155		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.13205349868923155 | validation: 0.10982679197257805]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_844.pth
	Model improved!!!
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477261696421332		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.1477261696421332 | validation: 0.13656599741737246]
	TIME [epoch: 25 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16296774384421914		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.16296774384421914 | validation: 0.15809613019540775]
	TIME [epoch: 24.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14733985020036217		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.14733985020036217 | validation: 0.12095181650935778]
	TIME [epoch: 25 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11656925783766633		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.11656925783766633 | validation: 0.13253551566243665]
	TIME [epoch: 24.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12503293108292735		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.12503293108292735 | validation: 0.11418323287523496]
	TIME [epoch: 25 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18427248726377377		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.18427248726377377 | validation: 0.19786562720996018]
	TIME [epoch: 24.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18034428652319942		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.18034428652319942 | validation: 0.1466718377429685]
	TIME [epoch: 25 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17362565287964027		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.17362565287964027 | validation: 0.1838437152972363]
	TIME [epoch: 24.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2210253102215959		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.2210253102215959 | validation: 0.16648550845140025]
	TIME [epoch: 25 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14820086708969693		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.14820086708969693 | validation: 0.11689047694848773]
	TIME [epoch: 24.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13308899626403403		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.13308899626403403 | validation: 0.11692875860861993]
	TIME [epoch: 25 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15723705455300258		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.15723705455300258 | validation: 0.1635574437126212]
	TIME [epoch: 24.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19909471905360288		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.19909471905360288 | validation: 0.1874441461209021]
	TIME [epoch: 25 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20673933469789083		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.20673933469789083 | validation: 0.1434134123458446]
	TIME [epoch: 24.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15887945951501653		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.15887945951501653 | validation: 0.20709047385333024]
	TIME [epoch: 25 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2114110088105573		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.2114110088105573 | validation: 0.18242762799121454]
	TIME [epoch: 24.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19399725540041488		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.19399725540041488 | validation: 0.16724848930396555]
	TIME [epoch: 25 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16572847608303154		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.16572847608303154 | validation: 0.14920562572103077]
	TIME [epoch: 24.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16757272428401612		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.16757272428401612 | validation: 0.15959508572411132]
	TIME [epoch: 24.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14169438114362415		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.14169438114362415 | validation: 0.1183891701212925]
	TIME [epoch: 24.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318958319215037		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.1318958319215037 | validation: 0.11667269141766631]
	TIME [epoch: 24.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12298841169676075		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.12298841169676075 | validation: 0.10249529278547231]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240309_135747/states/model_tr_study6_866.pth
	Model improved!!!
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13257717214223597		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.13257717214223597 | validation: 0.1283585811465658]
	TIME [epoch: 24.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14065566417963526		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.14065566417963526 | validation: 0.16934096605112445]
	TIME [epoch: 24.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16506057558448728		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.16506057558448728 | validation: 0.13188417960164373]
	TIME [epoch: 24.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13486792446552448		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.13486792446552448 | validation: 0.16513037316500712]
	TIME [epoch: 24.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16184580220598596		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.16184580220598596 | validation: 0.17459500408187675]
	TIME [epoch: 24.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17193474315148147		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.17193474315148147 | validation: 0.1777667438903702]
	TIME [epoch: 24.9 sec]
EPOCH 873/2000:
	Training over batches...
