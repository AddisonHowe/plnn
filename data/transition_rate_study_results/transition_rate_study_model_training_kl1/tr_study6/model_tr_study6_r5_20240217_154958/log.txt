Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r5', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=500, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 391520506

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.815907009473698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.815907009473698 | validation: 7.407498406926728]
	TIME [epoch: 49.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.28518142325047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.28518142325047 | validation: 6.675112751406324]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.208657664000336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.208657664000336 | validation: 5.758296406490045]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.21810461937946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.21810461937946 | validation: 6.927298492040284]
	TIME [epoch: 10.3 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.001091768223727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.001091768223727 | validation: 5.86901715643927]
	TIME [epoch: 10.3 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.495397373838472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.495397373838472 | validation: 5.29869359972505]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.849385480402882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.849385480402882 | validation: 4.013147551364461]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.964938621367049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.964938621367049 | validation: 6.744387037512041]
	TIME [epoch: 10.3 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.058252251481857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.058252251481857 | validation: 4.033658393775873]
	TIME [epoch: 10.3 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.310643124358318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.310643124358318 | validation: 3.0504440523129976]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.920747978889072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.920747978889072 | validation: 3.235085335211435]
	TIME [epoch: 10.3 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.123644849132171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.123644849132171 | validation: 3.0114110218512598]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6586343316421917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6586343316421917 | validation: 3.525887948965478]
	TIME [epoch: 10.3 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.60573460036683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.60573460036683 | validation: 2.5428970667869324]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9617038509757068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9617038509757068 | validation: 3.047843145565455]
	TIME [epoch: 10.3 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.088081415252487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.088081415252487 | validation: 4.726562461778906]
	TIME [epoch: 10.3 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.2061640083333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2061640083333 | validation: 4.20103843591426]
	TIME [epoch: 10.3 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.06291502364017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.06291502364017 | validation: 3.323321937746929]
	TIME [epoch: 10.3 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.913012462365984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.913012462365984 | validation: 2.872080877723503]
	TIME [epoch: 10.3 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.655258083177043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.655258083177043 | validation: 5.286384022010352]
	TIME [epoch: 10.3 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.364760315846534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.364760315846534 | validation: 3.620806938298234]
	TIME [epoch: 10.3 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8778435526067567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8778435526067567 | validation: 2.5387842449696745]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.072570094347587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.072570094347587 | validation: 3.4828393690894606]
	TIME [epoch: 10.3 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.49257043566445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.49257043566445 | validation: 2.6465120443244907]
	TIME [epoch: 10.3 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5897726573547386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5897726573547386 | validation: 3.1345036104286237]
	TIME [epoch: 10.3 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6411626677807964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6411626677807964 | validation: 2.9112259993642136]
	TIME [epoch: 10.3 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.554582339117752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.554582339117752 | validation: 2.889102953848665]
	TIME [epoch: 10.3 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.451316685623913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.451316685623913 | validation: 2.9335062580799702]
	TIME [epoch: 10.3 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4305479528872524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4305479528872524 | validation: 3.0222961319690884]
	TIME [epoch: 10.3 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.1246134194484325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1246134194484325 | validation: 5.409587179108651]
	TIME [epoch: 10.3 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.331579905303998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.331579905303998 | validation: 5.296859293484355]
	TIME [epoch: 10.3 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.625454432829325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.625454432829325 | validation: 4.712150950665583]
	TIME [epoch: 10.3 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.958308907252087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.958308907252087 | validation: 4.171091551058921]
	TIME [epoch: 10.3 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.247819344748182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.247819344748182 | validation: 3.6826296217367793]
	TIME [epoch: 10.3 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7453216646633907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7453216646633907 | validation: 3.043330451072304]
	TIME [epoch: 10.3 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.708803118214763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.708803118214763 | validation: 4.228775309413039]
	TIME [epoch: 10.3 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7558685172863746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7558685172863746 | validation: 2.7807334786106095]
	TIME [epoch: 10.3 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.169436537609788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.169436537609788 | validation: 3.2036517206989488]
	TIME [epoch: 10.3 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0971470668185477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0971470668185477 | validation: 2.8299830764402207]
	TIME [epoch: 10.3 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.539928963399542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.539928963399542 | validation: 4.54689485576116]
	TIME [epoch: 10.3 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.94991324422176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.94991324422176 | validation: 2.763113870695793]
	TIME [epoch: 10.3 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1138461628567446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1138461628567446 | validation: 2.7744473838362875]
	TIME [epoch: 10.3 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9509322379704876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9509322379704876 | validation: 2.7517557309287977]
	TIME [epoch: 10.3 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.887883786402676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.887883786402676 | validation: 2.6758794125546657]
	TIME [epoch: 10.3 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0227284985303378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0227284985303378 | validation: 2.42675601491984]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8108386278722923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8108386278722923 | validation: 2.436232784557913]
	TIME [epoch: 10.3 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.134078540397431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.134078540397431 | validation: 2.9970901906149674]
	TIME [epoch: 10.3 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0749426405189775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0749426405189775 | validation: 2.5450631404108175]
	TIME [epoch: 10.3 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6871517654386468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6871517654386468 | validation: 2.203227936471548]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2184339053751008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2184339053751008 | validation: 2.29211082343557]
	TIME [epoch: 10.3 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3604003110027967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3604003110027967 | validation: 1.837787220793705]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6523807412500604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6523807412500604 | validation: 2.247775424747087]
	TIME [epoch: 10.3 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1680802688813805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1680802688813805 | validation: 1.891224473310029]
	TIME [epoch: 10.3 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0073830079427077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0073830079427077 | validation: 2.7066194779620747]
	TIME [epoch: 10.3 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3919378526962616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3919378526962616 | validation: 2.0595832591340457]
	TIME [epoch: 10.3 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9074963097733053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9074963097733053 | validation: 1.9484831988253297]
	TIME [epoch: 10.3 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8436572177934214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8436572177934214 | validation: 1.791062983101622]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8119857603265472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8119857603265472 | validation: 2.1246037410953678]
	TIME [epoch: 10.3 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7765826196823067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7765826196823067 | validation: 2.3740198867505136]
	TIME [epoch: 10.3 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8117756010858463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8117756010858463 | validation: 1.4148529801858438]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0890812132398735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0890812132398735 | validation: 1.5150241321016629]
	TIME [epoch: 10.3 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4884557925203772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4884557925203772 | validation: 1.5688322971534208]
	TIME [epoch: 10.3 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5635259555659418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5635259555659418 | validation: 1.2409127298800209]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4206136654192376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4206136654192376 | validation: 1.5853333627852306]
	TIME [epoch: 10.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.479943454778068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.479943454778068 | validation: 1.196263793103612]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7385548286975552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7385548286975552 | validation: 1.2427280662689744]
	TIME [epoch: 10.3 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.260639664573479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.260639664573479 | validation: 1.407179957126852]
	TIME [epoch: 10.3 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4085814324063148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4085814324063148 | validation: 3.576913566398831]
	TIME [epoch: 10.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8399762719819415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8399762719819415 | validation: 2.84749590125394]
	TIME [epoch: 10.3 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0214899202404117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0214899202404117 | validation: 1.4366560784446312]
	TIME [epoch: 10.3 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3381874410056382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3381874410056382 | validation: 1.544287139047653]
	TIME [epoch: 10.3 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2385126164245683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2385126164245683 | validation: 1.3503206924078939]
	TIME [epoch: 10.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3017586322277075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3017586322277075 | validation: 1.5118248314738514]
	TIME [epoch: 10.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.14508735423879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.14508735423879 | validation: 1.0365080830134539]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.71513867494481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.71513867494481 | validation: 1.2385845875374708]
	TIME [epoch: 10.3 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1135101077315932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1135101077315932 | validation: 1.5082163824912034]
	TIME [epoch: 10.3 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3789414009751473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3789414009751473 | validation: 2.452957732277598]
	TIME [epoch: 10.3 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9226154889749754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9226154889749754 | validation: 2.9925683571949544]
	TIME [epoch: 10.3 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9934431272643394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9934431272643394 | validation: 1.471574826167929]
	TIME [epoch: 10.3 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3478891816483132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3478891816483132 | validation: 2.8975279571249932]
	TIME [epoch: 10.3 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7797892025148585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7797892025148585 | validation: 1.1826535999541894]
	TIME [epoch: 10.3 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1348340531332939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1348340531332939 | validation: 1.065242707286794]
	TIME [epoch: 10.3 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1044765524422369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1044765524422369 | validation: 1.08639921497581]
	TIME [epoch: 10.3 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0375162120507149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0375162120507149 | validation: 1.7563812301743071]
	TIME [epoch: 10.3 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3973461649898873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3973461649898873 | validation: 1.2097710280892802]
	TIME [epoch: 10.3 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9957327749356729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9957327749356729 | validation: 1.358145415555657]
	TIME [epoch: 10.3 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.102996730089234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.102996730089234 | validation: 1.2851431349740392]
	TIME [epoch: 10.3 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2706955744336859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2706955744336859 | validation: 0.945974981086873]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9739822464271798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9739822464271798 | validation: 0.9890463641977562]
	TIME [epoch: 10.3 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9717552493544478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9717552493544478 | validation: 1.1616025264809955]
	TIME [epoch: 10.3 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.915524655233166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.915524655233166 | validation: 1.1869085587140726]
	TIME [epoch: 10.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1433054282454884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1433054282454884 | validation: 1.605165767596225]
	TIME [epoch: 10.3 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0679852945152577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0679852945152577 | validation: 1.1355977746969885]
	TIME [epoch: 10.3 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0639671755810634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0639671755810634 | validation: 1.1597543484795754]
	TIME [epoch: 10.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.030482899580946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.030482899580946 | validation: 1.0032227177996007]
	TIME [epoch: 10.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1282962668647023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1282962668647023 | validation: 3.608836513200574]
	TIME [epoch: 10.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4712594311259037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4712594311259037 | validation: 1.1248486902773969]
	TIME [epoch: 10.3 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.910041065077546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.910041065077546 | validation: 0.750194046605553]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9345140415974547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9345140415974547 | validation: 2.250723247169587]
	TIME [epoch: 10.3 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.578582632631715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.578582632631715 | validation: 1.0992296796172452]
	TIME [epoch: 10.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4326790940409722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4326790940409722 | validation: 1.9982526073859663]
	TIME [epoch: 10.3 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3666209947276495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3666209947276495 | validation: 0.839373596908685]
	TIME [epoch: 10.3 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1659148594719462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1659148594719462 | validation: 2.0889365767271553]
	TIME [epoch: 10.3 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3543885798160997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3543885798160997 | validation: 1.0749119024276932]
	TIME [epoch: 10.3 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8050203864576349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8050203864576349 | validation: 1.7998289114938708]
	TIME [epoch: 10.3 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0640101999587555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0640101999587555 | validation: 0.935144139814051]
	TIME [epoch: 10.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3611231124448862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3611231124448862 | validation: 1.558996912499502]
	TIME [epoch: 10.3 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.15843995932715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.15843995932715 | validation: 0.9728447828316072]
	TIME [epoch: 10.3 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9003164401829521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9003164401829521 | validation: 0.9628012198437672]
	TIME [epoch: 10.3 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.970701113187795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.970701113187795 | validation: 1.4928992100028398]
	TIME [epoch: 10.3 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.108669241415261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.108669241415261 | validation: 0.8227032364088095]
	TIME [epoch: 10.3 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3151366877260737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3151366877260737 | validation: 1.206515056759936]
	TIME [epoch: 10.3 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9789918433388889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9789918433388889 | validation: 1.1060106741914804]
	TIME [epoch: 10.3 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1287697581642333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1287697581642333 | validation: 1.2526538566415355]
	TIME [epoch: 10.3 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0714198278773703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0714198278773703 | validation: 0.9785037254891095]
	TIME [epoch: 10.3 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0111744801546552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0111744801546552 | validation: 1.1931046426246237]
	TIME [epoch: 10.3 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0426322881359151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0426322881359151 | validation: 1.048404534195442]
	TIME [epoch: 10.3 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0201577739540362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0201577739540362 | validation: 1.0478573272489986]
	TIME [epoch: 10.3 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9337873306965591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9337873306965591 | validation: 0.8206263795282612]
	TIME [epoch: 10.3 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9308563867787747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9308563867787747 | validation: 0.9369088099207017]
	TIME [epoch: 10.3 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.268138610785332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.268138610785332 | validation: 2.3211926322571945]
	TIME [epoch: 10.3 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0014854222091314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0014854222091314 | validation: 1.3991873500060419]
	TIME [epoch: 10.3 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7802946137517832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7802946137517832 | validation: 2.8186569112267446]
	TIME [epoch: 10.3 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1284060656721873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1284060656721873 | validation: 1.0862192738272702]
	TIME [epoch: 10.3 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8894681763138989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8894681763138989 | validation: 1.2929720938943308]
	TIME [epoch: 10.3 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5281623439115584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5281623439115584 | validation: 1.6738860396084743]
	TIME [epoch: 10.3 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9795942693221396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9795942693221396 | validation: 1.2239111406712444]
	TIME [epoch: 10.3 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4020151794560303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4020151794560303 | validation: 1.1920351059945449]
	TIME [epoch: 10.3 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9061401483460164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9061401483460164 | validation: 1.2670515852872595]
	TIME [epoch: 10.3 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7643744352465458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7643744352465458 | validation: 1.4175199519066592]
	TIME [epoch: 10.3 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0319658313214874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0319658313214874 | validation: 0.9916430037603432]
	TIME [epoch: 10.3 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1358457484787448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1358457484787448 | validation: 0.8680436940479538]
	TIME [epoch: 10.3 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9524908454074994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9524908454074994 | validation: 1.4266744800744187]
	TIME [epoch: 10.3 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8604939089847944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8604939089847944 | validation: 0.776902286189099]
	TIME [epoch: 10.3 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8588392975065648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8588392975065648 | validation: 0.7903684836850938]
	TIME [epoch: 10.3 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8304506823293067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8304506823293067 | validation: 1.6806511008678235]
	TIME [epoch: 10.3 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0921131049121808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0921131049121808 | validation: 0.8152579534506537]
	TIME [epoch: 10.3 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7948920198961504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7948920198961504 | validation: 0.8639810546786132]
	TIME [epoch: 10.3 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7662140945423174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7662140945423174 | validation: 1.007983770261873]
	TIME [epoch: 10.3 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8866967096751204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8866967096751204 | validation: 1.06042352552453]
	TIME [epoch: 10.3 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3036017840395924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3036017840395924 | validation: 2.0625154290371035]
	TIME [epoch: 10.3 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1769174166539726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1769174166539726 | validation: 0.8899270897756258]
	TIME [epoch: 10.3 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9684704816543179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9684704816543179 | validation: 1.1874778664157928]
	TIME [epoch: 10.3 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.845571420668654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.845571420668654 | validation: 0.5615221607695702]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7018808786670759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7018808786670759 | validation: 1.025031117924731]
	TIME [epoch: 10.3 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8146513440952161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8146513440952161 | validation: 1.1717651551747745]
	TIME [epoch: 10.3 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.126152960448882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.126152960448882 | validation: 1.1947732674226854]
	TIME [epoch: 10.3 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8085903020641698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8085903020641698 | validation: 0.5519134993386954]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6215745257421788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6215745257421788 | validation: 1.059735082751634]
	TIME [epoch: 10.3 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8825479302609507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8825479302609507 | validation: 0.8741737619810189]
	TIME [epoch: 10.3 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8632339705482215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8632339705482215 | validation: 2.858361271025218]
	TIME [epoch: 10.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3038257264059316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3038257264059316 | validation: 1.338926482544562]
	TIME [epoch: 10.3 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7982351694378057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7982351694378057 | validation: 0.9723676819786903]
	TIME [epoch: 10.3 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.848090660786181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.848090660786181 | validation: 0.8940744317266857]
	TIME [epoch: 10.3 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8859404471550427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8859404471550427 | validation: 0.9523864751047433]
	TIME [epoch: 10.3 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.233843393715431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.233843393715431 | validation: 0.9890301705566822]
	TIME [epoch: 10.3 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9636408639005634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9636408639005634 | validation: 1.0256410173390886]
	TIME [epoch: 10.3 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0886718178020025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0886718178020025 | validation: 1.075112605493064]
	TIME [epoch: 10.3 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.007324268375864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.007324268375864 | validation: 0.9797693645294868]
	TIME [epoch: 10.3 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8591697425996081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8591697425996081 | validation: 2.7632141583549443]
	TIME [epoch: 10.3 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.273252016280865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.273252016280865 | validation: 2.5707927096273306]
	TIME [epoch: 10.3 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.172912423108962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.172912423108962 | validation: 1.1097069163755942]
	TIME [epoch: 10.3 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.238758201985458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.238758201985458 | validation: 0.8794371305787182]
	TIME [epoch: 10.3 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.902253590913206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.902253590913206 | validation: 1.0193848708046533]
	TIME [epoch: 10.3 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9775998911238556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9775998911238556 | validation: 1.07736775083871]
	TIME [epoch: 10.3 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0998051553895427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0998051553895427 | validation: 2.5704269061446836]
	TIME [epoch: 10.3 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6200444672108412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6200444672108412 | validation: 1.2837117863784033]
	TIME [epoch: 10.3 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9811165014456297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9811165014456297 | validation: 1.3014484886536726]
	TIME [epoch: 10.3 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0810527049820793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0810527049820793 | validation: 1.328941340953257]
	TIME [epoch: 10.3 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8658816544522245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8658816544522245 | validation: 1.3511346024982605]
	TIME [epoch: 10.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2988855242523285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2988855242523285 | validation: 0.8117558959466976]
	TIME [epoch: 10.3 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0268111020196151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0268111020196151 | validation: 1.0234725513557732]
	TIME [epoch: 10.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1557322458622885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1557322458622885 | validation: 1.130338926535383]
	TIME [epoch: 10.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9532059011255012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9532059011255012 | validation: 0.7547121416758656]
	TIME [epoch: 10.3 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6426227424335937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6426227424335937 | validation: 0.6829094745866707]
	TIME [epoch: 10.3 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2535121789594403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2535121789594403 | validation: 0.8063770793512708]
	TIME [epoch: 10.3 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.994437958247811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.994437958247811 | validation: 0.9158506287532739]
	TIME [epoch: 10.3 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7384848742850645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7384848742850645 | validation: 2.5144446288413453]
	TIME [epoch: 10.3 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6394169435579604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6394169435579604 | validation: 1.6592816086162947]
	TIME [epoch: 10.3 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.066902591301694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.066902591301694 | validation: 1.9137560950141204]
	TIME [epoch: 10.3 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.151847523246915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.151847523246915 | validation: 1.0827715166725862]
	TIME [epoch: 10.3 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9632571023844981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9632571023844981 | validation: 0.9675401032462023]
	TIME [epoch: 10.3 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9096927683306687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9096927683306687 | validation: 0.7387057660598049]
	TIME [epoch: 10.3 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7869670192537532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7869670192537532 | validation: 0.7643946464601803]
	TIME [epoch: 10.3 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8683656011442047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8683656011442047 | validation: 0.9774987851738431]
	TIME [epoch: 10.3 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8629879926220573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8629879926220573 | validation: 1.0142419064118229]
	TIME [epoch: 10.3 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.136645874957404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.136645874957404 | validation: 0.8351370240040961]
	TIME [epoch: 10.3 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7825154879242456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7825154879242456 | validation: 0.8288581942335143]
	TIME [epoch: 10.3 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6948394781490669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6948394781490669 | validation: 0.575138830746317]
	TIME [epoch: 10.3 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8838082376272226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8838082376272226 | validation: 5.245686996408953]
	TIME [epoch: 10.3 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.886932083953961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.886932083953961 | validation: 4.855224683305045]
	TIME [epoch: 10.3 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5555144899738806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5555144899738806 | validation: 0.7842617549746703]
	TIME [epoch: 10.3 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9027069719851475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9027069719851475 | validation: 0.8520937482599638]
	TIME [epoch: 10.3 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6682339315615606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6682339315615606 | validation: 0.7799772422258269]
	TIME [epoch: 10.3 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8776457968853995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8776457968853995 | validation: 0.8185028775349449]
	TIME [epoch: 10.3 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.845120697101672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.845120697101672 | validation: 0.6210128342806001]
	TIME [epoch: 10.3 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1736948875315751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1736948875315751 | validation: 2.6405936221260853]
	TIME [epoch: 10.3 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7806064430128523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7806064430128523 | validation: 0.8119963191756762]
	TIME [epoch: 10.3 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1914207447078433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1914207447078433 | validation: 0.6714091135818465]
	TIME [epoch: 10.3 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8010825321517163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8010825321517163 | validation: 1.8660927738930913]
	TIME [epoch: 10.3 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1345734716128537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1345734716128537 | validation: 1.0549073248048644]
	TIME [epoch: 10.3 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7884065492924008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7884065492924008 | validation: 0.6936011782473511]
	TIME [epoch: 10.3 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7347132078298507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7347132078298507 | validation: 0.6626324357762576]
	TIME [epoch: 10.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8122932918497803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8122932918497803 | validation: 0.6154729398571341]
	TIME [epoch: 10.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8459022191958143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8459022191958143 | validation: 0.729113112384337]
	TIME [epoch: 10.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7430692600373332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7430692600373332 | validation: 0.7613614415606201]
	TIME [epoch: 10.3 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6837840425565177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6837840425565177 | validation: 0.8839548283486187]
	TIME [epoch: 10.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.695153803475842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.695153803475842 | validation: 1.1042666148209548]
	TIME [epoch: 10.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7081074633769123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7081074633769123 | validation: 0.6918206756396645]
	TIME [epoch: 10.3 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8054005847301238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8054005847301238 | validation: 0.6268099791045608]
	TIME [epoch: 10.3 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7300100595739315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7300100595739315 | validation: 0.6845546670134489]
	TIME [epoch: 10.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0268390968230912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0268390968230912 | validation: 1.1251502403081464]
	TIME [epoch: 10.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7921579515315285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7921579515315285 | validation: 0.6577066934623383]
	TIME [epoch: 10.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5833518389713939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5833518389713939 | validation: 0.5772149807535445]
	TIME [epoch: 10.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.473205131894092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.473205131894092 | validation: 1.5923741320153917]
	TIME [epoch: 10.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4472278236722096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4472278236722096 | validation: 0.7227252010650859]
	TIME [epoch: 10.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.664626415471296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.664626415471296 | validation: 0.6197155790466471]
	TIME [epoch: 10.3 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.459946748019201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.459946748019201 | validation: 0.6260040332659714]
	TIME [epoch: 10.3 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6703017126725183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6703017126725183 | validation: 0.6293837307707539]
	TIME [epoch: 10.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0660513723849054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0660513723849054 | validation: 1.8848357385412267]
	TIME [epoch: 10.3 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9352859685436847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9352859685436847 | validation: 0.5359293016388387]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5577577759096404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5577577759096404 | validation: 0.8905668031358078]
	TIME [epoch: 10.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9879070322985475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9879070322985475 | validation: 0.6926219792209811]
	TIME [epoch: 10.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6055739133478037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6055739133478037 | validation: 0.5142442600043807]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7292098830956256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7292098830956256 | validation: 0.6613140801902572]
	TIME [epoch: 10.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0533391075454848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0533391075454848 | validation: 1.1604811061812856]
	TIME [epoch: 10.3 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9268341334130088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9268341334130088 | validation: 0.796212915145461]
	TIME [epoch: 10.3 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.648541943914438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.648541943914438 | validation: 0.5794091914392661]
	TIME [epoch: 10.3 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8295403909336706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8295403909336706 | validation: 1.1695027216229508]
	TIME [epoch: 10.3 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9146059300761266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9146059300761266 | validation: 1.0045072044038128]
	TIME [epoch: 10.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.699879017875624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.699879017875624 | validation: 0.689019125494587]
	TIME [epoch: 10.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6876882397204203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6876882397204203 | validation: 0.7659246672794003]
	TIME [epoch: 10.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.70405745363964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.70405745363964 | validation: 0.8525915323442389]
	TIME [epoch: 10.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7063618868128582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7063618868128582 | validation: 0.9313768280889352]
	TIME [epoch: 10.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7136084261665181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7136084261665181 | validation: 0.8444429532301899]
	TIME [epoch: 10.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6933192094780504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6933192094780504 | validation: 1.330266541191504]
	TIME [epoch: 10.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1588370940672277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1588370940672277 | validation: 1.1378096997991016]
	TIME [epoch: 10.3 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9053826312754782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9053826312754782 | validation: 0.7028839264028862]
	TIME [epoch: 10.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6473086094673522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6473086094673522 | validation: 1.0198520189924676]
	TIME [epoch: 10.3 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0899950571935686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0899950571935686 | validation: 0.8181334883261983]
	TIME [epoch: 10.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7184877221976186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7184877221976186 | validation: 2.1973903716982712]
	TIME [epoch: 10.3 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3273530939127132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3273530939127132 | validation: 0.7833173032243247]
	TIME [epoch: 10.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0235126583472938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0235126583472938 | validation: 2.4058745468526967]
	TIME [epoch: 10.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5059660453132113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5059660453132113 | validation: 0.9993725054167587]
	TIME [epoch: 10.3 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0191735756879166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0191735756879166 | validation: 1.1847964194721683]
	TIME [epoch: 10.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9189389468983806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9189389468983806 | validation: 0.883226924871525]
	TIME [epoch: 10.3 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7169069005013091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7169069005013091 | validation: 0.9376468698208598]
	TIME [epoch: 10.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6278119099622217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6278119099622217 | validation: 0.7348982927903767]
	TIME [epoch: 10.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9544697272156937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9544697272156937 | validation: 0.8904584252450589]
	TIME [epoch: 10.3 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.252628268544214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.252628268544214 | validation: 2.8493392485642888]
	TIME [epoch: 10.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2732792544121216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2732792544121216 | validation: 2.588063952225529]
	TIME [epoch: 10.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0999655855047523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0999655855047523 | validation: 2.4705481039176]
	TIME [epoch: 10.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5987233698941687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5987233698941687 | validation: 1.0753467426805636]
	TIME [epoch: 10.3 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8512671948986059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8512671948986059 | validation: 0.7211643902523585]
	TIME [epoch: 10.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9261458976196988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9261458976196988 | validation: 1.0002558614597399]
	TIME [epoch: 10.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7709549697866261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7709549697866261 | validation: 0.8076509995801368]
	TIME [epoch: 10.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7013080205306205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7013080205306205 | validation: 0.7642784054131089]
	TIME [epoch: 10.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7268293362814381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7268293362814381 | validation: 0.7877837764567629]
	TIME [epoch: 10.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8980408380889688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8980408380889688 | validation: 1.048156664696262]
	TIME [epoch: 10.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8283356053319009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8283356053319009 | validation: 0.7172727767245801]
	TIME [epoch: 10.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.634226489178681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.634226489178681 | validation: 1.0585896524061411]
	TIME [epoch: 10.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1950345815427392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1950345815427392 | validation: 1.348863305256869]
	TIME [epoch: 10.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1640016342576254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1640016342576254 | validation: 0.6742435380285644]
	TIME [epoch: 10.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6660050436174052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6660050436174052 | validation: 0.7099772105043098]
	TIME [epoch: 10.3 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.649375119262819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.649375119262819 | validation: 1.060332228936763]
	TIME [epoch: 10.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7016223512206696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7016223512206696 | validation: 0.7049600271038285]
	TIME [epoch: 10.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8038727117909195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8038727117909195 | validation: 0.8326824309609164]
	TIME [epoch: 10.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.727548428831086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.727548428831086 | validation: 0.668149309276078]
	TIME [epoch: 10.3 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7912438713404417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7912438713404417 | validation: 0.8149338991229063]
	TIME [epoch: 10.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7269568736683869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7269568736683869 | validation: 1.0454625533959996]
	TIME [epoch: 10.3 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9549913362866904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9549913362866904 | validation: 0.8071892149235255]
	TIME [epoch: 10.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9154497643980808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9154497643980808 | validation: 0.9044785868989282]
	TIME [epoch: 10.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7947371412111071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7947371412111071 | validation: 0.8602615504854323]
	TIME [epoch: 10.3 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8568683951118503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8568683951118503 | validation: 0.8883938006854775]
	TIME [epoch: 10.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9262681318169953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9262681318169953 | validation: 1.0100067839515217]
	TIME [epoch: 10.3 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8671781895535288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8671781895535288 | validation: 0.8027602482614128]
	TIME [epoch: 10.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8150741387593383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8150741387593383 | validation: 0.6069264267218606]
	TIME [epoch: 10.3 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0377808688950458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0377808688950458 | validation: 0.6640619768726592]
	TIME [epoch: 10.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7463021565021654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7463021565021654 | validation: 0.6941903741149077]
	TIME [epoch: 10.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6023197588035203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6023197588035203 | validation: 0.6000156290245768]
	TIME [epoch: 10.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8936644040779373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8936644040779373 | validation: 0.8487409140281997]
	TIME [epoch: 10.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7983942815339029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7983942815339029 | validation: 0.9150728072497165]
	TIME [epoch: 10.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7048589413291838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7048589413291838 | validation: 0.6963633460026164]
	TIME [epoch: 10.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1828236787588189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1828236787588189 | validation: 0.7653575203634492]
	TIME [epoch: 10.3 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6359170506101913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6359170506101913 | validation: 0.630846670428629]
	TIME [epoch: 10.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3764847944768739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3764847944768739 | validation: 0.954411130934529]
	TIME [epoch: 10.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6241747184501216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6241747184501216 | validation: 0.5318489855082464]
	TIME [epoch: 10.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7427091664822301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7427091664822301 | validation: 0.6400587099398446]
	TIME [epoch: 10.3 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5482410158633764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5482410158633764 | validation: 0.5970823257028995]
	TIME [epoch: 10.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.579264085414528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.579264085414528 | validation: 0.6597598190419676]
	TIME [epoch: 10.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5369965222477517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5369965222477517 | validation: 0.594979603385705]
	TIME [epoch: 10.3 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5471096077837582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5471096077837582 | validation: 0.8024272399216384]
	TIME [epoch: 10.3 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7389664379700097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7389664379700097 | validation: 0.6989389669942443]
	TIME [epoch: 10.3 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7557368046215137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7557368046215137 | validation: 0.7871106277038911]
	TIME [epoch: 10.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6364640250429733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6364640250429733 | validation: 0.6207392310409333]
	TIME [epoch: 10.3 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.500434872762284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.500434872762284 | validation: 0.650489633080673]
	TIME [epoch: 10.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.516338169907862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.516338169907862 | validation: 0.47337294690059467]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_297.pth
	Model improved!!!
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5462720221619541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5462720221619541 | validation: 0.6310022230793432]
	TIME [epoch: 10.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9073794939848476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9073794939848476 | validation: 0.570248325118864]
	TIME [epoch: 10.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5824447978596844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5824447978596844 | validation: 1.0843959826636624]
	TIME [epoch: 10.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9578543196471472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9578543196471472 | validation: 1.3254181426469438]
	TIME [epoch: 10.3 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8858527569837884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8858527569837884 | validation: 0.6158172068632789]
	TIME [epoch: 10.3 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5370787424787491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5370787424787491 | validation: 0.6306215093927956]
	TIME [epoch: 10.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9431628701874132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9431628701874132 | validation: 1.0778907507328819]
	TIME [epoch: 10.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0851957425213326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0851957425213326 | validation: 0.6428587472931983]
	TIME [epoch: 10.3 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6928952051197845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6928952051197845 | validation: 1.9128259448850724]
	TIME [epoch: 10.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5145335411554115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5145335411554115 | validation: 0.9381665622138402]
	TIME [epoch: 10.3 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.974342196748889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.974342196748889 | validation: 1.0298414032213148]
	TIME [epoch: 10.3 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7600089148290909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7600089148290909 | validation: 0.7209056905314154]
	TIME [epoch: 10.3 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6065793550328287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6065793550328287 | validation: 1.0264245402360666]
	TIME [epoch: 10.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7631150306345997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7631150306345997 | validation: 0.5721889980889205]
	TIME [epoch: 10.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6326470893572068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6326470893572068 | validation: 0.8173201618327721]
	TIME [epoch: 10.3 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6999096065810203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6999096065810203 | validation: 0.6857173844072472]
	TIME [epoch: 10.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6276645978791114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6276645978791114 | validation: 0.6665987440186941]
	TIME [epoch: 10.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.554514240145031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.554514240145031 | validation: 0.6519752103931964]
	TIME [epoch: 10.3 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5687478460250264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5687478460250264 | validation: 0.8895023367371729]
	TIME [epoch: 10.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8902042715159479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8902042715159479 | validation: 0.8011444275029019]
	TIME [epoch: 10.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7111779070196177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7111779070196177 | validation: 0.6218548072351624]
	TIME [epoch: 10.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5812269292723005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5812269292723005 | validation: 0.5981039115812314]
	TIME [epoch: 10.3 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8096041535060492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8096041535060492 | validation: 0.9359659473043576]
	TIME [epoch: 10.3 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.768861301480473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.768861301480473 | validation: 3.3072552236423873]
	TIME [epoch: 10.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.569082645907654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.569082645907654 | validation: 2.381978058438519]
	TIME [epoch: 10.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0571644749432187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0571644749432187 | validation: 1.7429927526313844]
	TIME [epoch: 10.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5005222643478033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5005222643478033 | validation: 1.0085571292400615]
	TIME [epoch: 10.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9102017203875497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9102017203875497 | validation: 0.6870216579540146]
	TIME [epoch: 10.3 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7287832226944955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7287832226944955 | validation: 0.6651522896693294]
	TIME [epoch: 10.3 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8229328954639705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8229328954639705 | validation: 0.8413417907590196]
	TIME [epoch: 10.3 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7359762180324187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7359762180324187 | validation: 0.7230234502920591]
	TIME [epoch: 10.3 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.702029816887511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.702029816887511 | validation: 0.8814563634193576]
	TIME [epoch: 10.3 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6880437804600062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6880437804600062 | validation: 0.9996881424720662]
	TIME [epoch: 10.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8421974820510778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8421974820510778 | validation: 0.5425669464115883]
	TIME [epoch: 10.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6656041817262877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6656041817262877 | validation: 0.46947742310681767]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7869244246320172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7869244246320172 | validation: 0.8419505652145465]
	TIME [epoch: 10.3 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8174418009191419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8174418009191419 | validation: 0.6704607930201217]
	TIME [epoch: 10.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6304314725534577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6304314725534577 | validation: 0.6976639147621481]
	TIME [epoch: 10.3 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.693358142888502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.693358142888502 | validation: 0.6076524487533124]
	TIME [epoch: 10.3 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6415777789299232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6415777789299232 | validation: 1.0645449634505548]
	TIME [epoch: 10.3 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5373202180103127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5373202180103127 | validation: 0.648885349642989]
	TIME [epoch: 10.3 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6767020944674953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6767020944674953 | validation: 0.7551270616417562]
	TIME [epoch: 10.3 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9894707640266981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9894707640266981 | validation: 0.5538896791341602]
	TIME [epoch: 10.3 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.108881655524225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.108881655524225 | validation: 0.6207557396923739]
	TIME [epoch: 10.3 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6121159624668001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6121159624668001 | validation: 0.5502980883547922]
	TIME [epoch: 10.3 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0049299973551775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0049299973551775 | validation: 1.8942204204018227]
	TIME [epoch: 10.3 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0638777442908949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0638777442908949 | validation: 0.6502075672622766]
	TIME [epoch: 10.3 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5554908379830914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5554908379830914 | validation: 0.6793708396067362]
	TIME [epoch: 10.3 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5797001794491874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5797001794491874 | validation: 1.263737046581234]
	TIME [epoch: 10.3 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8643442051056531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8643442051056531 | validation: 1.0368212755856894]
	TIME [epoch: 10.3 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7857766240626665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7857766240626665 | validation: 0.983216494065407]
	TIME [epoch: 10.3 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7886540306701945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7886540306701945 | validation: 0.6406550509257578]
	TIME [epoch: 10.3 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7346926679017909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7346926679017909 | validation: 0.6128952501677758]
	TIME [epoch: 10.3 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6557685677975271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6557685677975271 | validation: 0.8788555268378586]
	TIME [epoch: 10.3 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2809793883489653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2809793883489653 | validation: 2.469860148130781]
	TIME [epoch: 10.3 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9694186248401695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9694186248401695 | validation: 0.6552386504367371]
	TIME [epoch: 10.3 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6353197349162619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6353197349162619 | validation: 0.5343739572709322]
	TIME [epoch: 10.3 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5337602028311663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5337602028311663 | validation: 0.8211198591387359]
	TIME [epoch: 10.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6834645933311456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6834645933311456 | validation: 0.861178204844739]
	TIME [epoch: 10.3 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6260500182026898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6260500182026898 | validation: 0.701313800786915]
	TIME [epoch: 10.3 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6129177112880229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6129177112880229 | validation: 0.613915689785955]
	TIME [epoch: 10.3 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6486749415179884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6486749415179884 | validation: 0.7501663752679631]
	TIME [epoch: 10.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6300810563637367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6300810563637367 | validation: 0.7960706216483684]
	TIME [epoch: 10.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6434858427490319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6434858427490319 | validation: 0.5644401441204262]
	TIME [epoch: 10.3 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5453890514897839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5453890514897839 | validation: 0.5880820118099339]
	TIME [epoch: 10.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5435205729497072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5435205729497072 | validation: 0.5810327765852069]
	TIME [epoch: 10.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7068468925502647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7068468925502647 | validation: 1.1121200542958785]
	TIME [epoch: 10.3 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.047744989650012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.047744989650012 | validation: 0.7243886840916293]
	TIME [epoch: 10.3 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6655002330025025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6655002330025025 | validation: 0.7771745309405038]
	TIME [epoch: 10.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6827364838574519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6827364838574519 | validation: 0.8726581751464427]
	TIME [epoch: 10.3 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7589182687029122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7589182687029122 | validation: 0.8115979540338266]
	TIME [epoch: 10.3 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6975551809419042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6975551809419042 | validation: 0.7488871081335569]
	TIME [epoch: 10.3 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.606485340042471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.606485340042471 | validation: 0.8318300846148791]
	TIME [epoch: 10.3 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.680421977100752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.680421977100752 | validation: 0.5939023038828929]
	TIME [epoch: 10.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6604370361231218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6604370361231218 | validation: 0.7610846222420556]
	TIME [epoch: 10.3 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7439681861135885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7439681861135885 | validation: 1.2648451470587092]
	TIME [epoch: 10.3 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.514039592825618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.514039592825618 | validation: 1.047470910856321]
	TIME [epoch: 10.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8240380724654683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8240380724654683 | validation: 0.6167420431612556]
	TIME [epoch: 10.3 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4915754961650656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4915754961650656 | validation: 0.5234478422417488]
	TIME [epoch: 10.3 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5680090046235176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5680090046235176 | validation: 0.5978715886544328]
	TIME [epoch: 10.3 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.652077414239784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.652077414239784 | validation: 0.6336923325734967]
	TIME [epoch: 10.3 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7018756831830315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7018756831830315 | validation: 1.0838826106313295]
	TIME [epoch: 10.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.727849225958915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.727849225958915 | validation: 0.8895009851641049]
	TIME [epoch: 10.3 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8022690256051958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8022690256051958 | validation: 0.9722235049641598]
	TIME [epoch: 10.3 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5525872460141343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5525872460141343 | validation: 0.9181622776092376]
	TIME [epoch: 10.3 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.847963955832894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.847963955832894 | validation: 1.7863752164621394]
	TIME [epoch: 10.3 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7406635365889713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7406635365889713 | validation: 1.4000831219412675]
	TIME [epoch: 10.3 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8109303147955047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8109303147955047 | validation: 3.140074437441401]
	TIME [epoch: 10.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4231332969211237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4231332969211237 | validation: 1.0298975892427225]
	TIME [epoch: 10.3 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6678605882636757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6678605882636757 | validation: 1.4717248673910779]
	TIME [epoch: 10.3 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1153998453690366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1153998453690366 | validation: 1.153495669671415]
	TIME [epoch: 10.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.259465310686566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.259465310686566 | validation: 0.7201020175361282]
	TIME [epoch: 10.3 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.741330226753003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.741330226753003 | validation: 0.9877263527860486]
	TIME [epoch: 10.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8683337155406242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8683337155406242 | validation: 0.6102953245616416]
	TIME [epoch: 10.3 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.571631282499632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.571631282499632 | validation: 0.6763160006757446]
	TIME [epoch: 10.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5474000217011973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5474000217011973 | validation: 0.5689556911706797]
	TIME [epoch: 10.3 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49857744295246853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49857744295246853 | validation: 1.7279419897447121]
	TIME [epoch: 10.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9996606127008532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9996606127008532 | validation: 0.6337360824444319]
	TIME [epoch: 10.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5397362897486361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5397362897486361 | validation: 0.6305578630943347]
	TIME [epoch: 10.3 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5143645120200867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5143645120200867 | validation: 0.5322629343774314]
	TIME [epoch: 10.3 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6829505705844053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6829505705844053 | validation: 0.7517982182738808]
	TIME [epoch: 10.3 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4878084388138614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4878084388138614 | validation: 0.5028288864552158]
	TIME [epoch: 10.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5154625976596213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5154625976596213 | validation: 0.673814068487305]
	TIME [epoch: 10.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4957098948802985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4957098948802985 | validation: 0.5632428420440319]
	TIME [epoch: 10.3 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5425954275417015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5425954275417015 | validation: 0.5383784673254978]
	TIME [epoch: 10.3 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7775477737853647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7775477737853647 | validation: 0.7134382846436261]
	TIME [epoch: 10.3 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5736641671744191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5736641671744191 | validation: 0.5953975037420389]
	TIME [epoch: 10.3 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.623555965527083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.623555965527083 | validation: 0.6134174143461122]
	TIME [epoch: 10.3 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.504337540083752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.504337540083752 | validation: 0.6645552070715917]
	TIME [epoch: 10.3 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9344411235962069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9344411235962069 | validation: 0.6932524839584508]
	TIME [epoch: 10.3 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5606786117216918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5606786117216918 | validation: 0.6200708974193263]
	TIME [epoch: 10.3 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5068386827498734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5068386827498734 | validation: 0.61525992624679]
	TIME [epoch: 10.3 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4941058535279044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4941058535279044 | validation: 0.8561251001147155]
	TIME [epoch: 10.3 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9291199454593905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9291199454593905 | validation: 0.705196304599223]
	TIME [epoch: 10.3 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6906454519666061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6906454519666061 | validation: 0.577109381924945]
	TIME [epoch: 10.3 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4908319913037326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4908319913037326 | validation: 0.5665461123970964]
	TIME [epoch: 10.3 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48436242709439536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48436242709439536 | validation: 0.69470349239704]
	TIME [epoch: 10.3 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5148920917788716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5148920917788716 | validation: 0.6419022135002231]
	TIME [epoch: 10.3 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5143341452600857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5143341452600857 | validation: 0.4545615810842035]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5630196244254929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5630196244254929 | validation: 0.661278286230002]
	TIME [epoch: 10.3 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43537226797372625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43537226797372625 | validation: 0.45755978217773063]
	TIME [epoch: 10.3 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4456209698522941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4456209698522941 | validation: 0.4510630241487539]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5838780031468559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5838780031468559 | validation: 0.5037567251956548]
	TIME [epoch: 10.3 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4896870466476395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4896870466476395 | validation: 0.4341456584729606]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5107741415643928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5107741415643928 | validation: 0.3876460738722581]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7232329537406759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7232329537406759 | validation: 1.2855559966898409]
	TIME [epoch: 10.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7126627847643059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7126627847643059 | validation: 0.4565133007029343]
	TIME [epoch: 10.3 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.471716275534133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.471716275534133 | validation: 0.7509843916968152]
	TIME [epoch: 10.3 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5677640469225309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5677640469225309 | validation: 2.039660245048314]
	TIME [epoch: 10.3 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8029073111519256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8029073111519256 | validation: 0.9477714970210147]
	TIME [epoch: 10.3 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7875594376236466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7875594376236466 | validation: 0.5622970899657421]
	TIME [epoch: 10.3 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6470431720375576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6470431720375576 | validation: 0.7700792865100619]
	TIME [epoch: 10.3 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8170414421976263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8170414421976263 | validation: 1.100999661415759]
	TIME [epoch: 10.3 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.954889517732262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.954889517732262 | validation: 0.5471211215337204]
	TIME [epoch: 10.3 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.545102415349353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.545102415349353 | validation: 0.5729591549007169]
	TIME [epoch: 10.3 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47428957698691043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47428957698691043 | validation: 0.5999028702105413]
	TIME [epoch: 10.3 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45279685708929246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45279685708929246 | validation: 0.5994923114542356]
	TIME [epoch: 10.3 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8868932767812037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8868932767812037 | validation: 0.5996028836888017]
	TIME [epoch: 10.3 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41946844434175545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41946844434175545 | validation: 0.40208563023547983]
	TIME [epoch: 10.3 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4066617352417582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4066617352417582 | validation: 0.6538552349366785]
	TIME [epoch: 10.3 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5004453218073966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5004453218073966 | validation: 0.5511247304912706]
	TIME [epoch: 10.3 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7121731274186643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7121731274186643 | validation: 0.627874025023617]
	TIME [epoch: 10.3 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6058160660888852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6058160660888852 | validation: 0.5510923814755101]
	TIME [epoch: 10.3 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49921029700176067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49921029700176067 | validation: 0.5355025211546308]
	TIME [epoch: 10.3 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7648486158440922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7648486158440922 | validation: 0.7426203159347066]
	TIME [epoch: 10.3 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7822115972066491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7822115972066491 | validation: 0.6811630232629835]
	TIME [epoch: 10.3 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5849170420443619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5849170420443619 | validation: 0.6907623571254008]
	TIME [epoch: 10.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5520251652103421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5520251652103421 | validation: 0.7079011912725603]
	TIME [epoch: 10.3 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5838010930363383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5838010930363383 | validation: 0.6830603864518989]
	TIME [epoch: 10.3 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6765578394075458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6765578394075458 | validation: 0.5648456754824897]
	TIME [epoch: 10.3 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48687195970995967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48687195970995967 | validation: 1.5334303504035074]
	TIME [epoch: 10.3 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4170628116132284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4170628116132284 | validation: 1.1712366893331092]
	TIME [epoch: 10.3 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4794945790886485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4794945790886485 | validation: 1.2836548130049488]
	TIME [epoch: 10.3 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.237476147000057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.237476147000057 | validation: 1.5040094662696493]
	TIME [epoch: 10.3 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0463950255814873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0463950255814873 | validation: 0.6665113656500712]
	TIME [epoch: 10.3 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6001155885376512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6001155885376512 | validation: 0.5578402731942089]
	TIME [epoch: 10.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5547789036983561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5547789036983561 | validation: 0.6958561050767813]
	TIME [epoch: 10.3 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5099748001237929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5099748001237929 | validation: 0.8391691728633892]
	TIME [epoch: 10.3 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7928212718684347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7928212718684347 | validation: 1.2683222341406808]
	TIME [epoch: 10.3 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6614294558095701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6614294558095701 | validation: 0.8056805257485157]
	TIME [epoch: 10.3 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5915630075282914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5915630075282914 | validation: 2.131381946767568]
	TIME [epoch: 10.3 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4592067293942157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4592067293942157 | validation: 0.6462503967025888]
	TIME [epoch: 10.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0657748682740564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0657748682740564 | validation: 0.9941698683511697]
	TIME [epoch: 10.3 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7761017384323097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7761017384323097 | validation: 0.5834968673622635]
	TIME [epoch: 10.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7918530736544798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7918530736544798 | validation: 1.4988811922192913]
	TIME [epoch: 10.3 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9225831516912628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9225831516912628 | validation: 0.5957977744105847]
	TIME [epoch: 10.3 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5062163088268402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5062163088268402 | validation: 0.6255495593150687]
	TIME [epoch: 10.3 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5938006476892859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5938006476892859 | validation: 1.233415249587443]
	TIME [epoch: 10.3 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8173898730065179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8173898730065179 | validation: 0.598944110198929]
	TIME [epoch: 10.3 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48256234659417885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48256234659417885 | validation: 0.5520706528213538]
	TIME [epoch: 10.3 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5046921514203728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5046921514203728 | validation: 0.730989440051749]
	TIME [epoch: 10.3 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5279665904130869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5279665904130869 | validation: 0.5442547566332113]
	TIME [epoch: 10.3 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4758216738610287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4758216738610287 | validation: 0.5000117669248593]
	TIME [epoch: 10.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43489208890652664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43489208890652664 | validation: 0.28031683719778994]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.402654728445731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.402654728445731 | validation: 0.42258330867566757]
	TIME [epoch: 10.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1527108856934152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1527108856934152 | validation: 1.386478021018216]
	TIME [epoch: 10.3 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9687478573546674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9687478573546674 | validation: 0.4841899455699287]
	TIME [epoch: 10.3 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6013722725552667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6013722725552667 | validation: 0.7295003220946887]
	TIME [epoch: 10.3 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2600350595927372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2600350595927372 | validation: 0.48332079920271676]
	TIME [epoch: 10.3 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5123013822581262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5123013822581262 | validation: 0.4351773926461494]
	TIME [epoch: 10.3 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5886911941850409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5886911941850409 | validation: 0.41141746671696927]
	TIME [epoch: 10.3 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5025554096015395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5025554096015395 | validation: 0.43137559467194025]
	TIME [epoch: 10.3 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4714334840535546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4714334840535546 | validation: 0.45768027879361084]
	TIME [epoch: 10.3 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6512094839853446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6512094839853446 | validation: 0.7069967050697734]
	TIME [epoch: 10.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.552614895960776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.552614895960776 | validation: 0.4919864770463096]
	TIME [epoch: 10.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5584355935386114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5584355935386114 | validation: 1.1068147577041925]
	TIME [epoch: 10.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.634583882989976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.634583882989976 | validation: 0.5791797410752149]
	TIME [epoch: 10.3 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47501276546153626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47501276546153626 | validation: 0.8372278676265836]
	TIME [epoch: 10.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.403486386370243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.403486386370243 | validation: 1.5461575609655125]
	TIME [epoch: 10.3 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.183238590200928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.183238590200928 | validation: 0.9383429140329284]
	TIME [epoch: 10.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.643553017023715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.643553017023715 | validation: 0.5446590326542676]
	TIME [epoch: 10.3 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4587839075521035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4587839075521035 | validation: 0.5373437947880159]
	TIME [epoch: 10.3 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5005594829785764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5005594829785764 | validation: 0.5034159283746051]
	TIME [epoch: 10.3 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.543891991378899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.543891991378899 | validation: 0.561432186891037]
	TIME [epoch: 10.3 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5118507632619533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5118507632619533 | validation: 0.390930102497594]
	TIME [epoch: 10.3 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46318250416423323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46318250416423323 | validation: 0.6184959377033843]
	TIME [epoch: 10.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49166516601022925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49166516601022925 | validation: 0.4104060067279907]
	TIME [epoch: 10.3 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5091851427956845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5091851427956845 | validation: 0.7291048462832472]
	TIME [epoch: 10.3 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6619400306271332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6619400306271332 | validation: 0.45693651647263117]
	TIME [epoch: 10.3 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48087729611073593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48087729611073593 | validation: 0.4773319660569316]
	TIME [epoch: 10.3 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4508031531170487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4508031531170487 | validation: 0.7839236877631881]
	TIME [epoch: 10.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7851104830140294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7851104830140294 | validation: 1.1305481476230919]
	TIME [epoch: 10.3 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9546356564725414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9546356564725414 | validation: 0.5502645601909802]
	TIME [epoch: 10.3 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8246813704750403		[learning rate: 0.0099755]
	Learning Rate: 0.00997547
	LOSS [training: 0.8246813704750403 | validation: 0.6337728422006927]
	TIME [epoch: 10.3 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5424340015634832		[learning rate: 0.0099449]
	Learning Rate: 0.00994489
	LOSS [training: 0.5424340015634832 | validation: 0.4350341350959988]
	TIME [epoch: 10.3 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8807584743429174		[learning rate: 0.0099144]
	Learning Rate: 0.0099144
	LOSS [training: 0.8807584743429174 | validation: 0.5587803492753514]
	TIME [epoch: 10.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5329852000020601		[learning rate: 0.009884]
	Learning Rate: 0.00988401
	LOSS [training: 0.5329852000020601 | validation: 0.7413676045832707]
	TIME [epoch: 10.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9142556471295975		[learning rate: 0.0098537]
	Learning Rate: 0.00985371
	LOSS [training: 1.9142556471295975 | validation: 0.63212876345164]
	TIME [epoch: 10.3 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7594784670532209		[learning rate: 0.0098235]
	Learning Rate: 0.00982351
	LOSS [training: 0.7594784670532209 | validation: 0.38666430297429216]
	TIME [epoch: 10.3 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5158272105935866		[learning rate: 0.0097934]
	Learning Rate: 0.0097934
	LOSS [training: 0.5158272105935866 | validation: 0.7616713883722394]
	TIME [epoch: 10.3 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6273189544338165		[learning rate: 0.0097634]
	Learning Rate: 0.00976337
	LOSS [training: 0.6273189544338165 | validation: 0.6737595531334327]
	TIME [epoch: 10.3 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6724058122709929		[learning rate: 0.0097334]
	Learning Rate: 0.00973345
	LOSS [training: 0.6724058122709929 | validation: 0.6271329407544378]
	TIME [epoch: 10.3 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5255780421022151		[learning rate: 0.0097036]
	Learning Rate: 0.00970361
	LOSS [training: 0.5255780421022151 | validation: 0.5629926213680545]
	TIME [epoch: 10.3 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46742133304678496		[learning rate: 0.0096739]
	Learning Rate: 0.00967386
	LOSS [training: 0.46742133304678496 | validation: 0.5976106201477392]
	TIME [epoch: 10.3 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4329513800699569		[learning rate: 0.0096442]
	Learning Rate: 0.00964421
	LOSS [training: 0.4329513800699569 | validation: 0.3838973355838064]
	TIME [epoch: 10.3 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4211881565705906		[learning rate: 0.0096146]
	Learning Rate: 0.00961465
	LOSS [training: 0.4211881565705906 | validation: 0.47640708900885487]
	TIME [epoch: 10.3 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39713006212150165		[learning rate: 0.0095852]
	Learning Rate: 0.00958517
	LOSS [training: 0.39713006212150165 | validation: 0.4966261575650705]
	TIME [epoch: 10.3 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45702798414174683		[learning rate: 0.0095558]
	Learning Rate: 0.00955579
	LOSS [training: 0.45702798414174683 | validation: 0.44233111446907186]
	TIME [epoch: 10.3 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.573463847013688		[learning rate: 0.0095265]
	Learning Rate: 0.0095265
	LOSS [training: 0.573463847013688 | validation: 1.2679497565120241]
	TIME [epoch: 10.3 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7583908814660416		[learning rate: 0.0094973]
	Learning Rate: 0.0094973
	LOSS [training: 0.7583908814660416 | validation: 0.5215558454201428]
	TIME [epoch: 10.3 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4703935814473127		[learning rate: 0.0094682]
	Learning Rate: 0.00946818
	LOSS [training: 0.4703935814473127 | validation: 0.5455130310931986]
	TIME [epoch: 10.3 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.469953224267745		[learning rate: 0.0094392]
	Learning Rate: 0.00943916
	LOSS [training: 0.469953224267745 | validation: 0.46853836852171254]
	TIME [epoch: 10.3 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45594180635261006		[learning rate: 0.0094102]
	Learning Rate: 0.00941022
	LOSS [training: 0.45594180635261006 | validation: 0.5381079317545678]
	TIME [epoch: 10.3 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43525118204033575		[learning rate: 0.0093814]
	Learning Rate: 0.00938138
	LOSS [training: 0.43525118204033575 | validation: 0.38513297359263204]
	TIME [epoch: 10.3 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38908198519403026		[learning rate: 0.0093526]
	Learning Rate: 0.00935262
	LOSS [training: 0.38908198519403026 | validation: 0.7709844622203967]
	TIME [epoch: 10.3 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1321823250562781		[learning rate: 0.009324]
	Learning Rate: 0.00932395
	LOSS [training: 1.1321823250562781 | validation: 0.898339969779098]
	TIME [epoch: 10.3 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6769431674778517		[learning rate: 0.0092954]
	Learning Rate: 0.00929537
	LOSS [training: 0.6769431674778517 | validation: 0.2388752525982035]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2892466599525346		[learning rate: 0.0092669]
	Learning Rate: 0.00926687
	LOSS [training: 0.2892466599525346 | validation: 0.22188825606290777]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_525.pth
	Model improved!!!
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4155003730488893		[learning rate: 0.0092385]
	Learning Rate: 0.00923847
	LOSS [training: 0.4155003730488893 | validation: 0.29085418861217777]
	TIME [epoch: 10.3 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.269671038150458		[learning rate: 0.0092101]
	Learning Rate: 0.00921015
	LOSS [training: 0.269671038150458 | validation: 0.18766957054548766]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2602228902359024		[learning rate: 0.0091819]
	Learning Rate: 0.00918192
	LOSS [training: 0.2602228902359024 | validation: 0.23220099972820804]
	TIME [epoch: 10.3 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2753443983387478		[learning rate: 0.0091538]
	Learning Rate: 0.00915377
	LOSS [training: 0.2753443983387478 | validation: 0.4182217179702947]
	TIME [epoch: 10.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4216967151810539		[learning rate: 0.0091257]
	Learning Rate: 0.00912571
	LOSS [training: 0.4216967151810539 | validation: 0.3257694117959197]
	TIME [epoch: 10.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23919695616488065		[learning rate: 0.0090977]
	Learning Rate: 0.00909774
	LOSS [training: 0.23919695616488065 | validation: 0.2867642140595708]
	TIME [epoch: 10.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2747708300130614		[learning rate: 0.0090698]
	Learning Rate: 0.00906985
	LOSS [training: 0.2747708300130614 | validation: 0.732534768900901]
	TIME [epoch: 10.3 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43238037979235333		[learning rate: 0.009042]
	Learning Rate: 0.00904205
	LOSS [training: 0.43238037979235333 | validation: 0.22798460496156697]
	TIME [epoch: 10.3 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19079955004448407		[learning rate: 0.0090143]
	Learning Rate: 0.00901433
	LOSS [training: 0.19079955004448407 | validation: 0.31087554057496425]
	TIME [epoch: 10.3 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40472723093204505		[learning rate: 0.0089867]
	Learning Rate: 0.00898669
	LOSS [training: 0.40472723093204505 | validation: 0.2183030514162398]
	TIME [epoch: 10.3 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39920170708008285		[learning rate: 0.0089591]
	Learning Rate: 0.00895915
	LOSS [training: 0.39920170708008285 | validation: 0.1953002442254887]
	TIME [epoch: 10.3 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1819202301987442		[learning rate: 0.0089317]
	Learning Rate: 0.00893168
	LOSS [training: 0.1819202301987442 | validation: 0.242306788484725]
	TIME [epoch: 10.3 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6847812222983484		[learning rate: 0.0089043]
	Learning Rate: 0.0089043
	LOSS [training: 0.6847812222983484 | validation: 0.9162835593961441]
	TIME [epoch: 10.3 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4883588222729096		[learning rate: 0.008877]
	Learning Rate: 0.00887701
	LOSS [training: 0.4883588222729096 | validation: 0.42120609472990994]
	TIME [epoch: 10.3 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5311111929522845		[learning rate: 0.0088498]
	Learning Rate: 0.0088498
	LOSS [training: 0.5311111929522845 | validation: 2.1260999299553474]
	TIME [epoch: 10.3 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4128267909715264		[learning rate: 0.0088227]
	Learning Rate: 0.00882267
	LOSS [training: 2.4128267909715264 | validation: 0.816050393317469]
	TIME [epoch: 10.3 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5231571222746332		[learning rate: 0.0087956]
	Learning Rate: 0.00879562
	LOSS [training: 0.5231571222746332 | validation: 0.359534940813432]
	TIME [epoch: 10.3 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4005407402767542		[learning rate: 0.0087687]
	Learning Rate: 0.00876866
	LOSS [training: 0.4005407402767542 | validation: 0.49653802479889636]
	TIME [epoch: 10.3 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3420302353118118		[learning rate: 0.0087418]
	Learning Rate: 0.00874178
	LOSS [training: 0.3420302353118118 | validation: 0.2809033427242397]
	TIME [epoch: 10.3 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2917647163486996		[learning rate: 0.008715]
	Learning Rate: 0.00871499
	LOSS [training: 0.2917647163486996 | validation: 0.2737201489014944]
	TIME [epoch: 10.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45878972417562186		[learning rate: 0.0086883]
	Learning Rate: 0.00868827
	LOSS [training: 0.45878972417562186 | validation: 0.5804961374721972]
	TIME [epoch: 10.3 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49508624986861055		[learning rate: 0.0086616]
	Learning Rate: 0.00866164
	LOSS [training: 0.49508624986861055 | validation: 0.4055416551128204]
	TIME [epoch: 10.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3466810440723719		[learning rate: 0.0086351]
	Learning Rate: 0.00863509
	LOSS [training: 0.3466810440723719 | validation: 0.1758774825868624]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20019974173305544		[learning rate: 0.0086086]
	Learning Rate: 0.00860862
	LOSS [training: 0.20019974173305544 | validation: 0.38144928244329707]
	TIME [epoch: 10.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3639079792116957		[learning rate: 0.0085822]
	Learning Rate: 0.00858223
	LOSS [training: 0.3639079792116957 | validation: 0.29181080104993146]
	TIME [epoch: 10.3 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21856953016927405		[learning rate: 0.0085559]
	Learning Rate: 0.00855592
	LOSS [training: 0.21856953016927405 | validation: 0.14662836908457128]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_551.pth
	Model improved!!!
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2699714140232203		[learning rate: 0.0085297]
	Learning Rate: 0.00852969
	LOSS [training: 0.2699714140232203 | validation: 0.6872339006252662]
	TIME [epoch: 10.3 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46665125594294476		[learning rate: 0.0085035]
	Learning Rate: 0.00850354
	LOSS [training: 0.46665125594294476 | validation: 0.27034211297894706]
	TIME [epoch: 10.3 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3860204754687414		[learning rate: 0.0084775]
	Learning Rate: 0.00847748
	LOSS [training: 0.3860204754687414 | validation: 0.3322612812044148]
	TIME [epoch: 10.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25990662982727786		[learning rate: 0.0084515]
	Learning Rate: 0.00845149
	LOSS [training: 0.25990662982727786 | validation: 0.23141969617657515]
	TIME [epoch: 10.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34468738952030836		[learning rate: 0.0084256]
	Learning Rate: 0.00842558
	LOSS [training: 0.34468738952030836 | validation: 0.3504838450932942]
	TIME [epoch: 10.3 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2827158658908865		[learning rate: 0.0083998]
	Learning Rate: 0.00839976
	LOSS [training: 0.2827158658908865 | validation: 0.46804500957699674]
	TIME [epoch: 10.3 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29942972608677176		[learning rate: 0.008374]
	Learning Rate: 0.00837401
	LOSS [training: 0.29942972608677176 | validation: 0.3103599383702036]
	TIME [epoch: 10.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2454053859862527		[learning rate: 0.0083483]
	Learning Rate: 0.00834834
	LOSS [training: 0.2454053859862527 | validation: 0.3707587299207746]
	TIME [epoch: 10.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26008528257367		[learning rate: 0.0083227]
	Learning Rate: 0.00832275
	LOSS [training: 0.26008528257367 | validation: 0.26243262952894164]
	TIME [epoch: 10.3 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.394359793123057		[learning rate: 0.0082972]
	Learning Rate: 0.00829723
	LOSS [training: 0.394359793123057 | validation: 0.31116973664730585]
	TIME [epoch: 10.3 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2932597086806104		[learning rate: 0.0082718]
	Learning Rate: 0.0082718
	LOSS [training: 0.2932597086806104 | validation: 0.4453847401962525]
	TIME [epoch: 10.3 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4448822424885961		[learning rate: 0.0082464]
	Learning Rate: 0.00824644
	LOSS [training: 0.4448822424885961 | validation: 0.5277337296957879]
	TIME [epoch: 10.2 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46069529041738855		[learning rate: 0.0082212]
	Learning Rate: 0.00822116
	LOSS [training: 0.46069529041738855 | validation: 0.6316548919344297]
	TIME [epoch: 10.3 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5389707287273288		[learning rate: 0.008196]
	Learning Rate: 0.00819596
	LOSS [training: 0.5389707287273288 | validation: 0.2947647715021611]
	TIME [epoch: 10.3 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44268994053126354		[learning rate: 0.0081708]
	Learning Rate: 0.00817084
	LOSS [training: 0.44268994053126354 | validation: 0.3108455448492242]
	TIME [epoch: 10.3 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27380862832013453		[learning rate: 0.0081458]
	Learning Rate: 0.00814579
	LOSS [training: 0.27380862832013453 | validation: 0.2910277969188372]
	TIME [epoch: 10.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21366310344492062		[learning rate: 0.0081208]
	Learning Rate: 0.00812082
	LOSS [training: 0.21366310344492062 | validation: 0.2210526380095304]
	TIME [epoch: 10.3 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18662298484996379		[learning rate: 0.0080959]
	Learning Rate: 0.00809593
	LOSS [training: 0.18662298484996379 | validation: 0.4313720685745211]
	TIME [epoch: 10.3 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36210513077598405		[learning rate: 0.0080711]
	Learning Rate: 0.00807111
	LOSS [training: 0.36210513077598405 | validation: 0.3923271067745979]
	TIME [epoch: 10.3 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41376727935582724		[learning rate: 0.0080464]
	Learning Rate: 0.00804637
	LOSS [training: 0.41376727935582724 | validation: 0.40211401864904156]
	TIME [epoch: 10.2 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45424558221715		[learning rate: 0.0080217]
	Learning Rate: 0.0080217
	LOSS [training: 0.45424558221715 | validation: 0.40259338857489013]
	TIME [epoch: 10.3 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4190661637381877		[learning rate: 0.0079971]
	Learning Rate: 0.00799711
	LOSS [training: 0.4190661637381877 | validation: 0.4509582749302045]
	TIME [epoch: 10.3 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3382221141340601		[learning rate: 0.0079726]
	Learning Rate: 0.0079726
	LOSS [training: 0.3382221141340601 | validation: 0.39995223254931767]
	TIME [epoch: 10.3 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29757632095859643		[learning rate: 0.0079482]
	Learning Rate: 0.00794816
	LOSS [training: 0.29757632095859643 | validation: 0.17822891411057554]
	TIME [epoch: 10.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23413041006447619		[learning rate: 0.0079238]
	Learning Rate: 0.0079238
	LOSS [training: 0.23413041006447619 | validation: 0.22345551217886375]
	TIME [epoch: 10.3 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20192557864892774		[learning rate: 0.0078995]
	Learning Rate: 0.00789951
	LOSS [training: 0.20192557864892774 | validation: 0.2642216073122764]
	TIME [epoch: 10.3 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2578389483178776		[learning rate: 0.0078753]
	Learning Rate: 0.00787529
	LOSS [training: 0.2578389483178776 | validation: 0.5125502191581169]
	TIME [epoch: 10.3 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39950996374282727		[learning rate: 0.0078512]
	Learning Rate: 0.00785115
	LOSS [training: 0.39950996374282727 | validation: 0.6197718744520097]
	TIME [epoch: 10.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44267670966663547		[learning rate: 0.0078271]
	Learning Rate: 0.00782708
	LOSS [training: 0.44267670966663547 | validation: 1.3461790214223657]
	TIME [epoch: 10.3 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2676771509816098		[learning rate: 0.0078031]
	Learning Rate: 0.00780309
	LOSS [training: 1.2676771509816098 | validation: 0.6895453835168306]
	TIME [epoch: 10.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6514652867387289		[learning rate: 0.0077792]
	Learning Rate: 0.00777917
	LOSS [training: 0.6514652867387289 | validation: 0.2651482705930119]
	TIME [epoch: 10.3 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2975202428904402		[learning rate: 0.0077553]
	Learning Rate: 0.00775532
	LOSS [training: 0.2975202428904402 | validation: 0.44504407218740966]
	TIME [epoch: 10.3 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3046707737697365		[learning rate: 0.0077316]
	Learning Rate: 0.00773155
	LOSS [training: 0.3046707737697365 | validation: 0.381016527180516]
	TIME [epoch: 10.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34587059656106706		[learning rate: 0.0077079]
	Learning Rate: 0.00770785
	LOSS [training: 0.34587059656106706 | validation: 0.5025943963815754]
	TIME [epoch: 10.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.541635738869596		[learning rate: 0.0076842]
	Learning Rate: 0.00768422
	LOSS [training: 0.541635738869596 | validation: 1.3543298516119426]
	TIME [epoch: 10.3 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9387907808804629		[learning rate: 0.0076607]
	Learning Rate: 0.00766067
	LOSS [training: 0.9387907808804629 | validation: 0.795891610007039]
	TIME [epoch: 10.3 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5872800686959042		[learning rate: 0.0076372]
	Learning Rate: 0.00763718
	LOSS [training: 0.5872800686959042 | validation: 0.45265130385603913]
	TIME [epoch: 10.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4589873444349755		[learning rate: 0.0076138]
	Learning Rate: 0.00761377
	LOSS [training: 0.4589873444349755 | validation: 0.4912550169809694]
	TIME [epoch: 10.3 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.540947528675817		[learning rate: 0.0075904]
	Learning Rate: 0.00759043
	LOSS [training: 0.540947528675817 | validation: 0.4350565276404656]
	TIME [epoch: 10.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4476076873477345		[learning rate: 0.0075672]
	Learning Rate: 0.00756717
	LOSS [training: 0.4476076873477345 | validation: 0.3386391604762774]
	TIME [epoch: 10.3 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34406693738114374		[learning rate: 0.007544]
	Learning Rate: 0.00754397
	LOSS [training: 0.34406693738114374 | validation: 0.4323648730529553]
	TIME [epoch: 10.3 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.344659480279134		[learning rate: 0.0075208]
	Learning Rate: 0.00752085
	LOSS [training: 0.344659480279134 | validation: 0.2788963273102838]
	TIME [epoch: 10.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3575726109215889		[learning rate: 0.0074978]
	Learning Rate: 0.00749779
	LOSS [training: 0.3575726109215889 | validation: 0.3770797716153728]
	TIME [epoch: 10.3 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32480567834862656		[learning rate: 0.0074748]
	Learning Rate: 0.00747481
	LOSS [training: 0.32480567834862656 | validation: 0.2157639144899495]
	TIME [epoch: 10.3 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5181472337593986		[learning rate: 0.0074519]
	Learning Rate: 0.00745189
	LOSS [training: 0.5181472337593986 | validation: 0.36345157678852164]
	TIME [epoch: 10.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3521585310301635		[learning rate: 0.0074291]
	Learning Rate: 0.00742905
	LOSS [training: 0.3521585310301635 | validation: 0.3792521890255385]
	TIME [epoch: 10.3 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.017346942108185		[learning rate: 0.0074063]
	Learning Rate: 0.00740628
	LOSS [training: 1.017346942108185 | validation: 1.3020797355221225]
	TIME [epoch: 10.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.854648593637527		[learning rate: 0.0073836]
	Learning Rate: 0.00738357
	LOSS [training: 0.854648593637527 | validation: 0.8014812253251887]
	TIME [epoch: 10.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.779463730429846		[learning rate: 0.0073609]
	Learning Rate: 0.00736094
	LOSS [training: 0.779463730429846 | validation: 0.4669492477675371]
	TIME [epoch: 10.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4288251922395272		[learning rate: 0.0073384]
	Learning Rate: 0.00733838
	LOSS [training: 0.4288251922395272 | validation: 0.6707081251750776]
	TIME [epoch: 10.3 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5066823047923736		[learning rate: 0.0073159]
	Learning Rate: 0.00731588
	LOSS [training: 0.5066823047923736 | validation: 0.44285666708504634]
	TIME [epoch: 10.3 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4258061280332928		[learning rate: 0.0072935]
	Learning Rate: 0.00729345
	LOSS [training: 0.4258061280332928 | validation: 0.32215637566018474]
	TIME [epoch: 10.3 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3654556519496858		[learning rate: 0.0072711]
	Learning Rate: 0.0072711
	LOSS [training: 0.3654556519496858 | validation: 0.3126961024781843]
	TIME [epoch: 10.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4253177673142724		[learning rate: 0.0072488]
	Learning Rate: 0.00724881
	LOSS [training: 0.4253177673142724 | validation: 0.3271825586574821]
	TIME [epoch: 10.2 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35594361598171653		[learning rate: 0.0072266]
	Learning Rate: 0.00722659
	LOSS [training: 0.35594361598171653 | validation: 0.6793998100193767]
	TIME [epoch: 10.3 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.811036992889448		[learning rate: 0.0072044]
	Learning Rate: 0.00720444
	LOSS [training: 0.811036992889448 | validation: 0.4763044969118833]
	TIME [epoch: 10.3 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3304577559961767		[learning rate: 0.0071824]
	Learning Rate: 0.00718235
	LOSS [training: 0.3304577559961767 | validation: 0.2029597505642749]
	TIME [epoch: 10.3 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21836523120233284		[learning rate: 0.0071603]
	Learning Rate: 0.00716033
	LOSS [training: 0.21836523120233284 | validation: 0.43050467772977935]
	TIME [epoch: 10.3 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3347742031246931		[learning rate: 0.0071384]
	Learning Rate: 0.00713838
	LOSS [training: 0.3347742031246931 | validation: 0.5449537644148146]
	TIME [epoch: 10.3 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5092797621667093		[learning rate: 0.0071165]
	Learning Rate: 0.0071165
	LOSS [training: 0.5092797621667093 | validation: 0.443850682079439]
	TIME [epoch: 10.3 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47508171428180007		[learning rate: 0.0070947]
	Learning Rate: 0.00709469
	LOSS [training: 0.47508171428180007 | validation: 0.48622914541742007]
	TIME [epoch: 10.3 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7396163407259638		[learning rate: 0.0070729]
	Learning Rate: 0.00707294
	LOSS [training: 0.7396163407259638 | validation: 0.7313812250294445]
	TIME [epoch: 10.3 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6175450135302387		[learning rate: 0.0070513]
	Learning Rate: 0.00705126
	LOSS [training: 0.6175450135302387 | validation: 0.645930921844623]
	TIME [epoch: 10.3 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5485929941680636		[learning rate: 0.0070296]
	Learning Rate: 0.00702964
	LOSS [training: 0.5485929941680636 | validation: 0.7109447845361332]
	TIME [epoch: 10.3 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5342128678278024		[learning rate: 0.0070081]
	Learning Rate: 0.00700809
	LOSS [training: 0.5342128678278024 | validation: 0.48755869308426997]
	TIME [epoch: 10.3 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44787472230452374		[learning rate: 0.0069866]
	Learning Rate: 0.00698661
	LOSS [training: 0.44787472230452374 | validation: 0.5134136966797354]
	TIME [epoch: 10.3 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5432782337025568		[learning rate: 0.0069652]
	Learning Rate: 0.0069652
	LOSS [training: 0.5432782337025568 | validation: 0.5622913948625966]
	TIME [epoch: 10.3 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4229881905634255		[learning rate: 0.0069438]
	Learning Rate: 0.00694384
	LOSS [training: 0.4229881905634255 | validation: 0.44680326941461707]
	TIME [epoch: 10.3 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30671279780753735		[learning rate: 0.0069226]
	Learning Rate: 0.00692256
	LOSS [training: 0.30671279780753735 | validation: 0.2882093619116503]
	TIME [epoch: 10.3 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34925000326102407		[learning rate: 0.0069013]
	Learning Rate: 0.00690134
	LOSS [training: 0.34925000326102407 | validation: 0.34894236858259475]
	TIME [epoch: 10.3 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3164360599800672		[learning rate: 0.0068802]
	Learning Rate: 0.00688018
	LOSS [training: 0.3164360599800672 | validation: 0.3552669725705245]
	TIME [epoch: 10.3 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27219450806630363		[learning rate: 0.0068591]
	Learning Rate: 0.00685909
	LOSS [training: 0.27219450806630363 | validation: 0.3052090196215494]
	TIME [epoch: 10.3 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3010678121315157		[learning rate: 0.0068381]
	Learning Rate: 0.00683807
	LOSS [training: 0.3010678121315157 | validation: 0.3704835430022313]
	TIME [epoch: 10.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2794050901250551		[learning rate: 0.0068171]
	Learning Rate: 0.0068171
	LOSS [training: 0.2794050901250551 | validation: 0.2977523873051656]
	TIME [epoch: 10.3 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4200695115256419		[learning rate: 0.0067962]
	Learning Rate: 0.00679621
	LOSS [training: 0.4200695115256419 | validation: 0.20184405768373626]
	TIME [epoch: 10.3 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32574092784274544		[learning rate: 0.0067754]
	Learning Rate: 0.00677537
	LOSS [training: 0.32574092784274544 | validation: 0.2860115022381764]
	TIME [epoch: 10.3 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3108952553348229		[learning rate: 0.0067546]
	Learning Rate: 0.00675461
	LOSS [training: 0.3108952553348229 | validation: 0.46503213639854224]
	TIME [epoch: 10.3 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29705784296473536		[learning rate: 0.0067339]
	Learning Rate: 0.0067339
	LOSS [training: 0.29705784296473536 | validation: 0.2270547615978585]
	TIME [epoch: 10.3 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17953202640953297		[learning rate: 0.0067133]
	Learning Rate: 0.00671326
	LOSS [training: 0.17953202640953297 | validation: 0.18189826288998323]
	TIME [epoch: 10.3 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16510176088845868		[learning rate: 0.0066927]
	Learning Rate: 0.00669268
	LOSS [training: 0.16510176088845868 | validation: 0.275808872591139]
	TIME [epoch: 10.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24638217173826357		[learning rate: 0.0066722]
	Learning Rate: 0.00667216
	LOSS [training: 0.24638217173826357 | validation: 0.2163784082100348]
	TIME [epoch: 10.3 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20551227441900446		[learning rate: 0.0066517]
	Learning Rate: 0.00665171
	LOSS [training: 0.20551227441900446 | validation: 0.36203796674017186]
	TIME [epoch: 10.2 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32215630041136967		[learning rate: 0.0066313]
	Learning Rate: 0.00663132
	LOSS [training: 0.32215630041136967 | validation: 0.28120261019710563]
	TIME [epoch: 10.3 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22641160775711358		[learning rate: 0.006611]
	Learning Rate: 0.00661099
	LOSS [training: 0.22641160775711358 | validation: 0.6713318636154907]
	TIME [epoch: 10.3 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7927325073212336		[learning rate: 0.0065907]
	Learning Rate: 0.00659073
	LOSS [training: 0.7927325073212336 | validation: 0.2617949625845269]
	TIME [epoch: 10.3 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1868453029321547		[learning rate: 0.0065705]
	Learning Rate: 0.00657052
	LOSS [training: 0.1868453029321547 | validation: 0.18833511785658283]
	TIME [epoch: 10.3 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20952326046174613		[learning rate: 0.0065504]
	Learning Rate: 0.00655038
	LOSS [training: 0.20952326046174613 | validation: 0.2254444077306342]
	TIME [epoch: 10.3 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16269591473529654		[learning rate: 0.0065303]
	Learning Rate: 0.0065303
	LOSS [training: 0.16269591473529654 | validation: 0.16946244780934624]
	TIME [epoch: 10.3 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1614792291255301		[learning rate: 0.0065103]
	Learning Rate: 0.00651028
	LOSS [training: 0.1614792291255301 | validation: 0.2858006108392213]
	TIME [epoch: 10.3 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29500443092630446		[learning rate: 0.0064903]
	Learning Rate: 0.00649033
	LOSS [training: 0.29500443092630446 | validation: 0.28398542381462344]
	TIME [epoch: 10.3 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24206947270070148		[learning rate: 0.0064704]
	Learning Rate: 0.00647043
	LOSS [training: 0.24206947270070148 | validation: 0.3393226015268585]
	TIME [epoch: 10.3 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31181855660191765		[learning rate: 0.0064506]
	Learning Rate: 0.0064506
	LOSS [training: 0.31181855660191765 | validation: 0.44219531004866297]
	TIME [epoch: 10.3 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3353784566355409		[learning rate: 0.0064308]
	Learning Rate: 0.00643082
	LOSS [training: 0.3353784566355409 | validation: 0.1914435131153774]
	TIME [epoch: 10.3 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15817882275489703		[learning rate: 0.0064111]
	Learning Rate: 0.00641111
	LOSS [training: 0.15817882275489703 | validation: 0.13857412407273217]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_645.pth
	Model improved!!!
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1369683667193434		[learning rate: 0.0063915]
	Learning Rate: 0.00639146
	LOSS [training: 0.1369683667193434 | validation: 0.3013713213454689]
	TIME [epoch: 10.3 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7259263495476398		[learning rate: 0.0063719]
	Learning Rate: 0.00637187
	LOSS [training: 0.7259263495476398 | validation: 0.3776954144986741]
	TIME [epoch: 10.3 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7895071196239413		[learning rate: 0.0063523]
	Learning Rate: 0.00635233
	LOSS [training: 0.7895071196239413 | validation: 0.6343836034828351]
	TIME [epoch: 10.3 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4540079492202592		[learning rate: 0.0063329]
	Learning Rate: 0.00633286
	LOSS [training: 0.4540079492202592 | validation: 0.22993082918687258]
	TIME [epoch: 10.3 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22704332959131945		[learning rate: 0.0063134]
	Learning Rate: 0.00631345
	LOSS [training: 0.22704332959131945 | validation: 0.16037633842110488]
	TIME [epoch: 10.3 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14281337730867297		[learning rate: 0.0062941]
	Learning Rate: 0.0062941
	LOSS [training: 0.14281337730867297 | validation: 0.14366206468884113]
	TIME [epoch: 10.3 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3098835517354178		[learning rate: 0.0062748]
	Learning Rate: 0.0062748
	LOSS [training: 0.3098835517354178 | validation: 0.21716202561086514]
	TIME [epoch: 10.3 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1749602795547685		[learning rate: 0.0062556]
	Learning Rate: 0.00625557
	LOSS [training: 0.1749602795547685 | validation: 0.19434175953332836]
	TIME [epoch: 10.3 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3648893264848339		[learning rate: 0.0062364]
	Learning Rate: 0.00623639
	LOSS [training: 0.3648893264848339 | validation: 0.48629250741051383]
	TIME [epoch: 10.3 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4422595543026075		[learning rate: 0.0062173]
	Learning Rate: 0.00621727
	LOSS [training: 0.4422595543026075 | validation: 0.28760491001718064]
	TIME [epoch: 10.3 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42248251939252707		[learning rate: 0.0061982]
	Learning Rate: 0.00619822
	LOSS [training: 0.42248251939252707 | validation: 0.26528147297436255]
	TIME [epoch: 10.3 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22583804424030904		[learning rate: 0.0061792]
	Learning Rate: 0.00617922
	LOSS [training: 0.22583804424030904 | validation: 0.2395178215703517]
	TIME [epoch: 10.3 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18890221151370223		[learning rate: 0.0061603]
	Learning Rate: 0.00616027
	LOSS [training: 0.18890221151370223 | validation: 0.25460371411382443]
	TIME [epoch: 10.3 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16191649983066514		[learning rate: 0.0061414]
	Learning Rate: 0.00614139
	LOSS [training: 0.16191649983066514 | validation: 0.17906060126359993]
	TIME [epoch: 10.3 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3962246567385479		[learning rate: 0.0061226]
	Learning Rate: 0.00612256
	LOSS [training: 0.3962246567385479 | validation: 1.3202010731887055]
	TIME [epoch: 10.3 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7307526131772284		[learning rate: 0.0061038]
	Learning Rate: 0.0061038
	LOSS [training: 0.7307526131772284 | validation: 0.26883083388080936]
	TIME [epoch: 10.3 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.283431319637518		[learning rate: 0.0060851]
	Learning Rate: 0.00608508
	LOSS [training: 0.283431319637518 | validation: 0.2470051596776724]
	TIME [epoch: 10.3 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21358587238614857		[learning rate: 0.0060664]
	Learning Rate: 0.00606643
	LOSS [training: 0.21358587238614857 | validation: 0.2697285673999328]
	TIME [epoch: 10.3 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1912540056111907		[learning rate: 0.0060478]
	Learning Rate: 0.00604784
	LOSS [training: 0.1912540056111907 | validation: 0.24380513537169865]
	TIME [epoch: 10.3 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.202088774139806		[learning rate: 0.0060293]
	Learning Rate: 0.0060293
	LOSS [training: 0.202088774139806 | validation: 0.7319759105035439]
	TIME [epoch: 10.3 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6558248468121991		[learning rate: 0.0060108]
	Learning Rate: 0.00601081
	LOSS [training: 0.6558248468121991 | validation: 0.5865819211678455]
	TIME [epoch: 10.3 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5929784336842816		[learning rate: 0.0059924]
	Learning Rate: 0.00599239
	LOSS [training: 0.5929784336842816 | validation: 0.22617695432091772]
	TIME [epoch: 10.3 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2759122562334695		[learning rate: 0.005974]
	Learning Rate: 0.00597402
	LOSS [training: 0.2759122562334695 | validation: 0.21650167898658138]
	TIME [epoch: 10.3 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.559754758161775		[learning rate: 0.0059557]
	Learning Rate: 0.00595571
	LOSS [training: 0.559754758161775 | validation: 0.8531342287233619]
	TIME [epoch: 10.3 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.987360891089353		[learning rate: 0.0059375]
	Learning Rate: 0.00593745
	LOSS [training: 0.987360891089353 | validation: 0.5513704430304277]
	TIME [epoch: 10.3 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6071929764298621		[learning rate: 0.0059192]
	Learning Rate: 0.00591925
	LOSS [training: 0.6071929764298621 | validation: 0.3836926906744658]
	TIME [epoch: 10.3 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38293682977072513		[learning rate: 0.0059011]
	Learning Rate: 0.0059011
	LOSS [training: 0.38293682977072513 | validation: 0.21980503308581192]
	TIME [epoch: 10.3 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1816691827398227		[learning rate: 0.005883]
	Learning Rate: 0.00588302
	LOSS [training: 0.1816691827398227 | validation: 0.19244442936408812]
	TIME [epoch: 10.3 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12527001595498857		[learning rate: 0.005865]
	Learning Rate: 0.00586498
	LOSS [training: 0.12527001595498857 | validation: 0.15500382929244955]
	TIME [epoch: 10.3 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10812461229133614		[learning rate: 0.005847]
	Learning Rate: 0.005847
	LOSS [training: 0.10812461229133614 | validation: 0.167060219343704]
	TIME [epoch: 10.3 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19129837352919793		[learning rate: 0.0058291]
	Learning Rate: 0.00582908
	LOSS [training: 0.19129837352919793 | validation: 0.4693155157024001]
	TIME [epoch: 10.2 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17614244342327381		[learning rate: 0.0058112]
	Learning Rate: 0.00581121
	LOSS [training: 0.17614244342327381 | validation: 0.15387257857679487]
	TIME [epoch: 10.3 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09874606005466133		[learning rate: 0.0057934]
	Learning Rate: 0.0057934
	LOSS [training: 0.09874606005466133 | validation: 0.1486388215267014]
	TIME [epoch: 10.2 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31489718465341293		[learning rate: 0.0057756]
	Learning Rate: 0.00577564
	LOSS [training: 0.31489718465341293 | validation: 0.2694550232982725]
	TIME [epoch: 10.3 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23756164349546913		[learning rate: 0.0057579]
	Learning Rate: 0.00575793
	LOSS [training: 0.23756164349546913 | validation: 0.19192993698111152]
	TIME [epoch: 10.3 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1735747983679966		[learning rate: 0.0057403]
	Learning Rate: 0.00574028
	LOSS [training: 0.1735747983679966 | validation: 0.24869373684136645]
	TIME [epoch: 10.2 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18651858758665135		[learning rate: 0.0057227]
	Learning Rate: 0.00572269
	LOSS [training: 0.18651858758665135 | validation: 0.16437524893415414]
	TIME [epoch: 10.2 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11619604961883875		[learning rate: 0.0057051]
	Learning Rate: 0.00570514
	LOSS [training: 0.11619604961883875 | validation: 0.18321454165390422]
	TIME [epoch: 10.3 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1419763608307385		[learning rate: 0.0056877]
	Learning Rate: 0.00568766
	LOSS [training: 0.1419763608307385 | validation: 0.43487054886949433]
	TIME [epoch: 10.3 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23734931357096736		[learning rate: 0.0056702]
	Learning Rate: 0.00567022
	LOSS [training: 0.23734931357096736 | validation: 0.2132231181052375]
	TIME [epoch: 10.3 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22377345393016962		[learning rate: 0.0056528]
	Learning Rate: 0.00565284
	LOSS [training: 0.22377345393016962 | validation: 0.28889348602048315]
	TIME [epoch: 10.3 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22719442546345592		[learning rate: 0.0056355]
	Learning Rate: 0.00563551
	LOSS [training: 0.22719442546345592 | validation: 0.1805023702025837]
	TIME [epoch: 10.3 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14680111647637156		[learning rate: 0.0056182]
	Learning Rate: 0.00561824
	LOSS [training: 0.14680111647637156 | validation: 0.1475357920933311]
	TIME [epoch: 10.2 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1724798770111883		[learning rate: 0.005601]
	Learning Rate: 0.00560101
	LOSS [training: 0.1724798770111883 | validation: 0.2935217378093236]
	TIME [epoch: 10.2 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31035769690175175		[learning rate: 0.0055838]
	Learning Rate: 0.00558384
	LOSS [training: 0.31035769690175175 | validation: 0.41297646865126003]
	TIME [epoch: 10.3 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40561224199152635		[learning rate: 0.0055667]
	Learning Rate: 0.00556673
	LOSS [training: 0.40561224199152635 | validation: 0.6461135750373639]
	TIME [epoch: 10.3 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5660900593118534		[learning rate: 0.0055497]
	Learning Rate: 0.00554966
	LOSS [training: 0.5660900593118534 | validation: 0.663925819273991]
	TIME [epoch: 10.2 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.977733790909685		[learning rate: 0.0055327]
	Learning Rate: 0.00553265
	LOSS [training: 1.977733790909685 | validation: 0.677707621616058]
	TIME [epoch: 10.3 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.532068342010043		[learning rate: 0.0055157]
	Learning Rate: 0.00551569
	LOSS [training: 0.532068342010043 | validation: 0.36848134864899557]
	TIME [epoch: 10.2 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3032916774013292		[learning rate: 0.0054988]
	Learning Rate: 0.00549878
	LOSS [training: 0.3032916774013292 | validation: 0.28219728582544223]
	TIME [epoch: 10.3 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2682494860119544		[learning rate: 0.0054819]
	Learning Rate: 0.00548193
	LOSS [training: 0.2682494860119544 | validation: 0.19868147744476494]
	TIME [epoch: 10.3 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19766198022113993		[learning rate: 0.0054651]
	Learning Rate: 0.00546512
	LOSS [training: 0.19766198022113993 | validation: 0.20322587775242545]
	TIME [epoch: 10.3 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2401051930916132		[learning rate: 0.0054484]
	Learning Rate: 0.00544837
	LOSS [training: 0.2401051930916132 | validation: 0.25775896820065386]
	TIME [epoch: 10.3 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21787958457200407		[learning rate: 0.0054317]
	Learning Rate: 0.00543167
	LOSS [training: 0.21787958457200407 | validation: 0.2284982374334772]
	TIME [epoch: 10.3 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2274494173237449		[learning rate: 0.005415]
	Learning Rate: 0.00541502
	LOSS [training: 0.2274494173237449 | validation: 0.17404300078831866]
	TIME [epoch: 10.3 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26647843469525806		[learning rate: 0.0053984]
	Learning Rate: 0.00539842
	LOSS [training: 0.26647843469525806 | validation: 0.18338194298659752]
	TIME [epoch: 10.3 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1965705940804668		[learning rate: 0.0053819]
	Learning Rate: 0.00538187
	LOSS [training: 0.1965705940804668 | validation: 0.18692406170186693]
	TIME [epoch: 10.2 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13342961327472297		[learning rate: 0.0053654]
	Learning Rate: 0.00536537
	LOSS [training: 0.13342961327472297 | validation: 0.12989785711423818]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_703.pth
	Model improved!!!
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16736806067642088		[learning rate: 0.0053489]
	Learning Rate: 0.00534893
	LOSS [training: 0.16736806067642088 | validation: 0.25439484687182834]
	TIME [epoch: 10.3 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18348041820509797		[learning rate: 0.0053325]
	Learning Rate: 0.00533253
	LOSS [training: 0.18348041820509797 | validation: 0.25464149167149525]
	TIME [epoch: 10.3 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2328459050433299		[learning rate: 0.0053162]
	Learning Rate: 0.00531618
	LOSS [training: 0.2328459050433299 | validation: 0.156686594293978]
	TIME [epoch: 10.3 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27693622853269445		[learning rate: 0.0052999]
	Learning Rate: 0.00529989
	LOSS [training: 0.27693622853269445 | validation: 0.2846541508408398]
	TIME [epoch: 10.3 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6445302249529156		[learning rate: 0.0052836]
	Learning Rate: 0.00528364
	LOSS [training: 0.6445302249529156 | validation: 0.6796559186811626]
	TIME [epoch: 10.3 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6476402770859033		[learning rate: 0.0052674]
	Learning Rate: 0.00526744
	LOSS [training: 0.6476402770859033 | validation: 0.39744620422304766]
	TIME [epoch: 10.3 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2945178231546648		[learning rate: 0.0052513]
	Learning Rate: 0.0052513
	LOSS [training: 0.2945178231546648 | validation: 0.30480291441302065]
	TIME [epoch: 10.3 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18289982519312695		[learning rate: 0.0052352]
	Learning Rate: 0.0052352
	LOSS [training: 0.18289982519312695 | validation: 0.1809748248699912]
	TIME [epoch: 10.3 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15433274518597756		[learning rate: 0.0052192]
	Learning Rate: 0.00521915
	LOSS [training: 0.15433274518597756 | validation: 0.3160787786142991]
	TIME [epoch: 10.3 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20249682900756455		[learning rate: 0.0052032]
	Learning Rate: 0.00520315
	LOSS [training: 0.20249682900756455 | validation: 0.13920012484446903]
	TIME [epoch: 10.3 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1654849495997805		[learning rate: 0.0051872]
	Learning Rate: 0.0051872
	LOSS [training: 0.1654849495997805 | validation: 0.1670626613545108]
	TIME [epoch: 10.3 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525727908761426		[learning rate: 0.0051713]
	Learning Rate: 0.0051713
	LOSS [training: 0.1525727908761426 | validation: 0.18289614779063654]
	TIME [epoch: 10.3 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1524050380276417		[learning rate: 0.0051555]
	Learning Rate: 0.00515545
	LOSS [training: 0.1524050380276417 | validation: 0.1844730059465149]
	TIME [epoch: 10.3 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21368945917053384		[learning rate: 0.0051396]
	Learning Rate: 0.00513965
	LOSS [training: 0.21368945917053384 | validation: 0.25150898006719646]
	TIME [epoch: 10.3 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21579688965077998		[learning rate: 0.0051239]
	Learning Rate: 0.00512389
	LOSS [training: 0.21579688965077998 | validation: 0.33886593780391666]
	TIME [epoch: 10.3 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26231442549652567		[learning rate: 0.0051082]
	Learning Rate: 0.00510819
	LOSS [training: 0.26231442549652567 | validation: 0.27201910091455894]
	TIME [epoch: 10.3 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15670186660029234		[learning rate: 0.0050925]
	Learning Rate: 0.00509253
	LOSS [training: 0.15670186660029234 | validation: 0.15513751203458426]
	TIME [epoch: 10.3 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14469845937038942		[learning rate: 0.0050769]
	Learning Rate: 0.00507692
	LOSS [training: 0.14469845937038942 | validation: 0.15189169416804052]
	TIME [epoch: 10.3 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2094422237514079		[learning rate: 0.0050614]
	Learning Rate: 0.00506135
	LOSS [training: 0.2094422237514079 | validation: 0.42341326152214837]
	TIME [epoch: 10.3 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32941468719983463		[learning rate: 0.0050458]
	Learning Rate: 0.00504584
	LOSS [training: 0.32941468719983463 | validation: 0.4394742907099668]
	TIME [epoch: 10.3 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26470120996373836		[learning rate: 0.0050304]
	Learning Rate: 0.00503037
	LOSS [training: 0.26470120996373836 | validation: 0.25768134191520764]
	TIME [epoch: 10.3 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16768583724271902		[learning rate: 0.005015]
	Learning Rate: 0.00501495
	LOSS [training: 0.16768583724271902 | validation: 0.17962082220222392]
	TIME [epoch: 10.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12759192730293162		[learning rate: 0.0049996]
	Learning Rate: 0.00499958
	LOSS [training: 0.12759192730293162 | validation: 0.16676931620601437]
	TIME [epoch: 10.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10582961806155836		[learning rate: 0.0049843]
	Learning Rate: 0.00498425
	LOSS [training: 0.10582961806155836 | validation: 0.20160723316263376]
	TIME [epoch: 10.3 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11790697238579924		[learning rate: 0.004969]
	Learning Rate: 0.00496897
	LOSS [training: 0.11790697238579924 | validation: 0.2696544043105771]
	TIME [epoch: 10.3 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16396547162135416		[learning rate: 0.0049537]
	Learning Rate: 0.00495374
	LOSS [training: 0.16396547162135416 | validation: 0.14308215003850777]
	TIME [epoch: 10.3 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10224163645757749		[learning rate: 0.0049386]
	Learning Rate: 0.00493856
	LOSS [training: 0.10224163645757749 | validation: 0.13775627790884118]
	TIME [epoch: 10.3 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14495708061239093		[learning rate: 0.0049234]
	Learning Rate: 0.00492342
	LOSS [training: 0.14495708061239093 | validation: 0.2164745486802487]
	TIME [epoch: 10.3 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1661297655630309		[learning rate: 0.0049083]
	Learning Rate: 0.00490832
	LOSS [training: 0.1661297655630309 | validation: 0.23589495338825586]
	TIME [epoch: 10.3 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1273645766387948		[learning rate: 0.0048933]
	Learning Rate: 0.00489328
	LOSS [training: 0.1273645766387948 | validation: 0.15676481227738218]
	TIME [epoch: 10.3 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16462686186105685		[learning rate: 0.0048783]
	Learning Rate: 0.00487828
	LOSS [training: 0.16462686186105685 | validation: 0.24058406085735357]
	TIME [epoch: 10.3 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16147120229567538		[learning rate: 0.0048633]
	Learning Rate: 0.00486333
	LOSS [training: 0.16147120229567538 | validation: 0.19808931684390957]
	TIME [epoch: 10.3 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11780396653505995		[learning rate: 0.0048484]
	Learning Rate: 0.00484842
	LOSS [training: 0.11780396653505995 | validation: 0.15142375119300908]
	TIME [epoch: 10.3 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532269874079819		[learning rate: 0.0048336]
	Learning Rate: 0.00483355
	LOSS [training: 0.1532269874079819 | validation: 0.17264984275105696]
	TIME [epoch: 10.3 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17969884896951932		[learning rate: 0.0048187]
	Learning Rate: 0.00481874
	LOSS [training: 0.17969884896951932 | validation: 0.17299830799391636]
	TIME [epoch: 10.3 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11750937299616782		[learning rate: 0.004804]
	Learning Rate: 0.00480397
	LOSS [training: 0.11750937299616782 | validation: 0.13426403069138373]
	TIME [epoch: 10.3 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526815973854699		[learning rate: 0.0047892]
	Learning Rate: 0.00478924
	LOSS [training: 0.1526815973854699 | validation: 0.19132600219080054]
	TIME [epoch: 10.3 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19028903746964548		[learning rate: 0.0047746]
	Learning Rate: 0.00477456
	LOSS [training: 0.19028903746964548 | validation: 0.2231411633997265]
	TIME [epoch: 10.3 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1725826648203435		[learning rate: 0.0047599]
	Learning Rate: 0.00475992
	LOSS [training: 0.1725826648203435 | validation: 0.25802276146116215]
	TIME [epoch: 10.3 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15792256963490295		[learning rate: 0.0047453]
	Learning Rate: 0.00474533
	LOSS [training: 0.15792256963490295 | validation: 0.18675935312550443]
	TIME [epoch: 10.3 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15882098043702697		[learning rate: 0.0047308]
	Learning Rate: 0.00473079
	LOSS [training: 0.15882098043702697 | validation: 0.1575188576074526]
	TIME [epoch: 10.3 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12448655240271726		[learning rate: 0.0047163]
	Learning Rate: 0.00471628
	LOSS [training: 0.12448655240271726 | validation: 0.16611851781286016]
	TIME [epoch: 10.3 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1295960180877703		[learning rate: 0.0047018]
	Learning Rate: 0.00470183
	LOSS [training: 0.1295960180877703 | validation: 0.16036021728508643]
	TIME [epoch: 10.3 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15065484303939006		[learning rate: 0.0046874]
	Learning Rate: 0.00468741
	LOSS [training: 0.15065484303939006 | validation: 0.5799717938087209]
	TIME [epoch: 10.3 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0826095814298897		[learning rate: 0.004673]
	Learning Rate: 0.00467305
	LOSS [training: 1.0826095814298897 | validation: 0.8066129100960002]
	TIME [epoch: 10.3 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4999936836482903		[learning rate: 0.0046587]
	Learning Rate: 0.00465872
	LOSS [training: 1.4999936836482903 | validation: 0.6435951971545341]
	TIME [epoch: 10.3 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7764655180715607		[learning rate: 0.0046444]
	Learning Rate: 0.00464444
	LOSS [training: 0.7764655180715607 | validation: 0.26853479815852127]
	TIME [epoch: 10.3 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.321932226367735		[learning rate: 0.0046302]
	Learning Rate: 0.0046302
	LOSS [training: 0.321932226367735 | validation: 0.4470993728280457]
	TIME [epoch: 10.3 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3117173008885975		[learning rate: 0.004616]
	Learning Rate: 0.00461601
	LOSS [training: 0.3117173008885975 | validation: 0.1516695567409921]
	TIME [epoch: 10.3 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1443080455221426		[learning rate: 0.0046019]
	Learning Rate: 0.00460186
	LOSS [training: 0.1443080455221426 | validation: 0.21720243380592777]
	TIME [epoch: 10.3 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24002380507907778		[learning rate: 0.0045878]
	Learning Rate: 0.00458775
	LOSS [training: 0.24002380507907778 | validation: 0.23959722189454843]
	TIME [epoch: 10.3 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23317094896360238		[learning rate: 0.0045737]
	Learning Rate: 0.00457369
	LOSS [training: 0.23317094896360238 | validation: 0.15709773100307825]
	TIME [epoch: 10.3 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20064390868264032		[learning rate: 0.0045597]
	Learning Rate: 0.00455967
	LOSS [training: 0.20064390868264032 | validation: 0.3175715719749029]
	TIME [epoch: 10.3 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3759175671769613		[learning rate: 0.0045457]
	Learning Rate: 0.00454569
	LOSS [training: 0.3759175671769613 | validation: 0.28068149068053394]
	TIME [epoch: 10.3 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26610707212859824		[learning rate: 0.0045318]
	Learning Rate: 0.00453176
	LOSS [training: 0.26610707212859824 | validation: 0.3034656977789225]
	TIME [epoch: 10.3 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2465805791994971		[learning rate: 0.0045179]
	Learning Rate: 0.00451787
	LOSS [training: 0.2465805791994971 | validation: 0.21462847210304042]
	TIME [epoch: 10.3 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17671402700903965		[learning rate: 0.004504]
	Learning Rate: 0.00450402
	LOSS [training: 0.17671402700903965 | validation: 0.21078266774527826]
	TIME [epoch: 10.3 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17830269702432358		[learning rate: 0.0044902]
	Learning Rate: 0.00449021
	LOSS [training: 0.17830269702432358 | validation: 0.24896799856233487]
	TIME [epoch: 10.3 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21401801182723892		[learning rate: 0.0044764]
	Learning Rate: 0.00447645
	LOSS [training: 0.21401801182723892 | validation: 0.23371470361334357]
	TIME [epoch: 10.3 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1590896051669201		[learning rate: 0.0044627]
	Learning Rate: 0.00446272
	LOSS [training: 0.1590896051669201 | validation: 0.1962555623830008]
	TIME [epoch: 10.3 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2105124878106		[learning rate: 0.004449]
	Learning Rate: 0.00444904
	LOSS [training: 0.2105124878106 | validation: 0.25485161895808534]
	TIME [epoch: 10.3 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14771326305308183		[learning rate: 0.0044354]
	Learning Rate: 0.0044354
	LOSS [training: 0.14771326305308183 | validation: 0.1388131678862248]
	TIME [epoch: 10.3 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23397494092878485		[learning rate: 0.0044218]
	Learning Rate: 0.00442181
	LOSS [training: 0.23397494092878485 | validation: 0.31692976332673994]
	TIME [epoch: 10.3 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20335441439832067		[learning rate: 0.0044083]
	Learning Rate: 0.00440825
	LOSS [training: 0.20335441439832067 | validation: 0.12231284140458279]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_767.pth
	Model improved!!!
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09055382562621388		[learning rate: 0.0043947]
	Learning Rate: 0.00439474
	LOSS [training: 0.09055382562621388 | validation: 0.1526903454501335]
	TIME [epoch: 10.3 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09673336481724847		[learning rate: 0.0043813]
	Learning Rate: 0.00438127
	LOSS [training: 0.09673336481724847 | validation: 0.16882258167108302]
	TIME [epoch: 10.3 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18455152307484052		[learning rate: 0.0043678]
	Learning Rate: 0.00436784
	LOSS [training: 0.18455152307484052 | validation: 0.19231678453432602]
	TIME [epoch: 10.3 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12592700723802594		[learning rate: 0.0043544]
	Learning Rate: 0.00435445
	LOSS [training: 0.12592700723802594 | validation: 0.15866615121119476]
	TIME [epoch: 10.3 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11903095559903092		[learning rate: 0.0043411]
	Learning Rate: 0.0043411
	LOSS [training: 0.11903095559903092 | validation: 0.1286099315637879]
	TIME [epoch: 10.3 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12383758013112176		[learning rate: 0.0043278]
	Learning Rate: 0.0043278
	LOSS [training: 0.12383758013112176 | validation: 0.23059801302252042]
	TIME [epoch: 10.3 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13734807309828856		[learning rate: 0.0043145]
	Learning Rate: 0.00431453
	LOSS [training: 0.13734807309828856 | validation: 0.13485384137904036]
	TIME [epoch: 10.3 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15498268638425533		[learning rate: 0.0043013]
	Learning Rate: 0.0043013
	LOSS [training: 0.15498268638425533 | validation: 0.30229560934827215]
	TIME [epoch: 10.3 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26770407373384797		[learning rate: 0.0042881]
	Learning Rate: 0.00428812
	LOSS [training: 0.26770407373384797 | validation: 0.19987308718527577]
	TIME [epoch: 10.3 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1295541848656045		[learning rate: 0.004275]
	Learning Rate: 0.00427497
	LOSS [training: 0.1295541848656045 | validation: 0.1596736427225492]
	TIME [epoch: 10.3 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.131927025997159		[learning rate: 0.0042619]
	Learning Rate: 0.00426187
	LOSS [training: 0.131927025997159 | validation: 0.2521790500218132]
	TIME [epoch: 10.3 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1731282169049005		[learning rate: 0.0042488]
	Learning Rate: 0.0042488
	LOSS [training: 0.1731282169049005 | validation: 0.39388884706814836]
	TIME [epoch: 10.3 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30589530275381327		[learning rate: 0.0042358]
	Learning Rate: 0.00423578
	LOSS [training: 0.30589530275381327 | validation: 0.1515758834621795]
	TIME [epoch: 10.3 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1363477275779892		[learning rate: 0.0042228]
	Learning Rate: 0.00422279
	LOSS [training: 0.1363477275779892 | validation: 0.23399836109797573]
	TIME [epoch: 10.3 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24867311026327443		[learning rate: 0.0042098]
	Learning Rate: 0.00420985
	LOSS [training: 0.24867311026327443 | validation: 0.28659187597751185]
	TIME [epoch: 10.3 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2032991076715811		[learning rate: 0.0041969]
	Learning Rate: 0.00419695
	LOSS [training: 0.2032991076715811 | validation: 0.2658524798316631]
	TIME [epoch: 10.3 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2047533574753162		[learning rate: 0.0041841]
	Learning Rate: 0.00418408
	LOSS [training: 0.2047533574753162 | validation: 0.2810734886847201]
	TIME [epoch: 10.3 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2637257265655668		[learning rate: 0.0041713]
	Learning Rate: 0.00417125
	LOSS [training: 0.2637257265655668 | validation: 0.24417194840912707]
	TIME [epoch: 10.3 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18672660266898528		[learning rate: 0.0041585]
	Learning Rate: 0.00415847
	LOSS [training: 0.18672660266898528 | validation: 0.230466660183172]
	TIME [epoch: 10.3 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15565648057183604		[learning rate: 0.0041457]
	Learning Rate: 0.00414572
	LOSS [training: 0.15565648057183604 | validation: 0.17761553176195763]
	TIME [epoch: 10.3 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11709703180483352		[learning rate: 0.004133]
	Learning Rate: 0.00413301
	LOSS [training: 0.11709703180483352 | validation: 0.1592408428804872]
	TIME [epoch: 10.3 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11064214761021643		[learning rate: 0.0041203]
	Learning Rate: 0.00412034
	LOSS [training: 0.11064214761021643 | validation: 0.1987396372325891]
	TIME [epoch: 10.3 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09224753131188493		[learning rate: 0.0041077]
	Learning Rate: 0.00410771
	LOSS [training: 0.09224753131188493 | validation: 0.11273796331778552]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_790.pth
	Model improved!!!
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08736141847937959		[learning rate: 0.0040951]
	Learning Rate: 0.00409512
	LOSS [training: 0.08736141847937959 | validation: 0.1257658713083386]
	TIME [epoch: 10.3 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11066353366985116		[learning rate: 0.0040826]
	Learning Rate: 0.00408257
	LOSS [training: 0.11066353366985116 | validation: 0.16069267501296441]
	TIME [epoch: 10.3 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13466453408400567		[learning rate: 0.0040701]
	Learning Rate: 0.00407005
	LOSS [training: 0.13466453408400567 | validation: 0.24646513033835235]
	TIME [epoch: 10.3 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12950349083177934		[learning rate: 0.0040576]
	Learning Rate: 0.00405758
	LOSS [training: 0.12950349083177934 | validation: 0.15901335468754457]
	TIME [epoch: 10.3 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1332347368890532		[learning rate: 0.0040451]
	Learning Rate: 0.00404514
	LOSS [training: 0.1332347368890532 | validation: 0.08922970122352375]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_795.pth
	Model improved!!!
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10161874283551915		[learning rate: 0.0040327]
	Learning Rate: 0.00403274
	LOSS [training: 0.10161874283551915 | validation: 0.25342244165651956]
	TIME [epoch: 10.3 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29378471582310844		[learning rate: 0.0040204]
	Learning Rate: 0.00402038
	LOSS [training: 0.29378471582310844 | validation: 0.2319207994528504]
	TIME [epoch: 10.3 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28656002693017807		[learning rate: 0.0040081]
	Learning Rate: 0.00400805
	LOSS [training: 0.28656002693017807 | validation: 0.3230541009174613]
	TIME [epoch: 10.3 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2386081739076383		[learning rate: 0.0039958]
	Learning Rate: 0.00399577
	LOSS [training: 0.2386081739076383 | validation: 0.24256553475976758]
	TIME [epoch: 10.3 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19874564492443086		[learning rate: 0.0039835]
	Learning Rate: 0.00398352
	LOSS [training: 0.19874564492443086 | validation: 0.19078694524682072]
	TIME [epoch: 10.3 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1685376916413345		[learning rate: 0.0039713]
	Learning Rate: 0.00397131
	LOSS [training: 0.1685376916413345 | validation: 0.17061525247728973]
	TIME [epoch: 10.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14973047956194863		[learning rate: 0.0039591]
	Learning Rate: 0.00395913
	LOSS [training: 0.14973047956194863 | validation: 0.1487709368851901]
	TIME [epoch: 10.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10457602161362163		[learning rate: 0.003947]
	Learning Rate: 0.003947
	LOSS [training: 0.10457602161362163 | validation: 0.12513292151161834]
	TIME [epoch: 10.3 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12214572648332471		[learning rate: 0.0039349]
	Learning Rate: 0.0039349
	LOSS [training: 0.12214572648332471 | validation: 0.13056955793256214]
	TIME [epoch: 10.3 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09727824890476651		[learning rate: 0.0039228]
	Learning Rate: 0.00392283
	LOSS [training: 0.09727824890476651 | validation: 0.15747505312866164]
	TIME [epoch: 10.3 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15437459247978755		[learning rate: 0.0039108]
	Learning Rate: 0.00391081
	LOSS [training: 0.15437459247978755 | validation: 0.1729840468726708]
	TIME [epoch: 10.3 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14419635842461104		[learning rate: 0.0038988]
	Learning Rate: 0.00389882
	LOSS [training: 0.14419635842461104 | validation: 0.19186103621612133]
	TIME [epoch: 10.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1326748529016541		[learning rate: 0.0038869]
	Learning Rate: 0.00388687
	LOSS [training: 0.1326748529016541 | validation: 0.15650804702248025]
	TIME [epoch: 10.3 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1760756010665311		[learning rate: 0.003875]
	Learning Rate: 0.00387495
	LOSS [training: 0.1760756010665311 | validation: 0.21552302357679182]
	TIME [epoch: 10.3 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14748086840840724		[learning rate: 0.0038631]
	Learning Rate: 0.00386308
	LOSS [training: 0.14748086840840724 | validation: 0.2580748718496325]
	TIME [epoch: 10.3 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15613055795751402		[learning rate: 0.0038512]
	Learning Rate: 0.00385123
	LOSS [training: 0.15613055795751402 | validation: 0.20899563838415872]
	TIME [epoch: 10.3 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13292839501628553		[learning rate: 0.0038394]
	Learning Rate: 0.00383943
	LOSS [training: 0.13292839501628553 | validation: 0.16804658272409256]
	TIME [epoch: 10.3 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10357884644258328		[learning rate: 0.0038277]
	Learning Rate: 0.00382766
	LOSS [training: 0.10357884644258328 | validation: 0.15176549620560745]
	TIME [epoch: 10.3 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3288517289075657		[learning rate: 0.0038159]
	Learning Rate: 0.00381593
	LOSS [training: 0.3288517289075657 | validation: 0.497807128736647]
	TIME [epoch: 10.3 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9066033638705877		[learning rate: 0.0038042]
	Learning Rate: 0.00380423
	LOSS [training: 0.9066033638705877 | validation: 0.7356936688260922]
	TIME [epoch: 10.3 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5518352956345836		[learning rate: 0.0037926]
	Learning Rate: 0.00379257
	LOSS [training: 0.5518352956345836 | validation: 0.15075598994359746]
	TIME [epoch: 10.3 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24536696931177784		[learning rate: 0.0037809]
	Learning Rate: 0.00378094
	LOSS [training: 0.24536696931177784 | validation: 0.20755825060695315]
	TIME [epoch: 10.3 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1834165120947342		[learning rate: 0.0037694]
	Learning Rate: 0.00376935
	LOSS [training: 0.1834165120947342 | validation: 0.1440346588627573]
	TIME [epoch: 10.3 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11547685848234053		[learning rate: 0.0037578]
	Learning Rate: 0.0037578
	LOSS [training: 0.11547685848234053 | validation: 0.17726148314727275]
	TIME [epoch: 10.3 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615836067566499		[learning rate: 0.0037463]
	Learning Rate: 0.00374628
	LOSS [training: 0.1615836067566499 | validation: 0.21650228728708695]
	TIME [epoch: 10.3 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18139836038179108		[learning rate: 0.0037348]
	Learning Rate: 0.00373479
	LOSS [training: 0.18139836038179108 | validation: 0.13371691614456788]
	TIME [epoch: 10.3 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09303751941609309		[learning rate: 0.0037233]
	Learning Rate: 0.00372335
	LOSS [training: 0.09303751941609309 | validation: 0.1691109016246255]
	TIME [epoch: 10.3 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11144194075135742		[learning rate: 0.0037119]
	Learning Rate: 0.00371193
	LOSS [training: 0.11144194075135742 | validation: 0.1425105955772995]
	TIME [epoch: 10.3 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1869266262624254		[learning rate: 0.0037006]
	Learning Rate: 0.00370055
	LOSS [training: 0.1869266262624254 | validation: 0.2738040398775624]
	TIME [epoch: 10.3 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13970758133557015		[learning rate: 0.0036892]
	Learning Rate: 0.00368921
	LOSS [training: 0.13970758133557015 | validation: 0.22264820803289864]
	TIME [epoch: 10.3 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18230458267224803		[learning rate: 0.0036779]
	Learning Rate: 0.0036779
	LOSS [training: 0.18230458267224803 | validation: 0.16614619068176978]
	TIME [epoch: 10.3 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20248224255508376		[learning rate: 0.0036666]
	Learning Rate: 0.00366663
	LOSS [training: 0.20248224255508376 | validation: 0.2602056098742253]
	TIME [epoch: 10.3 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1898729617189092		[learning rate: 0.0036554]
	Learning Rate: 0.00365539
	LOSS [training: 0.1898729617189092 | validation: 0.19836907574836649]
	TIME [epoch: 10.3 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12205887678215684		[learning rate: 0.0036442]
	Learning Rate: 0.00364418
	LOSS [training: 0.12205887678215684 | validation: 0.14565743125292388]
	TIME [epoch: 10.3 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16931164820365208		[learning rate: 0.003633]
	Learning Rate: 0.00363301
	LOSS [training: 0.16931164820365208 | validation: 0.3373225983147632]
	TIME [epoch: 10.3 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22401229382077173		[learning rate: 0.0036219]
	Learning Rate: 0.00362187
	LOSS [training: 0.22401229382077173 | validation: 0.2458626608981375]
	TIME [epoch: 10.3 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16333585073814896		[learning rate: 0.0036108]
	Learning Rate: 0.00361077
	LOSS [training: 0.16333585073814896 | validation: 0.2611852766226085]
	TIME [epoch: 10.3 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19616791560024222		[learning rate: 0.0035997]
	Learning Rate: 0.0035997
	LOSS [training: 0.19616791560024222 | validation: 0.24395351113307492]
	TIME [epoch: 10.3 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2374477680252256		[learning rate: 0.0035887]
	Learning Rate: 0.00358867
	LOSS [training: 0.2374477680252256 | validation: 0.24226805350424366]
	TIME [epoch: 10.3 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25325798119184567		[learning rate: 0.0035777]
	Learning Rate: 0.00357767
	LOSS [training: 0.25325798119184567 | validation: 0.25687421758666484]
	TIME [epoch: 10.3 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21151229927924878		[learning rate: 0.0035667]
	Learning Rate: 0.0035667
	LOSS [training: 0.21151229927924878 | validation: 0.18588198894104038]
	TIME [epoch: 10.3 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17319000954238406		[learning rate: 0.0035558]
	Learning Rate: 0.00355577
	LOSS [training: 0.17319000954238406 | validation: 0.16878554729226458]
	TIME [epoch: 10.3 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12787193259612897		[learning rate: 0.0035449]
	Learning Rate: 0.00354487
	LOSS [training: 0.12787193259612897 | validation: 0.27296577660176824]
	TIME [epoch: 10.2 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39285936166273117		[learning rate: 0.003534]
	Learning Rate: 0.003534
	LOSS [training: 0.39285936166273117 | validation: 0.3897107900384325]
	TIME [epoch: 10.3 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3847768252849266		[learning rate: 0.0035232]
	Learning Rate: 0.00352317
	LOSS [training: 0.3847768252849266 | validation: 0.3083238440045734]
	TIME [epoch: 10.3 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3166887896616747		[learning rate: 0.0035124]
	Learning Rate: 0.00351237
	LOSS [training: 0.3166887896616747 | validation: 0.27662674509946]
	TIME [epoch: 10.3 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1888803281383013		[learning rate: 0.0035016]
	Learning Rate: 0.0035016
	LOSS [training: 0.1888803281383013 | validation: 0.1272980346173022]
	TIME [epoch: 10.3 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09127681536797642		[learning rate: 0.0034909]
	Learning Rate: 0.00349087
	LOSS [training: 0.09127681536797642 | validation: 0.12471403661376791]
	TIME [epoch: 10.3 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08542224508836932		[learning rate: 0.0034802]
	Learning Rate: 0.00348017
	LOSS [training: 0.08542224508836932 | validation: 0.13418289604630712]
	TIME [epoch: 10.3 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08816571705013675		[learning rate: 0.0034695]
	Learning Rate: 0.0034695
	LOSS [training: 0.08816571705013675 | validation: 0.20354702792006016]
	TIME [epoch: 10.3 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09311905457696999		[learning rate: 0.0034589]
	Learning Rate: 0.00345886
	LOSS [training: 0.09311905457696999 | validation: 0.15459677171406344]
	TIME [epoch: 10.3 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11292182530983039		[learning rate: 0.0034483]
	Learning Rate: 0.00344826
	LOSS [training: 0.11292182530983039 | validation: 0.09844072529216663]
	TIME [epoch: 10.3 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10559019912831617		[learning rate: 0.0034377]
	Learning Rate: 0.00343769
	LOSS [training: 0.10559019912831617 | validation: 0.12425887204382509]
	TIME [epoch: 10.3 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11502633151028623		[learning rate: 0.0034272]
	Learning Rate: 0.00342715
	LOSS [training: 0.11502633151028623 | validation: 0.17851112421750723]
	TIME [epoch: 10.3 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15998767364020994		[learning rate: 0.0034166]
	Learning Rate: 0.00341665
	LOSS [training: 0.15998767364020994 | validation: 0.34833745821740125]
	TIME [epoch: 10.3 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3381006724176943		[learning rate: 0.0034062]
	Learning Rate: 0.00340617
	LOSS [training: 0.3381006724176943 | validation: 0.1655964723266919]
	TIME [epoch: 10.3 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11435513020236861		[learning rate: 0.0033957]
	Learning Rate: 0.00339573
	LOSS [training: 0.11435513020236861 | validation: 0.16293538975215063]
	TIME [epoch: 10.3 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09695941402223737		[learning rate: 0.0033853]
	Learning Rate: 0.00338532
	LOSS [training: 0.09695941402223737 | validation: 0.13338618661844856]
	TIME [epoch: 10.3 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11431545752960451		[learning rate: 0.0033749]
	Learning Rate: 0.00337494
	LOSS [training: 0.11431545752960451 | validation: 0.16855802667791234]
	TIME [epoch: 10.3 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13079267259723745		[learning rate: 0.0033646]
	Learning Rate: 0.0033646
	LOSS [training: 0.13079267259723745 | validation: 0.1465772704372521]
	TIME [epoch: 10.3 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09412990230776186		[learning rate: 0.0033543]
	Learning Rate: 0.00335428
	LOSS [training: 0.09412990230776186 | validation: 0.10655262541360032]
	TIME [epoch: 10.3 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10229880109981895		[learning rate: 0.003344]
	Learning Rate: 0.003344
	LOSS [training: 0.10229880109981895 | validation: 0.1398723103854833]
	TIME [epoch: 10.3 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11852266473484005		[learning rate: 0.0033338]
	Learning Rate: 0.00333375
	LOSS [training: 0.11852266473484005 | validation: 0.20769358055105508]
	TIME [epoch: 10.3 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1391127142258844		[learning rate: 0.0033235]
	Learning Rate: 0.00332353
	LOSS [training: 0.1391127142258844 | validation: 0.14718359649973448]
	TIME [epoch: 10.3 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11952851069314796		[learning rate: 0.0033133]
	Learning Rate: 0.00331334
	LOSS [training: 0.11952851069314796 | validation: 0.15655313367608858]
	TIME [epoch: 10.3 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15741614471608262		[learning rate: 0.0033032]
	Learning Rate: 0.00330319
	LOSS [training: 0.15741614471608262 | validation: 0.17508929909934282]
	TIME [epoch: 10.3 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1395821864540691		[learning rate: 0.0032931]
	Learning Rate: 0.00329306
	LOSS [training: 0.1395821864540691 | validation: 0.1549111161809827]
	TIME [epoch: 10.3 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11282012270368413		[learning rate: 0.003283]
	Learning Rate: 0.00328297
	LOSS [training: 0.11282012270368413 | validation: 0.13642213198232134]
	TIME [epoch: 10.3 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12635922487191684		[learning rate: 0.0032729]
	Learning Rate: 0.0032729
	LOSS [training: 0.12635922487191684 | validation: 0.1556182318761024]
	TIME [epoch: 10.3 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12173922902611653		[learning rate: 0.0032629]
	Learning Rate: 0.00326287
	LOSS [training: 0.12173922902611653 | validation: 0.1357803100485292]
	TIME [epoch: 10.3 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1854492157681688		[learning rate: 0.0032529]
	Learning Rate: 0.00325287
	LOSS [training: 0.1854492157681688 | validation: 0.242940754724998]
	TIME [epoch: 10.3 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11578842972405037		[learning rate: 0.0032429]
	Learning Rate: 0.0032429
	LOSS [training: 0.11578842972405037 | validation: 0.14607990213364627]
	TIME [epoch: 10.3 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10179766777139151		[learning rate: 0.003233]
	Learning Rate: 0.00323296
	LOSS [training: 0.10179766777139151 | validation: 0.23525535799703673]
	TIME [epoch: 10.3 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12354018086127952		[learning rate: 0.003223]
	Learning Rate: 0.00322305
	LOSS [training: 0.12354018086127952 | validation: 0.15253821549836447]
	TIME [epoch: 10.3 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08868716266819174		[learning rate: 0.0032132]
	Learning Rate: 0.00321317
	LOSS [training: 0.08868716266819174 | validation: 0.11726482178957935]
	TIME [epoch: 10.3 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09672658166477897		[learning rate: 0.0032033]
	Learning Rate: 0.00320332
	LOSS [training: 0.09672658166477897 | validation: 0.16619699910495161]
	TIME [epoch: 10.3 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0850296838849493		[learning rate: 0.0031935]
	Learning Rate: 0.0031935
	LOSS [training: 0.0850296838849493 | validation: 0.13321310889263954]
	TIME [epoch: 10.3 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10666937903408502		[learning rate: 0.0031837]
	Learning Rate: 0.00318371
	LOSS [training: 0.10666937903408502 | validation: 0.19991658267310888]
	TIME [epoch: 10.3 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1618868735095801		[learning rate: 0.0031739]
	Learning Rate: 0.00317395
	LOSS [training: 0.1618868735095801 | validation: 0.17063516254231292]
	TIME [epoch: 10.3 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09093631456070742		[learning rate: 0.0031642]
	Learning Rate: 0.00316422
	LOSS [training: 0.09093631456070742 | validation: 0.10328570424835612]
	TIME [epoch: 10.3 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07837469351394197		[learning rate: 0.0031545]
	Learning Rate: 0.00315452
	LOSS [training: 0.07837469351394197 | validation: 0.12201990616778939]
	TIME [epoch: 10.3 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08805045586638136		[learning rate: 0.0031449]
	Learning Rate: 0.00314485
	LOSS [training: 0.08805045586638136 | validation: 0.12546124672529863]
	TIME [epoch: 10.3 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07935444788584371		[learning rate: 0.0031352]
	Learning Rate: 0.00313521
	LOSS [training: 0.07935444788584371 | validation: 0.1644914206050854]
	TIME [epoch: 10.3 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08519400394778535		[learning rate: 0.0031256]
	Learning Rate: 0.0031256
	LOSS [training: 0.08519400394778535 | validation: 0.16234085731153497]
	TIME [epoch: 10.3 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08752614681900549		[learning rate: 0.003116]
	Learning Rate: 0.00311602
	LOSS [training: 0.08752614681900549 | validation: 0.14121059606057088]
	TIME [epoch: 10.3 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1088808895295285		[learning rate: 0.0031065]
	Learning Rate: 0.00310647
	LOSS [training: 0.1088808895295285 | validation: 0.10609040204768082]
	TIME [epoch: 10.3 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09464253546891083		[learning rate: 0.0030969]
	Learning Rate: 0.00309694
	LOSS [training: 0.09464253546891083 | validation: 0.09996252364342866]
	TIME [epoch: 10.3 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0737441274891293		[learning rate: 0.0030875]
	Learning Rate: 0.00308745
	LOSS [training: 0.0737441274891293 | validation: 0.11005214594308417]
	TIME [epoch: 10.3 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07434411255646063		[learning rate: 0.003078]
	Learning Rate: 0.00307799
	LOSS [training: 0.07434411255646063 | validation: 0.13269655908985942]
	TIME [epoch: 10.3 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11014747886561668		[learning rate: 0.0030686]
	Learning Rate: 0.00306855
	LOSS [training: 0.11014747886561668 | validation: 0.127934178543188]
	TIME [epoch: 10.3 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12546853162621927		[learning rate: 0.0030591]
	Learning Rate: 0.00305914
	LOSS [training: 0.12546853162621927 | validation: 0.13112188692097154]
	TIME [epoch: 10.3 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09651083790951308		[learning rate: 0.0030498]
	Learning Rate: 0.00304977
	LOSS [training: 0.09651083790951308 | validation: 0.10216046991905074]
	TIME [epoch: 10.3 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10182395061534474		[learning rate: 0.0030404]
	Learning Rate: 0.00304042
	LOSS [training: 0.10182395061534474 | validation: 0.12033861670755082]
	TIME [epoch: 10.3 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11805149754274073		[learning rate: 0.0030311]
	Learning Rate: 0.0030311
	LOSS [training: 0.11805149754274073 | validation: 0.13204316036833733]
	TIME [epoch: 10.3 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07105053134029993		[learning rate: 0.0030218]
	Learning Rate: 0.00302181
	LOSS [training: 0.07105053134029993 | validation: 0.09066698551067014]
	TIME [epoch: 10.3 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07929968180885465		[learning rate: 0.0030125]
	Learning Rate: 0.00301254
	LOSS [training: 0.07929968180885465 | validation: 0.11720845697010074]
	TIME [epoch: 10.3 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06015539821192465		[learning rate: 0.0030033]
	Learning Rate: 0.00300331
	LOSS [training: 0.06015539821192465 | validation: 0.1170887305562625]
	TIME [epoch: 10.3 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1252174154339323		[learning rate: 0.0029941]
	Learning Rate: 0.0029941
	LOSS [training: 0.1252174154339323 | validation: 0.31897435678167835]
	TIME [epoch: 10.3 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2375087318715304		[learning rate: 0.0029849]
	Learning Rate: 0.00298492
	LOSS [training: 0.2375087318715304 | validation: 0.20163490538333784]
	TIME [epoch: 10.3 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13297521587090766		[learning rate: 0.0029758]
	Learning Rate: 0.00297577
	LOSS [training: 0.13297521587090766 | validation: 0.11304178177637245]
	TIME [epoch: 10.3 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1284830181469248		[learning rate: 0.0029667]
	Learning Rate: 0.00296665
	LOSS [training: 0.1284830181469248 | validation: 0.17440438449036996]
	TIME [epoch: 10.3 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12306165541505676		[learning rate: 0.0029576]
	Learning Rate: 0.00295756
	LOSS [training: 0.12306165541505676 | validation: 0.13257586170991117]
	TIME [epoch: 10.3 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08169400486560477		[learning rate: 0.0029485]
	Learning Rate: 0.00294849
	LOSS [training: 0.08169400486560477 | validation: 0.12001568650720565]
	TIME [epoch: 10.3 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05815073994824647		[learning rate: 0.0029395]
	Learning Rate: 0.00293945
	LOSS [training: 0.05815073994824647 | validation: 0.1434908167263704]
	TIME [epoch: 10.3 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12859575962902245		[learning rate: 0.0029304]
	Learning Rate: 0.00293044
	LOSS [training: 0.12859575962902245 | validation: 0.18967044563696]
	TIME [epoch: 10.3 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08615618103696814		[learning rate: 0.0029215]
	Learning Rate: 0.00292146
	LOSS [training: 0.08615618103696814 | validation: 0.13104417395431167]
	TIME [epoch: 10.3 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0851979883677851		[learning rate: 0.0029125]
	Learning Rate: 0.0029125
	LOSS [training: 0.0851979883677851 | validation: 0.11979101212328662]
	TIME [epoch: 10.3 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08999858135468759		[learning rate: 0.0029036]
	Learning Rate: 0.00290358
	LOSS [training: 0.08999858135468759 | validation: 0.1280025208840347]
	TIME [epoch: 10.3 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07737182949828567		[learning rate: 0.0028947]
	Learning Rate: 0.00289468
	LOSS [training: 0.07737182949828567 | validation: 0.14278700024059232]
	TIME [epoch: 10.3 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08727394219925566		[learning rate: 0.0028858]
	Learning Rate: 0.0028858
	LOSS [training: 0.08727394219925566 | validation: 0.1397226405005703]
	TIME [epoch: 10.3 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13363337120560453		[learning rate: 0.002877]
	Learning Rate: 0.00287696
	LOSS [training: 0.13363337120560453 | validation: 0.19814324370097336]
	TIME [epoch: 10.3 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2165573337923723		[learning rate: 0.0028681]
	Learning Rate: 0.00286814
	LOSS [training: 0.2165573337923723 | validation: 0.2171455826090162]
	TIME [epoch: 10.3 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16046947127438618		[learning rate: 0.0028593]
	Learning Rate: 0.00285935
	LOSS [training: 0.16046947127438618 | validation: 0.20448785715374385]
	TIME [epoch: 10.3 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12997607257916574		[learning rate: 0.0028506]
	Learning Rate: 0.00285058
	LOSS [training: 0.12997607257916574 | validation: 0.3258937685692919]
	TIME [epoch: 10.3 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3291439678374515		[learning rate: 0.0028418]
	Learning Rate: 0.00284184
	LOSS [training: 0.3291439678374515 | validation: 0.4760234244156223]
	TIME [epoch: 10.3 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41563918851916454		[learning rate: 0.0028331]
	Learning Rate: 0.00283313
	LOSS [training: 0.41563918851916454 | validation: 0.5951514651441324]
	TIME [epoch: 10.3 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4028661322813928		[learning rate: 0.0028244]
	Learning Rate: 0.00282445
	LOSS [training: 0.4028661322813928 | validation: 0.4419383022361674]
	TIME [epoch: 10.3 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35792564013432965		[learning rate: 0.0028158]
	Learning Rate: 0.00281579
	LOSS [training: 0.35792564013432965 | validation: 0.42901483694463594]
	TIME [epoch: 10.3 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6679722014318281		[learning rate: 0.0028072]
	Learning Rate: 0.00280716
	LOSS [training: 0.6679722014318281 | validation: 0.8511507335928303]
	TIME [epoch: 10.3 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7098659586377021		[learning rate: 0.0027986]
	Learning Rate: 0.00279855
	LOSS [training: 0.7098659586377021 | validation: 0.8452502737532985]
	TIME [epoch: 10.3 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6494580137735237		[learning rate: 0.00279]
	Learning Rate: 0.00278997
	LOSS [training: 0.6494580137735237 | validation: 0.6048573395689334]
	TIME [epoch: 10.3 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49691265455939443		[learning rate: 0.0027814]
	Learning Rate: 0.00278142
	LOSS [training: 0.49691265455939443 | validation: 0.5107860188544129]
	TIME [epoch: 10.3 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29253409785495404		[learning rate: 0.0027729]
	Learning Rate: 0.00277289
	LOSS [training: 0.29253409785495404 | validation: 0.2520421377739791]
	TIME [epoch: 10.3 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15710648577399472		[learning rate: 0.0027644]
	Learning Rate: 0.00276439
	LOSS [training: 0.15710648577399472 | validation: 0.16578916754322387]
	TIME [epoch: 10.3 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17073345942501092		[learning rate: 0.0027559]
	Learning Rate: 0.00275592
	LOSS [training: 0.17073345942501092 | validation: 0.17206758963044635]
	TIME [epoch: 10.3 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12199666056304419		[learning rate: 0.0027475]
	Learning Rate: 0.00274747
	LOSS [training: 0.12199666056304419 | validation: 0.17332104196728776]
	TIME [epoch: 10.3 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11587850148801111		[learning rate: 0.002739]
	Learning Rate: 0.00273905
	LOSS [training: 0.11587850148801111 | validation: 0.13817635811270182]
	TIME [epoch: 10.3 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09770905077720685		[learning rate: 0.0027307]
	Learning Rate: 0.00273065
	LOSS [training: 0.09770905077720685 | validation: 0.1870545792564728]
	TIME [epoch: 10.3 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10959207216847267		[learning rate: 0.0027223]
	Learning Rate: 0.00272228
	LOSS [training: 0.10959207216847267 | validation: 0.19350234172578826]
	TIME [epoch: 10.3 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27284474991993096		[learning rate: 0.0027139]
	Learning Rate: 0.00271394
	LOSS [training: 0.27284474991993096 | validation: 0.5932544178769941]
	TIME [epoch: 10.3 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8581707563108175		[learning rate: 0.0027056]
	Learning Rate: 0.00270562
	LOSS [training: 0.8581707563108175 | validation: 1.051745815423014]
	TIME [epoch: 10.3 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1146086634343806		[learning rate: 0.0026973]
	Learning Rate: 0.00269733
	LOSS [training: 1.1146086634343806 | validation: 0.8175581049100089]
	TIME [epoch: 10.3 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5227526236219143		[learning rate: 0.0026891]
	Learning Rate: 0.00268906
	LOSS [training: 0.5227526236219143 | validation: 0.28368136728396626]
	TIME [epoch: 10.3 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37572808383635753		[learning rate: 0.0026808]
	Learning Rate: 0.00268081
	LOSS [training: 0.37572808383635753 | validation: 0.33200905373910905]
	TIME [epoch: 10.3 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2605449766640141		[learning rate: 0.0026726]
	Learning Rate: 0.0026726
	LOSS [training: 0.2605449766640141 | validation: 0.29245484007790756]
	TIME [epoch: 10.3 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39621340595118937		[learning rate: 0.0026644]
	Learning Rate: 0.0026644
	LOSS [training: 0.39621340595118937 | validation: 0.48687002374513455]
	TIME [epoch: 10.3 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0053346937189083		[learning rate: 0.0026562]
	Learning Rate: 0.00265624
	LOSS [training: 1.0053346937189083 | validation: 1.2036861739268734]
	TIME [epoch: 10.3 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.242841167458628		[learning rate: 0.0026481]
	Learning Rate: 0.00264809
	LOSS [training: 1.242841167458628 | validation: 0.7394324129525467]
	TIME [epoch: 10.3 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4661068113049499		[learning rate: 0.00264]
	Learning Rate: 0.00263998
	LOSS [training: 0.4661068113049499 | validation: 0.23233364601844797]
	TIME [epoch: 10.3 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1822396611135889		[learning rate: 0.0026319]
	Learning Rate: 0.00263188
	LOSS [training: 0.1822396611135889 | validation: 0.20240220672150144]
	TIME [epoch: 10.3 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21841311610138847		[learning rate: 0.0026238]
	Learning Rate: 0.00262382
	LOSS [training: 0.21841311610138847 | validation: 0.2622666105529287]
	TIME [epoch: 10.3 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18740854810723584		[learning rate: 0.0026158]
	Learning Rate: 0.00261577
	LOSS [training: 0.18740854810723584 | validation: 0.23591956438408163]
	TIME [epoch: 10.3 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1996575676067819		[learning rate: 0.0026078]
	Learning Rate: 0.00260775
	LOSS [training: 0.1996575676067819 | validation: 0.3352633373712751]
	TIME [epoch: 10.3 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2892915613624245		[learning rate: 0.0025998]
	Learning Rate: 0.00259976
	LOSS [training: 0.2892915613624245 | validation: 0.25845671791761143]
	TIME [epoch: 10.3 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21611191601816526		[learning rate: 0.0025918]
	Learning Rate: 0.00259179
	LOSS [training: 0.21611191601816526 | validation: 0.20408136594524368]
	TIME [epoch: 10.3 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18549523697558903		[learning rate: 0.0025838]
	Learning Rate: 0.00258385
	LOSS [training: 0.18549523697558903 | validation: 0.17022897899369122]
	TIME [epoch: 10.3 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17228275453686265		[learning rate: 0.0025759]
	Learning Rate: 0.00257593
	LOSS [training: 0.17228275453686265 | validation: 0.1746239916597036]
	TIME [epoch: 10.3 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.131322235345726		[learning rate: 0.002568]
	Learning Rate: 0.00256803
	LOSS [training: 0.131322235345726 | validation: 0.1367828656894378]
	TIME [epoch: 10.3 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11507394397591182		[learning rate: 0.0025602]
	Learning Rate: 0.00256016
	LOSS [training: 0.11507394397591182 | validation: 0.14025415208075181]
	TIME [epoch: 10.3 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11556645167823268		[learning rate: 0.0025523]
	Learning Rate: 0.00255231
	LOSS [training: 0.11556645167823268 | validation: 0.19832419284735175]
	TIME [epoch: 10.3 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20351466550564273		[learning rate: 0.0025445]
	Learning Rate: 0.00254449
	LOSS [training: 0.20351466550564273 | validation: 0.2672496534384631]
	TIME [epoch: 10.3 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20574180021321647		[learning rate: 0.0025367]
	Learning Rate: 0.00253669
	LOSS [training: 0.20574180021321647 | validation: 0.16677856947725736]
	TIME [epoch: 10.3 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12262151697290098		[learning rate: 0.0025289]
	Learning Rate: 0.00252891
	LOSS [training: 0.12262151697290098 | validation: 0.13780191198636935]
	TIME [epoch: 10.3 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09386834403561851		[learning rate: 0.0025212]
	Learning Rate: 0.00252116
	LOSS [training: 0.09386834403561851 | validation: 0.13477009801806125]
	TIME [epoch: 10.3 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10511520512159456		[learning rate: 0.0025134]
	Learning Rate: 0.00251343
	LOSS [training: 0.10511520512159456 | validation: 0.17324596547400167]
	TIME [epoch: 10.3 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11169029968978042		[learning rate: 0.0025057]
	Learning Rate: 0.00250572
	LOSS [training: 0.11169029968978042 | validation: 0.1434894693043158]
	TIME [epoch: 10.3 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1213131819735139		[learning rate: 0.002498]
	Learning Rate: 0.00249804
	LOSS [training: 0.1213131819735139 | validation: 0.1657215314381478]
	TIME [epoch: 10.3 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0872381356022893		[learning rate: 0.0024904]
	Learning Rate: 0.00249039
	LOSS [training: 0.0872381356022893 | validation: 0.11640664642121142]
	TIME [epoch: 10.3 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09983718220387987		[learning rate: 0.0024828]
	Learning Rate: 0.00248275
	LOSS [training: 0.09983718220387987 | validation: 0.13096792924827866]
	TIME [epoch: 10.3 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07995239821655085		[learning rate: 0.0024751]
	Learning Rate: 0.00247514
	LOSS [training: 0.07995239821655085 | validation: 0.1332269285054417]
	TIME [epoch: 10.3 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06828245203969377		[learning rate: 0.0024676]
	Learning Rate: 0.00246755
	LOSS [training: 0.06828245203969377 | validation: 0.14694300236400804]
	TIME [epoch: 10.3 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09122004281573544		[learning rate: 0.00246]
	Learning Rate: 0.00245999
	LOSS [training: 0.09122004281573544 | validation: 0.157830849332145]
	TIME [epoch: 10.3 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08690523032463249		[learning rate: 0.0024524]
	Learning Rate: 0.00245245
	LOSS [training: 0.08690523032463249 | validation: 0.13057761566770817]
	TIME [epoch: 10.3 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0756569149862826		[learning rate: 0.0024449]
	Learning Rate: 0.00244493
	LOSS [training: 0.0756569149862826 | validation: 0.14420869459312277]
	TIME [epoch: 10.3 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07916020523077612		[learning rate: 0.0024374]
	Learning Rate: 0.00243744
	LOSS [training: 0.07916020523077612 | validation: 0.10289618263962444]
	TIME [epoch: 10.3 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07297943541885281		[learning rate: 0.00243]
	Learning Rate: 0.00242996
	LOSS [training: 0.07297943541885281 | validation: 0.1389493665935607]
	TIME [epoch: 10.3 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0878818635702578		[learning rate: 0.0024225]
	Learning Rate: 0.00242252
	LOSS [training: 0.0878818635702578 | validation: 0.14424633697266692]
	TIME [epoch: 10.3 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08032187250305942		[learning rate: 0.0024151]
	Learning Rate: 0.00241509
	LOSS [training: 0.08032187250305942 | validation: 0.10854438406235246]
	TIME [epoch: 10.3 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10375478417197112		[learning rate: 0.0024077]
	Learning Rate: 0.00240769
	LOSS [training: 0.10375478417197112 | validation: 0.07677818256909263]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_964.pth
	Model improved!!!
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060353386817082036		[learning rate: 0.0024003]
	Learning Rate: 0.00240031
	LOSS [training: 0.060353386817082036 | validation: 0.10264460593513758]
	TIME [epoch: 10.3 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05272634940946521		[learning rate: 0.0023929]
	Learning Rate: 0.00239295
	LOSS [training: 0.05272634940946521 | validation: 0.10792885373427981]
	TIME [epoch: 10.3 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07458833381215255		[learning rate: 0.0023856]
	Learning Rate: 0.00238561
	LOSS [training: 0.07458833381215255 | validation: 0.17518756151531947]
	TIME [epoch: 10.3 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12154728517065813		[learning rate: 0.0023783]
	Learning Rate: 0.0023783
	LOSS [training: 0.12154728517065813 | validation: 0.18318880291581305]
	TIME [epoch: 10.3 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10599505416143662		[learning rate: 0.002371]
	Learning Rate: 0.00237101
	LOSS [training: 0.10599505416143662 | validation: 0.10625587282152228]
	TIME [epoch: 10.3 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051146452260416295		[learning rate: 0.0023637]
	Learning Rate: 0.00236374
	LOSS [training: 0.051146452260416295 | validation: 0.09952478534441511]
	TIME [epoch: 10.3 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05649004064231557		[learning rate: 0.0023565]
	Learning Rate: 0.0023565
	LOSS [training: 0.05649004064231557 | validation: 0.11150751675642835]
	TIME [epoch: 10.3 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06223114284752668		[learning rate: 0.0023493]
	Learning Rate: 0.00234927
	LOSS [training: 0.06223114284752668 | validation: 0.12316568647508158]
	TIME [epoch: 10.3 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06211581777545759		[learning rate: 0.0023421]
	Learning Rate: 0.00234207
	LOSS [training: 0.06211581777545759 | validation: 0.1087655660780728]
	TIME [epoch: 10.3 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06553966699017108		[learning rate: 0.0023349]
	Learning Rate: 0.00233489
	LOSS [training: 0.06553966699017108 | validation: 0.11169486070512051]
	TIME [epoch: 10.3 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06575081050733891		[learning rate: 0.0023277]
	Learning Rate: 0.00232773
	LOSS [training: 0.06575081050733891 | validation: 0.10683216299710108]
	TIME [epoch: 10.3 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08041324865920721		[learning rate: 0.0023206]
	Learning Rate: 0.0023206
	LOSS [training: 0.08041324865920721 | validation: 0.1275419450302864]
	TIME [epoch: 10.3 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09167052918881251		[learning rate: 0.0023135]
	Learning Rate: 0.00231348
	LOSS [training: 0.09167052918881251 | validation: 0.14671165584250115]
	TIME [epoch: 10.3 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08731146494634412		[learning rate: 0.0023064]
	Learning Rate: 0.00230639
	LOSS [training: 0.08731146494634412 | validation: 0.15240147020163633]
	TIME [epoch: 10.3 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10150622066453222		[learning rate: 0.0022993]
	Learning Rate: 0.00229932
	LOSS [training: 0.10150622066453222 | validation: 0.2471196914656378]
	TIME [epoch: 10.3 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16744572015672374		[learning rate: 0.0022923]
	Learning Rate: 0.00229227
	LOSS [training: 0.16744572015672374 | validation: 0.1575288058106957]
	TIME [epoch: 10.3 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09421284059429468		[learning rate: 0.0022852]
	Learning Rate: 0.00228525
	LOSS [training: 0.09421284059429468 | validation: 0.11951222041589056]
	TIME [epoch: 10.3 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08884527268794125		[learning rate: 0.0022782]
	Learning Rate: 0.00227824
	LOSS [training: 0.08884527268794125 | validation: 0.11505012361240922]
	TIME [epoch: 10.3 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06681858259921106		[learning rate: 0.0022713]
	Learning Rate: 0.00227126
	LOSS [training: 0.06681858259921106 | validation: 0.11301344995514043]
	TIME [epoch: 10.3 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061796676432578856		[learning rate: 0.0022643]
	Learning Rate: 0.0022643
	LOSS [training: 0.061796676432578856 | validation: 0.10353246088851528]
	TIME [epoch: 10.3 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08761457770676459		[learning rate: 0.0022574]
	Learning Rate: 0.00225736
	LOSS [training: 0.08761457770676459 | validation: 0.13902435388063686]
	TIME [epoch: 10.3 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07959178133440122		[learning rate: 0.0022504]
	Learning Rate: 0.00225044
	LOSS [training: 0.07959178133440122 | validation: 0.13339291078759466]
	TIME [epoch: 10.3 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07356675188263165		[learning rate: 0.0022435]
	Learning Rate: 0.00224354
	LOSS [training: 0.07356675188263165 | validation: 0.1248176944395857]
	TIME [epoch: 10.3 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07150474839466218		[learning rate: 0.0022367]
	Learning Rate: 0.00223666
	LOSS [training: 0.07150474839466218 | validation: 0.09836930866751917]
	TIME [epoch: 10.3 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06914791883585841		[learning rate: 0.0022298]
	Learning Rate: 0.0022298
	LOSS [training: 0.06914791883585841 | validation: 0.13815624221420741]
	TIME [epoch: 10.3 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14934007593278487		[learning rate: 0.002223]
	Learning Rate: 0.00222297
	LOSS [training: 0.14934007593278487 | validation: 0.14480927956487924]
	TIME [epoch: 10.3 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11967532564623987		[learning rate: 0.0022162]
	Learning Rate: 0.00221615
	LOSS [training: 0.11967532564623987 | validation: 0.17301980588882743]
	TIME [epoch: 10.3 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14575238459391773		[learning rate: 0.0022094]
	Learning Rate: 0.00220936
	LOSS [training: 0.14575238459391773 | validation: 0.17946777097533764]
	TIME [epoch: 10.3 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13943795274793244		[learning rate: 0.0022026]
	Learning Rate: 0.00220259
	LOSS [training: 0.13943795274793244 | validation: 0.2148409908031494]
	TIME [epoch: 10.3 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10961507473141899		[learning rate: 0.0021958]
	Learning Rate: 0.00219584
	LOSS [training: 0.10961507473141899 | validation: 0.13698461257000225]
	TIME [epoch: 10.3 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1653429669208432		[learning rate: 0.0021891]
	Learning Rate: 0.00218911
	LOSS [training: 0.1653429669208432 | validation: 0.18888658797686103]
	TIME [epoch: 10.3 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475599982863562		[learning rate: 0.0021824]
	Learning Rate: 0.00218239
	LOSS [training: 0.1475599982863562 | validation: 0.1685160552944902]
	TIME [epoch: 10.3 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12093462942887918		[learning rate: 0.0021757]
	Learning Rate: 0.00217571
	LOSS [training: 0.12093462942887918 | validation: 0.14936035636629366]
	TIME [epoch: 10.3 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1152355074954458		[learning rate: 0.002169]
	Learning Rate: 0.00216904
	LOSS [training: 0.1152355074954458 | validation: 0.1690521008686449]
	TIME [epoch: 10.3 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12278267829345957		[learning rate: 0.0021624]
	Learning Rate: 0.00216239
	LOSS [training: 0.12278267829345957 | validation: 0.1885618529488394]
	TIME [epoch: 10.3 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1908021235835403		[learning rate: 0.0021558]
	Learning Rate: 0.00215576
	LOSS [training: 0.1908021235835403 | validation: 0.161713346165281]
	TIME [epoch: 10.3 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09669688007244796		[learning rate: 0.0021491]
	Learning Rate: 0.00214915
	LOSS [training: 0.09669688007244796 | validation: 0.18801930834229835]
	TIME [epoch: 10.3 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0919267137294861		[learning rate: 0.0021426]
	Learning Rate: 0.00214256
	LOSS [training: 0.0919267137294861 | validation: 0.1302247685473711]
	TIME [epoch: 10.3 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08369008717683685		[learning rate: 0.002136]
	Learning Rate: 0.00213599
	LOSS [training: 0.08369008717683685 | validation: 0.15098366611921354]
	TIME [epoch: 10.3 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11316499622603497		[learning rate: 0.0021294]
	Learning Rate: 0.00212945
	LOSS [training: 0.11316499622603497 | validation: 0.1773279578587868]
	TIME [epoch: 10.3 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12318743837975128		[learning rate: 0.0021229]
	Learning Rate: 0.00212292
	LOSS [training: 0.12318743837975128 | validation: 0.17875667499410167]
	TIME [epoch: 10.3 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342928650431653		[learning rate: 0.0021164]
	Learning Rate: 0.00211641
	LOSS [training: 0.1342928650431653 | validation: 0.18737366067293637]
	TIME [epoch: 10.3 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12020879445152852		[learning rate: 0.0021099]
	Learning Rate: 0.00210992
	LOSS [training: 0.12020879445152852 | validation: 0.12782121492428367]
	TIME [epoch: 10.3 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12350322447972813		[learning rate: 0.0021035]
	Learning Rate: 0.00210346
	LOSS [training: 0.12350322447972813 | validation: 0.16007457423798457]
	TIME [epoch: 10.3 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11905019304901757		[learning rate: 0.002097]
	Learning Rate: 0.00209701
	LOSS [training: 0.11905019304901757 | validation: 0.15462585194223472]
	TIME [epoch: 10.3 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09438869268361132		[learning rate: 0.0020906]
	Learning Rate: 0.00209058
	LOSS [training: 0.09438869268361132 | validation: 0.14696378288056425]
	TIME [epoch: 10.3 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11099621554946133		[learning rate: 0.0020842]
	Learning Rate: 0.00208417
	LOSS [training: 0.11099621554946133 | validation: 0.2132614609930017]
	TIME [epoch: 10.3 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14019869269569524		[learning rate: 0.0020778]
	Learning Rate: 0.00207778
	LOSS [training: 0.14019869269569524 | validation: 0.17614020587174473]
	TIME [epoch: 10.3 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09727980969442461		[learning rate: 0.0020714]
	Learning Rate: 0.00207141
	LOSS [training: 0.09727980969442461 | validation: 0.10376148848332266]
	TIME [epoch: 10.3 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09133590563049443		[learning rate: 0.0020651]
	Learning Rate: 0.00206506
	LOSS [training: 0.09133590563049443 | validation: 0.18702086413647664]
	TIME [epoch: 10.3 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12425403937680768		[learning rate: 0.0020587]
	Learning Rate: 0.00205873
	LOSS [training: 0.12425403937680768 | validation: 0.2075746744747703]
	TIME [epoch: 10.3 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24498191654206244		[learning rate: 0.0020524]
	Learning Rate: 0.00205242
	LOSS [training: 0.24498191654206244 | validation: 0.2209461849944846]
	TIME [epoch: 10.3 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2557634056233713		[learning rate: 0.0020461]
	Learning Rate: 0.00204613
	LOSS [training: 0.2557634056233713 | validation: 0.2728456385429072]
	TIME [epoch: 10.3 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30496904587349655		[learning rate: 0.0020399]
	Learning Rate: 0.00203986
	LOSS [training: 0.30496904587349655 | validation: 0.3557285235742644]
	TIME [epoch: 10.3 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3643004291548453		[learning rate: 0.0020336]
	Learning Rate: 0.00203361
	LOSS [training: 0.3643004291548453 | validation: 0.3365662545597586]
	TIME [epoch: 10.3 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23876905313597702		[learning rate: 0.0020274]
	Learning Rate: 0.00202737
	LOSS [training: 0.23876905313597702 | validation: 0.1604285279279238]
	TIME [epoch: 10.3 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1473664116061713		[learning rate: 0.0020212]
	Learning Rate: 0.00202116
	LOSS [training: 0.1473664116061713 | validation: 0.2180153238325312]
	TIME [epoch: 10.3 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13522162671354626		[learning rate: 0.002015]
	Learning Rate: 0.00201496
	LOSS [training: 0.13522162671354626 | validation: 0.1722616176417281]
	TIME [epoch: 10.3 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18225869238601378		[learning rate: 0.0020088]
	Learning Rate: 0.00200878
	LOSS [training: 0.18225869238601378 | validation: 0.36381667828605485]
	TIME [epoch: 10.3 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26606438974606367		[learning rate: 0.0020026]
	Learning Rate: 0.00200263
	LOSS [training: 0.26606438974606367 | validation: 0.28708495406642803]
	TIME [epoch: 10.3 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21017293775514162		[learning rate: 0.0019965]
	Learning Rate: 0.00199649
	LOSS [training: 0.21017293775514162 | validation: 0.2916913288271114]
	TIME [epoch: 10.3 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19707225457651728		[learning rate: 0.0019904]
	Learning Rate: 0.00199037
	LOSS [training: 0.19707225457651728 | validation: 0.22728578996978435]
	TIME [epoch: 10.3 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15679728214486258		[learning rate: 0.0019843]
	Learning Rate: 0.00198427
	LOSS [training: 0.15679728214486258 | validation: 0.20574976752017513]
	TIME [epoch: 10.3 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14652806083608844		[learning rate: 0.0019782]
	Learning Rate: 0.00197818
	LOSS [training: 0.14652806083608844 | validation: 0.16455217961905041]
	TIME [epoch: 10.3 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0861256119514624		[learning rate: 0.0019721]
	Learning Rate: 0.00197212
	LOSS [training: 0.0861256119514624 | validation: 0.12432894514850723]
	TIME [epoch: 10.3 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08158189072398345		[learning rate: 0.0019661]
	Learning Rate: 0.00196607
	LOSS [training: 0.08158189072398345 | validation: 0.14455344754091143]
	TIME [epoch: 10.3 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09204614946519031		[learning rate: 0.00196]
	Learning Rate: 0.00196005
	LOSS [training: 0.09204614946519031 | validation: 0.15066960417895411]
	TIME [epoch: 10.3 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12258140570521045		[learning rate: 0.001954]
	Learning Rate: 0.00195404
	LOSS [training: 0.12258140570521045 | validation: 0.17981645054909132]
	TIME [epoch: 10.3 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09022457635807561		[learning rate: 0.001948]
	Learning Rate: 0.00194805
	LOSS [training: 0.09022457635807561 | validation: 0.11865646756478264]
	TIME [epoch: 10.3 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06277140293873615		[learning rate: 0.0019421]
	Learning Rate: 0.00194208
	LOSS [training: 0.06277140293873615 | validation: 0.12151193980796134]
	TIME [epoch: 10.3 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07639513687986901		[learning rate: 0.0019361]
	Learning Rate: 0.00193612
	LOSS [training: 0.07639513687986901 | validation: 0.17588197471297087]
	TIME [epoch: 10.3 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07400075885839812		[learning rate: 0.0019302]
	Learning Rate: 0.00193019
	LOSS [training: 0.07400075885839812 | validation: 0.13557354250383374]
	TIME [epoch: 10.3 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10488035173776822		[learning rate: 0.0019243]
	Learning Rate: 0.00192427
	LOSS [training: 0.10488035173776822 | validation: 0.18618596258193987]
	TIME [epoch: 10.3 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09140099177398964		[learning rate: 0.0019184]
	Learning Rate: 0.00191837
	LOSS [training: 0.09140099177398964 | validation: 0.12036943832010602]
	TIME [epoch: 10.3 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06507439023882708		[learning rate: 0.0019125]
	Learning Rate: 0.00191249
	LOSS [training: 0.06507439023882708 | validation: 0.10627335679798967]
	TIME [epoch: 10.3 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07721286585252327		[learning rate: 0.0019066]
	Learning Rate: 0.00190663
	LOSS [training: 0.07721286585252327 | validation: 0.1288085871981788]
	TIME [epoch: 10.3 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08125088125609288		[learning rate: 0.0019008]
	Learning Rate: 0.00190079
	LOSS [training: 0.08125088125609288 | validation: 0.1399029133895835]
	TIME [epoch: 10.3 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09697201292257261		[learning rate: 0.001895]
	Learning Rate: 0.00189496
	LOSS [training: 0.09697201292257261 | validation: 0.1250887112248083]
	TIME [epoch: 10.3 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09805852320658477		[learning rate: 0.0018892]
	Learning Rate: 0.00188915
	LOSS [training: 0.09805852320658477 | validation: 0.17284973298589265]
	TIME [epoch: 10.3 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16046045685836202		[learning rate: 0.0018834]
	Learning Rate: 0.00188336
	LOSS [training: 0.16046045685836202 | validation: 0.14374076149554915]
	TIME [epoch: 10.3 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09847725606199954		[learning rate: 0.0018776]
	Learning Rate: 0.00187759
	LOSS [training: 0.09847725606199954 | validation: 0.15749616986760281]
	TIME [epoch: 10.3 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07752176183228042		[learning rate: 0.0018718]
	Learning Rate: 0.00187183
	LOSS [training: 0.07752176183228042 | validation: 0.127856298725946]
	TIME [epoch: 10.3 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0572451588993335		[learning rate: 0.0018661]
	Learning Rate: 0.00186609
	LOSS [training: 0.0572451588993335 | validation: 0.11279989124755802]
	TIME [epoch: 10.3 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06743127603207127		[learning rate: 0.0018604]
	Learning Rate: 0.00186037
	LOSS [training: 0.06743127603207127 | validation: 0.0997970978372045]
	TIME [epoch: 10.3 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052043006281665374		[learning rate: 0.0018547]
	Learning Rate: 0.00185467
	LOSS [training: 0.052043006281665374 | validation: 0.10742896157457948]
	TIME [epoch: 10.3 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06639663200946902		[learning rate: 0.001849]
	Learning Rate: 0.00184898
	LOSS [training: 0.06639663200946902 | validation: 0.10658434745501348]
	TIME [epoch: 10.3 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07229310886371779		[learning rate: 0.0018433]
	Learning Rate: 0.00184332
	LOSS [training: 0.07229310886371779 | validation: 0.11825417772487117]
	TIME [epoch: 10.3 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06692387732794321		[learning rate: 0.0018377]
	Learning Rate: 0.00183767
	LOSS [training: 0.06692387732794321 | validation: 0.1402923500557024]
	TIME [epoch: 10.3 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09048774468892094		[learning rate: 0.001832]
	Learning Rate: 0.00183203
	LOSS [training: 0.09048774468892094 | validation: 0.1377635966151446]
	TIME [epoch: 10.3 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06470419163144812		[learning rate: 0.0018264]
	Learning Rate: 0.00182642
	LOSS [training: 0.06470419163144812 | validation: 0.11863271868031366]
	TIME [epoch: 10.3 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06787224039354156		[learning rate: 0.0018208]
	Learning Rate: 0.00182082
	LOSS [training: 0.06787224039354156 | validation: 0.12874960709367983]
	TIME [epoch: 10.3 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07468170310274169		[learning rate: 0.0018152]
	Learning Rate: 0.00181524
	LOSS [training: 0.07468170310274169 | validation: 0.12164921111632396]
	TIME [epoch: 10.3 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11581693671218732		[learning rate: 0.0018097]
	Learning Rate: 0.00180967
	LOSS [training: 0.11581693671218732 | validation: 0.14198880312486364]
	TIME [epoch: 10.3 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10542873035551674		[learning rate: 0.0018041]
	Learning Rate: 0.00180412
	LOSS [training: 0.10542873035551674 | validation: 0.10675056667471576]
	TIME [epoch: 10.3 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10790186941647348		[learning rate: 0.0017986]
	Learning Rate: 0.00179859
	LOSS [training: 0.10790186941647348 | validation: 0.11743521537853129]
	TIME [epoch: 10.3 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08949359306119238		[learning rate: 0.0017931]
	Learning Rate: 0.00179308
	LOSS [training: 0.08949359306119238 | validation: 0.11469234747655381]
	TIME [epoch: 10.3 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09606586288186139		[learning rate: 0.0017876]
	Learning Rate: 0.00178758
	LOSS [training: 0.09606586288186139 | validation: 0.11223527623102438]
	TIME [epoch: 10.3 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07632872005344231		[learning rate: 0.0017821]
	Learning Rate: 0.00178211
	LOSS [training: 0.07632872005344231 | validation: 0.09172269997833248]
	TIME [epoch: 10.3 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07626444862247256		[learning rate: 0.0017766]
	Learning Rate: 0.00177664
	LOSS [training: 0.07626444862247256 | validation: 0.15068234043853682]
	TIME [epoch: 10.3 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09987416385093725		[learning rate: 0.0017712]
	Learning Rate: 0.0017712
	LOSS [training: 0.09987416385093725 | validation: 0.13276495608177993]
	TIME [epoch: 10.3 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07363343056269754		[learning rate: 0.0017658]
	Learning Rate: 0.00176577
	LOSS [training: 0.07363343056269754 | validation: 0.12500031849059834]
	TIME [epoch: 10.3 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06986641202850875		[learning rate: 0.0017604]
	Learning Rate: 0.00176035
	LOSS [training: 0.06986641202850875 | validation: 0.15857983406762183]
	TIME [epoch: 10.3 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10278786381155425		[learning rate: 0.001755]
	Learning Rate: 0.00175496
	LOSS [training: 0.10278786381155425 | validation: 0.1666893922356848]
	TIME [epoch: 10.3 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11921609897714938		[learning rate: 0.0017496]
	Learning Rate: 0.00174958
	LOSS [training: 0.11921609897714938 | validation: 0.19736297586702628]
	TIME [epoch: 10.3 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10066003239623074		[learning rate: 0.0017442]
	Learning Rate: 0.00174421
	LOSS [training: 0.10066003239623074 | validation: 0.1209509672218414]
	TIME [epoch: 10.3 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06211378309258166		[learning rate: 0.0017389]
	Learning Rate: 0.00173887
	LOSS [training: 0.06211378309258166 | validation: 0.1018032821523682]
	TIME [epoch: 10.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06347313845356597		[learning rate: 0.0017335]
	Learning Rate: 0.00173354
	LOSS [training: 0.06347313845356597 | validation: 0.09679442031397127]
	TIME [epoch: 10.3 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060650887347750884		[learning rate: 0.0017282]
	Learning Rate: 0.00172822
	LOSS [training: 0.060650887347750884 | validation: 0.10890859633070615]
	TIME [epoch: 10.3 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06349922586559749		[learning rate: 0.0017229]
	Learning Rate: 0.00172293
	LOSS [training: 0.06349922586559749 | validation: 0.1278323498744109]
	TIME [epoch: 10.3 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07542963313857833		[learning rate: 0.0017176]
	Learning Rate: 0.00171764
	LOSS [training: 0.07542963313857833 | validation: 0.15983971603227334]
	TIME [epoch: 10.3 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09579063661682899		[learning rate: 0.0017124]
	Learning Rate: 0.00171238
	LOSS [training: 0.09579063661682899 | validation: 0.14638021450952315]
	TIME [epoch: 10.3 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09120233915559195		[learning rate: 0.0017071]
	Learning Rate: 0.00170713
	LOSS [training: 0.09120233915559195 | validation: 0.13418760756166262]
	TIME [epoch: 10.3 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08016794948834823		[learning rate: 0.0017019]
	Learning Rate: 0.0017019
	LOSS [training: 0.08016794948834823 | validation: 0.12143942167429356]
	TIME [epoch: 10.3 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0644206505367088		[learning rate: 0.0016967]
	Learning Rate: 0.00169668
	LOSS [training: 0.0644206505367088 | validation: 0.1235081719570465]
	TIME [epoch: 10.3 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06470730723414483		[learning rate: 0.0016915]
	Learning Rate: 0.00169148
	LOSS [training: 0.06470730723414483 | validation: 0.11130533853600234]
	TIME [epoch: 10.3 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07277912668237388		[learning rate: 0.0016863]
	Learning Rate: 0.00168629
	LOSS [training: 0.07277912668237388 | validation: 0.08197546052824023]
	TIME [epoch: 10.3 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06218457220223356		[learning rate: 0.0016811]
	Learning Rate: 0.00168113
	LOSS [training: 0.06218457220223356 | validation: 0.09585917771818077]
	TIME [epoch: 10.3 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.071649914561513		[learning rate: 0.001676]
	Learning Rate: 0.00167597
	LOSS [training: 0.071649914561513 | validation: 0.11427823004708308]
	TIME [epoch: 10.3 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10323822289396303		[learning rate: 0.0016708]
	Learning Rate: 0.00167083
	LOSS [training: 0.10323822289396303 | validation: 0.16708506917193097]
	TIME [epoch: 10.3 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09337892264998841		[learning rate: 0.0016657]
	Learning Rate: 0.00166571
	LOSS [training: 0.09337892264998841 | validation: 0.127065991636283]
	TIME [epoch: 10.3 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06755060399132261		[learning rate: 0.0016606]
	Learning Rate: 0.00166061
	LOSS [training: 0.06755060399132261 | validation: 0.16965801031033137]
	TIME [epoch: 10.3 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10071721646998502		[learning rate: 0.0016555]
	Learning Rate: 0.00165552
	LOSS [training: 0.10071721646998502 | validation: 0.15862388170088593]
	TIME [epoch: 10.3 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0802723456624721		[learning rate: 0.0016504]
	Learning Rate: 0.00165044
	LOSS [training: 0.0802723456624721 | validation: 0.07683697915594163]
	TIME [epoch: 10.3 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06760210053681115		[learning rate: 0.0016454]
	Learning Rate: 0.00164538
	LOSS [training: 0.06760210053681115 | validation: 0.10557223856251881]
	TIME [epoch: 10.3 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052014897766592925		[learning rate: 0.0016403]
	Learning Rate: 0.00164034
	LOSS [training: 0.052014897766592925 | validation: 0.10154665067623725]
	TIME [epoch: 10.3 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07355746211109636		[learning rate: 0.0016353]
	Learning Rate: 0.00163531
	LOSS [training: 0.07355746211109636 | validation: 0.12232799291157548]
	TIME [epoch: 10.2 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07558859218710817		[learning rate: 0.0016303]
	Learning Rate: 0.0016303
	LOSS [training: 0.07558859218710817 | validation: 0.16373848969496746]
	TIME [epoch: 10.3 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10823868981175858		[learning rate: 0.0016253]
	Learning Rate: 0.0016253
	LOSS [training: 0.10823868981175858 | validation: 0.16602820774613355]
	TIME [epoch: 10.3 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07636071700943846		[learning rate: 0.0016203]
	Learning Rate: 0.00162032
	LOSS [training: 0.07636071700943846 | validation: 0.14477248430716125]
	TIME [epoch: 10.3 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07528840830520166		[learning rate: 0.0016154]
	Learning Rate: 0.00161535
	LOSS [training: 0.07528840830520166 | validation: 0.1226844323916397]
	TIME [epoch: 10.3 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05992468864748783		[learning rate: 0.0016104]
	Learning Rate: 0.0016104
	LOSS [training: 0.05992468864748783 | validation: 0.09381667442929725]
	TIME [epoch: 10.3 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055002675262031356		[learning rate: 0.0016055]
	Learning Rate: 0.00160546
	LOSS [training: 0.055002675262031356 | validation: 0.12317232493595089]
	TIME [epoch: 10.3 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07307112471301272		[learning rate: 0.0016005]
	Learning Rate: 0.00160054
	LOSS [training: 0.07307112471301272 | validation: 0.11887751421723237]
	TIME [epoch: 10.3 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05767951183232296		[learning rate: 0.0015956]
	Learning Rate: 0.00159563
	LOSS [training: 0.05767951183232296 | validation: 0.11690594530855547]
	TIME [epoch: 10.3 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07650419015995372		[learning rate: 0.0015907]
	Learning Rate: 0.00159074
	LOSS [training: 0.07650419015995372 | validation: 0.13819623700367842]
	TIME [epoch: 10.3 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06451854072706194		[learning rate: 0.0015859]
	Learning Rate: 0.00158587
	LOSS [training: 0.06451854072706194 | validation: 0.11956201385961446]
	TIME [epoch: 10.3 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05531915876838622		[learning rate: 0.001581]
	Learning Rate: 0.00158101
	LOSS [training: 0.05531915876838622 | validation: 0.09693316098105059]
	TIME [epoch: 10.3 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05236097050172915		[learning rate: 0.0015762]
	Learning Rate: 0.00157616
	LOSS [training: 0.05236097050172915 | validation: 0.11439511561678728]
	TIME [epoch: 10.3 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05662241294945539		[learning rate: 0.0015713]
	Learning Rate: 0.00157133
	LOSS [training: 0.05662241294945539 | validation: 0.11758485602911148]
	TIME [epoch: 10.3 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1184072414403099		[learning rate: 0.0015665]
	Learning Rate: 0.00156651
	LOSS [training: 0.1184072414403099 | validation: 0.1496937323286341]
	TIME [epoch: 10.3 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11267874906939487		[learning rate: 0.0015617]
	Learning Rate: 0.00156171
	LOSS [training: 0.11267874906939487 | validation: 0.1455711147029459]
	TIME [epoch: 10.3 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08552417919674339		[learning rate: 0.0015569]
	Learning Rate: 0.00155692
	LOSS [training: 0.08552417919674339 | validation: 0.12998781045806912]
	TIME [epoch: 10.3 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07874651932090666		[learning rate: 0.0015521]
	Learning Rate: 0.00155215
	LOSS [training: 0.07874651932090666 | validation: 0.12232703009277301]
	TIME [epoch: 10.3 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07118135142931861		[learning rate: 0.0015474]
	Learning Rate: 0.00154739
	LOSS [training: 0.07118135142931861 | validation: 0.10659978381088384]
	TIME [epoch: 10.3 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11039427796952508		[learning rate: 0.0015426]
	Learning Rate: 0.00154265
	LOSS [training: 0.11039427796952508 | validation: 0.19872830836275562]
	TIME [epoch: 10.3 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10408063770351546		[learning rate: 0.0015379]
	Learning Rate: 0.00153792
	LOSS [training: 0.10408063770351546 | validation: 0.15642621243528818]
	TIME [epoch: 10.3 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0706984286953512		[learning rate: 0.0015332]
	Learning Rate: 0.0015332
	LOSS [training: 0.0706984286953512 | validation: 0.13312806046746015]
	TIME [epoch: 10.3 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07527028325844491		[learning rate: 0.0015285]
	Learning Rate: 0.0015285
	LOSS [training: 0.07527028325844491 | validation: 0.1537066440576077]
	TIME [epoch: 10.3 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09964022650262046		[learning rate: 0.0015238]
	Learning Rate: 0.00152382
	LOSS [training: 0.09964022650262046 | validation: 0.18891670596501975]
	TIME [epoch: 10.3 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11311913884694016		[learning rate: 0.0015191]
	Learning Rate: 0.00151915
	LOSS [training: 0.11311913884694016 | validation: 0.14285031011892568]
	TIME [epoch: 10.3 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09178460320259647		[learning rate: 0.0015145]
	Learning Rate: 0.00151449
	LOSS [training: 0.09178460320259647 | validation: 0.1635337256025933]
	TIME [epoch: 10.3 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10212954377091492		[learning rate: 0.0015098]
	Learning Rate: 0.00150985
	LOSS [training: 0.10212954377091492 | validation: 0.18032462996435766]
	TIME [epoch: 10.3 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08150740286091922		[learning rate: 0.0015052]
	Learning Rate: 0.00150522
	LOSS [training: 0.08150740286091922 | validation: 0.13996110195183092]
	TIME [epoch: 10.3 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06741335260101114		[learning rate: 0.0015006]
	Learning Rate: 0.00150061
	LOSS [training: 0.06741335260101114 | validation: 0.11791889943526872]
	TIME [epoch: 10.3 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07627219458468033		[learning rate: 0.001496]
	Learning Rate: 0.00149601
	LOSS [training: 0.07627219458468033 | validation: 0.14213476517480447]
	TIME [epoch: 10.3 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09899659616790843		[learning rate: 0.0014914]
	Learning Rate: 0.00149142
	LOSS [training: 0.09899659616790843 | validation: 0.13687164700963864]
	TIME [epoch: 10.3 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0944323432295551		[learning rate: 0.0014868]
	Learning Rate: 0.00148685
	LOSS [training: 0.0944323432295551 | validation: 0.136805770107919]
	TIME [epoch: 10.3 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09792541973432504		[learning rate: 0.0014823]
	Learning Rate: 0.00148229
	LOSS [training: 0.09792541973432504 | validation: 0.12957358129166432]
	TIME [epoch: 10.3 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13128448504162554		[learning rate: 0.0014777]
	Learning Rate: 0.00147775
	LOSS [training: 0.13128448504162554 | validation: 0.15899035796183544]
	TIME [epoch: 10.3 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10061466322821759		[learning rate: 0.0014732]
	Learning Rate: 0.00147322
	LOSS [training: 0.10061466322821759 | validation: 0.13404360558205572]
	TIME [epoch: 10.3 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10681897218854686		[learning rate: 0.0014687]
	Learning Rate: 0.0014687
	LOSS [training: 0.10681897218854686 | validation: 0.22035383649212256]
	TIME [epoch: 10.3 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1277125506587638		[learning rate: 0.0014642]
	Learning Rate: 0.0014642
	LOSS [training: 0.1277125506587638 | validation: 0.16084870727396264]
	TIME [epoch: 10.3 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09072046559991528		[learning rate: 0.0014597]
	Learning Rate: 0.00145971
	LOSS [training: 0.09072046559991528 | validation: 0.15565217064664513]
	TIME [epoch: 10.3 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08952112620146924		[learning rate: 0.0014552]
	Learning Rate: 0.00145524
	LOSS [training: 0.08952112620146924 | validation: 0.12739145919224446]
	TIME [epoch: 10.3 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09080106543932587		[learning rate: 0.0014508]
	Learning Rate: 0.00145077
	LOSS [training: 0.09080106543932587 | validation: 0.1385133318863473]
	TIME [epoch: 10.3 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0751999577882196		[learning rate: 0.0014463]
	Learning Rate: 0.00144633
	LOSS [training: 0.0751999577882196 | validation: 0.10423610424806298]
	TIME [epoch: 10.3 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07027241403683586		[learning rate: 0.0014419]
	Learning Rate: 0.00144189
	LOSS [training: 0.07027241403683586 | validation: 0.15629371670447456]
	TIME [epoch: 10.3 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08556534318402197		[learning rate: 0.0014375]
	Learning Rate: 0.00143747
	LOSS [training: 0.08556534318402197 | validation: 0.11988977707559492]
	TIME [epoch: 10.3 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09424425481245809		[learning rate: 0.0014331]
	Learning Rate: 0.00143307
	LOSS [training: 0.09424425481245809 | validation: 0.11600753436114986]
	TIME [epoch: 10.3 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07618853640159219		[learning rate: 0.0014287]
	Learning Rate: 0.00142867
	LOSS [training: 0.07618853640159219 | validation: 0.09316299044060944]
	TIME [epoch: 10.3 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07201977109999648		[learning rate: 0.0014243]
	Learning Rate: 0.0014243
	LOSS [training: 0.07201977109999648 | validation: 0.14327055242617096]
	TIME [epoch: 10.3 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08852313047367391		[learning rate: 0.0014199]
	Learning Rate: 0.00141993
	LOSS [training: 0.08852313047367391 | validation: 0.18967746026557783]
	TIME [epoch: 10.3 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14353525011308294		[learning rate: 0.0014156]
	Learning Rate: 0.00141558
	LOSS [training: 0.14353525011308294 | validation: 0.16518176714590524]
	TIME [epoch: 10.3 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13237100480063652		[learning rate: 0.0014112]
	Learning Rate: 0.00141124
	LOSS [training: 0.13237100480063652 | validation: 0.3198615114127179]
	TIME [epoch: 10.3 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19927028042238945		[learning rate: 0.0014069]
	Learning Rate: 0.00140691
	LOSS [training: 0.19927028042238945 | validation: 0.21144888094028194]
	TIME [epoch: 10.3 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14747043598134865		[learning rate: 0.0014026]
	Learning Rate: 0.0014026
	LOSS [training: 0.14747043598134865 | validation: 0.1948544753435975]
	TIME [epoch: 10.3 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13209925598494357		[learning rate: 0.0013983]
	Learning Rate: 0.0013983
	LOSS [training: 0.13209925598494357 | validation: 0.1872065259746909]
	TIME [epoch: 10.3 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09901724168474657		[learning rate: 0.001394]
	Learning Rate: 0.00139401
	LOSS [training: 0.09901724168474657 | validation: 0.12937139139237278]
	TIME [epoch: 10.3 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08244295953471378		[learning rate: 0.0013897]
	Learning Rate: 0.00138974
	LOSS [training: 0.08244295953471378 | validation: 0.1506038510525816]
	TIME [epoch: 10.3 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08390181969531514		[learning rate: 0.0013855]
	Learning Rate: 0.00138548
	LOSS [training: 0.08390181969531514 | validation: 0.13436420078176145]
	TIME [epoch: 10.3 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07791861278740078		[learning rate: 0.0013812]
	Learning Rate: 0.00138123
	LOSS [training: 0.07791861278740078 | validation: 0.1269442391141792]
	TIME [epoch: 10.3 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08877394977462309		[learning rate: 0.001377]
	Learning Rate: 0.001377
	LOSS [training: 0.08877394977462309 | validation: 0.17167762267628953]
	TIME [epoch: 10.3 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11352227171139662		[learning rate: 0.0013728]
	Learning Rate: 0.00137278
	LOSS [training: 0.11352227171139662 | validation: 0.19695475421716563]
	TIME [epoch: 10.2 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11712144392272247		[learning rate: 0.0013686]
	Learning Rate: 0.00136857
	LOSS [training: 0.11712144392272247 | validation: 0.17362043036256403]
	TIME [epoch: 10.3 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11839961621435835		[learning rate: 0.0013644]
	Learning Rate: 0.00136437
	LOSS [training: 0.11839961621435835 | validation: 0.24649565639219173]
	TIME [epoch: 10.3 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.255632546451906		[learning rate: 0.0013602]
	Learning Rate: 0.00136019
	LOSS [training: 0.255632546451906 | validation: 0.38867063046625566]
	TIME [epoch: 10.3 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2796119861768951		[learning rate: 0.001356]
	Learning Rate: 0.00135602
	LOSS [training: 0.2796119861768951 | validation: 0.34258479232747996]
	TIME [epoch: 10.3 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2360471191594447		[learning rate: 0.0013519]
	Learning Rate: 0.00135187
	LOSS [training: 0.2360471191594447 | validation: 0.35103480806611453]
	TIME [epoch: 10.3 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26126965923263357		[learning rate: 0.0013477]
	Learning Rate: 0.00134772
	LOSS [training: 0.26126965923263357 | validation: 0.23640500272649578]
	TIME [epoch: 10.3 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18901854849006194		[learning rate: 0.0013436]
	Learning Rate: 0.00134359
	LOSS [training: 0.18901854849006194 | validation: 0.3571240004313296]
	TIME [epoch: 10.3 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2928780365251819		[learning rate: 0.0013395]
	Learning Rate: 0.00133947
	LOSS [training: 0.2928780365251819 | validation: 0.31574609186050046]
	TIME [epoch: 10.3 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25040459353945366		[learning rate: 0.0013354]
	Learning Rate: 0.00133536
	LOSS [training: 0.25040459353945366 | validation: 0.2605934409976625]
	TIME [epoch: 10.3 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1708683695495224		[learning rate: 0.0013313]
	Learning Rate: 0.00133127
	LOSS [training: 0.1708683695495224 | validation: 0.16404885857448911]
	TIME [epoch: 10.3 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1283030723948247		[learning rate: 0.0013272]
	Learning Rate: 0.00132719
	LOSS [training: 0.1283030723948247 | validation: 0.19251412965104156]
	TIME [epoch: 10.3 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14210961194651794		[learning rate: 0.0013231]
	Learning Rate: 0.00132312
	LOSS [training: 0.14210961194651794 | validation: 0.2116888993628573]
	TIME [epoch: 10.3 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1518992940163854		[learning rate: 0.0013191]
	Learning Rate: 0.00131907
	LOSS [training: 0.1518992940163854 | validation: 0.2237720919134234]
	TIME [epoch: 10.3 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16907727698035568		[learning rate: 0.001315]
	Learning Rate: 0.00131502
	LOSS [training: 0.16907727698035568 | validation: 0.20100459806358775]
	TIME [epoch: 10.3 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508749795077568		[learning rate: 0.001311]
	Learning Rate: 0.00131099
	LOSS [training: 0.1508749795077568 | validation: 0.18387817205250642]
	TIME [epoch: 10.3 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13313107277021893		[learning rate: 0.001307]
	Learning Rate: 0.00130697
	LOSS [training: 0.13313107277021893 | validation: 0.15212129934354782]
	TIME [epoch: 10.3 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11850286342764119		[learning rate: 0.001303]
	Learning Rate: 0.00130297
	LOSS [training: 0.11850286342764119 | validation: 0.1335389140568833]
	TIME [epoch: 10.3 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.111630840728692		[learning rate: 0.001299]
	Learning Rate: 0.00129897
	LOSS [training: 0.111630840728692 | validation: 0.18873329138436298]
	TIME [epoch: 10.3 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10294938583514313		[learning rate: 0.001295]
	Learning Rate: 0.00129499
	LOSS [training: 0.10294938583514313 | validation: 0.14175293906594388]
	TIME [epoch: 10.2 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09989327417018093		[learning rate: 0.001291]
	Learning Rate: 0.00129102
	LOSS [training: 0.09989327417018093 | validation: 0.13284584374684272]
	TIME [epoch: 10.3 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09644048814475062		[learning rate: 0.0012871]
	Learning Rate: 0.00128706
	LOSS [training: 0.09644048814475062 | validation: 0.11872539999366889]
	TIME [epoch: 10.3 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0919196566993719		[learning rate: 0.0012831]
	Learning Rate: 0.00128312
	LOSS [training: 0.0919196566993719 | validation: 0.13679636574741927]
	TIME [epoch: 10.3 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09540022529270331		[learning rate: 0.0012792]
	Learning Rate: 0.00127918
	LOSS [training: 0.09540022529270331 | validation: 0.12389616585327122]
	TIME [epoch: 10.2 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09451072965497458		[learning rate: 0.0012753]
	Learning Rate: 0.00127526
	LOSS [training: 0.09451072965497458 | validation: 0.1702734840821004]
	TIME [epoch: 10.2 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09771388459258962		[learning rate: 0.0012714]
	Learning Rate: 0.00127135
	LOSS [training: 0.09771388459258962 | validation: 0.11515570068762035]
	TIME [epoch: 10.3 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07396379984628877		[learning rate: 0.0012675]
	Learning Rate: 0.00126746
	LOSS [training: 0.07396379984628877 | validation: 0.13848136072208894]
	TIME [epoch: 10.3 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.104488629515054		[learning rate: 0.0012636]
	Learning Rate: 0.00126357
	LOSS [training: 0.104488629515054 | validation: 0.16193161556245628]
	TIME [epoch: 10.3 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09554415392883528		[learning rate: 0.0012597]
	Learning Rate: 0.0012597
	LOSS [training: 0.09554415392883528 | validation: 0.10292005252289865]
	TIME [epoch: 10.3 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09369690681273934		[learning rate: 0.0012558]
	Learning Rate: 0.00125584
	LOSS [training: 0.09369690681273934 | validation: 0.15095527233371517]
	TIME [epoch: 10.3 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1126996975901186		[learning rate: 0.001252]
	Learning Rate: 0.00125199
	LOSS [training: 0.1126996975901186 | validation: 0.1607475379774938]
	TIME [epoch: 10.3 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16227262220134664		[learning rate: 0.0012481]
	Learning Rate: 0.00124815
	LOSS [training: 0.16227262220134664 | validation: 0.15999893023781322]
	TIME [epoch: 10.3 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13557345566276707		[learning rate: 0.0012443]
	Learning Rate: 0.00124432
	LOSS [training: 0.13557345566276707 | validation: 0.22458159617499468]
	TIME [epoch: 10.3 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1711533967396655		[learning rate: 0.0012405]
	Learning Rate: 0.00124051
	LOSS [training: 0.1711533967396655 | validation: 0.19023085322873662]
	TIME [epoch: 10.3 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1908544938978356		[learning rate: 0.0012367]
	Learning Rate: 0.00123671
	LOSS [training: 0.1908544938978356 | validation: 0.2854533219252026]
	TIME [epoch: 10.3 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19205975937346775		[learning rate: 0.0012329]
	Learning Rate: 0.00123292
	LOSS [training: 0.19205975937346775 | validation: 0.22343392436963647]
	TIME [epoch: 10.3 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13841915105053865		[learning rate: 0.0012291]
	Learning Rate: 0.00122914
	LOSS [training: 0.13841915105053865 | validation: 0.19084000586215782]
	TIME [epoch: 10.3 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12181639831094251		[learning rate: 0.0012254]
	Learning Rate: 0.00122537
	LOSS [training: 0.12181639831094251 | validation: 0.2155911834760591]
	TIME [epoch: 10.3 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12512111397299516		[learning rate: 0.0012216]
	Learning Rate: 0.00122161
	LOSS [training: 0.12512111397299516 | validation: 0.17051603440749954]
	TIME [epoch: 10.3 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.096395502870299		[learning rate: 0.0012179]
	Learning Rate: 0.00121787
	LOSS [training: 0.096395502870299 | validation: 0.11826451800127102]
	TIME [epoch: 10.3 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09070713123710107		[learning rate: 0.0012141]
	Learning Rate: 0.00121413
	LOSS [training: 0.09070713123710107 | validation: 0.15310872629347397]
	TIME [epoch: 10.3 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10018131788882914		[learning rate: 0.0012104]
	Learning Rate: 0.00121041
	LOSS [training: 0.10018131788882914 | validation: 0.13539932536060498]
	TIME [epoch: 10.3 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0840945584199271		[learning rate: 0.0012067]
	Learning Rate: 0.0012067
	LOSS [training: 0.0840945584199271 | validation: 0.14515896491886351]
	TIME [epoch: 10.3 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08819839409248001		[learning rate: 0.001203]
	Learning Rate: 0.001203
	LOSS [training: 0.08819839409248001 | validation: 0.14891288332937092]
	TIME [epoch: 10.3 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10891161643910781		[learning rate: 0.0011993]
	Learning Rate: 0.00119932
	LOSS [training: 0.10891161643910781 | validation: 0.15907540970144093]
	TIME [epoch: 10.2 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12119185734769293		[learning rate: 0.0011956]
	Learning Rate: 0.00119564
	LOSS [training: 0.12119185734769293 | validation: 0.1622084658703684]
	TIME [epoch: 10.3 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09321017826740037		[learning rate: 0.001192]
	Learning Rate: 0.00119197
	LOSS [training: 0.09321017826740037 | validation: 0.1466658303986914]
	TIME [epoch: 10.3 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08283984046219259		[learning rate: 0.0011883]
	Learning Rate: 0.00118832
	LOSS [training: 0.08283984046219259 | validation: 0.14851658688521796]
	TIME [epoch: 10.3 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09369551209439943		[learning rate: 0.0011847]
	Learning Rate: 0.00118468
	LOSS [training: 0.09369551209439943 | validation: 0.12543416980224253]
	TIME [epoch: 10.3 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09140193254014321		[learning rate: 0.001181]
	Learning Rate: 0.00118105
	LOSS [training: 0.09140193254014321 | validation: 0.09733130416228924]
	TIME [epoch: 10.3 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07964070257424569		[learning rate: 0.0011774]
	Learning Rate: 0.00117743
	LOSS [training: 0.07964070257424569 | validation: 0.14083285183448682]
	TIME [epoch: 10.3 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07811858394010188		[learning rate: 0.0011738]
	Learning Rate: 0.00117382
	LOSS [training: 0.07811858394010188 | validation: 0.14583812472526048]
	TIME [epoch: 10.3 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07131924914411572		[learning rate: 0.0011702]
	Learning Rate: 0.00117022
	LOSS [training: 0.07131924914411572 | validation: 0.13355869997980072]
	TIME [epoch: 10.3 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0882738849673115		[learning rate: 0.0011666]
	Learning Rate: 0.00116663
	LOSS [training: 0.0882738849673115 | validation: 0.14833388814648327]
	TIME [epoch: 10.3 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08637358530721558		[learning rate: 0.0011631]
	Learning Rate: 0.00116305
	LOSS [training: 0.08637358530721558 | validation: 0.11415865957190269]
	TIME [epoch: 10.3 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07274883958794952		[learning rate: 0.0011595]
	Learning Rate: 0.00115949
	LOSS [training: 0.07274883958794952 | validation: 0.14105333527361072]
	TIME [epoch: 10.3 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08697703128499014		[learning rate: 0.0011559]
	Learning Rate: 0.00115593
	LOSS [training: 0.08697703128499014 | validation: 0.1699019551500326]
	TIME [epoch: 10.3 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08919047312485442		[learning rate: 0.0011524]
	Learning Rate: 0.00115239
	LOSS [training: 0.08919047312485442 | validation: 0.1275238949025869]
	TIME [epoch: 10.2 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10815977002741364		[learning rate: 0.0011489]
	Learning Rate: 0.00114886
	LOSS [training: 0.10815977002741364 | validation: 0.20311535070820938]
	TIME [epoch: 10.3 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13153543446023871		[learning rate: 0.0011453]
	Learning Rate: 0.00114534
	LOSS [training: 0.13153543446023871 | validation: 0.20656019203458104]
	TIME [epoch: 10.3 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1498188539848057		[learning rate: 0.0011418]
	Learning Rate: 0.00114183
	LOSS [training: 0.1498188539848057 | validation: 0.22164983156378593]
	TIME [epoch: 10.3 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16054490365370422		[learning rate: 0.0011383]
	Learning Rate: 0.00113833
	LOSS [training: 0.16054490365370422 | validation: 0.19475061324788578]
	TIME [epoch: 10.3 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11139611389513374		[learning rate: 0.0011348]
	Learning Rate: 0.00113484
	LOSS [training: 0.11139611389513374 | validation: 0.18003153856992163]
	TIME [epoch: 10.3 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09919480462973054		[learning rate: 0.0011314]
	Learning Rate: 0.00113136
	LOSS [training: 0.09919480462973054 | validation: 0.1308745608280843]
	TIME [epoch: 10.3 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0942943502898206		[learning rate: 0.0011279]
	Learning Rate: 0.00112789
	LOSS [training: 0.0942943502898206 | validation: 0.14262974375981446]
	TIME [epoch: 10.3 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09430980866901115		[learning rate: 0.0011244]
	Learning Rate: 0.00112443
	LOSS [training: 0.09430980866901115 | validation: 0.1263180925250891]
	TIME [epoch: 10.3 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08316902966903848		[learning rate: 0.001121]
	Learning Rate: 0.00112099
	LOSS [training: 0.08316902966903848 | validation: 0.1375037756571432]
	TIME [epoch: 10.3 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08520256899974951		[learning rate: 0.0011175]
	Learning Rate: 0.00111755
	LOSS [training: 0.08520256899974951 | validation: 0.12062238267977389]
	TIME [epoch: 10.3 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08297378580672413		[learning rate: 0.0011141]
	Learning Rate: 0.00111412
	LOSS [training: 0.08297378580672413 | validation: 0.13971319134362953]
	TIME [epoch: 10.3 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0724120977014089		[learning rate: 0.0011107]
	Learning Rate: 0.00111071
	LOSS [training: 0.0724120977014089 | validation: 0.14704618752838702]
	TIME [epoch: 10.3 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09216861956854364		[learning rate: 0.0011073]
	Learning Rate: 0.0011073
	LOSS [training: 0.09216861956854364 | validation: 0.10692743548728054]
	TIME [epoch: 10.3 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07112694972152395		[learning rate: 0.0011039]
	Learning Rate: 0.00110391
	LOSS [training: 0.07112694972152395 | validation: 0.11386456921886931]
	TIME [epoch: 10.3 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08121802903425454		[learning rate: 0.0011005]
	Learning Rate: 0.00110053
	LOSS [training: 0.08121802903425454 | validation: 0.13261383485739583]
	TIME [epoch: 10.3 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06741550916438314		[learning rate: 0.0010972]
	Learning Rate: 0.00109715
	LOSS [training: 0.06741550916438314 | validation: 0.12469529743716928]
	TIME [epoch: 10.3 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09468943498675193		[learning rate: 0.0010938]
	Learning Rate: 0.00109379
	LOSS [training: 0.09468943498675193 | validation: 0.13444946274995082]
	TIME [epoch: 10.3 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07958648655153319		[learning rate: 0.0010904]
	Learning Rate: 0.00109044
	LOSS [training: 0.07958648655153319 | validation: 0.1194455904357739]
	TIME [epoch: 10.3 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0753119953856213		[learning rate: 0.0010871]
	Learning Rate: 0.00108709
	LOSS [training: 0.0753119953856213 | validation: 0.16329483452174465]
	TIME [epoch: 10.3 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12126752605605082		[learning rate: 0.0010838]
	Learning Rate: 0.00108376
	LOSS [training: 0.12126752605605082 | validation: 0.1787764798879435]
	TIME [epoch: 10.3 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09485857603730416		[learning rate: 0.0010804]
	Learning Rate: 0.00108044
	LOSS [training: 0.09485857603730416 | validation: 0.1483052754250501]
	TIME [epoch: 10.3 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06378744059666311		[learning rate: 0.0010771]
	Learning Rate: 0.00107713
	LOSS [training: 0.06378744059666311 | validation: 0.11844163118056932]
	TIME [epoch: 10.3 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05870979721185039		[learning rate: 0.0010738]
	Learning Rate: 0.00107382
	LOSS [training: 0.05870979721185039 | validation: 0.10190263199688365]
	TIME [epoch: 10.3 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06173801437903624		[learning rate: 0.0010705]
	Learning Rate: 0.00107053
	LOSS [training: 0.06173801437903624 | validation: 0.14328043103321933]
	TIME [epoch: 10.3 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07807372267942062		[learning rate: 0.0010673]
	Learning Rate: 0.00106725
	LOSS [training: 0.07807372267942062 | validation: 0.10773723100284816]
	TIME [epoch: 10.3 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04152017781832273		[learning rate: 0.001064]
	Learning Rate: 0.00106398
	LOSS [training: 0.04152017781832273 | validation: 0.08841223572887164]
	TIME [epoch: 10.2 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04682129359978525		[learning rate: 0.0010607]
	Learning Rate: 0.00106072
	LOSS [training: 0.04682129359978525 | validation: 0.1208754067104928]
	TIME [epoch: 10.3 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06992925930395492		[learning rate: 0.0010575]
	Learning Rate: 0.00105747
	LOSS [training: 0.06992925930395492 | validation: 0.10630971436444388]
	TIME [epoch: 10.3 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046932163161395556		[learning rate: 0.0010542]
	Learning Rate: 0.00105422
	LOSS [training: 0.046932163161395556 | validation: 0.08649878842518875]
	TIME [epoch: 10.3 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050929390928439386		[learning rate: 0.001051]
	Learning Rate: 0.00105099
	LOSS [training: 0.050929390928439386 | validation: 0.11805963818592058]
	TIME [epoch: 10.2 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06878731791117067		[learning rate: 0.0010478]
	Learning Rate: 0.00104777
	LOSS [training: 0.06878731791117067 | validation: 0.1104739484951742]
	TIME [epoch: 10.2 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04509623993027804		[learning rate: 0.0010446]
	Learning Rate: 0.00104456
	LOSS [training: 0.04509623993027804 | validation: 0.1043312902054803]
	TIME [epoch: 10.2 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05041049965105941		[learning rate: 0.0010414]
	Learning Rate: 0.00104136
	LOSS [training: 0.05041049965105941 | validation: 0.11539116948747875]
	TIME [epoch: 10.3 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059442427395378236		[learning rate: 0.0010382]
	Learning Rate: 0.00103817
	LOSS [training: 0.059442427395378236 | validation: 0.12132763946983248]
	TIME [epoch: 10.3 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07606383929584395		[learning rate: 0.001035]
	Learning Rate: 0.00103498
	LOSS [training: 0.07606383929584395 | validation: 0.1361392199355224]
	TIME [epoch: 10.2 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05411586279738476		[learning rate: 0.0010318]
	Learning Rate: 0.00103181
	LOSS [training: 0.05411586279738476 | validation: 0.10591906026573994]
	TIME [epoch: 10.2 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04682957118706209		[learning rate: 0.0010286]
	Learning Rate: 0.00102865
	LOSS [training: 0.04682957118706209 | validation: 0.09272320715841485]
	TIME [epoch: 10.3 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0606381142137999		[learning rate: 0.0010255]
	Learning Rate: 0.00102549
	LOSS [training: 0.0606381142137999 | validation: 0.11620997029417084]
	TIME [epoch: 10.3 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062025862772551496		[learning rate: 0.0010224]
	Learning Rate: 0.00102235
	LOSS [training: 0.062025862772551496 | validation: 0.09985668219635459]
	TIME [epoch: 10.3 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0746095659989226		[learning rate: 0.0010192]
	Learning Rate: 0.00101922
	LOSS [training: 0.0746095659989226 | validation: 0.1442171490181059]
	TIME [epoch: 10.3 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08023186049381777		[learning rate: 0.0010161]
	Learning Rate: 0.00101609
	LOSS [training: 0.08023186049381777 | validation: 0.1138859246512801]
	TIME [epoch: 10.3 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07830152536844		[learning rate: 0.001013]
	Learning Rate: 0.00101298
	LOSS [training: 0.07830152536844 | validation: 0.10745320912149431]
	TIME [epoch: 10.3 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06742020560281195		[learning rate: 0.0010099]
	Learning Rate: 0.00100987
	LOSS [training: 0.06742020560281195 | validation: 0.13677804070941982]
	TIME [epoch: 10.3 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07150754368486927		[learning rate: 0.0010068]
	Learning Rate: 0.00100678
	LOSS [training: 0.07150754368486927 | validation: 0.10992239201573366]
	TIME [epoch: 10.3 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04453656056003795		[learning rate: 0.0010037]
	Learning Rate: 0.00100369
	LOSS [training: 0.04453656056003795 | validation: 0.12350408206760331]
	TIME [epoch: 10.3 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04727550947721713		[learning rate: 0.0010006]
	Learning Rate: 0.00100061
	LOSS [training: 0.04727550947721713 | validation: 0.10282334241977709]
	TIME [epoch: 10.3 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051405780932287114		[learning rate: 0.00099755]
	Learning Rate: 0.000997547
	LOSS [training: 0.051405780932287114 | validation: 0.11452352047154825]
	TIME [epoch: 10.3 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048839378406954		[learning rate: 0.00099449]
	Learning Rate: 0.000994489
	LOSS [training: 0.048839378406954 | validation: 0.09350418463969655]
	TIME [epoch: 10.3 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04815840040268956		[learning rate: 0.00099144]
	Learning Rate: 0.00099144
	LOSS [training: 0.04815840040268956 | validation: 0.0793962378668954]
	TIME [epoch: 10.3 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04732308742533562		[learning rate: 0.0009884]
	Learning Rate: 0.000988401
	LOSS [training: 0.04732308742533562 | validation: 0.09160306617238853]
	TIME [epoch: 10.3 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05629813651735015		[learning rate: 0.00098537]
	Learning Rate: 0.000985371
	LOSS [training: 0.05629813651735015 | validation: 0.13156387572640857]
	TIME [epoch: 10.3 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056066227692241934		[learning rate: 0.00098235]
	Learning Rate: 0.000982351
	LOSS [training: 0.056066227692241934 | validation: 0.12060171323964067]
	TIME [epoch: 10.3 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0635249411522264		[learning rate: 0.00097934]
	Learning Rate: 0.000979339
	LOSS [training: 0.0635249411522264 | validation: 0.1174598487989821]
	TIME [epoch: 10.3 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061417817834451535		[learning rate: 0.00097634]
	Learning Rate: 0.000976337
	LOSS [training: 0.061417817834451535 | validation: 0.11705389979321126]
	TIME [epoch: 10.3 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08271066851058774		[learning rate: 0.00097334]
	Learning Rate: 0.000973345
	LOSS [training: 0.08271066851058774 | validation: 0.11918230353284143]
	TIME [epoch: 10.3 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09385156056330238		[learning rate: 0.00097036]
	Learning Rate: 0.000970361
	LOSS [training: 0.09385156056330238 | validation: 0.14503762197660647]
	TIME [epoch: 10.3 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08751548051201827		[learning rate: 0.00096739]
	Learning Rate: 0.000967386
	LOSS [training: 0.08751548051201827 | validation: 0.1126384370381972]
	TIME [epoch: 10.3 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07570509129360817		[learning rate: 0.00096442]
	Learning Rate: 0.000964421
	LOSS [training: 0.07570509129360817 | validation: 0.09176806264748709]
	TIME [epoch: 10.3 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07197613103379777		[learning rate: 0.00096146]
	Learning Rate: 0.000961464
	LOSS [training: 0.07197613103379777 | validation: 0.101810977426589]
	TIME [epoch: 10.2 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05741950263541688		[learning rate: 0.00095852]
	Learning Rate: 0.000958517
	LOSS [training: 0.05741950263541688 | validation: 0.11728521584082985]
	TIME [epoch: 10.3 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07700536967714147		[learning rate: 0.00095558]
	Learning Rate: 0.000955579
	LOSS [training: 0.07700536967714147 | validation: 0.10984710107838583]
	TIME [epoch: 10.3 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07644515422296812		[learning rate: 0.00095265]
	Learning Rate: 0.00095265
	LOSS [training: 0.07644515422296812 | validation: 0.13770490647198616]
	TIME [epoch: 10.3 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07338882326956479		[learning rate: 0.00094973]
	Learning Rate: 0.00094973
	LOSS [training: 0.07338882326956479 | validation: 0.10215965086810343]
	TIME [epoch: 10.3 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07714794465767633		[learning rate: 0.00094682]
	Learning Rate: 0.000946818
	LOSS [training: 0.07714794465767633 | validation: 0.17627679341390312]
	TIME [epoch: 10.3 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12292947865185692		[learning rate: 0.00094392]
	Learning Rate: 0.000943916
	LOSS [training: 0.12292947865185692 | validation: 0.1766612532289806]
	TIME [epoch: 10.3 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09782063749525045		[learning rate: 0.00094102]
	Learning Rate: 0.000941023
	LOSS [training: 0.09782063749525045 | validation: 0.14120747787309415]
	TIME [epoch: 10.3 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09059965780125633		[learning rate: 0.00093814]
	Learning Rate: 0.000938138
	LOSS [training: 0.09059965780125633 | validation: 0.1492119334849664]
	TIME [epoch: 10.3 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07452367787450709		[learning rate: 0.00093526]
	Learning Rate: 0.000935262
	LOSS [training: 0.07452367787450709 | validation: 0.11734073946771346]
	TIME [epoch: 10.3 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08027879803102336		[learning rate: 0.0009324]
	Learning Rate: 0.000932395
	LOSS [training: 0.08027879803102336 | validation: 0.1444698236421676]
	TIME [epoch: 10.3 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08022631718051912		[learning rate: 0.00092954]
	Learning Rate: 0.000929537
	LOSS [training: 0.08022631718051912 | validation: 0.10066582763293766]
	TIME [epoch: 10.3 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06744762447325861		[learning rate: 0.00092669]
	Learning Rate: 0.000926688
	LOSS [training: 0.06744762447325861 | validation: 0.1380721799435295]
	TIME [epoch: 10.3 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06937433197984988		[learning rate: 0.00092385]
	Learning Rate: 0.000923847
	LOSS [training: 0.06937433197984988 | validation: 0.1090536730753914]
	TIME [epoch: 10.3 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08561975122706614		[learning rate: 0.00092101]
	Learning Rate: 0.000921015
	LOSS [training: 0.08561975122706614 | validation: 0.13074536450021346]
	TIME [epoch: 10.3 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07114021919155385		[learning rate: 0.00091819]
	Learning Rate: 0.000918192
	LOSS [training: 0.07114021919155385 | validation: 0.105389851574012]
	TIME [epoch: 10.3 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08568785402491938		[learning rate: 0.00091538]
	Learning Rate: 0.000915377
	LOSS [training: 0.08568785402491938 | validation: 0.12810142838725322]
	TIME [epoch: 10.3 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07426630158475583		[learning rate: 0.00091257]
	Learning Rate: 0.000912571
	LOSS [training: 0.07426630158475583 | validation: 0.11424303767153088]
	TIME [epoch: 10.3 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06539053557768779		[learning rate: 0.00090977]
	Learning Rate: 0.000909774
	LOSS [training: 0.06539053557768779 | validation: 0.11424525934621958]
	TIME [epoch: 10.3 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0538070228397037		[learning rate: 0.00090698]
	Learning Rate: 0.000906985
	LOSS [training: 0.0538070228397037 | validation: 0.10496851985630637]
	TIME [epoch: 10.3 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0500846112301776		[learning rate: 0.0009042]
	Learning Rate: 0.000904204
	LOSS [training: 0.0500846112301776 | validation: 0.11560291308288675]
	TIME [epoch: 10.3 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04729855344811493		[learning rate: 0.00090143]
	Learning Rate: 0.000901433
	LOSS [training: 0.04729855344811493 | validation: 0.10521732902963404]
	TIME [epoch: 10.3 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050698333263957694		[learning rate: 0.00089867]
	Learning Rate: 0.000898669
	LOSS [training: 0.050698333263957694 | validation: 0.10487947784041922]
	TIME [epoch: 10.3 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05660967210843484		[learning rate: 0.00089591]
	Learning Rate: 0.000895915
	LOSS [training: 0.05660967210843484 | validation: 0.10403982189663938]
	TIME [epoch: 10.3 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05432618780880634		[learning rate: 0.00089317]
	Learning Rate: 0.000893168
	LOSS [training: 0.05432618780880634 | validation: 0.08507289894865426]
	TIME [epoch: 10.3 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048034741757751666		[learning rate: 0.00089043]
	Learning Rate: 0.00089043
	LOSS [training: 0.048034741757751666 | validation: 0.08309615623116073]
	TIME [epoch: 10.3 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050228549244665556		[learning rate: 0.0008877]
	Learning Rate: 0.000887701
	LOSS [training: 0.050228549244665556 | validation: 0.11525447865819737]
	TIME [epoch: 10.3 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06814978753257901		[learning rate: 0.00088498]
	Learning Rate: 0.00088498
	LOSS [training: 0.06814978753257901 | validation: 0.10845648932481451]
	TIME [epoch: 10.3 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06983258091919128		[learning rate: 0.00088227]
	Learning Rate: 0.000882267
	LOSS [training: 0.06983258091919128 | validation: 0.14236892865498393]
	TIME [epoch: 10.3 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07552594013610013		[learning rate: 0.00087956]
	Learning Rate: 0.000879562
	LOSS [training: 0.07552594013610013 | validation: 0.1320948497788078]
	TIME [epoch: 10.3 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07047472885286467		[learning rate: 0.00087687]
	Learning Rate: 0.000876866
	LOSS [training: 0.07047472885286467 | validation: 0.1350759425911331]
	TIME [epoch: 10.2 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07649236700887022		[learning rate: 0.00087418]
	Learning Rate: 0.000874178
	LOSS [training: 0.07649236700887022 | validation: 0.10119085233088633]
	TIME [epoch: 10.3 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07400296068446255		[learning rate: 0.0008715]
	Learning Rate: 0.000871498
	LOSS [training: 0.07400296068446255 | validation: 0.12360815185242258]
	TIME [epoch: 10.2 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07894195931545729		[learning rate: 0.00086883]
	Learning Rate: 0.000868827
	LOSS [training: 0.07894195931545729 | validation: 0.1351307970208548]
	TIME [epoch: 10.3 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07532014234404301		[learning rate: 0.00086616]
	Learning Rate: 0.000866164
	LOSS [training: 0.07532014234404301 | validation: 0.09951218976439967]
	TIME [epoch: 10.3 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06791777296633981		[learning rate: 0.00086351]
	Learning Rate: 0.000863509
	LOSS [training: 0.06791777296633981 | validation: 0.1362684928252999]
	TIME [epoch: 10.3 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06565821921165846		[learning rate: 0.00086086]
	Learning Rate: 0.000860861
	LOSS [training: 0.06565821921165846 | validation: 0.1452081919675214]
	TIME [epoch: 10.3 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06601109144383996		[learning rate: 0.00085822]
	Learning Rate: 0.000858223
	LOSS [training: 0.06601109144383996 | validation: 0.10671247752790983]
	TIME [epoch: 10.3 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06450159280157106		[learning rate: 0.00085559]
	Learning Rate: 0.000855592
	LOSS [training: 0.06450159280157106 | validation: 0.10792595558091737]
	TIME [epoch: 10.3 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0688015466381599		[learning rate: 0.00085297]
	Learning Rate: 0.000852969
	LOSS [training: 0.0688015466381599 | validation: 0.1368721876646557]
	TIME [epoch: 10.3 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07130831103640452		[learning rate: 0.00085035]
	Learning Rate: 0.000850354
	LOSS [training: 0.07130831103640452 | validation: 0.10811393123057679]
	TIME [epoch: 10.3 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07628855685343597		[learning rate: 0.00084775]
	Learning Rate: 0.000847748
	LOSS [training: 0.07628855685343597 | validation: 0.10755677361245124]
	TIME [epoch: 10.3 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06706434567344009		[learning rate: 0.00084515]
	Learning Rate: 0.000845149
	LOSS [training: 0.06706434567344009 | validation: 0.1297795727100581]
	TIME [epoch: 10.3 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07481162083370671		[learning rate: 0.00084256]
	Learning Rate: 0.000842558
	LOSS [training: 0.07481162083370671 | validation: 0.15814477678304825]
	TIME [epoch: 10.3 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08383445014443337		[learning rate: 0.00083998]
	Learning Rate: 0.000839976
	LOSS [training: 0.08383445014443337 | validation: 0.14036579199429133]
	TIME [epoch: 10.3 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06295851738380959		[learning rate: 0.0008374]
	Learning Rate: 0.000837401
	LOSS [training: 0.06295851738380959 | validation: 0.08287667832677281]
	TIME [epoch: 10.3 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057879937438566106		[learning rate: 0.00083483]
	Learning Rate: 0.000834834
	LOSS [training: 0.057879937438566106 | validation: 0.08225940107348162]
	TIME [epoch: 10.3 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07022706159398527		[learning rate: 0.00083227]
	Learning Rate: 0.000832274
	LOSS [training: 0.07022706159398527 | validation: 0.13409228998734118]
	TIME [epoch: 10.3 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059200614009628824		[learning rate: 0.00082972]
	Learning Rate: 0.000829723
	LOSS [training: 0.059200614009628824 | validation: 0.10359943979948388]
	TIME [epoch: 10.3 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05857104846745768		[learning rate: 0.00082718]
	Learning Rate: 0.00082718
	LOSS [training: 0.05857104846745768 | validation: 0.12335339458494538]
	TIME [epoch: 10.3 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05095633526470798		[learning rate: 0.00082464]
	Learning Rate: 0.000824644
	LOSS [training: 0.05095633526470798 | validation: 0.1304038235372698]
	TIME [epoch: 10.3 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0662487655597568		[learning rate: 0.00082212]
	Learning Rate: 0.000822116
	LOSS [training: 0.0662487655597568 | validation: 0.13245131100281904]
	TIME [epoch: 10.3 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07251880005289468		[learning rate: 0.0008196]
	Learning Rate: 0.000819596
	LOSS [training: 0.07251880005289468 | validation: 0.1418917140837738]
	TIME [epoch: 10.3 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07627031064421337		[learning rate: 0.00081708]
	Learning Rate: 0.000817084
	LOSS [training: 0.07627031064421337 | validation: 0.13308366922049378]
	TIME [epoch: 10.3 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07524615786193367		[learning rate: 0.00081458]
	Learning Rate: 0.000814579
	LOSS [training: 0.07524615786193367 | validation: 0.1528505746028557]
	TIME [epoch: 10.3 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12004161963639097		[learning rate: 0.00081208]
	Learning Rate: 0.000812082
	LOSS [training: 0.12004161963639097 | validation: 0.1978593186180473]
	TIME [epoch: 10.3 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13823771315753966		[learning rate: 0.00080959]
	Learning Rate: 0.000809593
	LOSS [training: 0.13823771315753966 | validation: 0.16422992598730982]
	TIME [epoch: 10.3 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09934399989916759		[learning rate: 0.00080711]
	Learning Rate: 0.000807111
	LOSS [training: 0.09934399989916759 | validation: 0.13963153632718237]
	TIME [epoch: 10.3 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08232259511158613		[learning rate: 0.00080464]
	Learning Rate: 0.000804637
	LOSS [training: 0.08232259511158613 | validation: 0.16223580639691734]
	TIME [epoch: 10.3 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09454635478508153		[learning rate: 0.00080217]
	Learning Rate: 0.00080217
	LOSS [training: 0.09454635478508153 | validation: 0.17504729908835004]
	TIME [epoch: 10.3 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12354345623229801		[learning rate: 0.00079971]
	Learning Rate: 0.000799712
	LOSS [training: 0.12354345623229801 | validation: 0.22324001406099364]
	TIME [epoch: 10.3 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15299027405056462		[learning rate: 0.00079726]
	Learning Rate: 0.00079726
	LOSS [training: 0.15299027405056462 | validation: 0.21770956732698638]
	TIME [epoch: 10.3 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13051346234054342		[learning rate: 0.00079482]
	Learning Rate: 0.000794816
	LOSS [training: 0.13051346234054342 | validation: 0.17864097595450823]
	TIME [epoch: 10.3 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11160370778041546		[learning rate: 0.00079238]
	Learning Rate: 0.00079238
	LOSS [training: 0.11160370778041546 | validation: 0.18494339133453105]
	TIME [epoch: 10.3 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11597547470453282		[learning rate: 0.00078995]
	Learning Rate: 0.000789951
	LOSS [training: 0.11597547470453282 | validation: 0.18067125168393502]
	TIME [epoch: 10.3 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11482054331071065		[learning rate: 0.00078753]
	Learning Rate: 0.000787529
	LOSS [training: 0.11482054331071065 | validation: 0.165027362122311]
	TIME [epoch: 10.3 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11195534255787573		[learning rate: 0.00078512]
	Learning Rate: 0.000785115
	LOSS [training: 0.11195534255787573 | validation: 0.17746884867618748]
	TIME [epoch: 10.3 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11040460677237966		[learning rate: 0.00078271]
	Learning Rate: 0.000782708
	LOSS [training: 0.11040460677237966 | validation: 0.1402487629472888]
	TIME [epoch: 10.3 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10625940304008422		[learning rate: 0.00078031]
	Learning Rate: 0.000780309
	LOSS [training: 0.10625940304008422 | validation: 0.14303118597672226]
	TIME [epoch: 10.3 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09569760801481228		[learning rate: 0.00077792]
	Learning Rate: 0.000777917
	LOSS [training: 0.09569760801481228 | validation: 0.12978505309013938]
	TIME [epoch: 10.3 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08341180284326921		[learning rate: 0.00077553]
	Learning Rate: 0.000775533
	LOSS [training: 0.08341180284326921 | validation: 0.17548363162667993]
	TIME [epoch: 10.3 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09758000703652754		[learning rate: 0.00077316]
	Learning Rate: 0.000773155
	LOSS [training: 0.09758000703652754 | validation: 0.15817684870165238]
	TIME [epoch: 10.3 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08075693203981223		[learning rate: 0.00077079]
	Learning Rate: 0.000770785
	LOSS [training: 0.08075693203981223 | validation: 0.12543677600602332]
	TIME [epoch: 10.3 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08981459069754791		[learning rate: 0.00076842]
	Learning Rate: 0.000768422
	LOSS [training: 0.08981459069754791 | validation: 0.13872370452429011]
	TIME [epoch: 10.3 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08656570061454683		[learning rate: 0.00076607]
	Learning Rate: 0.000766067
	LOSS [training: 0.08656570061454683 | validation: 0.14812787888798715]
	TIME [epoch: 10.3 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11495621522566306		[learning rate: 0.00076372]
	Learning Rate: 0.000763719
	LOSS [training: 0.11495621522566306 | validation: 0.15259800036752574]
	TIME [epoch: 10.3 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0881527390208656		[learning rate: 0.00076138]
	Learning Rate: 0.000761377
	LOSS [training: 0.0881527390208656 | validation: 0.14896224267399333]
	TIME [epoch: 10.3 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08272385558754741		[learning rate: 0.00075904]
	Learning Rate: 0.000759043
	LOSS [training: 0.08272385558754741 | validation: 0.10592307353077636]
	TIME [epoch: 10.3 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08042361956977244		[learning rate: 0.00075672]
	Learning Rate: 0.000756717
	LOSS [training: 0.08042361956977244 | validation: 0.11605312380883483]
	TIME [epoch: 10.3 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08018324008353106		[learning rate: 0.0007544]
	Learning Rate: 0.000754397
	LOSS [training: 0.08018324008353106 | validation: 0.153689622553782]
	TIME [epoch: 10.3 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07820375296188777		[learning rate: 0.00075208]
	Learning Rate: 0.000752084
	LOSS [training: 0.07820375296188777 | validation: 0.15240958122521467]
	TIME [epoch: 10.3 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09205986969431242		[learning rate: 0.00074978]
	Learning Rate: 0.000749779
	LOSS [training: 0.09205986969431242 | validation: 0.16613217791871218]
	TIME [epoch: 10.2 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08405556478954374		[learning rate: 0.00074748]
	Learning Rate: 0.000747481
	LOSS [training: 0.08405556478954374 | validation: 0.15001012327434204]
	TIME [epoch: 10.3 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09956834237977617		[learning rate: 0.00074519]
	Learning Rate: 0.000745189
	LOSS [training: 0.09956834237977617 | validation: 0.1656658454170104]
	TIME [epoch: 10.3 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08773693333553022		[learning rate: 0.0007429]
	Learning Rate: 0.000742905
	LOSS [training: 0.08773693333553022 | validation: 0.13067186244349568]
	TIME [epoch: 10.3 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06656333012092938		[learning rate: 0.00074063]
	Learning Rate: 0.000740628
	LOSS [training: 0.06656333012092938 | validation: 0.12440904097382109]
	TIME [epoch: 10.3 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06952741922347236		[learning rate: 0.00073836]
	Learning Rate: 0.000738357
	LOSS [training: 0.06952741922347236 | validation: 0.13534099616270429]
	TIME [epoch: 10.3 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07079123662672664		[learning rate: 0.00073609]
	Learning Rate: 0.000736094
	LOSS [training: 0.07079123662672664 | validation: 0.12048449801318743]
	TIME [epoch: 10.3 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07659198491130151		[learning rate: 0.00073384]
	Learning Rate: 0.000733838
	LOSS [training: 0.07659198491130151 | validation: 0.14651701873055772]
	TIME [epoch: 10.3 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08566705004904926		[learning rate: 0.00073159]
	Learning Rate: 0.000731588
	LOSS [training: 0.08566705004904926 | validation: 0.1138696819040984]
	TIME [epoch: 10.3 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07288024353903429		[learning rate: 0.00072935]
	Learning Rate: 0.000729345
	LOSS [training: 0.07288024353903429 | validation: 0.12595153956539498]
	TIME [epoch: 10.3 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08962212703641668		[learning rate: 0.00072711]
	Learning Rate: 0.00072711
	LOSS [training: 0.08962212703641668 | validation: 0.1294836109780857]
	TIME [epoch: 10.3 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07429361020002567		[learning rate: 0.00072488]
	Learning Rate: 0.000724881
	LOSS [training: 0.07429361020002567 | validation: 0.15468446489990165]
	TIME [epoch: 10.3 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08464030344656019		[learning rate: 0.00072266]
	Learning Rate: 0.000722659
	LOSS [training: 0.08464030344656019 | validation: 0.16508363169302817]
	TIME [epoch: 10.3 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08446160967723161		[learning rate: 0.00072044]
	Learning Rate: 0.000720444
	LOSS [training: 0.08446160967723161 | validation: 0.14324487078775228]
	TIME [epoch: 10.2 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07688884602235183		[learning rate: 0.00071824]
	Learning Rate: 0.000718235
	LOSS [training: 0.07688884602235183 | validation: 0.12109691043202674]
	TIME [epoch: 10.3 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06993328698398701		[learning rate: 0.00071603]
	Learning Rate: 0.000716033
	LOSS [training: 0.06993328698398701 | validation: 0.10029156524416223]
	TIME [epoch: 10.3 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062295735699000765		[learning rate: 0.00071384]
	Learning Rate: 0.000713839
	LOSS [training: 0.062295735699000765 | validation: 0.13021516415560339]
	TIME [epoch: 10.3 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07309123520954745		[learning rate: 0.00071165]
	Learning Rate: 0.00071165
	LOSS [training: 0.07309123520954745 | validation: 0.17300836822618146]
	TIME [epoch: 10.3 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08750423771886448		[learning rate: 0.00070947]
	Learning Rate: 0.000709469
	LOSS [training: 0.08750423771886448 | validation: 0.15803089531923678]
	TIME [epoch: 10.3 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07779941667653945		[learning rate: 0.00070729]
	Learning Rate: 0.000707294
	LOSS [training: 0.07779941667653945 | validation: 0.1558610908736808]
	TIME [epoch: 10.3 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08705702007658318		[learning rate: 0.00070513]
	Learning Rate: 0.000705126
	LOSS [training: 0.08705702007658318 | validation: 0.149795193873009]
	TIME [epoch: 10.2 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1003227962235165		[learning rate: 0.00070296]
	Learning Rate: 0.000702964
	LOSS [training: 0.1003227962235165 | validation: 0.1621440487181196]
	TIME [epoch: 10.3 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09229385960999963		[learning rate: 0.00070081]
	Learning Rate: 0.00070081
	LOSS [training: 0.09229385960999963 | validation: 0.1422042580992041]
	TIME [epoch: 10.3 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07737068623345322		[learning rate: 0.00069866]
	Learning Rate: 0.000698661
	LOSS [training: 0.07737068623345322 | validation: 0.13841473877605698]
	TIME [epoch: 10.3 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06331218989701269		[learning rate: 0.00069652]
	Learning Rate: 0.000696519
	LOSS [training: 0.06331218989701269 | validation: 0.13729751613667426]
	TIME [epoch: 10.3 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07376548288338147		[learning rate: 0.00069438]
	Learning Rate: 0.000694384
	LOSS [training: 0.07376548288338147 | validation: 0.15240730687100315]
	TIME [epoch: 10.3 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08026256533176487		[learning rate: 0.00069226]
	Learning Rate: 0.000692256
	LOSS [training: 0.08026256533176487 | validation: 0.1574061426975217]
	TIME [epoch: 10.3 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09123656405271992		[learning rate: 0.00069013]
	Learning Rate: 0.000690134
	LOSS [training: 0.09123656405271992 | validation: 0.14375124380915696]
	TIME [epoch: 10.3 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08404454508858998		[learning rate: 0.00068802]
	Learning Rate: 0.000688018
	LOSS [training: 0.08404454508858998 | validation: 0.11615983023251239]
	TIME [epoch: 10.3 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06917927309875607		[learning rate: 0.00068591]
	Learning Rate: 0.000685909
	LOSS [training: 0.06917927309875607 | validation: 0.11492230789194162]
	TIME [epoch: 10.3 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05993802329887664		[learning rate: 0.00068381]
	Learning Rate: 0.000683807
	LOSS [training: 0.05993802329887664 | validation: 0.11523028799593728]
	TIME [epoch: 10.3 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05101398046849176		[learning rate: 0.00068171]
	Learning Rate: 0.000681711
	LOSS [training: 0.05101398046849176 | validation: 0.10849328176689359]
	TIME [epoch: 10.3 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06060345913755083		[learning rate: 0.00067962]
	Learning Rate: 0.000679621
	LOSS [training: 0.06060345913755083 | validation: 0.11179690786709866]
	TIME [epoch: 10.3 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06087688593485534		[learning rate: 0.00067754]
	Learning Rate: 0.000677538
	LOSS [training: 0.06087688593485534 | validation: 0.12492738177183763]
	TIME [epoch: 10.3 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0574668708690065		[learning rate: 0.00067546]
	Learning Rate: 0.000675461
	LOSS [training: 0.0574668708690065 | validation: 0.10799066365465898]
	TIME [epoch: 10.3 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05684845110630852		[learning rate: 0.00067339]
	Learning Rate: 0.00067339
	LOSS [training: 0.05684845110630852 | validation: 0.1365116163545618]
	TIME [epoch: 10.3 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0650476355054875		[learning rate: 0.00067133]
	Learning Rate: 0.000671326
	LOSS [training: 0.0650476355054875 | validation: 0.15464243659897833]
	TIME [epoch: 10.3 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07060849992586936		[learning rate: 0.00066927]
	Learning Rate: 0.000669268
	LOSS [training: 0.07060849992586936 | validation: 0.1296067007852141]
	TIME [epoch: 10.3 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06864194004612427		[learning rate: 0.00066722]
	Learning Rate: 0.000667216
	LOSS [training: 0.06864194004612427 | validation: 0.11823660462367278]
	TIME [epoch: 10.3 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0614080142799441		[learning rate: 0.00066517]
	Learning Rate: 0.000665171
	LOSS [training: 0.0614080142799441 | validation: 0.13818602098194457]
	TIME [epoch: 10.3 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0852161690530647		[learning rate: 0.00066313]
	Learning Rate: 0.000663132
	LOSS [training: 0.0852161690530647 | validation: 0.12911737950189228]
	TIME [epoch: 10.3 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07279032818498944		[learning rate: 0.0006611]
	Learning Rate: 0.000661099
	LOSS [training: 0.07279032818498944 | validation: 0.1326378137693639]
	TIME [epoch: 10.3 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07641133141988955		[learning rate: 0.00065907]
	Learning Rate: 0.000659073
	LOSS [training: 0.07641133141988955 | validation: 0.15455466149630426]
	TIME [epoch: 10.3 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07500347371390599		[learning rate: 0.00065705]
	Learning Rate: 0.000657052
	LOSS [training: 0.07500347371390599 | validation: 0.11568840597661316]
	TIME [epoch: 10.3 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0654335803978297		[learning rate: 0.00065504]
	Learning Rate: 0.000655038
	LOSS [training: 0.0654335803978297 | validation: 0.13996427635173178]
	TIME [epoch: 10.3 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05851813889220207		[learning rate: 0.00065303]
	Learning Rate: 0.00065303
	LOSS [training: 0.05851813889220207 | validation: 0.13637994200683326]
	TIME [epoch: 10.3 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06873254765866345		[learning rate: 0.00065103]
	Learning Rate: 0.000651028
	LOSS [training: 0.06873254765866345 | validation: 0.115315958582134]
	TIME [epoch: 10.3 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05402499868330139		[learning rate: 0.00064903]
	Learning Rate: 0.000649033
	LOSS [training: 0.05402499868330139 | validation: 0.13410098019514183]
	TIME [epoch: 10.3 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05818393796423625		[learning rate: 0.00064704]
	Learning Rate: 0.000647043
	LOSS [training: 0.05818393796423625 | validation: 0.12953012614748213]
	TIME [epoch: 10.3 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06305807404126777		[learning rate: 0.00064506]
	Learning Rate: 0.00064506
	LOSS [training: 0.06305807404126777 | validation: 0.12549471701742598]
	TIME [epoch: 10.3 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061433308691507524		[learning rate: 0.00064308]
	Learning Rate: 0.000643082
	LOSS [training: 0.061433308691507524 | validation: 0.11867611132787552]
	TIME [epoch: 10.3 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06253009820803017		[learning rate: 0.00064111]
	Learning Rate: 0.000641111
	LOSS [training: 0.06253009820803017 | validation: 0.0995971874491066]
	TIME [epoch: 10.3 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07233399523447577		[learning rate: 0.00063915]
	Learning Rate: 0.000639146
	LOSS [training: 0.07233399523447577 | validation: 0.14801380759319646]
	TIME [epoch: 10.3 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07977281544848351		[learning rate: 0.00063719]
	Learning Rate: 0.000637187
	LOSS [training: 0.07977281544848351 | validation: 0.1609663416476814]
	TIME [epoch: 10.3 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054219853985927956		[learning rate: 0.00063523]
	Learning Rate: 0.000635233
	LOSS [training: 0.054219853985927956 | validation: 0.11171616333762462]
	TIME [epoch: 10.3 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05441266067489632		[learning rate: 0.00063329]
	Learning Rate: 0.000633286
	LOSS [training: 0.05441266067489632 | validation: 0.10203137965354692]
	TIME [epoch: 10.3 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04463539794393822		[learning rate: 0.00063134]
	Learning Rate: 0.000631345
	LOSS [training: 0.04463539794393822 | validation: 0.08535448296937456]
	TIME [epoch: 10.3 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049346968852967334		[learning rate: 0.00062941]
	Learning Rate: 0.000629409
	LOSS [training: 0.049346968852967334 | validation: 0.11582518918266149]
	TIME [epoch: 10.3 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049402434083636024		[learning rate: 0.00062748]
	Learning Rate: 0.00062748
	LOSS [training: 0.049402434083636024 | validation: 0.1194834347176916]
	TIME [epoch: 10.3 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04304853877884485		[learning rate: 0.00062556]
	Learning Rate: 0.000625557
	LOSS [training: 0.04304853877884485 | validation: 0.12023691034132326]
	TIME [epoch: 10.3 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05639245074484397		[learning rate: 0.00062364]
	Learning Rate: 0.000623639
	LOSS [training: 0.05639245074484397 | validation: 0.12946493615982443]
	TIME [epoch: 10.3 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05810783555368974		[learning rate: 0.00062173]
	Learning Rate: 0.000621727
	LOSS [training: 0.05810783555368974 | validation: 0.1285821543199755]
	TIME [epoch: 10.3 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07458182042646909		[learning rate: 0.00061982]
	Learning Rate: 0.000619821
	LOSS [training: 0.07458182042646909 | validation: 0.13007317937242938]
	TIME [epoch: 10.3 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061752853886670414		[learning rate: 0.00061792]
	Learning Rate: 0.000617922
	LOSS [training: 0.061752853886670414 | validation: 0.15204006826766114]
	TIME [epoch: 10.3 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06671448213102996		[learning rate: 0.00061603]
	Learning Rate: 0.000616027
	LOSS [training: 0.06671448213102996 | validation: 0.09895731653203925]
	TIME [epoch: 10.3 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06831592421941396		[learning rate: 0.00061414]
	Learning Rate: 0.000614139
	LOSS [training: 0.06831592421941396 | validation: 0.11879874002355958]
	TIME [epoch: 10.3 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08558928466319647		[learning rate: 0.00061226]
	Learning Rate: 0.000612256
	LOSS [training: 0.08558928466319647 | validation: 0.15403380904882472]
	TIME [epoch: 10.3 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06624671524966025		[learning rate: 0.00061038]
	Learning Rate: 0.00061038
	LOSS [training: 0.06624671524966025 | validation: 0.12908776648781659]
	TIME [epoch: 10.3 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06710348092721344		[learning rate: 0.00060851]
	Learning Rate: 0.000608509
	LOSS [training: 0.06710348092721344 | validation: 0.11090075988048564]
	TIME [epoch: 10.3 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05482454660626231		[learning rate: 0.00060664]
	Learning Rate: 0.000606643
	LOSS [training: 0.05482454660626231 | validation: 0.1106914437180255]
	TIME [epoch: 10.3 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046856431272086725		[learning rate: 0.00060478]
	Learning Rate: 0.000604784
	LOSS [training: 0.046856431272086725 | validation: 0.120873659990692]
	TIME [epoch: 10.3 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04879560581238067		[learning rate: 0.00060293]
	Learning Rate: 0.00060293
	LOSS [training: 0.04879560581238067 | validation: 0.1077125200313161]
	TIME [epoch: 10.3 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054338722270433126		[learning rate: 0.00060108]
	Learning Rate: 0.000601081
	LOSS [training: 0.054338722270433126 | validation: 0.10855754161458647]
	TIME [epoch: 10.3 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05075502913985761		[learning rate: 0.00059924]
	Learning Rate: 0.000599239
	LOSS [training: 0.05075502913985761 | validation: 0.10839443061894137]
	TIME [epoch: 10.3 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07334775297631531		[learning rate: 0.0005974]
	Learning Rate: 0.000597402
	LOSS [training: 0.07334775297631531 | validation: 0.12552396795658358]
	TIME [epoch: 10.3 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07786108154516835		[learning rate: 0.00059557]
	Learning Rate: 0.000595571
	LOSS [training: 0.07786108154516835 | validation: 0.11187918788231023]
	TIME [epoch: 10.3 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06818722842620159		[learning rate: 0.00059375]
	Learning Rate: 0.000593745
	LOSS [training: 0.06818722842620159 | validation: 0.11023758378852343]
	TIME [epoch: 10.3 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06751288968157121		[learning rate: 0.00059192]
	Learning Rate: 0.000591925
	LOSS [training: 0.06751288968157121 | validation: 0.13830050865275065]
	TIME [epoch: 10.3 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0853462444328584		[learning rate: 0.00059011]
	Learning Rate: 0.00059011
	LOSS [training: 0.0853462444328584 | validation: 0.11227036635165273]
	TIME [epoch: 10.3 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06980941865127353		[learning rate: 0.0005883]
	Learning Rate: 0.000588302
	LOSS [training: 0.06980941865127353 | validation: 0.11109778913327226]
	TIME [epoch: 10.3 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07475876645745548		[learning rate: 0.0005865]
	Learning Rate: 0.000586498
	LOSS [training: 0.07475876645745548 | validation: 0.1009398411530903]
	TIME [epoch: 10.3 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0654748139579301		[learning rate: 0.0005847]
	Learning Rate: 0.0005847
	LOSS [training: 0.0654748139579301 | validation: 0.11988629504931898]
	TIME [epoch: 10.3 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05434115151861459		[learning rate: 0.00058291]
	Learning Rate: 0.000582908
	LOSS [training: 0.05434115151861459 | validation: 0.09182324331541121]
	TIME [epoch: 10.3 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06475224422878663		[learning rate: 0.00058112]
	Learning Rate: 0.000581121
	LOSS [training: 0.06475224422878663 | validation: 0.09846972157312965]
	TIME [epoch: 10.3 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06754117146398765		[learning rate: 0.00057934]
	Learning Rate: 0.00057934
	LOSS [training: 0.06754117146398765 | validation: 0.10803127658461587]
	TIME [epoch: 10.3 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06717809710705878		[learning rate: 0.00057756]
	Learning Rate: 0.000577564
	LOSS [training: 0.06717809710705878 | validation: 0.1321324505337434]
	TIME [epoch: 10.3 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07251352342192766		[learning rate: 0.00057579]
	Learning Rate: 0.000575793
	LOSS [training: 0.07251352342192766 | validation: 0.10074109234711466]
	TIME [epoch: 10.3 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07270543626489584		[learning rate: 0.00057403]
	Learning Rate: 0.000574028
	LOSS [training: 0.07270543626489584 | validation: 0.10450572013254668]
	TIME [epoch: 10.3 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0901865153570646		[learning rate: 0.00057227]
	Learning Rate: 0.000572269
	LOSS [training: 0.0901865153570646 | validation: 0.11500644938066196]
	TIME [epoch: 10.3 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08016349155880971		[learning rate: 0.00057051]
	Learning Rate: 0.000570514
	LOSS [training: 0.08016349155880971 | validation: 0.11151780279785252]
	TIME [epoch: 10.3 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08052417669965631		[learning rate: 0.00056877]
	Learning Rate: 0.000568766
	LOSS [training: 0.08052417669965631 | validation: 0.1262279090443116]
	TIME [epoch: 10.3 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07055218438633552		[learning rate: 0.00056702]
	Learning Rate: 0.000567022
	LOSS [training: 0.07055218438633552 | validation: 0.1147051154492357]
	TIME [epoch: 10.3 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06553274819971855		[learning rate: 0.00056528]
	Learning Rate: 0.000565284
	LOSS [training: 0.06553274819971855 | validation: 0.10836822899683965]
	TIME [epoch: 10.3 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06954656850115148		[learning rate: 0.00056355]
	Learning Rate: 0.000563551
	LOSS [training: 0.06954656850115148 | validation: 0.12938102112727023]
	TIME [epoch: 10.3 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07510005019983493		[learning rate: 0.00056182]
	Learning Rate: 0.000561824
	LOSS [training: 0.07510005019983493 | validation: 0.10234482046518156]
	TIME [epoch: 10.3 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06396713131869344		[learning rate: 0.0005601]
	Learning Rate: 0.000560101
	LOSS [training: 0.06396713131869344 | validation: 0.11547444164403511]
	TIME [epoch: 10.3 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0645634118662935		[learning rate: 0.00055838]
	Learning Rate: 0.000558385
	LOSS [training: 0.0645634118662935 | validation: 0.08746136013311386]
	TIME [epoch: 10.3 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05940189032600347		[learning rate: 0.00055667]
	Learning Rate: 0.000556673
	LOSS [training: 0.05940189032600347 | validation: 0.12009436973978278]
	TIME [epoch: 10.3 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06370587461547908		[learning rate: 0.00055497]
	Learning Rate: 0.000554966
	LOSS [training: 0.06370587461547908 | validation: 0.1046427495402015]
	TIME [epoch: 10.3 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06954195577165719		[learning rate: 0.00055327]
	Learning Rate: 0.000553265
	LOSS [training: 0.06954195577165719 | validation: 0.1344859066927124]
	TIME [epoch: 10.3 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07176969488333575		[learning rate: 0.00055157]
	Learning Rate: 0.000551569
	LOSS [training: 0.07176969488333575 | validation: 0.10314685618005384]
	TIME [epoch: 10.3 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06497294633376827		[learning rate: 0.00054988]
	Learning Rate: 0.000549878
	LOSS [training: 0.06497294633376827 | validation: 0.11170060450173923]
	TIME [epoch: 10.3 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047741936267893366		[learning rate: 0.00054819]
	Learning Rate: 0.000548193
	LOSS [training: 0.047741936267893366 | validation: 0.11301194387363424]
	TIME [epoch: 10.3 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054213465845739064		[learning rate: 0.00054651]
	Learning Rate: 0.000546512
	LOSS [training: 0.054213465845739064 | validation: 0.10307277166139872]
	TIME [epoch: 10.3 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05517613019767539		[learning rate: 0.00054484]
	Learning Rate: 0.000544837
	LOSS [training: 0.05517613019767539 | validation: 0.10548796713950288]
	TIME [epoch: 10.3 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05807682875106666		[learning rate: 0.00054317]
	Learning Rate: 0.000543167
	LOSS [training: 0.05807682875106666 | validation: 0.13298371293782488]
	TIME [epoch: 10.3 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06382346872665749		[learning rate: 0.0005415]
	Learning Rate: 0.000541502
	LOSS [training: 0.06382346872665749 | validation: 0.11400778117837528]
	TIME [epoch: 10.3 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055974068709155646		[learning rate: 0.00053984]
	Learning Rate: 0.000539842
	LOSS [training: 0.055974068709155646 | validation: 0.10013463816940985]
	TIME [epoch: 10.3 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051910632586775175		[learning rate: 0.00053819]
	Learning Rate: 0.000538187
	LOSS [training: 0.051910632586775175 | validation: 0.10502591602178558]
	TIME [epoch: 10.3 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054567242223461834		[learning rate: 0.00053654]
	Learning Rate: 0.000536537
	LOSS [training: 0.054567242223461834 | validation: 0.13254889543361528]
	TIME [epoch: 10.3 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061818094929290045		[learning rate: 0.00053489]
	Learning Rate: 0.000534893
	LOSS [training: 0.061818094929290045 | validation: 0.13680636774168092]
	TIME [epoch: 10.3 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05751854792332996		[learning rate: 0.00053325]
	Learning Rate: 0.000533253
	LOSS [training: 0.05751854792332996 | validation: 0.1068663147203855]
	TIME [epoch: 10.3 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04866976289838553		[learning rate: 0.00053162]
	Learning Rate: 0.000531618
	LOSS [training: 0.04866976289838553 | validation: 0.10384511638406338]
	TIME [epoch: 10.3 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055756651273687154		[learning rate: 0.00052999]
	Learning Rate: 0.000529989
	LOSS [training: 0.055756651273687154 | validation: 0.10205799540265682]
	TIME [epoch: 10.3 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0661813514390985		[learning rate: 0.00052836]
	Learning Rate: 0.000528364
	LOSS [training: 0.0661813514390985 | validation: 0.12635065591457373]
	TIME [epoch: 10.3 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06184643977200023		[learning rate: 0.00052674]
	Learning Rate: 0.000526744
	LOSS [training: 0.06184643977200023 | validation: 0.10986699325488926]
	TIME [epoch: 10.3 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051051492784628304		[learning rate: 0.00052513]
	Learning Rate: 0.00052513
	LOSS [training: 0.051051492784628304 | validation: 0.0829889355602906]
	TIME [epoch: 10.3 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0519338074666727		[learning rate: 0.00052352]
	Learning Rate: 0.00052352
	LOSS [training: 0.0519338074666727 | validation: 0.12162661561379808]
	TIME [epoch: 10.3 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050763803608997085		[learning rate: 0.00052192]
	Learning Rate: 0.000521915
	LOSS [training: 0.050763803608997085 | validation: 0.07853222160484001]
	TIME [epoch: 10.3 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049870049363153465		[learning rate: 0.00052032]
	Learning Rate: 0.000520315
	LOSS [training: 0.049870049363153465 | validation: 0.10527752357730112]
	TIME [epoch: 10.3 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05309908594909324		[learning rate: 0.00051872]
	Learning Rate: 0.00051872
	LOSS [training: 0.05309908594909324 | validation: 0.11436707112416207]
	TIME [epoch: 10.3 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05039651616659433		[learning rate: 0.00051713]
	Learning Rate: 0.00051713
	LOSS [training: 0.05039651616659433 | validation: 0.11211447577108306]
	TIME [epoch: 10.3 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05186203512977274		[learning rate: 0.00051555]
	Learning Rate: 0.000515545
	LOSS [training: 0.05186203512977274 | validation: 0.10118216445437836]
	TIME [epoch: 10.3 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05355782749774378		[learning rate: 0.00051396]
	Learning Rate: 0.000513965
	LOSS [training: 0.05355782749774378 | validation: 0.10825928632476492]
	TIME [epoch: 10.3 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05677618765805237		[learning rate: 0.00051239]
	Learning Rate: 0.000512389
	LOSS [training: 0.05677618765805237 | validation: 0.10893822843488904]
	TIME [epoch: 10.3 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05711061068285885		[learning rate: 0.00051082]
	Learning Rate: 0.000510818
	LOSS [training: 0.05711061068285885 | validation: 0.11417144491135549]
	TIME [epoch: 10.3 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06834421555799397		[learning rate: 0.00050925]
	Learning Rate: 0.000509253
	LOSS [training: 0.06834421555799397 | validation: 0.12599780073093025]
	TIME [epoch: 10.3 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06640804118627691		[learning rate: 0.00050769]
	Learning Rate: 0.000507692
	LOSS [training: 0.06640804118627691 | validation: 0.12218045772479968]
	TIME [epoch: 10.3 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08464555446951809		[learning rate: 0.00050614]
	Learning Rate: 0.000506135
	LOSS [training: 0.08464555446951809 | validation: 0.08979724694669677]
	TIME [epoch: 10.3 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06656103494197138		[learning rate: 0.00050458]
	Learning Rate: 0.000504584
	LOSS [training: 0.06656103494197138 | validation: 0.09663215855316246]
	TIME [epoch: 10.3 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06630065659193865		[learning rate: 0.00050304]
	Learning Rate: 0.000503037
	LOSS [training: 0.06630065659193865 | validation: 0.09163855159708029]
	TIME [epoch: 10.3 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05937895494373259		[learning rate: 0.00050149]
	Learning Rate: 0.000501495
	LOSS [training: 0.05937895494373259 | validation: 0.10960763208839623]
	TIME [epoch: 10.3 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047513881612462804		[learning rate: 0.00049996]
	Learning Rate: 0.000499958
	LOSS [training: 0.047513881612462804 | validation: 0.08381004783530617]
	TIME [epoch: 10.3 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05468605914979602		[learning rate: 0.00049843]
	Learning Rate: 0.000498425
	LOSS [training: 0.05468605914979602 | validation: 0.1113065697883875]
	TIME [epoch: 10.3 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058397659893481224		[learning rate: 0.0004969]
	Learning Rate: 0.000496897
	LOSS [training: 0.058397659893481224 | validation: 0.10952203793186378]
	TIME [epoch: 10.3 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054018803554230124		[learning rate: 0.00049537]
	Learning Rate: 0.000495374
	LOSS [training: 0.054018803554230124 | validation: 0.09893783296795391]
	TIME [epoch: 10.3 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06089296363027071		[learning rate: 0.00049386]
	Learning Rate: 0.000493856
	LOSS [training: 0.06089296363027071 | validation: 0.10342585183029034]
	TIME [epoch: 10.3 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059602786470881484		[learning rate: 0.00049234]
	Learning Rate: 0.000492342
	LOSS [training: 0.059602786470881484 | validation: 0.11196111948190478]
	TIME [epoch: 10.3 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05464831818045142		[learning rate: 0.00049083]
	Learning Rate: 0.000490832
	LOSS [training: 0.05464831818045142 | validation: 0.1021704710444427]
	TIME [epoch: 10.3 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05067299844177242		[learning rate: 0.00048933]
	Learning Rate: 0.000489328
	LOSS [training: 0.05067299844177242 | validation: 0.10063799943013794]
	TIME [epoch: 10.3 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06189911564189292		[learning rate: 0.00048783]
	Learning Rate: 0.000487828
	LOSS [training: 0.06189911564189292 | validation: 0.10324045529634514]
	TIME [epoch: 10.3 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05923495624623683		[learning rate: 0.00048633]
	Learning Rate: 0.000486333
	LOSS [training: 0.05923495624623683 | validation: 0.10622539472496695]
	TIME [epoch: 10.3 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05700168854470196		[learning rate: 0.00048484]
	Learning Rate: 0.000484842
	LOSS [training: 0.05700168854470196 | validation: 0.1189639761328299]
	TIME [epoch: 10.3 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05540771381735945		[learning rate: 0.00048336]
	Learning Rate: 0.000483356
	LOSS [training: 0.05540771381735945 | validation: 0.10164211997010232]
	TIME [epoch: 10.3 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059148676134065346		[learning rate: 0.00048187]
	Learning Rate: 0.000481874
	LOSS [training: 0.059148676134065346 | validation: 0.12700110306091325]
	TIME [epoch: 10.3 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06447104548558916		[learning rate: 0.0004804]
	Learning Rate: 0.000480397
	LOSS [training: 0.06447104548558916 | validation: 0.12318031692167448]
	TIME [epoch: 10.3 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0569139793237579		[learning rate: 0.00047892]
	Learning Rate: 0.000478924
	LOSS [training: 0.0569139793237579 | validation: 0.12097246964057719]
	TIME [epoch: 10.3 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06345421558228097		[learning rate: 0.00047746]
	Learning Rate: 0.000477456
	LOSS [training: 0.06345421558228097 | validation: 0.10446438308133439]
	TIME [epoch: 10.3 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05081258170519211		[learning rate: 0.00047599]
	Learning Rate: 0.000475992
	LOSS [training: 0.05081258170519211 | validation: 0.11804223296987601]
	TIME [epoch: 10.3 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0590257355343609		[learning rate: 0.00047453]
	Learning Rate: 0.000474533
	LOSS [training: 0.0590257355343609 | validation: 0.10250997487463191]
	TIME [epoch: 10.3 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06333840603989868		[learning rate: 0.00047308]
	Learning Rate: 0.000473079
	LOSS [training: 0.06333840603989868 | validation: 0.11382422928899573]
	TIME [epoch: 10.3 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05560457282144171		[learning rate: 0.00047163]
	Learning Rate: 0.000471628
	LOSS [training: 0.05560457282144171 | validation: 0.13481836387580742]
	TIME [epoch: 10.3 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07783052687396241		[learning rate: 0.00047018]
	Learning Rate: 0.000470183
	LOSS [training: 0.07783052687396241 | validation: 0.1584883071657713]
	TIME [epoch: 10.3 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09971846694455866		[learning rate: 0.00046874]
	Learning Rate: 0.000468741
	LOSS [training: 0.09971846694455866 | validation: 0.14594222275653354]
	TIME [epoch: 10.3 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08511379856324183		[learning rate: 0.0004673]
	Learning Rate: 0.000467304
	LOSS [training: 0.08511379856324183 | validation: 0.1266924473310683]
	TIME [epoch: 10.3 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06925629118385702		[learning rate: 0.00046587]
	Learning Rate: 0.000465872
	LOSS [training: 0.06925629118385702 | validation: 0.10033522640484492]
	TIME [epoch: 10.3 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06637789248638123		[learning rate: 0.00046444]
	Learning Rate: 0.000464444
	LOSS [training: 0.06637789248638123 | validation: 0.10388639694937073]
	TIME [epoch: 10.3 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05834955213955469		[learning rate: 0.00046302]
	Learning Rate: 0.00046302
	LOSS [training: 0.05834955213955469 | validation: 0.1146147808001707]
	TIME [epoch: 10.3 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04689321017090757		[learning rate: 0.0004616]
	Learning Rate: 0.000461601
	LOSS [training: 0.04689321017090757 | validation: 0.1172867966621672]
	TIME [epoch: 10.3 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04551913767538298		[learning rate: 0.00046019]
	Learning Rate: 0.000460186
	LOSS [training: 0.04551913767538298 | validation: 0.11930380486155931]
	TIME [epoch: 10.3 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06283507738776473		[learning rate: 0.00045878]
	Learning Rate: 0.000458775
	LOSS [training: 0.06283507738776473 | validation: 0.10458420550716221]
	TIME [epoch: 10.3 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05197122689699184		[learning rate: 0.00045737]
	Learning Rate: 0.000457369
	LOSS [training: 0.05197122689699184 | validation: 0.1115983032531129]
	TIME [epoch: 10.3 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04932644659772201		[learning rate: 0.00045597]
	Learning Rate: 0.000455967
	LOSS [training: 0.04932644659772201 | validation: 0.11105555715434688]
	TIME [epoch: 10.3 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05328354715640619		[learning rate: 0.00045457]
	Learning Rate: 0.000454569
	LOSS [training: 0.05328354715640619 | validation: 0.10776974178797963]
	TIME [epoch: 10.3 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05635849914744591		[learning rate: 0.00045318]
	Learning Rate: 0.000453176
	LOSS [training: 0.05635849914744591 | validation: 0.10359143603729544]
	TIME [epoch: 10.3 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06007567151255285		[learning rate: 0.00045179]
	Learning Rate: 0.000451787
	LOSS [training: 0.06007567151255285 | validation: 0.13097804903436036]
	TIME [epoch: 10.3 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06626533226093681		[learning rate: 0.0004504]
	Learning Rate: 0.000450402
	LOSS [training: 0.06626533226093681 | validation: 0.14260551438633762]
	TIME [epoch: 10.3 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05950405934736489		[learning rate: 0.00044902]
	Learning Rate: 0.000449021
	LOSS [training: 0.05950405934736489 | validation: 0.10292387488577318]
	TIME [epoch: 10.3 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0612989005717068		[learning rate: 0.00044764]
	Learning Rate: 0.000447645
	LOSS [training: 0.0612989005717068 | validation: 0.11181396602930303]
	TIME [epoch: 10.3 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05735691412195563		[learning rate: 0.00044627]
	Learning Rate: 0.000446272
	LOSS [training: 0.05735691412195563 | validation: 0.11620176859383442]
	TIME [epoch: 10.3 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05309855064010225		[learning rate: 0.0004449]
	Learning Rate: 0.000444904
	LOSS [training: 0.05309855064010225 | validation: 0.07832448335319075]
	TIME [epoch: 10.2 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05091433836874768		[learning rate: 0.00044354]
	Learning Rate: 0.000443541
	LOSS [training: 0.05091433836874768 | validation: 0.09773345752302406]
	TIME [epoch: 10.3 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05604342437119142		[learning rate: 0.00044218]
	Learning Rate: 0.000442181
	LOSS [training: 0.05604342437119142 | validation: 0.07753104719613546]
	TIME [epoch: 10.3 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05992995871687381		[learning rate: 0.00044083]
	Learning Rate: 0.000440825
	LOSS [training: 0.05992995871687381 | validation: 0.11005785863469428]
	TIME [epoch: 10.3 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053355535381960896		[learning rate: 0.00043947]
	Learning Rate: 0.000439474
	LOSS [training: 0.053355535381960896 | validation: 0.07450597284564936]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_1518.pth
	Model improved!!!
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05526344844542598		[learning rate: 0.00043813]
	Learning Rate: 0.000438127
	LOSS [training: 0.05526344844542598 | validation: 0.0898139671198961]
	TIME [epoch: 10.3 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05902508110867657		[learning rate: 0.00043678]
	Learning Rate: 0.000436784
	LOSS [training: 0.05902508110867657 | validation: 0.114663978579934]
	TIME [epoch: 10.3 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05647114597185772		[learning rate: 0.00043544]
	Learning Rate: 0.000435445
	LOSS [training: 0.05647114597185772 | validation: 0.1127503752505435]
	TIME [epoch: 10.3 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057878573319635696		[learning rate: 0.00043411]
	Learning Rate: 0.00043411
	LOSS [training: 0.057878573319635696 | validation: 0.12109148334348264]
	TIME [epoch: 10.3 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04602213445062883		[learning rate: 0.00043278]
	Learning Rate: 0.00043278
	LOSS [training: 0.04602213445062883 | validation: 0.11958501328736403]
	TIME [epoch: 10.3 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04668183102753663		[learning rate: 0.00043145]
	Learning Rate: 0.000431453
	LOSS [training: 0.04668183102753663 | validation: 0.10496909711916498]
	TIME [epoch: 10.3 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04148148973371858		[learning rate: 0.00043013]
	Learning Rate: 0.00043013
	LOSS [training: 0.04148148973371858 | validation: 0.11385934501425587]
	TIME [epoch: 10.3 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04878424754283341		[learning rate: 0.00042881]
	Learning Rate: 0.000428812
	LOSS [training: 0.04878424754283341 | validation: 0.11705267392696386]
	TIME [epoch: 10.3 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04965944101144276		[learning rate: 0.0004275]
	Learning Rate: 0.000427497
	LOSS [training: 0.04965944101144276 | validation: 0.0881275828073383]
	TIME [epoch: 10.3 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04528500707409062		[learning rate: 0.00042619]
	Learning Rate: 0.000426187
	LOSS [training: 0.04528500707409062 | validation: 0.12273888127417656]
	TIME [epoch: 10.3 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04400194690168403		[learning rate: 0.00042488]
	Learning Rate: 0.00042488
	LOSS [training: 0.04400194690168403 | validation: 0.11762161704560586]
	TIME [epoch: 10.3 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044129588261126916		[learning rate: 0.00042358]
	Learning Rate: 0.000423578
	LOSS [training: 0.044129588261126916 | validation: 0.08801950283567303]
	TIME [epoch: 10.3 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04772660600643217		[learning rate: 0.00042228]
	Learning Rate: 0.000422279
	LOSS [training: 0.04772660600643217 | validation: 0.10824914466518039]
	TIME [epoch: 10.3 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04197162472446213		[learning rate: 0.00042098]
	Learning Rate: 0.000420985
	LOSS [training: 0.04197162472446213 | validation: 0.08032487301835346]
	TIME [epoch: 10.3 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04300935703395885		[learning rate: 0.00041969]
	Learning Rate: 0.000419694
	LOSS [training: 0.04300935703395885 | validation: 0.09297080044801585]
	TIME [epoch: 10.3 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03988445086212527		[learning rate: 0.00041841]
	Learning Rate: 0.000418408
	LOSS [training: 0.03988445086212527 | validation: 0.09331106161023954]
	TIME [epoch: 10.3 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03674708588082947		[learning rate: 0.00041713]
	Learning Rate: 0.000417125
	LOSS [training: 0.03674708588082947 | validation: 0.10035899027380357]
	TIME [epoch: 10.3 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053804901001035785		[learning rate: 0.00041585]
	Learning Rate: 0.000415847
	LOSS [training: 0.053804901001035785 | validation: 0.10263472747563528]
	TIME [epoch: 10.3 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04559612925544425		[learning rate: 0.00041457]
	Learning Rate: 0.000414572
	LOSS [training: 0.04559612925544425 | validation: 0.0764124526000776]
	TIME [epoch: 10.3 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04260198424664559		[learning rate: 0.0004133]
	Learning Rate: 0.000413301
	LOSS [training: 0.04260198424664559 | validation: 0.10480610886922975]
	TIME [epoch: 10.3 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04716898870736137		[learning rate: 0.00041203]
	Learning Rate: 0.000412034
	LOSS [training: 0.04716898870736137 | validation: 0.08807857073971259]
	TIME [epoch: 10.3 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0427079036620909		[learning rate: 0.00041077]
	Learning Rate: 0.000410771
	LOSS [training: 0.0427079036620909 | validation: 0.1095040918333264]
	TIME [epoch: 10.3 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0360629915108102		[learning rate: 0.00040951]
	Learning Rate: 0.000409512
	LOSS [training: 0.0360629915108102 | validation: 0.06341598217313035]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_1541.pth
	Model improved!!!
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04070726737385336		[learning rate: 0.00040826]
	Learning Rate: 0.000408257
	LOSS [training: 0.04070726737385336 | validation: 0.06745082487214793]
	TIME [epoch: 10.3 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04435126986174098		[learning rate: 0.00040701]
	Learning Rate: 0.000407005
	LOSS [training: 0.04435126986174098 | validation: 0.07492431672287589]
	TIME [epoch: 10.3 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04622815498913639		[learning rate: 0.00040576]
	Learning Rate: 0.000405758
	LOSS [training: 0.04622815498913639 | validation: 0.08303714736160896]
	TIME [epoch: 10.3 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04460115991378051		[learning rate: 0.00040451]
	Learning Rate: 0.000404514
	LOSS [training: 0.04460115991378051 | validation: 0.08978374514835574]
	TIME [epoch: 10.3 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04535952555887499		[learning rate: 0.00040327]
	Learning Rate: 0.000403274
	LOSS [training: 0.04535952555887499 | validation: 0.09003336148121333]
	TIME [epoch: 10.3 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036095454179351616		[learning rate: 0.00040204]
	Learning Rate: 0.000402038
	LOSS [training: 0.036095454179351616 | validation: 0.10800120974629725]
	TIME [epoch: 10.3 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03422433430448703		[learning rate: 0.00040081]
	Learning Rate: 0.000400805
	LOSS [training: 0.03422433430448703 | validation: 0.09910326162100913]
	TIME [epoch: 10.3 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045347452582379315		[learning rate: 0.00039958]
	Learning Rate: 0.000399577
	LOSS [training: 0.045347452582379315 | validation: 0.10035209973030693]
	TIME [epoch: 10.3 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03930388139744778		[learning rate: 0.00039835]
	Learning Rate: 0.000398352
	LOSS [training: 0.03930388139744778 | validation: 0.10257603042628971]
	TIME [epoch: 10.3 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039729985720371355		[learning rate: 0.00039713]
	Learning Rate: 0.000397131
	LOSS [training: 0.039729985720371355 | validation: 0.10061887948981944]
	TIME [epoch: 10.3 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03898858722629429		[learning rate: 0.00039591]
	Learning Rate: 0.000395913
	LOSS [training: 0.03898858722629429 | validation: 0.09762682779985622]
	TIME [epoch: 10.3 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03858549802507023		[learning rate: 0.0003947]
	Learning Rate: 0.0003947
	LOSS [training: 0.03858549802507023 | validation: 0.08404835114702146]
	TIME [epoch: 10.3 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04053120987156609		[learning rate: 0.00039349]
	Learning Rate: 0.00039349
	LOSS [training: 0.04053120987156609 | validation: 0.10272516843334704]
	TIME [epoch: 10.3 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04448240444130959		[learning rate: 0.00039228]
	Learning Rate: 0.000392283
	LOSS [training: 0.04448240444130959 | validation: 0.07993345083044046]
	TIME [epoch: 10.3 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038245250694093166		[learning rate: 0.00039108]
	Learning Rate: 0.000391081
	LOSS [training: 0.038245250694093166 | validation: 0.07308666866199635]
	TIME [epoch: 10.3 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04117329934660986		[learning rate: 0.00038988]
	Learning Rate: 0.000389882
	LOSS [training: 0.04117329934660986 | validation: 0.09861808074494882]
	TIME [epoch: 10.3 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04184171192133245		[learning rate: 0.00038869]
	Learning Rate: 0.000388687
	LOSS [training: 0.04184171192133245 | validation: 0.07954333541258526]
	TIME [epoch: 10.3 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03900824361402979		[learning rate: 0.0003875]
	Learning Rate: 0.000387495
	LOSS [training: 0.03900824361402979 | validation: 0.08651410832945976]
	TIME [epoch: 10.3 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03227993675654616		[learning rate: 0.00038631]
	Learning Rate: 0.000386308
	LOSS [training: 0.03227993675654616 | validation: 0.09391226688513245]
	TIME [epoch: 10.3 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0336578732766601		[learning rate: 0.00038512]
	Learning Rate: 0.000385123
	LOSS [training: 0.0336578732766601 | validation: 0.08986477743725411]
	TIME [epoch: 10.3 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03734814817778288		[learning rate: 0.00038394]
	Learning Rate: 0.000383943
	LOSS [training: 0.03734814817778288 | validation: 0.07834158523512635]
	TIME [epoch: 10.3 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04194400843238558		[learning rate: 0.00038277]
	Learning Rate: 0.000382766
	LOSS [training: 0.04194400843238558 | validation: 0.08313574651933038]
	TIME [epoch: 10.3 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03659332210477695		[learning rate: 0.00038159]
	Learning Rate: 0.000381593
	LOSS [training: 0.03659332210477695 | validation: 0.06867350837604248]
	TIME [epoch: 10.3 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03539258153453769		[learning rate: 0.00038042]
	Learning Rate: 0.000380423
	LOSS [training: 0.03539258153453769 | validation: 0.08895986562698849]
	TIME [epoch: 10.3 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03413896344961889		[learning rate: 0.00037926]
	Learning Rate: 0.000379257
	LOSS [training: 0.03413896344961889 | validation: 0.10404145726824415]
	TIME [epoch: 10.3 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03731674169294683		[learning rate: 0.00037809]
	Learning Rate: 0.000378094
	LOSS [training: 0.03731674169294683 | validation: 0.09236193700774013]
	TIME [epoch: 10.3 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0385218566618515		[learning rate: 0.00037694]
	Learning Rate: 0.000376935
	LOSS [training: 0.0385218566618515 | validation: 0.10138466440410582]
	TIME [epoch: 10.3 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038916568162614365		[learning rate: 0.00037578]
	Learning Rate: 0.00037578
	LOSS [training: 0.038916568162614365 | validation: 0.10141385618094806]
	TIME [epoch: 10.3 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04542216866510555		[learning rate: 0.00037463]
	Learning Rate: 0.000374628
	LOSS [training: 0.04542216866510555 | validation: 0.1036691438558837]
	TIME [epoch: 10.3 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049525659571945754		[learning rate: 0.00037348]
	Learning Rate: 0.000373479
	LOSS [training: 0.049525659571945754 | validation: 0.06863559155004915]
	TIME [epoch: 10.3 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045788444566455144		[learning rate: 0.00037233]
	Learning Rate: 0.000372335
	LOSS [training: 0.045788444566455144 | validation: 0.10042953284796355]
	TIME [epoch: 10.3 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04510236868062851		[learning rate: 0.00037119]
	Learning Rate: 0.000371193
	LOSS [training: 0.04510236868062851 | validation: 0.08547231348931082]
	TIME [epoch: 10.3 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045553576653397265		[learning rate: 0.00037006]
	Learning Rate: 0.000370055
	LOSS [training: 0.045553576653397265 | validation: 0.10365336953285476]
	TIME [epoch: 10.3 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04957037100827423		[learning rate: 0.00036892]
	Learning Rate: 0.000368921
	LOSS [training: 0.04957037100827423 | validation: 0.11700568148522972]
	TIME [epoch: 10.3 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04629191597047991		[learning rate: 0.00036779]
	Learning Rate: 0.00036779
	LOSS [training: 0.04629191597047991 | validation: 0.10778551403617219]
	TIME [epoch: 10.3 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0483927838939198		[learning rate: 0.00036666]
	Learning Rate: 0.000366663
	LOSS [training: 0.0483927838939198 | validation: 0.10502075955180669]
	TIME [epoch: 10.3 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041076305335845345		[learning rate: 0.00036554]
	Learning Rate: 0.000365539
	LOSS [training: 0.041076305335845345 | validation: 0.10321770757980449]
	TIME [epoch: 10.3 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0318148399620523		[learning rate: 0.00036442]
	Learning Rate: 0.000364418
	LOSS [training: 0.0318148399620523 | validation: 0.08215213060315733]
	TIME [epoch: 10.3 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04250910166529084		[learning rate: 0.0003633]
	Learning Rate: 0.000363301
	LOSS [training: 0.04250910166529084 | validation: 0.09538018821818828]
	TIME [epoch: 10.3 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037484177436977226		[learning rate: 0.00036219]
	Learning Rate: 0.000362187
	LOSS [training: 0.037484177436977226 | validation: 0.07733408249056992]
	TIME [epoch: 10.3 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04301772107466603		[learning rate: 0.00036108]
	Learning Rate: 0.000361077
	LOSS [training: 0.04301772107466603 | validation: 0.07472548712177304]
	TIME [epoch: 10.3 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03778935096327053		[learning rate: 0.00035997]
	Learning Rate: 0.00035997
	LOSS [training: 0.03778935096327053 | validation: 0.07281584503802234]
	TIME [epoch: 10.3 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030138678708870444		[learning rate: 0.00035887]
	Learning Rate: 0.000358867
	LOSS [training: 0.030138678708870444 | validation: 0.09656629123276983]
	TIME [epoch: 10.3 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031156515823193027		[learning rate: 0.00035777]
	Learning Rate: 0.000357767
	LOSS [training: 0.031156515823193027 | validation: 0.07052626556047323]
	TIME [epoch: 10.3 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03960620818301402		[learning rate: 0.00035667]
	Learning Rate: 0.00035667
	LOSS [training: 0.03960620818301402 | validation: 0.09795502900779077]
	TIME [epoch: 10.3 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03181109304875187		[learning rate: 0.00035558]
	Learning Rate: 0.000355577
	LOSS [training: 0.03181109304875187 | validation: 0.10505133252119847]
	TIME [epoch: 10.3 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041647388253943284		[learning rate: 0.00035449]
	Learning Rate: 0.000354487
	LOSS [training: 0.041647388253943284 | validation: 0.09120191286162985]
	TIME [epoch: 10.3 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028509402441519394		[learning rate: 0.0003534]
	Learning Rate: 0.0003534
	LOSS [training: 0.028509402441519394 | validation: 0.07910309158431508]
	TIME [epoch: 10.3 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03421298104425339		[learning rate: 0.00035232]
	Learning Rate: 0.000352317
	LOSS [training: 0.03421298104425339 | validation: 0.08842384736872864]
	TIME [epoch: 10.3 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03806585342001047		[learning rate: 0.00035124]
	Learning Rate: 0.000351237
	LOSS [training: 0.03806585342001047 | validation: 0.08094049720796269]
	TIME [epoch: 10.3 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03149106118091735		[learning rate: 0.00035016]
	Learning Rate: 0.00035016
	LOSS [training: 0.03149106118091735 | validation: 0.07143899905415466]
	TIME [epoch: 10.3 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03152801357978557		[learning rate: 0.00034909]
	Learning Rate: 0.000349087
	LOSS [training: 0.03152801357978557 | validation: 0.07920503378246099]
	TIME [epoch: 10.3 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03922177772030118		[learning rate: 0.00034802]
	Learning Rate: 0.000348017
	LOSS [training: 0.03922177772030118 | validation: 0.08959307308026741]
	TIME [epoch: 10.3 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03198003291122447		[learning rate: 0.00034695]
	Learning Rate: 0.00034695
	LOSS [training: 0.03198003291122447 | validation: 0.08820475659314678]
	TIME [epoch: 10.3 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037952448200660405		[learning rate: 0.00034589]
	Learning Rate: 0.000345886
	LOSS [training: 0.037952448200660405 | validation: 0.09984588461678995]
	TIME [epoch: 10.3 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03181092440772024		[learning rate: 0.00034483]
	Learning Rate: 0.000344826
	LOSS [training: 0.03181092440772024 | validation: 0.08967364455131933]
	TIME [epoch: 10.3 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04027467091045332		[learning rate: 0.00034377]
	Learning Rate: 0.000343769
	LOSS [training: 0.04027467091045332 | validation: 0.08969595046481554]
	TIME [epoch: 10.3 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03448720217717255		[learning rate: 0.00034272]
	Learning Rate: 0.000342715
	LOSS [training: 0.03448720217717255 | validation: 0.09724413877314135]
	TIME [epoch: 10.3 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03813249556686965		[learning rate: 0.00034166]
	Learning Rate: 0.000341665
	LOSS [training: 0.03813249556686965 | validation: 0.09271282055138116]
	TIME [epoch: 10.3 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04199146650140097		[learning rate: 0.00034062]
	Learning Rate: 0.000340617
	LOSS [training: 0.04199146650140097 | validation: 0.07741752975483998]
	TIME [epoch: 10.3 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04079999370578419		[learning rate: 0.00033957]
	Learning Rate: 0.000339573
	LOSS [training: 0.04079999370578419 | validation: 0.08175589875068903]
	TIME [epoch: 10.3 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04621641572986068		[learning rate: 0.00033853]
	Learning Rate: 0.000338532
	LOSS [training: 0.04621641572986068 | validation: 0.10863498618198836]
	TIME [epoch: 10.3 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04437231523232686		[learning rate: 0.00033749]
	Learning Rate: 0.000337494
	LOSS [training: 0.04437231523232686 | validation: 0.10596268433711131]
	TIME [epoch: 10.3 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035616307513178465		[learning rate: 0.00033646]
	Learning Rate: 0.00033646
	LOSS [training: 0.035616307513178465 | validation: 0.10325346634509924]
	TIME [epoch: 10.3 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03135922189059344		[learning rate: 0.00033543]
	Learning Rate: 0.000335428
	LOSS [training: 0.03135922189059344 | validation: 0.09618610021401218]
	TIME [epoch: 10.3 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03780930912757279		[learning rate: 0.0003344]
	Learning Rate: 0.0003344
	LOSS [training: 0.03780930912757279 | validation: 0.07742027018724876]
	TIME [epoch: 10.2 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029269550741275685		[learning rate: 0.00033338]
	Learning Rate: 0.000333375
	LOSS [training: 0.029269550741275685 | validation: 0.08531183606034691]
	TIME [epoch: 10.2 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033634510413423316		[learning rate: 0.00033235]
	Learning Rate: 0.000332353
	LOSS [training: 0.033634510413423316 | validation: 0.07167088446142654]
	TIME [epoch: 10.3 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03353313387422565		[learning rate: 0.00033133]
	Learning Rate: 0.000331334
	LOSS [training: 0.03353313387422565 | validation: 0.08556546935611521]
	TIME [epoch: 10.3 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03185360122625445		[learning rate: 0.00033032]
	Learning Rate: 0.000330319
	LOSS [training: 0.03185360122625445 | validation: 0.09182229279641163]
	TIME [epoch: 10.3 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041164541912464415		[learning rate: 0.00032931]
	Learning Rate: 0.000329306
	LOSS [training: 0.041164541912464415 | validation: 0.11300037172413266]
	TIME [epoch: 10.3 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03427486261231958		[learning rate: 0.0003283]
	Learning Rate: 0.000328297
	LOSS [training: 0.03427486261231958 | validation: 0.08611736634960002]
	TIME [epoch: 10.3 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03694330677838531		[learning rate: 0.00032729]
	Learning Rate: 0.00032729
	LOSS [training: 0.03694330677838531 | validation: 0.09419582294622689]
	TIME [epoch: 10.3 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03382194456805267		[learning rate: 0.00032629]
	Learning Rate: 0.000326287
	LOSS [training: 0.03382194456805267 | validation: 0.09140393062702114]
	TIME [epoch: 10.3 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03283057034602294		[learning rate: 0.00032529]
	Learning Rate: 0.000325287
	LOSS [training: 0.03283057034602294 | validation: 0.08071195776908273]
	TIME [epoch: 10.3 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04106174124294263		[learning rate: 0.00032429]
	Learning Rate: 0.00032429
	LOSS [training: 0.04106174124294263 | validation: 0.07310652521990797]
	TIME [epoch: 10.3 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040283300357485397		[learning rate: 0.0003233]
	Learning Rate: 0.000323296
	LOSS [training: 0.040283300357485397 | validation: 0.10160981206619919]
	TIME [epoch: 10.3 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03589938567396192		[learning rate: 0.0003223]
	Learning Rate: 0.000322305
	LOSS [training: 0.03589938567396192 | validation: 0.08252643273911374]
	TIME [epoch: 10.3 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031935597248317		[learning rate: 0.00032132]
	Learning Rate: 0.000321317
	LOSS [training: 0.031935597248317 | validation: 0.09751014832402537]
	TIME [epoch: 10.3 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04049010354442549		[learning rate: 0.00032033]
	Learning Rate: 0.000320332
	LOSS [training: 0.04049010354442549 | validation: 0.11057902505325147]
	TIME [epoch: 10.3 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056682149386458505		[learning rate: 0.00031935]
	Learning Rate: 0.00031935
	LOSS [training: 0.056682149386458505 | validation: 0.08577458837750017]
	TIME [epoch: 10.3 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050898265254164424		[learning rate: 0.00031837]
	Learning Rate: 0.000318371
	LOSS [training: 0.050898265254164424 | validation: 0.09243570112006946]
	TIME [epoch: 10.3 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04652665639315323		[learning rate: 0.00031739]
	Learning Rate: 0.000317395
	LOSS [training: 0.04652665639315323 | validation: 0.09473719582914898]
	TIME [epoch: 10.3 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0401477272686168		[learning rate: 0.00031642]
	Learning Rate: 0.000316422
	LOSS [training: 0.0401477272686168 | validation: 0.07140845716771212]
	TIME [epoch: 10.3 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03842835327045624		[learning rate: 0.00031545]
	Learning Rate: 0.000315452
	LOSS [training: 0.03842835327045624 | validation: 0.10121971181405577]
	TIME [epoch: 10.3 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04158302026572915		[learning rate: 0.00031449]
	Learning Rate: 0.000314485
	LOSS [training: 0.04158302026572915 | validation: 0.09777279268118311]
	TIME [epoch: 10.3 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03647433894664527		[learning rate: 0.00031352]
	Learning Rate: 0.000313521
	LOSS [training: 0.03647433894664527 | validation: 0.09771546627940086]
	TIME [epoch: 10.3 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03388554789418184		[learning rate: 0.00031256]
	Learning Rate: 0.00031256
	LOSS [training: 0.03388554789418184 | validation: 0.07179024536346167]
	TIME [epoch: 10.3 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03250494069490292		[learning rate: 0.0003116]
	Learning Rate: 0.000311602
	LOSS [training: 0.03250494069490292 | validation: 0.06872445611223375]
	TIME [epoch: 10.3 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03215718338686063		[learning rate: 0.00031065]
	Learning Rate: 0.000310647
	LOSS [training: 0.03215718338686063 | validation: 0.08403018977006835]
	TIME [epoch: 10.3 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03219614878890947		[learning rate: 0.00030969]
	Learning Rate: 0.000309694
	LOSS [training: 0.03219614878890947 | validation: 0.09716731212072124]
	TIME [epoch: 10.3 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038658199340651594		[learning rate: 0.00030874]
	Learning Rate: 0.000308745
	LOSS [training: 0.038658199340651594 | validation: 0.08206414581864366]
	TIME [epoch: 10.3 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03656826583843224		[learning rate: 0.0003078]
	Learning Rate: 0.000307799
	LOSS [training: 0.03656826583843224 | validation: 0.08224925179884586]
	TIME [epoch: 10.3 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03305003068880878		[learning rate: 0.00030686]
	Learning Rate: 0.000306855
	LOSS [training: 0.03305003068880878 | validation: 0.10083144203125381]
	TIME [epoch: 10.3 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03512944841363652		[learning rate: 0.00030591]
	Learning Rate: 0.000305914
	LOSS [training: 0.03512944841363652 | validation: 0.07242668905081484]
	TIME [epoch: 10.3 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04128439452250568		[learning rate: 0.00030498]
	Learning Rate: 0.000304977
	LOSS [training: 0.04128439452250568 | validation: 0.10559755706230714]
	TIME [epoch: 10.3 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035059052721502684		[learning rate: 0.00030404]
	Learning Rate: 0.000304042
	LOSS [training: 0.035059052721502684 | validation: 0.07426823817467694]
	TIME [epoch: 10.3 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03441791195595861		[learning rate: 0.00030311]
	Learning Rate: 0.00030311
	LOSS [training: 0.03441791195595861 | validation: 0.10115646151075462]
	TIME [epoch: 10.3 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0396669131989776		[learning rate: 0.00030218]
	Learning Rate: 0.000302181
	LOSS [training: 0.0396669131989776 | validation: 0.07034907099482009]
	TIME [epoch: 10.3 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035361364357949385		[learning rate: 0.00030125]
	Learning Rate: 0.000301254
	LOSS [training: 0.035361364357949385 | validation: 0.09475934186430594]
	TIME [epoch: 10.3 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04042758399376446		[learning rate: 0.00030033]
	Learning Rate: 0.000300331
	LOSS [training: 0.04042758399376446 | validation: 0.08848668570174083]
	TIME [epoch: 10.3 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033866770819150314		[learning rate: 0.00029941]
	Learning Rate: 0.00029941
	LOSS [training: 0.033866770819150314 | validation: 0.08673526661994523]
	TIME [epoch: 10.3 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0328283356426836		[learning rate: 0.00029849]
	Learning Rate: 0.000298492
	LOSS [training: 0.0328283356426836 | validation: 0.08493261721160571]
	TIME [epoch: 10.3 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028804010728247426		[learning rate: 0.00029758]
	Learning Rate: 0.000297577
	LOSS [training: 0.028804010728247426 | validation: 0.08348566549668608]
	TIME [epoch: 10.2 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0331629640318898		[learning rate: 0.00029667]
	Learning Rate: 0.000296665
	LOSS [training: 0.0331629640318898 | validation: 0.10090662669581829]
	TIME [epoch: 10.3 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03567591674429631		[learning rate: 0.00029576]
	Learning Rate: 0.000295756
	LOSS [training: 0.03567591674429631 | validation: 0.08358117454977268]
	TIME [epoch: 10.3 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027330573373033164		[learning rate: 0.00029485]
	Learning Rate: 0.000294849
	LOSS [training: 0.027330573373033164 | validation: 0.08956198013729054]
	TIME [epoch: 10.3 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031024844671739337		[learning rate: 0.00029395]
	Learning Rate: 0.000293945
	LOSS [training: 0.031024844671739337 | validation: 0.06158474449929061]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_1649.pth
	Model improved!!!
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030488460916371685		[learning rate: 0.00029304]
	Learning Rate: 0.000293044
	LOSS [training: 0.030488460916371685 | validation: 0.08312177683258977]
	TIME [epoch: 10.3 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03430400889986275		[learning rate: 0.00029215]
	Learning Rate: 0.000292146
	LOSS [training: 0.03430400889986275 | validation: 0.059475041078192986]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_1651.pth
	Model improved!!!
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031500191027125736		[learning rate: 0.00029125]
	Learning Rate: 0.00029125
	LOSS [training: 0.031500191027125736 | validation: 0.06841203100405834]
	TIME [epoch: 10.3 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030642209844846613		[learning rate: 0.00029036]
	Learning Rate: 0.000290358
	LOSS [training: 0.030642209844846613 | validation: 0.0628263465182446]
	TIME [epoch: 10.3 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03215341247281322		[learning rate: 0.00028947]
	Learning Rate: 0.000289468
	LOSS [training: 0.03215341247281322 | validation: 0.08886962033797088]
	TIME [epoch: 10.3 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028535723094493166		[learning rate: 0.00028858]
	Learning Rate: 0.00028858
	LOSS [training: 0.028535723094493166 | validation: 0.06385322100661188]
	TIME [epoch: 10.3 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0289780429223017		[learning rate: 0.0002877]
	Learning Rate: 0.000287696
	LOSS [training: 0.0289780429223017 | validation: 0.10282329126182951]
	TIME [epoch: 10.3 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02841644596245512		[learning rate: 0.00028681]
	Learning Rate: 0.000286814
	LOSS [training: 0.02841644596245512 | validation: 0.06312693358194299]
	TIME [epoch: 10.3 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029780660314773798		[learning rate: 0.00028593]
	Learning Rate: 0.000285935
	LOSS [training: 0.029780660314773798 | validation: 0.07997531108022388]
	TIME [epoch: 10.3 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030069154598791913		[learning rate: 0.00028506]
	Learning Rate: 0.000285058
	LOSS [training: 0.030069154598791913 | validation: 0.0695141971250543]
	TIME [epoch: 10.3 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034307849301061566		[learning rate: 0.00028418]
	Learning Rate: 0.000284184
	LOSS [training: 0.034307849301061566 | validation: 0.09598536576360638]
	TIME [epoch: 10.3 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03317187031658618		[learning rate: 0.00028331]
	Learning Rate: 0.000283313
	LOSS [training: 0.03317187031658618 | validation: 0.09407332776673027]
	TIME [epoch: 10.3 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03563325642590873		[learning rate: 0.00028244]
	Learning Rate: 0.000282445
	LOSS [training: 0.03563325642590873 | validation: 0.09187700779440611]
	TIME [epoch: 10.3 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043463470474159556		[learning rate: 0.00028158]
	Learning Rate: 0.000281579
	LOSS [training: 0.043463470474159556 | validation: 0.0762169317300226]
	TIME [epoch: 10.3 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03129394164350319		[learning rate: 0.00028072]
	Learning Rate: 0.000280716
	LOSS [training: 0.03129394164350319 | validation: 0.0827554429774807]
	TIME [epoch: 10.3 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03556657585155709		[learning rate: 0.00027986]
	Learning Rate: 0.000279855
	LOSS [training: 0.03556657585155709 | validation: 0.08143499081409791]
	TIME [epoch: 10.3 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03118297717866499		[learning rate: 0.000279]
	Learning Rate: 0.000278997
	LOSS [training: 0.03118297717866499 | validation: 0.10437275502781476]
	TIME [epoch: 10.3 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03352389557648068		[learning rate: 0.00027814]
	Learning Rate: 0.000278142
	LOSS [training: 0.03352389557648068 | validation: 0.10384345457876046]
	TIME [epoch: 10.3 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03523921653297658		[learning rate: 0.00027729]
	Learning Rate: 0.000277289
	LOSS [training: 0.03523921653297658 | validation: 0.09213059760589307]
	TIME [epoch: 10.3 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03233340560794422		[learning rate: 0.00027644]
	Learning Rate: 0.000276439
	LOSS [training: 0.03233340560794422 | validation: 0.0820365089152621]
	TIME [epoch: 10.3 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03662900759717488		[learning rate: 0.00027559]
	Learning Rate: 0.000275592
	LOSS [training: 0.03662900759717488 | validation: 0.0715320197464621]
	TIME [epoch: 10.3 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027574574637491762		[learning rate: 0.00027475]
	Learning Rate: 0.000274747
	LOSS [training: 0.027574574637491762 | validation: 0.06556092430093524]
	TIME [epoch: 10.3 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032472767136430214		[learning rate: 0.00027391]
	Learning Rate: 0.000273905
	LOSS [training: 0.032472767136430214 | validation: 0.08571691305627653]
	TIME [epoch: 10.3 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03253933281137717		[learning rate: 0.00027307]
	Learning Rate: 0.000273065
	LOSS [training: 0.03253933281137717 | validation: 0.06881718777039181]
	TIME [epoch: 10.3 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03158887042272696		[learning rate: 0.00027223]
	Learning Rate: 0.000272228
	LOSS [training: 0.03158887042272696 | validation: 0.05766057402436535]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_1674.pth
	Model improved!!!
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0284566333829131		[learning rate: 0.00027139]
	Learning Rate: 0.000271394
	LOSS [training: 0.0284566333829131 | validation: 0.07261920906433489]
	TIME [epoch: 10.3 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03309976431386304		[learning rate: 0.00027056]
	Learning Rate: 0.000270562
	LOSS [training: 0.03309976431386304 | validation: 0.08974747632915364]
	TIME [epoch: 10.3 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030886715944357962		[learning rate: 0.00026973]
	Learning Rate: 0.000269733
	LOSS [training: 0.030886715944357962 | validation: 0.08163550977538432]
	TIME [epoch: 10.3 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04415326153770698		[learning rate: 0.00026891]
	Learning Rate: 0.000268906
	LOSS [training: 0.04415326153770698 | validation: 0.07666156857041367]
	TIME [epoch: 10.3 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035786968866774814		[learning rate: 0.00026808]
	Learning Rate: 0.000268081
	LOSS [training: 0.035786968866774814 | validation: 0.07933722842412408]
	TIME [epoch: 10.3 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0360280655031901		[learning rate: 0.00026726]
	Learning Rate: 0.00026726
	LOSS [training: 0.0360280655031901 | validation: 0.10509968789406486]
	TIME [epoch: 10.3 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03376980540886385		[learning rate: 0.00026644]
	Learning Rate: 0.00026644
	LOSS [training: 0.03376980540886385 | validation: 0.07619796413934415]
	TIME [epoch: 10.2 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03506057705735884		[learning rate: 0.00026562]
	Learning Rate: 0.000265624
	LOSS [training: 0.03506057705735884 | validation: 0.07858611296338036]
	TIME [epoch: 10.3 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03832818029148325		[learning rate: 0.00026481]
	Learning Rate: 0.000264809
	LOSS [training: 0.03832818029148325 | validation: 0.09745839547558528]
	TIME [epoch: 10.3 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035511104084235336		[learning rate: 0.000264]
	Learning Rate: 0.000263998
	LOSS [training: 0.035511104084235336 | validation: 0.09989279349034458]
	TIME [epoch: 10.3 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03319015758264145		[learning rate: 0.00026319]
	Learning Rate: 0.000263188
	LOSS [training: 0.03319015758264145 | validation: 0.07556704479467141]
	TIME [epoch: 10.3 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0396264978595918		[learning rate: 0.00026238]
	Learning Rate: 0.000262382
	LOSS [training: 0.0396264978595918 | validation: 0.08963893152019566]
	TIME [epoch: 10.3 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037086673280748536		[learning rate: 0.00026158]
	Learning Rate: 0.000261577
	LOSS [training: 0.037086673280748536 | validation: 0.07177584152841643]
	TIME [epoch: 10.3 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03485274644765247		[learning rate: 0.00026078]
	Learning Rate: 0.000260775
	LOSS [training: 0.03485274644765247 | validation: 0.09422911453234693]
	TIME [epoch: 10.3 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043726795086180575		[learning rate: 0.00025998]
	Learning Rate: 0.000259976
	LOSS [training: 0.043726795086180575 | validation: 0.10015215210004443]
	TIME [epoch: 10.3 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03959611492043622		[learning rate: 0.00025918]
	Learning Rate: 0.000259179
	LOSS [training: 0.03959611492043622 | validation: 0.09423354483351042]
	TIME [epoch: 10.3 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03804747366432494		[learning rate: 0.00025838]
	Learning Rate: 0.000258385
	LOSS [training: 0.03804747366432494 | validation: 0.0964443898310195]
	TIME [epoch: 10.3 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036509285729741485		[learning rate: 0.00025759]
	Learning Rate: 0.000257593
	LOSS [training: 0.036509285729741485 | validation: 0.09793963044263382]
	TIME [epoch: 10.3 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04349476087597268		[learning rate: 0.0002568]
	Learning Rate: 0.000256803
	LOSS [training: 0.04349476087597268 | validation: 0.071922440030034]
	TIME [epoch: 10.3 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03483568968031794		[learning rate: 0.00025602]
	Learning Rate: 0.000256016
	LOSS [training: 0.03483568968031794 | validation: 0.06728342606331074]
	TIME [epoch: 10.3 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03394949477380148		[learning rate: 0.00025523]
	Learning Rate: 0.000255231
	LOSS [training: 0.03394949477380148 | validation: 0.08821385960696969]
	TIME [epoch: 10.3 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037112957501319446		[learning rate: 0.00025445]
	Learning Rate: 0.000254449
	LOSS [training: 0.037112957501319446 | validation: 0.07682003963243011]
	TIME [epoch: 10.3 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030298030945995997		[learning rate: 0.00025367]
	Learning Rate: 0.000253669
	LOSS [training: 0.030298030945995997 | validation: 0.07057716189358712]
	TIME [epoch: 10.3 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03507536263752757		[learning rate: 0.00025289]
	Learning Rate: 0.000252891
	LOSS [training: 0.03507536263752757 | validation: 0.06560340446859127]
	TIME [epoch: 10.3 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031017747016253726		[learning rate: 0.00025212]
	Learning Rate: 0.000252116
	LOSS [training: 0.031017747016253726 | validation: 0.07039064586817526]
	TIME [epoch: 10.3 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023072789549525		[learning rate: 0.00025134]
	Learning Rate: 0.000251343
	LOSS [training: 0.023072789549525 | validation: 0.07821752504704896]
	TIME [epoch: 10.3 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03205831012269157		[learning rate: 0.00025057]
	Learning Rate: 0.000250572
	LOSS [training: 0.03205831012269157 | validation: 0.07021484326648818]
	TIME [epoch: 10.3 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028178782351213343		[learning rate: 0.0002498]
	Learning Rate: 0.000249804
	LOSS [training: 0.028178782351213343 | validation: 0.09581856186260927]
	TIME [epoch: 10.3 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03260758406699878		[learning rate: 0.00024904]
	Learning Rate: 0.000249039
	LOSS [training: 0.03260758406699878 | validation: 0.0689572625000148]
	TIME [epoch: 10.3 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03609044755806183		[learning rate: 0.00024828]
	Learning Rate: 0.000248275
	LOSS [training: 0.03609044755806183 | validation: 0.07994768597108257]
	TIME [epoch: 10.3 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03932550180592538		[learning rate: 0.00024751]
	Learning Rate: 0.000247514
	LOSS [training: 0.03932550180592538 | validation: 0.10321465524177363]
	TIME [epoch: 10.3 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03674485457790453		[learning rate: 0.00024676]
	Learning Rate: 0.000246755
	LOSS [training: 0.03674485457790453 | validation: 0.08728120754919032]
	TIME [epoch: 10.3 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03906065941983077		[learning rate: 0.000246]
	Learning Rate: 0.000245999
	LOSS [training: 0.03906065941983077 | validation: 0.09290706472741984]
	TIME [epoch: 10.3 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040116486948040896		[learning rate: 0.00024524]
	Learning Rate: 0.000245245
	LOSS [training: 0.040116486948040896 | validation: 0.07263156221092075]
	TIME [epoch: 10.3 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03795249025286701		[learning rate: 0.00024449]
	Learning Rate: 0.000244493
	LOSS [training: 0.03795249025286701 | validation: 0.07275659732410908]
	TIME [epoch: 10.3 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031650745913998746		[learning rate: 0.00024374]
	Learning Rate: 0.000243744
	LOSS [training: 0.031650745913998746 | validation: 0.07433335870894221]
	TIME [epoch: 10.3 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031509050501518254		[learning rate: 0.000243]
	Learning Rate: 0.000242996
	LOSS [training: 0.031509050501518254 | validation: 0.08601104127002375]
	TIME [epoch: 10.3 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03225862414587296		[learning rate: 0.00024225]
	Learning Rate: 0.000242252
	LOSS [training: 0.03225862414587296 | validation: 0.06698129470834444]
	TIME [epoch: 10.3 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03091588268418265		[learning rate: 0.00024151]
	Learning Rate: 0.000241509
	LOSS [training: 0.03091588268418265 | validation: 0.07451778951377135]
	TIME [epoch: 10.3 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03477940628583218		[learning rate: 0.00024077]
	Learning Rate: 0.000240769
	LOSS [training: 0.03477940628583218 | validation: 0.08482919269105646]
	TIME [epoch: 10.3 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030271249559709622		[learning rate: 0.00024003]
	Learning Rate: 0.000240031
	LOSS [training: 0.030271249559709622 | validation: 0.10059602978566361]
	TIME [epoch: 10.3 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02865626854035625		[learning rate: 0.00023929]
	Learning Rate: 0.000239295
	LOSS [training: 0.02865626854035625 | validation: 0.0597482425152907]
	TIME [epoch: 10.3 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030775785476537094		[learning rate: 0.00023856]
	Learning Rate: 0.000238561
	LOSS [training: 0.030775785476537094 | validation: 0.09651239192297617]
	TIME [epoch: 10.3 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029505021515353037		[learning rate: 0.00023783]
	Learning Rate: 0.00023783
	LOSS [training: 0.029505021515353037 | validation: 0.07830827748723966]
	TIME [epoch: 10.3 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030838153861606703		[learning rate: 0.0002371]
	Learning Rate: 0.000237101
	LOSS [training: 0.030838153861606703 | validation: 0.0821930924603944]
	TIME [epoch: 10.3 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03305030388072483		[learning rate: 0.00023637]
	Learning Rate: 0.000236374
	LOSS [training: 0.03305030388072483 | validation: 0.09656562276982569]
	TIME [epoch: 10.3 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03118283528455079		[learning rate: 0.00023565]
	Learning Rate: 0.00023565
	LOSS [training: 0.03118283528455079 | validation: 0.07068747763363196]
	TIME [epoch: 10.3 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040587567116773804		[learning rate: 0.00023493]
	Learning Rate: 0.000234927
	LOSS [training: 0.040587567116773804 | validation: 0.08206016334610976]
	TIME [epoch: 10.3 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03763534825985297		[learning rate: 0.00023421]
	Learning Rate: 0.000234207
	LOSS [training: 0.03763534825985297 | validation: 0.10379419261059714]
	TIME [epoch: 10.3 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03083205475824155		[learning rate: 0.00023349]
	Learning Rate: 0.000233489
	LOSS [training: 0.03083205475824155 | validation: 0.09648948567009696]
	TIME [epoch: 10.3 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03621163581891477		[learning rate: 0.00023277]
	Learning Rate: 0.000232773
	LOSS [training: 0.03621163581891477 | validation: 0.09850914884805491]
	TIME [epoch: 10.3 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034720357527173396		[learning rate: 0.00023206]
	Learning Rate: 0.00023206
	LOSS [training: 0.034720357527173396 | validation: 0.093446604823401]
	TIME [epoch: 10.3 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02833371700878879		[learning rate: 0.00023135]
	Learning Rate: 0.000231348
	LOSS [training: 0.02833371700878879 | validation: 0.07380350425756017]
	TIME [epoch: 10.3 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03290477613940003		[learning rate: 0.00023064]
	Learning Rate: 0.000230639
	LOSS [training: 0.03290477613940003 | validation: 0.09479756856018029]
	TIME [epoch: 10.3 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02982497045657902		[learning rate: 0.00022993]
	Learning Rate: 0.000229932
	LOSS [training: 0.02982497045657902 | validation: 0.0868633075564454]
	TIME [epoch: 10.3 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0342100632648622		[learning rate: 0.00022923]
	Learning Rate: 0.000229227
	LOSS [training: 0.0342100632648622 | validation: 0.09278608813552186]
	TIME [epoch: 10.3 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03416772296219988		[learning rate: 0.00022852]
	Learning Rate: 0.000228525
	LOSS [training: 0.03416772296219988 | validation: 0.09543504681998062]
	TIME [epoch: 10.3 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02697780011732363		[learning rate: 0.00022782]
	Learning Rate: 0.000227824
	LOSS [training: 0.02697780011732363 | validation: 0.09729916782812296]
	TIME [epoch: 10.3 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03188567338680969		[learning rate: 0.00022713]
	Learning Rate: 0.000227126
	LOSS [training: 0.03188567338680969 | validation: 0.08331410203769701]
	TIME [epoch: 10.3 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02748809491806446		[learning rate: 0.00022643]
	Learning Rate: 0.00022643
	LOSS [training: 0.02748809491806446 | validation: 0.08776413603824557]
	TIME [epoch: 10.3 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0324973914498551		[learning rate: 0.00022574]
	Learning Rate: 0.000225736
	LOSS [training: 0.0324973914498551 | validation: 0.06913978060597664]
	TIME [epoch: 10.3 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03517700365574909		[learning rate: 0.00022504]
	Learning Rate: 0.000225044
	LOSS [training: 0.03517700365574909 | validation: 0.09293888705267848]
	TIME [epoch: 10.3 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029997374913293507		[learning rate: 0.00022435]
	Learning Rate: 0.000224354
	LOSS [training: 0.029997374913293507 | validation: 0.1017175937177194]
	TIME [epoch: 10.3 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033563351385817265		[learning rate: 0.00022367]
	Learning Rate: 0.000223666
	LOSS [training: 0.033563351385817265 | validation: 0.06743440178906546]
	TIME [epoch: 10.3 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0322888019771592		[learning rate: 0.00022298]
	Learning Rate: 0.00022298
	LOSS [training: 0.0322888019771592 | validation: 0.0924983521515482]
	TIME [epoch: 10.3 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03678946269797651		[learning rate: 0.0002223]
	Learning Rate: 0.000222297
	LOSS [training: 0.03678946269797651 | validation: 0.06856474718141278]
	TIME [epoch: 10.3 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033406680652106384		[learning rate: 0.00022162]
	Learning Rate: 0.000221615
	LOSS [training: 0.033406680652106384 | validation: 0.10053237346621675]
	TIME [epoch: 10.3 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03362628356510453		[learning rate: 0.00022094]
	Learning Rate: 0.000220936
	LOSS [training: 0.03362628356510453 | validation: 0.06215318672729053]
	TIME [epoch: 10.3 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03176133064244103		[learning rate: 0.00022026]
	Learning Rate: 0.000220259
	LOSS [training: 0.03176133064244103 | validation: 0.08791277556711151]
	TIME [epoch: 10.3 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030787426407662088		[learning rate: 0.00021958]
	Learning Rate: 0.000219584
	LOSS [training: 0.030787426407662088 | validation: 0.09092006780369488]
	TIME [epoch: 10.3 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032393098992576204		[learning rate: 0.00021891]
	Learning Rate: 0.000218911
	LOSS [training: 0.032393098992576204 | validation: 0.07733538594349498]
	TIME [epoch: 10.3 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035128826264796666		[learning rate: 0.00021824]
	Learning Rate: 0.000218239
	LOSS [training: 0.035128826264796666 | validation: 0.07586956237824277]
	TIME [epoch: 10.3 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03520128764135318		[learning rate: 0.00021757]
	Learning Rate: 0.00021757
	LOSS [training: 0.03520128764135318 | validation: 0.06707594772813348]
	TIME [epoch: 10.3 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032158700611181215		[learning rate: 0.0002169]
	Learning Rate: 0.000216904
	LOSS [training: 0.032158700611181215 | validation: 0.09114572404701686]
	TIME [epoch: 10.3 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034476315317756676		[learning rate: 0.00021624]
	Learning Rate: 0.000216239
	LOSS [training: 0.034476315317756676 | validation: 0.11337745259885423]
	TIME [epoch: 10.3 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033574596503052986		[learning rate: 0.00021558]
	Learning Rate: 0.000215576
	LOSS [training: 0.033574596503052986 | validation: 0.07462591507082932]
	TIME [epoch: 10.3 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031611105253808794		[learning rate: 0.00021491]
	Learning Rate: 0.000214915
	LOSS [training: 0.031611105253808794 | validation: 0.06503729226031169]
	TIME [epoch: 10.3 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026515608882859153		[learning rate: 0.00021426]
	Learning Rate: 0.000214256
	LOSS [training: 0.026515608882859153 | validation: 0.09118531695950836]
	TIME [epoch: 10.3 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027259015367294005		[learning rate: 0.0002136]
	Learning Rate: 0.000213599
	LOSS [training: 0.027259015367294005 | validation: 0.08844570524270383]
	TIME [epoch: 10.3 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02729902433533188		[learning rate: 0.00021294]
	Learning Rate: 0.000212945
	LOSS [training: 0.02729902433533188 | validation: 0.06236205189073763]
	TIME [epoch: 10.3 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03364155445165527		[learning rate: 0.00021229]
	Learning Rate: 0.000212292
	LOSS [training: 0.03364155445165527 | validation: 0.06367118932201635]
	TIME [epoch: 10.3 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02687024338797655		[learning rate: 0.00021164]
	Learning Rate: 0.000211641
	LOSS [training: 0.02687024338797655 | validation: 0.10022067970590748]
	TIME [epoch: 10.3 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032421179732215935		[learning rate: 0.00021099]
	Learning Rate: 0.000210992
	LOSS [training: 0.032421179732215935 | validation: 0.09474232271402565]
	TIME [epoch: 10.3 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030990682950630354		[learning rate: 0.00021035]
	Learning Rate: 0.000210346
	LOSS [training: 0.030990682950630354 | validation: 0.08539576274031724]
	TIME [epoch: 10.3 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0340552720207324		[learning rate: 0.0002097]
	Learning Rate: 0.000209701
	LOSS [training: 0.0340552720207324 | validation: 0.08685085060143448]
	TIME [epoch: 10.3 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029023054604826626		[learning rate: 0.00020906]
	Learning Rate: 0.000209058
	LOSS [training: 0.029023054604826626 | validation: 0.0874930726912984]
	TIME [epoch: 10.3 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03195601341063602		[learning rate: 0.00020842]
	Learning Rate: 0.000208417
	LOSS [training: 0.03195601341063602 | validation: 0.08728464893725757]
	TIME [epoch: 10.3 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029218623322766556		[learning rate: 0.00020778]
	Learning Rate: 0.000207778
	LOSS [training: 0.029218623322766556 | validation: 0.07638182468492319]
	TIME [epoch: 10.3 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03551431136322212		[learning rate: 0.00020714]
	Learning Rate: 0.000207141
	LOSS [training: 0.03551431136322212 | validation: 0.09213664704530469]
	TIME [epoch: 10.3 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027148708232761075		[learning rate: 0.00020651]
	Learning Rate: 0.000206506
	LOSS [training: 0.027148708232761075 | validation: 0.08475618894307602]
	TIME [epoch: 10.3 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029003213587064074		[learning rate: 0.00020587]
	Learning Rate: 0.000205873
	LOSS [training: 0.029003213587064074 | validation: 0.07408691369747535]
	TIME [epoch: 10.3 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029855416967912368		[learning rate: 0.00020524]
	Learning Rate: 0.000205242
	LOSS [training: 0.029855416967912368 | validation: 0.08346481688174025]
	TIME [epoch: 10.3 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03265073915452432		[learning rate: 0.00020461]
	Learning Rate: 0.000204613
	LOSS [training: 0.03265073915452432 | validation: 0.08716972171898142]
	TIME [epoch: 10.3 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03310005480620716		[learning rate: 0.00020399]
	Learning Rate: 0.000203986
	LOSS [training: 0.03310005480620716 | validation: 0.07863690497793206]
	TIME [epoch: 10.3 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04274992146252689		[learning rate: 0.00020336]
	Learning Rate: 0.00020336
	LOSS [training: 0.04274992146252689 | validation: 0.09247126262380072]
	TIME [epoch: 10.3 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030494495168392633		[learning rate: 0.00020274]
	Learning Rate: 0.000202737
	LOSS [training: 0.030494495168392633 | validation: 0.11078285268924329]
	TIME [epoch: 10.3 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030056381394511073		[learning rate: 0.00020212]
	Learning Rate: 0.000202116
	LOSS [training: 0.030056381394511073 | validation: 0.08751918094115521]
	TIME [epoch: 10.3 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03183344215807629		[learning rate: 0.0002015]
	Learning Rate: 0.000201496
	LOSS [training: 0.03183344215807629 | validation: 0.09739506231763637]
	TIME [epoch: 10.3 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03058167548916054		[learning rate: 0.00020088]
	Learning Rate: 0.000200878
	LOSS [training: 0.03058167548916054 | validation: 0.09394796196234836]
	TIME [epoch: 10.3 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03276533215309463		[learning rate: 0.00020026]
	Learning Rate: 0.000200263
	LOSS [training: 0.03276533215309463 | validation: 0.05503106272798398]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_154958/states/model_tr_study6_1774.pth
	Model improved!!!
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032061660932787395		[learning rate: 0.00019965]
	Learning Rate: 0.000199649
	LOSS [training: 0.032061660932787395 | validation: 0.08955665380065259]
	TIME [epoch: 10.3 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03145672495877729		[learning rate: 0.00019904]
	Learning Rate: 0.000199037
	LOSS [training: 0.03145672495877729 | validation: 0.09780008385945173]
	TIME [epoch: 10.3 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02077000425023101		[learning rate: 0.00019843]
	Learning Rate: 0.000198427
	LOSS [training: 0.02077000425023101 | validation: 0.06295043117909348]
	TIME [epoch: 10.3 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030673318488365263		[learning rate: 0.00019782]
	Learning Rate: 0.000197818
	LOSS [training: 0.030673318488365263 | validation: 0.09582316514294313]
	TIME [epoch: 10.3 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035286938767180476		[learning rate: 0.00019721]
	Learning Rate: 0.000197212
	LOSS [training: 0.035286938767180476 | validation: 0.08464333248924366]
	TIME [epoch: 10.3 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025863211137363895		[learning rate: 0.00019661]
	Learning Rate: 0.000196607
	LOSS [training: 0.025863211137363895 | validation: 0.09613047002717155]
	TIME [epoch: 10.3 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027046924321063114		[learning rate: 0.000196]
	Learning Rate: 0.000196005
	LOSS [training: 0.027046924321063114 | validation: 0.09624641830789205]
	TIME [epoch: 10.3 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02423513245484965		[learning rate: 0.0001954]
	Learning Rate: 0.000195404
	LOSS [training: 0.02423513245484965 | validation: 0.08587985036916529]
	TIME [epoch: 10.3 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03199431230534315		[learning rate: 0.0001948]
	Learning Rate: 0.000194805
	LOSS [training: 0.03199431230534315 | validation: 0.06628382651962339]
	TIME [epoch: 10.3 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039587509089332104		[learning rate: 0.00019421]
	Learning Rate: 0.000194208
	LOSS [training: 0.039587509089332104 | validation: 0.0702992843641292]
	TIME [epoch: 10.3 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02758042788518651		[learning rate: 0.00019361]
	Learning Rate: 0.000193612
	LOSS [training: 0.02758042788518651 | validation: 0.08963136917632485]
	TIME [epoch: 10.3 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024849179464222264		[learning rate: 0.00019302]
	Learning Rate: 0.000193019
	LOSS [training: 0.024849179464222264 | validation: 0.07105152919246606]
	TIME [epoch: 10.3 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028968708416646338		[learning rate: 0.00019243]
	Learning Rate: 0.000192427
	LOSS [training: 0.028968708416646338 | validation: 0.09462136006574841]
	TIME [epoch: 10.3 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02997321774302102		[learning rate: 0.00019184]
	Learning Rate: 0.000191837
	LOSS [training: 0.02997321774302102 | validation: 0.05677370004825546]
	TIME [epoch: 10.3 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03164875509191155		[learning rate: 0.00019125]
	Learning Rate: 0.000191249
	LOSS [training: 0.03164875509191155 | validation: 0.07175118886375569]
	TIME [epoch: 10.3 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03061747121943383		[learning rate: 0.00019066]
	Learning Rate: 0.000190663
	LOSS [training: 0.03061747121943383 | validation: 0.10006364972374622]
	TIME [epoch: 10.3 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033960782825476536		[learning rate: 0.00019008]
	Learning Rate: 0.000190079
	LOSS [training: 0.033960782825476536 | validation: 0.10058346538485921]
	TIME [epoch: 10.3 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03214430756302218		[learning rate: 0.0001895]
	Learning Rate: 0.000189496
	LOSS [training: 0.03214430756302218 | validation: 0.08411861575435517]
	TIME [epoch: 10.3 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030971982192329005		[learning rate: 0.00018892]
	Learning Rate: 0.000188915
	LOSS [training: 0.030971982192329005 | validation: 0.08609756550508803]
	TIME [epoch: 10.3 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032517217855387984		[learning rate: 0.00018834]
	Learning Rate: 0.000188336
	LOSS [training: 0.032517217855387984 | validation: 0.08240006616717516]
	TIME [epoch: 10.3 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028852001959701345		[learning rate: 0.00018776]
	Learning Rate: 0.000187759
	LOSS [training: 0.028852001959701345 | validation: 0.09196521813078323]
	TIME [epoch: 10.3 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03306073797799482		[learning rate: 0.00018718]
	Learning Rate: 0.000187183
	LOSS [training: 0.03306073797799482 | validation: 0.08942597425718515]
	TIME [epoch: 10.3 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029826606865026938		[learning rate: 0.00018661]
	Learning Rate: 0.000186609
	LOSS [training: 0.029826606865026938 | validation: 0.0903636123000534]
	TIME [epoch: 10.3 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03449723382371365		[learning rate: 0.00018604]
	Learning Rate: 0.000186037
	LOSS [training: 0.03449723382371365 | validation: 0.07205274027615062]
	TIME [epoch: 10.3 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027155994702394576		[learning rate: 0.00018547]
	Learning Rate: 0.000185467
	LOSS [training: 0.027155994702394576 | validation: 0.07881920463907424]
	TIME [epoch: 10.3 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030154263465282393		[learning rate: 0.0001849]
	Learning Rate: 0.000184898
	LOSS [training: 0.030154263465282393 | validation: 0.10577393029280575]
	TIME [epoch: 10.3 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03136659644518342		[learning rate: 0.00018433]
	Learning Rate: 0.000184332
	LOSS [training: 0.03136659644518342 | validation: 0.09442677093528291]
	TIME [epoch: 10.3 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03948663258186426		[learning rate: 0.00018377]
	Learning Rate: 0.000183767
	LOSS [training: 0.03948663258186426 | validation: 0.08790866350798414]
	TIME [epoch: 10.3 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03265767143717342		[learning rate: 0.0001832]
	Learning Rate: 0.000183203
	LOSS [training: 0.03265767143717342 | validation: 0.09416372850805217]
	TIME [epoch: 10.3 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04255569158504673		[learning rate: 0.00018264]
	Learning Rate: 0.000182642
	LOSS [training: 0.04255569158504673 | validation: 0.10479020767587073]
	TIME [epoch: 10.3 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046717647433971485		[learning rate: 0.00018208]
	Learning Rate: 0.000182082
	LOSS [training: 0.046717647433971485 | validation: 0.10923634423072212]
	TIME [epoch: 10.3 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03588148534493619		[learning rate: 0.00018152]
	Learning Rate: 0.000181524
	LOSS [training: 0.03588148534493619 | validation: 0.07866951816283421]
	TIME [epoch: 10.3 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03877622063072768		[learning rate: 0.00018097]
	Learning Rate: 0.000180967
	LOSS [training: 0.03877622063072768 | validation: 0.09968692310598147]
	TIME [epoch: 10.3 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032935659401753525		[learning rate: 0.00018041]
	Learning Rate: 0.000180412
	LOSS [training: 0.032935659401753525 | validation: 0.09225306010793032]
	TIME [epoch: 10.3 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0350739510529101		[learning rate: 0.00017986]
	Learning Rate: 0.000179859
	LOSS [training: 0.0350739510529101 | validation: 0.06272756569984037]
	TIME [epoch: 10.3 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04182968329130325		[learning rate: 0.00017931]
	Learning Rate: 0.000179308
	LOSS [training: 0.04182968329130325 | validation: 0.10002581858094062]
	TIME [epoch: 10.3 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04273712326166168		[learning rate: 0.00017876]
	Learning Rate: 0.000178758
	LOSS [training: 0.04273712326166168 | validation: 0.10062850314825003]
	TIME [epoch: 10.3 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037926464988657906		[learning rate: 0.00017821]
	Learning Rate: 0.00017821
	LOSS [training: 0.037926464988657906 | validation: 0.09768763113741927]
	TIME [epoch: 10.3 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04322499905495394		[learning rate: 0.00017766]
	Learning Rate: 0.000177664
	LOSS [training: 0.04322499905495394 | validation: 0.10408513210784484]
	TIME [epoch: 10.3 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03932029795289517		[learning rate: 0.00017712]
	Learning Rate: 0.00017712
	LOSS [training: 0.03932029795289517 | validation: 0.10197930364649879]
	TIME [epoch: 10.3 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03484549137151949		[learning rate: 0.00017658]
	Learning Rate: 0.000176577
	LOSS [training: 0.03484549137151949 | validation: 0.08844766407003718]
	TIME [epoch: 10.3 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031738239436859834		[learning rate: 0.00017604]
	Learning Rate: 0.000176035
	LOSS [training: 0.031738239436859834 | validation: 0.0903903093984751]
	TIME [epoch: 10.3 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030812887070756457		[learning rate: 0.0001755]
	Learning Rate: 0.000175496
	LOSS [training: 0.030812887070756457 | validation: 0.09285751337086785]
	TIME [epoch: 10.3 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029534778754358837		[learning rate: 0.00017496]
	Learning Rate: 0.000174958
	LOSS [training: 0.029534778754358837 | validation: 0.08349678095551674]
	TIME [epoch: 10.3 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034972570733601493		[learning rate: 0.00017442]
	Learning Rate: 0.000174421
	LOSS [training: 0.034972570733601493 | validation: 0.09838677065381926]
	TIME [epoch: 10.3 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0357212677759384		[learning rate: 0.00017389]
	Learning Rate: 0.000173887
	LOSS [training: 0.0357212677759384 | validation: 0.09210717605080693]
	TIME [epoch: 10.3 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031027941449216563		[learning rate: 0.00017335]
	Learning Rate: 0.000173354
	LOSS [training: 0.031027941449216563 | validation: 0.07637176656537589]
	TIME [epoch: 10.3 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029559574588912774		[learning rate: 0.00017282]
	Learning Rate: 0.000172822
	LOSS [training: 0.029559574588912774 | validation: 0.08993915835027007]
	TIME [epoch: 10.3 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03438701336797362		[learning rate: 0.00017229]
	Learning Rate: 0.000172293
	LOSS [training: 0.03438701336797362 | validation: 0.08523011972499382]
	TIME [epoch: 10.3 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03543329456437716		[learning rate: 0.00017176]
	Learning Rate: 0.000171764
	LOSS [training: 0.03543329456437716 | validation: 0.10428097693849583]
	TIME [epoch: 10.3 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04054729419290566		[learning rate: 0.00017124]
	Learning Rate: 0.000171238
	LOSS [training: 0.04054729419290566 | validation: 0.07363235455154545]
	TIME [epoch: 10.3 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02910704984639559		[learning rate: 0.00017071]
	Learning Rate: 0.000170713
	LOSS [training: 0.02910704984639559 | validation: 0.08448575212018276]
	TIME [epoch: 10.3 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031913019426856704		[learning rate: 0.00017019]
	Learning Rate: 0.00017019
	LOSS [training: 0.031913019426856704 | validation: 0.07220411446108381]
	TIME [epoch: 10.3 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029397587112617158		[learning rate: 0.00016967]
	Learning Rate: 0.000169668
	LOSS [training: 0.029397587112617158 | validation: 0.08616210083302232]
	TIME [epoch: 10.3 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03028695633874725		[learning rate: 0.00016915]
	Learning Rate: 0.000169148
	LOSS [training: 0.03028695633874725 | validation: 0.06931721449900884]
	TIME [epoch: 10.3 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0329205162440709		[learning rate: 0.00016863]
	Learning Rate: 0.000168629
	LOSS [training: 0.0329205162440709 | validation: 0.09463632232779051]
	TIME [epoch: 10.3 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02822163225879255		[learning rate: 0.00016811]
	Learning Rate: 0.000168112
	LOSS [training: 0.02822163225879255 | validation: 0.0873440159230335]
	TIME [epoch: 10.3 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021571561935617392		[learning rate: 0.0001676]
	Learning Rate: 0.000167597
	LOSS [training: 0.021571561935617392 | validation: 0.06701376870719015]
	TIME [epoch: 10.3 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02472191630754413		[learning rate: 0.00016708]
	Learning Rate: 0.000167083
	LOSS [training: 0.02472191630754413 | validation: 0.07422925742761564]
	TIME [epoch: 10.3 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03237986120579248		[learning rate: 0.00016657]
	Learning Rate: 0.000166571
	LOSS [training: 0.03237986120579248 | validation: 0.0808006154168307]
	TIME [epoch: 10.3 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027016210682264757		[learning rate: 0.00016606]
	Learning Rate: 0.000166061
	LOSS [training: 0.027016210682264757 | validation: 0.06769733639800822]
	TIME [epoch: 10.3 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032885433196575393		[learning rate: 0.00016555]
	Learning Rate: 0.000165552
	LOSS [training: 0.032885433196575393 | validation: 0.09423285203291361]
	TIME [epoch: 10.3 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0281477312053852		[learning rate: 0.00016504]
	Learning Rate: 0.000165044
	LOSS [training: 0.0281477312053852 | validation: 0.0684367479569994]
	TIME [epoch: 10.3 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0267156986134608		[learning rate: 0.00016454]
	Learning Rate: 0.000164538
	LOSS [training: 0.0267156986134608 | validation: 0.07915750289166551]
	TIME [epoch: 10.3 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029611248450271854		[learning rate: 0.00016403]
	Learning Rate: 0.000164034
	LOSS [training: 0.029611248450271854 | validation: 0.07629304893009502]
	TIME [epoch: 10.3 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030798590971251982		[learning rate: 0.00016353]
	Learning Rate: 0.000163531
	LOSS [training: 0.030798590971251982 | validation: 0.07816363971265214]
	TIME [epoch: 10.3 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028209701124132864		[learning rate: 0.00016303]
	Learning Rate: 0.00016303
	LOSS [training: 0.028209701124132864 | validation: 0.0641433136657122]
	TIME [epoch: 10.3 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02638291609866687		[learning rate: 0.00016253]
	Learning Rate: 0.00016253
	LOSS [training: 0.02638291609866687 | validation: 0.06373339105561507]
	TIME [epoch: 10.3 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027423661846880297		[learning rate: 0.00016203]
	Learning Rate: 0.000162032
	LOSS [training: 0.027423661846880297 | validation: 0.10147922770448815]
	TIME [epoch: 10.3 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035569662206235364		[learning rate: 0.00016153]
	Learning Rate: 0.000161535
	LOSS [training: 0.035569662206235364 | validation: 0.09468117843962844]
	TIME [epoch: 10.3 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02936274144770975		[learning rate: 0.00016104]
	Learning Rate: 0.00016104
	LOSS [training: 0.02936274144770975 | validation: 0.1000964753169308]
	TIME [epoch: 10.3 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03404225179795292		[learning rate: 0.00016055]
	Learning Rate: 0.000160546
	LOSS [training: 0.03404225179795292 | validation: 0.0999787912797926]
	TIME [epoch: 10.3 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04232185202086179		[learning rate: 0.00016005]
	Learning Rate: 0.000160054
	LOSS [training: 0.04232185202086179 | validation: 0.07177941105715475]
	TIME [epoch: 10.3 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03370116931930381		[learning rate: 0.00015956]
	Learning Rate: 0.000159563
	LOSS [training: 0.03370116931930381 | validation: 0.08789469496544762]
	TIME [epoch: 10.3 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03681541761461484		[learning rate: 0.00015907]
	Learning Rate: 0.000159074
	LOSS [training: 0.03681541761461484 | validation: 0.1030846365994289]
	TIME [epoch: 10.3 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03659434333169088		[learning rate: 0.00015859]
	Learning Rate: 0.000158587
	LOSS [training: 0.03659434333169088 | validation: 0.10218724326776625]
	TIME [epoch: 10.3 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0384390114538771		[learning rate: 0.0001581]
	Learning Rate: 0.000158101
	LOSS [training: 0.0384390114538771 | validation: 0.10348455394350108]
	TIME [epoch: 10.3 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0396705147315613		[learning rate: 0.00015762]
	Learning Rate: 0.000157616
	LOSS [training: 0.0396705147315613 | validation: 0.09098065969070387]
	TIME [epoch: 10.3 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03816638483436727		[learning rate: 0.00015713]
	Learning Rate: 0.000157133
	LOSS [training: 0.03816638483436727 | validation: 0.08735578879832714]
	TIME [epoch: 10.3 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03155227827247118		[learning rate: 0.00015665]
	Learning Rate: 0.000156651
	LOSS [training: 0.03155227827247118 | validation: 0.07431093738176997]
	TIME [epoch: 10.3 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040845434245571		[learning rate: 0.00015617]
	Learning Rate: 0.000156171
	LOSS [training: 0.040845434245571 | validation: 0.07747171832057916]
	TIME [epoch: 10.3 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048187965911654515		[learning rate: 0.00015569]
	Learning Rate: 0.000155692
	LOSS [training: 0.048187965911654515 | validation: 0.11632863140679105]
	TIME [epoch: 10.3 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048179071654522225		[learning rate: 0.00015521]
	Learning Rate: 0.000155215
	LOSS [training: 0.048179071654522225 | validation: 0.09824760984790096]
	TIME [epoch: 10.3 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044800901298500936		[learning rate: 0.00015474]
	Learning Rate: 0.000154739
	LOSS [training: 0.044800901298500936 | validation: 0.10785925418842673]
	TIME [epoch: 10.3 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04750093714879404		[learning rate: 0.00015426]
	Learning Rate: 0.000154265
	LOSS [training: 0.04750093714879404 | validation: 0.08913882512229573]
	TIME [epoch: 10.3 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04703411841891071		[learning rate: 0.00015379]
	Learning Rate: 0.000153792
	LOSS [training: 0.04703411841891071 | validation: 0.1069763086331443]
	TIME [epoch: 10.3 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04305179474794605		[learning rate: 0.00015332]
	Learning Rate: 0.00015332
	LOSS [training: 0.04305179474794605 | validation: 0.07743586931662667]
	TIME [epoch: 10.3 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04153468501077646		[learning rate: 0.00015285]
	Learning Rate: 0.00015285
	LOSS [training: 0.04153468501077646 | validation: 0.07756829457263945]
	TIME [epoch: 10.3 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04284364283602765		[learning rate: 0.00015238]
	Learning Rate: 0.000152382
	LOSS [training: 0.04284364283602765 | validation: 0.10527264921985355]
	TIME [epoch: 10.3 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03886142092710579		[learning rate: 0.00015191]
	Learning Rate: 0.000151915
	LOSS [training: 0.03886142092710579 | validation: 0.08569126949264609]
	TIME [epoch: 10.3 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04381924404767397		[learning rate: 0.00015145]
	Learning Rate: 0.000151449
	LOSS [training: 0.04381924404767397 | validation: 0.09731788336276266]
	TIME [epoch: 10.3 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043924151982405825		[learning rate: 0.00015098]
	Learning Rate: 0.000150985
	LOSS [training: 0.043924151982405825 | validation: 0.09179451337493415]
	TIME [epoch: 10.3 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04480024262812969		[learning rate: 0.00015052]
	Learning Rate: 0.000150522
	LOSS [training: 0.04480024262812969 | validation: 0.10225861947064942]
	TIME [epoch: 10.3 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03935956280353138		[learning rate: 0.00015006]
	Learning Rate: 0.000150061
	LOSS [training: 0.03935956280353138 | validation: 0.1109004673893941]
	TIME [epoch: 10.3 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03981696858554943		[learning rate: 0.0001496]
	Learning Rate: 0.000149601
	LOSS [training: 0.03981696858554943 | validation: 0.09454083001404646]
	TIME [epoch: 10.3 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04703639753333602		[learning rate: 0.00014914]
	Learning Rate: 0.000149142
	LOSS [training: 0.04703639753333602 | validation: 0.11291985623093853]
	TIME [epoch: 10.3 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03720325612852145		[learning rate: 0.00014868]
	Learning Rate: 0.000148685
	LOSS [training: 0.03720325612852145 | validation: 0.08311960333376167]
	TIME [epoch: 10.3 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041002799655840215		[learning rate: 0.00014823]
	Learning Rate: 0.000148229
	LOSS [training: 0.041002799655840215 | validation: 0.07622866303029865]
	TIME [epoch: 10.3 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04662687759871667		[learning rate: 0.00014777]
	Learning Rate: 0.000147775
	LOSS [training: 0.04662687759871667 | validation: 0.09245943430332677]
	TIME [epoch: 10.3 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04232639688889292		[learning rate: 0.00014732]
	Learning Rate: 0.000147322
	LOSS [training: 0.04232639688889292 | validation: 0.07811350923126358]
	TIME [epoch: 10.3 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03739269567501075		[learning rate: 0.00014687]
	Learning Rate: 0.00014687
	LOSS [training: 0.03739269567501075 | validation: 0.08354086606480386]
	TIME [epoch: 10.3 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04299836426132388		[learning rate: 0.00014642]
	Learning Rate: 0.00014642
	LOSS [training: 0.04299836426132388 | validation: 0.10165363482670639]
	TIME [epoch: 10.3 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0351804382832138		[learning rate: 0.00014597]
	Learning Rate: 0.000145971
	LOSS [training: 0.0351804382832138 | validation: 0.10346501676415677]
	TIME [epoch: 10.3 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04172114883696334		[learning rate: 0.00014552]
	Learning Rate: 0.000145524
	LOSS [training: 0.04172114883696334 | validation: 0.10345535751540559]
	TIME [epoch: 10.3 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04083681025924168		[learning rate: 0.00014508]
	Learning Rate: 0.000145077
	LOSS [training: 0.04083681025924168 | validation: 0.08179360618987903]
	TIME [epoch: 10.3 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045644566642809		[learning rate: 0.00014463]
	Learning Rate: 0.000144633
	LOSS [training: 0.045644566642809 | validation: 0.10515419329320957]
	TIME [epoch: 10.3 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04860906046664735		[learning rate: 0.00014419]
	Learning Rate: 0.000144189
	LOSS [training: 0.04860906046664735 | validation: 0.08231462984019437]
	TIME [epoch: 10.3 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049395467550052356		[learning rate: 0.00014375]
	Learning Rate: 0.000143747
	LOSS [training: 0.049395467550052356 | validation: 0.08458102138384792]
	TIME [epoch: 10.3 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046591089097248746		[learning rate: 0.00014331]
	Learning Rate: 0.000143307
	LOSS [training: 0.046591089097248746 | validation: 0.12293563556246043]
	TIME [epoch: 10.3 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04352717441350912		[learning rate: 0.00014287]
	Learning Rate: 0.000142867
	LOSS [training: 0.04352717441350912 | validation: 0.07777098621478741]
	TIME [epoch: 10.3 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04524101804571502		[learning rate: 0.00014243]
	Learning Rate: 0.00014243
	LOSS [training: 0.04524101804571502 | validation: 0.10275895325694233]
	TIME [epoch: 10.3 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04112434771306907		[learning rate: 0.00014199]
	Learning Rate: 0.000141993
	LOSS [training: 0.04112434771306907 | validation: 0.11590910738104208]
	TIME [epoch: 10.3 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04161168341332726		[learning rate: 0.00014156]
	Learning Rate: 0.000141558
	LOSS [training: 0.04161168341332726 | validation: 0.11380302534632973]
	TIME [epoch: 10.3 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045334755056363626		[learning rate: 0.00014112]
	Learning Rate: 0.000141124
	LOSS [training: 0.045334755056363626 | validation: 0.07728768096436604]
	TIME [epoch: 10.3 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04782772708720386		[learning rate: 0.00014069]
	Learning Rate: 0.000140691
	LOSS [training: 0.04782772708720386 | validation: 0.10278781829823253]
	TIME [epoch: 10.3 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05138263932469071		[learning rate: 0.00014026]
	Learning Rate: 0.00014026
	LOSS [training: 0.05138263932469071 | validation: 0.08599068589846058]
	TIME [epoch: 10.3 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051283696322030295		[learning rate: 0.00013983]
	Learning Rate: 0.00013983
	LOSS [training: 0.051283696322030295 | validation: 0.09149806992411891]
	TIME [epoch: 10.3 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05123714406834388		[learning rate: 0.0001394]
	Learning Rate: 0.000139401
	LOSS [training: 0.05123714406834388 | validation: 0.11250903078951208]
	TIME [epoch: 10.3 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04473035135710544		[learning rate: 0.00013897]
	Learning Rate: 0.000138974
	LOSS [training: 0.04473035135710544 | validation: 0.10556939950395737]
	TIME [epoch: 10.3 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04170843108083687		[learning rate: 0.00013855]
	Learning Rate: 0.000138548
	LOSS [training: 0.04170843108083687 | validation: 0.10918835425005081]
	TIME [epoch: 10.3 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04109022331917495		[learning rate: 0.00013812]
	Learning Rate: 0.000138123
	LOSS [training: 0.04109022331917495 | validation: 0.10327363170858872]
	TIME [epoch: 10.3 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039964239782880294		[learning rate: 0.0001377]
	Learning Rate: 0.0001377
	LOSS [training: 0.039964239782880294 | validation: 0.0863921476453483]
	TIME [epoch: 10.3 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04404167319637349		[learning rate: 0.00013728]
	Learning Rate: 0.000137278
	LOSS [training: 0.04404167319637349 | validation: 0.10966826435192499]
	TIME [epoch: 10.3 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04496594017876411		[learning rate: 0.00013686]
	Learning Rate: 0.000136857
	LOSS [training: 0.04496594017876411 | validation: 0.09408508464669113]
	TIME [epoch: 10.3 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04314817946082643		[learning rate: 0.00013644]
	Learning Rate: 0.000136437
	LOSS [training: 0.04314817946082643 | validation: 0.10130397255730862]
	TIME [epoch: 10.3 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04052707710428854		[learning rate: 0.00013602]
	Learning Rate: 0.000136019
	LOSS [training: 0.04052707710428854 | validation: 0.09084453276513937]
	TIME [epoch: 10.3 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04195521691693153		[learning rate: 0.0001356]
	Learning Rate: 0.000135602
	LOSS [training: 0.04195521691693153 | validation: 0.08123467584911379]
	TIME [epoch: 10.3 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04145685939168256		[learning rate: 0.00013519]
	Learning Rate: 0.000135186
	LOSS [training: 0.04145685939168256 | validation: 0.08082262766783671]
	TIME [epoch: 10.3 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03851395458289795		[learning rate: 0.00013477]
	Learning Rate: 0.000134772
	LOSS [training: 0.03851395458289795 | validation: 0.07016754914521718]
	TIME [epoch: 10.3 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042315605199894156		[learning rate: 0.00013436]
	Learning Rate: 0.000134359
	LOSS [training: 0.042315605199894156 | validation: 0.09163309725957478]
	TIME [epoch: 10.3 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038637794163982914		[learning rate: 0.00013395]
	Learning Rate: 0.000133947
	LOSS [training: 0.038637794163982914 | validation: 0.10358426953192496]
	TIME [epoch: 10.3 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04056051941601745		[learning rate: 0.00013354]
	Learning Rate: 0.000133536
	LOSS [training: 0.04056051941601745 | validation: 0.09925709585954355]
	TIME [epoch: 10.3 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03740587712203409		[learning rate: 0.00013313]
	Learning Rate: 0.000133127
	LOSS [training: 0.03740587712203409 | validation: 0.08094661788124415]
	TIME [epoch: 10.3 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03419882915180857		[learning rate: 0.00013272]
	Learning Rate: 0.000132719
	LOSS [training: 0.03419882915180857 | validation: 0.09254765180151366]
	TIME [epoch: 10.3 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03272235470353656		[learning rate: 0.00013231]
	Learning Rate: 0.000132312
	LOSS [training: 0.03272235470353656 | validation: 0.06187558485043006]
	TIME [epoch: 10.3 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03842639287083035		[learning rate: 0.00013191]
	Learning Rate: 0.000131907
	LOSS [training: 0.03842639287083035 | validation: 0.0776171039157833]
	TIME [epoch: 10.3 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03473185908492323		[learning rate: 0.0001315]
	Learning Rate: 0.000131502
	LOSS [training: 0.03473185908492323 | validation: 0.0960190820678006]
	TIME [epoch: 10.3 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03163446163272273		[learning rate: 0.0001311]
	Learning Rate: 0.000131099
	LOSS [training: 0.03163446163272273 | validation: 0.0702130956188596]
	TIME [epoch: 10.3 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03483683236803721		[learning rate: 0.0001307]
	Learning Rate: 0.000130697
	LOSS [training: 0.03483683236803721 | validation: 0.10841507909351879]
	TIME [epoch: 10.3 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03244906290456072		[learning rate: 0.0001303]
	Learning Rate: 0.000130297
	LOSS [training: 0.03244906290456072 | validation: 0.10184077762412205]
	TIME [epoch: 10.3 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033581607564846724		[learning rate: 0.0001299]
	Learning Rate: 0.000129897
	LOSS [training: 0.033581607564846724 | validation: 0.07480584599991286]
	TIME [epoch: 10.3 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036779687327523326		[learning rate: 0.0001295]
	Learning Rate: 0.000129499
	LOSS [training: 0.036779687327523326 | validation: 0.07658427877771141]
	TIME [epoch: 10.3 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033901706851898104		[learning rate: 0.0001291]
	Learning Rate: 0.000129102
	LOSS [training: 0.033901706851898104 | validation: 0.09794275217847204]
	TIME [epoch: 10.3 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033863683690793865		[learning rate: 0.00012871]
	Learning Rate: 0.000128706
	LOSS [training: 0.033863683690793865 | validation: 0.07836151235647064]
	TIME [epoch: 10.3 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03493650298793004		[learning rate: 0.00012831]
	Learning Rate: 0.000128312
	LOSS [training: 0.03493650298793004 | validation: 0.07355062908797201]
	TIME [epoch: 10.3 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03113131431448938		[learning rate: 0.00012792]
	Learning Rate: 0.000127918
	LOSS [training: 0.03113131431448938 | validation: 0.08473245935093618]
	TIME [epoch: 10.3 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03326704171880544		[learning rate: 0.00012753]
	Learning Rate: 0.000127526
	LOSS [training: 0.03326704171880544 | validation: 0.09099255019930823]
	TIME [epoch: 10.3 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03666130801886933		[learning rate: 0.00012714]
	Learning Rate: 0.000127135
	LOSS [training: 0.03666130801886933 | validation: 0.09343875785452527]
	TIME [epoch: 10.3 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03958325262734346		[learning rate: 0.00012675]
	Learning Rate: 0.000126746
	LOSS [training: 0.03958325262734346 | validation: 0.08537886565390311]
	TIME [epoch: 10.3 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037394890045443316		[learning rate: 0.00012636]
	Learning Rate: 0.000126357
	LOSS [training: 0.037394890045443316 | validation: 0.08459772320625929]
	TIME [epoch: 10.3 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031197106432365857		[learning rate: 0.00012597]
	Learning Rate: 0.00012597
	LOSS [training: 0.031197106432365857 | validation: 0.10876476245976903]
	TIME [epoch: 10.3 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039242504974922675		[learning rate: 0.00012558]
	Learning Rate: 0.000125584
	LOSS [training: 0.039242504974922675 | validation: 0.10150069910571934]
	TIME [epoch: 10.3 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03498749157986086		[learning rate: 0.0001252]
	Learning Rate: 0.000125199
	LOSS [training: 0.03498749157986086 | validation: 0.0913167929831551]
	TIME [epoch: 10.3 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032533393769018974		[learning rate: 0.00012481]
	Learning Rate: 0.000124815
	LOSS [training: 0.032533393769018974 | validation: 0.10603469363503358]
	TIME [epoch: 10.3 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031950945054456704		[learning rate: 0.00012443]
	Learning Rate: 0.000124432
	LOSS [training: 0.031950945054456704 | validation: 0.07987205904371969]
	TIME [epoch: 10.3 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037496432361672716		[learning rate: 0.00012405]
	Learning Rate: 0.000124051
	LOSS [training: 0.037496432361672716 | validation: 0.07545961935727837]
	TIME [epoch: 10.3 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03587800777834642		[learning rate: 0.00012367]
	Learning Rate: 0.000123671
	LOSS [training: 0.03587800777834642 | validation: 0.07817736929436842]
	TIME [epoch: 10.3 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03684109291172094		[learning rate: 0.00012329]
	Learning Rate: 0.000123292
	LOSS [training: 0.03684109291172094 | validation: 0.07824127432661737]
	TIME [epoch: 10.2 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03958329406408094		[learning rate: 0.00012291]
	Learning Rate: 0.000122914
	LOSS [training: 0.03958329406408094 | validation: 0.0958657806033005]
	TIME [epoch: 10.3 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03456034153501007		[learning rate: 0.00012254]
	Learning Rate: 0.000122537
	LOSS [training: 0.03456034153501007 | validation: 0.09002442763446654]
	TIME [epoch: 10.3 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03254829068050232		[learning rate: 0.00012216]
	Learning Rate: 0.000122161
	LOSS [training: 0.03254829068050232 | validation: 0.0757775399871466]
	TIME [epoch: 10.2 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02817964441213857		[learning rate: 0.00012179]
	Learning Rate: 0.000121787
	LOSS [training: 0.02817964441213857 | validation: 0.09756708906973058]
	TIME [epoch: 10.3 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0335313143834146		[learning rate: 0.00012141]
	Learning Rate: 0.000121413
	LOSS [training: 0.0335313143834146 | validation: 0.07886965860711383]
	TIME [epoch: 10.3 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031202225594886168		[learning rate: 0.00012104]
	Learning Rate: 0.000121041
	LOSS [training: 0.031202225594886168 | validation: 0.09549461239674933]
	TIME [epoch: 10.3 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035423979030529344		[learning rate: 0.00012067]
	Learning Rate: 0.00012067
	LOSS [training: 0.035423979030529344 | validation: 0.07349028941753764]
	TIME [epoch: 10.3 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03438360658693091		[learning rate: 0.0001203]
	Learning Rate: 0.0001203
	LOSS [training: 0.03438360658693091 | validation: 0.08859210362779887]
	TIME [epoch: 10.3 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03125340155434469		[learning rate: 0.00011993]
	Learning Rate: 0.000119932
	LOSS [training: 0.03125340155434469 | validation: 0.09488824644976497]
	TIME [epoch: 10.3 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029110149794724243		[learning rate: 0.00011956]
	Learning Rate: 0.000119564
	LOSS [training: 0.029110149794724243 | validation: 0.10172624799357838]
	TIME [epoch: 10.3 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03195972860404391		[learning rate: 0.0001192]
	Learning Rate: 0.000119197
	LOSS [training: 0.03195972860404391 | validation: 0.08847728447574134]
	TIME [epoch: 10.3 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028994995138403305		[learning rate: 0.00011883]
	Learning Rate: 0.000118832
	LOSS [training: 0.028994995138403305 | validation: 0.08521488958661796]
	TIME [epoch: 10.3 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036074442185280886		[learning rate: 0.00011847]
	Learning Rate: 0.000118468
	LOSS [training: 0.036074442185280886 | validation: 0.07351918338036073]
	TIME [epoch: 10.3 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03365458992788979		[learning rate: 0.0001181]
	Learning Rate: 0.000118105
	LOSS [training: 0.03365458992788979 | validation: 0.08002287407192339]
	TIME [epoch: 10.3 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03304883421725857		[learning rate: 0.00011774]
	Learning Rate: 0.000117743
	LOSS [training: 0.03304883421725857 | validation: 0.0720165467160644]
	TIME [epoch: 10.3 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03279631566635358		[learning rate: 0.00011738]
	Learning Rate: 0.000117382
	LOSS [training: 0.03279631566635358 | validation: 0.07178616914795745]
	TIME [epoch: 10.3 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031504793011553775		[learning rate: 0.00011702]
	Learning Rate: 0.000117022
	LOSS [training: 0.031504793011553775 | validation: 0.09648539290506886]
	TIME [epoch: 10.3 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027517895038277167		[learning rate: 0.00011666]
	Learning Rate: 0.000116663
	LOSS [training: 0.027517895038277167 | validation: 0.07092216770576812]
	TIME [epoch: 10.3 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03015376884596998		[learning rate: 0.00011631]
	Learning Rate: 0.000116305
	LOSS [training: 0.03015376884596998 | validation: 0.10415170008675549]
	TIME [epoch: 10.3 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030703221868711127		[learning rate: 0.00011595]
	Learning Rate: 0.000115949
	LOSS [training: 0.030703221868711127 | validation: 0.08699121547695236]
	TIME [epoch: 10.3 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03308341281665104		[learning rate: 0.00011559]
	Learning Rate: 0.000115593
	LOSS [training: 0.03308341281665104 | validation: 0.07742394566131205]
	TIME [epoch: 10.3 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032649114660451416		[learning rate: 0.00011524]
	Learning Rate: 0.000115239
	LOSS [training: 0.032649114660451416 | validation: 0.09167957336429952]
	TIME [epoch: 10.3 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02915851187512783		[learning rate: 0.00011489]
	Learning Rate: 0.000114886
	LOSS [training: 0.02915851187512783 | validation: 0.07267222208129899]
	TIME [epoch: 10.3 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03265544514980662		[learning rate: 0.00011453]
	Learning Rate: 0.000114534
	LOSS [training: 0.03265544514980662 | validation: 0.09076923515051157]
	TIME [epoch: 10.3 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03510226193337529		[learning rate: 0.00011418]
	Learning Rate: 0.000114183
	LOSS [training: 0.03510226193337529 | validation: 0.08074458377313821]
	TIME [epoch: 10.3 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031494065258656515		[learning rate: 0.00011383]
	Learning Rate: 0.000113833
	LOSS [training: 0.031494065258656515 | validation: 0.09888587848153735]
	TIME [epoch: 10.3 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03300567374146532		[learning rate: 0.00011348]
	Learning Rate: 0.000113484
	LOSS [training: 0.03300567374146532 | validation: 0.09383953234235293]
	TIME [epoch: 10.3 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032391285957566886		[learning rate: 0.00011314]
	Learning Rate: 0.000113136
	LOSS [training: 0.032391285957566886 | validation: 0.07432069011387314]
	TIME [epoch: 10.3 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03018302647376402		[learning rate: 0.00011279]
	Learning Rate: 0.000112789
	LOSS [training: 0.03018302647376402 | validation: 0.07912254838062233]
	TIME [epoch: 10.3 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028995695386699973		[learning rate: 0.00011244]
	Learning Rate: 0.000112443
	LOSS [training: 0.028995695386699973 | validation: 0.09533050368389386]
	TIME [epoch: 10.3 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03579568712318339		[learning rate: 0.0001121]
	Learning Rate: 0.000112099
	LOSS [training: 0.03579568712318339 | validation: 0.09421081464017451]
	TIME [epoch: 10.3 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034019697203450924		[learning rate: 0.00011175]
	Learning Rate: 0.000111755
	LOSS [training: 0.034019697203450924 | validation: 0.08888949943656993]
	TIME [epoch: 10.3 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03596258530699378		[learning rate: 0.00011141]
	Learning Rate: 0.000111412
	LOSS [training: 0.03596258530699378 | validation: 0.09448696776570426]
	TIME [epoch: 10.3 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02923101421757559		[learning rate: 0.00011107]
	Learning Rate: 0.000111071
	LOSS [training: 0.02923101421757559 | validation: 0.09006592451784289]
	TIME [epoch: 10.3 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029438687043598966		[learning rate: 0.00011073]
	Learning Rate: 0.00011073
	LOSS [training: 0.029438687043598966 | validation: 0.07080471399398708]
	TIME [epoch: 10.3 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030116560319431607		[learning rate: 0.00011039]
	Learning Rate: 0.000110391
	LOSS [training: 0.030116560319431607 | validation: 0.09025354114974135]
	TIME [epoch: 10.2 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03211263867974773		[learning rate: 0.00011005]
	Learning Rate: 0.000110053
	LOSS [training: 0.03211263867974773 | validation: 0.07423962794018714]
	TIME [epoch: 10.3 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04290629003924963		[learning rate: 0.00010972]
	Learning Rate: 0.000109715
	LOSS [training: 0.04290629003924963 | validation: 0.06317379115657648]
	TIME [epoch: 10.3 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03130151449358969		[learning rate: 0.00010938]
	Learning Rate: 0.000109379
	LOSS [training: 0.03130151449358969 | validation: 0.08168410788856552]
	TIME [epoch: 10.3 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03250257439452019		[learning rate: 0.00010904]
	Learning Rate: 0.000109044
	LOSS [training: 0.03250257439452019 | validation: 0.09482113139630949]
	TIME [epoch: 10.3 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03445986166480367		[learning rate: 0.00010871]
	Learning Rate: 0.000108709
	LOSS [training: 0.03445986166480367 | validation: 0.08883818751952886]
	TIME [epoch: 10.3 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02734002366058379		[learning rate: 0.00010838]
	Learning Rate: 0.000108376
	LOSS [training: 0.02734002366058379 | validation: 0.09826647763494128]
	TIME [epoch: 10.2 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035165464064700405		[learning rate: 0.00010804]
	Learning Rate: 0.000108044
	LOSS [training: 0.035165464064700405 | validation: 0.0900111941571593]
	TIME [epoch: 10.2 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029064025275324458		[learning rate: 0.00010771]
	Learning Rate: 0.000107713
	LOSS [training: 0.029064025275324458 | validation: 0.1004305519592936]
	TIME [epoch: 10.3 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03087731789628111		[learning rate: 0.00010738]
	Learning Rate: 0.000107382
	LOSS [training: 0.03087731789628111 | validation: 0.0916543319057951]
	TIME [epoch: 10.3 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03021558477865428		[learning rate: 0.00010705]
	Learning Rate: 0.000107053
	LOSS [training: 0.03021558477865428 | validation: 0.07259407888602366]
	TIME [epoch: 10.3 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03325099627795511		[learning rate: 0.00010673]
	Learning Rate: 0.000106725
	LOSS [training: 0.03325099627795511 | validation: 0.08133846154838555]
	TIME [epoch: 10.3 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03242148261238341		[learning rate: 0.0001064]
	Learning Rate: 0.000106398
	LOSS [training: 0.03242148261238341 | validation: 0.09091223664546462]
	TIME [epoch: 10.3 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03897488293655034		[learning rate: 0.00010607]
	Learning Rate: 0.000106072
	LOSS [training: 0.03897488293655034 | validation: 0.06920107115811586]
	TIME [epoch: 10.3 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03505815460851619		[learning rate: 0.00010575]
	Learning Rate: 0.000105747
	LOSS [training: 0.03505815460851619 | validation: 0.10671094973070037]
	TIME [epoch: 10.3 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033670226048949634		[learning rate: 0.00010542]
	Learning Rate: 0.000105423
	LOSS [training: 0.033670226048949634 | validation: 0.07678606119672138]
	TIME [epoch: 10.3 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0368367261669717		[learning rate: 0.0001051]
	Learning Rate: 0.000105099
	LOSS [training: 0.0368367261669717 | validation: 0.09089436541761028]
	TIME [epoch: 10.3 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032782339027358054		[learning rate: 0.00010478]
	Learning Rate: 0.000104777
	LOSS [training: 0.032782339027358054 | validation: 0.10203024740717377]
	TIME [epoch: 10.3 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026218305274074667		[learning rate: 0.00010446]
	Learning Rate: 0.000104456
	LOSS [training: 0.026218305274074667 | validation: 0.09217060949163344]
	TIME [epoch: 10.3 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027619933945390585		[learning rate: 0.00010414]
	Learning Rate: 0.000104136
	LOSS [training: 0.027619933945390585 | validation: 0.07560920146240399]
	TIME [epoch: 10.3 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03450997627081055		[learning rate: 0.00010382]
	Learning Rate: 0.000103817
	LOSS [training: 0.03450997627081055 | validation: 0.09310598771556902]
	TIME [epoch: 10.3 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03133204945999251		[learning rate: 0.0001035]
	Learning Rate: 0.000103498
	LOSS [training: 0.03133204945999251 | validation: 0.07156869326829796]
	TIME [epoch: 10.3 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03231702772922796		[learning rate: 0.00010318]
	Learning Rate: 0.000103181
	LOSS [training: 0.03231702772922796 | validation: 0.09822183964607774]
	TIME [epoch: 10.3 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03468675167175433		[learning rate: 0.00010286]
	Learning Rate: 0.000102865
	LOSS [training: 0.03468675167175433 | validation: 0.0825358896912909]
	TIME [epoch: 10.3 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03146028524438752		[learning rate: 0.00010255]
	Learning Rate: 0.000102549
	LOSS [training: 0.03146028524438752 | validation: 0.08343693734024933]
	TIME [epoch: 10.3 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03579291708764034		[learning rate: 0.00010224]
	Learning Rate: 0.000102235
	LOSS [training: 0.03579291708764034 | validation: 0.06998590473687398]
	TIME [epoch: 10.3 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036278789765483224		[learning rate: 0.00010192]
	Learning Rate: 0.000101922
	LOSS [training: 0.036278789765483224 | validation: 0.06537133583900319]
	TIME [epoch: 10.3 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03142472478163652		[learning rate: 0.00010161]
	Learning Rate: 0.000101609
	LOSS [training: 0.03142472478163652 | validation: 0.0706087152101782]
	TIME [epoch: 10.3 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03543798612438437		[learning rate: 0.0001013]
	Learning Rate: 0.000101298
	LOSS [training: 0.03543798612438437 | validation: 0.06176747737225724]
	TIME [epoch: 10.3 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03475205640642255		[learning rate: 0.00010099]
	Learning Rate: 0.000100987
	LOSS [training: 0.03475205640642255 | validation: 0.07462130433176967]
	TIME [epoch: 10.3 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036044953673609076		[learning rate: 0.00010068]
	Learning Rate: 0.000100678
	LOSS [training: 0.036044953673609076 | validation: 0.09738779106338459]
	TIME [epoch: 10.3 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03055880207419693		[learning rate: 0.00010037]
	Learning Rate: 0.000100369
	LOSS [training: 0.03055880207419693 | validation: 0.07766006877563744]
	TIME [epoch: 10.3 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03449473339515029		[learning rate: 0.00010006]
	Learning Rate: 0.000100061
	LOSS [training: 0.03449473339515029 | validation: 0.08429216076868544]
	TIME [epoch: 10.3 sec]
Finished training in 20647.573 seconds.
