Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r5', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3023977210

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.239456221503353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.239456221503353 | validation: 7.774219362604927]
	TIME [epoch: 98.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.647880242156634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.647880242156634 | validation: 7.661686468190871]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.222604505126114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.222604505126114 | validation: 6.626412940617675]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.966194833629996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.966194833629996 | validation: 6.030147712746033]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.46301126702105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.46301126702105 | validation: 5.417598227395019]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8498325488877745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8498325488877745 | validation: 4.757636134902505]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.398750633325925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.398750633325925 | validation: 4.407582632769772]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.097044570660887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.097044570660887 | validation: 4.066460606747591]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7686098715621985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7686098715621985 | validation: 3.979092564149183]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.689452619602673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.689452619602673 | validation: 3.942151144442107]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6745912652793344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6745912652793344 | validation: 3.8674639438559133]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.58615696970277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.58615696970277 | validation: 4.032602773953318]
	TIME [epoch: 11.6 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.620510649501858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.620510649501858 | validation: 4.073047885516222]
	TIME [epoch: 11.6 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7664065793749226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7664065793749226 | validation: 3.882961547986612]
	TIME [epoch: 11.5 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.462242608350874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.462242608350874 | validation: 3.6803830900717163]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.428403592617406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.428403592617406 | validation: 3.5803275169636017]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3843904376856546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3843904376856546 | validation: 3.57411847196289]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.322808188160842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.322808188160842 | validation: 3.4693655643646175]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4170900701197797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4170900701197797 | validation: 3.564732508931491]
	TIME [epoch: 11.6 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.31784271951672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.31784271951672 | validation: 3.5211457831433255]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1519715874116185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1519715874116185 | validation: 3.7056652177528746]
	TIME [epoch: 11.5 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227128099976275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.227128099976275 | validation: 2.9921697060730863]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7778102285466097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7778102285466097 | validation: 3.191125290700295]
	TIME [epoch: 11.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.713732289789342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.713732289789342 | validation: 2.617445850131532]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.627769831634364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.627769831634364 | validation: 3.195483403965101]
	TIME [epoch: 11.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.652708746389966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.652708746389966 | validation: 2.4801560961993605]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3855779366607237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3855779366607237 | validation: 2.1702848607224]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.94170946319184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.94170946319184 | validation: 3.516223666346956]
	TIME [epoch: 11.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3541031083591655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3541031083591655 | validation: 2.454785336378219]
	TIME [epoch: 11.6 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4291048971052014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4291048971052014 | validation: 2.333217141657612]
	TIME [epoch: 11.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4652420308433864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4652420308433864 | validation: 2.269864945312702]
	TIME [epoch: 11.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1677307379483377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1677307379483377 | validation: 2.067486371318008]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9255416813078106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9255416813078106 | validation: 1.8117771440581214]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9439562778178878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9439562778178878 | validation: 2.019861025675801]
	TIME [epoch: 11.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7219262261065265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7219262261065265 | validation: 2.0528041684734175]
	TIME [epoch: 11.6 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7532378442706538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7532378442706538 | validation: 1.5880798451126408]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5260241480125996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5260241480125996 | validation: 1.3022179973165688]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3193571985342836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3193571985342836 | validation: 1.7761377379465757]
	TIME [epoch: 11.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.796610030124885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.796610030124885 | validation: 1.7964724504124838]
	TIME [epoch: 11.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5755973738337594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5755973738337594 | validation: 1.087942048683678]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0614183818652498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0614183818652498 | validation: 0.9597572807902974]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0757640537417026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0757640537417026 | validation: 1.2799121650160936]
	TIME [epoch: 11.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1473995494564422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1473995494564422 | validation: 0.9956265215128878]
	TIME [epoch: 11.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.768307933604281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.768307933604281 | validation: 3.3602977300197154]
	TIME [epoch: 11.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7325559164055324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7325559164055324 | validation: 3.2647063150063604]
	TIME [epoch: 11.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.606705131419617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.606705131419617 | validation: 3.059328551814331]
	TIME [epoch: 11.6 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5077220515547007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5077220515547007 | validation: 3.165789556664644]
	TIME [epoch: 11.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4220085421696753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4220085421696753 | validation: 2.924795647714751]
	TIME [epoch: 11.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0310065836305875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0310065836305875 | validation: 1.31052745926294]
	TIME [epoch: 11.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5778741208104625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5778741208104625 | validation: 1.4677270652296346]
	TIME [epoch: 11.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2282784294950613		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.2282784294950613 | validation: 1.4104487008526625]
	TIME [epoch: 11.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.254316495913801		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.254316495913801 | validation: 0.9668035810078276]
	TIME [epoch: 11.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.227168122630376		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.227168122630376 | validation: 1.1824072808067039]
	TIME [epoch: 11.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0826790125133792		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.0826790125133792 | validation: 1.047189959327032]
	TIME [epoch: 11.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0883914232997975		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.0883914232997975 | validation: 0.9463030027391264]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.127626839897944		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.127626839897944 | validation: 0.9109655890491771]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8708864985301975		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.8708864985301975 | validation: 0.8282728549897889]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2026240805308814		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.2026240805308814 | validation: 1.2998466917610154]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1703912291801077		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.1703912291801077 | validation: 1.1428669143128503]
	TIME [epoch: 11.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.226547457182106		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.226547457182106 | validation: 1.5535235191606336]
	TIME [epoch: 11.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4295888300029684		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.4295888300029684 | validation: 1.4235143045672365]
	TIME [epoch: 11.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0418987256017893		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.0418987256017893 | validation: 0.842436039082994]
	TIME [epoch: 11.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8076678559895729		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.8076678559895729 | validation: 0.9648446675442577]
	TIME [epoch: 11.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9027032324133071		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.9027032324133071 | validation: 0.7821199560297477]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8159934750799737		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.8159934750799737 | validation: 0.8341793367163124]
	TIME [epoch: 11.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.979557029708852		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.979557029708852 | validation: 1.0415389823786327]
	TIME [epoch: 11.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4593310173622285		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.4593310173622285 | validation: 0.8651951934909922]
	TIME [epoch: 11.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8333226771151381		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.8333226771151381 | validation: 0.7879494637495802]
	TIME [epoch: 11.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9685027504967524		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.9685027504967524 | validation: 0.779108534901352]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7288805452691896		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.7288805452691896 | validation: 0.6732043919793077]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6736696013083411		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.6736696013083411 | validation: 0.7637289904967678]
	TIME [epoch: 11.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8938685632496456		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.8938685632496456 | validation: 0.7322167087916822]
	TIME [epoch: 11.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7734243686609069		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.7734243686609069 | validation: 2.616434308427772]
	TIME [epoch: 11.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0419854176031333		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.0419854176031333 | validation: 0.720504172563857]
	TIME [epoch: 11.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.738115850302975		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.738115850302975 | validation: 0.8119145883211536]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879945148615546		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.6879945148615546 | validation: 0.6785810731353652]
	TIME [epoch: 11.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.170735652650765		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.170735652650765 | validation: 0.8012181925631188]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8044577173206279		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.8044577173206279 | validation: 0.7140675220469614]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7402697335150211		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.7402697335150211 | validation: 0.7189002322402326]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7849265667401735		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.7849265667401735 | validation: 0.9872087390664747]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8173271509038349		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.8173271509038349 | validation: 3.1785470826715154]
	TIME [epoch: 11.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6917399377202713		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.6917399377202713 | validation: 3.3024103596814753]
	TIME [epoch: 11.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.595065279113402		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.595065279113402 | validation: 3.217082453095758]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5491926982926953		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.5491926982926953 | validation: 3.018394954731357]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4800287865501742		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.4800287865501742 | validation: 2.946974685505377]
	TIME [epoch: 11.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3742179765058626		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.3742179765058626 | validation: 2.8008192358459327]
	TIME [epoch: 11.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.707725052076124		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.707725052076124 | validation: 1.331627366247251]
	TIME [epoch: 11.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1772589850585637		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.1772589850585637 | validation: 0.9230066694247668]
	TIME [epoch: 11.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0984919692889956		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.0984919692889956 | validation: 1.0057138301546318]
	TIME [epoch: 11.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0555395538941512		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.0555395538941512 | validation: 1.1140664455017972]
	TIME [epoch: 11.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9000021705720125		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.9000021705720125 | validation: 0.7385317787610319]
	TIME [epoch: 11.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7918477177304334		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.7918477177304334 | validation: 3.006394207805615]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9651442956982228		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.9651442956982228 | validation: 1.3327404078560126]
	TIME [epoch: 11.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9399598779228642		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.9399598779228642 | validation: 0.9921343245088348]
	TIME [epoch: 11.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9296989370524886		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.9296989370524886 | validation: 2.170421928139425]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.325390973245017		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.325390973245017 | validation: 0.7296429853173058]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8003622751168007		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.8003622751168007 | validation: 0.8321888571478073]
	TIME [epoch: 11.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7474055464409908		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.7474055464409908 | validation: 0.800233436256703]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.155071681400319		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.155071681400319 | validation: 0.7119123354289266]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8035072973908398		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.8035072973908398 | validation: 0.6792148587759611]
	TIME [epoch: 11.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7559695578583838		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.7559695578583838 | validation: 0.9700905403852388]
	TIME [epoch: 11.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7864711433717366		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.7864711433717366 | validation: 0.7541391382144528]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.741435509434858		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.741435509434858 | validation: 0.7340645580794916]
	TIME [epoch: 11.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8108568832515239		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.8108568832515239 | validation: 0.6549169591394847]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963307982174222		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.6963307982174222 | validation: 0.7531952345790627]
	TIME [epoch: 11.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7406761325064939		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.7406761325064939 | validation: 0.7917087913560289]
	TIME [epoch: 11.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7746569579623697		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.7746569579623697 | validation: 0.8222312208445454]
	TIME [epoch: 11.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7138800258385377		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.7138800258385377 | validation: 0.7418102060923221]
	TIME [epoch: 11.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6703037754256929		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.6703037754256929 | validation: 0.7416510190910782]
	TIME [epoch: 11.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8842744722048814		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.8842744722048814 | validation: 0.8546080643752763]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7563100330377899		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.7563100330377899 | validation: 0.7463024039018535]
	TIME [epoch: 11.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7375594162155786		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.7375594162155786 | validation: 0.5863356563593153]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.655590724750841		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.655590724750841 | validation: 1.355329993363585]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.809646624827379		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.809646624827379 | validation: 3.8483948213112695]
	TIME [epoch: 11.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.037959369561888		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.037959369561888 | validation: 3.368174934491451]
	TIME [epoch: 11.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.770761261330608		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.770761261330608 | validation: 3.1703960997467]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6225251694013907		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.6225251694013907 | validation: 3.08024089489831]
	TIME [epoch: 11.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.540531084902751		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.540531084902751 | validation: 3.0183781957755187]
	TIME [epoch: 11.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.505048762518922		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.505048762518922 | validation: 3.038288790219904]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4813144566139256		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.4813144566139256 | validation: 2.9367510810860757]
	TIME [epoch: 11.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3701630582746085		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.3701630582746085 | validation: 2.774754943564224]
	TIME [epoch: 11.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0988858657492164		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.0988858657492164 | validation: 0.9709121447142108]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0984710172081762		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.0984710172081762 | validation: 0.8958158182827348]
	TIME [epoch: 11.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02031292890585		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.02031292890585 | validation: 1.094954762493682]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8130888389929054		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.8130888389929054 | validation: 0.6641675378657527]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6650018250764058		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.6650018250764058 | validation: 0.6237638159037038]
	TIME [epoch: 11.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7671807138215649		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.7671807138215649 | validation: 0.6552733842764908]
	TIME [epoch: 11.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6918444108546917		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.6918444108546917 | validation: 0.5840085526699291]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6875102922199007		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.6875102922199007 | validation: 0.9054400848298514]
	TIME [epoch: 11.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9189481647940719		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.9189481647940719 | validation: 0.609029645912545]
	TIME [epoch: 11.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7312961656925799		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.7312961656925799 | validation: 0.8515048580349037]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7574312150531526		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.7574312150531526 | validation: 0.6505312164623607]
	TIME [epoch: 11.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5823203138921101		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.5823203138921101 | validation: 0.8949375046404695]
	TIME [epoch: 11.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6084095329031154		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.6084095329031154 | validation: 0.5730922817516608]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6369908114268104		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.6369908114268104 | validation: 0.5241386025862161]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5587418956384596		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.5587418956384596 | validation: 0.5259328868972888]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5829269556598401		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.5829269556598401 | validation: 0.7647969354188624]
	TIME [epoch: 11.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6817613505875464		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.6817613505875464 | validation: 0.9156687375298945]
	TIME [epoch: 11.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865402049454445		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.6865402049454445 | validation: 0.663429669476546]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.77573459710555		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.77573459710555 | validation: 0.790702671288396]
	TIME [epoch: 11.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6699427180768185		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.6699427180768185 | validation: 0.5390920563542769]
	TIME [epoch: 11.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6515871641359497		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.6515871641359497 | validation: 0.7172312053860571]
	TIME [epoch: 11.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030926917767883		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.7030926917767883 | validation: 0.6400484773184762]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9226173114619668		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.9226173114619668 | validation: 0.6432568727510793]
	TIME [epoch: 11.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7401819838824625		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.7401819838824625 | validation: 0.7348651593225979]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7679894146059433		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.7679894146059433 | validation: 0.7261410161595703]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5464744973184432		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.5464744973184432 | validation: 0.5889739555084862]
	TIME [epoch: 11.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5596603047532358		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.5596603047532358 | validation: 0.5683664246381073]
	TIME [epoch: 11.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4928360675238766		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.4928360675238766 | validation: 0.675175664663914]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5935493920455451		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.5935493920455451 | validation: 0.4717697311953664]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5883728342700468		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.5883728342700468 | validation: 0.6402099510117977]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5176674128073836		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.5176674128073836 | validation: 0.5962719673274426]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6721109645965404		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.6721109645965404 | validation: 0.6306980728050606]
	TIME [epoch: 11.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5132525769918561		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.5132525769918561 | validation: 0.5560792553179111]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5459538337533101		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.5459538337533101 | validation: 0.4381564626518151]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.548043975421507		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.548043975421507 | validation: 0.44116778840062026]
	TIME [epoch: 11.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44658727494001776		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.44658727494001776 | validation: 0.548507914595155]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199060317374431		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.5199060317374431 | validation: 0.6904702633760958]
	TIME [epoch: 11.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5247071047641078		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.5247071047641078 | validation: 0.8985799543458337]
	TIME [epoch: 11.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6058593854117201		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.6058593854117201 | validation: 0.45187336361376906]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4555704609548386		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.4555704609548386 | validation: 1.2591711656788054]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7270236173419466		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.7270236173419466 | validation: 0.48931021108260536]
	TIME [epoch: 11.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41441460756739207		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.41441460756739207 | validation: 0.47699906191473174]
	TIME [epoch: 11.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41284759483647304		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.41284759483647304 | validation: 0.3903947692086571]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35603094356353115		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.35603094356353115 | validation: 0.667928182188294]
	TIME [epoch: 11.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8463676077581808		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.8463676077581808 | validation: 1.2158489807528052]
	TIME [epoch: 11.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216263961373073		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.7216263961373073 | validation: 0.46936664994310634]
	TIME [epoch: 11.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5137519758710192		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.5137519758710192 | validation: 0.43029944562627975]
	TIME [epoch: 11.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40738099807166095		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.40738099807166095 | validation: 0.4738083194358764]
	TIME [epoch: 11.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4629873518004923		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.4629873518004923 | validation: 0.6411982652802535]
	TIME [epoch: 11.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49697819370469665		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.49697819370469665 | validation: 0.4753189254431544]
	TIME [epoch: 11.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38942791002920313		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.38942791002920313 | validation: 0.4150286474891369]
	TIME [epoch: 11.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3477581900193045		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.3477581900193045 | validation: 0.5596913637556561]
	TIME [epoch: 11.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46691854379247627		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.46691854379247627 | validation: 0.6230420112751324]
	TIME [epoch: 11.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4747800689390237		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.4747800689390237 | validation: 0.32178235021687845]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35870043322036527		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.35870043322036527 | validation: 0.40379595213438046]
	TIME [epoch: 11.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5096220912157506		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.5096220912157506 | validation: 0.6018756547305862]
	TIME [epoch: 11.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5856848041292005		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.5856848041292005 | validation: 0.2939531328874018]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846575016567067		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.6846575016567067 | validation: 1.7410008397721495]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4668979599617327		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.4668979599617327 | validation: 0.5488800095208537]
	TIME [epoch: 11.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7823881614740393		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.7823881614740393 | validation: 0.4395358325309019]
	TIME [epoch: 11.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3760449775718614		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.3760449775718614 | validation: 0.39644670740732835]
	TIME [epoch: 11.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3778149477121313		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.3778149477121313 | validation: 0.49206983810552857]
	TIME [epoch: 11.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44053196368240616		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.44053196368240616 | validation: 0.48774779225284615]
	TIME [epoch: 11.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4723615627024957		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.4723615627024957 | validation: 0.33842189680809914]
	TIME [epoch: 11.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3743267767627166		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.3743267767627166 | validation: 0.344248650305656]
	TIME [epoch: 11.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41652367886709885		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.41652367886709885 | validation: 0.4621523001774848]
	TIME [epoch: 11.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4288766730617108		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.4288766730617108 | validation: 0.3824030394005554]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.497924533487071		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.497924533487071 | validation: 0.3260130305133568]
	TIME [epoch: 11.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40652196547678443		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.40652196547678443 | validation: 0.79654807286928]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6090168672140752		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.6090168672140752 | validation: 0.3777595083685109]
	TIME [epoch: 11.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3502489940236814		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.3502489940236814 | validation: 0.257271218611072]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.266366525821817		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.266366525821817 | validation: 0.2963226145171109]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32559532716825473		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.32559532716825473 | validation: 0.3070373465785553]
	TIME [epoch: 11.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3039392194756212		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.3039392194756212 | validation: 0.2770349770300247]
	TIME [epoch: 11.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32065952473486203		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.32065952473486203 | validation: 0.27355903744576165]
	TIME [epoch: 11.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2694443114288395		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.2694443114288395 | validation: 0.28057357429749313]
	TIME [epoch: 11.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3285828150570946		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.3285828150570946 | validation: 0.359515730760076]
	TIME [epoch: 11.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3370033351815221		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.3370033351815221 | validation: 0.4378987132801489]
	TIME [epoch: 11.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3245999388186295		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.3245999388186295 | validation: 0.28243140238796]
	TIME [epoch: 11.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28828718358474886		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.28828718358474886 | validation: 0.44044173018172744]
	TIME [epoch: 11.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8896769088553361		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.8896769088553361 | validation: 1.0945965002753393]
	TIME [epoch: 11.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.515253727295594		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.515253727295594 | validation: 0.3826390247639071]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2812653333264125		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.2812653333264125 | validation: 0.3062475988986438]
	TIME [epoch: 11.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28148461713685213		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.28148461713685213 | validation: 0.24012473034243947]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33584101174731257		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.33584101174731257 | validation: 0.2584031569944056]
	TIME [epoch: 11.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2941977118304365		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.2941977118304365 | validation: 0.234415102237475]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22554160273403856		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.22554160273403856 | validation: 0.2637441789554923]
	TIME [epoch: 11.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31666977202558183		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.31666977202558183 | validation: 0.44585913018060314]
	TIME [epoch: 11.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6033359757847004		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.6033359757847004 | validation: 0.3467206447499116]
	TIME [epoch: 11.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491841735176418		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.3491841735176418 | validation: 0.34797648578305795]
	TIME [epoch: 11.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1833283904648221		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.1833283904648221 | validation: 0.40638246364362784]
	TIME [epoch: 11.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4221195323418743		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.4221195323418743 | validation: 0.24865136242745223]
	TIME [epoch: 11.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27073103730616227		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.27073103730616227 | validation: 0.3674876716593819]
	TIME [epoch: 11.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22307182652379542		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.22307182652379542 | validation: 0.2178271239265031]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17558750297847625		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.17558750297847625 | validation: 0.4830251143771627]
	TIME [epoch: 11.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27621922698882373		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.27621922698882373 | validation: 0.16977201640118875]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2079573285814113		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.2079573285814113 | validation: 0.24831410284734934]
	TIME [epoch: 11.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24401644424005314		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.24401644424005314 | validation: 0.39609923557756327]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24335859943951946		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.24335859943951946 | validation: 0.2127342515973377]
	TIME [epoch: 11.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26253292140510215		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.26253292140510215 | validation: 0.25797136722721614]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33284755641038316		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.33284755641038316 | validation: 0.32053510094865756]
	TIME [epoch: 11.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3023523202323263		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.3023523202323263 | validation: 0.23813355715771636]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46921824397158407		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.46921824397158407 | validation: 0.5736792780801462]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43586882299610397		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.43586882299610397 | validation: 0.42227017869457806]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2839589008350518		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.2839589008350518 | validation: 0.20792448389896287]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26911532718651565		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.26911532718651565 | validation: 0.3029620963819945]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28032928413497027		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.28032928413497027 | validation: 0.34259398175472255]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3460599013458521		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.3460599013458521 | validation: 0.903369630092008]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9218776818412233		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.9218776818412233 | validation: 0.46471451177028483]
	TIME [epoch: 11.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5219414680983945		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.5219414680983945 | validation: 0.7794167053778597]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6309577334587568		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.6309577334587568 | validation: 0.25037482421244517]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16447878046721912		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.16447878046721912 | validation: 0.1973724467574912]
	TIME [epoch: 11.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18118192573334924		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.18118192573334924 | validation: 0.12341121747510661]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1905601887899744		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.1905601887899744 | validation: 0.21281788288569087]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2217281007867256		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.2217281007867256 | validation: 0.36731178926657415]
	TIME [epoch: 11.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25592509170417754		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.25592509170417754 | validation: 0.26986924343610275]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22382808864306797		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.22382808864306797 | validation: 0.12469236370150874]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28635767366488296		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.28635767366488296 | validation: 0.5307927399392133]
	TIME [epoch: 11.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7011014595238257		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.7011014595238257 | validation: 0.4301150887000597]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43200812660614846		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.43200812660614846 | validation: 0.2975412988396752]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3037674193820148		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.3037674193820148 | validation: 0.324426699619649]
	TIME [epoch: 11.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21307595614559818		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.21307595614559818 | validation: 0.4728170219615845]
	TIME [epoch: 11.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2836301938813884		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.2836301938813884 | validation: 0.3671448961911203]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2729393592556056		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.2729393592556056 | validation: 0.19093525160893968]
	TIME [epoch: 11.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19195178177185546		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.19195178177185546 | validation: 0.18024977329970143]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15923487384046392		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.15923487384046392 | validation: 0.19836215269269325]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18478361023458661		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.18478361023458661 | validation: 0.5785164727746006]
	TIME [epoch: 11.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7696213830831009		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.7696213830831009 | validation: 0.22490376774429577]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24344739379419844		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.24344739379419844 | validation: 0.21101920738753777]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20595162587959107		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.20595162587959107 | validation: 0.1606809063756995]
	TIME [epoch: 11.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2222376516092136		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.2222376516092136 | validation: 0.24452919859479189]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2279061977540981		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.2279061977540981 | validation: 0.27418425936627516]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22613680135872646		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.22613680135872646 | validation: 0.19773873272884843]
	TIME [epoch: 11.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20895086027158566		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.20895086027158566 | validation: 0.3530552503867787]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24857009212726067		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.24857009212726067 | validation: 0.22812049116165514]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22351228185225203		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.22351228185225203 | validation: 0.17362701667491998]
	TIME [epoch: 11.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14727809402372632		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.14727809402372632 | validation: 0.1417352076252365]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2069216004334354		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.2069216004334354 | validation: 0.2604356040831199]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2806269470850973		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.2806269470850973 | validation: 0.35556714178471893]
	TIME [epoch: 11.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27377781116912697		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.27377781116912697 | validation: 0.1404231585540803]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1817626204334319		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.1817626204334319 | validation: 0.7697907295640704]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3648427929906295		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.3648427929906295 | validation: 0.25991162649177624]
	TIME [epoch: 11.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2054589534937543		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.2054589534937543 | validation: 0.24527211452749784]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23318248225169058		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.23318248225169058 | validation: 0.32862631640539713]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22876881612881533		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.22876881612881533 | validation: 0.13181586612491472]
	TIME [epoch: 11.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19154297484898308		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.19154297484898308 | validation: 0.24070883188744316]
	TIME [epoch: 11.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3211347027266281		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.3211347027266281 | validation: 0.28976604398492334]
	TIME [epoch: 11.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2346466715088381		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.2346466715088381 | validation: 0.15938600912655854]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13850816659801254		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.13850816659801254 | validation: 0.15749538415898287]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21649138562934536		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.21649138562934536 | validation: 0.16721482740927163]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20185465926326562		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.20185465926326562 | validation: 0.30073958013807955]
	TIME [epoch: 11.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2632762238877142		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.2632762238877142 | validation: 0.2878794695107812]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2826914839086503		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.2826914839086503 | validation: 0.2822678372675217]
	TIME [epoch: 11.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2691302858891037		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.2691302858891037 | validation: 0.22614941514079262]
	TIME [epoch: 11.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21079446474437938		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.21079446474437938 | validation: 0.20932778569965846]
	TIME [epoch: 11.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19756492228863523		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.19756492228863523 | validation: 0.2274280782585301]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3089646666646896		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.3089646666646896 | validation: 0.2775290771379207]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2696884955809304		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.2696884955809304 | validation: 0.2731476665549224]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23721981717553578		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.23721981717553578 | validation: 0.2984442091734003]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17193188177605465		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.17193188177605465 | validation: 0.20930963927841134]
	TIME [epoch: 11.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2091528279292712		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.2091528279292712 | validation: 0.31118589900984006]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3829603744049638		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.3829603744049638 | validation: 0.1600045732940324]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2102633855478763		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.2102633855478763 | validation: 0.33801380320683605]
	TIME [epoch: 11.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24349069040797225		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.24349069040797225 | validation: 0.1413109057610359]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16951180206814642		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.16951180206814642 | validation: 0.15501345647047277]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18211419651219068		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.18211419651219068 | validation: 0.16258575955207513]
	TIME [epoch: 11.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20056805172149214		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.20056805172149214 | validation: 0.19083550064272753]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2888854701703051		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.2888854701703051 | validation: 0.17981683709217955]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17879288121346848		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.17879288121346848 | validation: 0.2007493021336066]
	TIME [epoch: 11.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19764821613932004		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.19764821613932004 | validation: 0.28520240409817793]
	TIME [epoch: 11.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18683164343611997		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.18683164343611997 | validation: 0.13264197026047]
	TIME [epoch: 11.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19535936685998395		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.19535936685998395 | validation: 0.3160739795971105]
	TIME [epoch: 11.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2764505067763686		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.2764505067763686 | validation: 0.3509239804978456]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23108569781135024		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.23108569781135024 | validation: 0.16373953777598801]
	TIME [epoch: 11.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18710692914009028		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.18710692914009028 | validation: 0.13154093655799354]
	TIME [epoch: 11.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19928399645674544		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.19928399645674544 | validation: 0.23080802629894975]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1833505194990246		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.1833505194990246 | validation: 0.16146450142888472]
	TIME [epoch: 11.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17853323252179368		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.17853323252179368 | validation: 0.3547335201903075]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21056642988958807		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.21056642988958807 | validation: 0.28699222531899726]
	TIME [epoch: 11.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338504216271808		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.3338504216271808 | validation: 0.30693240543517697]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686411699814699		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.2686411699814699 | validation: 0.2564507722641519]
	TIME [epoch: 11.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19337601773263305		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.19337601773263305 | validation: 0.2503717391004553]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25143834077975186		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.25143834077975186 | validation: 0.24732057370474173]
	TIME [epoch: 11.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18693661149602506		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.18693661149602506 | validation: 0.18525055098407067]
	TIME [epoch: 11.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20846318627398394		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.20846318627398394 | validation: 0.19899680714656676]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1738455194505391		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.1738455194505391 | validation: 0.25374065098986653]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2658620462544881		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.2658620462544881 | validation: 0.16471769036138048]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16139206487866142		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.16139206487866142 | validation: 0.16140399170575592]
	TIME [epoch: 11.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17474825677746825		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.17474825677746825 | validation: 0.14612363988815888]
	TIME [epoch: 11.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1519151762308193		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.1519151762308193 | validation: 0.13255327668093725]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322171504167177		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.1322171504167177 | validation: 0.2886037885982782]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23830149033162568		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.23830149033162568 | validation: 0.2399212191367444]
	TIME [epoch: 11.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21129344280215184		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.21129344280215184 | validation: 0.4720949460891238]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3243669346222185		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.3243669346222185 | validation: 0.24612960439502465]
	TIME [epoch: 11.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1871918019553853		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.1871918019553853 | validation: 0.30195802474223365]
	TIME [epoch: 11.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20641513450464727		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.20641513450464727 | validation: 0.17913144685197033]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14848402376289924		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.14848402376289924 | validation: 0.2608453814484092]
	TIME [epoch: 11.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16974861019183013		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.16974861019183013 | validation: 0.18954686068008186]
	TIME [epoch: 11.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23160084788422794		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.23160084788422794 | validation: 0.2342434818452714]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2579138047495984		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.2579138047495984 | validation: 0.21596666869362455]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28231262689644426		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.28231262689644426 | validation: 0.4519185384764478]
	TIME [epoch: 11.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5598145175006152		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.5598145175006152 | validation: 0.5870089447345953]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7815539895926398		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.7815539895926398 | validation: 0.6064218676333198]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5402729825675647		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.5402729825675647 | validation: 0.34767617995345546]
	TIME [epoch: 11.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3731600774861862		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.3731600774861862 | validation: 0.6009886290300485]
	TIME [epoch: 11.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.178180858753021		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.178180858753021 | validation: 0.606457486118445]
	TIME [epoch: 11.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8565341342898961		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.8565341342898961 | validation: 0.45405226418664607]
	TIME [epoch: 11.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43312116088457536		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.43312116088457536 | validation: 0.4216516990412521]
	TIME [epoch: 11.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4332698241498254		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.4332698241498254 | validation: 0.3817612503411332]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4309844871772228		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.4309844871772228 | validation: 0.2643957611987656]
	TIME [epoch: 11.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31510541001517056		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.31510541001517056 | validation: 0.3536069823351922]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29537614121057115		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.29537614121057115 | validation: 0.19490361527896216]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18138834810937163		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.18138834810937163 | validation: 0.16692364792195452]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21171095642457413		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.21171095642457413 | validation: 0.2633839233460667]
	TIME [epoch: 11.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2284265826864617		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.2284265826864617 | validation: 0.27274679640899274]
	TIME [epoch: 11.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21640534806196754		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.21640534806196754 | validation: 0.22766941089063758]
	TIME [epoch: 11.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1910531642210408		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.1910531642210408 | validation: 0.14932744915520385]
	TIME [epoch: 11.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1740232181675301		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.1740232181675301 | validation: 0.14086659737975996]
	TIME [epoch: 11.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1854757058476684		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.1854757058476684 | validation: 0.14965207921655563]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838684680634631		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.1838684680634631 | validation: 0.16380757357160533]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20770878310620622		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.20770878310620622 | validation: 0.2729235091983299]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788241878083479		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.2788241878083479 | validation: 0.31724769080926335]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26934284085325383		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.26934284085325383 | validation: 0.26914827439616523]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21267886979572087		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.21267886979572087 | validation: 0.21211767834498652]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2548223862117365		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.2548223862117365 | validation: 0.18918659209053354]
	TIME [epoch: 11.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18509523354192825		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.18509523354192825 | validation: 0.17419567837162564]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15076790629013315		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.15076790629013315 | validation: 0.20862871736772884]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1617875396812251		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.1617875396812251 | validation: 0.1369257088376106]
	TIME [epoch: 11.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20607803541844588		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.20607803541844588 | validation: 0.27045047997060584]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21532265912668014		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.21532265912668014 | validation: 0.16379026573024574]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28420721185022724		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.28420721185022724 | validation: 0.3165633997416714]
	TIME [epoch: 11.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21139169629431476		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.21139169629431476 | validation: 0.15698340379036144]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17541358769364218		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.17541358769364218 | validation: 0.18356597532690064]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15932458685552509		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.15932458685552509 | validation: 0.16470496106860058]
	TIME [epoch: 11.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16826335346955237		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.16826335346955237 | validation: 0.18541108344136878]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2100270367703425		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.2100270367703425 | validation: 0.22556222784522567]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23768874006060692		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.23768874006060692 | validation: 0.14790452392602446]
	TIME [epoch: 11.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18347486509499036		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.18347486509499036 | validation: 0.1624517564510588]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16039876424004978		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.16039876424004978 | validation: 0.26052927731666825]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25134746299418054		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.25134746299418054 | validation: 0.24631955638655206]
	TIME [epoch: 11.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24008388388216845		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.24008388388216845 | validation: 0.2064433708156577]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28416608011479644		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.28416608011479644 | validation: 0.9566290339183876]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49689819302098515		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.49689819302098515 | validation: 0.19009542592413486]
	TIME [epoch: 11.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20456571246463356		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.20456571246463356 | validation: 0.2532201124604608]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2711321486282894		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.2711321486282894 | validation: 0.23153817723096026]
	TIME [epoch: 11.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23744838666665238		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.23744838666665238 | validation: 0.3431188994393831]
	TIME [epoch: 11.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25294292034074617		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.25294292034074617 | validation: 0.26583110547726113]
	TIME [epoch: 11.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27896162131967606		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.27896162131967606 | validation: 0.17220517620357406]
	TIME [epoch: 11.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1819000882345433		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.1819000882345433 | validation: 0.20084954108310257]
	TIME [epoch: 11.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1832601672047356		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.1832601672047356 | validation: 0.1766542436549713]
	TIME [epoch: 11.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15116443264852		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.15116443264852 | validation: 0.19875154775214754]
	TIME [epoch: 11.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13929236271050022		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.13929236271050022 | validation: 0.16970407817710814]
	TIME [epoch: 11.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17695142735953945		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.17695142735953945 | validation: 0.16309683996047777]
	TIME [epoch: 11.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279986583905809		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.1279986583905809 | validation: 0.20011967132685882]
	TIME [epoch: 11.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.191953932425275		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.191953932425275 | validation: 0.24310166383300505]
	TIME [epoch: 11.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20466026051005845		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.20466026051005845 | validation: 0.1757502299162365]
	TIME [epoch: 11.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17525436802478056		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.17525436802478056 | validation: 0.12465951457789722]
	TIME [epoch: 11.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13125346351985837		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.13125346351985837 | validation: 0.14443468660457778]
	TIME [epoch: 11.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1668590568090637		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.1668590568090637 | validation: 0.1427432244931109]
	TIME [epoch: 11.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13462760345070002		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.13462760345070002 | validation: 0.16650010418415384]
	TIME [epoch: 11.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17534134045390137		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.17534134045390137 | validation: 0.2653724548487971]
	TIME [epoch: 11.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2004379354979835		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.2004379354979835 | validation: 0.1667754967421928]
	TIME [epoch: 11.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.158305009368065		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.158305009368065 | validation: 0.1783692703189549]
	TIME [epoch: 11.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2118524237148036		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.2118524237148036 | validation: 0.15422536997129752]
	TIME [epoch: 11.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23243077326895167		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.23243077326895167 | validation: 0.24741979577699277]
	TIME [epoch: 11.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1985113803004622		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.1985113803004622 | validation: 0.1693092187499577]
	TIME [epoch: 11.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2498709814813292		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.2498709814813292 | validation: 0.1709164765691679]
	TIME [epoch: 11.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2288235197945106		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.2288235197945106 | validation: 0.347087822546557]
	TIME [epoch: 11.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7301948601636039		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.7301948601636039 | validation: 0.441927716931918]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5325168213614879		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.5325168213614879 | validation: 0.3319835464774707]
	TIME [epoch: 11.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30520964882079293		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.30520964882079293 | validation: 0.17651041735863998]
	TIME [epoch: 11.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2908789265712822		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.2908789265712822 | validation: 0.2697554406125363]
	TIME [epoch: 11.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5066549455762315		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.5066549455762315 | validation: 1.0530647512719844]
	TIME [epoch: 11.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0325648645713996		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.0325648645713996 | validation: 0.3615993238383763]
	TIME [epoch: 11.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.447743164276068		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.447743164276068 | validation: 0.3432146633706553]
	TIME [epoch: 11.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3800824012783518		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.3800824012783518 | validation: 0.5083726921664051]
	TIME [epoch: 11.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6505622702865912		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.6505622702865912 | validation: 0.3581766517021383]
	TIME [epoch: 11.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4166131934420606		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.4166131934420606 | validation: 0.33538286887865987]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3502760013342628		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.3502760013342628 | validation: 0.2616086123420357]
	TIME [epoch: 11.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28090763087080217		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.28090763087080217 | validation: 0.23083012829843083]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23821326151459327		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.23821326151459327 | validation: 0.326211371398355]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24898286285103624		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.24898286285103624 | validation: 0.1682926901718124]
	TIME [epoch: 11.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16140905784491083		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.16140905784491083 | validation: 0.1315588566199651]
	TIME [epoch: 11.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13442497411813606		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.13442497411813606 | validation: 0.12403007653456033]
	TIME [epoch: 11.6 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1067845127088443		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.1067845127088443 | validation: 0.15725326812111842]
	TIME [epoch: 11.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29223871610763696		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.29223871610763696 | validation: 0.25679449308984786]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3758282016985597		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.3758282016985597 | validation: 1.1895926912552515]
	TIME [epoch: 11.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.111550459763452		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.111550459763452 | validation: 0.45829184091798253]
	TIME [epoch: 11.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36524080135108944		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.36524080135108944 | validation: 0.22178605943445415]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25462293351149223		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.25462293351149223 | validation: 0.22609951832716257]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31730893573062735		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.31730893573062735 | validation: 0.2363160409187806]
	TIME [epoch: 11.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1819730085958044		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.1819730085958044 | validation: 0.18230810220290422]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18700701767632263		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.18700701767632263 | validation: 0.22359852366728802]
	TIME [epoch: 11.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17746002684458007		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.17746002684458007 | validation: 0.1701935659762162]
	TIME [epoch: 11.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21727396834341445		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.21727396834341445 | validation: 0.24692677369006485]
	TIME [epoch: 11.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19819091907129294		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.19819091907129294 | validation: 0.15789087987476672]
	TIME [epoch: 11.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17429430033282237		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.17429430033282237 | validation: 0.1613906868757948]
	TIME [epoch: 11.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16190060319819843		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.16190060319819843 | validation: 0.20662148676512843]
	TIME [epoch: 11.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15500964880968646		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.15500964880968646 | validation: 0.1993191278590558]
	TIME [epoch: 11.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14516055392479674		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.14516055392479674 | validation: 0.15994175229084992]
	TIME [epoch: 11.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15204674973280613		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.15204674973280613 | validation: 0.14866436638540306]
	TIME [epoch: 11.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11825433569007326		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.11825433569007326 | validation: 0.18343038870068104]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14314908234797552		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.14314908234797552 | validation: 0.11200407900828685]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09547701842949155		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.09547701842949155 | validation: 0.0781882700331917]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_425.pth
	Model improved!!!
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0802572152498356		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.0802572152498356 | validation: 0.17743560491405128]
	TIME [epoch: 11.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17226204582749904		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.17226204582749904 | validation: 0.14734135930277062]
	TIME [epoch: 11.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11596397940057898		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.11596397940057898 | validation: 0.11320383550876585]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1169391519666503		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.1169391519666503 | validation: 0.15795217694216732]
	TIME [epoch: 11.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17948883337839877		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.17948883337839877 | validation: 0.15742087984315692]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14412984149249747		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.14412984149249747 | validation: 0.1551152113020447]
	TIME [epoch: 11.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13017789740949437		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.13017789740949437 | validation: 0.13791880382635324]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1706874680541348		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.1706874680541348 | validation: 0.22341999239939292]
	TIME [epoch: 11.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16530847202172658		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.16530847202172658 | validation: 0.14334752818156524]
	TIME [epoch: 11.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11468387336102968		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.11468387336102968 | validation: 0.19691804386461648]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13699690959005612		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.13699690959005612 | validation: 0.21851221847913635]
	TIME [epoch: 11.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16436150219686946		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.16436150219686946 | validation: 0.1029204866197363]
	TIME [epoch: 11.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08963146205954123		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.08963146205954123 | validation: 0.10658867464525021]
	TIME [epoch: 11.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11034072370552263		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.11034072370552263 | validation: 0.198720618042224]
	TIME [epoch: 11.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14933802282803177		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.14933802282803177 | validation: 0.10065760666354549]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17601407188133616		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.17601407188133616 | validation: 0.4162510066814182]
	TIME [epoch: 11.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26772996478592803		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.26772996478592803 | validation: 0.27033960118162054]
	TIME [epoch: 11.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17725056880649123		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.17725056880649123 | validation: 0.1787781696079491]
	TIME [epoch: 11.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17255216892352954		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.17255216892352954 | validation: 0.16137002334734116]
	TIME [epoch: 11.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12555845104918245		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.12555845104918245 | validation: 0.24707328566580716]
	TIME [epoch: 11.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3412217219129229		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.3412217219129229 | validation: 0.28645112162917913]
	TIME [epoch: 11.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15921404491912658		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.15921404491912658 | validation: 0.17127133937649344]
	TIME [epoch: 11.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13691865468291683		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.13691865468291683 | validation: 0.18266938487415382]
	TIME [epoch: 11.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18400308631138568		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.18400308631138568 | validation: 0.20063720823554157]
	TIME [epoch: 11.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1315351311659079		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.1315351311659079 | validation: 0.1386677359809999]
	TIME [epoch: 11.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1218487230697751		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.1218487230697751 | validation: 0.1223943872595407]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10227275749753256		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.10227275749753256 | validation: 0.16962730849592916]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10445291129883545		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.10445291129883545 | validation: 0.07711212101817438]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_453.pth
	Model improved!!!
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09037765552995697		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.09037765552995697 | validation: 0.09666683932148067]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13008295569480652		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.13008295569480652 | validation: 0.09233206142586173]
	TIME [epoch: 11.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08029040795277556		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.08029040795277556 | validation: 0.11539867305992328]
	TIME [epoch: 11.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08245679417795558		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.08245679417795558 | validation: 0.104157613778297]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13831195033747926		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.13831195033747926 | validation: 0.1558609250670521]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13755835597424035		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.13755835597424035 | validation: 0.13943093406908383]
	TIME [epoch: 11.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11304954875647803		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.11304954875647803 | validation: 0.07881867336922997]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10621576789691714		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.10621576789691714 | validation: 0.1208611786635001]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08514564943405079		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.08514564943405079 | validation: 0.08993848262025501]
	TIME [epoch: 11.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08513692821128824		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.08513692821128824 | validation: 0.16267880285322084]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11391737186862227		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.11391737186862227 | validation: 0.15432797592334102]
	TIME [epoch: 11.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10984425082038388		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.10984425082038388 | validation: 0.1223321159516412]
	TIME [epoch: 11.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11256268198191764		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.11256268198191764 | validation: 0.07798972816220086]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09127552523012947		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.09127552523012947 | validation: 0.08949620329606622]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07717887820814957		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.07717887820814957 | validation: 0.09374212552476822]
	TIME [epoch: 11.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08715333348571591		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.08715333348571591 | validation: 0.09079546436106636]
	TIME [epoch: 11.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11701225182201316		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.11701225182201316 | validation: 0.09813563888738502]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15162678265290402		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.15162678265290402 | validation: 0.4838909041168964]
	TIME [epoch: 11.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28578936293742124		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.28578936293742124 | validation: 0.17450996826647686]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11992039436804779		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.11992039436804779 | validation: 0.13468930994297204]
	TIME [epoch: 11.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11092126653400183		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.11092126653400183 | validation: 0.10409958788418408]
	TIME [epoch: 11.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15321355315239588		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.15321355315239588 | validation: 0.16115818046185246]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10539508113254738		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.10539508113254738 | validation: 0.18757613899782918]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14096860465681743		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.14096860465681743 | validation: 0.11503777791337987]
	TIME [epoch: 11.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09951039257404569		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.09951039257404569 | validation: 0.13107276100396167]
	TIME [epoch: 11.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1658495270364717		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.1658495270364717 | validation: 0.34414180650774356]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2029767692953705		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.2029767692953705 | validation: 0.27665240877543373]
	TIME [epoch: 11.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521761817108895		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.1521761817108895 | validation: 0.10207178512184989]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08195089415042833		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.08195089415042833 | validation: 0.15884131773791557]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1921723505759594		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.1921723505759594 | validation: 0.16627023120714854]
	TIME [epoch: 11.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12150739845956914		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.12150739845956914 | validation: 0.09879480585614041]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10554316758993557		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.10554316758993557 | validation: 0.13086163812710605]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16265440298311337		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.16265440298311337 | validation: 0.13763709823363077]
	TIME [epoch: 11.6 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09105321336106201		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.09105321336106201 | validation: 0.13539288590374957]
	TIME [epoch: 11.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12399994489956952		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.12399994489956952 | validation: 0.09622946847243397]
	TIME [epoch: 11.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1030961783432462		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.1030961783432462 | validation: 0.13095916748309486]
	TIME [epoch: 11.6 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08757151437251502		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.08757151437251502 | validation: 0.09078060757476163]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0654432677407771		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.0654432677407771 | validation: 0.08071319649333203]
	TIME [epoch: 11.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06462997233348755		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.06462997233348755 | validation: 0.09197040835582941]
	TIME [epoch: 11.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0657595048163614		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.0657595048163614 | validation: 0.11059409781987807]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06982939551008953		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.06982939551008953 | validation: 0.06334680314728713]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05967340872110511		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.05967340872110511 | validation: 0.11613753378110517]
	TIME [epoch: 11.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09329454403091281		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.09329454403091281 | validation: 0.09203415621572912]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10260386485907204		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.10260386485907204 | validation: 0.20890813238086162]
	TIME [epoch: 11.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17359877240736768		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.17359877240736768 | validation: 0.1734150080984142]
	TIME [epoch: 11.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19882846421869577		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.19882846421869577 | validation: 0.30607812762349595]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23785353313698385		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.23785353313698385 | validation: 0.18051901249390817]
	TIME [epoch: 11.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11884777277252388		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.11884777277252388 | validation: 0.11826548235028618]
	TIME [epoch: 11.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08521745615865478		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.08521745615865478 | validation: 0.09539770867171558]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09007251842983999		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.09007251842983999 | validation: 0.10349945835975019]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09420412041381754		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.09420412041381754 | validation: 0.1239442632262767]
	TIME [epoch: 11.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10074528682579023		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.10074528682579023 | validation: 0.09614128671351643]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07588257200679088		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.07588257200679088 | validation: 0.06378661586794801]
	TIME [epoch: 11.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09379314657321648		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.09379314657321648 | validation: 0.121692630420111]
	TIME [epoch: 11.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09442528563703893		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.09442528563703893 | validation: 0.09897654028300622]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357143349855966		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.1357143349855966 | validation: 0.1537191525117466]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11137862896567621		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.11137862896567621 | validation: 0.08945142843552421]
	TIME [epoch: 11.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0856255890618017		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.0856255890618017 | validation: 0.08270880821511774]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08349516310002829		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.08349516310002829 | validation: 0.09356370150278026]
	TIME [epoch: 11.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09116086039042828		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.09116086039042828 | validation: 0.09574451260869808]
	TIME [epoch: 11.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08273394581448433		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.08273394581448433 | validation: 0.09179200604339259]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0661815899904944		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.0661815899904944 | validation: 0.09369179867827492]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07761108724773431		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.07761108724773431 | validation: 0.12022891125902603]
	TIME [epoch: 11.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12562062231245982		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.12562062231245982 | validation: 0.08837527726774984]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07458034960301749		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.07458034960301749 | validation: 0.071319500690586]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08339135383485818		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.08339135383485818 | validation: 0.1429094224017896]
	TIME [epoch: 11.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10388171998636522		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.10388171998636522 | validation: 0.11104010040977551]
	TIME [epoch: 11.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06631656626949176		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.06631656626949176 | validation: 0.11614728599924207]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07997524624659363		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.07997524624659363 | validation: 0.1289082459852293]
	TIME [epoch: 11.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09763399517626206		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.09763399517626206 | validation: 0.10974271652661535]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07085798732387111		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.07085798732387111 | validation: 0.08668689550180723]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06603233325950877		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.06603233325950877 | validation: 0.06901357320029378]
	TIME [epoch: 11.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0772735748953299		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.0772735748953299 | validation: 0.0971610396015097]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08415534564879693		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.08415534564879693 | validation: 0.16195508961200353]
	TIME [epoch: 11.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17120285647682598		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.17120285647682598 | validation: 0.14647918930814932]
	TIME [epoch: 11.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1176382739173097		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.1176382739173097 | validation: 0.08610265035629043]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07817767773141542		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.07817767773141542 | validation: 0.07702020908054563]
	TIME [epoch: 11.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06233140629533723		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.06233140629533723 | validation: 0.07195080264778012]
	TIME [epoch: 11.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09619871476046762		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.09619871476046762 | validation: 0.15592385550805166]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15946959473743333		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.15946959473743333 | validation: 0.081871693498769]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06837525369289804		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.06837525369289804 | validation: 0.08929682985209735]
	TIME [epoch: 11.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08900496959957005		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.08900496959957005 | validation: 0.11979333433302594]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0947294551547786		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.0947294551547786 | validation: 0.09942847331438284]
	TIME [epoch: 11.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08631558480015067		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.08631558480015067 | validation: 0.09023236376756467]
	TIME [epoch: 11.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.065216026423164		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.065216026423164 | validation: 0.09410684774555868]
	TIME [epoch: 11.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0966892840565558		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.0966892840565558 | validation: 0.11751761317716548]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08621421667228618		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.08621421667228618 | validation: 0.1016310976673242]
	TIME [epoch: 11.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07100695484683509		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.07100695484683509 | validation: 0.0727084492788923]
	TIME [epoch: 11.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06726566289943803		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.06726566289943803 | validation: 0.11127263831994683]
	TIME [epoch: 11.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08990835279484635		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.08990835279484635 | validation: 0.10965954620179712]
	TIME [epoch: 11.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11367242933243632		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.11367242933243632 | validation: 0.11248199736757525]
	TIME [epoch: 11.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1136112771590557		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.1136112771590557 | validation: 0.13829509428296435]
	TIME [epoch: 11.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08629244856068743		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.08629244856068743 | validation: 0.12597105225242408]
	TIME [epoch: 11.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12345315396261086		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.12345315396261086 | validation: 0.11698832851900826]
	TIME [epoch: 11.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0874117700948993		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.0874117700948993 | validation: 0.1033794454262316]
	TIME [epoch: 11.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07997647207129008		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.07997647207129008 | validation: 0.13725894243442235]
	TIME [epoch: 11.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10543481470632313		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.10543481470632313 | validation: 0.08560728575282905]
	TIME [epoch: 11.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07751422659904939		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.07751422659904939 | validation: 0.09889245740643407]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08047821453674744		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.08047821453674744 | validation: 0.10899484046933491]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09715871726169663		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.09715871726169663 | validation: 0.2371764390685647]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19153136583845323		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.19153136583845323 | validation: 0.21428303426453071]
	TIME [epoch: 11.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19889025583762343		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.19889025583762343 | validation: 0.24265916123904732]
	TIME [epoch: 11.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13004689929143282		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.13004689929143282 | validation: 0.1250584226313722]
	TIME [epoch: 11.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09372445206108226		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.09372445206108226 | validation: 0.10259123064804154]
	TIME [epoch: 11.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08078543399254756		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.08078543399254756 | validation: 0.08517370097140084]
	TIME [epoch: 11.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09251094730935758		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.09251094730935758 | validation: 0.1493928304609603]
	TIME [epoch: 11.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18028210100223113		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.18028210100223113 | validation: 0.5094730859815476]
	TIME [epoch: 11.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46923301447690513		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.46923301447690513 | validation: 0.3806008540836125]
	TIME [epoch: 11.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17235356387670014		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.17235356387670014 | validation: 0.12931213932984353]
	TIME [epoch: 11.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10185311443955553		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.10185311443955553 | validation: 0.14130830841784048]
	TIME [epoch: 11.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12407366164233476		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.12407366164233476 | validation: 0.11619568166267144]
	TIME [epoch: 11.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07771429057574182		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.07771429057574182 | validation: 0.08836462001433894]
	TIME [epoch: 11.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09318879873065156		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.09318879873065156 | validation: 0.08499135755532543]
	TIME [epoch: 11.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07453095832866916		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.07453095832866916 | validation: 0.09039319074509222]
	TIME [epoch: 11.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07023791533267151		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.07023791533267151 | validation: 0.0584283379917828]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_568.pth
	Model improved!!!
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06615192706636715		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.06615192706636715 | validation: 0.07204604117023815]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058308025135604666		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.058308025135604666 | validation: 0.11642968454746504]
	TIME [epoch: 11.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07670157486714413		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.07670157486714413 | validation: 0.11214350115367903]
	TIME [epoch: 11.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10582135450596765		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.10582135450596765 | validation: 0.09286163862401639]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0663786677268653		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.0663786677268653 | validation: 0.09595512148104496]
	TIME [epoch: 11.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06475299731100807		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.06475299731100807 | validation: 0.08731618156354085]
	TIME [epoch: 11.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07025544371930398		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.07025544371930398 | validation: 0.06162968869216412]
	TIME [epoch: 11.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.065265452380876		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.065265452380876 | validation: 0.07928535625399806]
	TIME [epoch: 11.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0822903238147508		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.0822903238147508 | validation: 0.09842226472890317]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09510529148401053		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.09510529148401053 | validation: 0.12370143998068926]
	TIME [epoch: 11.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.078510767318614		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.078510767318614 | validation: 0.1018046902485515]
	TIME [epoch: 11.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08910966348382292		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.08910966348382292 | validation: 0.07917300070119829]
	TIME [epoch: 11.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0914130968991116		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.0914130968991116 | validation: 0.11571647194250374]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09857586931900832		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.09857586931900832 | validation: 0.10124807970769481]
	TIME [epoch: 11.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08938570344710327		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.08938570344710327 | validation: 0.09974834314704073]
	TIME [epoch: 11.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08766915516527367		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.08766915516527367 | validation: 0.09562338226218992]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08516035117104838		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.08516035117104838 | validation: 0.08196105860092287]
	TIME [epoch: 11.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06520335817306736		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.06520335817306736 | validation: 0.09259888172223235]
	TIME [epoch: 11.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10085142726515177		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.10085142726515177 | validation: 0.1561186980532961]
	TIME [epoch: 11.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11100009254709656		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.11100009254709656 | validation: 0.1238733132989596]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11834799367185538		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.11834799367185538 | validation: 0.11244713602366779]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09728753418679442		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.09728753418679442 | validation: 0.14935743201595642]
	TIME [epoch: 11.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12523592336424413		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.12523592336424413 | validation: 0.11287111308436554]
	TIME [epoch: 11.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188824580503863		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.09188824580503863 | validation: 0.07616635334662786]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08155458272211179		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.08155458272211179 | validation: 0.1235357702281219]
	TIME [epoch: 11.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13678295178679353		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.13678295178679353 | validation: 0.1486630864989371]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16278390970136497		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.16278390970136497 | validation: 0.09252289198004711]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11490766538280783		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.11490766538280783 | validation: 0.13529803795671572]
	TIME [epoch: 11.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17379611191070973		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.17379611191070973 | validation: 0.11519393288729564]
	TIME [epoch: 11.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343867054041813		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.1343867054041813 | validation: 0.15618916304151736]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.178897333966661		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.178897333966661 | validation: 0.10929822536883393]
	TIME [epoch: 11.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11753753837888851		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.11753753837888851 | validation: 0.12266598531817698]
	TIME [epoch: 11.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1203358450941055		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.1203358450941055 | validation: 0.10132660295483772]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1020085028727322		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.1020085028727322 | validation: 0.08843886067925498]
	TIME [epoch: 11.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09884644124836046		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.09884644124836046 | validation: 0.14263262587581918]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16575787563390842		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.16575787563390842 | validation: 0.19421008735573483]
	TIME [epoch: 11.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12745615368932522		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.12745615368932522 | validation: 0.09380916571142298]
	TIME [epoch: 11.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07341329399934635		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.07341329399934635 | validation: 0.06779918793683294]
	TIME [epoch: 11.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06744288104836098		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.06744288104836098 | validation: 0.1543130818787014]
	TIME [epoch: 11.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09983248835892519		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.09983248835892519 | validation: 0.09208025605911135]
	TIME [epoch: 11.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07254295849349873		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.07254295849349873 | validation: 0.11256066590502747]
	TIME [epoch: 11.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.100980182568927		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.100980182568927 | validation: 0.07024527476088321]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07245384724754343		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.07245384724754343 | validation: 0.08561853239860462]
	TIME [epoch: 11.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06534391932738229		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.06534391932738229 | validation: 0.07589421594087073]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08086113278390947		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.08086113278390947 | validation: 0.11459539510496432]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08174783234656177		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.08174783234656177 | validation: 0.07019376281667132]
	TIME [epoch: 11.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052446046692914576		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.052446046692914576 | validation: 0.07254450664177901]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05250197941686955		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.05250197941686955 | validation: 0.09451900908499199]
	TIME [epoch: 11.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06314072403023792		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.06314072403023792 | validation: 0.05717548404483421]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_617.pth
	Model improved!!!
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059883184118940946		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.059883184118940946 | validation: 0.08206581822005994]
	TIME [epoch: 11.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06556238069862758		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.06556238069862758 | validation: 0.053576023437421516]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_619.pth
	Model improved!!!
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047411609131515146		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.047411609131515146 | validation: 0.05911264646770976]
	TIME [epoch: 11.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055800327990190975		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.055800327990190975 | validation: 0.06454486431871312]
	TIME [epoch: 11.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05101056499328121		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.05101056499328121 | validation: 0.07269342233362629]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06318319360711301		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.06318319360711301 | validation: 0.11982097405993156]
	TIME [epoch: 11.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0623808506901413		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.0623808506901413 | validation: 0.07967493260215862]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09184291072755038		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.09184291072755038 | validation: 0.15413876357899883]
	TIME [epoch: 11.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12789876565951497		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.12789876565951497 | validation: 0.12993304222292915]
	TIME [epoch: 11.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07226041958099579		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.07226041958099579 | validation: 0.08644436929148518]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05726596176195531		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.05726596176195531 | validation: 0.08248596098455634]
	TIME [epoch: 11.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06063681848049108		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.06063681848049108 | validation: 0.08618580379735744]
	TIME [epoch: 11.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08730752363071911		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.08730752363071911 | validation: 0.09450157636807495]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10044613002152894		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.10044613002152894 | validation: 0.08120574461826499]
	TIME [epoch: 11.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06414329795274637		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.06414329795274637 | validation: 0.06707563320671912]
	TIME [epoch: 11.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04370976672391572		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.04370976672391572 | validation: 0.07832411341140107]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07543464371452746		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.07543464371452746 | validation: 0.16672333866548505]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32432876624926055		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.32432876624926055 | validation: 0.4323341959647363]
	TIME [epoch: 11.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40245378126255343		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.40245378126255343 | validation: 0.39662956865049614]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3948624575143346		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.3948624575143346 | validation: 0.39382301882631127]
	TIME [epoch: 11.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534648370588763		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.3534648370588763 | validation: 0.2989606203866314]
	TIME [epoch: 11.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31963231977586243		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.31963231977586243 | validation: 0.1931486830041207]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26592464442429165		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.26592464442429165 | validation: 0.19950671874530776]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22070971551105126		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.22070971551105126 | validation: 0.14067756982678947]
	TIME [epoch: 11.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586173154338823		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.1586173154338823 | validation: 0.16845772580630175]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17630174988488478		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.17630174988488478 | validation: 0.10692801681076919]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11687586294981674		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.11687586294981674 | validation: 0.10784148976669085]
	TIME [epoch: 11.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14482742072336252		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.14482742072336252 | validation: 0.12814144117633425]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10422420731603113		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.10422420731603113 | validation: 0.09393208637945018]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11226771580098596		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.11226771580098596 | validation: 0.13383598798998733]
	TIME [epoch: 11.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12087908528119473		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.12087908528119473 | validation: 0.10958767632436764]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0996911103413847		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.0996911103413847 | validation: 0.08904088646489505]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08065482656567668		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.08065482656567668 | validation: 0.11461822836008725]
	TIME [epoch: 11.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09375582943760567		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.09375582943760567 | validation: 0.11006028312364922]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08314077760201216		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.08314077760201216 | validation: 0.09441972549749139]
	TIME [epoch: 11.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10199021312717711		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.10199021312717711 | validation: 0.0982917111424101]
	TIME [epoch: 11.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08101029013803104		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.08101029013803104 | validation: 0.09112570241312344]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07168777482431692		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.07168777482431692 | validation: 0.0821776876121593]
	TIME [epoch: 11.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07019504184322105		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.07019504184322105 | validation: 0.10111182934765987]
	TIME [epoch: 11.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0848571560310517		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.0848571560310517 | validation: 0.08221501448413733]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09737248540313159		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.09737248540313159 | validation: 0.1287154725256737]
	TIME [epoch: 11.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10344704608591535		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.10344704608591535 | validation: 0.09878314757577535]
	TIME [epoch: 11.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10426430641359431		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.10426430641359431 | validation: 0.13066272023875874]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1002399388997605		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.1002399388997605 | validation: 0.08318827108176959]
	TIME [epoch: 11.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07791046507994699		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.07791046507994699 | validation: 0.08659059384348229]
	TIME [epoch: 11.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07797325892734527		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.07797325892734527 | validation: 0.10538361508197173]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11012778267803403		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.11012778267803403 | validation: 0.1305982210803963]
	TIME [epoch: 11.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15801249443963425		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.15801249443963425 | validation: 0.19887988458650568]
	TIME [epoch: 11.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13455218532522228		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.13455218532522228 | validation: 0.12058656669246849]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09844234213366138		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.09844234213366138 | validation: 0.14187643075950837]
	TIME [epoch: 11.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09024069473478355		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.09024069473478355 | validation: 0.06783324818471194]
	TIME [epoch: 11.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07277496085440725		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.07277496085440725 | validation: 0.11747025444545167]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11578557665024222		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.11578557665024222 | validation: 0.13435726683025195]
	TIME [epoch: 11.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1208076790994288		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.1208076790994288 | validation: 0.1070401682858987]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07347562815987457		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.07347562815987457 | validation: 0.07979019334383987]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05229782799737389		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.05229782799737389 | validation: 0.06722428453803897]
	TIME [epoch: 11.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05451754717245444		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.05451754717245444 | validation: 0.06847561330598295]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049064085985037156		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.049064085985037156 | validation: 0.06796719619752983]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06704944625582693		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.06704944625582693 | validation: 0.08734482257914128]
	TIME [epoch: 11.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062199336691198696		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.062199336691198696 | validation: 0.07696187365462066]
	TIME [epoch: 11.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06959439899763911		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.06959439899763911 | validation: 0.08245161743404648]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07083151073077898		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.07083151073077898 | validation: 0.10724458395307725]
	TIME [epoch: 11.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10588892668390258		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.10588892668390258 | validation: 0.10224090571882463]
	TIME [epoch: 11.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08032989596655499		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.08032989596655499 | validation: 0.11208812608062622]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08479378104001631		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.08479378104001631 | validation: 0.07311517848950602]
	TIME [epoch: 11.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06606137912042617		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.06606137912042617 | validation: 0.08565395862877838]
	TIME [epoch: 11.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07446221439447456		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.07446221439447456 | validation: 0.09392869957281223]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08786405539737611		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.08786405539737611 | validation: 0.10256689516344088]
	TIME [epoch: 11.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08763507764126731		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.08763507764126731 | validation: 0.09611027844585547]
	TIME [epoch: 11.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09305677175024586		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.09305677175024586 | validation: 0.13796783055045722]
	TIME [epoch: 11.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16180407230257735		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.16180407230257735 | validation: 0.13631387569496461]
	TIME [epoch: 11.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15752317194450122		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.15752317194450122 | validation: 0.13891845246058004]
	TIME [epoch: 11.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20519277086771423		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.20519277086771423 | validation: 0.19748280826831255]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21073922510675697		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.21073922510675697 | validation: 0.16071468720297397]
	TIME [epoch: 11.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15447179154768836		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.15447179154768836 | validation: 0.11056763332690422]
	TIME [epoch: 11.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11354708013237018		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.11354708013237018 | validation: 0.11588112612232862]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11339195195709664		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.11339195195709664 | validation: 0.11354871367005498]
	TIME [epoch: 11.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11244800201344413		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.11244800201344413 | validation: 0.09614875806451068]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10747827472940398		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.10747827472940398 | validation: 0.11772063027095246]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11857658235298993		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.11857658235298993 | validation: 0.12593672616158721]
	TIME [epoch: 11.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11485429447168904		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.11485429447168904 | validation: 0.10445261748738545]
	TIME [epoch: 11.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10365404366686971		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.10365404366686971 | validation: 0.14545471512443645]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13594586250415153		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.13594586250415153 | validation: 0.11586634029911565]
	TIME [epoch: 11.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10296171853139939		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.10296171853139939 | validation: 0.08237829415109948]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07756599092279154		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.07756599092279154 | validation: 0.07948581105186801]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07473886417083138		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.07473886417083138 | validation: 0.07452854265522707]
	TIME [epoch: 11.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07908212828029604		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.07908212828029604 | validation: 0.11266760255004458]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09926854887934196		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.09926854887934196 | validation: 0.09804675776211898]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07728240151732942		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.07728240151732942 | validation: 0.10063024687642257]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06876404911249312		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.06876404911249312 | validation: 0.07054419111549676]
	TIME [epoch: 11.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05717343194515828		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.05717343194515828 | validation: 0.06436169183856247]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05188792655783779		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.05188792655783779 | validation: 0.06377430937303916]
	TIME [epoch: 11.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05913089421459446		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.05913089421459446 | validation: 0.07043576801137531]
	TIME [epoch: 11.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06915659471977773		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.06915659471977773 | validation: 0.07255343566350812]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647753073985202		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.0647753073985202 | validation: 0.07208567123425971]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06727506329745991		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.06727506329745991 | validation: 0.09987786517717386]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06577888600918634		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.06577888600918634 | validation: 0.0666006070674133]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06255443401658578		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.06255443401658578 | validation: 0.10396622674573429]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813768738705281		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.0813768738705281 | validation: 0.10053099760942061]
	TIME [epoch: 11.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06983037874206771		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.06983037874206771 | validation: 0.07871248649783522]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0634352803208343		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.0634352803208343 | validation: 0.08062974008488553]
	TIME [epoch: 11.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05888925475638194		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.05888925475638194 | validation: 0.06094673472613983]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0398105302277627		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.0398105302277627 | validation: 0.06790123001563166]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04942152458591803		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.04942152458591803 | validation: 0.06312341764506242]
	TIME [epoch: 11.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06441931431301483		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.06441931431301483 | validation: 0.06867376117643602]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050246971317414756		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.050246971317414756 | validation: 0.0684469906331994]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061195646859495745		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.061195646859495745 | validation: 0.0712987365150639]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06565791886939165		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.06565791886939165 | validation: 0.08340580389392141]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06685498831639629		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.06685498831639629 | validation: 0.05445074884826134]
	TIME [epoch: 11.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04394296784007614		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.04394296784007614 | validation: 0.06990345250875157]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052786841699467575		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.052786841699467575 | validation: 0.08904008104257947]
	TIME [epoch: 11.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05764621662462588		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.05764621662462588 | validation: 0.07508920953041937]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048575989725799316		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.048575989725799316 | validation: 0.050999959011064466]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_730.pth
	Model improved!!!
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046712007283809004		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.046712007283809004 | validation: 0.07508568967126189]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06466350120993902		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.06466350120993902 | validation: 0.07720873947347545]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09523815510603567		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.09523815510603567 | validation: 0.1311336227072789]
	TIME [epoch: 11.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08248541970560043		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.08248541970560043 | validation: 0.07178146712555583]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04442840472405355		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.04442840472405355 | validation: 0.058298267356116366]
	TIME [epoch: 11.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04598726317571318		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.04598726317571318 | validation: 0.05455056597721098]
	TIME [epoch: 11.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04156808506207462		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.04156808506207462 | validation: 0.06827696811870826]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04861607278071971		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.04861607278071971 | validation: 0.05825296412217304]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050014014718187325		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.050014014718187325 | validation: 0.05701020187989199]
	TIME [epoch: 11.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04894076253171864		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.04894076253171864 | validation: 0.06073929643334662]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04431113613699363		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.04431113613699363 | validation: 0.080775879297248]
	TIME [epoch: 11.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053236275347943306		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.053236275347943306 | validation: 0.09971014046857529]
	TIME [epoch: 11.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07110213289202544		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.07110213289202544 | validation: 0.09232731695503187]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07056506223389933		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.07056506223389933 | validation: 0.1195899764631356]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09585909001018351		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.09585909001018351 | validation: 0.0861818368897673]
	TIME [epoch: 11.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0661150813771863		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.0661150813771863 | validation: 0.070472567451141]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06951048853256661		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.06951048853256661 | validation: 0.1014854588570088]
	TIME [epoch: 11.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10823954672149994		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.10823954672149994 | validation: 0.1370468598634394]
	TIME [epoch: 11.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09631106798805797		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.09631106798805797 | validation: 0.07091882387597774]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049967574255368685		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.049967574255368685 | validation: 0.07980442537942058]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056047996127155185		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.056047996127155185 | validation: 0.05895116341097153]
	TIME [epoch: 11.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05073318243299641		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.05073318243299641 | validation: 0.0780859491601439]
	TIME [epoch: 11.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04599932697266579		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.04599932697266579 | validation: 0.06624211785113886]
	TIME [epoch: 11.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04968856162681183		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.04968856162681183 | validation: 0.06305484264179248]
	TIME [epoch: 11.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04342209068403297		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.04342209068403297 | validation: 0.059462081789209496]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05183749794092723		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.05183749794092723 | validation: 0.06803746455818595]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04725373167296625		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.04725373167296625 | validation: 0.06932729185427335]
	TIME [epoch: 11.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06214564737185321		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.06214564737185321 | validation: 0.0754430222520986]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06666689506069227		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.06666689506069227 | validation: 0.07966615533347297]
	TIME [epoch: 11.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05664361844244474		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.05664361844244474 | validation: 0.07647142141954788]
	TIME [epoch: 11.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04989324789130844		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.04989324789130844 | validation: 0.07384713003318936]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055211610590453125		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.055211610590453125 | validation: 0.07999495608092508]
	TIME [epoch: 11.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06367590837571764		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.06367590837571764 | validation: 0.09331918624150454]
	TIME [epoch: 11.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243593870221277		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.08243593870221277 | validation: 0.08006480058852691]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625717138816244		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.0625717138816244 | validation: 0.06522893320767721]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06332393179095688		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.06332393179095688 | validation: 0.11098959628384428]
	TIME [epoch: 11.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1061531384078199		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.1061531384078199 | validation: 0.0945700934026483]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.085791846329272		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.085791846329272 | validation: 0.08637474167217057]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07601502184249131		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.07601502184249131 | validation: 0.08408505339589263]
	TIME [epoch: 11.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791190382861898		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.0791190382861898 | validation: 0.08271754401988586]
	TIME [epoch: 11.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07141962767740687		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.07141962767740687 | validation: 0.0720894810093557]
	TIME [epoch: 11.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06398581353988643		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.06398581353988643 | validation: 0.07425215355556913]
	TIME [epoch: 11.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07122433356696231		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.07122433356696231 | validation: 0.10395464285972501]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791769268277516		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.0791769268277516 | validation: 0.07538419080717089]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09039859005491294		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.09039859005491294 | validation: 0.12501102350683474]
	TIME [epoch: 11.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10485526921293215		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.10485526921293215 | validation: 0.08954284950117196]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08011177851126462		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.08011177851126462 | validation: 0.0958313764259556]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06597186089773163		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.06597186089773163 | validation: 0.06886936035075657]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05113601476660731		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.05113601476660731 | validation: 0.0643278320339967]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049960056151230954		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.049960056151230954 | validation: 0.06738792339513054]
	TIME [epoch: 11.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04373023466833206		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.04373023466833206 | validation: 0.05597457736380585]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03889935010544669		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.03889935010544669 | validation: 0.05747668538517083]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06254886317933984		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.06254886317933984 | validation: 0.0871687913862397]
	TIME [epoch: 11.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625141206112359		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.0625141206112359 | validation: 0.06080818337115623]
	TIME [epoch: 11.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046366153021271686		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.046366153021271686 | validation: 0.07009760794734367]
	TIME [epoch: 11.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05882174952539953		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.05882174952539953 | validation: 0.07244578627031216]
	TIME [epoch: 11.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05924939292043184		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.05924939292043184 | validation: 0.054280688374445885]
	TIME [epoch: 11.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04185579928752223		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.04185579928752223 | validation: 0.06499424531803763]
	TIME [epoch: 11.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042950698941640345		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.042950698941640345 | validation: 0.06550029228701142]
	TIME [epoch: 11.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04383217281312253		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.04383217281312253 | validation: 0.048120373948374255]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_790.pth
	Model improved!!!
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04219170745273783		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.04219170745273783 | validation: 0.05975911646796584]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03847394560205529		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.03847394560205529 | validation: 0.06328554377158917]
	TIME [epoch: 11.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0494390086449352		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.0494390086449352 | validation: 0.06173289543995702]
	TIME [epoch: 11.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04716501779055726		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.04716501779055726 | validation: 0.057357720491255114]
	TIME [epoch: 11.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041309938769558595		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.041309938769558595 | validation: 0.0788856231231188]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037276395026574566		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.037276395026574566 | validation: 0.05358033608741341]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03754330288621689		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.03754330288621689 | validation: 0.05328420056591264]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036928853775521936		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.036928853775521936 | validation: 0.04738121258181382]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_798.pth
	Model improved!!!
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037553297825743695		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.037553297825743695 | validation: 0.06158138548510645]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036140697839106596		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.036140697839106596 | validation: 0.049763688514090756]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03869633605069547		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.03869633605069547 | validation: 0.05722689717732692]
	TIME [epoch: 11.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04176288683338484		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.04176288683338484 | validation: 0.0970326330110818]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06452999522688682		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.06452999522688682 | validation: 0.07184477455225872]
	TIME [epoch: 11.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044768600799423804		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.044768600799423804 | validation: 0.060889642881574516]
	TIME [epoch: 11.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043288674580217755		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.043288674580217755 | validation: 0.08190358859915606]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06023724322983347		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.06023724322983347 | validation: 0.07393908890083861]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04721772110704503		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.04721772110704503 | validation: 0.059923455651753235]
	TIME [epoch: 11.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037779731734212924		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.037779731734212924 | validation: 0.0537098985186437]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04199219142069868		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.04199219142069868 | validation: 0.05972103735209952]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04026506201703896		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.04026506201703896 | validation: 0.04327710911325045]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_810.pth
	Model improved!!!
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036873588420461685		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.036873588420461685 | validation: 0.06000869719524813]
	TIME [epoch: 11.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050711972904998896		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.050711972904998896 | validation: 0.06327176289273062]
	TIME [epoch: 11.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04327308259141817		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.04327308259141817 | validation: 0.07242537307934539]
	TIME [epoch: 11.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05973991792790689		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.05973991792790689 | validation: 0.0732165830959916]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05020508468726117		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.05020508468726117 | validation: 0.06815616293084449]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05409712817286142		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.05409712817286142 | validation: 0.07001636697813216]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04993099828227684		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.04993099828227684 | validation: 0.0725948475767585]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06152773386599117		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.06152773386599117 | validation: 0.07470540933658704]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04216590056805678		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.04216590056805678 | validation: 0.050845424553213794]
	TIME [epoch: 11.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04103885294086565		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.04103885294086565 | validation: 0.05309068328848543]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03855526863463464		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.03855526863463464 | validation: 0.05097829469908419]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037357272107008115		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.037357272107008115 | validation: 0.06294619159324547]
	TIME [epoch: 11.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03857720294421831		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.03857720294421831 | validation: 0.06182738085573433]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05029900792006151		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.05029900792006151 | validation: 0.06545144696577039]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04700154315928814		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.04700154315928814 | validation: 0.057981219915389896]
	TIME [epoch: 11.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04322406724549167		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.04322406724549167 | validation: 0.05784411958992266]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043242468921646175		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.043242468921646175 | validation: 0.0761100066491315]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04820765058241707		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.04820765058241707 | validation: 0.07192579993196867]
	TIME [epoch: 11.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04856701999792048		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.04856701999792048 | validation: 0.05036597145067084]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04119544140407723		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.04119544140407723 | validation: 0.0619829905812157]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043218551300882375		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.043218551300882375 | validation: 0.05642188945498829]
	TIME [epoch: 11.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04593628541506725		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.04593628541506725 | validation: 0.0568829662158084]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04247743359153146		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.04247743359153146 | validation: 0.06662569760119791]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051679267580234375		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.051679267580234375 | validation: 0.06168055810290008]
	TIME [epoch: 11.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06602748897857946		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.06602748897857946 | validation: 0.07211349736353813]
	TIME [epoch: 11.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06138829334594447		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.06138829334594447 | validation: 0.07189457515955117]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05619194143573044		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.05619194143573044 | validation: 0.049869730554889434]
	TIME [epoch: 11.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04407915475151984		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.04407915475151984 | validation: 0.06185644806464333]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0468066777208172		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.0468066777208172 | validation: 0.05973894511974424]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0498899561408574		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.0498899561408574 | validation: 0.064100318864934]
	TIME [epoch: 11.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06915688941309713		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.06915688941309713 | validation: 0.07332321463066309]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060329059423663386		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.060329059423663386 | validation: 0.07345318208898598]
	TIME [epoch: 11.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05454618736200491		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.05454618736200491 | validation: 0.05162531718302293]
	TIME [epoch: 11.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03874582956986875		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.03874582956986875 | validation: 0.05231127592750527]
	TIME [epoch: 11.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03705611856035837		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.03705611856035837 | validation: 0.04970680238158995]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04289648408662517		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.04289648408662517 | validation: 0.06122919741814668]
	TIME [epoch: 11.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04581038669428861		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.04581038669428861 | validation: 0.05340812755740372]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044740383990143164		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.044740383990143164 | validation: 0.05535997669001537]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04774951236370542		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.04774951236370542 | validation: 0.05750524011763664]
	TIME [epoch: 11.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04339293063621433		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.04339293063621433 | validation: 0.052515703295453964]
	TIME [epoch: 11.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03854242209445869		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.03854242209445869 | validation: 0.05999495565690914]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045106512550980735		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.045106512550980735 | validation: 0.043378429621922975]
	TIME [epoch: 11.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031161697162442117		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.031161697162442117 | validation: 0.04435600862617159]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031541126637964385		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.031541126637964385 | validation: 0.0553256577575456]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03332733319192626		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.03332733319192626 | validation: 0.06614173589663527]
	TIME [epoch: 11.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04332709719481222		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.04332709719481222 | validation: 0.044335356105234834]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036571668311350586		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.036571668311350586 | validation: 0.05845953013324429]
	TIME [epoch: 11.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04469693578578479		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.04469693578578479 | validation: 0.05881609426564672]
	TIME [epoch: 11.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041784369989766604		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.041784369989766604 | validation: 0.04784157726125256]
	TIME [epoch: 11.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04047075339894806		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.04047075339894806 | validation: 0.06349933390437756]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04052640130716226		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.04052640130716226 | validation: 0.05781268397613919]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03783991147589561		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.03783991147589561 | validation: 0.06165711249134767]
	TIME [epoch: 11.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047396950109650976		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.047396950109650976 | validation: 0.04505651575636293]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03661544958014882		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.03661544958014882 | validation: 0.0509260996570087]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03535930562694687		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.03535930562694687 | validation: 0.061204701299503325]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05937577800085983		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.05937577800085983 | validation: 0.09599666821739757]
	TIME [epoch: 11.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0805145634743747		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.0805145634743747 | validation: 0.07660478060233346]
	TIME [epoch: 11.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06168300968566535		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.06168300968566535 | validation: 0.07226089461716907]
	TIME [epoch: 11.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05011477489752138		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.05011477489752138 | validation: 0.0527972404960457]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04524142229311607		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.04524142229311607 | validation: 0.03931287836278808]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_870.pth
	Model improved!!!
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033949910294698044		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.033949910294698044 | validation: 0.05457191826333141]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03682402814784446		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.03682402814784446 | validation: 0.05973178584029481]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04668985507862021		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.04668985507862021 | validation: 0.05050340583733275]
	TIME [epoch: 11.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03887411746134249		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.03887411746134249 | validation: 0.05686389363496955]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04585951410854415		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.04585951410854415 | validation: 0.05552552100730956]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037525092197827334		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.037525092197827334 | validation: 0.04961331425792334]
	TIME [epoch: 11.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0441239685907149		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.0441239685907149 | validation: 0.07401747450647853]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05484019015864715		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.05484019015864715 | validation: 0.06307834648825131]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06180810967858688		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.06180810967858688 | validation: 0.07313238230481173]
	TIME [epoch: 11.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06860048188755707		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.06860048188755707 | validation: 0.08985659613516983]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07301270662868523		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.07301270662868523 | validation: 0.07853156885132427]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07490895944695515		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.07490895944695515 | validation: 0.08993651336657742]
	TIME [epoch: 11.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1001564208140909		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.1001564208140909 | validation: 0.08894673651109536]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10793472080663766		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.10793472080663766 | validation: 0.09586913648604435]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09019699036063394		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.09019699036063394 | validation: 0.07331617327988144]
	TIME [epoch: 11.6 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06630888149658126		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.06630888149658126 | validation: 0.06358919904197373]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06430912112243531		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.06430912112243531 | validation: 0.07619462016286647]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07730280362864395		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.07730280362864395 | validation: 0.08348158590723966]
	TIME [epoch: 11.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08168084510405907		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.08168084510405907 | validation: 0.10821435273003914]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13251829068277204		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.13251829068277204 | validation: 0.13106328487906643]
	TIME [epoch: 11.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1399322611039332		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.1399322611039332 | validation: 0.12880209526005193]
	TIME [epoch: 11.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14309297619327332		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.14309297619327332 | validation: 0.13861473401087762]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15819976764328122		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.15819976764328122 | validation: 0.12665691797292017]
	TIME [epoch: 11.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13293193581251897		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.13293193581251897 | validation: 0.10695537263494011]
	TIME [epoch: 11.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11596382888074278		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.11596382888074278 | validation: 0.08173923099476892]
	TIME [epoch: 11.6 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09883889451676536		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.09883889451676536 | validation: 0.10397703065869766]
	TIME [epoch: 11.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12648518244659754		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.12648518244659754 | validation: 0.0955235166064745]
	TIME [epoch: 11.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11040220955408557		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.11040220955408557 | validation: 0.10325827330282727]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10456698310393418		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.10456698310393418 | validation: 0.08913044039849441]
	TIME [epoch: 11.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09249084784922881		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.09249084784922881 | validation: 0.10246507085930873]
	TIME [epoch: 11.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10175804218836741		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.10175804218836741 | validation: 0.08971149747659414]
	TIME [epoch: 11.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253948627373227		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.1253948627373227 | validation: 0.11891605290483132]
	TIME [epoch: 11.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1481805911550405		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.1481805911550405 | validation: 0.11856411880570229]
	TIME [epoch: 11.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539865461862283		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.1539865461862283 | validation: 0.1270373396548594]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14922701057393695		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.14922701057393695 | validation: 0.11504623489787767]
	TIME [epoch: 11.6 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14260209531177287		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.14260209531177287 | validation: 0.12479202560974283]
	TIME [epoch: 11.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1527932911549908		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.1527932911549908 | validation: 0.1175741985345667]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17348363014396295		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.17348363014396295 | validation: 0.14321444390144902]
	TIME [epoch: 11.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19917757047116708		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.19917757047116708 | validation: 0.16419622132341002]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21449809164907963		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.21449809164907963 | validation: 0.16827455985855125]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22010183358622798		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.22010183358622798 | validation: 0.1400706620401929]
	TIME [epoch: 11.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18033929461443704		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.18033929461443704 | validation: 0.13375778757439127]
	TIME [epoch: 11.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19274256319893512		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.19274256319893512 | validation: 0.14714236814051312]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17747705109670533		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.17747705109670533 | validation: 0.12874315142969336]
	TIME [epoch: 11.6 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18122609469795808		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.18122609469795808 | validation: 0.1308523457919472]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.159905682732074		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.159905682732074 | validation: 0.13017940656035873]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15503412270117733		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.15503412270117733 | validation: 0.11494896718723392]
	TIME [epoch: 11.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13128718076319867		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.13128718076319867 | validation: 0.12203208453794069]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15713513181165759		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.15713513181165759 | validation: 0.12793785272558442]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12919055161459347		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.12919055161459347 | validation: 0.09782032630859488]
	TIME [epoch: 11.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10030320575364518		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.10030320575364518 | validation: 0.08340646172990587]
	TIME [epoch: 11.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08753101710532114		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.08753101710532114 | validation: 0.09175250369569693]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08738441165826312		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.08738441165826312 | validation: 0.08893923911367224]
	TIME [epoch: 11.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0840000422210063		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.0840000422210063 | validation: 0.08573434771434282]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08015821591079368		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.08015821591079368 | validation: 0.10662950601706676]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09550722446972684		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.09550722446972684 | validation: 0.1153533228789716]
	TIME [epoch: 11.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10942404636453362		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.10942404636453362 | validation: 0.1059413724062875]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1001775622736011		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.1001775622736011 | validation: 0.11227475680833884]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0991219529669999		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.0991219529669999 | validation: 0.11453244535804187]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09835449642946523		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.09835449642946523 | validation: 0.10128556426888713]
	TIME [epoch: 11.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09450970994745941		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.09450970994745941 | validation: 0.09481720612552601]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0988431586695872		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.0988431586695872 | validation: 0.09974509929357668]
	TIME [epoch: 11.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1183519930985767		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.1183519930985767 | validation: 0.08790048385767998]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0990890083964436		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.0990890083964436 | validation: 0.09504946105256384]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09003524533547856		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.09003524533547856 | validation: 0.09834825151216822]
	TIME [epoch: 11.6 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10109613121392629		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.10109613121392629 | validation: 0.09978718706464353]
	TIME [epoch: 11.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08470588183219623		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.08470588183219623 | validation: 0.08440883557258566]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08989106641017028		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.08989106641017028 | validation: 0.08697200372917116]
	TIME [epoch: 11.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08114551799605801		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.08114551799605801 | validation: 0.07893317685430522]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07387548180617591		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.07387548180617591 | validation: 0.09740279911236917]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08875230550839085		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.08875230550839085 | validation: 0.10029495078746824]
	TIME [epoch: 11.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08146805870512429		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.08146805870512429 | validation: 0.06786562578031129]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06579889414215534		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.06579889414215534 | validation: 0.06491523770587679]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06090227160594719		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.06090227160594719 | validation: 0.0678173137946583]
	TIME [epoch: 11.6 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06061979772539318		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.06061979772539318 | validation: 0.08936503795414183]
	TIME [epoch: 11.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06388785962927124		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.06388785962927124 | validation: 0.07975284493941713]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06518320779870006		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.06518320779870006 | validation: 0.07378863501018844]
	TIME [epoch: 11.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06935193394417807		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.06935193394417807 | validation: 0.07022109080111845]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06300697339920845		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.06300697339920845 | validation: 0.0517056267576967]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04680231659024363		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.04680231659024363 | validation: 0.06179025102574757]
	TIME [epoch: 11.6 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04874012844108197		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.04874012844108197 | validation: 0.06096020446790583]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053250444948826706		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.053250444948826706 | validation: 0.07761119231813746]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07895882251283244		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.07895882251283244 | validation: 0.0905508988079194]
	TIME [epoch: 11.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06740194638284838		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.06740194638284838 | validation: 0.06579236166314031]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04843798012442674		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.04843798012442674 | validation: 0.05843630093446159]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04307322508943297		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.04307322508943297 | validation: 0.06489449115172821]
	TIME [epoch: 11.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04967184389375211		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.04967184389375211 | validation: 0.047013645032505096]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04452356141032494		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.04452356141032494 | validation: 0.050295054311263396]
	TIME [epoch: 11.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04520652044221386		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.04520652044221386 | validation: 0.06901005672406314]
	TIME [epoch: 11.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07174470172909049		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.07174470172909049 | validation: 0.08381828268969482]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08594841242815263		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.08594841242815263 | validation: 0.09985185543979765]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08663573732797578		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.08663573732797578 | validation: 0.0662538574999888]
	TIME [epoch: 11.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05837302133267999		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.05837302133267999 | validation: 0.06948894597001895]
	TIME [epoch: 11.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05485795480760653		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.05485795480760653 | validation: 0.06780970104138481]
	TIME [epoch: 11.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0582033861750968		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.0582033861750968 | validation: 0.06506135892840716]
	TIME [epoch: 11.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061692778328752695		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.061692778328752695 | validation: 0.05698313571265359]
	TIME [epoch: 11.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0542511431682815		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.0542511431682815 | validation: 0.06073857940018428]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05663941850627496		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.05663941850627496 | validation: 0.07071049796491057]
	TIME [epoch: 11.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0678850960209886		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.0678850960209886 | validation: 0.06878357918909968]
	TIME [epoch: 11.6 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06027472788416641		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.06027472788416641 | validation: 0.0718836550889235]
	TIME [epoch: 11.6 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0550878890135522		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.0550878890135522 | validation: 0.06712223318457895]
	TIME [epoch: 11.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0533632874524268		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.0533632874524268 | validation: 0.061088719476984236]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04859657552445529		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.04859657552445529 | validation: 0.062139944531080855]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04912635439908132		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.04912635439908132 | validation: 0.06249490235114547]
	TIME [epoch: 11.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05404987329122723		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.05404987329122723 | validation: 0.05572490732153973]
	TIME [epoch: 11.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04871989806518191		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.04871989806518191 | validation: 0.0581212860470749]
	TIME [epoch: 11.6 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055442192132536164		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.055442192132536164 | validation: 0.05748913512543089]
	TIME [epoch: 11.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0482603159892325		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.0482603159892325 | validation: 0.044384585099690545]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03878097044254556		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.03878097044254556 | validation: 0.0511639164747624]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03815351180953102		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.03815351180953102 | validation: 0.04950135528045536]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04739294322005935		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.04739294322005935 | validation: 0.07357017142256365]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04467950652769176		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.04467950652769176 | validation: 0.055132700465818626]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04142058588875087		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.04142058588875087 | validation: 0.06201938732773812]
	TIME [epoch: 11.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04010408901913054		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.04010408901913054 | validation: 0.04478049684206992]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03565322974650891		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.03565322974650891 | validation: 0.044113617290949016]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035209774603421104		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.035209774603421104 | validation: 0.06055505292398472]
	TIME [epoch: 11.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03297272011128795		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.03297272011128795 | validation: 0.07141231055853968]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052736714056451334		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.052736714056451334 | validation: 0.06506669322182644]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04748463756573549		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.04748463756573549 | validation: 0.052703113751410714]
	TIME [epoch: 11.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043069577897632834		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.043069577897632834 | validation: 0.05255300299700554]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041349020882975866		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.041349020882975866 | validation: 0.05420121430170857]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039155239506575165		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.039155239506575165 | validation: 0.05056209831399199]
	TIME [epoch: 11.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04136051720893156		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.04136051720893156 | validation: 0.051390154951982625]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038170102760233714		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.038170102760233714 | validation: 0.052499315461485986]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03995000383111166		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.03995000383111166 | validation: 0.04353628389791158]
	TIME [epoch: 11.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046149775727275834		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.046149775727275834 | validation: 0.05285156907755936]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04256952965904158		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.04256952965904158 | validation: 0.05953964794707501]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037372870969823474		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.037372870969823474 | validation: 0.06198133996389311]
	TIME [epoch: 11.6 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03673601110850761		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.03673601110850761 | validation: 0.0464275969016777]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04000835484711364		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.04000835484711364 | validation: 0.05434143620936444]
	TIME [epoch: 11.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036686589410845565		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.036686589410845565 | validation: 0.04483603899011964]
	TIME [epoch: 11.6 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04051190864663645		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.04051190864663645 | validation: 0.07065171747122186]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04475839492367345		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.04475839492367345 | validation: 0.04867880385411399]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034688884028641176		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.034688884028641176 | validation: 0.054671058285099314]
	TIME [epoch: 11.6 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03648449605026671		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.03648449605026671 | validation: 0.051030776051944844]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03504937917578338		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.03504937917578338 | validation: 0.041374174536828796]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03424401537676816		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.03424401537676816 | validation: 0.04379142982868627]
	TIME [epoch: 11.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035471841163990214		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.035471841163990214 | validation: 0.03848003082269541]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_1008.pth
	Model improved!!!
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03519532705533198		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.03519532705533198 | validation: 0.05230553904485721]
	TIME [epoch: 11.6 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033679002282913206		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.033679002282913206 | validation: 0.0539795614625813]
	TIME [epoch: 11.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03715953900577206		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.03715953900577206 | validation: 0.04592559894528878]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034762338598241724		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.034762338598241724 | validation: 0.04894330311803549]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03088744161031738		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.03088744161031738 | validation: 0.04133344809226235]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03578999960837953		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.03578999960837953 | validation: 0.04958404392315531]
	TIME [epoch: 11.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03392113139042118		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.03392113139042118 | validation: 0.05681635155186436]
	TIME [epoch: 11.6 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0428371063127922		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.0428371063127922 | validation: 0.07145899125301897]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045766744884756315		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.045766744884756315 | validation: 0.06090590887875212]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04241985809241199		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.04241985809241199 | validation: 0.0500237148673568]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042748282450057865		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.042748282450057865 | validation: 0.05644476138348438]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0494500309671875		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.0494500309671875 | validation: 0.059869105762408815]
	TIME [epoch: 11.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05415919107572211		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.05415919107572211 | validation: 0.06791838017224115]
	TIME [epoch: 11.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056148847331109114		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.056148847331109114 | validation: 0.054300293278925764]
	TIME [epoch: 11.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04391075040298608		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.04391075040298608 | validation: 0.04513571518113034]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03714864506073732		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.03714864506073732 | validation: 0.0594983740883651]
	TIME [epoch: 11.6 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03893118147981943		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.03893118147981943 | validation: 0.05237105563675198]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03259723247781514		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.03259723247781514 | validation: 0.04587529778420105]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03230558394846182		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.03230558394846182 | validation: 0.04363100889727555]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03236866175069448		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.03236866175069448 | validation: 0.04599302355680535]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03425798485800935		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.03425798485800935 | validation: 0.050320620567813695]
	TIME [epoch: 11.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03209979133232523		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.03209979133232523 | validation: 0.05082269539639438]
	TIME [epoch: 11.6 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032814703545707376		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.032814703545707376 | validation: 0.055332885620797294]
	TIME [epoch: 11.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033388738592215084		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.033388738592215084 | validation: 0.0477305651652129]
	TIME [epoch: 11.6 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0344481178701543		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.0344481178701543 | validation: 0.04563808678691309]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03753227651959365		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.03753227651959365 | validation: 0.05796905198823275]
	TIME [epoch: 11.6 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0451072019006354		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.0451072019006354 | validation: 0.04749924468581334]
	TIME [epoch: 11.6 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03418073526530762		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.03418073526530762 | validation: 0.05839261630178754]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03805258965134574		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.03805258965134574 | validation: 0.054867390611449914]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04009443432068118		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.04009443432068118 | validation: 0.052173258898911314]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044043821713872805		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.044043821713872805 | validation: 0.048447769801041256]
	TIME [epoch: 11.6 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03623996661465438		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.03623996661465438 | validation: 0.046475193804148704]
	TIME [epoch: 11.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04313099096794973		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.04313099096794973 | validation: 0.05758822388070149]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048703243359052406		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.048703243359052406 | validation: 0.05737401781608895]
	TIME [epoch: 11.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05742796033185035		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.05742796033185035 | validation: 0.07377761497077137]
	TIME [epoch: 11.6 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0603584332473799		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.0603584332473799 | validation: 0.06556984211665767]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05631475576563469		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.05631475576563469 | validation: 0.05630727922500969]
	TIME [epoch: 11.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05196700602895819		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.05196700602895819 | validation: 0.0565992620254241]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051408456857107966		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.051408456857107966 | validation: 0.058683530246289806]
	TIME [epoch: 11.6 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05016268401381108		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.05016268401381108 | validation: 0.06015838856508266]
	TIME [epoch: 11.6 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043979804122438765		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.043979804122438765 | validation: 0.05839634718157967]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046359900371577945		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.046359900371577945 | validation: 0.06524100622745865]
	TIME [epoch: 11.6 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04802211956812067		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.04802211956812067 | validation: 0.057391530907430884]
	TIME [epoch: 11.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04349409893898459		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.04349409893898459 | validation: 0.05495213058460153]
	TIME [epoch: 11.6 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042506405936466304		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.042506405936466304 | validation: 0.04912605368435342]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04207130943716442		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.04207130943716442 | validation: 0.052707396884142166]
	TIME [epoch: 11.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621625341480694		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.03621625341480694 | validation: 0.06325133282302765]
	TIME [epoch: 11.6 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03550231202755702		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.03550231202755702 | validation: 0.04778204759319598]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037001860050886		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.037001860050886 | validation: 0.053330785134333106]
	TIME [epoch: 11.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04559689635825953		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.04559689635825953 | validation: 0.07185668793799063]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05753433624125014		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.05753433624125014 | validation: 0.06893341787453576]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04212304125299265		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.04212304125299265 | validation: 0.06548344401581152]
	TIME [epoch: 11.6 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05131017291964136		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.05131017291964136 | validation: 0.06591844310322974]
	TIME [epoch: 11.6 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05154145676121001		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.05154145676121001 | validation: 0.06133743811635746]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050816666988883985		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.050816666988883985 | validation: 0.06525948095580608]
	TIME [epoch: 11.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049442286666402754		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.049442286666402754 | validation: 0.06324670077556772]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04822494827219745		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.04822494827219745 | validation: 0.06272008651973097]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04212063799652444		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.04212063799652444 | validation: 0.05995082800035025]
	TIME [epoch: 11.6 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04395489158757769		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.04395489158757769 | validation: 0.055745772497731653]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034779921165032944		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.034779921165032944 | validation: 0.05678572587955464]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0328721519696165		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.0328721519696165 | validation: 0.05394102843985083]
	TIME [epoch: 11.6 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04298899639061743		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.04298899639061743 | validation: 0.06967319092789437]
	TIME [epoch: 11.6 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046785082490962276		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.046785082490962276 | validation: 0.06891847593396302]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054396300287901427		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.054396300287901427 | validation: 0.06892829037370592]
	TIME [epoch: 11.6 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05203104391109963		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.05203104391109963 | validation: 0.060385036191806664]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03986131191091529		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.03986131191091529 | validation: 0.05222454734701488]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0332063025671995		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.0332063025671995 | validation: 0.05210384226906352]
	TIME [epoch: 11.6 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03707134590207034		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.03707134590207034 | validation: 0.049380010823247215]
	TIME [epoch: 11.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031964241325251455		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.031964241325251455 | validation: 0.04821008399490381]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03533881331012541		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.03533881331012541 | validation: 0.05640465001186797]
	TIME [epoch: 11.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03725913531955113		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.03725913531955113 | validation: 0.05669620221960336]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04122579060102252		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.04122579060102252 | validation: 0.06507285050009363]
	TIME [epoch: 11.6 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04898775829191629		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.04898775829191629 | validation: 0.05409560358683379]
	TIME [epoch: 11.6 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03989877376326788		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.03989877376326788 | validation: 0.04870146918930738]
	TIME [epoch: 11.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040657805235672195		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.040657805235672195 | validation: 0.04949090646059715]
	TIME [epoch: 11.6 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04097664069888181		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.04097664069888181 | validation: 0.05478010915786891]
	TIME [epoch: 11.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03675167304366547		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.03675167304366547 | validation: 0.04685650516606197]
	TIME [epoch: 11.6 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0395737419006124		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.0395737419006124 | validation: 0.059508629077096836]
	TIME [epoch: 11.6 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03862363063785701		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.03862363063785701 | validation: 0.04466693573578078]
	TIME [epoch: 11.6 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039063839103565125		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.039063839103565125 | validation: 0.05203529295614778]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03575910339548763		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.03575910339548763 | validation: 0.060724436062453896]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04004273345281796		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.04004273345281796 | validation: 0.04913958832009347]
	TIME [epoch: 11.6 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036982905028103565		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.036982905028103565 | validation: 0.05385968569250016]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0370621282682628		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.0370621282682628 | validation: 0.06049922466674331]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03540200171643062		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.03540200171643062 | validation: 0.059323508862822186]
	TIME [epoch: 11.6 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038690178082408315		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.038690178082408315 | validation: 0.05810225835082864]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036436480584652396		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.036436480584652396 | validation: 0.04659264566594103]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032185784142996075		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.032185784142996075 | validation: 0.04193981290934885]
	TIME [epoch: 11.6 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0343711163671265		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.0343711163671265 | validation: 0.04187210937695562]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031294173846157264		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.031294173846157264 | validation: 0.054495850168892766]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038026284792327544		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.038026284792327544 | validation: 0.053736124656539416]
	TIME [epoch: 11.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035960171028139074		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.035960171028139074 | validation: 0.048584792615234684]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030580207342533992		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.030580207342533992 | validation: 0.04501321426591841]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034609625920384156		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.034609625920384156 | validation: 0.06259252808052526]
	TIME [epoch: 11.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047581558644023136		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.047581558644023136 | validation: 0.0580098924126186]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04409822942486497		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.04409822942486497 | validation: 0.05248756157137296]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0432501038088771		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.0432501038088771 | validation: 0.052553549110591326]
	TIME [epoch: 11.6 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040521254304076645		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.040521254304076645 | validation: 0.04721650464451686]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035477133114666624		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.035477133114666624 | validation: 0.056276484826202254]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03324239280934719		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.03324239280934719 | validation: 0.0581131305015205]
	TIME [epoch: 11.6 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034289112882916105		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.034289112882916105 | validation: 0.044380325957624416]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028299032544720246		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.028299032544720246 | validation: 0.05017626303981002]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03497040680350566		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.03497040680350566 | validation: 0.04235729574019866]
	TIME [epoch: 11.6 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036746063029918674		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.036746063029918674 | validation: 0.043914819462639074]
	TIME [epoch: 11.6 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03342432012552656		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.03342432012552656 | validation: 0.04854034985871602]
	TIME [epoch: 11.6 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029929542643670665		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.029929542643670665 | validation: 0.04921730678401014]
	TIME [epoch: 11.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03575333914663622		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.03575333914663622 | validation: 0.0438718700704816]
	TIME [epoch: 11.6 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034716318135820746		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.034716318135820746 | validation: 0.04555963499352882]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033882381245026676		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.033882381245026676 | validation: 0.04755997596715823]
	TIME [epoch: 11.6 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032165104388530694		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.032165104388530694 | validation: 0.05130056473903377]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03416854579726609		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.03416854579726609 | validation: 0.04544932210265031]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03636647330357684		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.03636647330357684 | validation: 0.05295391010673422]
	TIME [epoch: 11.6 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03862104657614866		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.03862104657614866 | validation: 0.054538769931117365]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044018153820648484		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.044018153820648484 | validation: 0.05797327309155329]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05077317360981598		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.05077317360981598 | validation: 0.056542184628173675]
	TIME [epoch: 11.6 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045785528970066894		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.045785528970066894 | validation: 0.04545095364169158]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04298594861860715		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.04298594861860715 | validation: 0.05439239755644936]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04405137477899789		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.04405137477899789 | validation: 0.04741305683464215]
	TIME [epoch: 11.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04167131727737115		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.04167131727737115 | validation: 0.05308210013644105]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040527377390059356		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.040527377390059356 | validation: 0.05395682942555977]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03924754287785172		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.03924754287785172 | validation: 0.04556553595201046]
	TIME [epoch: 11.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03323252910558029		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.03323252910558029 | validation: 0.05341490235671136]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03599828220091334		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.03599828220091334 | validation: 0.062245349997388476]
	TIME [epoch: 11.6 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045217057724086074		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.045217057724086074 | validation: 0.05310785447201388]
	TIME [epoch: 11.6 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04047955667585553		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.04047955667585553 | validation: 0.05593543648762636]
	TIME [epoch: 11.6 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04386576259545252		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.04386576259545252 | validation: 0.05081364600530254]
	TIME [epoch: 11.6 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038740062620937855		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.038740062620937855 | validation: 0.04949233659763756]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044271932001577044		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.044271932001577044 | validation: 0.053615636319775034]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03655950497771972		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.03655950497771972 | validation: 0.05518726739391853]
	TIME [epoch: 11.6 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03281341056105015		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.03281341056105015 | validation: 0.05196236578544856]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032251178604192104		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.032251178604192104 | validation: 0.05961945082019625]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04419452259319454		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.04419452259319454 | validation: 0.06412367641287192]
	TIME [epoch: 11.6 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046706538346994744		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.046706538346994744 | validation: 0.07825763099558888]
	TIME [epoch: 11.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055340849037469726		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.055340849037469726 | validation: 0.07106033491696341]
	TIME [epoch: 11.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049648860299873226		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.049648860299873226 | validation: 0.0684607776207688]
	TIME [epoch: 11.6 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04694103236740183		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.04694103236740183 | validation: 0.06118505216503003]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04129176257374989		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.04129176257374989 | validation: 0.05069574125039017]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034431307100408204		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.034431307100408204 | validation: 0.04836266230559813]
	TIME [epoch: 11.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029771248384325776		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.029771248384325776 | validation: 0.04965061524235745]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036367048696859895		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.036367048696859895 | validation: 0.04921851718430762]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03610051389666074		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.03610051389666074 | validation: 0.05216284463727211]
	TIME [epoch: 11.6 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313544966417833		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.03313544966417833 | validation: 0.04090295841197945]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03100150761881635		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.03100150761881635 | validation: 0.047772058383719965]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03681087724315342		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.03681087724315342 | validation: 0.05341341415282729]
	TIME [epoch: 11.6 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03814988823322678		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.03814988823322678 | validation: 0.04851849360265395]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038531570356932276		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.038531570356932276 | validation: 0.05540602261034089]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032477841875764926		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.032477841875764926 | validation: 0.053078043133433894]
	TIME [epoch: 11.6 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03765455277558011		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.03765455277558011 | validation: 0.05492639929437946]
	TIME [epoch: 11.6 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034615123138638265		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.034615123138638265 | validation: 0.053130846779056676]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032424130091116575		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.032424130091116575 | validation: 0.04493204731500538]
	TIME [epoch: 11.6 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02968488528748962		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.02968488528748962 | validation: 0.04916851489332589]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033282405117479055		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.033282405117479055 | validation: 0.05023758113440919]
	TIME [epoch: 11.6 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03408585182241029		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.03408585182241029 | validation: 0.04739097921734291]
	TIME [epoch: 11.6 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028621037051954186		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.028621037051954186 | validation: 0.05429055236653507]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03146302136217775		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.03146302136217775 | validation: 0.047567637391379466]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03125613940333645		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.03125613940333645 | validation: 0.04778413304640806]
	TIME [epoch: 11.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036120683460620154		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.036120683460620154 | validation: 0.049989058990423434]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03703308949521863		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.03703308949521863 | validation: 0.04454600878508213]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03464433074554099		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.03464433074554099 | validation: 0.04315422085131353]
	TIME [epoch: 11.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03232923703945096		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.03232923703945096 | validation: 0.04428952602956576]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03057874582927874		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.03057874582927874 | validation: 0.04475479953673232]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028617303240414158		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.028617303240414158 | validation: 0.04644928797418627]
	TIME [epoch: 11.6 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02869842781198471		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.02869842781198471 | validation: 0.0465469267798931]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031808590779091664		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.031808590779091664 | validation: 0.04097905952422494]
	TIME [epoch: 11.6 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03115679577114583		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.03115679577114583 | validation: 0.04443926888713411]
	TIME [epoch: 11.6 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028395367565752186		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.028395367565752186 | validation: 0.04214773472644843]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03239607601741444		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.03239607601741444 | validation: 0.05069146225004831]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0279789819183281		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.0279789819183281 | validation: 0.0498372033178922]
	TIME [epoch: 11.6 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03209210086303454		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.03209210086303454 | validation: 0.04374484800906835]
	TIME [epoch: 11.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030544671416571054		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.030544671416571054 | validation: 0.054029961889386996]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031709904154916244		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.031709904154916244 | validation: 0.05007792903020498]
	TIME [epoch: 11.6 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03405307627034021		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.03405307627034021 | validation: 0.04164286559792354]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03051782619795184		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.03051782619795184 | validation: 0.04753248963023261]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033260971620482596		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.033260971620482596 | validation: 0.05140169101152541]
	TIME [epoch: 11.6 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03429951048756087		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.03429951048756087 | validation: 0.049072360165405116]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037886634942955716		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.037886634942955716 | validation: 0.0540378589297833]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034936741619168904		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.034936741619168904 | validation: 0.05144038765699415]
	TIME [epoch: 11.6 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0347186712832466		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.0347186712832466 | validation: 0.05301676027146396]
	TIME [epoch: 11.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033733016526977924		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.033733016526977924 | validation: 0.05183594579425254]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03478169389651951		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.03478169389651951 | validation: 0.04459333184836048]
	TIME [epoch: 11.6 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037614747111595015		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.037614747111595015 | validation: 0.04911581859329998]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033849688848482135		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.033849688848482135 | validation: 0.042577583456169854]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03561510642580648		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.03561510642580648 | validation: 0.06087640451849605]
	TIME [epoch: 11.6 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03616353570365877		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.03616353570365877 | validation: 0.04797403237960772]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035244867750223195		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.035244867750223195 | validation: 0.05636134733348754]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03515945261866926		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.03515945261866926 | validation: 0.05720437248775968]
	TIME [epoch: 11.6 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030493970032376125		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.030493970032376125 | validation: 0.0571756701937354]
	TIME [epoch: 11.6 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03099858705645101		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.03099858705645101 | validation: 0.048807042146376926]
	TIME [epoch: 11.6 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03648390157251323		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.03648390157251323 | validation: 0.0550617435370868]
	TIME [epoch: 11.6 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03179992948840903		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.03179992948840903 | validation: 0.060246749854770146]
	TIME [epoch: 11.6 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034801466947344414		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.034801466947344414 | validation: 0.060633388601968596]
	TIME [epoch: 11.6 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040486084122905934		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.040486084122905934 | validation: 0.054159023514228764]
	TIME [epoch: 11.6 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03795135470583624		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.03795135470583624 | validation: 0.0585578926136829]
	TIME [epoch: 11.6 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032318624472330346		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.032318624472330346 | validation: 0.04856577212556113]
	TIME [epoch: 11.6 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035397218533222065		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.035397218533222065 | validation: 0.04999129409096154]
	TIME [epoch: 11.6 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0387378374505109		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.0387378374505109 | validation: 0.05085789301903708]
	TIME [epoch: 11.6 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039739518673923245		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.039739518673923245 | validation: 0.05461017895419957]
	TIME [epoch: 11.6 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0401349001092395		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.0401349001092395 | validation: 0.05806186498883609]
	TIME [epoch: 11.6 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04030204619155377		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.04030204619155377 | validation: 0.05562245234062605]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03899317140458641		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.03899317140458641 | validation: 0.041869149612594435]
	TIME [epoch: 11.6 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037211464970260164		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.037211464970260164 | validation: 0.050084508455270065]
	TIME [epoch: 11.6 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038078719182245785		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.038078719182245785 | validation: 0.050300816402128835]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038740644911154885		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.038740644911154885 | validation: 0.053503857975363285]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04186761640717083		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.04186761640717083 | validation: 0.053472001186452844]
	TIME [epoch: 11.6 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03901714619960454		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.03901714619960454 | validation: 0.04702318195968929]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037586014281707644		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.037586014281707644 | validation: 0.045250228976150615]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03215895251676314		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.03215895251676314 | validation: 0.046667471711981295]
	TIME [epoch: 11.6 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029815125587969477		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.029815125587969477 | validation: 0.05177970906817707]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03524893424160806		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.03524893424160806 | validation: 0.05022796311183592]
	TIME [epoch: 11.6 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03173931867564669		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.03173931867564669 | validation: 0.04475350181028661]
	TIME [epoch: 11.6 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03148206588741709		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.03148206588741709 | validation: 0.05650366592773213]
	TIME [epoch: 11.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035282421051238744		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.035282421051238744 | validation: 0.04684026268134244]
	TIME [epoch: 11.6 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03237835437653325		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.03237835437653325 | validation: 0.04951035559577261]
	TIME [epoch: 11.6 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031036507126135843		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.031036507126135843 | validation: 0.05158825332632642]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031573250453048846		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.031573250453048846 | validation: 0.05710019619263092]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03618372604946744		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.03618372604946744 | validation: 0.04831566475877876]
	TIME [epoch: 11.6 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038954503508664924		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.038954503508664924 | validation: 0.059083127358662446]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03525212821070746		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.03525212821070746 | validation: 0.05663206099638928]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03220348987457483		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.03220348987457483 | validation: 0.04763493000817892]
	TIME [epoch: 11.6 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036448761115445816		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.036448761115445816 | validation: 0.05107000256695311]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035778485958842775		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.035778485958842775 | validation: 0.05109427172740687]
	TIME [epoch: 11.6 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03895878547328856		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.03895878547328856 | validation: 0.05269549662002786]
	TIME [epoch: 11.6 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04035620675392638		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.04035620675392638 | validation: 0.06129888896994742]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042703090290841794		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.042703090290841794 | validation: 0.060050162330891624]
	TIME [epoch: 11.6 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03783055050771317		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.03783055050771317 | validation: 0.0514607282820724]
	TIME [epoch: 11.6 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03775995968925512		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.03775995968925512 | validation: 0.05643297352875768]
	TIME [epoch: 11.6 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042640049480187375		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.042640049480187375 | validation: 0.0653962490548504]
	TIME [epoch: 11.6 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048506681960733815		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.048506681960733815 | validation: 0.05974865743045644]
	TIME [epoch: 11.6 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04184854452538369		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.04184854452538369 | validation: 0.05403851807395388]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04367434968443991		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.04367434968443991 | validation: 0.06037285052806293]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03861553265351947		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.03861553265351947 | validation: 0.05238487288870347]
	TIME [epoch: 11.6 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03703336637316747		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.03703336637316747 | validation: 0.0540870439717306]
	TIME [epoch: 11.6 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03153280682624873		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.03153280682624873 | validation: 0.04928553508102672]
	TIME [epoch: 11.6 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03257997785217803		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.03257997785217803 | validation: 0.055107711102467614]
	TIME [epoch: 11.6 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03427822275300592		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.03427822275300592 | validation: 0.04225233314301063]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035037454293368714		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.035037454293368714 | validation: 0.05045963299543962]
	TIME [epoch: 11.6 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037389222543019116		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.037389222543019116 | validation: 0.04955798667324688]
	TIME [epoch: 11.6 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03894784695772456		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.03894784695772456 | validation: 0.06579058747797839]
	TIME [epoch: 11.6 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03744777188880784		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.03744777188880784 | validation: 0.04718037254759232]
	TIME [epoch: 11.6 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037871819412915286		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.037871819412915286 | validation: 0.054701364188159074]
	TIME [epoch: 11.6 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0348394968171929		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.0348394968171929 | validation: 0.0453883161080586]
	TIME [epoch: 11.6 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0338243815367067		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.0338243815367067 | validation: 0.05169670375206672]
	TIME [epoch: 11.6 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03477948511321387		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.03477948511321387 | validation: 0.05366791492809714]
	TIME [epoch: 11.6 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033927674446258244		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.033927674446258244 | validation: 0.042907956809872444]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03492840834547432		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.03492840834547432 | validation: 0.04709912332775611]
	TIME [epoch: 11.6 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0341131009328032		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.0341131009328032 | validation: 0.05296443496518089]
	TIME [epoch: 11.6 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0314685598910071		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.0314685598910071 | validation: 0.045233784233337196]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033992679002557265		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.033992679002557265 | validation: 0.04435758287931305]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03569900874775249		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.03569900874775249 | validation: 0.0520086633619149]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03514098255410569		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.03514098255410569 | validation: 0.04367972157405792]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03377424981123964		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.03377424981123964 | validation: 0.04240909839150412]
	TIME [epoch: 11.6 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031211744803603943		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.031211744803603943 | validation: 0.04797267357654919]
	TIME [epoch: 11.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032239495265706505		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.032239495265706505 | validation: 0.049596595060867256]
	TIME [epoch: 11.6 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330372978771054		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.0330372978771054 | validation: 0.047102415120682056]
	TIME [epoch: 11.6 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03443725782263936		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.03443725782263936 | validation: 0.05331292468413782]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03202023213973694		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.03202023213973694 | validation: 0.047493216093083886]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029718376085947646		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.029718376085947646 | validation: 0.054012451297986715]
	TIME [epoch: 11.6 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03238269389699367		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.03238269389699367 | validation: 0.05090369855471634]
	TIME [epoch: 11.6 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035058127827677726		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.035058127827677726 | validation: 0.047467429637179426]
	TIME [epoch: 11.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03658262272335238		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.03658262272335238 | validation: 0.04990207918869425]
	TIME [epoch: 11.6 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03535324662167346		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.03535324662167346 | validation: 0.04996631760558112]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037579115264924634		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.037579115264924634 | validation: 0.0554151859484452]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0342895346222588		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.0342895346222588 | validation: 0.04371187563457113]
	TIME [epoch: 11.6 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03606181429757596		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.03606181429757596 | validation: 0.05483316237876704]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032940371096714834		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.032940371096714834 | validation: 0.04134305389878704]
	TIME [epoch: 11.6 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034557577438483186		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.034557577438483186 | validation: 0.04793398982922265]
	TIME [epoch: 11.6 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03627318960456584		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.03627318960456584 | validation: 0.055923633367536425]
	TIME [epoch: 11.6 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037438508563422054		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.037438508563422054 | validation: 0.04871475606581504]
	TIME [epoch: 11.6 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03305332016997554		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.03305332016997554 | validation: 0.04867718534124598]
	TIME [epoch: 11.6 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03330891660892212		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.03330891660892212 | validation: 0.04194117756233602]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034618263630101107		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.034618263630101107 | validation: 0.04703630737181027]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03029843297360893		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.03029843297360893 | validation: 0.04648679431484738]
	TIME [epoch: 11.6 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030880361559605322		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.030880361559605322 | validation: 0.03829569179600369]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_1281.pth
	Model improved!!!
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03482556814900978		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.03482556814900978 | validation: 0.053797453145011484]
	TIME [epoch: 11.6 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032952031483290595		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.032952031483290595 | validation: 0.048306741364898244]
	TIME [epoch: 11.6 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03178638184394501		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.03178638184394501 | validation: 0.040791598034767985]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033471988597860464		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.033471988597860464 | validation: 0.0467300528312529]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03173614227229464		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.03173614227229464 | validation: 0.04188819831800731]
	TIME [epoch: 11.6 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03742913594389499		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.03742913594389499 | validation: 0.04289416743317192]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032338212078775866		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.032338212078775866 | validation: 0.04323663144004315]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03340688782363904		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.03340688782363904 | validation: 0.04579309549551883]
	TIME [epoch: 11.6 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034760491456692216		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.034760491456692216 | validation: 0.04823737400788163]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03710455655259798		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.03710455655259798 | validation: 0.03966141309033255]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035624180876557505		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.035624180876557505 | validation: 0.042775216607290056]
	TIME [epoch: 11.6 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037641596714102665		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.037641596714102665 | validation: 0.05596417193458197]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037511692086581505		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.037511692086581505 | validation: 0.052202341056093345]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03882693631335569		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.03882693631335569 | validation: 0.05290928415954315]
	TIME [epoch: 11.6 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040979499625053		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.040979499625053 | validation: 0.04408828299220096]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03850607455185817		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.03850607455185817 | validation: 0.05162886265455994]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03810992311997286		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.03810992311997286 | validation: 0.05210910409578821]
	TIME [epoch: 11.6 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04308059912629695		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.04308059912629695 | validation: 0.056785717191157756]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045924529760878165		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.045924529760878165 | validation: 0.056022247504323615]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03650596914757987		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.03650596914757987 | validation: 0.04553667907398074]
	TIME [epoch: 11.6 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04270543161171742		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.04270543161171742 | validation: 0.0516033057640668]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04182975434912407		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.04182975434912407 | validation: 0.05534739079240583]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049191257119705685		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.049191257119705685 | validation: 0.06119812983378045]
	TIME [epoch: 11.6 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05131841411409999		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.05131841411409999 | validation: 0.05791093653435211]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042607867776541415		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.042607867776541415 | validation: 0.0491606379427675]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042582500964257544		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.042582500964257544 | validation: 0.05299847336482537]
	TIME [epoch: 11.6 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04179492541959651		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.04179492541959651 | validation: 0.046696176494037796]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03825045768270335		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.03825045768270335 | validation: 0.047800188635236614]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04041734106734875		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.04041734106734875 | validation: 0.05362758385637885]
	TIME [epoch: 11.6 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03701531626750547		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.03701531626750547 | validation: 0.04725986103972372]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03994119852963084		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.03994119852963084 | validation: 0.049506656772950186]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032930071524567756		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.032930071524567756 | validation: 0.05384146853264284]
	TIME [epoch: 11.6 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03371960312815796		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.03371960312815796 | validation: 0.04658208551549337]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032318673216455096		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.032318673216455096 | validation: 0.04271943868799536]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0316508472792532		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.0316508472792532 | validation: 0.053065266987929544]
	TIME [epoch: 11.6 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031515142370113464		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.031515142370113464 | validation: 0.05862435726626404]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03072118068972937		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.03072118068972937 | validation: 0.043273731390752586]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030069860344295405		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.030069860344295405 | validation: 0.03898390640104509]
	TIME [epoch: 11.6 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03184095915966997		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.03184095915966997 | validation: 0.039994113495554]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02965328166396375		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.02965328166396375 | validation: 0.049911197396090706]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032224676091628046		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.032224676091628046 | validation: 0.04898869101985245]
	TIME [epoch: 11.6 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033861683924184746		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.033861683924184746 | validation: 0.04293552054127341]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03087454752559093		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.03087454752559093 | validation: 0.04261838516871437]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03345006725826455		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.03345006725826455 | validation: 0.048221902429304374]
	TIME [epoch: 11.6 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0360729572979894		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.0360729572979894 | validation: 0.04627028540244355]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0336649085785993		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.0336649085785993 | validation: 0.053310870474483296]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03602830007025344		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.03602830007025344 | validation: 0.04955851867186578]
	TIME [epoch: 11.6 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036061838086726396		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.036061838086726396 | validation: 0.045869864268937785]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03309862364677245		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.03309862364677245 | validation: 0.05327297861828754]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037182527720140614		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.037182527720140614 | validation: 0.048204770643834466]
	TIME [epoch: 11.6 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035766155767943626		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.035766155767943626 | validation: 0.04301058119730866]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033550349451386005		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.033550349451386005 | validation: 0.04918448870557998]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03184271931246625		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.03184271931246625 | validation: 0.048827495449580656]
	TIME [epoch: 11.6 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029692276336570813		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.029692276336570813 | validation: 0.048371395456798257]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03448247453288392		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.03448247453288392 | validation: 0.04339591207554468]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035778287010695936		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.035778287010695936 | validation: 0.04532825001761877]
	TIME [epoch: 11.6 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03453245627470955		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.03453245627470955 | validation: 0.05038982429034592]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031675971317641646		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.031675971317641646 | validation: 0.05422098474913563]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03674228785132967		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.03674228785132967 | validation: 0.045025065045167005]
	TIME [epoch: 11.6 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03152606507803163		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.03152606507803163 | validation: 0.05253741431474244]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03276347685391642		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.03276347685391642 | validation: 0.050273937387217055]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028761283565633892		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.028761283565633892 | validation: 0.04431477215349022]
	TIME [epoch: 11.6 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0335657855327522		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.0335657855327522 | validation: 0.053039731347949426]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03307513283527456		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.03307513283527456 | validation: 0.04715353231999794]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282705928410049		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.03282705928410049 | validation: 0.044422917920187606]
	TIME [epoch: 11.6 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03210387919977942		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.03210387919977942 | validation: 0.05076413570553992]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033086443283655745		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.033086443283655745 | validation: 0.042762337571762926]
	TIME [epoch: 11.6 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0304556216744204		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.0304556216744204 | validation: 0.041596694251845624]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02942206055230744		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.02942206055230744 | validation: 0.04291585789777429]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03170276802313113		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.03170276802313113 | validation: 0.053769971658914825]
	TIME [epoch: 11.6 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03292427470768498		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.03292427470768498 | validation: 0.04733417006944544]
	TIME [epoch: 11.6 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030999187335082667		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.030999187335082667 | validation: 0.05397441297865866]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034426933846142725		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.034426933846142725 | validation: 0.04696322477905183]
	TIME [epoch: 11.6 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028274948147539846		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.028274948147539846 | validation: 0.04995693401837352]
	TIME [epoch: 11.6 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034245888717657394		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.034245888717657394 | validation: 0.0468671545005693]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03171702359933903		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.03171702359933903 | validation: 0.04341353220020921]
	TIME [epoch: 11.6 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03553928703383739		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.03553928703383739 | validation: 0.052507219617085425]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031911864479142966		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.031911864479142966 | validation: 0.0482773754628094]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032454692896837306		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.032454692896837306 | validation: 0.05150660048829414]
	TIME [epoch: 11.6 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033607401516730376		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.033607401516730376 | validation: 0.049717878156441596]
	TIME [epoch: 11.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0314677667529212		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.0314677667529212 | validation: 0.047506799415485156]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031631712092493706		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.031631712092493706 | validation: 0.04354346660002218]
	TIME [epoch: 11.6 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03222646585436448		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.03222646585436448 | validation: 0.04501659707334952]
	TIME [epoch: 11.6 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0354617592909901		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.0354617592909901 | validation: 0.05084747944988294]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03440113550426382		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.03440113550426382 | validation: 0.04930190798360709]
	TIME [epoch: 11.6 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03551078706911925		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.03551078706911925 | validation: 0.044500928479664394]
	TIME [epoch: 11.6 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03133260359476618		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.03133260359476618 | validation: 0.04419118118619907]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03195839806908241		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.03195839806908241 | validation: 0.047009585700819784]
	TIME [epoch: 11.6 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027383442140283345		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.027383442140283345 | validation: 0.047774645049119345]
	TIME [epoch: 11.6 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031109845637776495		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.031109845637776495 | validation: 0.044370021744400294]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032885103993738216		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.032885103993738216 | validation: 0.045895665180447465]
	TIME [epoch: 11.6 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03338626320774858		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.03338626320774858 | validation: 0.044865739878575735]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029544625461284744		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.029544625461284744 | validation: 0.04444789864218307]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02980751902426829		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.02980751902426829 | validation: 0.04632270025539971]
	TIME [epoch: 11.6 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03468592044850104		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.03468592044850104 | validation: 0.0462853389431166]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02866178295365747		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.02866178295365747 | validation: 0.052427078608747735]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03185995275941467		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.03185995275941467 | validation: 0.04406443711716725]
	TIME [epoch: 11.6 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0318553721220414		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.0318553721220414 | validation: 0.05193801479451482]
	TIME [epoch: 11.6 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028336219782715194		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.028336219782715194 | validation: 0.046561915408647306]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031966587829662774		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.031966587829662774 | validation: 0.05467289262362366]
	TIME [epoch: 11.6 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03122484911662602		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.03122484911662602 | validation: 0.03689583125475574]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_1382.pth
	Model improved!!!
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02907843257860207		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.02907843257860207 | validation: 0.04008492416755608]
	TIME [epoch: 11.6 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02711228744406234		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.02711228744406234 | validation: 0.051352167254317876]
	TIME [epoch: 11.6 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032963080206212796		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.032963080206212796 | validation: 0.04401440513987745]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02959348876087735		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.02959348876087735 | validation: 0.048792040500048275]
	TIME [epoch: 11.6 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03190140666814764		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.03190140666814764 | validation: 0.05200856878813673]
	TIME [epoch: 11.6 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030920604405368597		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.030920604405368597 | validation: 0.04134889860388287]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0325472952263226		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.0325472952263226 | validation: 0.04298513791554865]
	TIME [epoch: 11.6 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029481624089203098		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.029481624089203098 | validation: 0.042539373623851344]
	TIME [epoch: 11.6 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0296202309807344		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.0296202309807344 | validation: 0.05258487231612866]
	TIME [epoch: 11.6 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027629163024771905		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.027629163024771905 | validation: 0.0415369339471406]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029399340043501147		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.029399340043501147 | validation: 0.04657252954269116]
	TIME [epoch: 11.6 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02883595903499385		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.02883595903499385 | validation: 0.045811952897160835]
	TIME [epoch: 11.6 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028586956899036446		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.028586956899036446 | validation: 0.03767965644423029]
	TIME [epoch: 11.6 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02736395124954813		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.02736395124954813 | validation: 0.046193255682078396]
	TIME [epoch: 11.6 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02790732733966851		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.02790732733966851 | validation: 0.03884198473885223]
	TIME [epoch: 11.6 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03010735297860299		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.03010735297860299 | validation: 0.04084853922375408]
	TIME [epoch: 11.6 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029901948496909286		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.029901948496909286 | validation: 0.04349394594132058]
	TIME [epoch: 11.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03144781997776122		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.03144781997776122 | validation: 0.04831856811376095]
	TIME [epoch: 11.6 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029958648620369482		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.029958648620369482 | validation: 0.04334591230765287]
	TIME [epoch: 11.6 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030295148722137483		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.030295148722137483 | validation: 0.038172708192793364]
	TIME [epoch: 11.6 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028677674259292595		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.028677674259292595 | validation: 0.04702410724612261]
	TIME [epoch: 11.6 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03189042817737844		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.03189042817737844 | validation: 0.046439353201860066]
	TIME [epoch: 11.6 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029473720490107796		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.029473720490107796 | validation: 0.03936730420742162]
	TIME [epoch: 11.6 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621354563926622		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.03621354563926622 | validation: 0.05300257810473353]
	TIME [epoch: 11.6 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03276153836097197		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.03276153836097197 | validation: 0.0506408729927744]
	TIME [epoch: 11.6 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03568539252528144		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.03568539252528144 | validation: 0.05072962631283631]
	TIME [epoch: 11.6 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033760420056343714		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.033760420056343714 | validation: 0.047343949987794454]
	TIME [epoch: 11.6 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03849142872449227		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.03849142872449227 | validation: 0.04793711447154009]
	TIME [epoch: 11.6 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0342992507392519		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.0342992507392519 | validation: 0.04419860750300859]
	TIME [epoch: 11.6 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03127342489600185		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.03127342489600185 | validation: 0.03903919149424892]
	TIME [epoch: 11.6 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03213068798075016		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.03213068798075016 | validation: 0.045042672715509935]
	TIME [epoch: 11.6 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029744172999892758		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.029744172999892758 | validation: 0.04532982124257066]
	TIME [epoch: 11.6 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026562884609781717		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.026562884609781717 | validation: 0.04151044373442016]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03568854381629453		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.03568854381629453 | validation: 0.05227866015780008]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03307398794652555		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.03307398794652555 | validation: 0.04207391559358241]
	TIME [epoch: 11.6 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0276696628622247		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.0276696628622247 | validation: 0.0494761359276168]
	TIME [epoch: 11.6 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031319223341225014		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.031319223341225014 | validation: 0.04394634840628382]
	TIME [epoch: 11.6 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03120651501568107		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.03120651501568107 | validation: 0.05109239472923001]
	TIME [epoch: 11.6 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035575853740279925		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.035575853740279925 | validation: 0.04704788552167192]
	TIME [epoch: 11.6 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03327813746174153		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.03327813746174153 | validation: 0.04969374733051765]
	TIME [epoch: 11.6 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031560772944768584		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.031560772944768584 | validation: 0.04620529033836163]
	TIME [epoch: 11.6 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03109840313441016		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.03109840313441016 | validation: 0.04919141165352148]
	TIME [epoch: 11.6 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03263724742926917		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.03263724742926917 | validation: 0.043627110455869554]
	TIME [epoch: 11.6 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030089553067827398		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.030089553067827398 | validation: 0.04469813074591031]
	TIME [epoch: 11.6 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028140360163449892		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.028140360163449892 | validation: 0.041923213310831466]
	TIME [epoch: 11.6 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03057266554948966		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.03057266554948966 | validation: 0.044612640157374546]
	TIME [epoch: 11.6 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028002267427157182		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.028002267427157182 | validation: 0.04239501699186483]
	TIME [epoch: 11.6 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028134741256149315		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.028134741256149315 | validation: 0.03904585125838069]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02550308605389868		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.02550308605389868 | validation: 0.038921829776539484]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02791898715886494		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.02791898715886494 | validation: 0.039308962655278126]
	TIME [epoch: 11.6 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030051321828489283		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.030051321828489283 | validation: 0.04735467033470898]
	TIME [epoch: 11.6 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029638456041511663		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.029638456041511663 | validation: 0.04278003257558795]
	TIME [epoch: 11.6 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03193374582154899		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.03193374582154899 | validation: 0.03916667785035671]
	TIME [epoch: 11.6 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03254161409856713		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.03254161409856713 | validation: 0.05160379938153418]
	TIME [epoch: 11.6 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029612220532018445		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.029612220532018445 | validation: 0.03966764635338543]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02816779650385897		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.02816779650385897 | validation: 0.04213034360163213]
	TIME [epoch: 11.6 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028429828016825177		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.028429828016825177 | validation: 0.04327412267257751]
	TIME [epoch: 11.6 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034563567392882466		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.034563567392882466 | validation: 0.04849969137061185]
	TIME [epoch: 11.6 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03102002735577542		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.03102002735577542 | validation: 0.03872015743152409]
	TIME [epoch: 11.6 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03312802884662822		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.03312802884662822 | validation: 0.04787763176672709]
	TIME [epoch: 11.6 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032001085266199054		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.032001085266199054 | validation: 0.04464299508943047]
	TIME [epoch: 11.6 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028927164415202385		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.028927164415202385 | validation: 0.03858641146912884]
	TIME [epoch: 11.6 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03388876101146108		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.03388876101146108 | validation: 0.05147186463260639]
	TIME [epoch: 11.6 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02790233377998667		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.02790233377998667 | validation: 0.039220471077998004]
	TIME [epoch: 11.6 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033005182723594484		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.033005182723594484 | validation: 0.04814409333539608]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032092906077428436		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.032092906077428436 | validation: 0.04502229551196568]
	TIME [epoch: 11.6 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030467474369521644		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.030467474369521644 | validation: 0.045186252014563236]
	TIME [epoch: 11.6 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030435231417873403		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.030435231417873403 | validation: 0.04556757657838761]
	TIME [epoch: 11.6 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02993365370712199		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.02993365370712199 | validation: 0.040578202672594696]
	TIME [epoch: 11.6 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02972262929624883		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.02972262929624883 | validation: 0.04646530001293844]
	TIME [epoch: 11.6 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029675958350028918		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.029675958350028918 | validation: 0.04534639518417451]
	TIME [epoch: 11.6 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027555868581465595		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.027555868581465595 | validation: 0.04423767036702856]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029100170902220293		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.029100170902220293 | validation: 0.04566697937610969]
	TIME [epoch: 11.6 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02888206885618985		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.02888206885618985 | validation: 0.04666863900971097]
	TIME [epoch: 11.6 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028695493782089427		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.028695493782089427 | validation: 0.0425289407319274]
	TIME [epoch: 11.6 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02871735195059963		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.02871735195059963 | validation: 0.04805033439581331]
	TIME [epoch: 11.6 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02980609780414856		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.02980609780414856 | validation: 0.04406766232244418]
	TIME [epoch: 11.6 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02957990479223635		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.02957990479223635 | validation: 0.045730281646698075]
	TIME [epoch: 11.6 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030623486244219608		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.030623486244219608 | validation: 0.040379215899563]
	TIME [epoch: 11.6 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026067568131527767		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.026067568131527767 | validation: 0.03543980372751492]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_1462.pth
	Model improved!!!
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02773137929783283		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.02773137929783283 | validation: 0.03752550152278166]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026431084489766166		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.026431084489766166 | validation: 0.041220965854676994]
	TIME [epoch: 11.6 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029607540344073875		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.029607540344073875 | validation: 0.04050184002124595]
	TIME [epoch: 11.6 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029298117422271525		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.029298117422271525 | validation: 0.04456408754120529]
	TIME [epoch: 11.6 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034188712183453054		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.034188712183453054 | validation: 0.047854077496557144]
	TIME [epoch: 11.6 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027409775464917265		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.027409775464917265 | validation: 0.05055451727484986]
	TIME [epoch: 11.6 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030399882683547874		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.030399882683547874 | validation: 0.05569123612953064]
	TIME [epoch: 11.6 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03146193434118317		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.03146193434118317 | validation: 0.04982908682489036]
	TIME [epoch: 11.6 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032515710155258566		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.032515710155258566 | validation: 0.0517966784322133]
	TIME [epoch: 11.6 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034871848474720295		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.034871848474720295 | validation: 0.053456040709034154]
	TIME [epoch: 11.6 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03322056610375608		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.03322056610375608 | validation: 0.04847935894779133]
	TIME [epoch: 11.6 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03524309330209341		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.03524309330209341 | validation: 0.04854982142301772]
	TIME [epoch: 11.6 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0387347199929826		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.0387347199929826 | validation: 0.05966297804728843]
	TIME [epoch: 11.6 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03688963105849438		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.03688963105849438 | validation: 0.0478707587080007]
	TIME [epoch: 11.6 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0348381081877312		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.0348381081877312 | validation: 0.05107027039481974]
	TIME [epoch: 11.6 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03290375272533538		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.03290375272533538 | validation: 0.04889539375902711]
	TIME [epoch: 11.6 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03288335799716176		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.03288335799716176 | validation: 0.04166974466300421]
	TIME [epoch: 11.6 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03189155259394723		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.03189155259394723 | validation: 0.04744729400724613]
	TIME [epoch: 11.6 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030213764526615276		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.030213764526615276 | validation: 0.041169293555994864]
	TIME [epoch: 11.6 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032335186205850054		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.032335186205850054 | validation: 0.045763505366074146]
	TIME [epoch: 11.6 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0337215309425624		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.0337215309425624 | validation: 0.045063421170920236]
	TIME [epoch: 11.6 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0360942570717254		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.0360942570717254 | validation: 0.04387932943499055]
	TIME [epoch: 11.6 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03158817211337598		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.03158817211337598 | validation: 0.04863346840988683]
	TIME [epoch: 11.6 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032385658791496984		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.032385658791496984 | validation: 0.04004501416308791]
	TIME [epoch: 11.6 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02843787163728305		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.02843787163728305 | validation: 0.045984772230816595]
	TIME [epoch: 11.6 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032926331776393924		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.032926331776393924 | validation: 0.04533011730683473]
	TIME [epoch: 11.6 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033177388244800585		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.033177388244800585 | validation: 0.03843709515532878]
	TIME [epoch: 11.6 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02903571578964413		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.02903571578964413 | validation: 0.050930133995963606]
	TIME [epoch: 11.6 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02799613188060802		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.02799613188060802 | validation: 0.050429193754246544]
	TIME [epoch: 11.6 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028570810158533303		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.028570810158533303 | validation: 0.04585062409464656]
	TIME [epoch: 11.6 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030670717695338287		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.030670717695338287 | validation: 0.04505028554421168]
	TIME [epoch: 11.6 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02975719398455232		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.02975719398455232 | validation: 0.04859250451302053]
	TIME [epoch: 11.6 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032878430699794715		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.032878430699794715 | validation: 0.0456072700286164]
	TIME [epoch: 11.6 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02812545990429135		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.02812545990429135 | validation: 0.03901263925936603]
	TIME [epoch: 11.6 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027499708539855734		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.027499708539855734 | validation: 0.046646361439320085]
	TIME [epoch: 11.6 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029899530311636852		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.029899530311636852 | validation: 0.04349625558725793]
	TIME [epoch: 11.6 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032340542346943425		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.032340542346943425 | validation: 0.04140219221253868]
	TIME [epoch: 11.6 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02983579738995805		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.02983579738995805 | validation: 0.048439008025964174]
	TIME [epoch: 11.6 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02978435727732688		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.02978435727732688 | validation: 0.03313918699293085]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_1501.pth
	Model improved!!!
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028803262419481515		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.028803262419481515 | validation: 0.040290023107274434]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026029065431530853		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.026029065431530853 | validation: 0.04245588238459095]
	TIME [epoch: 11.6 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030034442987834017		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.030034442987834017 | validation: 0.045589023405042485]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028860107497631644		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.028860107497631644 | validation: 0.04048795215565471]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028961327866152253		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.028961327866152253 | validation: 0.04521671688026863]
	TIME [epoch: 11.6 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028683460155989934		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.028683460155989934 | validation: 0.038828629330792064]
	TIME [epoch: 11.6 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027760326794311684		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.027760326794311684 | validation: 0.04772562571746621]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030665234758909442		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.030665234758909442 | validation: 0.045674940624785124]
	TIME [epoch: 11.6 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028446248206350635		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.028446248206350635 | validation: 0.04351856393526668]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028836253955443238		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.028836253955443238 | validation: 0.05093106326502589]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02967516264601224		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.02967516264601224 | validation: 0.043486837167019135]
	TIME [epoch: 11.6 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03153029285450405		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.03153029285450405 | validation: 0.04514686680987403]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030564747842109156		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.030564747842109156 | validation: 0.03872655015708232]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028814560798288605		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.028814560798288605 | validation: 0.043451834542608925]
	TIME [epoch: 11.6 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025971267496750605		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.025971267496750605 | validation: 0.04599791351202032]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029165525319051755		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.029165525319051755 | validation: 0.04734301936688885]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031717715721496925		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.031717715721496925 | validation: 0.04199169411718054]
	TIME [epoch: 11.6 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028517130112070507		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.028517130112070507 | validation: 0.04615879778956895]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02852075622701918		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.02852075622701918 | validation: 0.04513578133071558]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028708677827224797		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.028708677827224797 | validation: 0.05087336296904547]
	TIME [epoch: 11.6 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030188274374384594		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.030188274374384594 | validation: 0.042573869900120784]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03364988496944101		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.03364988496944101 | validation: 0.04494657614762948]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03049200565526612		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.03049200565526612 | validation: 0.042887321244559636]
	TIME [epoch: 11.6 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02878370733609249		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.02878370733609249 | validation: 0.05433258045306245]
	TIME [epoch: 11.6 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02758063518553353		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.02758063518553353 | validation: 0.0468275004183272]
	TIME [epoch: 11.6 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03182182279089849		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.03182182279089849 | validation: 0.04131036428083164]
	TIME [epoch: 11.6 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027082698511293093		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.027082698511293093 | validation: 0.04621820180247283]
	TIME [epoch: 11.6 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02637146564976919		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.02637146564976919 | validation: 0.049401064868618276]
	TIME [epoch: 11.6 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029984307864484673		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.029984307864484673 | validation: 0.04292216748658027]
	TIME [epoch: 11.6 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0309678964665054		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.0309678964665054 | validation: 0.04356328394453432]
	TIME [epoch: 11.6 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02706137530589424		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.02706137530589424 | validation: 0.04381024135211347]
	TIME [epoch: 11.6 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02734574737701831		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.02734574737701831 | validation: 0.039889557489696637]
	TIME [epoch: 11.6 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029955411213638695		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.029955411213638695 | validation: 0.04564424386265121]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02752723144060293		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.02752723144060293 | validation: 0.04404055617423417]
	TIME [epoch: 11.6 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02601913857248942		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.02601913857248942 | validation: 0.039505169475707216]
	TIME [epoch: 11.6 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03445287278307489		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.03445287278307489 | validation: 0.025781712493929427]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240309_135644/states/model_tr_study4_1537.pth
	Model improved!!!
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028221941513005937		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.028221941513005937 | validation: 0.034280732488155774]
	TIME [epoch: 11.6 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029171549577815915		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.029171549577815915 | validation: 0.03962978662017519]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025022053322739705		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.025022053322739705 | validation: 0.03914953252762992]
	TIME [epoch: 11.6 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02847179620748571		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.02847179620748571 | validation: 0.042715746169863913]
	TIME [epoch: 11.6 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02882453446015444		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.02882453446015444 | validation: 0.0373113706553638]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026817971307621608		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.026817971307621608 | validation: 0.0430292540554763]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03084233363015624		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.03084233363015624 | validation: 0.04410289123793014]
	TIME [epoch: 11.6 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027647536714145125		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.027647536714145125 | validation: 0.04337146762214209]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027295651335499577		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.027295651335499577 | validation: 0.042834422877208844]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030206547638064535		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.030206547638064535 | validation: 0.04705941356624373]
	TIME [epoch: 11.6 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02857065383241755		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.02857065383241755 | validation: 0.030013678206217784]
	TIME [epoch: 11.6 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029117865560694886		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.029117865560694886 | validation: 0.049772298209393696]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030023047587316207		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.030023047587316207 | validation: 0.039054626269379486]
	TIME [epoch: 11.6 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03008035465998069		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.03008035465998069 | validation: 0.03891424473487491]
	TIME [epoch: 11.6 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026567253886455512		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.026567253886455512 | validation: 0.04711269601336816]
	TIME [epoch: 11.6 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02935435109172571		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.02935435109172571 | validation: 0.04201961840776372]
	TIME [epoch: 11.6 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026450973342494064		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.026450973342494064 | validation: 0.041736200103224624]
	TIME [epoch: 11.6 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031054682869607365		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.031054682869607365 | validation: 0.0390677686691372]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02642743676566808		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.02642743676566808 | validation: 0.04132872870594231]
	TIME [epoch: 11.6 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029704318946828605		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.029704318946828605 | validation: 0.041766091815464035]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026013431532913772		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.026013431532913772 | validation: 0.03787355309330752]
	TIME [epoch: 11.6 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02845225989639748		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.02845225989639748 | validation: 0.045570126507050904]
	TIME [epoch: 11.6 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028228235128324015		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.028228235128324015 | validation: 0.04313763831257117]
	TIME [epoch: 11.6 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026871380459577206		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.026871380459577206 | validation: 0.04367767417254068]
	TIME [epoch: 11.6 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028398812026335735		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.028398812026335735 | validation: 0.04514069912188739]
	TIME [epoch: 11.6 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02969171023725018		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.02969171023725018 | validation: 0.038729831560954275]
	TIME [epoch: 11.6 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027497391010929333		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.027497391010929333 | validation: 0.03897911557839496]
	TIME [epoch: 11.6 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030191724066348888		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.030191724066348888 | validation: 0.04817386969104858]
	TIME [epoch: 11.6 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032019534310276196		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.032019534310276196 | validation: 0.04197124144633808]
	TIME [epoch: 11.6 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02700788273425278		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.02700788273425278 | validation: 0.03474532693117305]
	TIME [epoch: 11.6 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03325321985109736		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.03325321985109736 | validation: 0.040872259319362225]
	TIME [epoch: 11.6 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029002147048150052		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.029002147048150052 | validation: 0.041250655999261115]
	TIME [epoch: 11.6 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0313829191963291		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.0313829191963291 | validation: 0.04311541677799847]
	TIME [epoch: 11.6 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03180079177871745		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.03180079177871745 | validation: 0.04778797623311196]
	TIME [epoch: 11.6 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029006667128994478		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.029006667128994478 | validation: 0.04248909320890152]
	TIME [epoch: 11.6 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030805319890297733		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.030805319890297733 | validation: 0.045125720684861696]
	TIME [epoch: 11.6 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02965087160465999		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.02965087160465999 | validation: 0.04461781901103477]
	TIME [epoch: 11.6 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030025790667966366		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.030025790667966366 | validation: 0.05186185335139655]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0316566066514504		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.0316566066514504 | validation: 0.04321843410992596]
	TIME [epoch: 11.6 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030955119937535358		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.030955119937535358 | validation: 0.04588648537192299]
	TIME [epoch: 11.6 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02993372463468114		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.02993372463468114 | validation: 0.04502298613060514]
	TIME [epoch: 11.6 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028772930516993648		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.028772930516993648 | validation: 0.04697423363947053]
	TIME [epoch: 11.6 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030951910179273286		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.030951910179273286 | validation: 0.047677011274693815]
	TIME [epoch: 11.6 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03616458522423206		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.03616458522423206 | validation: 0.04741080236338149]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03123127771162743		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.03123127771162743 | validation: 0.041962503337053134]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03312471641867502		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.03312471641867502 | validation: 0.04237110413812297]
	TIME [epoch: 11.6 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030055412240403628		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.030055412240403628 | validation: 0.04703608746895374]
	TIME [epoch: 11.6 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03080033405105549		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.03080033405105549 | validation: 0.042965626367032606]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028096959575708444		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.028096959575708444 | validation: 0.04777123579288856]
	TIME [epoch: 11.6 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03125182423276418		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.03125182423276418 | validation: 0.04100206335636717]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0292003876248425		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.0292003876248425 | validation: 0.04747371335681924]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027298252900136842		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.027298252900136842 | validation: 0.051903046921153405]
	TIME [epoch: 11.6 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02849376322610412		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.02849376322610412 | validation: 0.04775457129549686]
	TIME [epoch: 11.6 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031776742522892136		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.031776742522892136 | validation: 0.046741364008688946]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031026285052006445		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.031026285052006445 | validation: 0.04487426263091354]
	TIME [epoch: 11.6 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028699049555570556		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.028699049555570556 | validation: 0.04307329354994014]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03105474709392974		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.03105474709392974 | validation: 0.041154227354744305]
	TIME [epoch: 11.6 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028552785051507983		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.028552785051507983 | validation: 0.04212421149952536]
	TIME [epoch: 11.6 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027947282776620674		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.027947282776620674 | validation: 0.044876952714885475]
	TIME [epoch: 11.6 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028948469173129553		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.028948469173129553 | validation: 0.041711793759302285]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029114083953085384		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.029114083953085384 | validation: 0.04397544869837354]
	TIME [epoch: 11.6 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029280088952353435		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.029280088952353435 | validation: 0.05346619636088706]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029066239021553135		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.029066239021553135 | validation: 0.04720034526415143]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02698491078110574		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.02698491078110574 | validation: 0.05086250528884871]
	TIME [epoch: 11.6 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03137879635296848		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.03137879635296848 | validation: 0.04701090038563361]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028551842216903517		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.028551842216903517 | validation: 0.03781192931073218]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026768623621596457		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.026768623621596457 | validation: 0.04403223905746682]
	TIME [epoch: 11.6 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028818632147811878		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.028818632147811878 | validation: 0.04032222203002579]
	TIME [epoch: 11.6 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03151014359189741		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.03151014359189741 | validation: 0.04816145741979531]
	TIME [epoch: 11.6 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026905459148846827		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.026905459148846827 | validation: 0.03363646500852038]
	TIME [epoch: 11.6 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030527699190234767		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.030527699190234767 | validation: 0.03326060311995404]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02888618907851011		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.02888618907851011 | validation: 0.04150331939293316]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029890732740549944		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.029890732740549944 | validation: 0.04347102202778099]
	TIME [epoch: 11.6 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029377596277346964		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.029377596277346964 | validation: 0.03861630491844408]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02618657163703885		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.02618657163703885 | validation: 0.04608673363652443]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025413459558308475		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.025413459558308475 | validation: 0.031985851978684046]
	TIME [epoch: 11.6 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03008060273566402		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.03008060273566402 | validation: 0.045197405839101513]
	TIME [epoch: 11.6 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02721392078675411		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.02721392078675411 | validation: 0.048971460960029155]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02995955875702909		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.02995955875702909 | validation: 0.043017012206413664]
	TIME [epoch: 11.6 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030908950890990876		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.030908950890990876 | validation: 0.04571024321334411]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0281333053876679		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.0281333053876679 | validation: 0.04035617118551068]
	TIME [epoch: 11.6 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032856426466044704		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.032856426466044704 | validation: 0.04600435408116413]
	TIME [epoch: 11.6 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033582396664848656		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.033582396664848656 | validation: 0.049067716631029004]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022400706676967842		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.022400706676967842 | validation: 0.045151864136110345]
	TIME [epoch: 11.6 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02884193138846378		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.02884193138846378 | validation: 0.04529168037195747]
	TIME [epoch: 11.6 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02972671506372631		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.02972671506372631 | validation: 0.0442370918821222]
	TIME [epoch: 11.6 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029669137138846377		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.029669137138846377 | validation: 0.047250689179677646]
	TIME [epoch: 11.6 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033484797527734075		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.033484797527734075 | validation: 0.0476464969450604]
	TIME [epoch: 11.6 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02581388548882228		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.02581388548882228 | validation: 0.04241510345532305]
	TIME [epoch: 11.6 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030719881276208047		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.030719881276208047 | validation: 0.04706422845891305]
	TIME [epoch: 11.6 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03388038220245538		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.03388038220245538 | validation: 0.04460094045755152]
	TIME [epoch: 11.6 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032154907875715996		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.032154907875715996 | validation: 0.04607150026237612]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02996346253201275		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.02996346253201275 | validation: 0.04490432296781754]
	TIME [epoch: 11.6 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032068587635113416		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.032068587635113416 | validation: 0.04884730667945925]
	TIME [epoch: 11.6 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02671598670674969		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.02671598670674969 | validation: 0.03915672661970992]
	TIME [epoch: 11.6 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028577759561886955		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.028577759561886955 | validation: 0.04958135891982709]
	TIME [epoch: 11.6 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02614646830306846		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.02614646830306846 | validation: 0.04148903449390993]
	TIME [epoch: 11.6 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033789534525934875		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.033789534525934875 | validation: 0.05108016251899885]
	TIME [epoch: 11.6 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430397769255709		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.03430397769255709 | validation: 0.04202835670068693]
	TIME [epoch: 11.6 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028304256078225058		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.028304256078225058 | validation: 0.040150887538450565]
	TIME [epoch: 11.6 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028771128512840444		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.028771128512840444 | validation: 0.040230319875196784]
	TIME [epoch: 11.6 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025025817181278567		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.025025817181278567 | validation: 0.036221470985278066]
	TIME [epoch: 11.6 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031593364315748634		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.031593364315748634 | validation: 0.0456916010149784]
	TIME [epoch: 11.6 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028540239216348885		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.028540239216348885 | validation: 0.04885623416673229]
	TIME [epoch: 11.6 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031111824494472015		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.031111824494472015 | validation: 0.042742811453581435]
	TIME [epoch: 11.6 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029687963738678873		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.029687963738678873 | validation: 0.050351707755706875]
	TIME [epoch: 11.6 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029538071532777613		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.029538071532777613 | validation: 0.04262327333008969]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028011009317590704		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.028011009317590704 | validation: 0.043693403959800446]
	TIME [epoch: 11.6 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026537717947486824		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.026537717947486824 | validation: 0.05694164174250894]
	TIME [epoch: 11.6 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02950817368990991		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.02950817368990991 | validation: 0.05000288401396081]
	TIME [epoch: 11.6 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03362338168320584		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.03362338168320584 | validation: 0.04331432240094323]
	TIME [epoch: 11.6 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02511021982710504		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.02511021982710504 | validation: 0.05314265342802095]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028820054201813536		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.028820054201813536 | validation: 0.04316301858567252]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02686783109738428		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.02686783109738428 | validation: 0.04344361467921166]
	TIME [epoch: 11.6 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02880406706857809		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.02880406706857809 | validation: 0.042831461422924384]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03041198941003183		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.03041198941003183 | validation: 0.04004917270008629]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02822315122451342		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.02822315122451342 | validation: 0.041051185103109365]
	TIME [epoch: 11.6 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026724456476390733		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.026724456476390733 | validation: 0.04356347528151997]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02688541230254862		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.02688541230254862 | validation: 0.03563885762917162]
	TIME [epoch: 11.6 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02771250018431376		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.02771250018431376 | validation: 0.04750128628168751]
	TIME [epoch: 11.6 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029277968135347953		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.029277968135347953 | validation: 0.04316122987029521]
	TIME [epoch: 11.6 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027945501532449173		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.027945501532449173 | validation: 0.040092228180252494]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02944529895452105		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.02944529895452105 | validation: 0.04578980363863962]
	TIME [epoch: 11.6 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03146338133696213		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.03146338133696213 | validation: 0.03927113464135675]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030797528738269152		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.030797528738269152 | validation: 0.04749919689707449]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02536590581590086		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.02536590581590086 | validation: 0.04781217455990719]
	TIME [epoch: 11.6 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027812298255438826		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.027812298255438826 | validation: 0.04716739827569074]
	TIME [epoch: 11.6 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029005832566652116		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.029005832566652116 | validation: 0.04883770368669056]
	TIME [epoch: 11.6 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024741825328809374		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.024741825328809374 | validation: 0.03697632692820747]
	TIME [epoch: 11.6 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02742720029274741		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.02742720029274741 | validation: 0.047621023038057375]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027344082702834425		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.027344082702834425 | validation: 0.04517853645283551]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03019829938601048		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.03019829938601048 | validation: 0.0465366094371741]
	TIME [epoch: 11.6 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03033379484417226		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.03033379484417226 | validation: 0.04585194477161649]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027099458754477307		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.027099458754477307 | validation: 0.049130878536611404]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028824369838084632		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.028824369838084632 | validation: 0.04180368437405565]
	TIME [epoch: 11.6 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033919114126016815		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.033919114126016815 | validation: 0.04045116235533563]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027008634418133344		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.027008634418133344 | validation: 0.046319501571996484]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030688282077334997		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.030688282077334997 | validation: 0.046791895837301534]
	TIME [epoch: 11.6 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031404001197365645		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.031404001197365645 | validation: 0.04578684257620995]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032700682898190316		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.032700682898190316 | validation: 0.04248446434950712]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028443598063916664		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.028443598063916664 | validation: 0.03617090768854219]
	TIME [epoch: 11.6 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02685077599275957		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.02685077599275957 | validation: 0.05037783756074359]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03146572845514033		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.03146572845514033 | validation: 0.04168398268208886]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03156380424479735		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.03156380424479735 | validation: 0.0468935224800747]
	TIME [epoch: 11.6 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029399279149282972		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.029399279149282972 | validation: 0.043063826811457456]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02890974099245344		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.02890974099245344 | validation: 0.04100537598650039]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025971490407090424		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.025971490407090424 | validation: 0.04516210261381636]
	TIME [epoch: 11.6 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029733134016691816		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.029733134016691816 | validation: 0.03824629125718869]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03489710687115187		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.03489710687115187 | validation: 0.04460069918165265]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032016336886415205		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.032016336886415205 | validation: 0.043412835406873615]
	TIME [epoch: 11.6 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03011975827579335		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.03011975827579335 | validation: 0.042743961221165895]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0293217106422839		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.0293217106422839 | validation: 0.03621315473595349]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029116987555314597		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.029116987555314597 | validation: 0.05398648515712049]
	TIME [epoch: 11.6 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027259116868230335		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.027259116868230335 | validation: 0.04801792452389203]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029869926288426933		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.029869926288426933 | validation: 0.03724035159111147]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025833282412473766		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.025833282412473766 | validation: 0.04417385492633009]
	TIME [epoch: 11.6 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0298668158032334		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.0298668158032334 | validation: 0.04623764298051501]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032695876944333006		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.032695876944333006 | validation: 0.048370899932196065]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02997008144547321		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.02997008144547321 | validation: 0.04685595506445596]
	TIME [epoch: 11.6 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028723267176212024		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.028723267176212024 | validation: 0.04242701828486977]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02429662425305347		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.02429662425305347 | validation: 0.04770481023841359]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030444334805340176		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.030444334805340176 | validation: 0.03447566700167177]
	TIME [epoch: 11.6 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029380491421247386		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.029380491421247386 | validation: 0.04216221082735405]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030095724628811008		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.030095724628811008 | validation: 0.045327064708978924]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028516271520665923		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.028516271520665923 | validation: 0.040379741943634015]
	TIME [epoch: 11.6 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028262640999788403		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.028262640999788403 | validation: 0.047130367204657395]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03203725372947507		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.03203725372947507 | validation: 0.04093034191414972]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03145056188003799		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.03145056188003799 | validation: 0.048580811585644604]
	TIME [epoch: 11.6 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029184788663858444		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.029184788663858444 | validation: 0.04395598938270712]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0317925132156647		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.0317925132156647 | validation: 0.050822565536578]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029704548034861646		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.029704548034861646 | validation: 0.047676698310368304]
	TIME [epoch: 11.6 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02960047068723213		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.02960047068723213 | validation: 0.04253936919997963]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027905561757720326		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.027905561757720326 | validation: 0.04255580593989031]
	TIME [epoch: 11.6 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0299498828759151		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.0299498828759151 | validation: 0.03685325338805682]
	TIME [epoch: 11.6 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024912424617636715		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.024912424617636715 | validation: 0.04493222941160247]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03402323403350424		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.03402323403350424 | validation: 0.04117856613033712]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030447340942499516		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.030447340942499516 | validation: 0.044475105445859225]
	TIME [epoch: 11.6 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030931131625339267		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.030931131625339267 | validation: 0.043885034784178906]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026434157208438985		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.026434157208438985 | validation: 0.04775175517412056]
	TIME [epoch: 11.6 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029093603727727818		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.029093603727727818 | validation: 0.04000787342573167]
	TIME [epoch: 11.6 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027306832121387237		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.027306832121387237 | validation: 0.046630879246579014]
	TIME [epoch: 11.6 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03013835620962689		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.03013835620962689 | validation: 0.03957982569722487]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025930453655366597		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.025930453655366597 | validation: 0.04144706343656015]
	TIME [epoch: 11.6 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02931167760923162		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.02931167760923162 | validation: 0.04008852186504171]
	TIME [epoch: 11.6 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028180670627835774		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.028180670627835774 | validation: 0.044941758021361536]
	TIME [epoch: 11.6 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029360859134546002		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.029360859134546002 | validation: 0.037822525662946214]
	TIME [epoch: 11.6 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029269460235189716		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.029269460235189716 | validation: 0.04319521807734832]
	TIME [epoch: 11.6 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028096869726574936		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.028096869726574936 | validation: 0.04740131371225278]
	TIME [epoch: 11.6 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029919182622050757		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.029919182622050757 | validation: 0.040808477812498294]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02911547964704106		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.02911547964704106 | validation: 0.03665027028827244]
	TIME [epoch: 11.6 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02689531563012505		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.02689531563012505 | validation: 0.041355606417012886]
	TIME [epoch: 11.6 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027191900779458093		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.027191900779458093 | validation: 0.042636190868870036]
	TIME [epoch: 11.6 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028461971869885423		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.028461971869885423 | validation: 0.043141698307843854]
	TIME [epoch: 11.6 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026510086747431112		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.026510086747431112 | validation: 0.04048994415430509]
	TIME [epoch: 11.6 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028968290376499607		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.028968290376499607 | validation: 0.0396447598671507]
	TIME [epoch: 11.6 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028383195536129772		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.028383195536129772 | validation: 0.04000785182985892]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02882309080276624		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.02882309080276624 | validation: 0.05202871358488048]
	TIME [epoch: 11.6 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02877827631024778		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.02877827631024778 | validation: 0.039813061185690425]
	TIME [epoch: 11.6 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02992023655183831		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.02992023655183831 | validation: 0.036604522434867136]
	TIME [epoch: 11.6 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028998733600319643		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.028998733600319643 | validation: 0.044807315766410824]
	TIME [epoch: 11.6 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033322779762289215		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.033322779762289215 | validation: 0.04455265102696248]
	TIME [epoch: 11.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028935481681909125		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.028935481681909125 | validation: 0.04448179810339272]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03247556215434812		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.03247556215434812 | validation: 0.040258622164387234]
	TIME [epoch: 11.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026876760796510704		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.026876760796510704 | validation: 0.04285457331649395]
	TIME [epoch: 11.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03211065768301911		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.03211065768301911 | validation: 0.0352624394927669]
	TIME [epoch: 11.6 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026387316074508792		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.026387316074508792 | validation: 0.038510753552555906]
	TIME [epoch: 11.6 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03067015672962428		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.03067015672962428 | validation: 0.0426525227588388]
	TIME [epoch: 11.6 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026845674106573767		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.026845674106573767 | validation: 0.04034622126759677]
	TIME [epoch: 11.6 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029222590624693245		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.029222590624693245 | validation: 0.038781840744216235]
	TIME [epoch: 11.6 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026934147855291964		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.026934147855291964 | validation: 0.046575538307906145]
	TIME [epoch: 11.6 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030511448723657138		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.030511448723657138 | validation: 0.04269266225104347]
	TIME [epoch: 11.6 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029768027198015558		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.029768027198015558 | validation: 0.04381145998035001]
	TIME [epoch: 11.6 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02705825760395513		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.02705825760395513 | validation: 0.03212577727212583]
	TIME [epoch: 11.6 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031101549532780676		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.031101549532780676 | validation: 0.047088973170789236]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027017194731642796		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.027017194731642796 | validation: 0.045887699885547084]
	TIME [epoch: 11.6 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028321968665644435		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.028321968665644435 | validation: 0.03759472341686767]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028202506367465068		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.028202506367465068 | validation: 0.04150969867125651]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025459861163979823		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.025459861163979823 | validation: 0.03748604464022545]
	TIME [epoch: 11.6 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024125200084647774		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.024125200084647774 | validation: 0.046028151552172096]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02370058573043444		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.02370058573043444 | validation: 0.04134064845362155]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028142203112343493		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.028142203112343493 | validation: 0.0527601265865616]
	TIME [epoch: 11.6 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028842115367487858		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.028842115367487858 | validation: 0.034841883702179374]
	TIME [epoch: 11.6 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0277541047802267		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.0277541047802267 | validation: 0.04228649072185973]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030563966817300003		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.030563966817300003 | validation: 0.036843104569163225]
	TIME [epoch: 11.6 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029473901305656306		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.029473901305656306 | validation: 0.04353837894144478]
	TIME [epoch: 11.6 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030106868065655962		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.030106868065655962 | validation: 0.040776685904841105]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030491561974621918		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.030491561974621918 | validation: 0.04823978053543075]
	TIME [epoch: 11.6 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03113121748447137		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.03113121748447137 | validation: 0.04236781809562344]
	TIME [epoch: 11.6 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03176318177279794		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.03176318177279794 | validation: 0.039993670481830106]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028627570952144583		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.028627570952144583 | validation: 0.041430093927865244]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032474576384260316		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.032474576384260316 | validation: 0.048064082032088076]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028002776636410986		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.028002776636410986 | validation: 0.044846716696497174]
	TIME [epoch: 11.6 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02936119956595402		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.02936119956595402 | validation: 0.046517474194378926]
	TIME [epoch: 11.6 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03039346628512269		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.03039346628512269 | validation: 0.04239177905187663]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02641696855569682		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.02641696855569682 | validation: 0.044566817857972965]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03217340375537284		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.03217340375537284 | validation: 0.03901338500898876]
	TIME [epoch: 11.6 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028323355309334018		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.028323355309334018 | validation: 0.042432274987394394]
	TIME [epoch: 11.6 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030501916871168332		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.030501916871168332 | validation: 0.03926882403801533]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026243294652341487		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.026243294652341487 | validation: 0.03701316486317496]
	TIME [epoch: 11.6 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030475013035983323		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.030475013035983323 | validation: 0.04357115934929662]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028491065563694726		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.028491065563694726 | validation: 0.04678165865720642]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03090894363876436		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.03090894363876436 | validation: 0.03991622483448255]
	TIME [epoch: 11.6 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03186462872942061		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.03186462872942061 | validation: 0.0410193668809686]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030912463464312746		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.030912463464312746 | validation: 0.041302967612929675]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030685092463658904		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.030685092463658904 | validation: 0.040989944417557655]
	TIME [epoch: 11.6 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03097496979557865		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.03097496979557865 | validation: 0.045035452191833275]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03124501452067526		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.03124501452067526 | validation: 0.04153517959806075]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031245896499622738		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.031245896499622738 | validation: 0.05011130389266819]
	TIME [epoch: 11.6 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027836830480361386		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.027836830480361386 | validation: 0.04111447226148899]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028920603185306558		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.028920603185306558 | validation: 0.03496724471975335]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02842717615605496		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.02842717615605496 | validation: 0.048272531723972376]
	TIME [epoch: 11.6 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028231920042098468		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.028231920042098468 | validation: 0.03880497086185039]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027547679411252732		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.027547679411252732 | validation: 0.04342460380693854]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029141041120470102		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.029141041120470102 | validation: 0.04625219721004668]
	TIME [epoch: 11.6 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030784985926774054		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.030784985926774054 | validation: 0.04303739704428045]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026515421593345287		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.026515421593345287 | validation: 0.044142519202296955]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030962618761745025		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.030962618761745025 | validation: 0.04534417885953669]
	TIME [epoch: 11.6 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0323715790916617		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.0323715790916617 | validation: 0.03545150449400819]
	TIME [epoch: 11.6 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026084837325571344		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.026084837325571344 | validation: 0.041423034344661484]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03220021504922767		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.03220021504922767 | validation: 0.040449327311216025]
	TIME [epoch: 11.6 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029201378693766725		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.029201378693766725 | validation: 0.04341296816588165]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029353753178882114		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.029353753178882114 | validation: 0.04416460862569451]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029353429613428295		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.029353429613428295 | validation: 0.04284439237101946]
	TIME [epoch: 11.6 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027227619230270568		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.027227619230270568 | validation: 0.04292976438510273]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028222418388150698		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.028222418388150698 | validation: 0.037988063599324835]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02686732059915216		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.02686732059915216 | validation: 0.039469795770687835]
	TIME [epoch: 11.6 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028761149170168428		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.028761149170168428 | validation: 0.0403108079279017]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033093038508189065		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.033093038508189065 | validation: 0.04037841945606019]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02902625247408938		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.02902625247408938 | validation: 0.043395497821996414]
	TIME [epoch: 11.6 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028081410232415026		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.028081410232415026 | validation: 0.04266902168359465]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026317322572094737		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.026317322572094737 | validation: 0.044312766222265855]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027697546398071905		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.027697546398071905 | validation: 0.047673945403244884]
	TIME [epoch: 11.6 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025428774481454336		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.025428774481454336 | validation: 0.04847183359614214]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030572446571752548		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.030572446571752548 | validation: 0.04311504454952474]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030730596982600646		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.030730596982600646 | validation: 0.04139901069894274]
	TIME [epoch: 11.6 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02822498107124965		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.02822498107124965 | validation: 0.03912623998532924]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0277312534651309		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.0277312534651309 | validation: 0.033793860812640214]
	TIME [epoch: 11.6 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027403863666577676		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.027403863666577676 | validation: 0.05038489206236948]
	TIME [epoch: 11.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02683216150366463		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.02683216150366463 | validation: 0.047712981316234464]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02745119480693168		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.02745119480693168 | validation: 0.03902560853953279]
	TIME [epoch: 11.6 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03253706929891537		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.03253706929891537 | validation: 0.043245052366806126]
	TIME [epoch: 11.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027618131845213376		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.027618131845213376 | validation: 0.04652871655991628]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02834226926756126		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.02834226926756126 | validation: 0.03826953071719073]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02962048680692378		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.02962048680692378 | validation: 0.04841250471236851]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0337277995948378		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.0337277995948378 | validation: 0.037736365989994435]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029963261862273566		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.029963261862273566 | validation: 0.04342028658847041]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028516623339421635		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.028516623339421635 | validation: 0.038380355557350525]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030642623975562337		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.030642623975562337 | validation: 0.0426037735038471]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02676798006590099		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.02676798006590099 | validation: 0.040088555501169375]
	TIME [epoch: 11.6 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024163872791639028		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.024163872791639028 | validation: 0.0401639571473099]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02745425556283743		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.02745425556283743 | validation: 0.04047748178055674]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029929569134087106		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.029929569134087106 | validation: 0.035104514748294464]
	TIME [epoch: 11.6 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02723072296115102		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.02723072296115102 | validation: 0.04089303466114957]
	TIME [epoch: 11.6 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02921147727691038		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.02921147727691038 | validation: 0.04509873321558893]
	TIME [epoch: 11.6 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029063102259962885		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.029063102259962885 | validation: 0.04263543427355522]
	TIME [epoch: 11.6 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027328429427120673		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.027328429427120673 | validation: 0.042032916067369794]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027315808874064942		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.027315808874064942 | validation: 0.04276691545395612]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02785805887730345		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.02785805887730345 | validation: 0.048692184390546275]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02661495737693345		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.02661495737693345 | validation: 0.04025665527560473]
	TIME [epoch: 11.6 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029154233311384205		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.029154233311384205 | validation: 0.04479768842313989]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026840214701659305		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.026840214701659305 | validation: 0.046566186648051226]
	TIME [epoch: 11.6 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02829679955895555		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.02829679955895555 | validation: 0.040857120534510294]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029609311226623178		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.029609311226623178 | validation: 0.04482291733048727]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03021571032489352		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.03021571032489352 | validation: 0.04124580782435157]
	TIME [epoch: 11.6 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025427733784286914		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.025427733784286914 | validation: 0.04274827249161039]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030505050167512846		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.030505050167512846 | validation: 0.03920648276499364]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028490183122796723		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.028490183122796723 | validation: 0.04724445420170825]
	TIME [epoch: 11.6 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028286169597639597		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.028286169597639597 | validation: 0.046216214965058004]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024172775390730233		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.024172775390730233 | validation: 0.04303183663286267]
	TIME [epoch: 11.6 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02968018771203852		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.02968018771203852 | validation: 0.04625238178463951]
	TIME [epoch: 11.6 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028067409728299644		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.028067409728299644 | validation: 0.04172500378420198]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029065539880653305		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.029065539880653305 | validation: 0.03983927936434427]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02747093012210154		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.02747093012210154 | validation: 0.035121995023811754]
	TIME [epoch: 11.6 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030853953351004285		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.030853953351004285 | validation: 0.039773010163539846]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029607619082636805		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.029607619082636805 | validation: 0.042610347392389294]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025940580820351805		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.025940580820351805 | validation: 0.038298837594596985]
	TIME [epoch: 11.6 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02893233945212732		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.02893233945212732 | validation: 0.043307182140318395]
	TIME [epoch: 11.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029066892349542656		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.029066892349542656 | validation: 0.039493722865143736]
	TIME [epoch: 11.6 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027070800074749757		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.027070800074749757 | validation: 0.04562414857186682]
	TIME [epoch: 11.6 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02851218495001483		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.02851218495001483 | validation: 0.040014504571078816]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029330533364782002		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.029330533364782002 | validation: 0.03429476322939356]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028534121859839136		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.028534121859839136 | validation: 0.03913160325404847]
	TIME [epoch: 11.6 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027167321210763058		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.027167321210763058 | validation: 0.04311791332964478]
	TIME [epoch: 11.6 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027842520764206548		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.027842520764206548 | validation: 0.05170723194719348]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025736804856526404		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.025736804856526404 | validation: 0.03664418557437883]
	TIME [epoch: 11.6 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027849304973137878		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.027849304973137878 | validation: 0.040079680848450254]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02731144431950605		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.02731144431950605 | validation: 0.04413674498230224]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030134993371527433		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.030134993371527433 | validation: 0.04936181450329771]
	TIME [epoch: 11.6 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026147786633549306		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.026147786633549306 | validation: 0.05336588477492959]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028563524639237583		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.028563524639237583 | validation: 0.04792045084570688]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02810386946165903		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.02810386946165903 | validation: 0.04084827145665225]
	TIME [epoch: 11.6 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028939115722161356		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.028939115722161356 | validation: 0.04989562982119276]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026326513663721098		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.026326513663721098 | validation: 0.04289023327387414]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02673918868386817		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.02673918868386817 | validation: 0.039854130286199926]
	TIME [epoch: 11.6 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02939249684162086		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.02939249684162086 | validation: 0.04950087046606666]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026156315214354423		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.026156315214354423 | validation: 0.03965292881565351]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026590628077835743		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.026590628077835743 | validation: 0.039588196210726824]
	TIME [epoch: 11.6 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028494173845094964		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.028494173845094964 | validation: 0.049760807674345355]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02659952589198496		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.02659952589198496 | validation: 0.0397939428472248]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028272187908026773		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.028272187908026773 | validation: 0.04135793640442638]
	TIME [epoch: 11.6 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026415351440803633		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.026415351440803633 | validation: 0.03692166267091948]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028546950935809754		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.028546950935809754 | validation: 0.04824084468759399]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
