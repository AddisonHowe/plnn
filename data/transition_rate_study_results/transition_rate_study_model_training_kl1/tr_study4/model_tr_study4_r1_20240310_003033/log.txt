Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r1', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3407523339

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.648978289194229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.648978289194229 | validation: 9.168358601485942]
	TIME [epoch: 101 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.153713698223523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.153713698223523 | validation: 7.563113547564182]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.971430581726247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.971430581726247 | validation: 7.381089194191469]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.581095166241436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.581095166241436 | validation: 7.370685083414017]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.490361798456793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.490361798456793 | validation: 6.98253111424135]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.241665181303321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.241665181303321 | validation: 6.900826911600043]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.164241341528527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.164241341528527 | validation: 6.835358302611593]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.069545030752593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.069545030752593 | validation: 6.734656202753493]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.142662474316567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.142662474316567 | validation: 5.284608172981201]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0779029724683244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0779029724683244 | validation: 4.570610701666368]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.498851105789051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.498851105789051 | validation: 3.992117369471705]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.922766576357563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.922766576357563 | validation: 3.8148920796471737]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.178225221658248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.178225221658248 | validation: 3.345478034942407]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.838070568046534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.838070568046534 | validation: 9.348458005330697]
	TIME [epoch: 11.5 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.942253631412148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.942253631412148 | validation: 3.979591043261189]
	TIME [epoch: 11.5 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.982683027100427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.982683027100427 | validation: 3.615442325316972]
	TIME [epoch: 11.5 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.640377736439106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.640377736439106 | validation: 3.4868033737871147]
	TIME [epoch: 11.5 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4594082181327224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4594082181327224 | validation: 3.380351803896101]
	TIME [epoch: 11.5 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.288772040395668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.288772040395668 | validation: 3.389468414530266]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4832299462675547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4832299462675547 | validation: 3.418150908154175]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1662627889542936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1662627889542936 | validation: 2.9037281958666092]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1330018102812915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1330018102812915 | validation: 2.8388563289704543]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9836619357341525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9836619357341525 | validation: 2.8744321196618627]
	TIME [epoch: 11.5 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.877739211324307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.877739211324307 | validation: 2.7403593642712987]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7316003615273656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7316003615273656 | validation: 2.572702668239082]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9113229734887383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9113229734887383 | validation: 2.5871511276706007]
	TIME [epoch: 11.5 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1400239401007535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1400239401007535 | validation: 2.5702263343989245]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.709207351077609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.709207351077609 | validation: 2.3865763772077218]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4521970077004402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4521970077004402 | validation: 2.7097089079525767]
	TIME [epoch: 11.5 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6613305988965026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6613305988965026 | validation: 2.364656680947922]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3473165249101298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3473165249101298 | validation: 2.844951597396949]
	TIME [epoch: 11.5 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6029244573787023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6029244573787023 | validation: 2.0385777914914143]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1042270701837724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1042270701837724 | validation: 2.074733871511079]
	TIME [epoch: 11.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.160456399782081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.160456399782081 | validation: 1.8460689787141735]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8850739286293838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8850739286293838 | validation: 1.8138810635998384]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9780048454449997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9780048454449997 | validation: 1.7168575245159]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.95667789253531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.95667789253531 | validation: 1.7546845882010729]
	TIME [epoch: 11.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8831343800184435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8831343800184435 | validation: 1.6302532857461507]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5838537563361212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5838537563361212 | validation: 3.707152383006443]
	TIME [epoch: 11.5 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.232869273752267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.232869273752267 | validation: 1.9386558768665965]
	TIME [epoch: 11.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8117982458438635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8117982458438635 | validation: 1.3108786435382367]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7231677618476366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7231677618476366 | validation: 1.520891031296539]
	TIME [epoch: 11.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.587611985967448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.587611985967448 | validation: 1.4183251897495794]
	TIME [epoch: 11.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3854872277794075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3854872277794075 | validation: 1.2232112647719207]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3475429981667322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3475429981667322 | validation: 1.3211732236805551]
	TIME [epoch: 11.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3144057503500914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3144057503500914 | validation: 1.3939471948919202]
	TIME [epoch: 11.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.759629315054344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.759629315054344 | validation: 1.1421134778379327]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2718340223824907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2718340223824907 | validation: 0.885220511510576]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3797116338645368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3797116338645368 | validation: 0.8292514336598168]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9573052910829744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9573052910829744 | validation: 1.032329371768186]
	TIME [epoch: 11.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0849226997112165		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.0849226997112165 | validation: 1.080563938970201]
	TIME [epoch: 11.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0399098273820768		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.0399098273820768 | validation: 0.7406592581764271]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1714740074974999		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.1714740074974999 | validation: 0.9583461773968651]
	TIME [epoch: 11.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3063289527157171		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.3063289527157171 | validation: 1.8117896569384941]
	TIME [epoch: 11.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9639673560533517		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.9639673560533517 | validation: 0.782851984260748]
	TIME [epoch: 11.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9553936986611327		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.9553936986611327 | validation: 0.8243871727329937]
	TIME [epoch: 11.5 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9386014208654918		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.9386014208654918 | validation: 0.6715903906243454]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2515412571885656		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.2515412571885656 | validation: 0.5870298899467364]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7500200644187877		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.7500200644187877 | validation: 1.0927166059493612]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7990851407225148		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.7990851407225148 | validation: 0.5885490320186836]
	TIME [epoch: 11.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7419585979518497		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.7419585979518497 | validation: 1.102163481163139]
	TIME [epoch: 11.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9100804930263362		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.9100804930263362 | validation: 1.1479483561269412]
	TIME [epoch: 11.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0723446891094401		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.0723446891094401 | validation: 0.9364893703030224]
	TIME [epoch: 11.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7513720104644659		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.7513720104644659 | validation: 0.7569871647343948]
	TIME [epoch: 11.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8480400951690406		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.8480400951690406 | validation: 0.5852037808393855]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396841723068485		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.5396841723068485 | validation: 0.6568322390951584]
	TIME [epoch: 11.5 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.903611524286062		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.903611524286062 | validation: 0.782999980279854]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8232807593583793		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.8232807593583793 | validation: 1.0553718669904364]
	TIME [epoch: 11.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6938550444915847		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.6938550444915847 | validation: 1.2582277377268811]
	TIME [epoch: 11.5 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.954481012052007		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.954481012052007 | validation: 1.4897969362302639]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.883520338537987		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.883520338537987 | validation: 0.4490620600928824]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235746994576575		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.6235746994576575 | validation: 0.5736422040280996]
	TIME [epoch: 11.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8227172702307418		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.8227172702307418 | validation: 0.715248217393795]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7130989102431865		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.7130989102431865 | validation: 0.976792489779632]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9650001444490254		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.9650001444490254 | validation: 0.8010543971458105]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7033621196160408		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.7033621196160408 | validation: 0.9154464694888976]
	TIME [epoch: 11.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6769059064003635		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.6769059064003635 | validation: 0.5436571419208294]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.889868703272746		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.889868703272746 | validation: 1.1007794806538818]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9104432261166722		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.9104432261166722 | validation: 0.7836652773532208]
	TIME [epoch: 11.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6352189618143826		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.6352189618143826 | validation: 0.5202702434995382]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5559286421432613		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.5559286421432613 | validation: 0.6731979748532462]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6541357974408988		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.6541357974408988 | validation: 0.4622978999845519]
	TIME [epoch: 11.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5872847948139793		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.5872847948139793 | validation: 2.849929627421287]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7644267660399044		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.7644267660399044 | validation: 0.7264815276853467]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872369163393152		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.6872369163393152 | validation: 0.6951060463760658]
	TIME [epoch: 11.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5822269385578447		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.5822269385578447 | validation: 0.5254682888797091]
	TIME [epoch: 11.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43194166250785504		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.43194166250785504 | validation: 0.4528003476427334]
	TIME [epoch: 11.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5807513666487065		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.5807513666487065 | validation: 0.6166190008316831]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6021905131627907		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.6021905131627907 | validation: 0.35265811068863523]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.820162647283498		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.820162647283498 | validation: 0.891273293210756]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6716643418749879		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.6716643418749879 | validation: 0.5949935424852142]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5729607230239014		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.5729607230239014 | validation: 0.822419885579262]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.587162516017883		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.587162516017883 | validation: 1.0085989379007771]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6279781932947797		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.6279781932947797 | validation: 1.1841534726447605]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0000975511139016		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.0000975511139016 | validation: 0.5531877401656093]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4860175372968485		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.4860175372968485 | validation: 0.522134128608937]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.75847424660404		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.75847424660404 | validation: 0.4003279642515165]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4736630973242718		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.4736630973242718 | validation: 0.5684486468375488]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5231669208276175		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.5231669208276175 | validation: 0.42937823409447784]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5271032648197811		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.5271032648197811 | validation: 0.9405115182492665]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7664923084119628		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.7664923084119628 | validation: 0.4626232487118299]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47372734990851884		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.47372734990851884 | validation: 0.3180023655670402]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4298335613721367		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.4298335613721367 | validation: 0.411189009485134]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4919944932678967		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.4919944932678967 | validation: 0.5414176923348836]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213218152093419		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.7213218152093419 | validation: 0.4872741250388733]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5128988364008822		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.5128988364008822 | validation: 0.5055243661383423]
	TIME [epoch: 11.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44041778754571614		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.44041778754571614 | validation: 0.3725709782880915]
	TIME [epoch: 11.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.432340448224349		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.432340448224349 | validation: 0.6333536843228978]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5270168340726027		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.5270168340726027 | validation: 0.3888207865161556]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48744776751942676		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.48744776751942676 | validation: 0.7253583693637111]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8371391633407976		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.8371391633407976 | validation: 0.36316102140381346]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4753378136701685		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.4753378136701685 | validation: 0.3568862970343302]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3909534923605271		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.3909534923605271 | validation: 0.31781710974324584]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42766582494515104		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.42766582494515104 | validation: 0.4986426069629398]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4504037509046176		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.4504037509046176 | validation: 0.4561514798023895]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5699549748380465		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.5699549748380465 | validation: 0.4279678945585813]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5763017599971142		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.5763017599971142 | validation: 0.8469229701263521]
	TIME [epoch: 11.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8978828833506067		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.8978828833506067 | validation: 0.4675015049918482]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5464362902176676		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.5464362902176676 | validation: 0.4151680011749175]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40627405736210875		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.40627405736210875 | validation: 0.5102069012385971]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.83266497297328		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.83266497297328 | validation: 0.8825316638572364]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6272873671197333		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.6272873671197333 | validation: 1.2322937565478256]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7924064427350405		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.7924064427350405 | validation: 0.42735458991306674]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4430056891739039		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.4430056891739039 | validation: 0.4033232176917826]
	TIME [epoch: 11.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4177726497588121		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.4177726497588121 | validation: 0.6444912963800802]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4778908414417612		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.4778908414417612 | validation: 0.5720133567817524]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5361660788632994		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.5361660788632994 | validation: 0.4414053257877014]
	TIME [epoch: 11.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37374271515897917		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.37374271515897917 | validation: 0.770885909880445]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.57197145431456		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.57197145431456 | validation: 0.7060372504107579]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7007011121193577		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.7007011121193577 | validation: 0.34682916110346623]
	TIME [epoch: 11.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9620596827215099		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.9620596827215099 | validation: 0.6617403987559669]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49970673435669655		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.49970673435669655 | validation: 0.4146230169910221]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4323080331671837		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.4323080331671837 | validation: 0.30228610611121304]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3220384471421626		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.3220384471421626 | validation: 0.4173113811219729]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4019946837619185		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.4019946837619185 | validation: 0.3818467990896381]
	TIME [epoch: 11.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601926162486886		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.3601926162486886 | validation: 0.43349334618228713]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5310662016231089		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.5310662016231089 | validation: 0.3092049636355212]
	TIME [epoch: 11.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43686466160729676		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.43686466160729676 | validation: 0.584707436510681]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4408271730597103		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.4408271730597103 | validation: 0.3049974122188877]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36589022706326635		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.36589022706326635 | validation: 0.25240925755242827]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3997273674964555		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.3997273674964555 | validation: 0.43354830444897324]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4119055208670883		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.4119055208670883 | validation: 0.33209232629389923]
	TIME [epoch: 11.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40955799265114534		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.40955799265114534 | validation: 0.36201600285090985]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3518554430499099		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.3518554430499099 | validation: 0.2933256225025337]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2879210825574755		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.2879210825574755 | validation: 0.2841754364696077]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3153922654296984		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.3153922654296984 | validation: 0.2561549860057969]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34774123491287395		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.34774123491287395 | validation: 0.5279217883496949]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5669317375416214		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.5669317375416214 | validation: 0.40361049831454837]
	TIME [epoch: 11.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3460892510020944		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.3460892510020944 | validation: 0.3884880040949665]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4077404469896665		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.4077404469896665 | validation: 0.38370373757515835]
	TIME [epoch: 11.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4507379913300219		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.4507379913300219 | validation: 0.3963076948564894]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3790561889813028		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3790561889813028 | validation: 0.35389660898419634]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42793662591999465		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.42793662591999465 | validation: 0.34695416630113246]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5483721521805309		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.5483721521805309 | validation: 0.4396299576752915]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46686882494916937		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.46686882494916937 | validation: 0.492552260132652]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.418263404367044		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.418263404367044 | validation: 0.673112157148238]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4689649869238963		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.4689649869238963 | validation: 0.3855327479457207]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27457093482666206		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.27457093482666206 | validation: 0.3850355465100404]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3280384621497912		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.3280384621497912 | validation: 0.2990970971936139]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3253587853875121		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.3253587853875121 | validation: 0.3454187543992613]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29488184980865273		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.29488184980865273 | validation: 0.40388179483740805]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5125224396126729		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.5125224396126729 | validation: 0.5316233467717209]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43477677800694503		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.43477677800694503 | validation: 0.3076723408515022]
	TIME [epoch: 11.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4308609027585882		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.4308609027585882 | validation: 2.4808345963619485]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0806046046042619		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.0806046046042619 | validation: 0.3275726632292276]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32344729968286934		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.32344729968286934 | validation: 0.4393848902879354]
	TIME [epoch: 11.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37117858458419495		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.37117858458419495 | validation: 0.29495055497134537]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29519607809036985		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.29519607809036985 | validation: 0.3357431765439959]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3349182693833128		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.3349182693833128 | validation: 0.29395043582292174]
	TIME [epoch: 11.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34927172246136484		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.34927172246136484 | validation: 0.26812614239774785]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3364138953875783		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.3364138953875783 | validation: 0.30539306441053965]
	TIME [epoch: 11.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2551103042018755		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.2551103042018755 | validation: 0.25175534446017134]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44285078044856524		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.44285078044856524 | validation: 0.32259515557666973]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3792510044633667		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.3792510044633667 | validation: 0.5285047091539664]
	TIME [epoch: 11.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5050920529370027		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.5050920529370027 | validation: 0.7755172384806602]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5100512582058909		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.5100512582058909 | validation: 0.3975690332010178]
	TIME [epoch: 11.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4999866873222811		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.4999866873222811 | validation: 0.38310203985101837]
	TIME [epoch: 11.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3367528573491025		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.3367528573491025 | validation: 0.3541389873843969]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2881203553158032		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2881203553158032 | validation: 0.3155564483234282]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3863813864658932		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.3863813864658932 | validation: 0.2858274623233447]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31770682739506095		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.31770682739506095 | validation: 0.5918919927784834]
	TIME [epoch: 11.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4343597463309186		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.4343597463309186 | validation: 0.2967513009987706]
	TIME [epoch: 11.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36228050663773104		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.36228050663773104 | validation: 0.6064518490471366]
	TIME [epoch: 11.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43548277572075844		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.43548277572075844 | validation: 0.36522089754938764]
	TIME [epoch: 11.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36134580556392415		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.36134580556392415 | validation: 0.33314442273244405]
	TIME [epoch: 11.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33216670791850456		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.33216670791850456 | validation: 0.3891080402432083]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3771967332564085		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.3771967332564085 | validation: 0.4283413898483988]
	TIME [epoch: 11.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43978228078173026		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.43978228078173026 | validation: 0.5480093612167933]
	TIME [epoch: 11.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4528017235888665		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.4528017235888665 | validation: 0.40508277612050514]
	TIME [epoch: 11.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42266850444092663		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.42266850444092663 | validation: 0.3833263529298073]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3406330916561531		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.3406330916561531 | validation: 0.3377085407747426]
	TIME [epoch: 11.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35884350768650075		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.35884350768650075 | validation: 0.5158545736617429]
	TIME [epoch: 11.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46519813596466125		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.46519813596466125 | validation: 0.6105270079082178]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6482039492287904		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.6482039492287904 | validation: 0.5325350515208159]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4106596356471764		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.4106596356471764 | validation: 0.5892987337990576]
	TIME [epoch: 11.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3832722386821194		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.3832722386821194 | validation: 0.39067234062345946]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2639437997863314		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.2639437997863314 | validation: 0.24248778996782608]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2759171248208971		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.2759171248208971 | validation: 0.3338956887988771]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3033583783727387		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.3033583783727387 | validation: 0.26719778765173896]
	TIME [epoch: 11.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2762215541137466		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.2762215541137466 | validation: 0.32483691945280796]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27622417887340034		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.27622417887340034 | validation: 0.295389304296643]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3712811023351832		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.3712811023351832 | validation: 0.3889385714167316]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2973872797388371		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.2973872797388371 | validation: 0.28446526385652265]
	TIME [epoch: 11.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2866078339434197		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.2866078339434197 | validation: 0.46099438265444903]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33576556552026054		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.33576556552026054 | validation: 0.20871688449416578]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27908622659865445		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.27908622659865445 | validation: 0.31305005130549524]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27069793175718526		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.27069793175718526 | validation: 0.18743729019333216]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2620731910281144		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.2620731910281144 | validation: 0.1742823201680001]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27880047931953794		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.27880047931953794 | validation: 0.3864531548439864]
	TIME [epoch: 11.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31497593182137773		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.31497593182137773 | validation: 0.27024703579266907]
	TIME [epoch: 11.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27415538139975526		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.27415538139975526 | validation: 0.2792960606926127]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4077974568662894		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.4077974568662894 | validation: 0.3007807114655798]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2722336599646673		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.2722336599646673 | validation: 0.24794689813835888]
	TIME [epoch: 11.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41952590901602055		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.41952590901602055 | validation: 0.38419338942144676]
	TIME [epoch: 11.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.361694523873923		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.361694523873923 | validation: 0.24654150495108318]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28831614505958514		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.28831614505958514 | validation: 0.44476089225659626]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3873906799888563		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.3873906799888563 | validation: 0.2887716929427275]
	TIME [epoch: 11.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2401319306856508		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.2401319306856508 | validation: 0.20764986071552005]
	TIME [epoch: 11.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2319933060150615		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.2319933060150615 | validation: 0.23311970161872456]
	TIME [epoch: 11.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22982146452897018		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.22982146452897018 | validation: 0.23059919046488625]
	TIME [epoch: 11.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22075433461937388		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.22075433461937388 | validation: 0.3013968280530895]
	TIME [epoch: 11.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785172773894754		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.2785172773894754 | validation: 0.30817132858480156]
	TIME [epoch: 11.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524795209401438		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.3524795209401438 | validation: 0.5522045570594734]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33307570626745064		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.33307570626745064 | validation: 0.3072494532194495]
	TIME [epoch: 11.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2780892395277428		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.2780892395277428 | validation: 0.5223087267826072]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35480885922417094		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.35480885922417094 | validation: 0.30358660259947556]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3489696517221268		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.3489696517221268 | validation: 0.3673067405082183]
	TIME [epoch: 11.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3705711001950844		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.3705711001950844 | validation: 0.3538910741735434]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33059626721807717		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.33059626721807717 | validation: 0.33523022246078976]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34806993210343384		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.34806993210343384 | validation: 0.3451175749637808]
	TIME [epoch: 11.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28790311218909503		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.28790311218909503 | validation: 0.240387799846132]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2561953390635083		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.2561953390635083 | validation: 0.2204148174026267]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24221094570014695		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.24221094570014695 | validation: 0.3629633026781908]
	TIME [epoch: 11.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2777458471243712		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.2777458471243712 | validation: 0.2074955967099443]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3285815632426448		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.3285815632426448 | validation: 0.3317560040602942]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31493353455550355		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.31493353455550355 | validation: 0.24673050475087327]
	TIME [epoch: 11.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2804502091796358		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.2804502091796358 | validation: 0.27729363263006757]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2223732931582998		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.2223732931582998 | validation: 0.1776439800234111]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2292147899335183		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.2292147899335183 | validation: 0.20681644047762046]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18465364604285342		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.18465364604285342 | validation: 0.1838199711318555]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24261419158766373		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.24261419158766373 | validation: 0.35513824245289555]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2797156606720503		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.2797156606720503 | validation: 0.27121932129028836]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2451411701898101		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.2451411701898101 | validation: 0.2107934806676989]
	TIME [epoch: 11.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21721727563569965		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.21721727563569965 | validation: 0.29680797194914443]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31801625037838915		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.31801625037838915 | validation: 0.3064370533943616]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28658395346026394		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.28658395346026394 | validation: 0.215383533014911]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2117250254770997		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.2117250254770997 | validation: 0.18109551326674994]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20228546238155543		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.20228546238155543 | validation: 0.19942398175732032]
	TIME [epoch: 11.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24928399502283533		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.24928399502283533 | validation: 0.26864965334808455]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24609130110823668		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.24609130110823668 | validation: 0.27972131274575657]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4524043827067423		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.4524043827067423 | validation: 0.46061855992000034]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33567363337990785		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.33567363337990785 | validation: 0.37951871746842913]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336979358539805		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.3336979358539805 | validation: 0.2807688712455325]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28948435745401935		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.28948435745401935 | validation: 0.34028027186147697]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34761613912537265		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.34761613912537265 | validation: 0.28723149406107484]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3188811950853347		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.3188811950853347 | validation: 0.23091403550666287]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25664738193303527		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.25664738193303527 | validation: 0.35235849324792173]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3069076659938927		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.3069076659938927 | validation: 0.29713861889774074]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32597966282918894		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.32597966282918894 | validation: 0.4009009851135859]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2952635879966361		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.2952635879966361 | validation: 0.23861521453250562]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20399737039483937		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.20399737039483937 | validation: 0.20338906521376066]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17942675934674862		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.17942675934674862 | validation: 0.24476501703284587]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26259599894832014		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.26259599894832014 | validation: 0.31941918628861915]
	TIME [epoch: 11.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2868268909126945		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.2868268909126945 | validation: 0.26327710899365014]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2482342498086736		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.2482342498086736 | validation: 0.18651815570858574]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22946810631928713		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.22946810631928713 | validation: 0.19361700349920077]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27746706132601956		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.27746706132601956 | validation: 0.1645989661892952]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19695958486582957		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.19695958486582957 | validation: 0.17299944029834527]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.210944842956939		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.210944842956939 | validation: 0.34364020380511184]
	TIME [epoch: 11.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2387295477025382		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.2387295477025382 | validation: 0.21660555125331157]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19084267843962868		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.19084267843962868 | validation: 0.17054666876779884]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16279020333529673		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.16279020333529673 | validation: 0.28046911151167586]
	TIME [epoch: 11.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2711229346519155		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.2711229346519155 | validation: 0.2922847895031789]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.294879628880118		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.294879628880118 | validation: 0.21853615002765878]
	TIME [epoch: 11.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22486593171190183		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.22486593171190183 | validation: 0.2031248857146513]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20152726897737117		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.20152726897737117 | validation: 0.20184902764504153]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25667888587388576		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.25667888587388576 | validation: 0.21954811994998646]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2294372335676869		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.2294372335676869 | validation: 0.19894770877680337]
	TIME [epoch: 11.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1966951753436213		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.1966951753436213 | validation: 0.20180853071867408]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20296286247579806		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.20296286247579806 | validation: 0.3158667350017392]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23412136441692608		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.23412136441692608 | validation: 0.2669315927766781]
	TIME [epoch: 11.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3170136595649383		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.3170136595649383 | validation: 0.421946525989621]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35433461296074464		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.35433461296074464 | validation: 0.22319791266892708]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22131563235082438		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.22131563235082438 | validation: 0.15942064983998255]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188379922615028		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.188379922615028 | validation: 0.2675837210074052]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26709969591072347		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.26709969591072347 | validation: 0.18396428670105622]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2191122862252658		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.2191122862252658 | validation: 0.23802439375580053]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20511059857842295		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.20511059857842295 | validation: 0.2357942126308015]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22099588242991464		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.22099588242991464 | validation: 0.23790352869200607]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21774797189957934		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.21774797189957934 | validation: 0.20011876272576956]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20132812119500426		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.20132812119500426 | validation: 0.23546024790855885]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21238790897138266		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.21238790897138266 | validation: 0.19908866973585576]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1805715756651345		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.1805715756651345 | validation: 0.2951560792011632]
	TIME [epoch: 11.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2776102500343701		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.2776102500343701 | validation: 0.6104422500902332]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31137098265301505		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.31137098265301505 | validation: 0.1587316676591368]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18272430079466961		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.18272430079466961 | validation: 0.26232238018163695]
	TIME [epoch: 11.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21647777529807302		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.21647777529807302 | validation: 0.18359600182814056]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15557750758805874		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.15557750758805874 | validation: 0.2668578750773477]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2177864398143458		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.2177864398143458 | validation: 0.19741069539139816]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23130949603553994		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.23130949603553994 | validation: 0.23666674382542843]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22511793840948954		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.22511793840948954 | validation: 0.22000943165035158]
	TIME [epoch: 11.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19988165698717147		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.19988165698717147 | validation: 0.19802207062006752]
	TIME [epoch: 11.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20981127375898517		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.20981127375898517 | validation: 0.23600318154729427]
	TIME [epoch: 11.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24082583010066305		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.24082583010066305 | validation: 0.20391021106543772]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29809000818931136		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.29809000818931136 | validation: 0.1774837111266104]
	TIME [epoch: 11.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2083742572392257		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.2083742572392257 | validation: 0.1850820280495165]
	TIME [epoch: 11.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1845389529967567		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.1845389529967567 | validation: 0.5426369428298041]
	TIME [epoch: 11.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36725333076815325		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.36725333076815325 | validation: 0.22466935260490345]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25600970349106805		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.25600970349106805 | validation: 0.3819377626132045]
	TIME [epoch: 11.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30514324766908413		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.30514324766908413 | validation: 0.28985202901700247]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2334278274097924		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.2334278274097924 | validation: 0.24885541070380768]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23252032247170726		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.23252032247170726 | validation: 0.2373058369359989]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20421668097983794		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.20421668097983794 | validation: 0.30202333817365135]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21241024820114143		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.21241024820114143 | validation: 0.1352262509495891]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12806834671456854		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.12806834671456854 | validation: 0.3200945173835538]
	TIME [epoch: 11.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2019201646058696		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.2019201646058696 | validation: 0.2623936468528062]
	TIME [epoch: 11.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3683010288413677		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.3683010288413677 | validation: 0.2052480305516172]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29344570002538084		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.29344570002538084 | validation: 0.18042787573152083]
	TIME [epoch: 11.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15162097561452753		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.15162097561452753 | validation: 0.12283302514405646]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16976077786492869		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.16976077786492869 | validation: 0.1044533963377722]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12211766721110555		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.12211766721110555 | validation: 0.1368502337224177]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13018283071079928		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.13018283071079928 | validation: 0.26936525016725876]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20327813572119338		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.20327813572119338 | validation: 0.16100223934524935]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25908444916337403		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.25908444916337403 | validation: 0.46602424612248117]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28827884985335467		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.28827884985335467 | validation: 0.2773893251963509]
	TIME [epoch: 11.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21833818438320118		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.21833818438320118 | validation: 0.13658803945084463]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19431943235126398		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.19431943235126398 | validation: 0.2636276819224306]
	TIME [epoch: 11.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21980983427337358		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.21980983427337358 | validation: 0.1830225443932808]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21148882201524538		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.21148882201524538 | validation: 0.1409734210026048]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16072957253584164		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.16072957253584164 | validation: 0.14025588418876062]
	TIME [epoch: 11.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16367603450277604		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.16367603450277604 | validation: 0.13891804637487362]
	TIME [epoch: 11.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15285670538958995		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.15285670538958995 | validation: 0.22099591093748655]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17614262582898862		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.17614262582898862 | validation: 0.14129012369366442]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1527242389642826		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.1527242389642826 | validation: 0.1451472324249478]
	TIME [epoch: 11.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1610447816048523		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.1610447816048523 | validation: 0.15983217529869564]
	TIME [epoch: 11.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14891028717552143		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.14891028717552143 | validation: 0.11539459955234853]
	TIME [epoch: 11.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12165843498521452		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.12165843498521452 | validation: 0.2251241022808334]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20659419400686302		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.20659419400686302 | validation: 0.13161412985625162]
	TIME [epoch: 11.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17075836125826988		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.17075836125826988 | validation: 0.19016477233951548]
	TIME [epoch: 11.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1788607608700894		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.1788607608700894 | validation: 0.1640621265271416]
	TIME [epoch: 11.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1489838742989908		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.1489838742989908 | validation: 0.1139761678523681]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1231563619098785		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.1231563619098785 | validation: 0.16383621567426357]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2047883267619376		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.2047883267619376 | validation: 0.22416702746374675]
	TIME [epoch: 11.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19055124664022283		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.19055124664022283 | validation: 0.20685695389576908]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17939849831500315		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.17939849831500315 | validation: 0.14592382760874031]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15729920323106308		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.15729920323106308 | validation: 0.1737193211706645]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18879605236233393		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.18879605236233393 | validation: 0.18043290438371018]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690384946531992		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.1690384946531992 | validation: 0.12217246207877462]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16313166803644563		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.16313166803644563 | validation: 0.3610287581517984]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4809136671862095		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.4809136671862095 | validation: 0.13071223463550033]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20883641193086422		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.20883641193086422 | validation: 0.3587469061892154]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2645992141570091		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.2645992141570091 | validation: 0.26399110378555896]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19834535086767568		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.19834535086767568 | validation: 0.11300397875249125]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17681050664714565		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.17681050664714565 | validation: 0.18577000834284985]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2100650252297183		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.2100650252297183 | validation: 0.1179334371523313]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25745455596995326		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.25745455596995326 | validation: 0.17293228682782655]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20628504704599343		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.20628504704599343 | validation: 0.14496155767054472]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1469681975403748		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.1469681975403748 | validation: 0.1716488364519325]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13695692363589335		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.13695692363589335 | validation: 0.20339150621592672]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18700949396037347		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.18700949396037347 | validation: 0.14448715135256307]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14528219276646853		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.14528219276646853 | validation: 0.1168887638007932]
	TIME [epoch: 11.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18724135852121565		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.18724135852121565 | validation: 0.22997114398164356]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15315170512746584		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.15315170512746584 | validation: 0.11693200373677817]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1639155949886485		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.1639155949886485 | validation: 0.1438814534304614]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17980895209866596		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.17980895209866596 | validation: 0.11394210327884968]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1311995756426761		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.1311995756426761 | validation: 0.13788226861575545]
	TIME [epoch: 11.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15596268652659503		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.15596268652659503 | validation: 0.19918289196173677]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2030424765842903		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.2030424765842903 | validation: 0.25420644869074815]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23825243120911377		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.23825243120911377 | validation: 0.23385593860871648]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22367069750658805		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.22367069750658805 | validation: 0.2239638666694]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2092854127290687		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.2092854127290687 | validation: 0.19285422389123788]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17597006423957445		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.17597006423957445 | validation: 0.17739846902542902]
	TIME [epoch: 11.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19343166555288346		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.19343166555288346 | validation: 0.20680652624773088]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2285107851195252		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.2285107851195252 | validation: 0.2780005576556316]
	TIME [epoch: 11.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22689048549910457		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.22689048549910457 | validation: 0.15855326695377164]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16183122763150237		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.16183122763150237 | validation: 0.12855049358901774]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16855625459653706		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.16855625459653706 | validation: 0.17297690798383755]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549686626290214		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.1549686626290214 | validation: 0.15088694737084088]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14040275753108591		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.14040275753108591 | validation: 0.13312595047573134]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12485634192491571		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.12485634192491571 | validation: 0.1579127888567865]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14894203697448222		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.14894203697448222 | validation: 0.14210709695083729]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17644057820080164		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.17644057820080164 | validation: 0.1811686803958907]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142182731261186		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.142182731261186 | validation: 0.14625636177458737]
	TIME [epoch: 11.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1664459829460772		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.1664459829460772 | validation: 0.15501259783626314]
	TIME [epoch: 11.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433904408418305		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.1433904408418305 | validation: 0.13955527722502428]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12192799812272401		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.12192799812272401 | validation: 0.12793473374179182]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125029982539071		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.125029982539071 | validation: 0.1264837010740486]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18911086890310763		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.18911086890310763 | validation: 0.19288047635506417]
	TIME [epoch: 11.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13447579304473065		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.13447579304473065 | validation: 0.13623898164172374]
	TIME [epoch: 11.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12452242849688391		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.12452242849688391 | validation: 0.1328969783895024]
	TIME [epoch: 11.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13293097704677886		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.13293097704677886 | validation: 0.3315237165152433]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2260639197125509		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.2260639197125509 | validation: 0.1640489990430126]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1824790593107296		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.1824790593107296 | validation: 0.14466970771709392]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13097702914192172		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.13097702914192172 | validation: 0.10747225326441535]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15560370818990427		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.15560370818990427 | validation: 0.252795057283581]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21977960874312857		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.21977960874312857 | validation: 0.1763430526271358]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342796802299891		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.1342796802299891 | validation: 0.14304965950138682]
	TIME [epoch: 11.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438095149457993		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.1438095149457993 | validation: 0.16428586452621682]
	TIME [epoch: 11.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15197314763996653		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.15197314763996653 | validation: 0.16575117303938405]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402732029790286		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.1402732029790286 | validation: 0.20534368443425835]
	TIME [epoch: 11.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16496198803760675		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.16496198803760675 | validation: 0.18763258121545334]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14281048813576763		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.14281048813576763 | validation: 0.25698512164292253]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2582737828181126		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.2582737828181126 | validation: 0.20756024858848807]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30802316329750634		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.30802316329750634 | validation: 0.2789465927444421]
	TIME [epoch: 11.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19421419435711554		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.19421419435711554 | validation: 0.1305840879009494]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12999680079015385		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.12999680079015385 | validation: 0.16953533676602398]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12506363376751678		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.12506363376751678 | validation: 0.1251724782621348]
	TIME [epoch: 11.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1412411142701401		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.1412411142701401 | validation: 0.1490327253196463]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13273043612047852		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.13273043612047852 | validation: 0.08816786351751525]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_409.pth
	Model improved!!!
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15886198161639636		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.15886198161639636 | validation: 0.09262851924921643]
	TIME [epoch: 11.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10395480853242234		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.10395480853242234 | validation: 0.1431276335177583]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14112344517079695		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.14112344517079695 | validation: 0.09813448560302089]
	TIME [epoch: 11.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11875129460092995		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.11875129460092995 | validation: 0.30056612610180633]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18581832399646475		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.18581832399646475 | validation: 0.22137027014886967]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18041835999962982		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.18041835999962982 | validation: 0.11769434148732093]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13626451932586098		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.13626451932586098 | validation: 0.26314450979136544]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18603308022816453		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.18603308022816453 | validation: 0.10785320868495375]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13194826268738605		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.13194826268738605 | validation: 0.17543486174288653]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15931939694374564		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.15931939694374564 | validation: 0.24584251734295534]
	TIME [epoch: 11.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25726623769248047		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.25726623769248047 | validation: 0.20653058051909493]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1830019136840839		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.1830019136840839 | validation: 0.1480918777848131]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19981154292555825		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.19981154292555825 | validation: 0.23131501806025817]
	TIME [epoch: 11.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19188632081944598		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.19188632081944598 | validation: 0.21679212662823574]
	TIME [epoch: 11.5 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.216447475265645		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.216447475265645 | validation: 0.20907150909200845]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17874289548442635		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.17874289548442635 | validation: 0.20915135060369827]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15938588073123378		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.15938588073123378 | validation: 0.14927029203685183]
	TIME [epoch: 11.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1694256093683649		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.1694256093683649 | validation: 0.18454219185809478]
	TIME [epoch: 11.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15322894711401217		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.15322894711401217 | validation: 0.20371448842129447]
	TIME [epoch: 11.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2102811863572772		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.2102811863572772 | validation: 0.17713036023575943]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1631294943522586		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.1631294943522586 | validation: 0.2048575840017923]
	TIME [epoch: 11.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18752289675659795		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.18752289675659795 | validation: 0.17370291997290704]
	TIME [epoch: 11.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15013972258023628		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.15013972258023628 | validation: 0.13636634728673153]
	TIME [epoch: 11.5 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1344329391944046		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.1344329391944046 | validation: 0.15275386897501367]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22092053587143873		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.22092053587143873 | validation: 0.20124845848175027]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13133907252230792		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.13133907252230792 | validation: 0.12732946218537086]
	TIME [epoch: 11.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14647554316688294		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.14647554316688294 | validation: 0.12529867363927255]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343640923564759		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.1343640923564759 | validation: 0.15533797718692874]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17478304774913808		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.17478304774913808 | validation: 0.18306620784229824]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17603879305973205		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.17603879305973205 | validation: 0.10084360377824711]
	TIME [epoch: 11.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14268935502784857		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.14268935502784857 | validation: 0.19181274855024463]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1776234912921238		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.1776234912921238 | validation: 0.1460234920630379]
	TIME [epoch: 11.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19302525357984485		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.19302525357984485 | validation: 0.13716380531952216]
	TIME [epoch: 11.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13096212510578054		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.13096212510578054 | validation: 0.11465112907694316]
	TIME [epoch: 11.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15247896357878718		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.15247896357878718 | validation: 0.1374391983821658]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1392254876526086		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.1392254876526086 | validation: 0.14144545089561614]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16534166861529942		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.16534166861529942 | validation: 0.1827521276285092]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14447039690678856		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.14447039690678856 | validation: 0.14216712589615094]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17553461407305074		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.17553461407305074 | validation: 0.14244251887316955]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09795759420366151		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.09795759420366151 | validation: 0.135452041751513]
	TIME [epoch: 11.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588233623128179		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.1588233623128179 | validation: 0.09932330349817102]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08134634320530815		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.08134634320530815 | validation: 0.10125281295685261]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10176398771274633		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.10176398771274633 | validation: 0.16858675000728432]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1081837469793104		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.1081837469793104 | validation: 0.12310994092491515]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18545720896317702		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.18545720896317702 | validation: 0.32254388434503867]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2188219924051235		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.2188219924051235 | validation: 0.14203865641696223]
	TIME [epoch: 11.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11521042679193268		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.11521042679193268 | validation: 0.11019395215345981]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12405539357374037		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.12405539357374037 | validation: 0.09768790410416213]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11094958498776174		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.11094958498776174 | validation: 0.09301931097289477]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.082521903201726		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.082521903201726 | validation: 0.07893374479554294]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_459.pth
	Model improved!!!
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09139699670264757		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.09139699670264757 | validation: 0.14239160792700145]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408412384503393		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.1408412384503393 | validation: 0.16803719887637655]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10330938777741568		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.10330938777741568 | validation: 0.09157778926866848]
	TIME [epoch: 11.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09308771261641284		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.09308771261641284 | validation: 0.09030321420834123]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13019723667504712		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.13019723667504712 | validation: 0.0807604563872599]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10378360929530231		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.10378360929530231 | validation: 0.1242806342470124]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14080942409039635		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.14080942409039635 | validation: 0.10587252097681776]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10152699643069478		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.10152699643069478 | validation: 0.11869308705842768]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1288350831286171		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.1288350831286171 | validation: 0.1505644932674551]
	TIME [epoch: 11.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13190169300285498		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.13190169300285498 | validation: 0.10326147612461684]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13554554470482794		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.13554554470482794 | validation: 0.15743927343361608]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1111261025193995		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.1111261025193995 | validation: 0.1237761051002839]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14632542438012403		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.14632542438012403 | validation: 0.07151537749802338]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1127195109749777		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.1127195109749777 | validation: 0.08896335924607993]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07926230733066815		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.07926230733066815 | validation: 0.08037959504838231]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07729031254514851		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.07729031254514851 | validation: 0.10529002695923043]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11409991129624923		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.11409991129624923 | validation: 0.13825909049502538]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09246037246582055		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.09246037246582055 | validation: 0.07119586141074692]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_477.pth
	Model improved!!!
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09317133453708647		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.09317133453708647 | validation: 0.10029670410015858]
	TIME [epoch: 11.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0897783945730111		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.0897783945730111 | validation: 0.09694279768821336]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07607822515054317		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.07607822515054317 | validation: 0.10370509125314115]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12411033788325015		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.12411033788325015 | validation: 0.1564076977751562]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11558368875701502		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.11558368875701502 | validation: 0.08410797330252331]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09252549497384048		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.09252549497384048 | validation: 0.0927034422250571]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07113759244450905		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.07113759244450905 | validation: 0.08265490809330933]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13061961655388948		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.13061961655388948 | validation: 0.18524455995983274]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11216950072699171		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.11216950072699171 | validation: 0.1754594219258798]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16944109714433514		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.16944109714433514 | validation: 0.11397332697996128]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12820882846558668		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.12820882846558668 | validation: 0.13176270875690974]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104078192176972		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.1104078192176972 | validation: 0.12965861068063375]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11378238955686637		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.11378238955686637 | validation: 0.11530438829334512]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10119457457520284		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.10119457457520284 | validation: 0.08509499506389294]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1434646105436461		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.1434646105436461 | validation: 0.11899209009007539]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14884972218449252		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.14884972218449252 | validation: 0.12558556066180393]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10085688635049207		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.10085688635049207 | validation: 0.12965478086818014]
	TIME [epoch: 11.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09724372962658837		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.09724372962658837 | validation: 0.14679505381336933]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321403117629357		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.1321403117629357 | validation: 0.11587673103810676]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254366610886879		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.1254366610886879 | validation: 0.1640626850309002]
	TIME [epoch: 11.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11982702280300533		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.11982702280300533 | validation: 0.0735839031713603]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0768772146724131		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.0768772146724131 | validation: 0.05938039499401011]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_499.pth
	Model improved!!!
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06985688535718702		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.06985688535718702 | validation: 0.06456589536542465]
	TIME [epoch: 11.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07664771496002626		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.07664771496002626 | validation: 0.08631167875085925]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07500103025345893		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.07500103025345893 | validation: 0.07844594517653979]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08071508961988916		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.08071508961988916 | validation: 0.06538382268077557]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06416224652043141		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.06416224652043141 | validation: 0.08208041573499031]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10586018406834385		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.10586018406834385 | validation: 0.08160902491183489]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0692937189176992		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.0692937189176992 | validation: 0.08014194372734833]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10777019458770817		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.10777019458770817 | validation: 0.14131657403050635]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11151138745085243		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.11151138745085243 | validation: 0.0853476744913155]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09591926062168368		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.09591926062168368 | validation: 0.1096267098873117]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07259068627094996		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.07259068627094996 | validation: 0.07422984163809423]
	TIME [epoch: 11.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0756789441417643		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.0756789441417643 | validation: 0.08071073326462895]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08668532713844906		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.08668532713844906 | validation: 0.07804920025549093]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.078138290492644		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.078138290492644 | validation: 0.08122926033095265]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10969505575066701		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.10969505575066701 | validation: 0.08943490034141213]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09075560652524821		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.09075560652524821 | validation: 0.10815916002007087]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09423392471977736		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.09423392471977736 | validation: 0.08634679380760214]
	TIME [epoch: 11.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0729341759804001		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.0729341759804001 | validation: 0.06561800335847794]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07949545934737512		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.07949545934737512 | validation: 0.10132539356283932]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11015797185185185		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.11015797185185185 | validation: 0.1353908413508962]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12277867794372593		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.12277867794372593 | validation: 0.08720008158880584]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08593788948521094		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.08593788948521094 | validation: 0.08906142233916235]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06783588979136207		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.06783588979136207 | validation: 0.0739096697631535]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07175671528772144		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.07175671528772144 | validation: 0.06954638272066138]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05277973943560202		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.05277973943560202 | validation: 0.056488452441164884]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11006375812868367		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.11006375812868367 | validation: 0.12129924379906067]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11195349505472135		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.11195349505472135 | validation: 0.07812368434441692]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08350937810695666		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.08350937810695666 | validation: 0.150345586348599]
	TIME [epoch: 11.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10040506819006632		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.10040506819006632 | validation: 0.11941575633319744]
	TIME [epoch: 11.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13264190039085205		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.13264190039085205 | validation: 0.11472949358346127]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11269492272254113		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.11269492272254113 | validation: 0.10111858803121447]
	TIME [epoch: 11.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0861896674507362		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.0861896674507362 | validation: 0.08852445446235295]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10725439542064008		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.10725439542064008 | validation: 0.1334876309961508]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09704312122031813		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.09704312122031813 | validation: 0.09379923312745614]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0760344171504801		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.0760344171504801 | validation: 0.08798296847380611]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1246750126174781		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.1246750126174781 | validation: 0.10265486538401701]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08250645695686573		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.08250645695686573 | validation: 0.12136715448623946]
	TIME [epoch: 11.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11093122983687372		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.11093122983687372 | validation: 0.10089258067456952]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.099030487121769		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.099030487121769 | validation: 0.07544206321052847]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10616090417668403		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.10616090417668403 | validation: 0.10596635246793984]
	TIME [epoch: 11.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09997569803685223		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.09997569803685223 | validation: 0.12949223327636372]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11521322241955512		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.11521322241955512 | validation: 0.1031169612776588]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1058197173114546		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.1058197173114546 | validation: 0.1105853520484503]
	TIME [epoch: 11.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1285755005371436		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.1285755005371436 | validation: 0.11772277786062371]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1087842223818532		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.1087842223818532 | validation: 0.09132747541914656]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1134897452641759		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.1134897452641759 | validation: 0.10421274574679398]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12204116912545497		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.12204116912545497 | validation: 0.09641172559968428]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08810587603471046		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.08810587603471046 | validation: 0.08111980866595818]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08156463254860019		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.08156463254860019 | validation: 0.09349086668689786]
	TIME [epoch: 11.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09981868471572025		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.09981868471572025 | validation: 0.12151504761003637]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11479283467735835		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.11479283467735835 | validation: 0.10095193031402562]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10790562699753473		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.10790562699753473 | validation: 0.09031154264701445]
	TIME [epoch: 11.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07334498173017955		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.07334498173017955 | validation: 0.18010163827637338]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1663441542632665		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.1663441542632665 | validation: 0.07727073453152658]
	TIME [epoch: 11.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08530076915134452		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.08530076915134452 | validation: 0.15357607332414985]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10015095559797985		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.10015095559797985 | validation: 0.07337110320579658]
	TIME [epoch: 11.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08456516016354816		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.08456516016354816 | validation: 0.0860574997887009]
	TIME [epoch: 11.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09795503702080854		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.09795503702080854 | validation: 0.08895395981339316]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0816783659527042		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.0816783659527042 | validation: 0.07024965913198211]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09282996814590466		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.09282996814590466 | validation: 0.08260037312760765]
	TIME [epoch: 11.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07579207388041564		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.07579207388041564 | validation: 0.07643882418055445]
	TIME [epoch: 11.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06824593927293642		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.06824593927293642 | validation: 0.11290421393087006]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09013111927997788		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.09013111927997788 | validation: 0.07692737952121059]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06577305475613605		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.06577305475613605 | validation: 0.09968394347859047]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0940561723858917		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.0940561723858917 | validation: 0.08083005311493471]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10048646188004112		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.10048646188004112 | validation: 0.07155154164974573]
	TIME [epoch: 11.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07394345484116222		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.07394345484116222 | validation: 0.0770751284889673]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07499652725747843		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.07499652725747843 | validation: 0.08138446560862461]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07373070718709447		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.07373070718709447 | validation: 0.10689320406989838]
	TIME [epoch: 11.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09151192245345105		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.09151192245345105 | validation: 0.1228462918470812]
	TIME [epoch: 11.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07954344440252943		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.07954344440252943 | validation: 0.07953925076451678]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13189550165409458		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.13189550165409458 | validation: 0.18877281967889417]
	TIME [epoch: 11.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1437186260330475		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.1437186260330475 | validation: 0.1187945036694807]
	TIME [epoch: 11.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11170324232657594		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.11170324232657594 | validation: 0.11521041653914878]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23723344457594753		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.23723344457594753 | validation: 0.39232493560159254]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3166470123290491		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.3166470123290491 | validation: 0.13617518135970363]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11291563920645838		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.11291563920645838 | validation: 0.12446717749524222]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10359445633229292		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.10359445633229292 | validation: 0.11379607001706372]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09210684613134303		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.09210684613134303 | validation: 0.09934307387110368]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08450853404422229		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.08450853404422229 | validation: 0.1618210135516307]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25137027712985854		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.25137027712985854 | validation: 0.28075733598562613]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18320247001663392		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.18320247001663392 | validation: 0.13346951216654934]
	TIME [epoch: 11.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11339210591170232		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.11339210591170232 | validation: 0.11818512348914893]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10702543249619799		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.10702543249619799 | validation: 0.10774461247007232]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09819349322444729		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.09819349322444729 | validation: 0.12294690034853314]
	TIME [epoch: 11.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12307055987378271		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.12307055987378271 | validation: 0.18620305055181396]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13144615311925317		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.13144615311925317 | validation: 0.07984886176730185]
	TIME [epoch: 11.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08952933228488616		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.08952933228488616 | validation: 0.10121778292441323]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07815321788295865		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.07815321788295865 | validation: 0.11606309885547267]
	TIME [epoch: 11.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12833156481421829		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.12833156481421829 | validation: 0.07626426643490962]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323491668364826		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.08323491668364826 | validation: 0.0810565128813089]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09082597618480515		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.09082597618480515 | validation: 0.11139917332934632]
	TIME [epoch: 11.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14911684199356479		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.14911684199356479 | validation: 0.12195970944193554]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446524829515452		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.1446524829515452 | validation: 0.30507286219268415]
	TIME [epoch: 11.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24560694381253037		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.24560694381253037 | validation: 0.12100797022032338]
	TIME [epoch: 11.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09921284906891864		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.09921284906891864 | validation: 0.08598666091752581]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08569210682434238		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.08569210682434238 | validation: 0.07592055842564147]
	TIME [epoch: 11.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06449673115250083		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.06449673115250083 | validation: 0.07115282754943912]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08752554872733792		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.08752554872733792 | validation: 0.13074581229279356]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11335410988899589		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.11335410988899589 | validation: 0.11072788005178737]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11344617258323297		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.11344617258323297 | validation: 0.11883905820116258]
	TIME [epoch: 11.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10554169152912565		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.10554169152912565 | validation: 0.08704042210931791]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06934974962011735		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.06934974962011735 | validation: 0.10411320127686152]
	TIME [epoch: 11.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08391356050364364		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.08391356050364364 | validation: 0.06780802907235024]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08019345047113387		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.08019345047113387 | validation: 0.1264334439035029]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11814559211301667		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.11814559211301667 | validation: 0.090234448473311]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09305107158020755		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.09305107158020755 | validation: 0.08369274290848988]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08722585608205527		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.08722585608205527 | validation: 0.0814798509434379]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07673799887547078		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.07673799887547078 | validation: 0.08328048489119612]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08033501732804621		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.08033501732804621 | validation: 0.09714555878446932]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09480093076045482		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.09480093076045482 | validation: 0.10097341212627538]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08420306572427722		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.08420306572427722 | validation: 0.09861403199520236]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07879957310944731		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.07879957310944731 | validation: 0.07837771919805617]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07935111233162649		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.07935111233162649 | validation: 0.1052733805262348]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0928639817718385		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.0928639817718385 | validation: 0.10185882628668028]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10815923859799184		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.10815923859799184 | validation: 0.10216983284468244]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08975725921988961		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.08975725921988961 | validation: 0.103882448943704]
	TIME [epoch: 11.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08909614064112008		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.08909614064112008 | validation: 0.09102132028663866]
	TIME [epoch: 11.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10675000148499421		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.10675000148499421 | validation: 0.13332585139329706]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312443215256371		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.1312443215256371 | validation: 0.15691928545694217]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13523968980511814		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.13523968980511814 | validation: 0.1795561749487219]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20274112445986486		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.20274112445986486 | validation: 0.29874128739064354]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20955634066143963		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.20955634066143963 | validation: 0.20702842824155596]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15507799626617685		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.15507799626617685 | validation: 0.14812304637869794]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12075628262547775		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.12075628262547775 | validation: 0.14459855392947074]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11322105926126627		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.11322105926126627 | validation: 0.11042691069565837]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10235161647547844		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.10235161647547844 | validation: 0.14871235491532775]
	TIME [epoch: 11.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1213373007762929		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.1213373007762929 | validation: 0.1551833990610598]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11873221614531707		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.11873221614531707 | validation: 0.12032850557032561]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10103625592845195		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.10103625592845195 | validation: 0.1029057105564065]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07248924277844798		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.07248924277844798 | validation: 0.0751263670000018]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07243395574477451		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.07243395574477451 | validation: 0.11789603085462709]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08571567522919923		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.08571567522919923 | validation: 0.08515480887805192]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08652121984890934		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.08652121984890934 | validation: 0.08428348403309574]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06637262366390917		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.06637262366390917 | validation: 0.07154757041695776]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06100422637021835		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.06100422637021835 | validation: 0.06698904041828622]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06935191778809072		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.06935191778809072 | validation: 0.07812369331845738]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05660054957062801		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.05660054957062801 | validation: 0.061269219241970665]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09058356517992741		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.09058356517992741 | validation: 0.12124501196642797]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10559995319027485		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.10559995319027485 | validation: 0.09207052012505247]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09276595837062096		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.09276595837062096 | validation: 0.07815990162803554]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08100337684539298		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.08100337684539298 | validation: 0.1231924755198097]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12155671255756506		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.12155671255756506 | validation: 0.1121493254737391]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10486753714526692		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.10486753714526692 | validation: 0.07706085672489747]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09587377185608811		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.09587377185608811 | validation: 0.10863731659290092]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09063341494742916		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.09063341494742916 | validation: 0.08735189325587024]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08744006375358201		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.08744006375358201 | validation: 0.0980586572840835]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10293066218347004		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.10293066218347004 | validation: 0.06629336526701335]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07737128605850084		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.07737128605850084 | validation: 0.0720186263296797]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08679710683402195		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.08679710683402195 | validation: 0.09021849417507123]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09773024611960518		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.09773024611960518 | validation: 0.1099836604940889]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10644557412212659		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.10644557412212659 | validation: 0.0798890910033841]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08634406114899924		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.08634406114899924 | validation: 0.08819954513627266]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08167851153266405		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.08167851153266405 | validation: 0.06448431464747804]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07019164023173596		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.07019164023173596 | validation: 0.06704996834522019]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07501308400772388		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.07501308400772388 | validation: 0.07333729667860231]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08124211827572637		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.08124211827572637 | validation: 0.09431643124393838]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09634987591145133		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.09634987591145133 | validation: 0.08457937512499417]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07849472653302977		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.07849472653302977 | validation: 0.08701077983076218]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.078782180647994		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.078782180647994 | validation: 0.06824820145935463]
	TIME [epoch: 11.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07106307247538773		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.07106307247538773 | validation: 0.08427064987132322]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10690268884716755		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.10690268884716755 | validation: 0.07384972672575822]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07661456690230531		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.07661456690230531 | validation: 0.11985492053902638]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10422603609394057		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.10422603609394057 | validation: 0.0826662308809923]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08750902223813264		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.08750902223813264 | validation: 0.08588195924953969]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07272432614053176		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.07272432614053176 | validation: 0.05851055259494878]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0651520290462084		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.0651520290462084 | validation: 0.08279089489184667]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06550671054139619		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.06550671054139619 | validation: 0.0630440679650127]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08685132759295414		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.08685132759295414 | validation: 0.11941009104399498]
	TIME [epoch: 11.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0743377038023504		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.0743377038023504 | validation: 0.09695471281333821]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08500930646843964		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.08500930646843964 | validation: 0.08028366207756933]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06087079440826831		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.06087079440826831 | validation: 0.06551492624374591]
	TIME [epoch: 11.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0676397951274191		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.0676397951274191 | validation: 0.0603953697281686]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07374648666648011		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.07374648666648011 | validation: 0.06659856348707643]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07545481940982002		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.07545481940982002 | validation: 0.13128102387333132]
	TIME [epoch: 11.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10302675032044385		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.10302675032044385 | validation: 0.08042363473963043]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0686922510321502		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.0686922510321502 | validation: 0.06059732462745108]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07280206349412216		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.07280206349412216 | validation: 0.11483668168930393]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10706277435384112		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.10706277435384112 | validation: 0.08889785903083826]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07918565166103408		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.07918565166103408 | validation: 0.09834708341422126]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08115996085013694		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.08115996085013694 | validation: 0.06053400076249455]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055883124614483894		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.055883124614483894 | validation: 0.05964019684999451]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07516340340782476		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.07516340340782476 | validation: 0.09783855330154698]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08433103628326144		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.08433103628326144 | validation: 0.09413940414160651]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07761757389241114		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.07761757389241114 | validation: 0.06172909765898792]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0552265098945863		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.0552265098945863 | validation: 0.07802876070059803]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10691665649659227		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.10691665649659227 | validation: 0.1386887644575596]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10554900901088635		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.10554900901088635 | validation: 0.09099942649225304]
	TIME [epoch: 11.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08582763757876598		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.08582763757876598 | validation: 0.07419316338199311]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06306342059811082		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.06306342059811082 | validation: 0.06189170750154361]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04937954182560373		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.04937954182560373 | validation: 0.07396701755379492]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08128560887019796		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.08128560887019796 | validation: 0.11622251091151643]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08368296827320486		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.08368296827320486 | validation: 0.07875330351169103]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.074608410865901		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.074608410865901 | validation: 0.06986705267433592]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06467166861098878		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.06467166861098878 | validation: 0.07469146172067731]
	TIME [epoch: 11.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056101216407732524		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.056101216407732524 | validation: 0.06773390484673515]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07329207727192252		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.07329207727192252 | validation: 0.09005565357470512]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06795237978290167		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.06795237978290167 | validation: 0.05683859222262927]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05303068287884047		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.05303068287884047 | validation: 0.05331366404291931]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06045732649875783		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.06045732649875783 | validation: 0.06537599852703681]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05421743324252657		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.05421743324252657 | validation: 0.06788693875216781]
	TIME [epoch: 11.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060996512747297185		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.060996512747297185 | validation: 0.07883960337322873]
	TIME [epoch: 11.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07412406915467178		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.07412406915467178 | validation: 0.06893594902666514]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06467464582602465		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.06467464582602465 | validation: 0.07751616738393606]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06192776010692391		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.06192776010692391 | validation: 0.06324779718692101]
	TIME [epoch: 11.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06194503883755806		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.06194503883755806 | validation: 0.09885912538521735]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07381322996205009		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.07381322996205009 | validation: 0.06314572542872872]
	TIME [epoch: 11.4 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060743839914266434		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.060743839914266434 | validation: 0.0861618622416858]
	TIME [epoch: 11.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06678744430120409		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.06678744430120409 | validation: 0.06503570943209709]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05953971009653259		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.05953971009653259 | validation: 0.05379704912053932]
	TIME [epoch: 11.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05437485120361322		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.05437485120361322 | validation: 0.053451052482077176]
	TIME [epoch: 11.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052078329624247965		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.052078329624247965 | validation: 0.05623134873754397]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06243878879921126		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.06243878879921126 | validation: 0.06253980099095198]
	TIME [epoch: 11.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08523666567599553		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.08523666567599553 | validation: 0.09608359387395585]
	TIME [epoch: 11.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09561162393003911		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.09561162393003911 | validation: 0.10500650799260865]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09519417306945492		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.09519417306945492 | validation: 0.06847678612254501]
	TIME [epoch: 11.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0688220069321425		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.0688220069321425 | validation: 0.06720469260147707]
	TIME [epoch: 11.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07673804955949896		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.07673804955949896 | validation: 0.11099467864507392]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.108847238780497		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.108847238780497 | validation: 0.07753831089097542]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08076785991703532		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.08076785991703532 | validation: 0.10292957565522143]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09004647800140406		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.09004647800140406 | validation: 0.07234490001404949]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0831337852528207		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.0831337852528207 | validation: 0.09427259471835622]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08213888073913347		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.08213888073913347 | validation: 0.07269590779052586]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0722715590461316		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.0722715590461316 | validation: 0.07494050461095718]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07722290293922751		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.07722290293922751 | validation: 0.09193029905797964]
	TIME [epoch: 11.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07375035990081757		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.07375035990081757 | validation: 0.06376274551412549]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05997481026243015		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.05997481026243015 | validation: 0.06649927695697558]
	TIME [epoch: 11.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07531202582678885		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.07531202582678885 | validation: 0.10871699724794852]
	TIME [epoch: 11.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07909453672960731		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.07909453672960731 | validation: 0.050861251436703406]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_728.pth
	Model improved!!!
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08025923702496995		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.08025923702496995 | validation: 0.08950678975704364]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0770162565353762		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.0770162565353762 | validation: 0.08373075890239093]
	TIME [epoch: 11.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06887856956489616		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.06887856956489616 | validation: 0.08279606213952198]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06768158456061496		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.06768158456061496 | validation: 0.06582765802675336]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0611711601875572		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.0611711601875572 | validation: 0.0794217540792864]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07202051340296631		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.07202051340296631 | validation: 0.05612485511078942]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046359042108122965		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.046359042108122965 | validation: 0.04122934187605339]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_735.pth
	Model improved!!!
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04442961271042625		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.04442961271042625 | validation: 0.051841918058902384]
	TIME [epoch: 11.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05105047324446686		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.05105047324446686 | validation: 0.061871482140806955]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05614304505656502		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.05614304505656502 | validation: 0.0935899948230298]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08698076546404047		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.08698076546404047 | validation: 0.07299787481938287]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05828054324426776		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.05828054324426776 | validation: 0.06925340751774131]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05503341928560404		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.05503341928560404 | validation: 0.05551093737302475]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04300674997167832		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.04300674997167832 | validation: 0.05126768142434626]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05918310738917938		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.05918310738917938 | validation: 0.053718321819690655]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050858948675507096		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.050858948675507096 | validation: 0.04240058117791232]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04510968583473164		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.04510968583473164 | validation: 0.054967025891093646]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058301802450664186		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.058301802450664186 | validation: 0.0879184415596976]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06446454103425564		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.06446454103425564 | validation: 0.06342282345563943]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0753377674919439		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.0753377674919439 | validation: 0.11579312861985395]
	TIME [epoch: 11.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09114144226200555		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.09114144226200555 | validation: 0.09324278541889859]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07648342491728892		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.07648342491728892 | validation: 0.0931670789234247]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08528576322072672		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.08528576322072672 | validation: 0.11373539808332658]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10429952830797094		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.10429952830797094 | validation: 0.11961241762970509]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08313667772908903		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.08313667772908903 | validation: 0.11434058693127554]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0876978283622911		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.0876978283622911 | validation: 0.0988060733911948]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059992833408731995		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.059992833408731995 | validation: 0.0634837748432167]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055731727298181766		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.055731727298181766 | validation: 0.08895024485585473]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07177208960152098		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.07177208960152098 | validation: 0.07938383286280858]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05084433145094572		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.05084433145094572 | validation: 0.07898269236601642]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353189105804095		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.06353189105804095 | validation: 0.06260053147027313]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05138578694224104		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.05138578694224104 | validation: 0.05556188701825507]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05307286445118162		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.05307286445118162 | validation: 0.052374818589121706]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06203273954617562		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.06203273954617562 | validation: 0.06915864011209275]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04798415670111092		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.04798415670111092 | validation: 0.05940553946536904]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0515387905713708		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0515387905713708 | validation: 0.08240386006575523]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06555616714077343		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.06555616714077343 | validation: 0.08494303203150476]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06399982275776853		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.06399982275776853 | validation: 0.0721520052553517]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06978377278941889		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.06978377278941889 | validation: 0.10724778217773512]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06810514783942584		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.06810514783942584 | validation: 0.0630334331220655]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04911293228345527		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.04911293228345527 | validation: 0.0647748427095172]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05228377835495229		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.05228377835495229 | validation: 0.06691390370812877]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05267992052700497		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.05267992052700497 | validation: 0.06509802071838046]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05412944509452145		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.05412944509452145 | validation: 0.057095876814553734]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046688090650963424		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.046688090650963424 | validation: 0.06658757509559807]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06141162193626828		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.06141162193626828 | validation: 0.0680312634483159]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04902704673572702		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.04902704673572702 | validation: 0.04728048049907623]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04319026401975594		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.04319026401975594 | validation: 0.058406526582792787]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05250268079148308		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.05250268079148308 | validation: 0.061072162081859525]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05845803906828099		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.05845803906828099 | validation: 0.06307306652662902]
	TIME [epoch: 11.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05069966920553207		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.05069966920553207 | validation: 0.05288383929843035]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05002792294172466		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.05002792294172466 | validation: 0.05004354435230266]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049827257083344		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.049827257083344 | validation: 0.0409621956883561]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_781.pth
	Model improved!!!
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053450198984874		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.053450198984874 | validation: 0.05561272808187363]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04754934971894677		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.04754934971894677 | validation: 0.06584209637823449]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04838368731583975		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.04838368731583975 | validation: 0.04654516736990187]
	TIME [epoch: 11.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0425020934790832		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.0425020934790832 | validation: 0.05885587531387456]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04839088077583591		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.04839088077583591 | validation: 0.05273145665311103]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04056331574512369		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.04056331574512369 | validation: 0.0499062024441333]
	TIME [epoch: 11.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049508781243350904		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.049508781243350904 | validation: 0.06670603514737736]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04861533732820057		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.04861533732820057 | validation: 0.07938991057474508]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04696071294232612		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.04696071294232612 | validation: 0.046901368457236026]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04622629345569721		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.04622629345569721 | validation: 0.04643276450761298]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04166539259666869		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.04166539259666869 | validation: 0.06385594144295509]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05106317317628163		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.05106317317628163 | validation: 0.052351033855908384]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046635212122340675		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.046635212122340675 | validation: 0.051488490968387]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06041250647251436		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.06041250647251436 | validation: 0.08835220397034478]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08971359624299029		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.08971359624299029 | validation: 0.0662818088428292]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054310135429754214		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.054310135429754214 | validation: 0.06243775192542315]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06671723310260302		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.06671723310260302 | validation: 0.06729239330577666]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07104073577603362		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.07104073577603362 | validation: 0.07457240461525086]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06428309627332844		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.06428309627332844 | validation: 0.05422652114770559]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05020695800112058		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.05020695800112058 | validation: 0.04816994111129083]
	TIME [epoch: 11.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04396602004765651		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.04396602004765651 | validation: 0.04832851354405504]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04064491427382953		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.04064491427382953 | validation: 0.051265816670685596]
	TIME [epoch: 11.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0386863216715642		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.0386863216715642 | validation: 0.04779111329601684]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051514578976476294		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.051514578976476294 | validation: 0.06390016048348787]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05942839032718074		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.05942839032718074 | validation: 0.04175073533895108]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04017316628506455		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.04017316628506455 | validation: 0.055021512518997756]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04699755430072936		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.04699755430072936 | validation: 0.0468032397346638]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05153207831865766		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.05153207831865766 | validation: 0.05974338633349668]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05786005450761254		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.05786005450761254 | validation: 0.05870935427455919]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044405620577562054		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.044405620577562054 | validation: 0.037863573405103]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_811.pth
	Model improved!!!
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05003944259228072		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.05003944259228072 | validation: 0.0698983980545949]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07542853768618801		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.07542853768618801 | validation: 0.06261468928703673]
	TIME [epoch: 11.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06165495698373272		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.06165495698373272 | validation: 0.049494375667671286]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04762149487601171		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.04762149487601171 | validation: 0.05667479471106009]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04818636722175056		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.04818636722175056 | validation: 0.050738395270151476]
	TIME [epoch: 11.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04791480272090172		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.04791480272090172 | validation: 0.04425930552109944]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055289061736874964		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.055289061736874964 | validation: 0.09599690623686595]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08932517197196993		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.08932517197196993 | validation: 0.10490938924537067]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07336788406242263		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.07336788406242263 | validation: 0.0654933914968755]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05804585788305737		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.05804585788305737 | validation: 0.0704126946899832]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05692853336051781		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.05692853336051781 | validation: 0.08252473214413016]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07346226777921398		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.07346226777921398 | validation: 0.06742141041858662]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06093674849408061		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.06093674849408061 | validation: 0.056750760025975754]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0496066737037139		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.0496066737037139 | validation: 0.05733707757407631]
	TIME [epoch: 11.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0440271851501118		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.0440271851501118 | validation: 0.05126130254204405]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0486444098681936		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.0486444098681936 | validation: 0.046194634664915524]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05051058726864249		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.05051058726864249 | validation: 0.05339187130119906]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04848194646398104		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.04848194646398104 | validation: 0.05541983155864103]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05521869834313531		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.05521869834313531 | validation: 0.05285178197685607]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0567511836986047		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.0567511836986047 | validation: 0.04987537860646613]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044740885706292206		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.044740885706292206 | validation: 0.06394096559914714]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05376964369295191		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.05376964369295191 | validation: 0.05115636403149815]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0490345265750698		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.0490345265750698 | validation: 0.05094575300969538]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04866521461309175		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.04866521461309175 | validation: 0.06388745285210398]
	TIME [epoch: 11.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059943560230579146		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.059943560230579146 | validation: 0.05160197849743423]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047707109773927885		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.047707109773927885 | validation: 0.039081915579194604]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03982918990309337		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.03982918990309337 | validation: 0.0503791569885159]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05803782048529676		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.05803782048529676 | validation: 0.06188316683193053]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05306315644099123		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.05306315644099123 | validation: 0.04550887349784102]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047762335907089934		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.047762335907089934 | validation: 0.05934481345170262]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05509973674656739		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.05509973674656739 | validation: 0.055152781534825675]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04864792597648394		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.04864792597648394 | validation: 0.05316455393705598]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04899120872361279		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.04899120872361279 | validation: 0.05082027431598812]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05176725231258866		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.05176725231258866 | validation: 0.06497848307345418]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060354534275478294		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.060354534275478294 | validation: 0.060086086946252434]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053370373245671836		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.053370373245671836 | validation: 0.047585279362781494]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04903804101142393		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.04903804101142393 | validation: 0.058561823495010136]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046897541633420095		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.046897541633420095 | validation: 0.054150510747748654]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047924994324576156		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.047924994324576156 | validation: 0.06649774179709213]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058452332962328324		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.058452332962328324 | validation: 0.06267135261634631]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060248668502151825		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.060248668502151825 | validation: 0.05379738566932613]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056432290952944796		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.056432290952944796 | validation: 0.07802105675900357]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07119766098060455		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.07119766098060455 | validation: 0.06404557905635871]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05258159685722896		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.05258159685722896 | validation: 0.05501449472278442]
	TIME [epoch: 11.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05448978522126037		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.05448978522126037 | validation: 0.05804724440702343]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052360274184992485		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.052360274184992485 | validation: 0.051885655885663524]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049403110177868796		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.049403110177868796 | validation: 0.050763431170638834]
	TIME [epoch: 11.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047274507375873284		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.047274507375873284 | validation: 0.04869630058649055]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05173097591266682		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.05173097591266682 | validation: 0.06390200899013194]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06630703935278225		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.06630703935278225 | validation: 0.055569478601511485]
	TIME [epoch: 11.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054925902279657615		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.054925902279657615 | validation: 0.050117288675277955]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04879661529774879		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.04879661529774879 | validation: 0.060308212588118665]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061933999005974676		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.061933999005974676 | validation: 0.057911930240896886]
	TIME [epoch: 11.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05820727508001228		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.05820727508001228 | validation: 0.07573360742160161]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07035757771582096		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.07035757771582096 | validation: 0.06449151988186298]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05283651130591594		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.05283651130591594 | validation: 0.04793932852150582]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05191137612179792		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.05191137612179792 | validation: 0.04826343730784024]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05151645726833892		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.05151645726833892 | validation: 0.05998605493446352]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04904840420295353		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.04904840420295353 | validation: 0.0443028327138176]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042741064500536746		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.042741064500536746 | validation: 0.047912673185719935]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04355030860767996		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.04355030860767996 | validation: 0.04359324510592483]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05560026019080393		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.05560026019080393 | validation: 0.06411821882869853]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06263446560941777		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.06263446560941777 | validation: 0.06247559875251891]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0528724078501769		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.0528724078501769 | validation: 0.06247490589724751]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05270623642856531		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.05270623642856531 | validation: 0.06233530389158128]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06812173152110156		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.06812173152110156 | validation: 0.08276474508097055]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468622962131172		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.06468622962131172 | validation: 0.05717229386712072]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04894446890510577		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.04894446890510577 | validation: 0.07207088359373377]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06377623289920535		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.06377623289920535 | validation: 0.06786815321752103]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055922577991248154		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.055922577991248154 | validation: 0.053487120006163756]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0468600175188226		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.0468600175188226 | validation: 0.0445349329421366]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045380257094847776		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.045380257094847776 | validation: 0.06737859412852244]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05295478257982337		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.05295478257982337 | validation: 0.04794032633460873]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048707775923911456		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.048707775923911456 | validation: 0.05462439222687129]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04511902115085062		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.04511902115085062 | validation: 0.04560216039973547]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05363293953457008		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.05363293953457008 | validation: 0.0664526859901382]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08432251058600904		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.08432251058600904 | validation: 0.10203625365867099]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06688384517490503		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.06688384517490503 | validation: 0.061600789265750404]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03923909236113399		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.03923909236113399 | validation: 0.04768286895910041]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03460959457816001		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.03460959457816001 | validation: 0.04080929229439053]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037097107834674875		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.037097107834674875 | validation: 0.056806298573148215]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04376023095699057		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.04376023095699057 | validation: 0.04628669508572426]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039431854481291544		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.039431854481291544 | validation: 0.04067457633524207]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040679075313951436		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.040679075313951436 | validation: 0.04920237232291048]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04177588230119467		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.04177588230119467 | validation: 0.06578782589846217]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04398644943479484		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.04398644943479484 | validation: 0.04010495470136648]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034454832929494354		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.034454832929494354 | validation: 0.043586402034978475]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039608329420778965		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.039608329420778965 | validation: 0.05699530803161411]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037817292939961764		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.037817292939961764 | validation: 0.0451247689745067]
	TIME [epoch: 11.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034968930064420096		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.034968930064420096 | validation: 0.039403038662539205]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041277416737794295		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.041277416737794295 | validation: 0.05550178089556168]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049628756464497575		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.049628756464497575 | validation: 0.04576251869238979]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04275655336651155		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.04275655336651155 | validation: 0.04571495736020713]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035642411050784445		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.035642411050784445 | validation: 0.05065391987676432]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03785514848952147		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.03785514848952147 | validation: 0.050319419919795126]
	TIME [epoch: 11.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034911384885047074		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.034911384885047074 | validation: 0.048292630538507825]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048562787906426916		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.048562787906426916 | validation: 0.047890062720178685]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04873196421138447		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.04873196421138447 | validation: 0.05458902809423935]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05001342886638247		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.05001342886638247 | validation: 0.04548944602581411]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04018586585751756		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.04018586585751756 | validation: 0.04359324035397002]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03724203433524412		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.03724203433524412 | validation: 0.03957430107432927]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045009243436137804		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.045009243436137804 | validation: 0.05687740349728663]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05097974690690883		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.05097974690690883 | validation: 0.05460278034349592]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04257463822473608		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.04257463822473608 | validation: 0.046862128697803665]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043780217707218315		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.043780217707218315 | validation: 0.042009190330933865]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03639511524290826		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.03639511524290826 | validation: 0.041741980892847044]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03775026451090903		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.03775026451090903 | validation: 0.05141783717020981]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03954901660361868		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.03954901660361868 | validation: 0.04219031165622623]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03641541492342923		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.03641541492342923 | validation: 0.05022402156222003]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03699948471941865		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.03699948471941865 | validation: 0.04447645960676939]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03870120626116136		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.03870120626116136 | validation: 0.03549549710279605]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_922.pth
	Model improved!!!
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032777114509156574		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.032777114509156574 | validation: 0.03828060111201666]
	TIME [epoch: 11.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03351093741063671		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.03351093741063671 | validation: 0.04236543080250215]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035752734367016016		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.035752734367016016 | validation: 0.042957952807157515]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03705402022166071		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.03705402022166071 | validation: 0.046822126063454254]
	TIME [epoch: 11.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04875269726549816		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.04875269726549816 | validation: 0.05019173534048319]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04862633457173972		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.04862633457173972 | validation: 0.04625255889191629]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03663638418334852		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.03663638418334852 | validation: 0.039780792455304026]
	TIME [epoch: 11.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033141248493285015		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.033141248493285015 | validation: 0.04171898882720962]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03142295449662701		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.03142295449662701 | validation: 0.03818579895119418]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03252776359813383		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.03252776359813383 | validation: 0.037861010777985184]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034845660551076865		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.034845660551076865 | validation: 0.03852164559378456]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03383000257246516		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.03383000257246516 | validation: 0.04340873043495245]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03384836369892388		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.03384836369892388 | validation: 0.049474337069465635]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03881285823741788		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.03881285823741788 | validation: 0.03306909876033358]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_936.pth
	Model improved!!!
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03505353752545397		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.03505353752545397 | validation: 0.04115444669502804]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04473670880415938		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.04473670880415938 | validation: 0.04370655998943146]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0368612949589536		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.0368612949589536 | validation: 0.04229717851203923]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04224968887317454		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.04224968887317454 | validation: 0.045237575103413495]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042366836164914067		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.042366836164914067 | validation: 0.046222259812224165]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04188523730461786		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.04188523730461786 | validation: 0.05300102778199899]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05121095823450939		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.05121095823450939 | validation: 0.06845787697449693]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04239758963026741		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.04239758963026741 | validation: 0.04537837935591523]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035770557667202524		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.035770557667202524 | validation: 0.054368796466533593]
	TIME [epoch: 11.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053053103890562454		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.053053103890562454 | validation: 0.04441956632958819]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05275374344172141		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.05275374344172141 | validation: 0.049759208957670734]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05034549410835532		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.05034549410835532 | validation: 0.0497799364043533]
	TIME [epoch: 11.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04366380278817499		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.04366380278817499 | validation: 0.05357825939605913]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04354784705167661		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.04354784705167661 | validation: 0.05318447726270318]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04126682654171128		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.04126682654171128 | validation: 0.03935888770804067]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03632242319959014		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.03632242319959014 | validation: 0.042279624637944845]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03130882535929747		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.03130882535929747 | validation: 0.04314060589384498]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038612920787721224		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.038612920787721224 | validation: 0.0559724232531933]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053480891830554114		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.053480891830554114 | validation: 0.043996521296369905]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044189326504974084		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.044189326504974084 | validation: 0.039492001448916056]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03784735619033032		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.03784735619033032 | validation: 0.0510666432547235]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04756447179795931		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.04756447179795931 | validation: 0.06555719707159113]
	TIME [epoch: 11.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05224156183866236		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.05224156183866236 | validation: 0.04236601179899574]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03673832710858323		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.03673832710858323 | validation: 0.04206983160523219]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03438699211063734		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.03438699211063734 | validation: 0.02567644200091336]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_961.pth
	Model improved!!!
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025907054936334467		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.025907054936334467 | validation: 0.03688029162036582]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03380405550650904		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.03380405550650904 | validation: 0.036822314844883956]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02945603814111311		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.02945603814111311 | validation: 0.042068814101252204]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0351321543661722		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.0351321543661722 | validation: 0.037602819068489446]
	TIME [epoch: 11.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03503013555567915		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.03503013555567915 | validation: 0.0491668789663379]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04080416308932489		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.04080416308932489 | validation: 0.04663418015222841]
	TIME [epoch: 11.4 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03828717086064422		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.03828717086064422 | validation: 0.046816270133688775]
	TIME [epoch: 11.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035678962334417176		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.035678962334417176 | validation: 0.039881291803815486]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03199432686030844		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.03199432686030844 | validation: 0.04342820746282864]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035700933256565856		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.035700933256565856 | validation: 0.037375230223831844]
	TIME [epoch: 11.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0266282190920537		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.0266282190920537 | validation: 0.04099642528482884]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03554651819890306		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.03554651819890306 | validation: 0.04283127103711165]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03733516714391417		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.03733516714391417 | validation: 0.042191722328589025]
	TIME [epoch: 11.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0392385474529453		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.0392385474529453 | validation: 0.037858770033567246]
	TIME [epoch: 11.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03267484201432362		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.03267484201432362 | validation: 0.0315522828302786]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035710008164130946		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.035710008164130946 | validation: 0.03789282633732973]
	TIME [epoch: 11.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03357383775617357		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.03357383775617357 | validation: 0.03838921659529663]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03567535447185004		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.03567535447185004 | validation: 0.042539675431417]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04133692715070896		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.04133692715070896 | validation: 0.05028770854282345]
	TIME [epoch: 11.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035138229566060754		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.035138229566060754 | validation: 0.034707823595368]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03680086151612094		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.03680086151612094 | validation: 0.051567594289072254]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04158070475327333		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.04158070475327333 | validation: 0.04119535125290434]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04753155346871202		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.04753155346871202 | validation: 0.03978366148632729]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043656127420543936		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.043656127420543936 | validation: 0.04548782531494346]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03912912107857898		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.03912912107857898 | validation: 0.03461084639249193]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026800967595027137		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.026800967595027137 | validation: 0.03721268687267055]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03928737863312201		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.03928737863312201 | validation: 0.05192725548026818]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03441747773212303		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.03441747773212303 | validation: 0.04759192088835562]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04749262226769353		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.04749262226769353 | validation: 0.05612862747937448]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04076328677246626		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.04076328677246626 | validation: 0.03986540019840054]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033099918686517855		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.033099918686517855 | validation: 0.03360781665495589]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03161281634303325		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.03161281634303325 | validation: 0.03825906282770111]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028787941780141678		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.028787941780141678 | validation: 0.03855874882562993]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03304891687342168		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.03304891687342168 | validation: 0.037374608434446094]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03241060053762443		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.03241060053762443 | validation: 0.03375805733692174]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032865211099106645		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.032865211099106645 | validation: 0.033252563869840206]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03156144227712733		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.03156144227712733 | validation: 0.03868850522646368]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0379847240681807		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.0379847240681807 | validation: 0.03728489485774861]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034986977409174974		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.034986977409174974 | validation: 0.04644915475027253]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03575505922322063		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.03575505922322063 | validation: 0.04110357805906208]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03670126363261367		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.03670126363261367 | validation: 0.04174868657332059]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03604158326550581		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.03604158326550581 | validation: 0.041568302922100724]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03512949004853979		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.03512949004853979 | validation: 0.04359223068600474]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037357337225604026		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.037357337225604026 | validation: 0.052916626953067515]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043588286562003205		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.043588286562003205 | validation: 0.05414782901313678]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04540891848461925		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.04540891848461925 | validation: 0.051735743372049774]
	TIME [epoch: 11.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04425966585727721		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.04425966585727721 | validation: 0.04930071918417691]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048193644704314496		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.048193644704314496 | validation: 0.05312798023074871]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0470604819556275		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.0470604819556275 | validation: 0.047382353753290474]
	TIME [epoch: 11.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0422125945960227		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.0422125945960227 | validation: 0.04369664589735775]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04650474452834201		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.04650474452834201 | validation: 0.04622689330306194]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0407733562810708		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.0407733562810708 | validation: 0.038594494195801764]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038990333890226395		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.038990333890226395 | validation: 0.03722652710187405]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03816549923428019		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.03816549923428019 | validation: 0.04190605294058703]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03864581489768767		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.03864581489768767 | validation: 0.04156298120680795]
	TIME [epoch: 11.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03342560871601126		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.03342560871601126 | validation: 0.04171546456105062]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031057474425537974		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.031057474425537974 | validation: 0.038749651733455515]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03252920241754334		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.03252920241754334 | validation: 0.03528736525737426]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030433010138989428		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.030433010138989428 | validation: 0.029614299729476753]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031078446075875663		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.031078446075875663 | validation: 0.042088237103405465]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029702412041825707		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.029702412041825707 | validation: 0.03728731931997787]
	TIME [epoch: 11.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03012400751521961		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.03012400751521961 | validation: 0.040184945814758316]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028973939579702145		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.028973939579702145 | validation: 0.035662593736895974]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030723595965428403		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.030723595965428403 | validation: 0.033693784460209576]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03538819055508196		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.03538819055508196 | validation: 0.03776774333657776]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038949220331489946		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.038949220331489946 | validation: 0.036463884568618744]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03418868537649659		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.03418868537649659 | validation: 0.02776164975863564]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034088740764563585		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.034088740764563585 | validation: 0.039898677629369404]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03046232684341538		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.03046232684341538 | validation: 0.03697813238470081]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03248860083470127		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.03248860083470127 | validation: 0.040540541895148156]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04650607327912808		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.04650607327912808 | validation: 0.042428934302867774]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03895787559631161		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.03895787559631161 | validation: 0.03903643368510944]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03726996436985948		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.03726996436985948 | validation: 0.05234379465233639]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04370208382897479		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.04370208382897479 | validation: 0.0433096553597925]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036131890520687104		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.036131890520687104 | validation: 0.03636662098900748]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03314808031638889		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.03314808031638889 | validation: 0.033874650424031934]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037189722554814696		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.037189722554814696 | validation: 0.04527625485434319]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03306570979327543		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.03306570979327543 | validation: 0.031175448840272103]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03270598622948814		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.03270598622948814 | validation: 0.040365321559929994]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0323206896715276		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.0323206896715276 | validation: 0.0325509165629108]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03383936387335333		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.03383936387335333 | validation: 0.04126574890436633]
	TIME [epoch: 11.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030768277013518888		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.030768277013518888 | validation: 0.03419298674450641]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03465970617582627		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.03465970617582627 | validation: 0.046305228468427106]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031967481825658305		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.031967481825658305 | validation: 0.040410238923131385]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03594029650629401		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.03594029650629401 | validation: 0.04689179135614621]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038069739450011644		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.038069739450011644 | validation: 0.039869864582308005]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03160768718540934		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.03160768718540934 | validation: 0.0436451966364861]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029429340824068072		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.029429340824068072 | validation: 0.03406860695155856]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03178324496017872		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.03178324496017872 | validation: 0.041788613758145104]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03219000566961501		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.03219000566961501 | validation: 0.04095613656242259]
	TIME [epoch: 11.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028394915900735847		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.028394915900735847 | validation: 0.041369993439139864]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485006292455715		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.03485006292455715 | validation: 0.0446364443008745]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03296366938433322		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.03296366938433322 | validation: 0.03716340922540063]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03192159760152554		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.03192159760152554 | validation: 0.037981253652303475]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031233539362308452		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.031233539362308452 | validation: 0.03578290632676204]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03259951025578335		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.03259951025578335 | validation: 0.05232398948336435]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04154598367401333		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.04154598367401333 | validation: 0.04348329682416527]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030504859565916115		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.030504859565916115 | validation: 0.04051862631430904]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0315634930358883		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.0315634930358883 | validation: 0.034086290579135856]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03309095920774044		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.03309095920774044 | validation: 0.0503029620937094]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03424548266836541		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.03424548266836541 | validation: 0.040145783838148874]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028317200118414737		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.028317200118414737 | validation: 0.03826030504011527]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03536774512082262		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.03536774512082262 | validation: 0.04518524760375506]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03887387552302114		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.03887387552302114 | validation: 0.0364772151806584]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033398672901642945		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.033398672901642945 | validation: 0.04268342488847585]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03221338244686622		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.03221338244686622 | validation: 0.04253614941320828]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03232707527482261		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.03232707527482261 | validation: 0.03667103139373427]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04015502628288134		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.04015502628288134 | validation: 0.048560072316991464]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02951975744514631		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.02951975744514631 | validation: 0.03540865032298286]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029482380873337946		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.029482380873337946 | validation: 0.03947281114825492]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0362242898610199		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.0362242898610199 | validation: 0.050932598048936635]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028615306233321335		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.028615306233321335 | validation: 0.03986876866549894]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03164234562604677		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.03164234562604677 | validation: 0.04273211417823804]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029639341950823905		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.029639341950823905 | validation: 0.03673630179183177]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030034280676145907		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.030034280676145907 | validation: 0.030037606967650194]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02597936018232657		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.02597936018232657 | validation: 0.039434838409121827]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03132510428281983		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.03132510428281983 | validation: 0.03675507287058823]
	TIME [epoch: 11.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03320165091278094		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.03320165091278094 | validation: 0.034555242863332544]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03117422829477586		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.03117422829477586 | validation: 0.030498977141395642]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028886086389795392		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.028886086389795392 | validation: 0.038466117465926784]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032064461888050094		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.032064461888050094 | validation: 0.03424727592311166]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03030713959176134		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.03030713959176134 | validation: 0.046118832914924614]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03275445183532226		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.03275445183532226 | validation: 0.034654560438919645]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030993080863228308		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.030993080863228308 | validation: 0.02791368203046019]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02598812302587006		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.02598812302587006 | validation: 0.03873767307556856]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024650600005550135		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.024650600005550135 | validation: 0.033660821908804935]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025663619824700657		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.025663619824700657 | validation: 0.036001377524208004]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030779012128613108		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.030779012128613108 | validation: 0.0378661010240719]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035944662930398746		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.035944662930398746 | validation: 0.04080903567986587]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03224029280682675		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.03224029280682675 | validation: 0.044941321400818024]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035531202855055906		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.035531202855055906 | validation: 0.0422242391127353]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03212662125991059		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.03212662125991059 | validation: 0.03366092717632398]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03176268527226467		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.03176268527226467 | validation: 0.033438673543767686]
	TIME [epoch: 11.4 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032107687730121695		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.032107687730121695 | validation: 0.0351625973598214]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03289555276776294		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.03289555276776294 | validation: 0.04227431775729095]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035176101291627716		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.035176101291627716 | validation: 0.03297188833546057]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03089980607733473		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.03089980607733473 | validation: 0.04127214485127146]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02636197581398191		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.02636197581398191 | validation: 0.03363324895412092]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028931882946191083		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.028931882946191083 | validation: 0.02865349227021549]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029727242153002077		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.029727242153002077 | validation: 0.03567255476610621]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029850294619325413		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.029850294619325413 | validation: 0.037331136015816536]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03151117650723077		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.03151117650723077 | validation: 0.04234765340636026]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025066187575809855		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.025066187575809855 | validation: 0.02854287671451476]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028113477154809566		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.028113477154809566 | validation: 0.03389465486107148]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031959663682197804		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.031959663682197804 | validation: 0.038144845453462514]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031109280858363536		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.031109280858363536 | validation: 0.03721535194079478]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028521584288691827		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.028521584288691827 | validation: 0.038599455063927826]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02754307438062624		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.02754307438062624 | validation: 0.042986920168013205]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027038305155919096		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.027038305155919096 | validation: 0.027964391317096497]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02620793834276188		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.02620793834276188 | validation: 0.04315245391333433]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03615812230650916		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.03615812230650916 | validation: 0.03921384862546978]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379156279455634		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.03379156279455634 | validation: 0.03850650087884212]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032874096722152364		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.032874096722152364 | validation: 0.039409038960454]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028275584997236106		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.028275584997236106 | validation: 0.04763568701798727]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02966374672640614		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.02966374672640614 | validation: 0.040546280740352846]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028704794481493417		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.028704794481493417 | validation: 0.046904980665385225]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039954434344823334		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.039954434344823334 | validation: 0.04577531208508324]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035641911741332695		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.035641911741332695 | validation: 0.045904249587711214]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032511825352697796		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.032511825352697796 | validation: 0.03935542395524871]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03059718622842278		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.03059718622842278 | validation: 0.031586904076882395]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028830534242589405		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.028830534242589405 | validation: 0.03126451178857904]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02563049537404037		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.02563049537404037 | validation: 0.0394964571277536]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029206239230978162		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.029206239230978162 | validation: 0.04492827903807017]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027419608663001426		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.027419608663001426 | validation: 0.03549051163177357]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03191212246594746		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.03191212246594746 | validation: 0.027450125614606972]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029616737194075617		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.029616737194075617 | validation: 0.03809481812195896]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02829931308215404		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.02829931308215404 | validation: 0.03639888644359175]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031801162447193096		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.031801162447193096 | validation: 0.03999205739285242]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03182649052623201		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.03182649052623201 | validation: 0.04104402155556075]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028419592213237366		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.028419592213237366 | validation: 0.04014073881913332]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030736020785094586		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.030736020785094586 | validation: 0.03879558269932543]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030377176003862055		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.030377176003862055 | validation: 0.03915168094456125]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028126745030453912		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.028126745030453912 | validation: 0.04164177890744432]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031116060141270684		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.031116060141270684 | validation: 0.036248758958375475]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03166189446878086		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.03166189446878086 | validation: 0.048443290660224306]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430865114036801		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.03430865114036801 | validation: 0.046238123740792336]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03346619867591939		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.03346619867591939 | validation: 0.042930740313654354]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03907983408107871		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.03907983408107871 | validation: 0.04597039903419242]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03779259013419556		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.03779259013419556 | validation: 0.04308542345035194]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0347059864797699		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.0347059864797699 | validation: 0.048836315483675535]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03378099088956262		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.03378099088956262 | validation: 0.046002761787971774]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028739184952122375		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.028739184952122375 | validation: 0.04175597741297555]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0305635595362339		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.0305635595362339 | validation: 0.048147784905513746]
	TIME [epoch: 11.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030833785935137734		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.030833785935137734 | validation: 0.03901732135027625]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031242117600091303		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.031242117600091303 | validation: 0.05204997403778368]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03333841377873217		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.03333841377873217 | validation: 0.03601237493214115]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028653813212287427		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.028653813212287427 | validation: 0.03941274274910575]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02742275703476288		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.02742275703476288 | validation: 0.048092481565634025]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03172463887927066		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.03172463887927066 | validation: 0.04711508703296528]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03438859557995628		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.03438859557995628 | validation: 0.043287316073415634]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03776350081113812		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.03776350081113812 | validation: 0.04678478412525449]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03330124927866257		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.03330124927866257 | validation: 0.02793079490002165]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028810148749257476		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.028810148749257476 | validation: 0.02879528180585064]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02609224666568677		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.02609224666568677 | validation: 0.03411358780615927]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030279365241395215		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.030279365241395215 | validation: 0.036300923269784395]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379230394046186		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.03379230394046186 | validation: 0.041375404414890314]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03058129498777097		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.03058129498777097 | validation: 0.0476950453774969]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029487586566153967		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.029487586566153967 | validation: 0.03920051508531291]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03386187861798085		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.03386187861798085 | validation: 0.03727825793113931]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02611987279802727		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.02611987279802727 | validation: 0.04415823695974545]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031341301789734495		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.031341301789734495 | validation: 0.038630508624893686]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030525639950309432		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.030525639950309432 | validation: 0.03938293233889027]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034010748715593966		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.034010748715593966 | validation: 0.03934623003922476]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031964494156452875		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.031964494156452875 | validation: 0.04060140161876023]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026988682455911663		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.026988682455911663 | validation: 0.04056046084471266]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02927588330911611		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.02927588330911611 | validation: 0.036036585331146016]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030966043039154505		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.030966043039154505 | validation: 0.03477256018304685]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032749505944734233		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.032749505944734233 | validation: 0.02456777787338495]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_1169.pth
	Model improved!!!
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03470648023277089		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.03470648023277089 | validation: 0.033023837666011364]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02924855584124971		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.02924855584124971 | validation: 0.03143508252443958]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027324875307485237		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.027324875307485237 | validation: 0.04175135248360554]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02772609867999503		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.02772609867999503 | validation: 0.0351143037154392]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02919194244556462		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.02919194244556462 | validation: 0.0356050156063737]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026803794953688384		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.026803794953688384 | validation: 0.03792459329480798]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027760278456257715		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.027760278456257715 | validation: 0.03517825067991943]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030589606999962382		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.030589606999962382 | validation: 0.04314806613238641]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02933309446068856		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.02933309446068856 | validation: 0.036094182415803165]
	TIME [epoch: 11.4 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028359360330398355		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.028359360330398355 | validation: 0.03764437834559228]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031296052145911316		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.031296052145911316 | validation: 0.029702053601815163]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02865528391345752		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.02865528391345752 | validation: 0.04090511799195237]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031472415609663865		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.031472415609663865 | validation: 0.04035727626732966]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030743806036733927		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.030743806036733927 | validation: 0.0396903331949959]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03555753650161596		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.03555753650161596 | validation: 0.04139921499480611]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03832983759114888		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.03832983759114888 | validation: 0.06006121953262704]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04642116633385413		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.04642116633385413 | validation: 0.04827360804751194]
	TIME [epoch: 11.5 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034758329131353974		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.034758329131353974 | validation: 0.06161164914131168]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04060805722902301		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.04060805722902301 | validation: 0.05641544847862557]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040935821362519484		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.040935821362519484 | validation: 0.05360652360834015]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046318245770222116		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.046318245770222116 | validation: 0.04859979601758948]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03847810475614197		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.03847810475614197 | validation: 0.05253464541575552]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03813196195785521		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.03813196195785521 | validation: 0.04895985585246735]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0388211519751864		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.0388211519751864 | validation: 0.04747724254522445]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036168399939584005		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.036168399939584005 | validation: 0.04748478339174196]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03359670005088056		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.03359670005088056 | validation: 0.03458445958284183]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029068805459434865		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.029068805459434865 | validation: 0.0422669535223638]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035395754914171296		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.035395754914171296 | validation: 0.03932723876461123]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03396980501333347		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.03396980501333347 | validation: 0.03791510288060546]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02898478591303354		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.02898478591303354 | validation: 0.03988431155848218]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028475639864359477		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.028475639864359477 | validation: 0.031001035101623966]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026892928986421035		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.026892928986421035 | validation: 0.0339775981299152]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033408087783029596		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.033408087783029596 | validation: 0.03704948363670691]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028223017795792317		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.028223017795792317 | validation: 0.03237736590247387]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027670909487327065		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.027670909487327065 | validation: 0.03624965781180886]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029349346563087884		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.029349346563087884 | validation: 0.03625914207787528]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02675500828454338		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.02675500828454338 | validation: 0.030211211547716027]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02807076229938878		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.02807076229938878 | validation: 0.036750572713490734]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03043012975062458		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.03043012975062458 | validation: 0.04111359686422798]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029356617282869937		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.029356617282869937 | validation: 0.03140393066315461]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032075887186542404		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.032075887186542404 | validation: 0.04458644350293048]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031233541626545964		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.031233541626545964 | validation: 0.03590414184920371]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028059706373716266		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.028059706373716266 | validation: 0.04037969787745542]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02999685586076402		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.02999685586076402 | validation: 0.03966527553770673]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02697104444250504		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.02697104444250504 | validation: 0.029156766579639608]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029277991538816783		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.029277991538816783 | validation: 0.037710897437759607]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030054018746338843		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.030054018746338843 | validation: 0.04561391275820956]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03362245785444694		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.03362245785444694 | validation: 0.046260176818920924]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029238443330657234		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.029238443330657234 | validation: 0.038755321944393586]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033790583287085056		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.033790583287085056 | validation: 0.03511801782825234]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031775343972178766		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.031775343972178766 | validation: 0.037845712164590706]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025853158046619935		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.025853158046619935 | validation: 0.03999654873020497]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03042474429902079		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.03042474429902079 | validation: 0.036832269122424356]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02290755638039445		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.02290755638039445 | validation: 0.040271820351049835]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02949556223956959		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.02949556223956959 | validation: 0.036928049780019234]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026707381756821455		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.026707381756821455 | validation: 0.033541072403404475]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027342672969950882		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.027342672969950882 | validation: 0.03994161358079992]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030110993620479923		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.030110993620479923 | validation: 0.036762876921637364]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02893080442414351		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.02893080442414351 | validation: 0.03684961291208906]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028644431808712834		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.028644431808712834 | validation: 0.04362220692017275]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028685209898043067		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.028685209898043067 | validation: 0.04195250333908376]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032606707224034616		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.032606707224034616 | validation: 0.03915565222800769]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033503522015724575		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.033503522015724575 | validation: 0.050400596611059924]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033799966306842635		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.033799966306842635 | validation: 0.039910209847714734]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031023179269217625		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.031023179269217625 | validation: 0.04707179070621826]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03567366823468579		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.03567366823468579 | validation: 0.048602904342767345]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02997079569591123		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.02997079569591123 | validation: 0.042971949283626736]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02722535758280178		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.02722535758280178 | validation: 0.04043117594876109]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02556921026898902		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.02556921026898902 | validation: 0.036970936114136245]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03321745555540149		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.03321745555540149 | validation: 0.042308664967227724]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039888957422175464		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.039888957422175464 | validation: 0.043429498190673516]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03363236122188305		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.03363236122188305 | validation: 0.04188665542453002]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029222690644744524		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.029222690644744524 | validation: 0.039498036499806766]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03085178276074669		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.03085178276074669 | validation: 0.03998422232306912]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03033221080523385		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.03033221080523385 | validation: 0.03808993867941887]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029393294163652287		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.029393294163652287 | validation: 0.032026506027160846]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02998391216864112		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.02998391216864112 | validation: 0.03190842337669482]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029242432823273375		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.029242432823273375 | validation: 0.03877408058257345]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02933230360028429		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.02933230360028429 | validation: 0.03860288878545639]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03163340300124996		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.03163340300124996 | validation: 0.042685387979512594]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031228556587569047		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.031228556587569047 | validation: 0.043131828231556674]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02805817564773247		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.02805817564773247 | validation: 0.03943978300467009]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028393325748864086		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.028393325748864086 | validation: 0.04639289092667131]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02911674623210083		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.02911674623210083 | validation: 0.033218695599020506]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027961981064754008		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.027961981064754008 | validation: 0.03475483101177115]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023271990526417728		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.023271990526417728 | validation: 0.038302410094850664]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02538958402416457		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.02538958402416457 | validation: 0.03796214391106668]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024741169487468153		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.024741169487468153 | validation: 0.03102804781197455]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02551990885547575		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.02551990885547575 | validation: 0.0338246052999655]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02831519499484066		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.02831519499484066 | validation: 0.03442237763294708]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024412744243046656		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.024412744243046656 | validation: 0.029582498758106562]
	TIME [epoch: 11.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028348799010778036		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.028348799010778036 | validation: 0.03673406780932492]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030274543178046814		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.030274543178046814 | validation: 0.04379749154744321]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03220072068219659		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.03220072068219659 | validation: 0.0430972407460666]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030330301067782922		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.030330301067782922 | validation: 0.04771055958671671]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02846492955405156		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.02846492955405156 | validation: 0.04128052206011917]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026397721092995628		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.026397721092995628 | validation: 0.049556107369939685]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029888498347418843		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.029888498347418843 | validation: 0.03841835275348752]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02917509374965562		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.02917509374965562 | validation: 0.034432882151257754]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024857906135264903		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.024857906135264903 | validation: 0.028908851439823843]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026440409666782558		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.026440409666782558 | validation: 0.02872717987692175]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029710000174943053		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.029710000174943053 | validation: 0.03562187164001552]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02844960653311512		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.02844960653311512 | validation: 0.03215295569872973]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029868600728707145		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.029868600728707145 | validation: 0.0408968769633203]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024626147904356094		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.024626147904356094 | validation: 0.03385969272506387]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027543296833147157		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.027543296833147157 | validation: 0.04155482746019717]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03139895651820655		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.03139895651820655 | validation: 0.03870548300597209]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03514021106132732		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.03514021106132732 | validation: 0.03781494760420319]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02851799256426729		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.02851799256426729 | validation: 0.033036293144851694]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029419502367227617		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.029419502367227617 | validation: 0.03146225084172729]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025353063150890268		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.025353063150890268 | validation: 0.030783462878811913]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024349712105718756		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.024349712105718756 | validation: 0.03550723389853363]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02911909346294249		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.02911909346294249 | validation: 0.04091018455569408]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03461692539925941		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.03461692539925941 | validation: 0.03987565319788115]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0363355448866618		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.0363355448866618 | validation: 0.04550427469025019]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03228419411443271		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.03228419411443271 | validation: 0.04311131233872986]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031518489916738904		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.031518489916738904 | validation: 0.03959912275389245]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032964126613283025		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.032964126613283025 | validation: 0.03426776029606704]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03314920202971461		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.03314920202971461 | validation: 0.03515060545753961]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02945336252367569		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.02945336252367569 | validation: 0.049835601120716576]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03370764851937628		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.03370764851937628 | validation: 0.04187268585746718]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03729509630606824		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.03729509630606824 | validation: 0.04300040836209666]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03776960143434099		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.03776960143434099 | validation: 0.04730685204394645]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035126847407589076		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.035126847407589076 | validation: 0.04559346512548884]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032612795880143895		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.032612795880143895 | validation: 0.03711929534841657]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03431024372876569		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.03431024372876569 | validation: 0.034171215273416336]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03129236848924073		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.03129236848924073 | validation: 0.04257948081983681]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028492108473327157		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.028492108473327157 | validation: 0.0465941225423088]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039291117167602835		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.039291117167602835 | validation: 0.05456378380120304]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039930760386492396		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.039930760386492396 | validation: 0.04868409606328011]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03748116919875755		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.03748116919875755 | validation: 0.042977077429315]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03611776111206953		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.03611776111206953 | validation: 0.04394784905842328]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038445376245657456		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.038445376245657456 | validation: 0.046058173062430506]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03393819190760436		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.03393819190760436 | validation: 0.0434533614470691]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038530203225711136		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.038530203225711136 | validation: 0.038616436867136485]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030497413407619287		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.030497413407619287 | validation: 0.047095623530056974]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037945167579944164		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.037945167579944164 | validation: 0.035686759572186554]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032809416424116916		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.032809416424116916 | validation: 0.0342456920337841]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033154507422804534		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.033154507422804534 | validation: 0.04628182224186525]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03219554409930159		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.03219554409930159 | validation: 0.035181547518905947]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03201127794729745		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.03201127794729745 | validation: 0.04214771097363839]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025579673852751967		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.025579673852751967 | validation: 0.04049329943027333]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03003931261421304		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.03003931261421304 | validation: 0.029790013722148498]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027104125635507455		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.027104125635507455 | validation: 0.03503408134896904]
	TIME [epoch: 11.4 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027709778432850097		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.027709778432850097 | validation: 0.03951812956806364]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02585992518576937		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.02585992518576937 | validation: 0.03338021815304176]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027948312565666118		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.027948312565666118 | validation: 0.036744466768467474]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024404534240137873		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.024404534240137873 | validation: 0.04957361422691495]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03193478449456226		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.03193478449456226 | validation: 0.04702897010087439]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330832553181898		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.0330832553181898 | validation: 0.03691715832612131]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03864262710488875		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.03864262710488875 | validation: 0.04804040311185293]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03940974621317433		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.03940974621317433 | validation: 0.04841576386993803]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03674346608499384		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.03674346608499384 | validation: 0.04770237583655325]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03469452840830872		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.03469452840830872 | validation: 0.043836084511649887]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03323284276724482		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.03323284276724482 | validation: 0.033935013546484115]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03180273002674859		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.03180273002674859 | validation: 0.04098129271887377]
	TIME [epoch: 11.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026764155161651614		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.026764155161651614 | validation: 0.04000067346355498]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03180726654871158		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.03180726654871158 | validation: 0.037135519839095237]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03203006934703453		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.03203006934703453 | validation: 0.04120477777931357]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02955224513934635		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.02955224513934635 | validation: 0.03535482436997423]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028927201093498205		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.028927201093498205 | validation: 0.031878742145702056]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027725699777268714		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.027725699777268714 | validation: 0.03350814503666139]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02805396594828255		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.02805396594828255 | validation: 0.026891700391442522]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02699089717835431		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.02699089717835431 | validation: 0.03959508659743748]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03165290774187594		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.03165290774187594 | validation: 0.035930717718569045]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024920419560308722		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.024920419560308722 | validation: 0.03762650719298758]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02690504723069819		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.02690504723069819 | validation: 0.032637979873389816]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026855744707334733		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.026855744707334733 | validation: 0.03701393056026897]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02714376587956837		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.02714376587956837 | validation: 0.033865436556115326]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027679959891942905		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.027679959891942905 | validation: 0.02692421748732294]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02817495579108705		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.02817495579108705 | validation: 0.03935707394339371]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02287439605711775		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.02287439605711775 | validation: 0.04102422633028249]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024390116813978107		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.024390116813978107 | validation: 0.0395486150840452]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027854041940897783		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.027854041940897783 | validation: 0.04590985308033558]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029374515645310868		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.029374515645310868 | validation: 0.03378448796218505]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02699178981225369		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.02699178981225369 | validation: 0.03444593569996178]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028220792945293963		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.028220792945293963 | validation: 0.027850016890200113]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02875326223547929		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.02875326223547929 | validation: 0.030558160980675805]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025984058676918217		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.025984058676918217 | validation: 0.03946518128669728]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025979980347535174		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.025979980347535174 | validation: 0.03565677262905998]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029271662095854724		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.029271662095854724 | validation: 0.037219354832930464]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03234379406346578		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.03234379406346578 | validation: 0.03800189000362456]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029980192049161504		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.029980192049161504 | validation: 0.034644923978440725]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029001004763969825		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.029001004763969825 | validation: 0.03193343124674106]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02369094619216283		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.02369094619216283 | validation: 0.039211709821656296]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02749831629875997		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.02749831629875997 | validation: 0.038139942812093486]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026379769134766543		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.026379769134766543 | validation: 0.035917583104140706]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026831807420995977		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.026831807420995977 | validation: 0.03928306754937067]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02990373931294431		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.02990373931294431 | validation: 0.037295905165537095]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026848189133479805		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.026848189133479805 | validation: 0.03098099205143436]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02413925776508752		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.02413925776508752 | validation: 0.03184177214108015]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02649629323417734		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.02649629323417734 | validation: 0.04139191514699824]
	TIME [epoch: 11.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023711666681575518		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.023711666681575518 | validation: 0.04186636485636372]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02643666515286986		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.02643666515286986 | validation: 0.04097018965998988]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025473922096444994		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.025473922096444994 | validation: 0.040079240254025636]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02941097856890899		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.02941097856890899 | validation: 0.03739117345377247]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03111707747921941		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.03111707747921941 | validation: 0.04247146357378886]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031175417088916475		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.031175417088916475 | validation: 0.02580282683575935]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0280347873224928		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.0280347873224928 | validation: 0.03895886295474026]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028613220785614783		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.028613220785614783 | validation: 0.03323876537786258]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028313533547079883		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.028313533547079883 | validation: 0.036927485061448016]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028889478710203313		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.028889478710203313 | validation: 0.042328579335494255]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03270492999162901		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.03270492999162901 | validation: 0.04072783741186256]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02730390559924193		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.02730390559924193 | validation: 0.03680194435261788]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030529083724703147		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.030529083724703147 | validation: 0.05044494094672072]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150825947996584		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.03150825947996584 | validation: 0.03945451367288036]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0344812466416364		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.0344812466416364 | validation: 0.03868346761343561]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029753255395767272		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.029753255395767272 | validation: 0.04189429069355853]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029563854463826724		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.029563854463826724 | validation: 0.040941539518943734]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02678562051171037		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.02678562051171037 | validation: 0.03531412597345117]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030352797906422584		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.030352797906422584 | validation: 0.039433484308112644]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03520364644275278		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.03520364644275278 | validation: 0.05099672610835342]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03180228244847776		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.03180228244847776 | validation: 0.041852969392581145]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03183521421761943		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.03183521421761943 | validation: 0.046162298741889075]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028978111714485465		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.028978111714485465 | validation: 0.04365519736794056]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027624221275599756		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.027624221275599756 | validation: 0.03664944211934902]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030671367350045064		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.030671367350045064 | validation: 0.03888891602425639]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03017555411235239		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.03017555411235239 | validation: 0.04157373268238544]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028694056999505613		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.028694056999505613 | validation: 0.05675549696649309]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035135897723077986		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.035135897723077986 | validation: 0.04556374816916133]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03423404147854027		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.03423404147854027 | validation: 0.04386923328411698]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030506969198425958		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.030506969198425958 | validation: 0.042601542326677996]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03471454219461753		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.03471454219461753 | validation: 0.05379246106266224]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03616906341119652		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.03616906341119652 | validation: 0.04562741435855429]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03876958943514524		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.03876958943514524 | validation: 0.05620243486290122]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04188293519712155		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.04188293519712155 | validation: 0.05424313611254688]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03797073122078312		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.03797073122078312 | validation: 0.05038532083068296]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04196630899289939		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.04196630899289939 | validation: 0.05369645637302797]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04216443534765993		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.04216443534765993 | validation: 0.053033837357752155]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04026981436245784		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.04026981436245784 | validation: 0.0571415198601658]
	TIME [epoch: 11.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040392877755710266		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.040392877755710266 | validation: 0.05259920824441915]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0426325395250724		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.0426325395250724 | validation: 0.05293510110816637]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04037872506579729		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.04037872506579729 | validation: 0.05838961296104287]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03432989184459288		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.03432989184459288 | validation: 0.04084957019319996]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03423490398818042		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.03423490398818042 | validation: 0.047319855037081054]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037539120404045376		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.037539120404045376 | validation: 0.0510728444385836]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033612082399981445		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.033612082399981445 | validation: 0.04998222512208612]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030715033373639063		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.030715033373639063 | validation: 0.050667028306317495]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03124923447823027		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.03124923447823027 | validation: 0.036730167412890674]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03626111083998704		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.03626111083998704 | validation: 0.04346645226633829]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031537830084093346		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.031537830084093346 | validation: 0.045050364557673896]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034363185814028294		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.034363185814028294 | validation: 0.03775320612590288]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150988778650484		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.03150988778650484 | validation: 0.04772576575414531]
	TIME [epoch: 11.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030299982754711456		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.030299982754711456 | validation: 0.03290684987117519]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029107859567464762		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.029107859567464762 | validation: 0.041283270938816834]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026593211186165124		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.026593211186165124 | validation: 0.03525312931671346]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028625721571036808		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.028625721571036808 | validation: 0.042299112671214376]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02909317141901275		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.02909317141901275 | validation: 0.03198327386030414]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025103692013535357		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.025103692013535357 | validation: 0.03169644679436863]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025600250456497876		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.025600250456497876 | validation: 0.03313023539734033]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02883709650009364		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.02883709650009364 | validation: 0.035477247195383116]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02876588122874704		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.02876588122874704 | validation: 0.034113718018019136]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025971048972605708		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.025971048972605708 | validation: 0.03785441517146795]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02552770949980442		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.02552770949980442 | validation: 0.02894016978879664]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03125975714794432		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.03125975714794432 | validation: 0.033584833105235204]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0278953002307315		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.0278953002307315 | validation: 0.03417928671712648]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02984237147171292		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.02984237147171292 | validation: 0.035600623396549194]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03265825322745375		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.03265825322745375 | validation: 0.036665754005315125]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031709905012099124		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.031709905012099124 | validation: 0.034176134092981064]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030937476670357136		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.030937476670357136 | validation: 0.028129939299317334]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024616598761021805		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.024616598761021805 | validation: 0.03206223520248854]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0255053562877494		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.0255053562877494 | validation: 0.038330461543405255]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02587682134854615		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.02587682134854615 | validation: 0.0441551875963948]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028136081720059047		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.028136081720059047 | validation: 0.039775990858858225]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027252186721021074		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.027252186721021074 | validation: 0.032781275183469634]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027013646611069204		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.027013646611069204 | validation: 0.041743605919953214]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028888870268354246		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.028888870268354246 | validation: 0.03825937648822806]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027963017476353137		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.027963017476353137 | validation: 0.03789025747916923]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03025538019813169		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.03025538019813169 | validation: 0.0329693237357839]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028178581626574137		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.028178581626574137 | validation: 0.038773071175745744]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029221417011572007		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.029221417011572007 | validation: 0.0328838393341731]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02739296172235204		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.02739296172235204 | validation: 0.03549929929906329]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02508615996225775		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.02508615996225775 | validation: 0.04059269807809802]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02950932196115805		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.02950932196115805 | validation: 0.030992541490773476]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023649430217470846		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.023649430217470846 | validation: 0.03372439189677017]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027527416778522662		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.027527416778522662 | validation: 0.04310016671287171]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025132378976887023		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.025132378976887023 | validation: 0.03578101006069281]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027479904100034536		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.027479904100034536 | validation: 0.0440266150036291]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028272030343754376		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.028272030343754376 | validation: 0.029600333429605438]
	TIME [epoch: 11.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029353261353779733		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.029353261353779733 | validation: 0.03365747534046998]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0266420812616742		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.0266420812616742 | validation: 0.034600626300610005]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023630842032450833		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.023630842032450833 | validation: 0.03685936426211182]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023765706067301638		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.023765706067301638 | validation: 0.026121417307315636]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028078278325450696		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.028078278325450696 | validation: 0.030086097950013425]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026511428229454403		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.026511428229454403 | validation: 0.03438072165559773]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026417293107753627		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.026417293107753627 | validation: 0.03256525066610199]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023927117239149538		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.023927117239149538 | validation: 0.03194041979962351]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0221339997134253		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.0221339997134253 | validation: 0.03921006637002106]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02643876374232941		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.02643876374232941 | validation: 0.031040170760828902]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024737116266474776		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.024737116266474776 | validation: 0.04624987622016553]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02845354244812078		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.02845354244812078 | validation: 0.03227770569427972]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027759504554845868		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.027759504554845868 | validation: 0.031250930101629194]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02603821541972466		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.02603821541972466 | validation: 0.03570992670323465]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02691353400093043		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.02691353400093043 | validation: 0.038924435945164475]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02595161060535951		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.02595161060535951 | validation: 0.035490191440860124]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027826612122662454		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.027826612122662454 | validation: 0.022088941060082145]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_1465.pth
	Model improved!!!
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024372265563681758		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.024372265563681758 | validation: 0.03225874698747898]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027122206117303517		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.027122206117303517 | validation: 0.03700365806992588]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02348646764255365		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.02348646764255365 | validation: 0.04073082702011517]
	TIME [epoch: 11.4 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025448540278252038		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.025448540278252038 | validation: 0.02965982355452142]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02477357205642859		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.02477357205642859 | validation: 0.030403997741933787]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025029735536120756		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.025029735536120756 | validation: 0.031524643256913565]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02641088096798219		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.02641088096798219 | validation: 0.03139708052254177]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025839412759368383		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.025839412759368383 | validation: 0.03623666585050623]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02225669358072808		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.02225669358072808 | validation: 0.035130467769586886]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026629431913520518		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.026629431913520518 | validation: 0.03120411720472627]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026640561257741634		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.026640561257741634 | validation: 0.03166973973041619]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027593382262431083		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.027593382262431083 | validation: 0.037817424491452964]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026477491914912103		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.026477491914912103 | validation: 0.03244042070664465]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031848052278007306		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.031848052278007306 | validation: 0.04317821902341404]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027252761919927905		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.027252761919927905 | validation: 0.04564183997372053]
	TIME [epoch: 11.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03107367324276182		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.03107367324276182 | validation: 0.03703844648583735]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025246523728608732		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.025246523728608732 | validation: 0.03638164687361171]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02909857014615016		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.02909857014615016 | validation: 0.03315801016069409]
	TIME [epoch: 11.4 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028056355816228746		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.028056355816228746 | validation: 0.0439806310495802]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02543105943076161		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.02543105943076161 | validation: 0.03885179959369396]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02682938559640731		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.02682938559640731 | validation: 0.0438519623629731]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027685036904132147		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.027685036904132147 | validation: 0.037990274346827384]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029983853320172667		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.029983853320172667 | validation: 0.03984149424203522]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024292640482341515		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.024292640482341515 | validation: 0.035944893827120176]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027356306846271532		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.027356306846271532 | validation: 0.03185744383208379]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02805454749012897		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.02805454749012897 | validation: 0.03846314004129443]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026236200829052526		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.026236200829052526 | validation: 0.03851088916360877]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026845558088226206		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.026845558088226206 | validation: 0.0366855834647234]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02536849791104		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.02536849791104 | validation: 0.03493861643716576]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026598709421364566		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.026598709421364566 | validation: 0.035886266947139166]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027160272446710487		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.027160272446710487 | validation: 0.02534632139141668]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02939362480212882		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.02939362480212882 | validation: 0.037158057502373706]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025843697012344437		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.025843697012344437 | validation: 0.03958166311293288]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02797377716416669		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.02797377716416669 | validation: 0.03146956928554763]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027312826055691426		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.027312826055691426 | validation: 0.03058184971815382]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030323046318191972		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.030323046318191972 | validation: 0.03390826679602206]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027976187998191515		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.027976187998191515 | validation: 0.04413877688575697]
	TIME [epoch: 11.4 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028585791796964594		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.028585791796964594 | validation: 0.038122073885679446]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026551521582720252		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.026551521582720252 | validation: 0.038262654921868214]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03259842933880551		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.03259842933880551 | validation: 0.040036481739898336]
	TIME [epoch: 11.4 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028674780717868147		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.028674780717868147 | validation: 0.0406158010877492]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030115122872300504		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.030115122872300504 | validation: 0.04020726071713413]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034000037475039636		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.034000037475039636 | validation: 0.03816839843291934]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03116067266110521		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.03116067266110521 | validation: 0.04906184646138659]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028323664232528006		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.028323664232528006 | validation: 0.03643619720773951]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032825421055428405		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.032825421055428405 | validation: 0.040381879504604534]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033133093103953445		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.033133093103953445 | validation: 0.03564853065772358]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0299532159463929		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.0299532159463929 | validation: 0.041732103907504065]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03360805923968488		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.03360805923968488 | validation: 0.04353491195284157]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02999746397076801		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.02999746397076801 | validation: 0.041715121654655046]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03166806048799838		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.03166806048799838 | validation: 0.03776104129253151]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030131443013910186		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.030131443013910186 | validation: 0.04427479567519477]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331202991381358		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.0331202991381358 | validation: 0.03288321557650911]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028523300986071157		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.028523300986071157 | validation: 0.04856768843748771]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028456825795988825		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.028456825795988825 | validation: 0.039758659471702484]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026547510845920864		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.026547510845920864 | validation: 0.04643043370269471]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027783251604759817		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.027783251604759817 | validation: 0.04627382714250311]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03289634544056168		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.03289634544056168 | validation: 0.037175403569722765]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031162841390519443		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.031162841390519443 | validation: 0.03750965298553888]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02856057275873456		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.02856057275873456 | validation: 0.04408955054744615]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03227326343475414		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.03227326343475414 | validation: 0.0352844677617861]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029991647055764046		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.029991647055764046 | validation: 0.04010502907991022]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029754944483050626		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.029754944483050626 | validation: 0.05478388847294171]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379533202222988		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.03379533202222988 | validation: 0.04781124131690034]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03153092557744758		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.03153092557744758 | validation: 0.04633640669836345]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02932468631407132		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.02932468631407132 | validation: 0.04209879425336391]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036704570643570834		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.036704570643570834 | validation: 0.028625019525116847]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03155682935087147		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.03155682935087147 | validation: 0.044893402034958604]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03339482437325527		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.03339482437325527 | validation: 0.046168044250788125]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028176309459766378		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.028176309459766378 | validation: 0.04120915724013968]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313727942491509		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.03313727942491509 | validation: 0.03972029065256431]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029210159464098787		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.029210159464098787 | validation: 0.0309506278685524]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027790177083371764		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.027790177083371764 | validation: 0.04022912534919481]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034871195456300755		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.034871195456300755 | validation: 0.041187510233011315]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03265671683147094		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.03265671683147094 | validation: 0.03438601422194551]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030086003149702806		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.030086003149702806 | validation: 0.03225551377880532]
	TIME [epoch: 11.4 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030975733876384998		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.030975733876384998 | validation: 0.04649444105715874]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028001820561156347		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.028001820561156347 | validation: 0.03234575830877262]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02965373833998285		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.02965373833998285 | validation: 0.04203278019105129]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02787097667194489		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.02787097667194489 | validation: 0.03618324823793858]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027972563473235502		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.027972563473235502 | validation: 0.046494021719242086]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026316992037414243		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.026316992037414243 | validation: 0.03822562659366602]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02779859225016986		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.02779859225016986 | validation: 0.03409721165504257]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025788671846178716		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.025788671846178716 | validation: 0.036735959547291544]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029365654005562014		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.029365654005562014 | validation: 0.02950687563465537]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02995506980559235		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.02995506980559235 | validation: 0.02847245550819748]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02803663516020754		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.02803663516020754 | validation: 0.03809861424736793]
	TIME [epoch: 11.4 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022093857613013638		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.022093857613013638 | validation: 0.0359500564754424]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027088399729532024		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.027088399729532024 | validation: 0.030977428316780544]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025120531275904964		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.025120531275904964 | validation: 0.027887784369713838]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028525243510639293		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.028525243510639293 | validation: 0.04396465644878947]
	TIME [epoch: 11.4 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027403883195753903		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.027403883195753903 | validation: 0.03734643117511814]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027767158711882834		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.027767158711882834 | validation: 0.030327503054373983]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025974497511582		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.025974497511582 | validation: 0.04462292813019547]
	TIME [epoch: 11.4 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027151429083411827		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.027151429083411827 | validation: 0.037856801325540784]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030695542615425186		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.030695542615425186 | validation: 0.041043610700804596]
	TIME [epoch: 11.4 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025004553149554735		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.025004553149554735 | validation: 0.03394422049833878]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024898756356111235		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.024898756356111235 | validation: 0.030644409164046055]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028394716302019358		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.028394716302019358 | validation: 0.03317831422201665]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02527958180958261		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.02527958180958261 | validation: 0.0298820079616932]
	TIME [epoch: 11.4 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027013867432193212		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.027013867432193212 | validation: 0.03758793769188649]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029276402219452255		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.029276402219452255 | validation: 0.030723932637256455]
	TIME [epoch: 11.4 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027838485774281385		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.027838485774281385 | validation: 0.028368069605971477]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022404324999580373		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.022404324999580373 | validation: 0.03454301885131638]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025407710522638727		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.025407710522638727 | validation: 0.03488991590738869]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026739604516018665		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.026739604516018665 | validation: 0.028129617146903412]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028982329520033507		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.028982329520033507 | validation: 0.03414187742438494]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026422953728904897		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.026422953728904897 | validation: 0.028313572075669945]
	TIME [epoch: 11.4 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02457535692114312		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.02457535692114312 | validation: 0.02827337037331269]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022896040212506304		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.022896040212506304 | validation: 0.03256210291077891]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029003393434745183		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.029003393434745183 | validation: 0.035212208031683956]
	TIME [epoch: 11.4 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02955604667765973		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.02955604667765973 | validation: 0.038633704042298725]
	TIME [epoch: 11.4 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02518546498763423		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.02518546498763423 | validation: 0.032089884743800694]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023133355705332547		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.023133355705332547 | validation: 0.03245600885578814]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026352682313309526		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.026352682313309526 | validation: 0.03614935332671979]
	TIME [epoch: 11.4 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0253998856117496		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.0253998856117496 | validation: 0.03582573176388498]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028368519182218714		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.028368519182218714 | validation: 0.03313860495109486]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025017075986712354		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.025017075986712354 | validation: 0.03173998183655439]
	TIME [epoch: 11.4 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023464446545075443		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.023464446545075443 | validation: 0.02732202604078721]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026426227647043235		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.026426227647043235 | validation: 0.016886366725050905]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240310_003033/states/model_tr_study4_1585.pth
	Model improved!!!
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025669368556743653		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.025669368556743653 | validation: 0.027022795210246937]
	TIME [epoch: 11.4 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026704710835737982		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.026704710835737982 | validation: 0.038174904384151116]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02478342378590921		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.02478342378590921 | validation: 0.033475968045264065]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024829225397385194		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.024829225397385194 | validation: 0.03233254616840396]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024559788938657554		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.024559788938657554 | validation: 0.03550625588507916]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023018859750603304		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.023018859750603304 | validation: 0.03234285559922415]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027988813781273776		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.027988813781273776 | validation: 0.033902492775438116]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023566301078557672		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.023566301078557672 | validation: 0.029276766195893728]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026181643242897245		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.026181643242897245 | validation: 0.03209277851258097]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024083608312631476		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.024083608312631476 | validation: 0.03521353603197621]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02342541148517087		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.02342541148517087 | validation: 0.030936869276265037]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02431784328055496		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.02431784328055496 | validation: 0.0233312103472979]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023671609250468222		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.023671609250468222 | validation: 0.02727372358104954]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023301279292301386		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.023301279292301386 | validation: 0.022115233766564067]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024131103716243836		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.024131103716243836 | validation: 0.029599097675048584]
	TIME [epoch: 11.4 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025544730865959535		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.025544730865959535 | validation: 0.03009226018157288]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022878443336187493		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.022878443336187493 | validation: 0.03426085736777038]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02395702028519602		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.02395702028519602 | validation: 0.02906888640293391]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025955430531639647		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.025955430531639647 | validation: 0.03574968583294955]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025600677990120734		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.025600677990120734 | validation: 0.03528779320284632]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02383485091865327		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.02383485091865327 | validation: 0.03182681204803304]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026075799510212175		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.026075799510212175 | validation: 0.034787933101742406]
	TIME [epoch: 11.4 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026144841321495662		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.026144841321495662 | validation: 0.03680744733682823]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02752686346759889		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.02752686346759889 | validation: 0.025402255229387518]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02702997344442543		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.02702997344442543 | validation: 0.03476109843986067]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025165668222040943		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.025165668222040943 | validation: 0.032674374410184316]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023245438626538398		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.023245438626538398 | validation: 0.03263106952172577]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02355560370896311		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.02355560370896311 | validation: 0.03007735125613703]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023828502996623965		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.023828502996623965 | validation: 0.028986715254052716]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02736638381315483		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.02736638381315483 | validation: 0.03449025003709675]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025399807542657412		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.025399807542657412 | validation: 0.033004552572901906]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023800945862727373		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.023800945862727373 | validation: 0.03258990398481136]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026824238739347903		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.026824238739347903 | validation: 0.0369761650703883]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027052248057558723		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.027052248057558723 | validation: 0.035280620429104195]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023759321880536328		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.023759321880536328 | validation: 0.03316547357618429]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025136237267297804		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.025136237267297804 | validation: 0.031606050946437876]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0245739282180319		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.0245739282180319 | validation: 0.02942886783619016]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026807279668203773		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.026807279668203773 | validation: 0.02966743736544473]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024548022615560373		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.024548022615560373 | validation: 0.034656276511420954]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025135128136685718		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.025135128136685718 | validation: 0.03491206133704563]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024774069779607024		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.024774069779607024 | validation: 0.0341291368522603]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02721167679720848		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.02721167679720848 | validation: 0.03489705038442844]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026680824700625855		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.026680824700625855 | validation: 0.03714148072873092]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02676552988299179		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.02676552988299179 | validation: 0.03544354947204332]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027034699494637354		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.027034699494637354 | validation: 0.029882865614363104]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02191016597687539		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.02191016597687539 | validation: 0.03208510587815674]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026550475100647668		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.026550475100647668 | validation: 0.032155836320536986]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024979538417126662		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.024979538417126662 | validation: 0.022503530796677815]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02339737308056072		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.02339737308056072 | validation: 0.03870789888538097]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027904380579680917		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.027904380579680917 | validation: 0.032050028063925685]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026629281386828442		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.026629281386828442 | validation: 0.036223446582773454]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020896883661416118		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.020896883661416118 | validation: 0.036773285343805695]
	TIME [epoch: 11.4 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020311454991784904		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.020311454991784904 | validation: 0.031658303789793195]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022610269031945688		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.022610269031945688 | validation: 0.036481145116542775]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02576074714961253		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.02576074714961253 | validation: 0.035766511103631084]
	TIME [epoch: 11.4 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02263413871393824		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.02263413871393824 | validation: 0.03590814726574995]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0240714114376613		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.0240714114376613 | validation: 0.0323318974811734]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023344383653943312		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.023344383653943312 | validation: 0.03278134857688146]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022381279485484906		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.022381279485484906 | validation: 0.02950140886257919]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024411044760541796		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.024411044760541796 | validation: 0.026928905704617145]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022642854482755846		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.022642854482755846 | validation: 0.03201706620227093]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026028927314256853		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.026028927314256853 | validation: 0.03438629067068795]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025542255361115117		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.025542255361115117 | validation: 0.032605643556964534]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022727753124159505		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.022727753124159505 | validation: 0.02542976002593994]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022022106272747262		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.022022106272747262 | validation: 0.030566361872003418]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024294435970464066		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.024294435970464066 | validation: 0.03021044469996543]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021858868374027025		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.021858868374027025 | validation: 0.03222830433250917]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024923315321461616		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.024923315321461616 | validation: 0.029681720807946507]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020662292043263718		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.020662292043263718 | validation: 0.04079157204408471]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023398162377861915		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.023398162377861915 | validation: 0.033863827949585895]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02418658439555449		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.02418658439555449 | validation: 0.028454960578321153]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023406101011301073		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.023406101011301073 | validation: 0.028915860800096064]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023982630075501738		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.023982630075501738 | validation: 0.031563608256807936]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023500031201435557		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.023500031201435557 | validation: 0.02680259904205449]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02547072401674273		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.02547072401674273 | validation: 0.03227846811811337]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02368760067173311		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.02368760067173311 | validation: 0.02695987787155185]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02691620377669427		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.02691620377669427 | validation: 0.0284705519687327]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02408216034819704		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.02408216034819704 | validation: 0.03388349882366931]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027633935831246098		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.027633935831246098 | validation: 0.03680361436491518]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021569362168375492		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.021569362168375492 | validation: 0.03369307323460497]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02417249485111128		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.02417249485111128 | validation: 0.03506080375947171]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025656481323304458		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.025656481323304458 | validation: 0.024967414603840825]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024924079951598423		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.024924079951598423 | validation: 0.03981260419557871]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024217121465119933		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.024217121465119933 | validation: 0.03187301426035377]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024988032836279518		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.024988032836279518 | validation: 0.03921643356323214]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02711153097725688		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.02711153097725688 | validation: 0.03496638601549025]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028820667096269414		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.028820667096269414 | validation: 0.029048492975377118]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026186504383402122		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.026186504383402122 | validation: 0.03444675294597264]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023974050621843043		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.023974050621843043 | validation: 0.04039317135313617]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022173946620901504		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.022173946620901504 | validation: 0.03373105232815787]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022254319792392195		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.022254319792392195 | validation: 0.0345739887870037]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02465911519626517		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.02465911519626517 | validation: 0.026484101695735136]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021236125061159537		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.021236125061159537 | validation: 0.030793781185425435]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0223956531469093		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.0223956531469093 | validation: 0.02875182159025123]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029994101235317802		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.029994101235317802 | validation: 0.028947521407967712]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025731809189683312		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.025731809189683312 | validation: 0.03416956463997211]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024894124787907992		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.024894124787907992 | validation: 0.04170649596120247]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023511000937703662		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.023511000937703662 | validation: 0.033936905828589915]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02366431875550067		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.02366431875550067 | validation: 0.033589588806433604]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027072162266397706		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.027072162266397706 | validation: 0.036790488971708724]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024705052293227316		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.024705052293227316 | validation: 0.037113603106833475]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02201410166903007		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.02201410166903007 | validation: 0.02673480872248485]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02233952869541647		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.02233952869541647 | validation: 0.02847055698849965]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026874322065817424		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.026874322065817424 | validation: 0.037225933168661476]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026287575206777564		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.026287575206777564 | validation: 0.038588373375878525]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019141989182022076		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.019141989182022076 | validation: 0.03252095442219078]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026256451408471014		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.026256451408471014 | validation: 0.024574086052339173]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027810856563798215		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.027810856563798215 | validation: 0.02731360011090514]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021224718384189076		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.021224718384189076 | validation: 0.03368600229442214]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024147792795997852		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.024147792795997852 | validation: 0.02860590696310161]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022993689455468425		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.022993689455468425 | validation: 0.025944814747171127]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022318419866965335		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.022318419866965335 | validation: 0.02486152950021733]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02388590380259165		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.02388590380259165 | validation: 0.0323197541656561]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024192733944884144		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.024192733944884144 | validation: 0.03512654818145613]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025970244949303826		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.025970244949303826 | validation: 0.028344540347374245]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025168570772625652		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.025168570772625652 | validation: 0.02493515166112338]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019549784995792338		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.019549784995792338 | validation: 0.031312481173403614]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024029111520797494		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.024029111520797494 | validation: 0.0253898246094169]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026461651759383868		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.026461651759383868 | validation: 0.03456408895911807]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024958659346528314		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.024958659346528314 | validation: 0.035058236582555795]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02151206600360271		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.02151206600360271 | validation: 0.024887236902186204]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025827063829690675		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.025827063829690675 | validation: 0.03419702659588781]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023615155939083192		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.023615155939083192 | validation: 0.030858168682763948]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024142052056671772		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.024142052056671772 | validation: 0.03607716949370942]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023613271009015196		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.023613271009015196 | validation: 0.030247520317502243]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023872863281321384		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.023872863281321384 | validation: 0.03412574310359905]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024451253231783664		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.024451253231783664 | validation: 0.02004773670903229]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025038888466937116		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.025038888466937116 | validation: 0.038108588607129436]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02433884544498787		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.02433884544498787 | validation: 0.031345668700458254]
	TIME [epoch: 11.4 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021727672012297517		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.021727672012297517 | validation: 0.0228883287710269]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021983799096130706		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.021983799096130706 | validation: 0.031038494368321658]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022390525669509703		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.022390525669509703 | validation: 0.03246349189941196]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022936030477679784		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.022936030477679784 | validation: 0.034154224477405515]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0238489659810548		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.0238489659810548 | validation: 0.03267220693635824]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026667475602729043		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.026667475602729043 | validation: 0.02802953819696149]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02116696806211752		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.02116696806211752 | validation: 0.03238594129637152]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025157534171238574		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.025157534171238574 | validation: 0.02741817606888891]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022124873550687325		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.022124873550687325 | validation: 0.02924572810849568]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02290934323504895		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.02290934323504895 | validation: 0.032923112252822996]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027139436668089524		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.027139436668089524 | validation: 0.03434321792831888]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019975192584342372		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.019975192584342372 | validation: 0.03425809026679305]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022605988677293888		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.022605988677293888 | validation: 0.026247204476394583]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025967885018011012		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.025967885018011012 | validation: 0.03298233693537185]
	TIME [epoch: 11.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02647400362667148		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.02647400362667148 | validation: 0.03091908396857051]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02716333475145159		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.02716333475145159 | validation: 0.02811245897440115]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025174857403321114		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.025174857403321114 | validation: 0.03237658164721012]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02769258225316818		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.02769258225316818 | validation: 0.025249207460503555]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02360616734514719		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.02360616734514719 | validation: 0.03442377917580088]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02635594186933063		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.02635594186933063 | validation: 0.03339801844542834]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024690480436640516		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.024690480436640516 | validation: 0.032213653669051066]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02308381886831156		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.02308381886831156 | validation: 0.0356444760609551]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027989113357372496		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.027989113357372496 | validation: 0.027035535958023077]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0235935368991589		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.0235935368991589 | validation: 0.03151208760224348]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019919445429172112		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.019919445429172112 | validation: 0.03170325931854024]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023617960515814534		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.023617960515814534 | validation: 0.033908783625322424]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02506313511208393		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.02506313511208393 | validation: 0.026573383895682656]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024346209347898162		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.024346209347898162 | validation: 0.030688062202337676]
	TIME [epoch: 11.4 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024014705319071017		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.024014705319071017 | validation: 0.030758474984808954]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02605598402281563		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.02605598402281563 | validation: 0.03002782103098989]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021910228670212736		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.021910228670212736 | validation: 0.028968227546156116]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024242423274425457		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.024242423274425457 | validation: 0.034168397174910575]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01892971501907611		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.01892971501907611 | validation: 0.03479857486750975]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023239664053661208		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.023239664053661208 | validation: 0.038644085989124076]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025515099039324134		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.025515099039324134 | validation: 0.024930316110587693]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022541782508788296		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.022541782508788296 | validation: 0.034020652295882386]
	TIME [epoch: 11.4 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023860267983468554		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.023860267983468554 | validation: 0.02393311201356512]
	TIME [epoch: 11.4 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023995456943884046		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.023995456943884046 | validation: 0.023348270733635792]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021791736300222877		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.021791736300222877 | validation: 0.026632461757937667]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02489623390874085		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.02489623390874085 | validation: 0.022496349192301885]
	TIME [epoch: 11.4 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02321357859231494		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.02321357859231494 | validation: 0.02863777144912045]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025565626530784702		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.025565626530784702 | validation: 0.02585045349718375]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024532939681845573		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.024532939681845573 | validation: 0.024204702794991477]
	TIME [epoch: 11.4 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024417305170851063		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.024417305170851063 | validation: 0.02489359477604599]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02320282153517462		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.02320282153517462 | validation: 0.037007722605713285]
	TIME [epoch: 11.4 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022519998416414787		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.022519998416414787 | validation: 0.03386167488285981]
	TIME [epoch: 11.4 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021082357676489756		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.021082357676489756 | validation: 0.019201257683991738]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02026350854125098		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.02026350854125098 | validation: 0.030757528100355997]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02635214779921166		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.02635214779921166 | validation: 0.03177405320204232]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020320232861432433		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.020320232861432433 | validation: 0.022235597959153953]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02321098243726273		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.02321098243726273 | validation: 0.023662653194542773]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023688931773461742		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.023688931773461742 | validation: 0.035278205995276785]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02844508531454635		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.02844508531454635 | validation: 0.029748613473447944]
	TIME [epoch: 11.5 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01904944109151429		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.01904944109151429 | validation: 0.025896319639152225]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026400462657125756		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.026400462657125756 | validation: 0.03432113735847305]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0213713502064123		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.0213713502064123 | validation: 0.029229039499062973]
	TIME [epoch: 11.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022578155686442582		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.022578155686442582 | validation: 0.03680900210856767]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02375577650907502		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.02375577650907502 | validation: 0.03083741764342244]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017261558337289738		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.017261558337289738 | validation: 0.030569272022159037]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020340756659533075		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.020340756659533075 | validation: 0.03378730649021147]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021050346152731467		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.021050346152731467 | validation: 0.03576915215254203]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02172051831475623		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.02172051831475623 | validation: 0.029282796448792964]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022140332583532134		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.022140332583532134 | validation: 0.027880118400117247]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020691664996200083		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.020691664996200083 | validation: 0.033164993298231665]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023119301346029755		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.023119301346029755 | validation: 0.02656744709307473]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023593407475122972		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.023593407475122972 | validation: 0.03192947959746207]
	TIME [epoch: 11.4 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020956396012257232		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.020956396012257232 | validation: 0.02810310276695928]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02456257061352187		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.02456257061352187 | validation: 0.024812825266396672]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02330820970752688		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.02330820970752688 | validation: 0.026702992493531395]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02186882624582357		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.02186882624582357 | validation: 0.02480452401332541]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021961988113600207		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.021961988113600207 | validation: 0.02603982907368877]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02312111684065739		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.02312111684065739 | validation: 0.03275895247287997]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021973739369440137		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.021973739369440137 | validation: 0.02969795929178503]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022436947556073054		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.022436947556073054 | validation: 0.02676000159637864]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022313376586887257		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.022313376586887257 | validation: 0.03491391601011078]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025297378033030726		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.025297378033030726 | validation: 0.03943638745602693]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025457553933971633		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.025457553933971633 | validation: 0.03865789793151393]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025268992617197793		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.025268992617197793 | validation: 0.02885414921977051]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0223769962769429		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.0223769962769429 | validation: 0.029231326769598703]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024028850046213256		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.024028850046213256 | validation: 0.02905729723294668]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023619399380739474		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.023619399380739474 | validation: 0.03661871688860823]
	TIME [epoch: 11.4 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022667923471731643		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.022667923471731643 | validation: 0.02933772481515704]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020188637077080344		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.020188637077080344 | validation: 0.02539780436277848]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021229046203736175		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.021229046203736175 | validation: 0.03174828597099732]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023707717930120255		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.023707717930120255 | validation: 0.026860058281596617]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024239357319717783		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.024239357319717783 | validation: 0.03388040807914127]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02344137954225333		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.02344137954225333 | validation: 0.03076862479241691]
	TIME [epoch: 11.4 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021745439890135436		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.021745439890135436 | validation: 0.030496334517669074]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02195410919738426		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.02195410919738426 | validation: 0.031078568494744507]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01831796630559225		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.01831796630559225 | validation: 0.028664802252116397]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022108511467806194		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.022108511467806194 | validation: 0.02921847186225825]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023434003790412588		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.023434003790412588 | validation: 0.027485983453660615]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024463162512072967		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.024463162512072967 | validation: 0.038452935799547755]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024091820123687588		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.024091820123687588 | validation: 0.03239389665456654]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018796919153809818		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.018796919153809818 | validation: 0.024865826925083653]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024402778218599444		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.024402778218599444 | validation: 0.02840915447310309]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02191981780018288		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.02191981780018288 | validation: 0.033898485628225096]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023894670580581347		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.023894670580581347 | validation: 0.025706211176549178]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023291899778913768		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.023291899778913768 | validation: 0.03000103710780727]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01983123664081278		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.01983123664081278 | validation: 0.0364895663791784]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01986618905486153		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.01986618905486153 | validation: 0.03488106948777903]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025156381454851016		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.025156381454851016 | validation: 0.037482823848789364]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016851738178919343		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.016851738178919343 | validation: 0.030157336392309376]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02371948448373165		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.02371948448373165 | validation: 0.031351371564131425]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021379399643080096		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.021379399643080096 | validation: 0.03369701108196968]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02430539511473972		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.02430539511473972 | validation: 0.037892479558273795]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024025680151341784		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.024025680151341784 | validation: 0.028662011071637572]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026318234326940082		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.026318234326940082 | validation: 0.03778241479777564]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022300970568890993		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.022300970568890993 | validation: 0.03646171668039065]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020056132365015095		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.020056132365015095 | validation: 0.036450579712202384]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02247179296581687		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.02247179296581687 | validation: 0.022958461355737345]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020807743400810534		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.020807743400810534 | validation: 0.02004259515439349]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021477673271055864		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.021477673271055864 | validation: 0.02797574684430007]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025703528326462423		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.025703528326462423 | validation: 0.033950650747960213]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024392172841565696		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.024392172841565696 | validation: 0.03809473397545158]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0283178269689488		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.0283178269689488 | validation: 0.03344300015272538]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02118201557756287		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.02118201557756287 | validation: 0.032384102974119186]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02823380321652306		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.02823380321652306 | validation: 0.03223169874494496]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024550331018947033		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.024550331018947033 | validation: 0.02719019289617709]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020991621254239454		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.020991621254239454 | validation: 0.026062228263546986]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025135845442462244		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.025135845442462244 | validation: 0.030483593553991658]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02324791997203928		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.02324791997203928 | validation: 0.03487090501437416]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020749306976323108		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.020749306976323108 | validation: 0.02679878684993083]
	TIME [epoch: 11.4 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02392055357985723		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.02392055357985723 | validation: 0.03005697172872733]
	TIME [epoch: 11.4 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02483388485832893		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.02483388485832893 | validation: 0.03127281406853743]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02450437393211193		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.02450437393211193 | validation: 0.032657773346727044]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026200494906527164		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.026200494906527164 | validation: 0.031765626203710554]
	TIME [epoch: 11.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024991970771967433		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.024991970771967433 | validation: 0.03452339692919354]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026013526034117385		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.026013526034117385 | validation: 0.028629378444990587]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02276015314980246		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.02276015314980246 | validation: 0.02682765161251353]
	TIME [epoch: 11.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022876814258798603		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.022876814258798603 | validation: 0.03402086572224963]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022194154705941552		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.022194154705941552 | validation: 0.02615880331665063]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021335728449727413		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.021335728449727413 | validation: 0.03111526233318508]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024930156134128474		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.024930156134128474 | validation: 0.037015152761480104]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021552824563254892		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.021552824563254892 | validation: 0.03567782269345591]
	TIME [epoch: 11.4 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021222060630148035		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.021222060630148035 | validation: 0.02941267791035367]
	TIME [epoch: 11.4 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023792675117946145		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.023792675117946145 | validation: 0.022593082932872717]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022430535612599493		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.022430535612599493 | validation: 0.027830855499490235]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020955915500462954		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.020955915500462954 | validation: 0.03561418689995303]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025064515523721062		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.025064515523721062 | validation: 0.024986672666521798]
	TIME [epoch: 11.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02668414030990542		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.02668414030990542 | validation: 0.03289984737128335]
	TIME [epoch: 11.4 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025848488070854915		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.025848488070854915 | validation: 0.030327666992601605]
	TIME [epoch: 11.4 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025440079226386084		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.025440079226386084 | validation: 0.03128956433118945]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020590294702388476		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.020590294702388476 | validation: 0.03535719995032404]
	TIME [epoch: 11.4 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021657808456506864		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.021657808456506864 | validation: 0.029708298189413753]
	TIME [epoch: 11.4 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021406444823412092		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.021406444823412092 | validation: 0.029554721822107645]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021494584626772555		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.021494584626772555 | validation: 0.025657294515031168]
	TIME [epoch: 11.4 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01882024097694342		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.01882024097694342 | validation: 0.03133438855084684]
	TIME [epoch: 11.4 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022662998245918685		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.022662998245918685 | validation: 0.02905362847749014]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0231902824413837		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.0231902824413837 | validation: 0.029114077537842366]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02250280565588432		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.02250280565588432 | validation: 0.0290604028428425]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024558813983210928		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.024558813983210928 | validation: 0.03519629819106513]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02448667646177914		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.02448667646177914 | validation: 0.0365487017948643]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02014438254637044		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.02014438254637044 | validation: 0.032710776291439016]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021074050463557013		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.021074050463557013 | validation: 0.03188688751096845]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024883893979766966		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.024883893979766966 | validation: 0.0317262713435276]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022892877450300487		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.022892877450300487 | validation: 0.028507208308181264]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02043673016902396		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.02043673016902396 | validation: 0.033645328175594943]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02645124733754991		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.02645124733754991 | validation: 0.025613878462066513]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023282618215487008		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.023282618215487008 | validation: 0.02325895949735574]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02477374553191569		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.02477374553191569 | validation: 0.021087339031413712]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020786432651579617		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.020786432651579617 | validation: 0.027279355704676524]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019783432061191566		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.019783432061191566 | validation: 0.029883658748936354]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02305909370863401		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.02305909370863401 | validation: 0.029971524030225974]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022489552140694473		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.022489552140694473 | validation: 0.030304387849121293]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024251868723662088		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.024251868723662088 | validation: 0.0185493233434984]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021358861250677548		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.021358861250677548 | validation: 0.028479954668951528]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02376938384310604		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.02376938384310604 | validation: 0.029948665449993712]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020431024959724164		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.020431024959724164 | validation: 0.03202520282663461]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024691456885514843		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.024691456885514843 | validation: 0.024234021861645933]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02512621259624156		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.02512621259624156 | validation: 0.022608376948812473]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024147128429927747		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.024147128429927747 | validation: 0.03143414800244133]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023670046097926126		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.023670046097926126 | validation: 0.02859201187508393]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02413349521987156		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.02413349521987156 | validation: 0.030826776807831413]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024285401880409098		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.024285401880409098 | validation: 0.025239302596896933]
	TIME [epoch: 11.5 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023959592058014265		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.023959592058014265 | validation: 0.03034727623819645]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02420729478113253		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.02420729478113253 | validation: 0.02756600856149606]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024335840784393395		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.024335840784393395 | validation: 0.027799587530456027]
	TIME [epoch: 11.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01884748972548675		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.01884748972548675 | validation: 0.028078339126744893]
	TIME [epoch: 11.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024690037703470575		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.024690037703470575 | validation: 0.026838842218257827]
	TIME [epoch: 11.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02107066249405665		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.02107066249405665 | validation: 0.02689014451803357]
	TIME [epoch: 11.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020819127519227987		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.020819127519227987 | validation: 0.032855078447479855]
	TIME [epoch: 11.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02162726318588399		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.02162726318588399 | validation: 0.02530035416735175]
	TIME [epoch: 11.5 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019771116744051423		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.019771116744051423 | validation: 0.0323730811292213]
	TIME [epoch: 11.5 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023454119956664934		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.023454119956664934 | validation: 0.03149391283044347]
	TIME [epoch: 11.5 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0209156808993615		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.0209156808993615 | validation: 0.029452930388230575]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023411281172621153		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.023411281172621153 | validation: 0.03191919481321696]
	TIME [epoch: 11.5 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023707804015058925		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.023707804015058925 | validation: 0.03295945624962262]
	TIME [epoch: 11.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024323159459953198		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.024323159459953198 | validation: 0.03309384970779969]
	TIME [epoch: 11.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022642832604707567		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.022642832604707567 | validation: 0.03378999836358979]
	TIME [epoch: 11.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020683619097337104		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.020683619097337104 | validation: 0.033030565997335073]
	TIME [epoch: 11.5 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022489404189245606		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.022489404189245606 | validation: 0.024739793651103785]
	TIME [epoch: 11.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022204909805130894		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.022204909805130894 | validation: 0.03483605305392845]
	TIME [epoch: 11.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023265961047707333		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.023265961047707333 | validation: 0.030310425887413398]
	TIME [epoch: 11.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023046939470874404		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.023046939470874404 | validation: 0.029753890597070783]
	TIME [epoch: 11.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020802452257653602		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.020802452257653602 | validation: 0.025631632623147636]
	TIME [epoch: 11.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023016613656804942		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.023016613656804942 | validation: 0.027243481699405738]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022877552064059514		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.022877552064059514 | validation: 0.03122453567624763]
	TIME [epoch: 11.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01911523556858559		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.01911523556858559 | validation: 0.03182527669828996]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024306506391270088		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.024306506391270088 | validation: 0.03049281089436107]
	TIME [epoch: 11.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020189002040000528		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.020189002040000528 | validation: 0.03486042603831602]
	TIME [epoch: 11.4 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02024491674552599		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.02024491674552599 | validation: 0.03307606816055324]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02445080055267363		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.02445080055267363 | validation: 0.02927993866541633]
	TIME [epoch: 11.5 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023710664667484085		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.023710664667484085 | validation: 0.036984723532966716]
	TIME [epoch: 11.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0255183861471825		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.0255183861471825 | validation: 0.028222077124219105]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020132226430528075		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.020132226430528075 | validation: 0.03235022397886497]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02326211047768965		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.02326211047768965 | validation: 0.026717607835241113]
	TIME [epoch: 11.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024222885069500433		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.024222885069500433 | validation: 0.0294608552816713]
	TIME [epoch: 11.5 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022532942762206055		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.022532942762206055 | validation: 0.03243146817814659]
	TIME [epoch: 11.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02371425774309645		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.02371425774309645 | validation: 0.026043860928846585]
	TIME [epoch: 11.5 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02063876620738798		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.02063876620738798 | validation: 0.024190328697077667]
	TIME [epoch: 11.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02493731745147096		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.02493731745147096 | validation: 0.02554466074326237]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021523052872635208		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.021523052872635208 | validation: 0.02812900240978741]
	TIME [epoch: 11.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023579351675842516		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.023579351675842516 | validation: 0.028929975201714215]
	TIME [epoch: 11.5 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026544049739292037		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.026544049739292037 | validation: 0.029791147850210233]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021415470463139852		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.021415470463139852 | validation: 0.02608225341423334]
	TIME [epoch: 11.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020852707603231952		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.020852707603231952 | validation: 0.028468491410509146]
	TIME [epoch: 11.7 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020351391031181408		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.020351391031181408 | validation: 0.025499627179454643]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02393570669554243		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.02393570669554243 | validation: 0.03206465601603119]
	TIME [epoch: 11.5 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021257254706081263		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.021257254706081263 | validation: 0.027237525732822496]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022589440404021957		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.022589440404021957 | validation: 0.01980259486722495]
	TIME [epoch: 11.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023789510238264977		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.023789510238264977 | validation: 0.030700369311709816]
	TIME [epoch: 11.5 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019538924885777926		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.019538924885777926 | validation: 0.030639939396970916]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02093141544347848		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.02093141544347848 | validation: 0.036970478690311635]
	TIME [epoch: 11.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02066992569070559		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.02066992569070559 | validation: 0.03259665751320136]
	TIME [epoch: 11.5 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02537362667686807		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.02537362667686807 | validation: 0.031565999913304825]
	TIME [epoch: 11.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020447868515522865		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.020447868515522865 | validation: 0.029936562564321367]
	TIME [epoch: 11.5 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02182898481296043		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.02182898481296043 | validation: 0.03756742920523755]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02307146925799276		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.02307146925799276 | validation: 0.03127428615564391]
	TIME [epoch: 11.5 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021593693845317702		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.021593693845317702 | validation: 0.025928453015093788]
	TIME [epoch: 11.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02287470783201602		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.02287470783201602 | validation: 0.03187280788252204]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018584973923080835		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.018584973923080835 | validation: 0.029711046163697505]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020440349130434955		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.020440349130434955 | validation: 0.03593520795551213]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025027060617604274		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.025027060617604274 | validation: 0.03513357824644937]
	TIME [epoch: 11.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021858758863740883		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.021858758863740883 | validation: 0.033606519283734516]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021983865937599253		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.021983865937599253 | validation: 0.02908839160127363]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023911190327277267		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.023911190327277267 | validation: 0.03828212596114725]
	TIME [epoch: 11.5 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022107418209764428		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.022107418209764428 | validation: 0.03550072984596027]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02236986491512728		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.02236986491512728 | validation: 0.03273222675208996]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02213999981389462		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.02213999981389462 | validation: 0.03257713170071204]
	TIME [epoch: 11.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02454140488193128		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.02454140488193128 | validation: 0.024551334791024695]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021865360209731007		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.021865360209731007 | validation: 0.029717802756493043]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021298034575260687		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.021298034575260687 | validation: 0.031208052474995977]
	TIME [epoch: 11.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021041230673690882		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.021041230673690882 | validation: 0.02951997115446691]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021306762873154073		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.021306762873154073 | validation: 0.03082246505422595]
	TIME [epoch: 11.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02364361187797663		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.02364361187797663 | validation: 0.032941794308662294]
	TIME [epoch: 11.5 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024680515608056397		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.024680515608056397 | validation: 0.02454353236089534]
	TIME [epoch: 11.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021045363285366162		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.021045363285366162 | validation: 0.02560526333619127]
	TIME [epoch: 11.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021456860512765137		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.021456860512765137 | validation: 0.025078095758263478]
	TIME [epoch: 11.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021867935156077403		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.021867935156077403 | validation: 0.02445500252670959]
	TIME [epoch: 11.5 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02619475666845795		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.02619475666845795 | validation: 0.02446325188298686]
	TIME [epoch: 11.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024325486685692316		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.024325486685692316 | validation: 0.032676927636940876]
	TIME [epoch: 11.5 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021229619660561083		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.021229619660561083 | validation: 0.020520459362923273]
	TIME [epoch: 11.5 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023173640178055455		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.023173640178055455 | validation: 0.035271568898990004]
	TIME [epoch: 11.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023045122137998898		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.023045122137998898 | validation: 0.03544873312183939]
	TIME [epoch: 11.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019785976306886475		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.019785976306886475 | validation: 0.0370932178073664]
	TIME [epoch: 11.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02485016193458648		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.02485016193458648 | validation: 0.02709028417596961]
	TIME [epoch: 11.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022590290835879594		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.022590290835879594 | validation: 0.031378800126708135]
	TIME [epoch: 11.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025203592182406215		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.025203592182406215 | validation: 0.030505066350530543]
	TIME [epoch: 11.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02416094350968254		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.02416094350968254 | validation: 0.03595658044115708]
	TIME [epoch: 11.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022864646993998414		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.022864646993998414 | validation: 0.030214909171059838]
	TIME [epoch: 11.5 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021539122043498872		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.021539122043498872 | validation: 0.03729143413596932]
	TIME [epoch: 11.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024300719752152884		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.024300719752152884 | validation: 0.03319381297160972]
	TIME [epoch: 11.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021784671440502234		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.021784671440502234 | validation: 0.03523082653794328]
	TIME [epoch: 11.5 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02407313416898381		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.02407313416898381 | validation: 0.03199970352784815]
	TIME [epoch: 11.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021274517300120352		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.021274517300120352 | validation: 0.026081556368796]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02089491701462158		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.02089491701462158 | validation: 0.02810182777446351]
	TIME [epoch: 11.5 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020063825630279915		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.020063825630279915 | validation: 0.03764786129295955]
	TIME [epoch: 11.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022085939501045784		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.022085939501045784 | validation: 0.033828394913924455]
	TIME [epoch: 11.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020942521711128086		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.020942521711128086 | validation: 0.030650286892591784]
	TIME [epoch: 11.5 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023779706565505595		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.023779706565505595 | validation: 0.02753180267463571]
	TIME [epoch: 11.5 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01990962958024514		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.01990962958024514 | validation: 0.027713753382982424]
	TIME [epoch: 11.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022410326372070015		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.022410326372070015 | validation: 0.03001051721384966]
	TIME [epoch: 11.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021200452278561096		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.021200452278561096 | validation: 0.027192506565285435]
	TIME [epoch: 11.5 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020368122175999464		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.020368122175999464 | validation: 0.0316367218373368]
	TIME [epoch: 11.5 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02283335411569678		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.02283335411569678 | validation: 0.033955147523728496]
	TIME [epoch: 11.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024589917224824006		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.024589917224824006 | validation: 0.025951571249454488]
	TIME [epoch: 11.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018389758227832058		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.018389758227832058 | validation: 0.025638433642033505]
	TIME [epoch: 11.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020370079416838115		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.020370079416838115 | validation: 0.020666797220496688]
	TIME [epoch: 11.5 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022369894963756198		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.022369894963756198 | validation: 0.026925617791657135]
	TIME [epoch: 11.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02076243502069564		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.02076243502069564 | validation: 0.03471898284744757]
	TIME [epoch: 11.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019267815838362796		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.019267815838362796 | validation: 0.02960364319110414]
	TIME [epoch: 11.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02560895713690125		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.02560895713690125 | validation: 0.025102668500726996]
	TIME [epoch: 11.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023076791558551885		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.023076791558551885 | validation: 0.03032546235311232]
	TIME [epoch: 11.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018839358222916113		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.018839358222916113 | validation: 0.033868548701210595]
	TIME [epoch: 11.5 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022404675943154255		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.022404675943154255 | validation: 0.026768239653969114]
	TIME [epoch: 11.5 sec]
Finished training in 23178.507 seconds.
