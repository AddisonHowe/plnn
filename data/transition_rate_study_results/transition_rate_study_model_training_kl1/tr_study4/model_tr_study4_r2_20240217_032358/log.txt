Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r2', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=500, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2406811225

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.339945591150052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.339945591150052 | validation: 7.93858015399424]
	TIME [epoch: 48.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.066873177224002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.066873177224002 | validation: 6.570079326690207]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.249113136202638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.249113136202638 | validation: 5.499895128055264]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.6643060212158876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6643060212158876 | validation: 5.320575913160734]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.286127710283417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.286127710283417 | validation: 4.157444494760628]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.348687999199957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.348687999199957 | validation: 3.598261861489348]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.097383938268864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.097383938268864 | validation: 3.6296904995585706]
	TIME [epoch: 9.09 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5258242594521847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5258242594521847 | validation: 3.2276206535001806]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7591880708785546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7591880708785546 | validation: 3.8140163859732485]
	TIME [epoch: 9.07 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.744687489160848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.744687489160848 | validation: 3.150667686066531]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1337782159826477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1337782159826477 | validation: 3.093275243648371]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.029506942599562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.029506942599562 | validation: 2.814773101864145]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0560141618974113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0560141618974113 | validation: 2.9066935504409717]
	TIME [epoch: 9.07 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.890719056944806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.890719056944806 | validation: 2.893497933368931]
	TIME [epoch: 9.07 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8966615481349454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8966615481349454 | validation: 3.0700393672002257]
	TIME [epoch: 9.07 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.865315200673235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.865315200673235 | validation: 2.9751651984810987]
	TIME [epoch: 9.1 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7652744205857305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7652744205857305 | validation: 2.3676514155250707]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5779945011761756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5779945011761756 | validation: 2.420526769141862]
	TIME [epoch: 9.07 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3471146746562797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3471146746562797 | validation: 2.930948301862526]
	TIME [epoch: 9.07 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3346633406154385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3346633406154385 | validation: 1.9190187947270292]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9395200789284908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9395200789284908 | validation: 1.5803988894702612]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7051623325976901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7051623325976901 | validation: 1.6345074883221429]
	TIME [epoch: 9.07 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.636007699037488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.636007699037488 | validation: 1.1724124607267483]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.389893549559146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.389893549559146 | validation: 1.3375466581773532]
	TIME [epoch: 9.07 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5059215438123825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5059215438123825 | validation: 1.3226478649867364]
	TIME [epoch: 9.09 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1166231472044033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1166231472044033 | validation: 0.9582779456134891]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.005639764300701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.005639764300701 | validation: 1.3641993007977062]
	TIME [epoch: 9.07 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8770291663476758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8770291663476758 | validation: 2.420874909963261]
	TIME [epoch: 9.06 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1509981473154376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1509981473154376 | validation: 0.7342468353881026]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9079881187586528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9079881187586528 | validation: 1.0303845475983615]
	TIME [epoch: 9.06 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2220520017265009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2220520017265009 | validation: 0.8306387491292567]
	TIME [epoch: 9.06 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8884891831669606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8884891831669606 | validation: 1.4625029108150973]
	TIME [epoch: 9.06 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.270051665535761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.270051665535761 | validation: 0.5960648005474014]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2408732337975812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2408732337975812 | validation: 0.7793120375610089]
	TIME [epoch: 9.07 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9646864071059944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9646864071059944 | validation: 0.764559436582662]
	TIME [epoch: 9.06 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9430599554325972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9430599554325972 | validation: 0.5935230984147126]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0035865822140313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0035865822140313 | validation: 0.6193418467022791]
	TIME [epoch: 9.09 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9896907376961271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9896907376961271 | validation: 0.9333618207670895]
	TIME [epoch: 9.07 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0236161220726245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0236161220726245 | validation: 1.5623089639168923]
	TIME [epoch: 9.06 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1243283591397808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1243283591397808 | validation: 0.6748820372194938]
	TIME [epoch: 9.06 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6727506616511868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6727506616511868 | validation: 1.452932445913842]
	TIME [epoch: 9.08 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.818178285021063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.818178285021063 | validation: 0.568416146343832]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6861107612764545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6861107612764545 | validation: 0.7136179692056188]
	TIME [epoch: 9.07 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7722255948051838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7722255948051838 | validation: 0.6563986260306675]
	TIME [epoch: 9.07 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8335282278279535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8335282278279535 | validation: 0.5384950833822335]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.718475550364907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.718475550364907 | validation: 0.5233821199701205]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8449625205121807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8449625205121807 | validation: 0.4907101638447253]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6505174172430132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6505174172430132 | validation: 0.5304305276597456]
	TIME [epoch: 9.06 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6586719788967629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6586719788967629 | validation: 1.0232934293346727]
	TIME [epoch: 9.08 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6930474890633609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6930474890633609 | validation: 0.6064175823633906]
	TIME [epoch: 9.08 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.71436611012943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.71436611012943 | validation: 0.4434454333949367]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.708289121006522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.708289121006522 | validation: 0.5915670275481454]
	TIME [epoch: 9.07 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5902899247230013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5902899247230013 | validation: 0.4769043780694985]
	TIME [epoch: 9.07 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5889736144808915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5889736144808915 | validation: 0.5770350656758949]
	TIME [epoch: 9.08 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8150109294065704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8150109294065704 | validation: 0.6669803971030073]
	TIME [epoch: 9.06 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5918290712559792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5918290712559792 | validation: 0.7483043595417798]
	TIME [epoch: 9.06 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8251085975820109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8251085975820109 | validation: 0.7261507264467609]
	TIME [epoch: 9.06 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8478259076115936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8478259076115936 | validation: 2.954615019184277]
	TIME [epoch: 9.08 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7442024063997046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7442024063997046 | validation: 0.6023275282939313]
	TIME [epoch: 9.07 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7628526239793467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7628526239793467 | validation: 0.529457438249098]
	TIME [epoch: 9.06 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6215948445261112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6215948445261112 | validation: 0.549631438756589]
	TIME [epoch: 9.07 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6645369344481005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6645369344481005 | validation: 0.5975993875801109]
	TIME [epoch: 9.08 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5445395987340217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5445395987340217 | validation: 0.5364144500181403]
	TIME [epoch: 9.07 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6229432083669014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6229432083669014 | validation: 0.5510239299080525]
	TIME [epoch: 9.06 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5504725958118144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5504725958118144 | validation: 0.5665694189541643]
	TIME [epoch: 9.07 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6798674560478724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6798674560478724 | validation: 0.8970978615297128]
	TIME [epoch: 9.09 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6490282197249646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6490282197249646 | validation: 0.44372996604880766]
	TIME [epoch: 9.07 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5258201509878658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5258201509878658 | validation: 1.1886794744207312]
	TIME [epoch: 9.06 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8252331903079249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8252331903079249 | validation: 0.6429111939923913]
	TIME [epoch: 9.06 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5532087441759219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5532087441759219 | validation: 0.4867667174897179]
	TIME [epoch: 9.08 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5108935898353706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5108935898353706 | validation: 0.4607158801517092]
	TIME [epoch: 9.08 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5002958995835101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5002958995835101 | validation: 0.4655529954615738]
	TIME [epoch: 9.07 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5711486810855476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5711486810855476 | validation: 0.45585506292060207]
	TIME [epoch: 9.07 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.946635503739493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.946635503739493 | validation: 0.38899225669165194]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44235127822191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44235127822191 | validation: 0.4472393071053614]
	TIME [epoch: 9.08 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5153988309244588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5153988309244588 | validation: 0.5920076385425206]
	TIME [epoch: 9.06 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5116804496903523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5116804496903523 | validation: 0.3689835812787021]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47665690843505387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47665690843505387 | validation: 0.4451541504733994]
	TIME [epoch: 9.07 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6369501979403582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6369501979403582 | validation: 0.887641879827873]
	TIME [epoch: 9.08 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6376347865258911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6376347865258911 | validation: 2.7525119052242646]
	TIME [epoch: 9.06 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.706160930723739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.706160930723739 | validation: 2.8614450028044156]
	TIME [epoch: 9.06 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.658908093074828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.658908093074828 | validation: 3.0085189279190683]
	TIME [epoch: 9.05 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.02419712659732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.02419712659732 | validation: 4.000139728436513]
	TIME [epoch: 9.08 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.690628852592661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.690628852592661 | validation: 3.0226538103573364]
	TIME [epoch: 9.05 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6132732297107415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6132732297107415 | validation: 3.447543666415349]
	TIME [epoch: 9.05 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.654920625836329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.654920625836329 | validation: 2.9786281616645134]
	TIME [epoch: 9.06 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.432527631367333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.432527631367333 | validation: 2.8609777436314996]
	TIME [epoch: 9.07 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.454476922185993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.454476922185993 | validation: 3.060703089749073]
	TIME [epoch: 9.06 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4220387449190732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4220387449190732 | validation: 2.997550504125581]
	TIME [epoch: 9.06 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8667242508950173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8667242508950173 | validation: 2.885607585168697]
	TIME [epoch: 9.06 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4067015163113625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4067015163113625 | validation: 2.997208552796438]
	TIME [epoch: 9.08 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3742515942456386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3742515942456386 | validation: 2.799907254646107]
	TIME [epoch: 9.06 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.91384366608952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.91384366608952 | validation: 0.9064693678970225]
	TIME [epoch: 9.06 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7736397349985136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7736397349985136 | validation: 0.3465121822963825]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5147912256282879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5147912256282879 | validation: 1.046540222342127]
	TIME [epoch: 9.07 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5641520485622914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5641520485622914 | validation: 0.38641327254281127]
	TIME [epoch: 9.09 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42068536969516596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42068536969516596 | validation: 0.4886710758347018]
	TIME [epoch: 9.07 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5371788767760179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5371788767760179 | validation: 0.39431808584688166]
	TIME [epoch: 9.07 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8377375274811072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8377375274811072 | validation: 0.5268324797136923]
	TIME [epoch: 9.07 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4876957097258644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4876957097258644 | validation: 0.6405520249147465]
	TIME [epoch: 9.08 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6735372855749193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6735372855749193 | validation: 0.30397077755601887]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4470829230177193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4470829230177193 | validation: 0.36860390149399536]
	TIME [epoch: 9.06 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.479198867807324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.479198867807324 | validation: 0.682242473824529]
	TIME [epoch: 9.07 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5401730662021682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5401730662021682 | validation: 0.3984029445509261]
	TIME [epoch: 9.07 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4107690843533655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4107690843533655 | validation: 0.308657653282145]
	TIME [epoch: 9.05 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3896172154145153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3896172154145153 | validation: 0.30524002555149876]
	TIME [epoch: 9.06 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45494966194752673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45494966194752673 | validation: 0.5177850519390803]
	TIME [epoch: 9.06 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9525815479299509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9525815479299509 | validation: 0.6735251260199234]
	TIME [epoch: 9.08 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5268811321792333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5268811321792333 | validation: 0.28073095023685884]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4963798624862313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4963798624862313 | validation: 0.335658910609818]
	TIME [epoch: 9.06 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49245460691198967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49245460691198967 | validation: 0.2762833010781808]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38845110982852504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38845110982852504 | validation: 0.2578063819714995]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42779273108217397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42779273108217397 | validation: 0.3656277442867908]
	TIME [epoch: 9.07 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3554050286141426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3554050286141426 | validation: 0.5179007543834303]
	TIME [epoch: 9.05 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3452683178644636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3452683178644636 | validation: 0.23213571993360213]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3785371474310949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3785371474310949 | validation: 0.35055759308714274]
	TIME [epoch: 9.06 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34955448637958236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34955448637958236 | validation: 0.9869232782004882]
	TIME [epoch: 9.08 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49128814561447065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49128814561447065 | validation: 0.4212636208686886]
	TIME [epoch: 9.05 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33765135906576227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33765135906576227 | validation: 0.35806056804878883]
	TIME [epoch: 9.06 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39950611605794917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39950611605794917 | validation: 0.2151741148206457]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.598782422477815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.598782422477815 | validation: 0.26908045889283483]
	TIME [epoch: 9.08 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30045452611908174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30045452611908174 | validation: 0.25801297166050424]
	TIME [epoch: 9.09 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3722271221543889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3722271221543889 | validation: 0.3692306578416951]
	TIME [epoch: 9.07 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3785702853347591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3785702853347591 | validation: 0.3539473599637918]
	TIME [epoch: 9.07 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9481204324177293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9481204324177293 | validation: 3.7851153873213934]
	TIME [epoch: 9.07 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.438718120106794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.438718120106794 | validation: 3.7337382992962875]
	TIME [epoch: 9.09 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1838409559470593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1838409559470593 | validation: 3.6546703436031507]
	TIME [epoch: 9.08 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.948900537640344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.948900537640344 | validation: 2.9299027290696174]
	TIME [epoch: 9.07 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7296338933352036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7296338933352036 | validation: 0.636215438923288]
	TIME [epoch: 9.07 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5656144545819923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5656144545819923 | validation: 0.3032002736458941]
	TIME [epoch: 9.09 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5835385871339944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5835385871339944 | validation: 0.3734525961750833]
	TIME [epoch: 9.08 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45440909205084334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45440909205084334 | validation: 0.2657324045912256]
	TIME [epoch: 9.07 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3022021927485683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3022021927485683 | validation: 0.34023212035196704]
	TIME [epoch: 9.07 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4532000836166534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4532000836166534 | validation: 0.3862924196492522]
	TIME [epoch: 9.08 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34217405973869436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34217405973869436 | validation: 0.218410196410181]
	TIME [epoch: 9.08 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31584034211402673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31584034211402673 | validation: 0.2362087745372709]
	TIME [epoch: 9.07 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27316426793424436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27316426793424436 | validation: 0.25529049294986766]
	TIME [epoch: 9.07 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3234185229009083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3234185229009083 | validation: 1.3010375684788928]
	TIME [epoch: 9.08 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42120950702984655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42120950702984655 | validation: 0.2594977484614109]
	TIME [epoch: 9.09 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41651778451403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41651778451403 | validation: 0.2971490081608029]
	TIME [epoch: 9.07 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40897542834444806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40897542834444806 | validation: 0.2051324229336573]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6609892041790787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6609892041790787 | validation: 0.4742452177436577]
	TIME [epoch: 9.08 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4121520918947711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4121520918947711 | validation: 1.8256519089941925]
	TIME [epoch: 9.09 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9124336909659304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9124336909659304 | validation: 0.35070089781451996]
	TIME [epoch: 9.07 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3176393087998973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3176393087998973 | validation: 0.22514145221000792]
	TIME [epoch: 9.07 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2970293307833768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2970293307833768 | validation: 0.2995516197583559]
	TIME [epoch: 9.07 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30939208874180724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30939208874180724 | validation: 0.28209806250570224]
	TIME [epoch: 9.08 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33834059799386873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33834059799386873 | validation: 1.037616388877865]
	TIME [epoch: 9.08 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49729394861163545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49729394861163545 | validation: 0.6142233038282788]
	TIME [epoch: 9.07 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9370935621465739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9370935621465739 | validation: 0.6008744816885458]
	TIME [epoch: 9.07 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8283139468196368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8283139468196368 | validation: 0.2269778066643331]
	TIME [epoch: 9.08 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8625940743943783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8625940743943783 | validation: 0.4244115467946419]
	TIME [epoch: 9.08 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5285470726583407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5285470726583407 | validation: 0.3802581892699588]
	TIME [epoch: 9.07 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3434370901210105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3434370901210105 | validation: 0.2982961348157154]
	TIME [epoch: 9.07 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25949616050586566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25949616050586566 | validation: 0.19552522173530615]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.308866255047596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.308866255047596 | validation: 0.1229260495576559]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43931068461868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43931068461868 | validation: 0.24505686541891714]
	TIME [epoch: 9.07 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28174424011273963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28174424011273963 | validation: 0.22031851668656843]
	TIME [epoch: 9.06 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23611707952321104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23611707952321104 | validation: 0.24859141050794326]
	TIME [epoch: 9.06 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3242273538026389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3242273538026389 | validation: 0.16994365662451755]
	TIME [epoch: 9.09 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25872347587052713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25872347587052713 | validation: 0.276326927548993]
	TIME [epoch: 9.07 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27768432933766346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27768432933766346 | validation: 0.36156549406017774]
	TIME [epoch: 9.06 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34890250681824186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34890250681824186 | validation: 0.25945803103114146]
	TIME [epoch: 9.06 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3089212686858887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3089212686858887 | validation: 0.32154522263574536]
	TIME [epoch: 9.06 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3589147548855472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3589147548855472 | validation: 0.5026462087733851]
	TIME [epoch: 9.09 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3960175870951409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3960175870951409 | validation: 0.3157018555423763]
	TIME [epoch: 9.06 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7095115184730629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7095115184730629 | validation: 0.7741148163199414]
	TIME [epoch: 9.07 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4788217166231664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4788217166231664 | validation: 0.3749673726547613]
	TIME [epoch: 9.06 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4397148768167747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4397148768167747 | validation: 0.1819315345170126]
	TIME [epoch: 9.08 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2710809274388249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2710809274388249 | validation: 0.22905527427418546]
	TIME [epoch: 9.06 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3895111308248607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3895111308248607 | validation: 0.30301479502759077]
	TIME [epoch: 9.06 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0804703011012073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0804703011012073 | validation: 0.5622812557214417]
	TIME [epoch: 9.07 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6014035456936118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6014035456936118 | validation: 0.5233834575103982]
	TIME [epoch: 9.08 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40963812466714317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40963812466714317 | validation: 0.1993091402938637]
	TIME [epoch: 9.07 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2240385643530304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2240385643530304 | validation: 0.6358429945806781]
	TIME [epoch: 9.06 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36093613963629356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36093613963629356 | validation: 0.2108079102808246]
	TIME [epoch: 9.06 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3443158806474404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3443158806474404 | validation: 0.37506568946202784]
	TIME [epoch: 9.07 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6291820021614584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6291820021614584 | validation: 0.22251792034467982]
	TIME [epoch: 9.07 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2650200941745269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2650200941745269 | validation: 0.3385529950455835]
	TIME [epoch: 9.06 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2804079228953306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2804079228953306 | validation: 0.16126683530225214]
	TIME [epoch: 9.06 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25614955321868726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25614955321868726 | validation: 0.26519812830651435]
	TIME [epoch: 9.08 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.458037250858004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.458037250858004 | validation: 0.5632306554186625]
	TIME [epoch: 9.08 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6750615005816999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6750615005816999 | validation: 0.19438842113935073]
	TIME [epoch: 9.06 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556597849987833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2556597849987833 | validation: 0.194451458275685]
	TIME [epoch: 9.06 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28821610145065674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28821610145065674 | validation: 0.2913443605546684]
	TIME [epoch: 9.07 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3204496890527706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3204496890527706 | validation: 0.21161649790675774]
	TIME [epoch: 9.08 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45762847019179154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45762847019179154 | validation: 0.6824847409393319]
	TIME [epoch: 9.07 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41727349441207495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41727349441207495 | validation: 0.3598084044472018]
	TIME [epoch: 9.06 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3359071288489356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3359071288489356 | validation: 0.2615372898460857]
	TIME [epoch: 9.06 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22788230964971526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22788230964971526 | validation: 0.16667896279332783]
	TIME [epoch: 9.08 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2882421869924813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2882421869924813 | validation: 0.14974823573840756]
	TIME [epoch: 9.06 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2203771041145294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2203771041145294 | validation: 0.16664813924709998]
	TIME [epoch: 9.06 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22873511318284967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22873511318284967 | validation: 0.3066786701711153]
	TIME [epoch: 9.06 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4504165333585009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4504165333585009 | validation: 0.48763495196292217]
	TIME [epoch: 9.08 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3519222951764488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3519222951764488 | validation: 0.09308371732483232]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1649859685912993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1649859685912993 | validation: 0.2536880634945156]
	TIME [epoch: 9.07 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1865693445927561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1865693445927561 | validation: 0.14241420552998058]
	TIME [epoch: 9.07 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23564551006063877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23564551006063877 | validation: 0.18486729192251894]
	TIME [epoch: 9.09 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2661740326233636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2661740326233636 | validation: 0.36299608789849763]
	TIME [epoch: 9.06 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4166014415176692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4166014415176692 | validation: 0.2215385221956333]
	TIME [epoch: 9.06 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27534806874831463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27534806874831463 | validation: 0.27345296954806425]
	TIME [epoch: 9.06 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41297214192270115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41297214192270115 | validation: 0.6805020071693243]
	TIME [epoch: 9.06 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2099112765035163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2099112765035163 | validation: 0.23148163268749072]
	TIME [epoch: 9.09 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24702048399762874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24702048399762874 | validation: 0.21329862120993365]
	TIME [epoch: 9.06 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2440112005713042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2440112005713042 | validation: 0.24344401137376964]
	TIME [epoch: 9.06 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24964090264695651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24964090264695651 | validation: 0.30090321851978424]
	TIME [epoch: 9.05 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2326874767314871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2326874767314871 | validation: 0.22833414543043495]
	TIME [epoch: 9.08 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30746994774808456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30746994774808456 | validation: 0.2870713044545892]
	TIME [epoch: 9.06 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3634611005956237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3634611005956237 | validation: 0.29438179132885156]
	TIME [epoch: 9.06 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26675594970940264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26675594970940264 | validation: 0.22402519884554015]
	TIME [epoch: 9.06 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4065730758109417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4065730758109417 | validation: 2.4719331175773545]
	TIME [epoch: 9.08 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0556825340784832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0556825340784832 | validation: 1.2863463291307073]
	TIME [epoch: 9.07 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6013732081585637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6013732081585637 | validation: 0.16395413639431566]
	TIME [epoch: 9.06 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23428052281396844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23428052281396844 | validation: 0.20355307160940614]
	TIME [epoch: 9.06 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2395310216045113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2395310216045113 | validation: 0.19495395607961405]
	TIME [epoch: 9.07 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2905174756339912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2905174756339912 | validation: 0.2541690785484345]
	TIME [epoch: 9.07 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31355767428357717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31355767428357717 | validation: 0.29155233907673395]
	TIME [epoch: 9.06 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23642806827711227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23642806827711227 | validation: 0.18566066696759542]
	TIME [epoch: 9.05 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22061367103992485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22061367103992485 | validation: 0.2391808294279985]
	TIME [epoch: 9.07 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5947501461305331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5947501461305331 | validation: 0.6523557230377355]
	TIME [epoch: 9.07 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3125115303607002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3125115303607002 | validation: 0.7028636782243246]
	TIME [epoch: 9.06 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5361256504207235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5361256504207235 | validation: 1.7103022348898542]
	TIME [epoch: 9.06 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6377086209380061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6377086209380061 | validation: 0.1551435517240662]
	TIME [epoch: 9.06 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2416381408039167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2416381408039167 | validation: 0.23929133428863325]
	TIME [epoch: 9.08 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.391093400567496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.391093400567496 | validation: 0.3048950063861575]
	TIME [epoch: 9.06 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3782375665356265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3782375665356265 | validation: 0.18708342661223376]
	TIME [epoch: 9.06 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24568927853091962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24568927853091962 | validation: 0.1871541963761726]
	TIME [epoch: 9.06 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32676130102189466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32676130102189466 | validation: 0.2327913864615371]
	TIME [epoch: 9.08 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24827040899825956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24827040899825956 | validation: 0.3294648491258438]
	TIME [epoch: 9.06 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39898008699692245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39898008699692245 | validation: 0.3980117881835704]
	TIME [epoch: 9.06 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.320887887697536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.320887887697536 | validation: 0.6919698986772924]
	TIME [epoch: 9.06 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6189384596896212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6189384596896212 | validation: 0.1678451133228231]
	TIME [epoch: 9.09 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.154524883637492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.154524883637492 | validation: 0.31442249727517024]
	TIME [epoch: 9.06 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26720139503893625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26720139503893625 | validation: 0.17433226815216393]
	TIME [epoch: 9.06 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18892919707007333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18892919707007333 | validation: 0.16770015153190798]
	TIME [epoch: 9.06 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3038267754864995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3038267754864995 | validation: 0.26524953042569943]
	TIME [epoch: 9.07 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3406571523802901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3406571523802901 | validation: 0.25486306536713904]
	TIME [epoch: 9.06 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2777578955441327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2777578955441327 | validation: 0.24667090350752047]
	TIME [epoch: 9.06 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.253780762612936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.253780762612936 | validation: 0.5813665192543132]
	TIME [epoch: 9.06 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41608958144365554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41608958144365554 | validation: 0.1581566559740956]
	TIME [epoch: 9.07 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2537159541578975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2537159541578975 | validation: 0.19712622310339267]
	TIME [epoch: 9.08 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2621074749696543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2621074749696543 | validation: 0.22192191710145265]
	TIME [epoch: 9.06 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2545333550787708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2545333550787708 | validation: 0.34516036392044513]
	TIME [epoch: 9.06 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3677266423188423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3677266423188423 | validation: 0.2434199152092175]
	TIME [epoch: 9.06 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25973157449112144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25973157449112144 | validation: 0.15137572990173792]
	TIME [epoch: 9.08 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2505336831148203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2505336831148203 | validation: 0.18169033373694066]
	TIME [epoch: 9.06 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29337359229150406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29337359229150406 | validation: 0.30315869859912203]
	TIME [epoch: 9.06 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3357225504490212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3357225504490212 | validation: 0.10198997716814258]
	TIME [epoch: 9.06 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19975766220653357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19975766220653357 | validation: 0.11979284856577925]
	TIME [epoch: 9.08 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21853289253779043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21853289253779043 | validation: 0.10452737592920591]
	TIME [epoch: 9.06 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16724528476498876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16724528476498876 | validation: 0.1377351241612242]
	TIME [epoch: 9.05 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2038212883196643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2038212883196643 | validation: 0.1512135573576328]
	TIME [epoch: 9.06 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20711412186807426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20711412186807426 | validation: 0.21926579194481982]
	TIME [epoch: 9.08 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2805124515243526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2805124515243526 | validation: 0.3867561388205111]
	TIME [epoch: 9.06 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8692507745472129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8692507745472129 | validation: 0.3589880741531546]
	TIME [epoch: 9.06 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2903402292531166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2903402292531166 | validation: 0.44169211721544954]
	TIME [epoch: 9.06 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30896854405878676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30896854405878676 | validation: 0.28451737107366204]
	TIME [epoch: 9.08 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26302617840821896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26302617840821896 | validation: 0.25464205354803376]
	TIME [epoch: 9.06 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2700545898323158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2700545898323158 | validation: 0.2117116671107587]
	TIME [epoch: 9.06 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27683094630480803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27683094630480803 | validation: 0.1858421767825797]
	TIME [epoch: 9.06 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22948427043669653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22948427043669653 | validation: 0.16189851602883215]
	TIME [epoch: 9.07 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38637708195787657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38637708195787657 | validation: 0.3611588667063239]
	TIME [epoch: 9.07 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32735706436549666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32735706436549666 | validation: 0.2732905536696466]
	TIME [epoch: 9.05 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.286373713690888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.286373713690888 | validation: 0.31019134616996247]
	TIME [epoch: 9.06 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2697642589645052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2697642589645052 | validation: 0.30604466479603565]
	TIME [epoch: 9.07 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2779167422058751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2779167422058751 | validation: 0.1826352103226319]
	TIME [epoch: 9.07 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2808451048416464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2808451048416464 | validation: 0.2641986926885896]
	TIME [epoch: 9.05 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30746031351817094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30746031351817094 | validation: 0.2502999415214219]
	TIME [epoch: 9.06 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6467859797597983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6467859797597983 | validation: 1.4010350071664401]
	TIME [epoch: 9.06 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6255685748831283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6255685748831283 | validation: 0.3489269087249731]
	TIME [epoch: 9.08 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28887662879707854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28887662879707854 | validation: 0.28552339336383653]
	TIME [epoch: 9.05 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30217495180729725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30217495180729725 | validation: 0.4366070059397891]
	TIME [epoch: 9.05 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.536157919849308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.536157919849308 | validation: 0.3455321450249652]
	TIME [epoch: 9.05 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41967008011342444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41967008011342444 | validation: 0.6521037379205914]
	TIME [epoch: 9.08 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.460068960675183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.460068960675183 | validation: 0.28763850804415286]
	TIME [epoch: 9.06 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24098659500082933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24098659500082933 | validation: 0.24414587887661798]
	TIME [epoch: 9.06 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24148271705748123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24148271705748123 | validation: 0.10335135940264506]
	TIME [epoch: 9.05 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15634783733234753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15634783733234753 | validation: 0.14506350922209837]
	TIME [epoch: 9.08 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30314892307554675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30314892307554675 | validation: 0.2545407810257967]
	TIME [epoch: 9.06 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29584150580713114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29584150580713114 | validation: 0.24465216107171012]
	TIME [epoch: 9.05 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3544190743052985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3544190743052985 | validation: 0.7199712111094067]
	TIME [epoch: 9.05 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4714852173453286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4714852173453286 | validation: 0.12838278480231]
	TIME [epoch: 9.07 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16052182966914869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16052182966914869 | validation: 0.1289230106812504]
	TIME [epoch: 9.06 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20643543795158922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20643543795158922 | validation: 0.359774836605921]
	TIME [epoch: 9.05 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2600287425840288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2600287425840288 | validation: 0.36364421244041506]
	TIME [epoch: 9.06 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2633474004793387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2633474004793387 | validation: 0.18369814112400135]
	TIME [epoch: 9.06 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16755382709847247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16755382709847247 | validation: 0.16205863884628896]
	TIME [epoch: 9.09 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5658599027147198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5658599027147198 | validation: 0.15859837754705738]
	TIME [epoch: 9.06 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1573051440802189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1573051440802189 | validation: 0.21953613049124687]
	TIME [epoch: 9.05 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18726829476959106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18726829476959106 | validation: 0.18564084259810054]
	TIME [epoch: 9.06 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24307679741620633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24307679741620633 | validation: 0.2706725463109561]
	TIME [epoch: 9.07 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2672124130415531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2672124130415531 | validation: 0.10116047144736245]
	TIME [epoch: 9.06 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4231542386012963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4231542386012963 | validation: 0.3439433960950675]
	TIME [epoch: 9.05 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2974549706867887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2974549706867887 | validation: 0.38002113682287386]
	TIME [epoch: 9.05 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.262108010142619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.262108010142619 | validation: 0.16991438653991606]
	TIME [epoch: 9.08 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18698247637432813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18698247637432813 | validation: 0.2669951163021818]
	TIME [epoch: 9.05 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1945540667362863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1945540667362863 | validation: 0.13490678893277247]
	TIME [epoch: 9.05 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2168239929819741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2168239929819741 | validation: 0.11946293345213084]
	TIME [epoch: 9.05 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6112450446074031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6112450446074031 | validation: 0.1912963816389521]
	TIME [epoch: 9.07 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2273474437679462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2273474437679462 | validation: 1.454048071019428]
	TIME [epoch: 9.05 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6231909016858567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6231909016858567 | validation: 0.30880086760363906]
	TIME [epoch: 9.05 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20876375297641733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20876375297641733 | validation: 0.1382543879555851]
	TIME [epoch: 9.05 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17509178743155876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17509178743155876 | validation: 0.18382752772166908]
	TIME [epoch: 9.08 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2804637610396913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2804637610396913 | validation: 0.148870579633625]
	TIME [epoch: 9.06 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15330772334643522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15330772334643522 | validation: 0.08452408174149578]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09628997624195182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09628997624195182 | validation: 0.13831873347404042]
	TIME [epoch: 9.05 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16344767491261564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16344767491261564 | validation: 0.16718117851793426]
	TIME [epoch: 9.06 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20858895044262887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20858895044262887 | validation: 0.20467135792761237]
	TIME [epoch: 9.07 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25807643134974906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25807643134974906 | validation: 0.3436842306835758]
	TIME [epoch: 9.05 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2478455274630587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2478455274630587 | validation: 0.21875925239931635]
	TIME [epoch: 9.05 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2507968149487427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2507968149487427 | validation: 0.24915836316904094]
	TIME [epoch: 9.06 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4106475583195713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4106475583195713 | validation: 0.4029729644357902]
	TIME [epoch: 9.08 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8002071325627828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8002071325627828 | validation: 0.3745233634775709]
	TIME [epoch: 9.05 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23048242631504254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23048242631504254 | validation: 0.258626208752302]
	TIME [epoch: 9.05 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5522549801898557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5522549801898557 | validation: 0.3344446620152214]
	TIME [epoch: 9.05 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18207674917314182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18207674917314182 | validation: 0.12350127956772089]
	TIME [epoch: 9.07 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15358602255824955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15358602255824955 | validation: 0.15335801423328543]
	TIME [epoch: 9.06 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2223798720890394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2223798720890394 | validation: 0.41178178366812124]
	TIME [epoch: 9.05 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26305232351323826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26305232351323826 | validation: 0.2750666733037884]
	TIME [epoch: 9.05 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25105834449502623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25105834449502623 | validation: 0.17533609951708334]
	TIME [epoch: 9.07 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4403879306880377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4403879306880377 | validation: 0.14671536247303008]
	TIME [epoch: 9.06 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.715674977009752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.715674977009752 | validation: 2.505259539968068]
	TIME [epoch: 9.05 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0292811693856008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0292811693856008 | validation: 2.640421303991647]
	TIME [epoch: 9.05 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1412598886787126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1412598886787126 | validation: 2.658742409766094]
	TIME [epoch: 9.06 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9799139186593109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9799139186593109 | validation: 0.9796495595287189]
	TIME [epoch: 9.07 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4998835637118497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4998835637118497 | validation: 2.692590844023621]
	TIME [epoch: 9.05 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.094099118552111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.094099118552111 | validation: 2.7365082494285478]
	TIME [epoch: 9.05 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1714341775048487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1714341775048487 | validation: 2.568177939449357]
	TIME [epoch: 9.06 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2188952579562264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2188952579562264 | validation: 1.1919465446417108]
	TIME [epoch: 9.08 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9203650372724447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9203650372724447 | validation: 0.562565596702171]
	TIME [epoch: 9.05 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.385429149363138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.385429149363138 | validation: 0.1762633863301386]
	TIME [epoch: 9.06 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29904204408135804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29904204408135804 | validation: 0.25683358649284926]
	TIME [epoch: 9.05 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.459318493961389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.459318493961389 | validation: 1.9001043801729764]
	TIME [epoch: 9.08 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9438852378614353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9438852378614353 | validation: 0.3031749508873032]
	TIME [epoch: 9.06 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5922246387600311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5922246387600311 | validation: 0.7885573140503783]
	TIME [epoch: 9.05 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.951401887601714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.951401887601714 | validation: 0.4432784711200134]
	TIME [epoch: 9.06 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3859826113814032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3859826113814032 | validation: 0.1984320081781681]
	TIME [epoch: 9.08 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.364283787814794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.364283787814794 | validation: 0.4360981519089665]
	TIME [epoch: 9.05 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33718999466039584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33718999466039584 | validation: 0.24450389849215304]
	TIME [epoch: 9.05 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2018671026312609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2018671026312609 | validation: 0.14568352206551655]
	TIME [epoch: 9.05 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20562217940938488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20562217940938488 | validation: 0.45122424959720997]
	TIME [epoch: 9.08 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39506122762120677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39506122762120677 | validation: 0.41142004475825245]
	TIME [epoch: 9.06 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20621092555054016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20621092555054016 | validation: 0.17171592137274683]
	TIME [epoch: 9.05 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18613282125652958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18613282125652958 | validation: 0.2654449509895907]
	TIME [epoch: 9.05 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2248265855641524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2248265855641524 | validation: 0.25994156361512344]
	TIME [epoch: 9.07 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21274728904889123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21274728904889123 | validation: 0.13842728998130466]
	TIME [epoch: 9.07 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1510949239161159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1510949239161159 | validation: 0.4463277314570081]
	TIME [epoch: 9.06 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24968334971666634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24968334971666634 | validation: 0.3331765437741496]
	TIME [epoch: 9.05 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25645151574361247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25645151574361247 | validation: 0.27900142539724415]
	TIME [epoch: 9.06 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34376567246011874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34376567246011874 | validation: 0.15389463677865456]
	TIME [epoch: 9.07 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24344350316419536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24344350316419536 | validation: 0.24614627510683557]
	TIME [epoch: 9.06 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5775531680214258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5775531680214258 | validation: 0.6153031234020055]
	TIME [epoch: 9.05 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3951853638778403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3951853638778403 | validation: 0.2843228554512675]
	TIME [epoch: 9.05 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27343504799431895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27343504799431895 | validation: 0.2627503455380333]
	TIME [epoch: 9.08 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42280531590510967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42280531590510967 | validation: 0.20715639799175345]
	TIME [epoch: 9.05 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26422204603559923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26422204603559923 | validation: 0.4566950748504982]
	TIME [epoch: 9.05 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43923411505366927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43923411505366927 | validation: 0.21600920233188606]
	TIME [epoch: 9.05 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21121424665940897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21121424665940897 | validation: 0.19451743425488421]
	TIME [epoch: 9.08 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2394834881593421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2394834881593421 | validation: 0.31117468775757706]
	TIME [epoch: 9.06 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2844666844561384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2844666844561384 | validation: 0.17687347591616537]
	TIME [epoch: 9.05 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21879123102052328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21879123102052328 | validation: 0.3632681793995622]
	TIME [epoch: 9.05 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4534807478537881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4534807478537881 | validation: 2.9281936718249213]
	TIME [epoch: 9.08 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3860647755616684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3860647755616684 | validation: 2.43358652012585]
	TIME [epoch: 9.06 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.389967826310316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.389967826310316 | validation: 0.6500567774510454]
	TIME [epoch: 9.06 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9014194394903484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9014194394903484 | validation: 0.5457010702902514]
	TIME [epoch: 9.06 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4680273309188805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4680273309188805 | validation: 0.22748807526512024]
	TIME [epoch: 9.07 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24717156369814303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24717156369814303 | validation: 0.15169512137647861]
	TIME [epoch: 9.07 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22684754376758462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22684754376758462 | validation: 0.15916074637982278]
	TIME [epoch: 9.05 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20541168145132072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20541168145132072 | validation: 0.13042208436281422]
	TIME [epoch: 9.05 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19977097228088492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19977097228088492 | validation: 0.2316282154513975]
	TIME [epoch: 9.06 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24221712552796001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24221712552796001 | validation: 0.16799984110395028]
	TIME [epoch: 9.07 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20656226101227343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20656226101227343 | validation: 0.2188186478295012]
	TIME [epoch: 9.06 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27358877033210305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27358877033210305 | validation: 0.3878674489287348]
	TIME [epoch: 9.05 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25785495814170367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25785495814170367 | validation: 0.5326457316596109]
	TIME [epoch: 9.06 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8643525137796013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8643525137796013 | validation: 1.6864951175952179]
	TIME [epoch: 9.08 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5647807031379581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5647807031379581 | validation: 0.6942546738318573]
	TIME [epoch: 9.06 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2903310820933916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2903310820933916 | validation: 0.17007076351265102]
	TIME [epoch: 9.05 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29978210085761664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29978210085761664 | validation: 0.6694128845467393]
	TIME [epoch: 9.05 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2684281513690693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2684281513690693 | validation: 0.16269203013859945]
	TIME [epoch: 9.11 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21478867935064044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21478867935064044 | validation: 0.1634130260327978]
	TIME [epoch: 9.06 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1744555662981952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1744555662981952 | validation: 0.12963759765267432]
	TIME [epoch: 9.05 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14849025849832323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14849025849832323 | validation: 0.08790728533150713]
	TIME [epoch: 9.05 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20708981742944288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20708981742944288 | validation: 0.1347636551494433]
	TIME [epoch: 9.08 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15734759486343114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15734759486343114 | validation: 0.11433023691895812]
	TIME [epoch: 9.06 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12122903902182776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12122903902182776 | validation: 0.17804344444959122]
	TIME [epoch: 9.05 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24744545424474734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24744545424474734 | validation: 0.22209030179614325]
	TIME [epoch: 9.06 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23398225852455198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23398225852455198 | validation: 0.3293917048357719]
	TIME [epoch: 9.08 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20612193675132992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20612193675132992 | validation: 0.1210840325775188]
	TIME [epoch: 9.07 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19961329328493224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19961329328493224 | validation: 0.19963508759809664]
	TIME [epoch: 9.06 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2460735337059477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2460735337059477 | validation: 0.24626981896955713]
	TIME [epoch: 9.06 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2441779496998843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2441779496998843 | validation: 0.12501130149253106]
	TIME [epoch: 9.07 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18126283071141105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18126283071141105 | validation: 0.11793706755143546]
	TIME [epoch: 9.08 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17858378297458016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17858378297458016 | validation: 0.30622076368356943]
	TIME [epoch: 9.06 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2484138810740657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2484138810740657 | validation: 0.27411093388492214]
	TIME [epoch: 9.06 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9963575872632289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9963575872632289 | validation: 0.21284948720136043]
	TIME [epoch: 9.07 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17531896015868947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17531896015868947 | validation: 0.22467989777853925]
	TIME [epoch: 9.07 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3805491529195509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3805491529195509 | validation: 0.29367734913664406]
	TIME [epoch: 9.06 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2562503457935633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2562503457935633 | validation: 0.45619709740607073]
	TIME [epoch: 9.06 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4218954633366529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4218954633366529 | validation: 0.1352393490644348]
	TIME [epoch: 9.05 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.207948318067093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.207948318067093 | validation: 0.27134371278625935]
	TIME [epoch: 9.08 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23132853234297873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23132853234297873 | validation: 0.2238779615799961]
	TIME [epoch: 9.06 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18402474493126889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18402474493126889 | validation: 0.1531595357046646]
	TIME [epoch: 9.06 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16582427530563754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16582427530563754 | validation: 0.14537066006068958]
	TIME [epoch: 9.06 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2155307947928266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2155307947928266 | validation: 0.15346720223584615]
	TIME [epoch: 9.08 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2199535314026097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2199535314026097 | validation: 0.16209999263762534]
	TIME [epoch: 9.06 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18109508838123795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18109508838123795 | validation: 0.7334402437014259]
	TIME [epoch: 9.06 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9274433044738082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9274433044738082 | validation: 0.20027053631596664]
	TIME [epoch: 9.06 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6389781751532513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6389781751532513 | validation: 0.24333466005087565]
	TIME [epoch: 9.08 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21868979322321813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21868979322321813 | validation: 0.08045111187848361]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_409.pth
	Model improved!!!
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1849778255776256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1849778255776256 | validation: 0.3974171494218808]
	TIME [epoch: 9.05 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24824951676272175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24824951676272175 | validation: 0.2615265212240349]
	TIME [epoch: 9.04 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2922823490344156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2922823490344156 | validation: 0.16107522286694023]
	TIME [epoch: 9.06 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6756717984426521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6756717984426521 | validation: 1.1537668371545133]
	TIME [epoch: 9.06 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3364027440884424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3364027440884424 | validation: 0.15191454680709682]
	TIME [epoch: 9.06 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23088222677218165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23088222677218165 | validation: 0.2695001098708847]
	TIME [epoch: 9.05 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28267151416753866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28267151416753866 | validation: 0.22303049782507406]
	TIME [epoch: 9.05 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25733189940361634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25733189940361634 | validation: 0.16886405903514046]
	TIME [epoch: 9.06 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2461502002989044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2461502002989044 | validation: 0.33209477712392077]
	TIME [epoch: 9.05 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26398219347641155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26398219347641155 | validation: 0.19121186322368158]
	TIME [epoch: 9.04 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2609268903835669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2609268903835669 | validation: 0.3013475735828697]
	TIME [epoch: 9.05 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2363201586461819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2363201586461819 | validation: 0.16727499193566808]
	TIME [epoch: 9.07 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28958283920858585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28958283920858585 | validation: 0.20348028743779079]
	TIME [epoch: 9.06 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24444465500320317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24444465500320317 | validation: 0.16643517537535113]
	TIME [epoch: 9.05 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2586356462128806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2586356462128806 | validation: 0.18980400337574554]
	TIME [epoch: 9.04 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23463282052938358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23463282052938358 | validation: 0.25495555211623827]
	TIME [epoch: 9.07 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2496297232835122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2496297232835122 | validation: 0.16317673657231496]
	TIME [epoch: 9.05 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2651247384209556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2651247384209556 | validation: 0.27670099864426856]
	TIME [epoch: 9.05 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2736362407503288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2736362407503288 | validation: 0.211216096361119]
	TIME [epoch: 9.05 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28739236286407127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28739236286407127 | validation: 0.197521918478684]
	TIME [epoch: 9.05 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3299679703878141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3299679703878141 | validation: 0.16806126600609383]
	TIME [epoch: 9.06 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2311317051653586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2311317051653586 | validation: 0.17060810022578382]
	TIME [epoch: 9.04 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2251877573160424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2251877573160424 | validation: 0.20928187704947757]
	TIME [epoch: 9.05 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25067165624485555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25067165624485555 | validation: 0.1607499244116658]
	TIME [epoch: 9.05 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2479737117070937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2479737117070937 | validation: 0.17387357180399438]
	TIME [epoch: 9.07 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22362080265179646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22362080265179646 | validation: 0.1670747902759217]
	TIME [epoch: 9.05 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2545597923392619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2545597923392619 | validation: 0.20567599730223285]
	TIME [epoch: 9.04 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2843834546496552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2843834546496552 | validation: 0.2830078599828504]
	TIME [epoch: 9.05 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2473894997432194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2473894997432194 | validation: 0.17434464108160158]
	TIME [epoch: 9.07 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23172278409945585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23172278409945585 | validation: 0.1530714265690179]
	TIME [epoch: 9.05 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21968634571605206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21968634571605206 | validation: 0.18187408154163565]
	TIME [epoch: 9.05 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20211397461627595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20211397461627595 | validation: 0.11611354529078655]
	TIME [epoch: 9.04 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23077722829818076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23077722829818076 | validation: 0.32737082511496407]
	TIME [epoch: 9.07 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3652316117973136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3652316117973136 | validation: 1.7643910973769636]
	TIME [epoch: 9.05 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.84386178550279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.84386178550279 | validation: 1.2625952834043346]
	TIME [epoch: 9.05 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2437059239864872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2437059239864872 | validation: 0.9805826609938566]
	TIME [epoch: 9.05 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.078572868885382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.078572868885382 | validation: 0.8408608248571434]
	TIME [epoch: 9.07 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1075298426490425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1075298426490425 | validation: 0.7574616330893937]
	TIME [epoch: 9.05 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44624345198549714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44624345198549714 | validation: 0.34454621356295745]
	TIME [epoch: 9.05 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3500804051864523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3500804051864523 | validation: 0.3091362444947938]
	TIME [epoch: 9.05 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3642237261056716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3642237261056716 | validation: 0.3460568621674955]
	TIME [epoch: 9.05 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2892457047851943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2892457047851943 | validation: 0.21941762821728777]
	TIME [epoch: 9.07 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2541260595032457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2541260595032457 | validation: 0.25969434024003135]
	TIME [epoch: 9.05 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27945028618533385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27945028618533385 | validation: 0.1623819941953765]
	TIME [epoch: 9.05 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22478336517752076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22478336517752076 | validation: 0.3026409793930763]
	TIME [epoch: 9.05 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27259116626814506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27259116626814506 | validation: 0.23725439140380503]
	TIME [epoch: 9.06 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26253316057796006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26253316057796006 | validation: 0.16266171715928798]
	TIME [epoch: 9.05 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4274411577477932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4274411577477932 | validation: 0.24295369264745698]
	TIME [epoch: 9.04 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38544837841789054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38544837841789054 | validation: 0.2133179442989374]
	TIME [epoch: 9.05 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3059984158940584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3059984158940584 | validation: 0.4223797636493428]
	TIME [epoch: 9.06 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47221501495324103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47221501495324103 | validation: 0.2770858058781185]
	TIME [epoch: 9.05 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3388611736706678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3388611736706678 | validation: 0.4184538543493648]
	TIME [epoch: 9.05 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31833835984886266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31833835984886266 | validation: 0.2126427794471788]
	TIME [epoch: 9.04 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31786058428129926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31786058428129926 | validation: 0.24352631640558048]
	TIME [epoch: 9.07 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25772261352695647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25772261352695647 | validation: 0.2459788836622488]
	TIME [epoch: 9.04 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24035174379835772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24035174379835772 | validation: 0.17657434392710813]
	TIME [epoch: 9.04 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3149299982070233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3149299982070233 | validation: 0.24623598414591621]
	TIME [epoch: 9.05 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21252969075222522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21252969075222522 | validation: 0.22933980385025915]
	TIME [epoch: 9.06 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2612721918106944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2612721918106944 | validation: 0.4726504453802516]
	TIME [epoch: 9.05 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33203942947235043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33203942947235043 | validation: 0.17655369282333966]
	TIME [epoch: 9.05 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20641219488254875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20641219488254875 | validation: 0.1550440219505995]
	TIME [epoch: 9.05 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20454065189674422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20454065189674422 | validation: 0.1568837120253892]
	TIME [epoch: 9.08 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22699481970425417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22699481970425417 | validation: 0.1011796668409751]
	TIME [epoch: 9.05 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.446515395210999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.446515395210999 | validation: 0.40272602360899823]
	TIME [epoch: 9.05 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6354674557129932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6354674557129932 | validation: 1.1205644251868292]
	TIME [epoch: 9.05 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5692778766911778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5692778766911778 | validation: 0.31698037703183146]
	TIME [epoch: 9.06 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23863479910974944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23863479910974944 | validation: 0.13652730709233776]
	TIME [epoch: 9.06 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2034974669357051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2034974669357051 | validation: 0.19754311618871595]
	TIME [epoch: 9.05 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42442130025836766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42442130025836766 | validation: 0.2809628057180426]
	TIME [epoch: 9.05 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3097804209786206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3097804209786206 | validation: 0.17813516322020673]
	TIME [epoch: 9.06 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20670387204139962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20670387204139962 | validation: 0.1847068450956055]
	TIME [epoch: 9.08 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18885184133620186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18885184133620186 | validation: 0.10995603774203451]
	TIME [epoch: 9.05 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.501340379599905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.501340379599905 | validation: 0.20926711318197785]
	TIME [epoch: 9.05 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4005283293790544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4005283293790544 | validation: 0.17705876965231845]
	TIME [epoch: 9.05 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19534849884423733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19534849884423733 | validation: 0.14478952757535127]
	TIME [epoch: 9.07 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4660997898821232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4660997898821232 | validation: 0.1230214216809663]
	TIME [epoch: 9.05 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16361912414380908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16361912414380908 | validation: 0.15827762121997965]
	TIME [epoch: 9.04 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2740658255000521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2740658255000521 | validation: 0.12481809805793875]
	TIME [epoch: 9.06 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1667090779807737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1667090779807737 | validation: 0.19424406334739974]
	TIME [epoch: 9.07 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47719224125757675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47719224125757675 | validation: 0.19004927505518812]
	TIME [epoch: 9.06 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3412666407926672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3412666407926672 | validation: 0.14871412212777213]
	TIME [epoch: 9.05 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1694033328961548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1694033328961548 | validation: 0.1780479864063697]
	TIME [epoch: 9.06 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3692043531782908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3692043531782908 | validation: 0.17453060638076962]
	TIME [epoch: 9.08 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1693697101752274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1693697101752274 | validation: 0.15479442131356885]
	TIME [epoch: 9.06 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20915099922053199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20915099922053199 | validation: 0.1685881148725294]
	TIME [epoch: 9.06 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24839099645461885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24839099645461885 | validation: 0.18319746130624426]
	TIME [epoch: 9.05 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2078270428911099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2078270428911099 | validation: 0.13756792295889697]
	TIME [epoch: 9.07 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17828193080541108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17828193080541108 | validation: 0.24439471433229776]
	TIME [epoch: 9.07 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24701001045640422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24701001045640422 | validation: 0.20050964275864236]
	TIME [epoch: 9.05 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.271203273802709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.271203273802709 | validation: 0.2693963591610429]
	TIME [epoch: 9.06 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15757033958782035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15757033958782035 | validation: 0.14033614873959338]
	TIME [epoch: 9.07 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17186580927582587		[learning rate: 0.0099724]
	Learning Rate: 0.00997241
	LOSS [training: 0.17186580927582587 | validation: 1.1330057383007175]
	TIME [epoch: 9.06 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7904627330106915		[learning rate: 0.0099418]
	Learning Rate: 0.00994184
	LOSS [training: 0.7904627330106915 | validation: 0.1526276978416285]
	TIME [epoch: 9.05 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2456673897001452		[learning rate: 0.0099114]
	Learning Rate: 0.00991136
	LOSS [training: 0.2456673897001452 | validation: 0.20340436846788176]
	TIME [epoch: 9.05 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1752589274233586		[learning rate: 0.009881]
	Learning Rate: 0.00988098
	LOSS [training: 0.1752589274233586 | validation: 0.1756488635237307]
	TIME [epoch: 9.05 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1860416618767509		[learning rate: 0.0098507]
	Learning Rate: 0.00985069
	LOSS [training: 0.1860416618767509 | validation: 0.36456645011991307]
	TIME [epoch: 9.07 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2354815806585091		[learning rate: 0.0098205]
	Learning Rate: 0.00982049
	LOSS [training: 0.2354815806585091 | validation: 0.15268131897781456]
	TIME [epoch: 9.05 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19565346620930865		[learning rate: 0.0097904]
	Learning Rate: 0.00979039
	LOSS [training: 0.19565346620930865 | validation: 0.14757530721274564]
	TIME [epoch: 9.04 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15388950146008856		[learning rate: 0.0097604]
	Learning Rate: 0.00976038
	LOSS [training: 0.15388950146008856 | validation: 0.544155699514172]
	TIME [epoch: 9.05 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27193434119439697		[learning rate: 0.0097305]
	Learning Rate: 0.00973046
	LOSS [training: 0.27193434119439697 | validation: 0.28085938801806415]
	TIME [epoch: 9.07 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1854160375752842		[learning rate: 0.0097006]
	Learning Rate: 0.00970063
	LOSS [training: 0.1854160375752842 | validation: 0.18670980065707987]
	TIME [epoch: 9.05 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17739352461629077		[learning rate: 0.0096709]
	Learning Rate: 0.00967089
	LOSS [training: 0.17739352461629077 | validation: 0.2880863115127418]
	TIME [epoch: 9.06 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18792823441058		[learning rate: 0.0096412]
	Learning Rate: 0.00964125
	LOSS [training: 0.18792823441058 | validation: 0.26463695390978526]
	TIME [epoch: 9.05 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21175772092530615		[learning rate: 0.0096117]
	Learning Rate: 0.0096117
	LOSS [training: 0.21175772092530615 | validation: 0.17435030496559406]
	TIME [epoch: 9.08 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20127041446954846		[learning rate: 0.0095822]
	Learning Rate: 0.00958223
	LOSS [training: 0.20127041446954846 | validation: 0.14688540680248202]
	TIME [epoch: 9.05 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16027071138825938		[learning rate: 0.0095529]
	Learning Rate: 0.00955286
	LOSS [training: 0.16027071138825938 | validation: 0.12754315227035967]
	TIME [epoch: 9.06 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20897791055719694		[learning rate: 0.0095236]
	Learning Rate: 0.00952357
	LOSS [training: 0.20897791055719694 | validation: 0.46696056607298975]
	TIME [epoch: 9.05 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4404469462181013		[learning rate: 0.0094944]
	Learning Rate: 0.00949438
	LOSS [training: 0.4404469462181013 | validation: 0.5765722898620722]
	TIME [epoch: 9.06 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4339702431481264		[learning rate: 0.0094653]
	Learning Rate: 0.00946528
	LOSS [training: 0.4339702431481264 | validation: 0.22793143312449562]
	TIME [epoch: 9.05 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3391581924847784		[learning rate: 0.0094363]
	Learning Rate: 0.00943626
	LOSS [training: 0.3391581924847784 | validation: 0.2880560977673142]
	TIME [epoch: 9.04 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2593028339778992		[learning rate: 0.0094073]
	Learning Rate: 0.00940734
	LOSS [training: 0.2593028339778992 | validation: 0.22139617262987865]
	TIME [epoch: 9.05 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36553587212642297		[learning rate: 0.0093785]
	Learning Rate: 0.0093785
	LOSS [training: 0.36553587212642297 | validation: 0.29834069051020234]
	TIME [epoch: 9.06 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.65803840129695		[learning rate: 0.0093497]
	Learning Rate: 0.00934975
	LOSS [training: 0.65803840129695 | validation: 0.1908339348970582]
	TIME [epoch: 9.06 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28962158220442213		[learning rate: 0.0093211]
	Learning Rate: 0.00932109
	LOSS [training: 0.28962158220442213 | validation: 0.13096593761494957]
	TIME [epoch: 9.04 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1866487050814803		[learning rate: 0.0092925]
	Learning Rate: 0.00929252
	LOSS [training: 0.1866487050814803 | validation: 0.13850179151824937]
	TIME [epoch: 9.05 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3949908747217047		[learning rate: 0.009264]
	Learning Rate: 0.00926403
	LOSS [training: 0.3949908747217047 | validation: 0.20394480841916346]
	TIME [epoch: 9.06 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19197168477692717		[learning rate: 0.0092356]
	Learning Rate: 0.00923563
	LOSS [training: 0.19197168477692717 | validation: 0.13663956898665425]
	TIME [epoch: 9.06 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0198810360930808		[learning rate: 0.0092073]
	Learning Rate: 0.00920732
	LOSS [training: 1.0198810360930808 | validation: 0.37798542142697933]
	TIME [epoch: 9.04 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5206442288911701		[learning rate: 0.0091791]
	Learning Rate: 0.0091791
	LOSS [training: 0.5206442288911701 | validation: 0.24704494949789277]
	TIME [epoch: 9.05 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2371954317330645		[learning rate: 0.009151]
	Learning Rate: 0.00915096
	LOSS [training: 0.2371954317330645 | validation: 0.2344675780773817]
	TIME [epoch: 9.04 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19142891095917686		[learning rate: 0.0091229]
	Learning Rate: 0.00912291
	LOSS [training: 0.19142891095917686 | validation: 0.293291468700306]
	TIME [epoch: 9.07 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2080920299158299		[learning rate: 0.0090949]
	Learning Rate: 0.00909494
	LOSS [training: 0.2080920299158299 | validation: 0.13963298851193967]
	TIME [epoch: 9.05 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1764231862090666		[learning rate: 0.0090671]
	Learning Rate: 0.00906706
	LOSS [training: 0.1764231862090666 | validation: 0.07753102680066783]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_532.pth
	Model improved!!!
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1330981474080521		[learning rate: 0.0090393]
	Learning Rate: 0.00903927
	LOSS [training: 0.1330981474080521 | validation: 0.259458910808714]
	TIME [epoch: 9.05 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33151495953107507		[learning rate: 0.0090116]
	Learning Rate: 0.00901156
	LOSS [training: 0.33151495953107507 | validation: 0.36989960764275553]
	TIME [epoch: 9.06 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27493157801246465		[learning rate: 0.0089839]
	Learning Rate: 0.00898394
	LOSS [training: 0.27493157801246465 | validation: 0.22219629186152684]
	TIME [epoch: 9.05 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17988086664623706		[learning rate: 0.0089564]
	Learning Rate: 0.0089564
	LOSS [training: 0.17988086664623706 | validation: 0.11568802030802941]
	TIME [epoch: 9.05 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1930224047175048		[learning rate: 0.0089289]
	Learning Rate: 0.00892894
	LOSS [training: 0.1930224047175048 | validation: 0.21145152034296474]
	TIME [epoch: 9.04 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2976293523463621		[learning rate: 0.0089016]
	Learning Rate: 0.00890157
	LOSS [training: 0.2976293523463621 | validation: 0.4732977458904212]
	TIME [epoch: 9.05 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24550601409982473		[learning rate: 0.0088743]
	Learning Rate: 0.00887428
	LOSS [training: 0.24550601409982473 | validation: 0.18305872168675774]
	TIME [epoch: 9.06 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20471154812005182		[learning rate: 0.0088471]
	Learning Rate: 0.00884708
	LOSS [training: 0.20471154812005182 | validation: 0.12123877062750399]
	TIME [epoch: 9.04 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17761877051072883		[learning rate: 0.00882]
	Learning Rate: 0.00881996
	LOSS [training: 0.17761877051072883 | validation: 0.4874069550972566]
	TIME [epoch: 9.05 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27502746135099526		[learning rate: 0.0087929]
	Learning Rate: 0.00879292
	LOSS [training: 0.27502746135099526 | validation: 0.1201798041098734]
	TIME [epoch: 9.05 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17186882482493832		[learning rate: 0.008766]
	Learning Rate: 0.00876597
	LOSS [training: 0.17186882482493832 | validation: 0.1318304673511128]
	TIME [epoch: 9.06 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15018401962766476		[learning rate: 0.0087391]
	Learning Rate: 0.0087391
	LOSS [training: 0.15018401962766476 | validation: 0.15333816056733457]
	TIME [epoch: 9.05 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1494318743577145		[learning rate: 0.0087123]
	Learning Rate: 0.00871231
	LOSS [training: 0.1494318743577145 | validation: 0.12297218192772713]
	TIME [epoch: 9.04 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16757606871228115		[learning rate: 0.0086856]
	Learning Rate: 0.0086856
	LOSS [training: 0.16757606871228115 | validation: 0.14905095277671804]
	TIME [epoch: 9.04 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18408404181319887		[learning rate: 0.008659]
	Learning Rate: 0.00865898
	LOSS [training: 0.18408404181319887 | validation: 0.09588856215260486]
	TIME [epoch: 9.06 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14587600090616976		[learning rate: 0.0086324]
	Learning Rate: 0.00863244
	LOSS [training: 0.14587600090616976 | validation: 0.3709999147763203]
	TIME [epoch: 9.04 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2627112642686182		[learning rate: 0.008606]
	Learning Rate: 0.00860597
	LOSS [training: 0.2627112642686182 | validation: 0.24124527522042416]
	TIME [epoch: 9.05 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.315575882905761		[learning rate: 0.0085796]
	Learning Rate: 0.00857959
	LOSS [training: 0.315575882905761 | validation: 0.5232570832988795]
	TIME [epoch: 9.04 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3564057872485737		[learning rate: 0.0085533]
	Learning Rate: 0.00855329
	LOSS [training: 0.3564057872485737 | validation: 0.31884265905732356]
	TIME [epoch: 9.06 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45438971012991364		[learning rate: 0.0085271]
	Learning Rate: 0.00852707
	LOSS [training: 0.45438971012991364 | validation: 0.7637187430277347]
	TIME [epoch: 9.04 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8478109935012329		[learning rate: 0.0085009]
	Learning Rate: 0.00850093
	LOSS [training: 0.8478109935012329 | validation: 0.32599548730008604]
	TIME [epoch: 9.04 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.263908655178591		[learning rate: 0.0084749]
	Learning Rate: 0.00847488
	LOSS [training: 0.263908655178591 | validation: 0.10763271768334723]
	TIME [epoch: 9.04 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4373426702381743		[learning rate: 0.0084489]
	Learning Rate: 0.0084489
	LOSS [training: 0.4373426702381743 | validation: 0.2909457138870982]
	TIME [epoch: 9.06 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1887242812193395		[learning rate: 0.008423]
	Learning Rate: 0.008423
	LOSS [training: 0.1887242812193395 | validation: 0.13855488456706772]
	TIME [epoch: 9.05 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.215309728592643		[learning rate: 0.0083972]
	Learning Rate: 0.00839718
	LOSS [training: 1.215309728592643 | validation: 0.6441216037265449]
	TIME [epoch: 9.04 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33977050956008215		[learning rate: 0.0083714]
	Learning Rate: 0.00837144
	LOSS [training: 0.33977050956008215 | validation: 0.19473711270980013]
	TIME [epoch: 9.04 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1551215913459763		[learning rate: 0.0083458]
	Learning Rate: 0.00834577
	LOSS [training: 0.1551215913459763 | validation: 0.13772134686694104]
	TIME [epoch: 9.05 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2103147807794774		[learning rate: 0.0083202]
	Learning Rate: 0.00832019
	LOSS [training: 0.2103147807794774 | validation: 0.27370062673984175]
	TIME [epoch: 9.06 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2567587920760091		[learning rate: 0.0082947]
	Learning Rate: 0.00829469
	LOSS [training: 0.2567587920760091 | validation: 0.3188415127508403]
	TIME [epoch: 9.04 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25042849737867356		[learning rate: 0.0082693]
	Learning Rate: 0.00826926
	LOSS [training: 0.25042849737867356 | validation: 0.11053285540038542]
	TIME [epoch: 9.04 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30361374961947113		[learning rate: 0.0082439]
	Learning Rate: 0.00824391
	LOSS [training: 0.30361374961947113 | validation: 0.1979149570145096]
	TIME [epoch: 9.04 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15144409808570705		[learning rate: 0.0082186]
	Learning Rate: 0.00821864
	LOSS [training: 0.15144409808570705 | validation: 0.18109174679598644]
	TIME [epoch: 9.06 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1415109358905728		[learning rate: 0.0081934]
	Learning Rate: 0.00819345
	LOSS [training: 0.1415109358905728 | validation: 0.09868770299254483]
	TIME [epoch: 9.04 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19271314837648207		[learning rate: 0.0081683]
	Learning Rate: 0.00816833
	LOSS [training: 0.19271314837648207 | validation: 0.11876556663488358]
	TIME [epoch: 9.04 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1915952847188567		[learning rate: 0.0081433]
	Learning Rate: 0.00814329
	LOSS [training: 0.1915952847188567 | validation: 0.13979412535188013]
	TIME [epoch: 9.05 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3444621475884136		[learning rate: 0.0081183]
	Learning Rate: 0.00811833
	LOSS [training: 0.3444621475884136 | validation: 0.5257536880845883]
	TIME [epoch: 9.07 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4001595883013963		[learning rate: 0.0080934]
	Learning Rate: 0.00809344
	LOSS [training: 0.4001595883013963 | validation: 0.23900873982763426]
	TIME [epoch: 9.04 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31834290985396463		[learning rate: 0.0080686]
	Learning Rate: 0.00806863
	LOSS [training: 0.31834290985396463 | validation: 0.17823936817234826]
	TIME [epoch: 9.05 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21155257822477397		[learning rate: 0.0080439]
	Learning Rate: 0.0080439
	LOSS [training: 0.21155257822477397 | validation: 0.07952810764467683]
	TIME [epoch: 9.04 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18759387269594222		[learning rate: 0.0080192]
	Learning Rate: 0.00801924
	LOSS [training: 0.18759387269594222 | validation: 0.6130853855475491]
	TIME [epoch: 9.07 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5399885725947833		[learning rate: 0.0079947]
	Learning Rate: 0.00799466
	LOSS [training: 0.5399885725947833 | validation: 0.4463728437913532]
	TIME [epoch: 9.06 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47922216066470436		[learning rate: 0.0079702]
	Learning Rate: 0.00797015
	LOSS [training: 0.47922216066470436 | validation: 0.34614398624349474]
	TIME [epoch: 9.05 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.467240602147925		[learning rate: 0.0079457]
	Learning Rate: 0.00794572
	LOSS [training: 0.467240602147925 | validation: 0.23915847090589537]
	TIME [epoch: 9.05 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4913605188421675		[learning rate: 0.0079214]
	Learning Rate: 0.00792136
	LOSS [training: 0.4913605188421675 | validation: 0.393920985810954]
	TIME [epoch: 9.07 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40646360619325783		[learning rate: 0.0078971]
	Learning Rate: 0.00789708
	LOSS [training: 0.40646360619325783 | validation: 0.42704494495832]
	TIME [epoch: 9.05 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26807257334045825		[learning rate: 0.0078729]
	Learning Rate: 0.00787287
	LOSS [training: 0.26807257334045825 | validation: 0.18007746536365304]
	TIME [epoch: 9.04 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6755196578600418		[learning rate: 0.0078487]
	Learning Rate: 0.00784874
	LOSS [training: 0.6755196578600418 | validation: 0.201191809769038]
	TIME [epoch: 9.05 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31112101665491226		[learning rate: 0.0078247]
	Learning Rate: 0.00782468
	LOSS [training: 0.31112101665491226 | validation: 0.48543111739440675]
	TIME [epoch: 9.05 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.508348985213117		[learning rate: 0.0078007]
	Learning Rate: 0.0078007
	LOSS [training: 0.508348985213117 | validation: 0.262214437540368]
	TIME [epoch: 9.05 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5235801066653075		[learning rate: 0.0077768]
	Learning Rate: 0.00777678
	LOSS [training: 0.5235801066653075 | validation: 0.36991284725922524]
	TIME [epoch: 9.04 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38238089210218684		[learning rate: 0.0077529]
	Learning Rate: 0.00775294
	LOSS [training: 0.38238089210218684 | validation: 0.28013171967723893]
	TIME [epoch: 9.04 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2469081339286599		[learning rate: 0.0077292]
	Learning Rate: 0.00772918
	LOSS [training: 0.2469081339286599 | validation: 0.08102619720204482]
	TIME [epoch: 9.05 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12956787198106662		[learning rate: 0.0077055]
	Learning Rate: 0.00770548
	LOSS [training: 0.12956787198106662 | validation: 0.21914842920469713]
	TIME [epoch: 9.06 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21135890182237937		[learning rate: 0.0076819]
	Learning Rate: 0.00768186
	LOSS [training: 0.21135890182237937 | validation: 0.11472402649263036]
	TIME [epoch: 9.05 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14910490588272446		[learning rate: 0.0076583]
	Learning Rate: 0.00765832
	LOSS [training: 0.14910490588272446 | validation: 0.10355597700732272]
	TIME [epoch: 9.04 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16595182219710566		[learning rate: 0.0076348]
	Learning Rate: 0.00763484
	LOSS [training: 0.16595182219710566 | validation: 0.21518772249228935]
	TIME [epoch: 9.05 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18023060772690153		[learning rate: 0.0076114]
	Learning Rate: 0.00761144
	LOSS [training: 0.18023060772690153 | validation: 0.13429261900028228]
	TIME [epoch: 9.06 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13844063132234585		[learning rate: 0.0075881]
	Learning Rate: 0.0075881
	LOSS [training: 0.13844063132234585 | validation: 0.25805358384797406]
	TIME [epoch: 9.05 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2281298519316594		[learning rate: 0.0075648]
	Learning Rate: 0.00756484
	LOSS [training: 0.2281298519316594 | validation: 0.1380139813206353]
	TIME [epoch: 9.05 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1893908285473137		[learning rate: 0.0075417]
	Learning Rate: 0.00754165
	LOSS [training: 0.1893908285473137 | validation: 0.2819354898091619]
	TIME [epoch: 9.04 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18800105513793997		[learning rate: 0.0075185]
	Learning Rate: 0.00751854
	LOSS [training: 0.18800105513793997 | validation: 0.13714982423091138]
	TIME [epoch: 9.08 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.252794401915992		[learning rate: 0.0074955]
	Learning Rate: 0.00749549
	LOSS [training: 0.252794401915992 | validation: 0.3770728835256951]
	TIME [epoch: 9.05 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37063942189445986		[learning rate: 0.0074725]
	Learning Rate: 0.00747251
	LOSS [training: 0.37063942189445986 | validation: 0.20595249703078916]
	TIME [epoch: 9.04 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.12206215714607		[learning rate: 0.0074496]
	Learning Rate: 0.00744961
	LOSS [training: 1.12206215714607 | validation: 0.4958029848992843]
	TIME [epoch: 9.04 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5267726827112592		[learning rate: 0.0074268]
	Learning Rate: 0.00742677
	LOSS [training: 0.5267726827112592 | validation: 0.40722979259135605]
	TIME [epoch: 9.06 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42347289747897954		[learning rate: 0.007404]
	Learning Rate: 0.007404
	LOSS [training: 0.42347289747897954 | validation: 0.31967887798105654]
	TIME [epoch: 9.04 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25106640159154253		[learning rate: 0.0073813]
	Learning Rate: 0.00738131
	LOSS [training: 0.25106640159154253 | validation: 0.1714535173643243]
	TIME [epoch: 9.05 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2697432544361772		[learning rate: 0.0073587]
	Learning Rate: 0.00735868
	LOSS [training: 0.2697432544361772 | validation: 1.101332627802326]
	TIME [epoch: 9.04 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4702728645348648		[learning rate: 0.0073361]
	Learning Rate: 0.00733612
	LOSS [training: 0.4702728645348648 | validation: 0.13643479106639866]
	TIME [epoch: 9.07 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15600981479705156		[learning rate: 0.0073136]
	Learning Rate: 0.00731364
	LOSS [training: 0.15600981479705156 | validation: 0.18586509551053404]
	TIME [epoch: 9.05 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.901621146066991		[learning rate: 0.0072912]
	Learning Rate: 0.00729122
	LOSS [training: 0.901621146066991 | validation: 0.40022011396872803]
	TIME [epoch: 9.05 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30933453972535685		[learning rate: 0.0072689]
	Learning Rate: 0.00726887
	LOSS [training: 0.30933453972535685 | validation: 0.27012609717432956]
	TIME [epoch: 9.05 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18192357790912392		[learning rate: 0.0072466]
	Learning Rate: 0.00724658
	LOSS [training: 0.18192357790912392 | validation: 0.2257521045048607]
	TIME [epoch: 9.05 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2459870582213625		[learning rate: 0.0072244]
	Learning Rate: 0.00722437
	LOSS [training: 0.2459870582213625 | validation: 0.296203774225524]
	TIME [epoch: 9.06 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16675698650171755		[learning rate: 0.0072022]
	Learning Rate: 0.00720222
	LOSS [training: 0.16675698650171755 | validation: 0.09190071583688844]
	TIME [epoch: 9.04 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17330878113114875		[learning rate: 0.0071801]
	Learning Rate: 0.00718015
	LOSS [training: 0.17330878113114875 | validation: 0.10315942960013166]
	TIME [epoch: 9.05 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1373469225664031		[learning rate: 0.0071581]
	Learning Rate: 0.00715814
	LOSS [training: 0.1373469225664031 | validation: 0.08864460670265037]
	TIME [epoch: 9.05 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3047618976189801		[learning rate: 0.0071362]
	Learning Rate: 0.00713619
	LOSS [training: 0.3047618976189801 | validation: 0.15943525791676913]
	TIME [epoch: 9.07 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16155534826319773		[learning rate: 0.0071143]
	Learning Rate: 0.00711432
	LOSS [training: 0.16155534826319773 | validation: 0.12011318369294717]
	TIME [epoch: 9.05 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12888126143403442		[learning rate: 0.0070925]
	Learning Rate: 0.00709251
	LOSS [training: 0.12888126143403442 | validation: 0.13438439839417654]
	TIME [epoch: 9.05 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1668894194951539		[learning rate: 0.0070708]
	Learning Rate: 0.00707077
	LOSS [training: 0.1668894194951539 | validation: 0.15168225438885258]
	TIME [epoch: 9.05 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1545206886558045		[learning rate: 0.0070491]
	Learning Rate: 0.00704909
	LOSS [training: 0.1545206886558045 | validation: 0.09605865215922635]
	TIME [epoch: 9.07 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1240426006773748		[learning rate: 0.0070275]
	Learning Rate: 0.00702749
	LOSS [training: 0.1240426006773748 | validation: 0.44075442711471824]
	TIME [epoch: 9.05 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19709107813793972		[learning rate: 0.0070059]
	Learning Rate: 0.00700594
	LOSS [training: 0.19709107813793972 | validation: 0.17180965909882925]
	TIME [epoch: 9.04 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22786464964546801		[learning rate: 0.0069845]
	Learning Rate: 0.00698447
	LOSS [training: 0.22786464964546801 | validation: 0.34712828590430633]
	TIME [epoch: 9.04 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5280245835650701		[learning rate: 0.0069631]
	Learning Rate: 0.00696306
	LOSS [training: 0.5280245835650701 | validation: 0.6533319983916439]
	TIME [epoch: 9.06 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43442962953048736		[learning rate: 0.0069417]
	Learning Rate: 0.00694171
	LOSS [training: 0.43442962953048736 | validation: 0.23609664484367737]
	TIME [epoch: 9.05 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2553321223994892		[learning rate: 0.0069204]
	Learning Rate: 0.00692043
	LOSS [training: 0.2553321223994892 | validation: 0.1467304567735772]
	TIME [epoch: 9.05 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17778419752429964		[learning rate: 0.0068992]
	Learning Rate: 0.00689922
	LOSS [training: 0.17778419752429964 | validation: 0.13189435458059637]
	TIME [epoch: 9.04 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16510834921369452		[learning rate: 0.0068781]
	Learning Rate: 0.00687807
	LOSS [training: 0.16510834921369452 | validation: 0.12700323353420395]
	TIME [epoch: 9.07 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14788487089730126		[learning rate: 0.006857]
	Learning Rate: 0.00685699
	LOSS [training: 0.14788487089730126 | validation: 0.16908005317681513]
	TIME [epoch: 9.05 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17177322263686762		[learning rate: 0.006836]
	Learning Rate: 0.00683597
	LOSS [training: 0.17177322263686762 | validation: 0.1840698984196243]
	TIME [epoch: 9.04 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17216370426859515		[learning rate: 0.006815]
	Learning Rate: 0.00681501
	LOSS [training: 0.17216370426859515 | validation: 0.12895720677353475]
	TIME [epoch: 9.05 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16798361436458267		[learning rate: 0.0067941]
	Learning Rate: 0.00679412
	LOSS [training: 0.16798361436458267 | validation: 0.21716591215270936]
	TIME [epoch: 9.06 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.200922888848577		[learning rate: 0.0067733]
	Learning Rate: 0.00677329
	LOSS [training: 0.200922888848577 | validation: 0.18589284270696071]
	TIME [epoch: 9.06 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17887604337866198		[learning rate: 0.0067525]
	Learning Rate: 0.00675253
	LOSS [training: 0.17887604337866198 | validation: 0.1374678317151523]
	TIME [epoch: 9.05 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17111273368873942		[learning rate: 0.0067318]
	Learning Rate: 0.00673183
	LOSS [training: 0.17111273368873942 | validation: 0.12022378503939685]
	TIME [epoch: 9.05 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10844294973959115		[learning rate: 0.0067112]
	Learning Rate: 0.0067112
	LOSS [training: 0.10844294973959115 | validation: 0.1403350853852396]
	TIME [epoch: 9.06 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19568951259837944		[learning rate: 0.0066906]
	Learning Rate: 0.00669062
	LOSS [training: 0.19568951259837944 | validation: 0.15721648502968438]
	TIME [epoch: 9.05 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18656314825349027		[learning rate: 0.0066701]
	Learning Rate: 0.00667012
	LOSS [training: 0.18656314825349027 | validation: 0.11827949350021331]
	TIME [epoch: 9.05 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1312575528885678		[learning rate: 0.0066497]
	Learning Rate: 0.00664967
	LOSS [training: 0.1312575528885678 | validation: 0.11053382355310207]
	TIME [epoch: 9.04 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13914571955344804		[learning rate: 0.0066293]
	Learning Rate: 0.00662928
	LOSS [training: 0.13914571955344804 | validation: 0.1109005604261294]
	TIME [epoch: 9.05 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1634274350608893		[learning rate: 0.006609]
	Learning Rate: 0.00660896
	LOSS [training: 0.1634274350608893 | validation: 0.1486342336734301]
	TIME [epoch: 9.07 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14468378420871997		[learning rate: 0.0065887]
	Learning Rate: 0.0065887
	LOSS [training: 0.14468378420871997 | validation: 0.14431076841335758]
	TIME [epoch: 9.04 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1306175967156105		[learning rate: 0.0065685]
	Learning Rate: 0.00656851
	LOSS [training: 0.1306175967156105 | validation: 0.08222616691129733]
	TIME [epoch: 9.05 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1259732252391032		[learning rate: 0.0065484]
	Learning Rate: 0.00654837
	LOSS [training: 0.1259732252391032 | validation: 0.15838478382470067]
	TIME [epoch: 9.04 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15782004606789315		[learning rate: 0.0065283]
	Learning Rate: 0.0065283
	LOSS [training: 0.15782004606789315 | validation: 0.1161686654776862]
	TIME [epoch: 9.06 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11436749909578854		[learning rate: 0.0065083]
	Learning Rate: 0.00650829
	LOSS [training: 0.11436749909578854 | validation: 0.13674208372727978]
	TIME [epoch: 9.04 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16043054560995743		[learning rate: 0.0064883]
	Learning Rate: 0.00648834
	LOSS [training: 0.16043054560995743 | validation: 0.16670678763377245]
	TIME [epoch: 9.05 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18906018661536764		[learning rate: 0.0064684]
	Learning Rate: 0.00646845
	LOSS [training: 0.18906018661536764 | validation: 0.28242216305830115]
	TIME [epoch: 9.04 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19372833137480924		[learning rate: 0.0064486]
	Learning Rate: 0.00644862
	LOSS [training: 0.19372833137480924 | validation: 0.07819208083011309]
	TIME [epoch: 9.06 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16328075150351937		[learning rate: 0.0064289]
	Learning Rate: 0.00642885
	LOSS [training: 0.16328075150351937 | validation: 0.12974890286165297]
	TIME [epoch: 9.04 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12902490729265154		[learning rate: 0.0064091]
	Learning Rate: 0.00640914
	LOSS [training: 0.12902490729265154 | validation: 0.1075078229152548]
	TIME [epoch: 9.05 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12810276117827982		[learning rate: 0.0063895]
	Learning Rate: 0.0063895
	LOSS [training: 0.12810276117827982 | validation: 0.09435555869987514]
	TIME [epoch: 9.05 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11184172753713213		[learning rate: 0.0063699]
	Learning Rate: 0.00636991
	LOSS [training: 0.11184172753713213 | validation: 0.0766084145817241]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_647.pth
	Model improved!!!
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18010681066788084		[learning rate: 0.0063504]
	Learning Rate: 0.00635038
	LOSS [training: 0.18010681066788084 | validation: 0.1722459771808114]
	TIME [epoch: 9.05 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1371481525892603		[learning rate: 0.0063309]
	Learning Rate: 0.00633092
	LOSS [training: 0.1371481525892603 | validation: 0.2311212174333111]
	TIME [epoch: 9.05 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21200273764107808		[learning rate: 0.0063115]
	Learning Rate: 0.00631151
	LOSS [training: 0.21200273764107808 | validation: 0.18160797715974825]
	TIME [epoch: 9.05 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17536139562925873		[learning rate: 0.0062922]
	Learning Rate: 0.00629216
	LOSS [training: 0.17536139562925873 | validation: 0.1297666486526708]
	TIME [epoch: 9.05 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1925421315474321		[learning rate: 0.0062729]
	Learning Rate: 0.00627288
	LOSS [training: 0.1925421315474321 | validation: 0.1716711185251409]
	TIME [epoch: 9.06 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21880290688796408		[learning rate: 0.0062536]
	Learning Rate: 0.00625365
	LOSS [training: 0.21880290688796408 | validation: 0.18809030698454865]
	TIME [epoch: 9.04 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.185831156910388		[learning rate: 0.0062345]
	Learning Rate: 0.00623448
	LOSS [training: 0.185831156910388 | validation: 0.1139062550620697]
	TIME [epoch: 9.05 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14745966185330173		[learning rate: 0.0062154]
	Learning Rate: 0.00621536
	LOSS [training: 0.14745966185330173 | validation: 0.19690706201766303]
	TIME [epoch: 9.05 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18242824557774676		[learning rate: 0.0061963]
	Learning Rate: 0.00619631
	LOSS [training: 0.18242824557774676 | validation: 0.1518290454410211]
	TIME [epoch: 9.07 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20431325460364952		[learning rate: 0.0061773]
	Learning Rate: 0.00617732
	LOSS [training: 0.20431325460364952 | validation: 0.08516082727844401]
	TIME [epoch: 9.05 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10525986013758118		[learning rate: 0.0061584]
	Learning Rate: 0.00615838
	LOSS [training: 0.10525986013758118 | validation: 0.0727440790511886]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_658.pth
	Model improved!!!
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1352355147442303		[learning rate: 0.0061395]
	Learning Rate: 0.0061395
	LOSS [training: 0.1352355147442303 | validation: 0.1085162649097455]
	TIME [epoch: 9.05 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11555509250523585		[learning rate: 0.0061207]
	Learning Rate: 0.00612068
	LOSS [training: 0.11555509250523585 | validation: 0.11659328165350598]
	TIME [epoch: 9.06 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2137045256007414		[learning rate: 0.0061019]
	Learning Rate: 0.00610192
	LOSS [training: 0.2137045256007414 | validation: 0.11184292027325854]
	TIME [epoch: 9.05 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13070372405286793		[learning rate: 0.0060832]
	Learning Rate: 0.00608322
	LOSS [training: 0.13070372405286793 | validation: 0.11219089734396798]
	TIME [epoch: 9.04 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14796810838760474		[learning rate: 0.0060646]
	Learning Rate: 0.00606457
	LOSS [training: 0.14796810838760474 | validation: 0.10936183591684537]
	TIME [epoch: 9.04 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15555413234873366		[learning rate: 0.006046]
	Learning Rate: 0.00604598
	LOSS [training: 0.15555413234873366 | validation: 0.15691516122832624]
	TIME [epoch: 9.04 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1703227304351216		[learning rate: 0.0060274]
	Learning Rate: 0.00602745
	LOSS [training: 0.1703227304351216 | validation: 0.1345030502301332]
	TIME [epoch: 9.07 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15529840286149676		[learning rate: 0.006009]
	Learning Rate: 0.00600897
	LOSS [training: 0.15529840286149676 | validation: 0.15824575895512544]
	TIME [epoch: 9.04 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1646195414752684		[learning rate: 0.0059905]
	Learning Rate: 0.00599055
	LOSS [training: 0.1646195414752684 | validation: 0.13038586525573775]
	TIME [epoch: 9.05 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12765992372519205		[learning rate: 0.0059722]
	Learning Rate: 0.00597219
	LOSS [training: 0.12765992372519205 | validation: 0.09143720793126603]
	TIME [epoch: 9.04 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1341618546777562		[learning rate: 0.0059539]
	Learning Rate: 0.00595388
	LOSS [training: 0.1341618546777562 | validation: 0.3048197919705903]
	TIME [epoch: 9.06 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2585239931978441		[learning rate: 0.0059356]
	Learning Rate: 0.00593563
	LOSS [training: 0.2585239931978441 | validation: 0.12927794294346087]
	TIME [epoch: 9.04 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16334615089615703		[learning rate: 0.0059174]
	Learning Rate: 0.00591743
	LOSS [training: 0.16334615089615703 | validation: 0.1494897819427657]
	TIME [epoch: 9.04 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15036322174131903		[learning rate: 0.0058993]
	Learning Rate: 0.00589929
	LOSS [training: 0.15036322174131903 | validation: 0.10087392338114518]
	TIME [epoch: 9.05 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1402511384703784		[learning rate: 0.0058812]
	Learning Rate: 0.00588121
	LOSS [training: 0.1402511384703784 | validation: 0.16528343167881454]
	TIME [epoch: 9.07 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14203125652299475		[learning rate: 0.0058632]
	Learning Rate: 0.00586318
	LOSS [training: 0.14203125652299475 | validation: 0.1172208881443603]
	TIME [epoch: 9.05 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15398560910858777		[learning rate: 0.0058452]
	Learning Rate: 0.00584521
	LOSS [training: 0.15398560910858777 | validation: 0.13607848129973985]
	TIME [epoch: 9.06 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15030549957210668		[learning rate: 0.0058273]
	Learning Rate: 0.00582729
	LOSS [training: 0.15030549957210668 | validation: 0.11654009235886134]
	TIME [epoch: 9.06 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14056215252572712		[learning rate: 0.0058094]
	Learning Rate: 0.00580943
	LOSS [training: 0.14056215252572712 | validation: 0.131402806097022]
	TIME [epoch: 9.07 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1240576518800138		[learning rate: 0.0057916]
	Learning Rate: 0.00579162
	LOSS [training: 0.1240576518800138 | validation: 0.09899011792074348]
	TIME [epoch: 9.06 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11538449924988117		[learning rate: 0.0057739]
	Learning Rate: 0.00577387
	LOSS [training: 0.11538449924988117 | validation: 0.05852271946853565]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_679.pth
	Model improved!!!
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12912356261762264		[learning rate: 0.0057562]
	Learning Rate: 0.00575617
	LOSS [training: 0.12912356261762264 | validation: 0.1600763993145932]
	TIME [epoch: 9.05 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14400684973745262		[learning rate: 0.0057385]
	Learning Rate: 0.00573852
	LOSS [training: 0.14400684973745262 | validation: 0.11285157814945401]
	TIME [epoch: 9.06 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14106927974967962		[learning rate: 0.0057209]
	Learning Rate: 0.00572093
	LOSS [training: 0.14106927974967962 | validation: 0.10720988548358053]
	TIME [epoch: 9.07 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15918296780401855		[learning rate: 0.0057034]
	Learning Rate: 0.00570339
	LOSS [training: 0.15918296780401855 | validation: 0.1365591852314802]
	TIME [epoch: 9.05 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1494848086839635		[learning rate: 0.0056859]
	Learning Rate: 0.00568591
	LOSS [training: 0.1494848086839635 | validation: 0.110572318668695]
	TIME [epoch: 9.05 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1627400759495451		[learning rate: 0.0056685]
	Learning Rate: 0.00566848
	LOSS [training: 0.1627400759495451 | validation: 0.10097772098485436]
	TIME [epoch: 9.05 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13338394690140948		[learning rate: 0.0056511]
	Learning Rate: 0.0056511
	LOSS [training: 0.13338394690140948 | validation: 0.1095237804326196]
	TIME [epoch: 9.07 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13838398154193815		[learning rate: 0.0056338]
	Learning Rate: 0.00563378
	LOSS [training: 0.13838398154193815 | validation: 0.14903207157249043]
	TIME [epoch: 9.05 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13757803049091447		[learning rate: 0.0056165]
	Learning Rate: 0.00561651
	LOSS [training: 0.13757803049091447 | validation: 0.14308412082379218]
	TIME [epoch: 9.04 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14941886765822843		[learning rate: 0.0055993]
	Learning Rate: 0.00559929
	LOSS [training: 0.14941886765822843 | validation: 0.13502239397744314]
	TIME [epoch: 9.05 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1223199796127417		[learning rate: 0.0055821]
	Learning Rate: 0.00558213
	LOSS [training: 0.1223199796127417 | validation: 0.05866917085691713]
	TIME [epoch: 9.06 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1678657533854667		[learning rate: 0.005565]
	Learning Rate: 0.00556502
	LOSS [training: 0.1678657533854667 | validation: 0.10519172556871781]
	TIME [epoch: 9.04 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07740180080134632		[learning rate: 0.005548]
	Learning Rate: 0.00554796
	LOSS [training: 0.07740180080134632 | validation: 0.08353272722029263]
	TIME [epoch: 9.04 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11953365323600587		[learning rate: 0.005531]
	Learning Rate: 0.00553095
	LOSS [training: 0.11953365323600587 | validation: 0.08380156742676254]
	TIME [epoch: 9.04 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08953303895243842		[learning rate: 0.005514]
	Learning Rate: 0.005514
	LOSS [training: 0.08953303895243842 | validation: 0.07505370630485868]
	TIME [epoch: 9.05 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06215505406566988		[learning rate: 0.0054971]
	Learning Rate: 0.0054971
	LOSS [training: 0.06215505406566988 | validation: 0.23082371335802757]
	TIME [epoch: 9.06 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15364365794860246		[learning rate: 0.0054802]
	Learning Rate: 0.00548025
	LOSS [training: 0.15364365794860246 | validation: 0.07772341826805856]
	TIME [epoch: 9.04 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09598141992666862		[learning rate: 0.0054634]
	Learning Rate: 0.00546345
	LOSS [training: 0.09598141992666862 | validation: 0.07478081888552571]
	TIME [epoch: 9.04 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09656177608946209		[learning rate: 0.0054467]
	Learning Rate: 0.0054467
	LOSS [training: 0.09656177608946209 | validation: 0.12808722978344117]
	TIME [epoch: 9.06 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13893388789215538		[learning rate: 0.00543]
	Learning Rate: 0.00543
	LOSS [training: 0.13893388789215538 | validation: 0.3824996682646578]
	TIME [epoch: 9.05 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22832438596558302		[learning rate: 0.0054134]
	Learning Rate: 0.00541336
	LOSS [training: 0.22832438596558302 | validation: 0.08029194805117934]
	TIME [epoch: 9.04 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14102371093480065		[learning rate: 0.0053968]
	Learning Rate: 0.00539676
	LOSS [training: 0.14102371093480065 | validation: 0.05602698716679475]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_701.pth
	Model improved!!!
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10115732496273118		[learning rate: 0.0053802]
	Learning Rate: 0.00538022
	LOSS [training: 0.10115732496273118 | validation: 0.06490740106502624]
	TIME [epoch: 9.05 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10296932068225406		[learning rate: 0.0053637]
	Learning Rate: 0.00536373
	LOSS [training: 0.10296932068225406 | validation: 0.09797066756296582]
	TIME [epoch: 9.06 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10864585432355209		[learning rate: 0.0053473]
	Learning Rate: 0.00534728
	LOSS [training: 0.10864585432355209 | validation: 0.06782504930373724]
	TIME [epoch: 9.04 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08309895962597035		[learning rate: 0.0053309]
	Learning Rate: 0.00533089
	LOSS [training: 0.08309895962597035 | validation: 0.11244342229050691]
	TIME [epoch: 9.04 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11788331485452666		[learning rate: 0.0053146]
	Learning Rate: 0.00531455
	LOSS [training: 0.11788331485452666 | validation: 0.10963657344045706]
	TIME [epoch: 9.04 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1366470694030193		[learning rate: 0.0052983]
	Learning Rate: 0.00529826
	LOSS [training: 0.1366470694030193 | validation: 0.14397677813180626]
	TIME [epoch: 9.05 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15401902310923277		[learning rate: 0.005282]
	Learning Rate: 0.00528202
	LOSS [training: 0.15401902310923277 | validation: 0.14053252976026756]
	TIME [epoch: 9.05 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13426116919455874		[learning rate: 0.0052658]
	Learning Rate: 0.00526583
	LOSS [training: 0.13426116919455874 | validation: 0.1040327006391877]
	TIME [epoch: 9.04 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10016887225760547		[learning rate: 0.0052497]
	Learning Rate: 0.00524969
	LOSS [training: 0.10016887225760547 | validation: 0.08884646452960471]
	TIME [epoch: 9.04 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07715553996193628		[learning rate: 0.0052336]
	Learning Rate: 0.00523359
	LOSS [training: 0.07715553996193628 | validation: 0.0762761219607643]
	TIME [epoch: 9.05 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12425516776772969		[learning rate: 0.0052176]
	Learning Rate: 0.00521755
	LOSS [training: 0.12425516776772969 | validation: 0.14776082857941142]
	TIME [epoch: 9.06 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10412088738705043		[learning rate: 0.0052016]
	Learning Rate: 0.00520156
	LOSS [training: 0.10412088738705043 | validation: 0.18362579477055052]
	TIME [epoch: 9.04 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2497405247358458		[learning rate: 0.0051856]
	Learning Rate: 0.00518561
	LOSS [training: 0.2497405247358458 | validation: 0.26105178660129486]
	TIME [epoch: 9.04 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2331347855219375		[learning rate: 0.0051697]
	Learning Rate: 0.00516972
	LOSS [training: 0.2331347855219375 | validation: 0.09994763506964242]
	TIME [epoch: 9.04 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10312177451888989		[learning rate: 0.0051539]
	Learning Rate: 0.00515387
	LOSS [training: 0.10312177451888989 | validation: 0.2684152111993117]
	TIME [epoch: 9.06 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42497717033048954		[learning rate: 0.0051381]
	Learning Rate: 0.00513807
	LOSS [training: 0.42497717033048954 | validation: 0.3554108244059607]
	TIME [epoch: 9.04 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32393049746031444		[learning rate: 0.0051223]
	Learning Rate: 0.00512232
	LOSS [training: 0.32393049746031444 | validation: 0.10036830258782062]
	TIME [epoch: 9.04 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2641997710862937		[learning rate: 0.0051066]
	Learning Rate: 0.00510662
	LOSS [training: 0.2641997710862937 | validation: 0.10401691805820543]
	TIME [epoch: 9.04 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36916691195700285		[learning rate: 0.005091]
	Learning Rate: 0.00509096
	LOSS [training: 0.36916691195700285 | validation: 0.6686894988628922]
	TIME [epoch: 9.06 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.672375023100059		[learning rate: 0.0050754]
	Learning Rate: 0.00507536
	LOSS [training: 0.672375023100059 | validation: 1.1468234701763804]
	TIME [epoch: 9.05 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9931284379481224		[learning rate: 0.0050598]
	Learning Rate: 0.0050598
	LOSS [training: 0.9931284379481224 | validation: 0.3079531323007599]
	TIME [epoch: 9.04 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5740915735823459		[learning rate: 0.0050443]
	Learning Rate: 0.00504429
	LOSS [training: 0.5740915735823459 | validation: 0.2530680093774859]
	TIME [epoch: 9.03 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24603248488159224		[learning rate: 0.0050288]
	Learning Rate: 0.00502883
	LOSS [training: 0.24603248488159224 | validation: 0.17237757081200716]
	TIME [epoch: 9.06 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14738203415110437		[learning rate: 0.0050134]
	Learning Rate: 0.00501341
	LOSS [training: 0.14738203415110437 | validation: 0.0879121753924321]
	TIME [epoch: 9.05 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08225649026849884		[learning rate: 0.004998]
	Learning Rate: 0.00499804
	LOSS [training: 0.08225649026849884 | validation: 0.052324845852332866]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22933113012185688		[learning rate: 0.0049827]
	Learning Rate: 0.00498272
	LOSS [training: 0.22933113012185688 | validation: 0.1946238962773239]
	TIME [epoch: 9.04 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.329673545276379		[learning rate: 0.0049674]
	Learning Rate: 0.00496745
	LOSS [training: 0.329673545276379 | validation: 0.45353425243230927]
	TIME [epoch: 9.06 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2582941985401581		[learning rate: 0.0049522]
	Learning Rate: 0.00495222
	LOSS [training: 0.2582941985401581 | validation: 0.19716813150210197]
	TIME [epoch: 9.04 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14362469891155208		[learning rate: 0.004937]
	Learning Rate: 0.00493704
	LOSS [training: 0.14362469891155208 | validation: 0.0537394828974659]
	TIME [epoch: 9.04 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08186312872085404		[learning rate: 0.0049219]
	Learning Rate: 0.00492191
	LOSS [training: 0.08186312872085404 | validation: 0.07632550612374475]
	TIME [epoch: 9.05 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1017166420593181		[learning rate: 0.0049068]
	Learning Rate: 0.00490682
	LOSS [training: 0.1017166420593181 | validation: 0.1269931022594976]
	TIME [epoch: 9.03 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1080703788993436		[learning rate: 0.0048918]
	Learning Rate: 0.00489178
	LOSS [training: 0.1080703788993436 | validation: 0.05808092979695012]
	TIME [epoch: 9.06 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15837082802743377		[learning rate: 0.0048768]
	Learning Rate: 0.00487678
	LOSS [training: 0.15837082802743377 | validation: 0.07507517144116815]
	TIME [epoch: 9.03 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12112094561197731		[learning rate: 0.0048618]
	Learning Rate: 0.00486183
	LOSS [training: 0.12112094561197731 | validation: 0.1349414987035894]
	TIME [epoch: 9.04 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12155017169915798		[learning rate: 0.0048469]
	Learning Rate: 0.00484693
	LOSS [training: 0.12155017169915798 | validation: 0.08734597124354672]
	TIME [epoch: 9.03 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10987680419702606		[learning rate: 0.0048321]
	Learning Rate: 0.00483207
	LOSS [training: 0.10987680419702606 | validation: 0.07207438809801953]
	TIME [epoch: 9.06 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09283260499548898		[learning rate: 0.0048173]
	Learning Rate: 0.00481726
	LOSS [training: 0.09283260499548898 | validation: 0.08508584490623697]
	TIME [epoch: 9.04 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12323770086623671		[learning rate: 0.0048025]
	Learning Rate: 0.00480249
	LOSS [training: 0.12323770086623671 | validation: 0.09848276955791055]
	TIME [epoch: 9.03 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09925788839850799		[learning rate: 0.0047878]
	Learning Rate: 0.00478777
	LOSS [training: 0.09925788839850799 | validation: 0.09527713010517341]
	TIME [epoch: 9.03 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09925618419500273		[learning rate: 0.0047731]
	Learning Rate: 0.00477309
	LOSS [training: 0.09925618419500273 | validation: 0.07202378354442804]
	TIME [epoch: 9.06 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07813425330220072		[learning rate: 0.0047585]
	Learning Rate: 0.00475846
	LOSS [training: 0.07813425330220072 | validation: 0.07634453517532447]
	TIME [epoch: 9.04 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15181063789118826		[learning rate: 0.0047439]
	Learning Rate: 0.00474388
	LOSS [training: 0.15181063789118826 | validation: 0.09594135988539257]
	TIME [epoch: 9.04 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0824917318375035		[learning rate: 0.0047293]
	Learning Rate: 0.00472933
	LOSS [training: 0.0824917318375035 | validation: 0.05879508765784419]
	TIME [epoch: 9.04 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09287856179453927		[learning rate: 0.0047148]
	Learning Rate: 0.00471484
	LOSS [training: 0.09287856179453927 | validation: 0.05286067039835703]
	TIME [epoch: 9.06 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08060901126302977		[learning rate: 0.0047004]
	Learning Rate: 0.00470038
	LOSS [training: 0.08060901126302977 | validation: 0.08513230145114664]
	TIME [epoch: 9.04 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08760411701454253		[learning rate: 0.004686]
	Learning Rate: 0.00468598
	LOSS [training: 0.08760411701454253 | validation: 0.1577580461140738]
	TIME [epoch: 9.03 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11479188885241791		[learning rate: 0.0046716]
	Learning Rate: 0.00467161
	LOSS [training: 0.11479188885241791 | validation: 0.06400965734573755]
	TIME [epoch: 9.03 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11012166548825844		[learning rate: 0.0046573]
	Learning Rate: 0.00465729
	LOSS [training: 0.11012166548825844 | validation: 0.10922882866585026]
	TIME [epoch: 9.05 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.137356900477656		[learning rate: 0.004643]
	Learning Rate: 0.00464301
	LOSS [training: 0.137356900477656 | validation: 0.07752389315581135]
	TIME [epoch: 9.05 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11093057388209511		[learning rate: 0.0046288]
	Learning Rate: 0.00462878
	LOSS [training: 0.11093057388209511 | validation: 0.11998659302694839]
	TIME [epoch: 9.04 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10196620693116865		[learning rate: 0.0046146]
	Learning Rate: 0.00461459
	LOSS [training: 0.10196620693116865 | validation: 0.1342660894812146]
	TIME [epoch: 9.04 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15267200735981973		[learning rate: 0.0046004]
	Learning Rate: 0.00460045
	LOSS [training: 0.15267200735981973 | validation: 0.1339472093881957]
	TIME [epoch: 9.03 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08280033793183203		[learning rate: 0.0045863]
	Learning Rate: 0.00458634
	LOSS [training: 0.08280033793183203 | validation: 0.086697467967201]
	TIME [epoch: 9.06 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09730329481169893		[learning rate: 0.0045723]
	Learning Rate: 0.00457229
	LOSS [training: 0.09730329481169893 | validation: 0.05847505822561581]
	TIME [epoch: 9.04 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1937947162456723		[learning rate: 0.0045583]
	Learning Rate: 0.00455827
	LOSS [training: 0.1937947162456723 | validation: 0.16812203647430368]
	TIME [epoch: 9.03 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1368026962146159		[learning rate: 0.0045443]
	Learning Rate: 0.0045443
	LOSS [training: 0.1368026962146159 | validation: 0.13836229231738487]
	TIME [epoch: 9.03 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14561847428241753		[learning rate: 0.0045304]
	Learning Rate: 0.00453037
	LOSS [training: 0.14561847428241753 | validation: 0.12880463337969938]
	TIME [epoch: 9.06 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4133512069733758		[learning rate: 0.0045165]
	Learning Rate: 0.00451648
	LOSS [training: 0.4133512069733758 | validation: 0.5067529657073241]
	TIME [epoch: 9.04 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23183298219511572		[learning rate: 0.0045026]
	Learning Rate: 0.00450263
	LOSS [training: 0.23183298219511572 | validation: 0.12430728111871589]
	TIME [epoch: 9.04 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1975190361928383		[learning rate: 0.0044888]
	Learning Rate: 0.00448883
	LOSS [training: 0.1975190361928383 | validation: 0.20161718758405522]
	TIME [epoch: 9.03 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14591564819657749		[learning rate: 0.0044751]
	Learning Rate: 0.00447507
	LOSS [training: 0.14591564819657749 | validation: 0.09294464548537547]
	TIME [epoch: 9.05 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10770229664995153		[learning rate: 0.0044614]
	Learning Rate: 0.00446135
	LOSS [training: 0.10770229664995153 | validation: 0.05379706905704862]
	TIME [epoch: 9.04 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11964920580161027		[learning rate: 0.0044477]
	Learning Rate: 0.00444768
	LOSS [training: 0.11964920580161027 | validation: 0.059050968262956235]
	TIME [epoch: 9.04 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1414380408348455		[learning rate: 0.004434]
	Learning Rate: 0.00443404
	LOSS [training: 0.1414380408348455 | validation: 0.1637145477801002]
	TIME [epoch: 9.04 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09578561579614672		[learning rate: 0.0044205]
	Learning Rate: 0.00442045
	LOSS [training: 0.09578561579614672 | validation: 0.07437178441975356]
	TIME [epoch: 9.05 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13244138904921568		[learning rate: 0.0044069]
	Learning Rate: 0.0044069
	LOSS [training: 0.13244138904921568 | validation: 0.23550014666647479]
	TIME [epoch: 9.05 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14520205834797242		[learning rate: 0.0043934]
	Learning Rate: 0.00439339
	LOSS [training: 0.14520205834797242 | validation: 0.1211607185786055]
	TIME [epoch: 9.04 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13592353778460864		[learning rate: 0.0043799]
	Learning Rate: 0.00437992
	LOSS [training: 0.13592353778460864 | validation: 0.20999718633942713]
	TIME [epoch: 9.04 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14195733842872438		[learning rate: 0.0043665]
	Learning Rate: 0.0043665
	LOSS [training: 0.14195733842872438 | validation: 0.14019746153393423]
	TIME [epoch: 9.05 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5360560410124933		[learning rate: 0.0043531]
	Learning Rate: 0.00435311
	LOSS [training: 0.5360560410124933 | validation: 0.2969862918279576]
	TIME [epoch: 9.06 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19487611599857058		[learning rate: 0.0043398]
	Learning Rate: 0.00433977
	LOSS [training: 0.19487611599857058 | validation: 0.1302493550137478]
	TIME [epoch: 9.04 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2667113953346477		[learning rate: 0.0043265]
	Learning Rate: 0.00432647
	LOSS [training: 0.2667113953346477 | validation: 0.609267361065049]
	TIME [epoch: 9.04 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.593212580694812		[learning rate: 0.0043132]
	Learning Rate: 0.0043132
	LOSS [training: 0.593212580694812 | validation: 0.13528194245362202]
	TIME [epoch: 9.04 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1668230187261132		[learning rate: 0.0043]
	Learning Rate: 0.00429998
	LOSS [training: 0.1668230187261132 | validation: 0.10972961471625142]
	TIME [epoch: 9.05 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14376144935457968		[learning rate: 0.0042868]
	Learning Rate: 0.0042868
	LOSS [training: 0.14376144935457968 | validation: 0.12290099508975134]
	TIME [epoch: 9.04 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33206655047463746		[learning rate: 0.0042737]
	Learning Rate: 0.00427366
	LOSS [training: 0.33206655047463746 | validation: 0.22852675295489328]
	TIME [epoch: 9.04 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6028833185450138		[learning rate: 0.0042606]
	Learning Rate: 0.00426056
	LOSS [training: 0.6028833185450138 | validation: 0.7147638152789912]
	TIME [epoch: 9.04 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42867731312311286		[learning rate: 0.0042475]
	Learning Rate: 0.0042475
	LOSS [training: 0.42867731312311286 | validation: 0.3302489589674583]
	TIME [epoch: 9.06 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.382296905859354		[learning rate: 0.0042345]
	Learning Rate: 0.00423448
	LOSS [training: 0.382296905859354 | validation: 0.23811487587141633]
	TIME [epoch: 9.05 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3077449024178406		[learning rate: 0.0042215]
	Learning Rate: 0.0042215
	LOSS [training: 0.3077449024178406 | validation: 0.18155614472055404]
	TIME [epoch: 9.05 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3225221949796878		[learning rate: 0.0042086]
	Learning Rate: 0.00420856
	LOSS [training: 0.3225221949796878 | validation: 0.19095855260879907]
	TIME [epoch: 9.05 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23430980466737888		[learning rate: 0.0041957]
	Learning Rate: 0.00419566
	LOSS [training: 0.23430980466737888 | validation: 0.1935227130722702]
	TIME [epoch: 9.05 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1969877715176629		[learning rate: 0.0041828]
	Learning Rate: 0.0041828
	LOSS [training: 0.1969877715176629 | validation: 0.4869868998579663]
	TIME [epoch: 9.05 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.328297977580852		[learning rate: 0.00417]
	Learning Rate: 0.00416997
	LOSS [training: 0.328297977580852 | validation: 0.1108838312203615]
	TIME [epoch: 9.05 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12958723986462536		[learning rate: 0.0041572]
	Learning Rate: 0.00415719
	LOSS [training: 0.12958723986462536 | validation: 0.19507596180707912]
	TIME [epoch: 9.05 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2078270754594287		[learning rate: 0.0041444]
	Learning Rate: 0.00414445
	LOSS [training: 0.2078270754594287 | validation: 0.08349534487481217]
	TIME [epoch: 9.07 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0858034851299349		[learning rate: 0.0041317]
	Learning Rate: 0.00413174
	LOSS [training: 0.0858034851299349 | validation: 0.0646595738828047]
	TIME [epoch: 9.05 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14442781995589335		[learning rate: 0.0041191]
	Learning Rate: 0.00411908
	LOSS [training: 0.14442781995589335 | validation: 0.1679028610490975]
	TIME [epoch: 9.05 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13954959054877486		[learning rate: 0.0041065]
	Learning Rate: 0.00410645
	LOSS [training: 0.13954959054877486 | validation: 0.10788894027743157]
	TIME [epoch: 9.05 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11682319887305752		[learning rate: 0.0040939]
	Learning Rate: 0.00409386
	LOSS [training: 0.11682319887305752 | validation: 0.11408742839176314]
	TIME [epoch: 9.06 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16378582785525797		[learning rate: 0.0040813]
	Learning Rate: 0.00408131
	LOSS [training: 0.16378582785525797 | validation: 0.10506882851136928]
	TIME [epoch: 9.06 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1338983041265515		[learning rate: 0.0040688]
	Learning Rate: 0.0040688
	LOSS [training: 0.1338983041265515 | validation: 0.09368135718420717]
	TIME [epoch: 9.05 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07136643835921584		[learning rate: 0.0040563]
	Learning Rate: 0.00405633
	LOSS [training: 0.07136643835921584 | validation: 0.08669830092884143]
	TIME [epoch: 9.05 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08669443464692848		[learning rate: 0.0040439]
	Learning Rate: 0.0040439
	LOSS [training: 0.08669443464692848 | validation: 0.062088571295658396]
	TIME [epoch: 9.06 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08035250735536534		[learning rate: 0.0040315]
	Learning Rate: 0.0040315
	LOSS [training: 0.08035250735536534 | validation: 0.06964887219476534]
	TIME [epoch: 9.06 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09614611971288527		[learning rate: 0.0040191]
	Learning Rate: 0.00401914
	LOSS [training: 0.09614611971288527 | validation: 0.19128221603447398]
	TIME [epoch: 9.05 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09147538376484353		[learning rate: 0.0040068]
	Learning Rate: 0.00400682
	LOSS [training: 0.09147538376484353 | validation: 0.05439937172956558]
	TIME [epoch: 9.05 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056231103519904124		[learning rate: 0.0039945]
	Learning Rate: 0.00399454
	LOSS [training: 0.056231103519904124 | validation: 0.05515733151375034]
	TIME [epoch: 9.05 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06815431155298592		[learning rate: 0.0039823]
	Learning Rate: 0.00398229
	LOSS [training: 0.06815431155298592 | validation: 0.0819789650185441]
	TIME [epoch: 9.07 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0748343921164946		[learning rate: 0.0039701]
	Learning Rate: 0.00397009
	LOSS [training: 0.0748343921164946 | validation: 0.046269186478835544]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_801.pth
	Model improved!!!
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07045016045738349		[learning rate: 0.0039579]
	Learning Rate: 0.00395792
	LOSS [training: 0.07045016045738349 | validation: 0.07913205800139742]
	TIME [epoch: 9.05 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06524763403093295		[learning rate: 0.0039458]
	Learning Rate: 0.00394578
	LOSS [training: 0.06524763403093295 | validation: 0.08059949749475265]
	TIME [epoch: 9.04 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10398608183427405		[learning rate: 0.0039337]
	Learning Rate: 0.00393369
	LOSS [training: 0.10398608183427405 | validation: 0.09026156405436334]
	TIME [epoch: 9.06 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14174768524435258		[learning rate: 0.0039216]
	Learning Rate: 0.00392163
	LOSS [training: 0.14174768524435258 | validation: 0.11034250698373357]
	TIME [epoch: 9.05 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11095993528595023		[learning rate: 0.0039096]
	Learning Rate: 0.00390961
	LOSS [training: 0.11095993528595023 | validation: 0.06337885906428309]
	TIME [epoch: 9.04 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09652734659979709		[learning rate: 0.0038976]
	Learning Rate: 0.00389762
	LOSS [training: 0.09652734659979709 | validation: 0.06073546477347667]
	TIME [epoch: 9.06 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12223117910965357		[learning rate: 0.0038857]
	Learning Rate: 0.00388568
	LOSS [training: 0.12223117910965357 | validation: 0.10744903248576285]
	TIME [epoch: 9.06 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09067576051889677		[learning rate: 0.0038738]
	Learning Rate: 0.00387377
	LOSS [training: 0.09067576051889677 | validation: 0.1223301297547715]
	TIME [epoch: 9.06 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1210585161244054		[learning rate: 0.0038619]
	Learning Rate: 0.00386189
	LOSS [training: 0.1210585161244054 | validation: 0.050368943809694026]
	TIME [epoch: 9.05 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07219007424280968		[learning rate: 0.0038501]
	Learning Rate: 0.00385005
	LOSS [training: 0.07219007424280968 | validation: 0.054332455389893904]
	TIME [epoch: 9.04 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07987940081742696		[learning rate: 0.0038383]
	Learning Rate: 0.00383825
	LOSS [training: 0.07987940081742696 | validation: 0.0601558516482381]
	TIME [epoch: 9.04 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07578915087671652		[learning rate: 0.0038265]
	Learning Rate: 0.00382648
	LOSS [training: 0.07578915087671652 | validation: 0.044867769174564684]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_813.pth
	Model improved!!!
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11203386858541346		[learning rate: 0.0038148]
	Learning Rate: 0.00381476
	LOSS [training: 0.11203386858541346 | validation: 0.0414084031899368]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_814.pth
	Model improved!!!
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07001549809334594		[learning rate: 0.0038031]
	Learning Rate: 0.00380306
	LOSS [training: 0.07001549809334594 | validation: 0.11173176527099224]
	TIME [epoch: 9.04 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09445875711605375		[learning rate: 0.0037914]
	Learning Rate: 0.0037914
	LOSS [training: 0.09445875711605375 | validation: 0.05616779217237851]
	TIME [epoch: 9.04 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09115868545342413		[learning rate: 0.0037798]
	Learning Rate: 0.00377978
	LOSS [training: 0.09115868545342413 | validation: 0.110066048622225]
	TIME [epoch: 9.06 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12769454332131586		[learning rate: 0.0037682]
	Learning Rate: 0.00376819
	LOSS [training: 0.12769454332131586 | validation: 0.049251927742559896]
	TIME [epoch: 9.04 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07591728404051148		[learning rate: 0.0037566]
	Learning Rate: 0.00375664
	LOSS [training: 0.07591728404051148 | validation: 0.046861336335248235]
	TIME [epoch: 9.04 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06599667541653173		[learning rate: 0.0037451]
	Learning Rate: 0.00374513
	LOSS [training: 0.06599667541653173 | validation: 0.06452286304043586]
	TIME [epoch: 9.04 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0721437752911174		[learning rate: 0.0037336]
	Learning Rate: 0.00373365
	LOSS [training: 0.0721437752911174 | validation: 0.04299478957086983]
	TIME [epoch: 9.05 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09963165988804476		[learning rate: 0.0037222]
	Learning Rate: 0.0037222
	LOSS [training: 0.09963165988804476 | validation: 0.12495260699257033]
	TIME [epoch: 9.05 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10349097245631207		[learning rate: 0.0037108]
	Learning Rate: 0.00371079
	LOSS [training: 0.10349097245631207 | validation: 0.1503659939097517]
	TIME [epoch: 9.04 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11024511292674082		[learning rate: 0.0036994]
	Learning Rate: 0.00369942
	LOSS [training: 0.11024511292674082 | validation: 0.03622359031289164]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_824.pth
	Model improved!!!
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06443982053394799		[learning rate: 0.0036881]
	Learning Rate: 0.00368808
	LOSS [training: 0.06443982053394799 | validation: 0.04839703340002034]
	TIME [epoch: 9.05 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08701437681065372		[learning rate: 0.0036768]
	Learning Rate: 0.00367677
	LOSS [training: 0.08701437681065372 | validation: 0.13777508133698363]
	TIME [epoch: 9.05 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19115611683509268		[learning rate: 0.0036655]
	Learning Rate: 0.0036655
	LOSS [training: 0.19115611683509268 | validation: 0.13259228842346982]
	TIME [epoch: 9.04 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16082751817712165		[learning rate: 0.0036543]
	Learning Rate: 0.00365426
	LOSS [training: 0.16082751817712165 | validation: 0.1312966429777487]
	TIME [epoch: 9.04 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1197839823049928		[learning rate: 0.0036431]
	Learning Rate: 0.00364306
	LOSS [training: 0.1197839823049928 | validation: 0.14234427596440885]
	TIME [epoch: 9.04 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1023447654060333		[learning rate: 0.0036319]
	Learning Rate: 0.0036319
	LOSS [training: 0.1023447654060333 | validation: 0.05392638510012322]
	TIME [epoch: 9.06 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1027880634114812		[learning rate: 0.0036208]
	Learning Rate: 0.00362076
	LOSS [training: 0.1027880634114812 | validation: 0.09662622283344127]
	TIME [epoch: 9.04 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08807928244374391		[learning rate: 0.0036097]
	Learning Rate: 0.00360966
	LOSS [training: 0.08807928244374391 | validation: 0.05556368194701361]
	TIME [epoch: 9.04 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08099703791253168		[learning rate: 0.0035986]
	Learning Rate: 0.0035986
	LOSS [training: 0.08099703791253168 | validation: 0.14747596120379836]
	TIME [epoch: 9.04 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1856016446126813		[learning rate: 0.0035876]
	Learning Rate: 0.00358757
	LOSS [training: 0.1856016446126813 | validation: 0.09380629461076703]
	TIME [epoch: 9.05 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35491247562989187		[learning rate: 0.0035766]
	Learning Rate: 0.00357657
	LOSS [training: 0.35491247562989187 | validation: 0.3064797041922458]
	TIME [epoch: 9.04 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14058957478938888		[learning rate: 0.0035656]
	Learning Rate: 0.00356561
	LOSS [training: 0.14058957478938888 | validation: 0.08404246415181055]
	TIME [epoch: 9.03 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08405674348922042		[learning rate: 0.0035547]
	Learning Rate: 0.00355468
	LOSS [training: 0.08405674348922042 | validation: 0.08167415805302865]
	TIME [epoch: 9.04 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10230381912042737		[learning rate: 0.0035438]
	Learning Rate: 0.00354378
	LOSS [training: 0.10230381912042737 | validation: 0.13123169032898424]
	TIME [epoch: 9.04 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23880208975803133		[learning rate: 0.0035329]
	Learning Rate: 0.00353292
	LOSS [training: 0.23880208975803133 | validation: 0.11650193820285834]
	TIME [epoch: 9.05 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11194115055861176		[learning rate: 0.0035221]
	Learning Rate: 0.00352209
	LOSS [training: 0.11194115055861176 | validation: 0.08385462448963675]
	TIME [epoch: 9.04 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08370787150747606		[learning rate: 0.0035113]
	Learning Rate: 0.00351129
	LOSS [training: 0.08370787150747606 | validation: 0.054472817024581566]
	TIME [epoch: 9.04 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07205480759084697		[learning rate: 0.0035005]
	Learning Rate: 0.00350053
	LOSS [training: 0.07205480759084697 | validation: 0.04318270213434418]
	TIME [epoch: 9.04 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05478234870763608		[learning rate: 0.0034898]
	Learning Rate: 0.0034898
	LOSS [training: 0.05478234870763608 | validation: 0.08251368503104231]
	TIME [epoch: 9.06 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13352262593007283		[learning rate: 0.0034791]
	Learning Rate: 0.0034791
	LOSS [training: 0.13352262593007283 | validation: 0.11014577070347767]
	TIME [epoch: 9.03 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07944317369853093		[learning rate: 0.0034684]
	Learning Rate: 0.00346843
	LOSS [training: 0.07944317369853093 | validation: 0.06684747007293886]
	TIME [epoch: 9.04 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08666346380121098		[learning rate: 0.0034578]
	Learning Rate: 0.0034578
	LOSS [training: 0.08666346380121098 | validation: 0.061568628669123465]
	TIME [epoch: 9.04 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07255043930640236		[learning rate: 0.0034472]
	Learning Rate: 0.0034472
	LOSS [training: 0.07255043930640236 | validation: 0.06188458926385826]
	TIME [epoch: 9.06 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07413788852114209		[learning rate: 0.0034366]
	Learning Rate: 0.00343663
	LOSS [training: 0.07413788852114209 | validation: 0.04905984585105289]
	TIME [epoch: 9.04 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06671647052670575		[learning rate: 0.0034261]
	Learning Rate: 0.0034261
	LOSS [training: 0.06671647052670575 | validation: 0.04290189774712278]
	TIME [epoch: 9.03 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07660868006612474		[learning rate: 0.0034156]
	Learning Rate: 0.0034156
	LOSS [training: 0.07660868006612474 | validation: 0.10041305475681275]
	TIME [epoch: 9.03 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06660693183701173		[learning rate: 0.0034051]
	Learning Rate: 0.00340513
	LOSS [training: 0.06660693183701173 | validation: 0.05697308822704421]
	TIME [epoch: 9.06 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06961107273294045		[learning rate: 0.0033947]
	Learning Rate: 0.00339469
	LOSS [training: 0.06961107273294045 | validation: 0.1320124755838257]
	TIME [epoch: 9.04 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07558613014632093		[learning rate: 0.0033843]
	Learning Rate: 0.00338428
	LOSS [training: 0.07558613014632093 | validation: 0.03806637703960186]
	TIME [epoch: 9.03 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055710669779976206		[learning rate: 0.0033739]
	Learning Rate: 0.00337391
	LOSS [training: 0.055710669779976206 | validation: 0.04867153822349581]
	TIME [epoch: 9.03 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07909119758762916		[learning rate: 0.0033636]
	Learning Rate: 0.00336357
	LOSS [training: 0.07909119758762916 | validation: 0.05571491555059552]
	TIME [epoch: 9.06 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0765137616271824		[learning rate: 0.0033533]
	Learning Rate: 0.00335326
	LOSS [training: 0.0765137616271824 | validation: 0.12069364538821134]
	TIME [epoch: 9.04 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09879032347240417		[learning rate: 0.003343]
	Learning Rate: 0.00334298
	LOSS [training: 0.09879032347240417 | validation: 0.05768490038581872]
	TIME [epoch: 9.04 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08365710899607826		[learning rate: 0.0033327]
	Learning Rate: 0.00333273
	LOSS [training: 0.08365710899607826 | validation: 0.049433814721869175]
	TIME [epoch: 9.04 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04945076158554416		[learning rate: 0.0033225]
	Learning Rate: 0.00332251
	LOSS [training: 0.04945076158554416 | validation: 0.06200275449656319]
	TIME [epoch: 9.05 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07922021401656071		[learning rate: 0.0033123]
	Learning Rate: 0.00331233
	LOSS [training: 0.07922021401656071 | validation: 0.08720461450969598]
	TIME [epoch: 9.05 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08295286627494804		[learning rate: 0.0033022]
	Learning Rate: 0.00330217
	LOSS [training: 0.08295286627494804 | validation: 0.11144583868563684]
	TIME [epoch: 9.04 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1257556112863322		[learning rate: 0.0032921]
	Learning Rate: 0.00329205
	LOSS [training: 0.1257556112863322 | validation: 0.11205052198704157]
	TIME [epoch: 9.04 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07613160865108204		[learning rate: 0.003282]
	Learning Rate: 0.00328196
	LOSS [training: 0.07613160865108204 | validation: 0.05447293436319951]
	TIME [epoch: 9.05 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0775114154655895		[learning rate: 0.0032719]
	Learning Rate: 0.0032719
	LOSS [training: 0.0775114154655895 | validation: 0.04984822146523547]
	TIME [epoch: 9.06 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08311641219477887		[learning rate: 0.0032619]
	Learning Rate: 0.00326187
	LOSS [training: 0.08311641219477887 | validation: 0.07621131918503034]
	TIME [epoch: 9.04 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19359449120118563		[learning rate: 0.0032519]
	Learning Rate: 0.00325187
	LOSS [training: 0.19359449120118563 | validation: 0.09713063173437934]
	TIME [epoch: 9.04 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06980531242056946		[learning rate: 0.0032419]
	Learning Rate: 0.0032419
	LOSS [training: 0.06980531242056946 | validation: 0.04639520788668432]
	TIME [epoch: 9.04 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051645853645014006		[learning rate: 0.003232]
	Learning Rate: 0.00323197
	LOSS [training: 0.051645853645014006 | validation: 0.03412509148456844]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_868.pth
	Model improved!!!
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055179346526744145		[learning rate: 0.0032221]
	Learning Rate: 0.00322206
	LOSS [training: 0.055179346526744145 | validation: 0.06535992752273001]
	TIME [epoch: 9.04 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09205033111540077		[learning rate: 0.0032122]
	Learning Rate: 0.00321218
	LOSS [training: 0.09205033111540077 | validation: 0.047654247428830926]
	TIME [epoch: 9.05 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05117285881856193		[learning rate: 0.0032023]
	Learning Rate: 0.00320233
	LOSS [training: 0.05117285881856193 | validation: 0.05153953656321758]
	TIME [epoch: 9.04 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08139840264160647		[learning rate: 0.0031925]
	Learning Rate: 0.00319252
	LOSS [training: 0.08139840264160647 | validation: 0.04494711617152823]
	TIME [epoch: 9.06 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06487568121563782		[learning rate: 0.0031827]
	Learning Rate: 0.00318273
	LOSS [training: 0.06487568121563782 | validation: 0.06921184398208306]
	TIME [epoch: 9.05 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07433199951634384		[learning rate: 0.003173]
	Learning Rate: 0.00317297
	LOSS [training: 0.07433199951634384 | validation: 0.05338058430982766]
	TIME [epoch: 9.04 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1065729757175797		[learning rate: 0.0031632]
	Learning Rate: 0.00316325
	LOSS [training: 0.1065729757175797 | validation: 0.08633665570243781]
	TIME [epoch: 9.04 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09891131599945055		[learning rate: 0.0031536]
	Learning Rate: 0.00315355
	LOSS [training: 0.09891131599945055 | validation: 0.1945141228297837]
	TIME [epoch: 9.05 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36550912653226103		[learning rate: 0.0031439]
	Learning Rate: 0.00314389
	LOSS [training: 0.36550912653226103 | validation: 0.11030501712718939]
	TIME [epoch: 9.05 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11738314610227052		[learning rate: 0.0031342]
	Learning Rate: 0.00313425
	LOSS [training: 0.11738314610227052 | validation: 0.09510604594736585]
	TIME [epoch: 9.05 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23130233484433416		[learning rate: 0.0031246]
	Learning Rate: 0.00312464
	LOSS [training: 0.23130233484433416 | validation: 0.09758561275648003]
	TIME [epoch: 9.04 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11739130521409176		[learning rate: 0.0031151]
	Learning Rate: 0.00311506
	LOSS [training: 0.11739130521409176 | validation: 0.11668438606840244]
	TIME [epoch: 9.05 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3678489985946566		[learning rate: 0.0031055]
	Learning Rate: 0.00310551
	LOSS [training: 0.3678489985946566 | validation: 0.08398426763452997]
	TIME [epoch: 9.07 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09303546456703456		[learning rate: 0.003096]
	Learning Rate: 0.00309599
	LOSS [training: 0.09303546456703456 | validation: 0.10672839877145883]
	TIME [epoch: 9.05 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09527615261647272		[learning rate: 0.0030865]
	Learning Rate: 0.0030865
	LOSS [training: 0.09527615261647272 | validation: 0.07557783329434498]
	TIME [epoch: 9.04 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07789477592135008		[learning rate: 0.003077]
	Learning Rate: 0.00307704
	LOSS [training: 0.07789477592135008 | validation: 0.05498959133780765]
	TIME [epoch: 9.04 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06483532320639569		[learning rate: 0.0030676]
	Learning Rate: 0.00306761
	LOSS [training: 0.06483532320639569 | validation: 0.04718208836428868]
	TIME [epoch: 9.07 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0785147927907646		[learning rate: 0.0030582]
	Learning Rate: 0.00305821
	LOSS [training: 0.0785147927907646 | validation: 0.07119097291631582]
	TIME [epoch: 9.05 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07287473890930316		[learning rate: 0.0030488]
	Learning Rate: 0.00304883
	LOSS [training: 0.07287473890930316 | validation: 0.06116912843448023]
	TIME [epoch: 9.04 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08965749728454073		[learning rate: 0.0030395]
	Learning Rate: 0.00303948
	LOSS [training: 0.08965749728454073 | validation: 0.03840866435789381]
	TIME [epoch: 9.04 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13617589597964586		[learning rate: 0.0030302]
	Learning Rate: 0.00303017
	LOSS [training: 0.13617589597964586 | validation: 0.3003359395810107]
	TIME [epoch: 9.07 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1945530082603137		[learning rate: 0.0030209]
	Learning Rate: 0.00302088
	LOSS [training: 0.1945530082603137 | validation: 0.10122955636096861]
	TIME [epoch: 9.06 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1834565659268677		[learning rate: 0.0030116]
	Learning Rate: 0.00301162
	LOSS [training: 0.1834565659268677 | validation: 0.08022771190248082]
	TIME [epoch: 9.04 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11818573069307917		[learning rate: 0.0030024]
	Learning Rate: 0.00300239
	LOSS [training: 0.11818573069307917 | validation: 0.08668111862372674]
	TIME [epoch: 9.03 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09071888831432633		[learning rate: 0.0029932]
	Learning Rate: 0.00299318
	LOSS [training: 0.09071888831432633 | validation: 0.1187457252243996]
	TIME [epoch: 9.06 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1871223231534849		[learning rate: 0.002984]
	Learning Rate: 0.00298401
	LOSS [training: 0.1871223231534849 | validation: 0.06842972506071932]
	TIME [epoch: 9.04 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.068117678005336		[learning rate: 0.0029749]
	Learning Rate: 0.00297486
	LOSS [training: 0.068117678005336 | validation: 0.04915263385564717]
	TIME [epoch: 9.04 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06184472199308836		[learning rate: 0.0029657]
	Learning Rate: 0.00296574
	LOSS [training: 0.06184472199308836 | validation: 0.049609334928906984]
	TIME [epoch: 9.04 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09193670371911279		[learning rate: 0.0029567]
	Learning Rate: 0.00295665
	LOSS [training: 0.09193670371911279 | validation: 0.03211703038935578]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_897.pth
	Model improved!!!
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058433196870577686		[learning rate: 0.0029476]
	Learning Rate: 0.00294759
	LOSS [training: 0.058433196870577686 | validation: 0.045701470525706195]
	TIME [epoch: 9.13 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07311611272683893		[learning rate: 0.0029386]
	Learning Rate: 0.00293855
	LOSS [training: 0.07311611272683893 | validation: 0.04478327221391493]
	TIME [epoch: 9.05 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06713682406632411		[learning rate: 0.0029295]
	Learning Rate: 0.00292954
	LOSS [training: 0.06713682406632411 | validation: 0.07859336555718473]
	TIME [epoch: 9.05 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20633276617287438		[learning rate: 0.0029206]
	Learning Rate: 0.00292056
	LOSS [training: 0.20633276617287438 | validation: 0.095555536598523]
	TIME [epoch: 9.05 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19495612625709602		[learning rate: 0.0029116]
	Learning Rate: 0.00291161
	LOSS [training: 0.19495612625709602 | validation: 0.0956022527725161]
	TIME [epoch: 9.07 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23006415108027595		[learning rate: 0.0029027]
	Learning Rate: 0.00290269
	LOSS [training: 0.23006415108027595 | validation: 0.3056263330268847]
	TIME [epoch: 9.06 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17207106846881107		[learning rate: 0.0028938]
	Learning Rate: 0.00289379
	LOSS [training: 0.17207106846881107 | validation: 0.09608106808526432]
	TIME [epoch: 9.05 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1873402519002435		[learning rate: 0.0028849]
	Learning Rate: 0.00288492
	LOSS [training: 0.1873402519002435 | validation: 0.1143800175662463]
	TIME [epoch: 9.05 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10241754593333426		[learning rate: 0.0028761]
	Learning Rate: 0.00287607
	LOSS [training: 0.10241754593333426 | validation: 0.07613720626131615]
	TIME [epoch: 9.07 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15095455100219787		[learning rate: 0.0028673]
	Learning Rate: 0.00286726
	LOSS [training: 0.15095455100219787 | validation: 0.22345662544208278]
	TIME [epoch: 9.06 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15365105329094766		[learning rate: 0.0028585]
	Learning Rate: 0.00285847
	LOSS [training: 0.15365105329094766 | validation: 0.12701850840030823]
	TIME [epoch: 9.05 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10263566699204807		[learning rate: 0.0028497]
	Learning Rate: 0.00284971
	LOSS [training: 0.10263566699204807 | validation: 0.08685700410900696]
	TIME [epoch: 9.05 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09996251260887937		[learning rate: 0.002841]
	Learning Rate: 0.00284097
	LOSS [training: 0.09996251260887937 | validation: 0.1021571818153248]
	TIME [epoch: 9.06 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08142234899811905		[learning rate: 0.0028323]
	Learning Rate: 0.00283226
	LOSS [training: 0.08142234899811905 | validation: 0.04584545631571588]
	TIME [epoch: 9.05 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06859751389383799		[learning rate: 0.0028236]
	Learning Rate: 0.00282358
	LOSS [training: 0.06859751389383799 | validation: 0.04357291061509756]
	TIME [epoch: 9.05 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0487424693635733		[learning rate: 0.0028149]
	Learning Rate: 0.00281492
	LOSS [training: 0.0487424693635733 | validation: 0.033767508852876944]
	TIME [epoch: 9.05 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050715802981930805		[learning rate: 0.0028063]
	Learning Rate: 0.0028063
	LOSS [training: 0.050715802981930805 | validation: 0.08604508888025113]
	TIME [epoch: 9.06 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16782348390238305		[learning rate: 0.0027977]
	Learning Rate: 0.00279769
	LOSS [training: 0.16782348390238305 | validation: 0.1714792410640136]
	TIME [epoch: 9.07 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22581136611806554		[learning rate: 0.0027891]
	Learning Rate: 0.00278912
	LOSS [training: 0.22581136611806554 | validation: 0.2989045959491341]
	TIME [epoch: 9.05 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30891495741480435		[learning rate: 0.0027806]
	Learning Rate: 0.00278057
	LOSS [training: 0.30891495741480435 | validation: 0.1532912393645435]
	TIME [epoch: 9.05 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1348803978339987		[learning rate: 0.002772]
	Learning Rate: 0.00277204
	LOSS [training: 0.1348803978339987 | validation: 0.14909618790431453]
	TIME [epoch: 9.05 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09649324367203353		[learning rate: 0.0027635]
	Learning Rate: 0.00276355
	LOSS [training: 0.09649324367203353 | validation: 0.08233308388744712]
	TIME [epoch: 9.07 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08959314350582923		[learning rate: 0.0027551]
	Learning Rate: 0.00275507
	LOSS [training: 0.08959314350582923 | validation: 0.06344173353496343]
	TIME [epoch: 9.05 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12817802972745482		[learning rate: 0.0027466]
	Learning Rate: 0.00274663
	LOSS [training: 0.12817802972745482 | validation: 0.19530379623818434]
	TIME [epoch: 9.05 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15372886354951928		[learning rate: 0.0027382]
	Learning Rate: 0.00273821
	LOSS [training: 0.15372886354951928 | validation: 0.16352815535409054]
	TIME [epoch: 9.05 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1590743357597851		[learning rate: 0.0027298]
	Learning Rate: 0.00272982
	LOSS [training: 0.1590743357597851 | validation: 0.1159123074209201]
	TIME [epoch: 9.07 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3205037825833417		[learning rate: 0.0027214]
	Learning Rate: 0.00272145
	LOSS [training: 0.3205037825833417 | validation: 0.14455071710874778]
	TIME [epoch: 9.05 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10434392558758152		[learning rate: 0.0027131]
	Learning Rate: 0.00271311
	LOSS [training: 0.10434392558758152 | validation: 0.10055320026067661]
	TIME [epoch: 9.05 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08782630378584479		[learning rate: 0.0027048]
	Learning Rate: 0.00270479
	LOSS [training: 0.08782630378584479 | validation: 0.0815033417800202]
	TIME [epoch: 9.05 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11607212723257487		[learning rate: 0.0026965]
	Learning Rate: 0.0026965
	LOSS [training: 0.11607212723257487 | validation: 0.062098429786647105]
	TIME [epoch: 9.07 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0892076855998221		[learning rate: 0.0026882]
	Learning Rate: 0.00268823
	LOSS [training: 0.0892076855998221 | validation: 0.10098629752402595]
	TIME [epoch: 9.06 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07715028834262247		[learning rate: 0.00268]
	Learning Rate: 0.00267999
	LOSS [training: 0.07715028834262247 | validation: 0.11143989427183396]
	TIME [epoch: 9.05 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11462083412360471		[learning rate: 0.0026718]
	Learning Rate: 0.00267178
	LOSS [training: 0.11462083412360471 | validation: 0.07002427414385723]
	TIME [epoch: 9.05 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07795835932446661		[learning rate: 0.0026636]
	Learning Rate: 0.00266359
	LOSS [training: 0.07795835932446661 | validation: 0.05075944889331847]
	TIME [epoch: 9.07 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09337243917401629		[learning rate: 0.0026554]
	Learning Rate: 0.00265542
	LOSS [training: 0.09337243917401629 | validation: 0.06751834027807264]
	TIME [epoch: 9.05 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13359901620012277		[learning rate: 0.0026473]
	Learning Rate: 0.00264728
	LOSS [training: 0.13359901620012277 | validation: 0.0825377224359341]
	TIME [epoch: 9.05 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0910589275581802		[learning rate: 0.0026392]
	Learning Rate: 0.00263917
	LOSS [training: 0.0910589275581802 | validation: 0.1072820177903411]
	TIME [epoch: 9.05 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3004890137708395		[learning rate: 0.0026311]
	Learning Rate: 0.00263108
	LOSS [training: 0.3004890137708395 | validation: 0.3447101972563512]
	TIME [epoch: 9.06 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3161285177876		[learning rate: 0.002623]
	Learning Rate: 0.00262301
	LOSS [training: 0.3161285177876 | validation: 0.1698596779938496]
	TIME [epoch: 9.07 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16643033175504232		[learning rate: 0.002615]
	Learning Rate: 0.00261497
	LOSS [training: 0.16643033175504232 | validation: 0.17041650526157148]
	TIME [epoch: 9.05 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.222342891471316		[learning rate: 0.002607]
	Learning Rate: 0.00260695
	LOSS [training: 0.222342891471316 | validation: 0.17152409818130818]
	TIME [epoch: 9.05 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13274646027299933		[learning rate: 0.002599]
	Learning Rate: 0.00259896
	LOSS [training: 0.13274646027299933 | validation: 0.16333210425499536]
	TIME [epoch: 9.06 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15313211682861835		[learning rate: 0.002591]
	Learning Rate: 0.002591
	LOSS [training: 0.15313211682861835 | validation: 0.1462855513988111]
	TIME [epoch: 9.06 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14849282808679223		[learning rate: 0.0025831]
	Learning Rate: 0.00258305
	LOSS [training: 0.14849282808679223 | validation: 0.09627047871566981]
	TIME [epoch: 9.05 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20136762904421507		[learning rate: 0.0025751]
	Learning Rate: 0.00257513
	LOSS [training: 0.20136762904421507 | validation: 0.38601273188244734]
	TIME [epoch: 9.05 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4148718778879698		[learning rate: 0.0025672]
	Learning Rate: 0.00256724
	LOSS [training: 0.4148718778879698 | validation: 0.19021093920275312]
	TIME [epoch: 9.05 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1597552207387649		[learning rate: 0.0025594]
	Learning Rate: 0.00255937
	LOSS [training: 0.1597552207387649 | validation: 0.14504779589407404]
	TIME [epoch: 9.07 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1866226874211083		[learning rate: 0.0025515]
	Learning Rate: 0.00255153
	LOSS [training: 0.1866226874211083 | validation: 0.21845708549666643]
	TIME [epoch: 9.05 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16699913807779804		[learning rate: 0.0025437]
	Learning Rate: 0.0025437
	LOSS [training: 0.16699913807779804 | validation: 0.14335550049231793]
	TIME [epoch: 9.05 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1215548951243367		[learning rate: 0.0025359]
	Learning Rate: 0.00253591
	LOSS [training: 0.1215548951243367 | validation: 0.06847251937362508]
	TIME [epoch: 9.05 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14413551541654931		[learning rate: 0.0025281]
	Learning Rate: 0.00252813
	LOSS [training: 0.14413551541654931 | validation: 0.18032234067776556]
	TIME [epoch: 9.07 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3569243016642031		[learning rate: 0.0025204]
	Learning Rate: 0.00252038
	LOSS [training: 0.3569243016642031 | validation: 0.19175973914988403]
	TIME [epoch: 9.05 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2728904015762324		[learning rate: 0.0025127]
	Learning Rate: 0.00251266
	LOSS [training: 0.2728904015762324 | validation: 0.20446686520619028]
	TIME [epoch: 9.05 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21690315051942374		[learning rate: 0.002505]
	Learning Rate: 0.00250496
	LOSS [training: 0.21690315051942374 | validation: 0.19469197392163656]
	TIME [epoch: 9.05 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16748801573768204		[learning rate: 0.0024973]
	Learning Rate: 0.00249728
	LOSS [training: 0.16748801573768204 | validation: 0.1408182504506441]
	TIME [epoch: 9.07 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17385214412785835		[learning rate: 0.0024896]
	Learning Rate: 0.00248962
	LOSS [training: 0.17385214412785835 | validation: 0.1365645880221576]
	TIME [epoch: 9.05 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17010652582623725		[learning rate: 0.002482]
	Learning Rate: 0.00248199
	LOSS [training: 0.17010652582623725 | validation: 0.23211380267836124]
	TIME [epoch: 9.05 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30383176563148806		[learning rate: 0.0024744]
	Learning Rate: 0.00247438
	LOSS [training: 0.30383176563148806 | validation: 0.1732784021975564]
	TIME [epoch: 9.05 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16928445643066292		[learning rate: 0.0024668]
	Learning Rate: 0.0024668
	LOSS [training: 0.16928445643066292 | validation: 0.10952042394919248]
	TIME [epoch: 9.07 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15710056048336765		[learning rate: 0.0024592]
	Learning Rate: 0.00245923
	LOSS [training: 0.15710056048336765 | validation: 0.2832720251938503]
	TIME [epoch: 9.06 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2525494002247689		[learning rate: 0.0024517]
	Learning Rate: 0.0024517
	LOSS [training: 0.2525494002247689 | validation: 0.170897108966175]
	TIME [epoch: 9.05 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12686745119564483		[learning rate: 0.0024442]
	Learning Rate: 0.00244418
	LOSS [training: 0.12686745119564483 | validation: 0.09136882707050742]
	TIME [epoch: 9.05 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12214114515533722		[learning rate: 0.0024367]
	Learning Rate: 0.00243669
	LOSS [training: 0.12214114515533722 | validation: 0.16589585716199523]
	TIME [epoch: 9.05 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22915938611433		[learning rate: 0.0024292]
	Learning Rate: 0.00242922
	LOSS [training: 0.22915938611433 | validation: 0.19509841008087356]
	TIME [epoch: 9.06 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1509101289130969		[learning rate: 0.0024218]
	Learning Rate: 0.00242177
	LOSS [training: 0.1509101289130969 | validation: 0.1544105419179611]
	TIME [epoch: 9.05 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17721996329822487		[learning rate: 0.0024143]
	Learning Rate: 0.00241435
	LOSS [training: 0.17721996329822487 | validation: 0.10041038343924745]
	TIME [epoch: 9.05 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12776310864313656		[learning rate: 0.0024069]
	Learning Rate: 0.00240695
	LOSS [training: 0.12776310864313656 | validation: 0.14832086246528797]
	TIME [epoch: 9.05 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11746618679374585		[learning rate: 0.0023996]
	Learning Rate: 0.00239957
	LOSS [training: 0.11746618679374585 | validation: 0.16096657607093798]
	TIME [epoch: 9.06 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11268649710494054		[learning rate: 0.0023922]
	Learning Rate: 0.00239221
	LOSS [training: 0.11268649710494054 | validation: 0.06673009225887938]
	TIME [epoch: 9.05 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08675260857375496		[learning rate: 0.0023849]
	Learning Rate: 0.00238488
	LOSS [training: 0.08675260857375496 | validation: 0.07996093624931895]
	TIME [epoch: 9.05 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1325055118460933		[learning rate: 0.0023776]
	Learning Rate: 0.00237757
	LOSS [training: 0.1325055118460933 | validation: 0.21401819168068567]
	TIME [epoch: 9.05 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1317719718054299		[learning rate: 0.0023703]
	Learning Rate: 0.00237028
	LOSS [training: 0.1317719718054299 | validation: 0.09591773547075721]
	TIME [epoch: 9.07 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13693516624737953		[learning rate: 0.002363]
	Learning Rate: 0.00236302
	LOSS [training: 0.13693516624737953 | validation: 0.08685714154971089]
	TIME [epoch: 9.05 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11091991966122358		[learning rate: 0.0023558]
	Learning Rate: 0.00235577
	LOSS [training: 0.11091991966122358 | validation: 0.0789283401852532]
	TIME [epoch: 9.05 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19563819605964397		[learning rate: 0.0023486]
	Learning Rate: 0.00234855
	LOSS [training: 0.19563819605964397 | validation: 0.20089742827058085]
	TIME [epoch: 9.05 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22006995026149873		[learning rate: 0.0023414]
	Learning Rate: 0.00234135
	LOSS [training: 0.22006995026149873 | validation: 0.26777082900423327]
	TIME [epoch: 9.06 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19325560433815508		[learning rate: 0.0023342]
	Learning Rate: 0.00233417
	LOSS [training: 0.19325560433815508 | validation: 0.11664950009369848]
	TIME [epoch: 9.05 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17684085143705283		[learning rate: 0.002327]
	Learning Rate: 0.00232702
	LOSS [training: 0.17684085143705283 | validation: 0.30292304532466857]
	TIME [epoch: 9.05 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4626369615837505		[learning rate: 0.0023199]
	Learning Rate: 0.00231989
	LOSS [training: 0.4626369615837505 | validation: 0.38333723588164126]
	TIME [epoch: 9.05 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3519151433380975		[learning rate: 0.0023128]
	Learning Rate: 0.00231277
	LOSS [training: 0.3519151433380975 | validation: 0.28826576552039107]
	TIME [epoch: 9.07 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32173232522557066		[learning rate: 0.0023057]
	Learning Rate: 0.00230569
	LOSS [training: 0.32173232522557066 | validation: 0.2605242312785201]
	TIME [epoch: 9.06 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34551350505297235		[learning rate: 0.0022986]
	Learning Rate: 0.00229862
	LOSS [training: 0.34551350505297235 | validation: 0.18708540419059516]
	TIME [epoch: 9.04 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19827490083762925		[learning rate: 0.0022916]
	Learning Rate: 0.00229157
	LOSS [training: 0.19827490083762925 | validation: 0.4617204416873887]
	TIME [epoch: 9.05 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4102352434313398		[learning rate: 0.0022845]
	Learning Rate: 0.00228455
	LOSS [training: 0.4102352434313398 | validation: 0.3197174088036357]
	TIME [epoch: 9.06 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31955620317982675		[learning rate: 0.0022775]
	Learning Rate: 0.00227754
	LOSS [training: 0.31955620317982675 | validation: 0.21812152382199734]
	TIME [epoch: 9.05 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1867075820858542		[learning rate: 0.0022706]
	Learning Rate: 0.00227056
	LOSS [training: 0.1867075820858542 | validation: 0.2074775121888863]
	TIME [epoch: 9.05 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.516008838586367		[learning rate: 0.0022636]
	Learning Rate: 0.0022636
	LOSS [training: 0.516008838586367 | validation: 1.1217986544544591]
	TIME [epoch: 9.05 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7145657136059091		[learning rate: 0.0022567]
	Learning Rate: 0.00225666
	LOSS [training: 0.7145657136059091 | validation: 0.3520908023964112]
	TIME [epoch: 9.06 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4137702752557185		[learning rate: 0.0022497]
	Learning Rate: 0.00224975
	LOSS [training: 0.4137702752557185 | validation: 0.4321468870843992]
	TIME [epoch: 9.06 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5460151696825586		[learning rate: 0.0022428]
	Learning Rate: 0.00224285
	LOSS [training: 0.5460151696825586 | validation: 0.49811047191663166]
	TIME [epoch: 9.05 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38021504460689093		[learning rate: 0.002236]
	Learning Rate: 0.00223597
	LOSS [training: 0.38021504460689093 | validation: 0.37011799395429446]
	TIME [epoch: 9.04 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.301925581142318		[learning rate: 0.0022291]
	Learning Rate: 0.00222912
	LOSS [training: 0.301925581142318 | validation: 0.3054872343509715]
	TIME [epoch: 9.05 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2507434620706324		[learning rate: 0.0022223]
	Learning Rate: 0.00222229
	LOSS [training: 0.2507434620706324 | validation: 0.17779435721124606]
	TIME [epoch: 9.06 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18034422585519203		[learning rate: 0.0022155]
	Learning Rate: 0.00221547
	LOSS [training: 0.18034422585519203 | validation: 0.14912312854524146]
	TIME [epoch: 9.05 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14853526475037232		[learning rate: 0.0022087]
	Learning Rate: 0.00220868
	LOSS [training: 0.14853526475037232 | validation: 0.12422028537607267]
	TIME [epoch: 9.04 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15210992919252747		[learning rate: 0.0022019]
	Learning Rate: 0.00220191
	LOSS [training: 0.15210992919252747 | validation: 0.1574641575101263]
	TIME [epoch: 9.04 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14031040810057932		[learning rate: 0.0021952]
	Learning Rate: 0.00219516
	LOSS [training: 0.14031040810057932 | validation: 0.12547466758290474]
	TIME [epoch: 9.07 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14792421502006792		[learning rate: 0.0021884]
	Learning Rate: 0.00218843
	LOSS [training: 0.14792421502006792 | validation: 0.14347200217729572]
	TIME [epoch: 9.05 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1692641739770575		[learning rate: 0.0021817]
	Learning Rate: 0.00218173
	LOSS [training: 0.1692641739770575 | validation: 0.2513928228576623]
	TIME [epoch: 9.04 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39687553985956514		[learning rate: 0.002175]
	Learning Rate: 0.00217504
	LOSS [training: 0.39687553985956514 | validation: 0.25076530035764893]
	TIME [epoch: 9.05 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14026477338688367		[learning rate: 0.0021684]
	Learning Rate: 0.00216837
	LOSS [training: 0.14026477338688367 | validation: 0.08345388992172804]
	TIME [epoch: 9.06 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10445526771667064		[learning rate: 0.0021617]
	Learning Rate: 0.00216172
	LOSS [training: 0.10445526771667064 | validation: 0.08918086814781981]
	TIME [epoch: 9.05 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12602600944417605		[learning rate: 0.0021551]
	Learning Rate: 0.0021551
	LOSS [training: 0.12602600944417605 | validation: 0.13818313779717348]
	TIME [epoch: 9.05 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1219396233319747		[learning rate: 0.0021485]
	Learning Rate: 0.00214849
	LOSS [training: 0.1219396233319747 | validation: 0.10585479388327534]
	TIME [epoch: 9.05 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1236143607613573		[learning rate: 0.0021419]
	Learning Rate: 0.0021419
	LOSS [training: 0.1236143607613573 | validation: 0.06165615747085229]
	TIME [epoch: 9.06 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07343332480488367		[learning rate: 0.0021353]
	Learning Rate: 0.00213534
	LOSS [training: 0.07343332480488367 | validation: 0.05912002387733863]
	TIME [epoch: 9.05 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062063797896154925		[learning rate: 0.0021288]
	Learning Rate: 0.00212879
	LOSS [training: 0.062063797896154925 | validation: 0.03438427773291083]
	TIME [epoch: 9.06 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05868950000343913		[learning rate: 0.0021223]
	Learning Rate: 0.00212227
	LOSS [training: 0.05868950000343913 | validation: 0.08353238418552499]
	TIME [epoch: 9.05 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09133470856066066		[learning rate: 0.0021158]
	Learning Rate: 0.00211576
	LOSS [training: 0.09133470856066066 | validation: 0.049393968529057516]
	TIME [epoch: 9.05 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1086337079277575		[learning rate: 0.0021093]
	Learning Rate: 0.00210928
	LOSS [training: 0.1086337079277575 | validation: 0.1259013506139205]
	TIME [epoch: 9.06 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24580153065555038		[learning rate: 0.0021028]
	Learning Rate: 0.00210281
	LOSS [training: 0.24580153065555038 | validation: 0.21767908081311782]
	TIME [epoch: 9.04 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19219263819570429		[learning rate: 0.0020964]
	Learning Rate: 0.00209636
	LOSS [training: 0.19219263819570429 | validation: 0.05359201699507314]
	TIME [epoch: 9.05 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06426297121074104		[learning rate: 0.0020899]
	Learning Rate: 0.00208994
	LOSS [training: 0.06426297121074104 | validation: 0.05041128453720725]
	TIME [epoch: 9.06 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0672822200032921		[learning rate: 0.0020835]
	Learning Rate: 0.00208353
	LOSS [training: 0.0672822200032921 | validation: 0.09838984450707486]
	TIME [epoch: 9.06 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1265805686878982		[learning rate: 0.0020771]
	Learning Rate: 0.00207714
	LOSS [training: 0.1265805686878982 | validation: 0.058033276169373524]
	TIME [epoch: 9.05 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08257034514308215		[learning rate: 0.0020708]
	Learning Rate: 0.00207078
	LOSS [training: 0.08257034514308215 | validation: 0.1128253950065237]
	TIME [epoch: 9.04 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09995702390340473		[learning rate: 0.0020644]
	Learning Rate: 0.00206443
	LOSS [training: 0.09995702390340473 | validation: 0.06794235342170134]
	TIME [epoch: 9.04 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08060484315167753		[learning rate: 0.0020581]
	Learning Rate: 0.0020581
	LOSS [training: 0.08060484315167753 | validation: 0.055749231613338224]
	TIME [epoch: 9.07 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09568286813200387		[learning rate: 0.0020518]
	Learning Rate: 0.00205179
	LOSS [training: 0.09568286813200387 | validation: 0.07860840779606684]
	TIME [epoch: 9.05 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14120869816922008		[learning rate: 0.0020455]
	Learning Rate: 0.0020455
	LOSS [training: 0.14120869816922008 | validation: 0.18015876928614988]
	TIME [epoch: 9.05 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20703832114282536		[learning rate: 0.0020392]
	Learning Rate: 0.00203923
	LOSS [training: 0.20703832114282536 | validation: 0.222068991409892]
	TIME [epoch: 9.04 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1566336191150781		[learning rate: 0.002033]
	Learning Rate: 0.00203298
	LOSS [training: 0.1566336191150781 | validation: 0.12016269565250731]
	TIME [epoch: 9.07 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10904762033934443		[learning rate: 0.0020267]
	Learning Rate: 0.00202675
	LOSS [training: 0.10904762033934443 | validation: 0.12872289270613207]
	TIME [epoch: 9.05 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10383896431127342		[learning rate: 0.0020205]
	Learning Rate: 0.00202054
	LOSS [training: 0.10383896431127342 | validation: 0.08511930956022143]
	TIME [epoch: 9.05 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1521887047078036		[learning rate: 0.0020143]
	Learning Rate: 0.00201434
	LOSS [training: 0.1521887047078036 | validation: 0.24283896300409802]
	TIME [epoch: 9.05 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18384845623966156		[learning rate: 0.0020082]
	Learning Rate: 0.00200817
	LOSS [training: 0.18384845623966156 | validation: 0.14216727756919476]
	TIME [epoch: 9.07 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09396905130837234		[learning rate: 0.002002]
	Learning Rate: 0.00200201
	LOSS [training: 0.09396905130837234 | validation: 0.0641988825283372]
	TIME [epoch: 9.05 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08710002908341274		[learning rate: 0.0019959]
	Learning Rate: 0.00199587
	LOSS [training: 0.08710002908341274 | validation: 0.07946847886799105]
	TIME [epoch: 9.05 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07889915660561343		[learning rate: 0.0019898]
	Learning Rate: 0.00198976
	LOSS [training: 0.07889915660561343 | validation: 0.06602532309560283]
	TIME [epoch: 9.05 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0705677055838211		[learning rate: 0.0019837]
	Learning Rate: 0.00198366
	LOSS [training: 0.0705677055838211 | validation: 0.06458787513671554]
	TIME [epoch: 9.07 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0771679810690445		[learning rate: 0.0019776]
	Learning Rate: 0.00197758
	LOSS [training: 0.0771679810690445 | validation: 0.09888468138930814]
	TIME [epoch: 9.06 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09550886345729379		[learning rate: 0.0019715]
	Learning Rate: 0.00197151
	LOSS [training: 0.09550886345729379 | validation: 0.10272724202685679]
	TIME [epoch: 9.06 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07877960997115921		[learning rate: 0.0019655]
	Learning Rate: 0.00196547
	LOSS [training: 0.07877960997115921 | validation: 0.08361800355120881]
	TIME [epoch: 9.06 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08922403055739378		[learning rate: 0.0019594]
	Learning Rate: 0.00195945
	LOSS [training: 0.08922403055739378 | validation: 0.09239822060571272]
	TIME [epoch: 9.07 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07580377358378386		[learning rate: 0.0019534]
	Learning Rate: 0.00195344
	LOSS [training: 0.07580377358378386 | validation: 0.049287331964751414]
	TIME [epoch: 9.07 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06579865885908426		[learning rate: 0.0019475]
	Learning Rate: 0.00194745
	LOSS [training: 0.06579865885908426 | validation: 0.04847282809721663]
	TIME [epoch: 9.06 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10406832047945855		[learning rate: 0.0019415]
	Learning Rate: 0.00194148
	LOSS [training: 0.10406832047945855 | validation: 0.18392861977386285]
	TIME [epoch: 9.06 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16892046918796627		[learning rate: 0.0019355]
	Learning Rate: 0.00193553
	LOSS [training: 0.16892046918796627 | validation: 0.10228114860529938]
	TIME [epoch: 9.07 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11657688132251846		[learning rate: 0.0019296]
	Learning Rate: 0.0019296
	LOSS [training: 0.11657688132251846 | validation: 0.07762795992052739]
	TIME [epoch: 9.07 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0819224504224971		[learning rate: 0.0019237]
	Learning Rate: 0.00192368
	LOSS [training: 0.0819224504224971 | validation: 0.09810119453325958]
	TIME [epoch: 9.06 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09309289307076406		[learning rate: 0.0019178]
	Learning Rate: 0.00191779
	LOSS [training: 0.09309289307076406 | validation: 0.08624497159560705]
	TIME [epoch: 9.06 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13203651503064132		[learning rate: 0.0019119]
	Learning Rate: 0.00191191
	LOSS [training: 0.13203651503064132 | validation: 0.0921001999608976]
	TIME [epoch: 9.05 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2314619733049157		[learning rate: 0.001906]
	Learning Rate: 0.00190605
	LOSS [training: 0.2314619733049157 | validation: 0.2818830345815705]
	TIME [epoch: 9.08 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.423048899759719		[learning rate: 0.0019002]
	Learning Rate: 0.0019002
	LOSS [training: 0.423048899759719 | validation: 0.40480718884948247]
	TIME [epoch: 9.06 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32789511885973965		[learning rate: 0.0018944]
	Learning Rate: 0.00189438
	LOSS [training: 0.32789511885973965 | validation: 0.11076673723925096]
	TIME [epoch: 9.06 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09434293544321569		[learning rate: 0.0018886]
	Learning Rate: 0.00188857
	LOSS [training: 0.09434293544321569 | validation: 0.07255634258782948]
	TIME [epoch: 9.06 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16535388022110104		[learning rate: 0.0018828]
	Learning Rate: 0.00188278
	LOSS [training: 0.16535388022110104 | validation: 0.23256047353714454]
	TIME [epoch: 9.08 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2988820430796288		[learning rate: 0.001877]
	Learning Rate: 0.00187701
	LOSS [training: 0.2988820430796288 | validation: 0.12827045857975639]
	TIME [epoch: 9.06 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19311275523396948		[learning rate: 0.0018713]
	Learning Rate: 0.00187126
	LOSS [training: 0.19311275523396948 | validation: 0.16875372318929127]
	TIME [epoch: 9.06 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1707184043205252		[learning rate: 0.0018655]
	Learning Rate: 0.00186552
	LOSS [training: 0.1707184043205252 | validation: 0.12324053225963383]
	TIME [epoch: 9.06 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09045811237995252		[learning rate: 0.0018598]
	Learning Rate: 0.0018598
	LOSS [training: 0.09045811237995252 | validation: 0.06377839252821829]
	TIME [epoch: 9.08 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12138409580828495		[learning rate: 0.0018541]
	Learning Rate: 0.0018541
	LOSS [training: 0.12138409580828495 | validation: 0.15315740523089322]
	TIME [epoch: 9.06 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1161895309137804		[learning rate: 0.0018484]
	Learning Rate: 0.00184842
	LOSS [training: 0.1161895309137804 | validation: 0.06819986667632869]
	TIME [epoch: 9.06 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0930423391412448		[learning rate: 0.0018428]
	Learning Rate: 0.00184275
	LOSS [training: 0.0930423391412448 | validation: 0.11795358368482867]
	TIME [epoch: 9.06 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21982990124133212		[learning rate: 0.0018371]
	Learning Rate: 0.0018371
	LOSS [training: 0.21982990124133212 | validation: 0.1257458703277385]
	TIME [epoch: 9.08 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18722230844909646		[learning rate: 0.0018315]
	Learning Rate: 0.00183147
	LOSS [training: 0.18722230844909646 | validation: 0.20242824740877857]
	TIME [epoch: 9.06 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26387601541885186		[learning rate: 0.0018259]
	Learning Rate: 0.00182586
	LOSS [training: 0.26387601541885186 | validation: 0.0986382718737179]
	TIME [epoch: 9.06 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09080140588292848		[learning rate: 0.0018203]
	Learning Rate: 0.00182026
	LOSS [training: 0.09080140588292848 | validation: 0.061094286762215635]
	TIME [epoch: 9.06 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07436302929976134		[learning rate: 0.0018147]
	Learning Rate: 0.00181468
	LOSS [training: 0.07436302929976134 | validation: 0.08280751330484512]
	TIME [epoch: 9.07 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1064520150965355		[learning rate: 0.0018091]
	Learning Rate: 0.00180912
	LOSS [training: 0.1064520150965355 | validation: 0.0924178857174577]
	TIME [epoch: 9.07 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3379935250847878		[learning rate: 0.0018036]
	Learning Rate: 0.00180357
	LOSS [training: 0.3379935250847878 | validation: 0.3723856613539472]
	TIME [epoch: 9.06 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40170330150046124		[learning rate: 0.001798]
	Learning Rate: 0.00179804
	LOSS [training: 0.40170330150046124 | validation: 0.4823291747089511]
	TIME [epoch: 9.06 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45423708807560254		[learning rate: 0.0017925]
	Learning Rate: 0.00179253
	LOSS [training: 0.45423708807560254 | validation: 0.2269306124311345]
	TIME [epoch: 9.06 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2848473731021104		[learning rate: 0.001787]
	Learning Rate: 0.00178704
	LOSS [training: 0.2848473731021104 | validation: 0.29750875256549647]
	TIME [epoch: 9.08 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29456399045524834		[learning rate: 0.0017816]
	Learning Rate: 0.00178156
	LOSS [training: 0.29456399045524834 | validation: 0.23978721495898903]
	TIME [epoch: 9.06 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.286280128145456		[learning rate: 0.0017761]
	Learning Rate: 0.0017761
	LOSS [training: 0.286280128145456 | validation: 0.2050678109563716]
	TIME [epoch: 9.06 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.253584321969259		[learning rate: 0.0017707]
	Learning Rate: 0.00177065
	LOSS [training: 0.253584321969259 | validation: 0.22110351217982335]
	TIME [epoch: 9.06 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19013855889476375		[learning rate: 0.0017652]
	Learning Rate: 0.00176522
	LOSS [training: 0.19013855889476375 | validation: 0.1184457328109624]
	TIME [epoch: 9.08 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12040751124270141		[learning rate: 0.0017598]
	Learning Rate: 0.00175981
	LOSS [training: 0.12040751124270141 | validation: 0.08463245939973074]
	TIME [epoch: 9.07 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10317863061820934		[learning rate: 0.0017544]
	Learning Rate: 0.00175442
	LOSS [training: 0.10317863061820934 | validation: 0.09440531522003004]
	TIME [epoch: 9.06 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08885615088420032		[learning rate: 0.001749]
	Learning Rate: 0.00174904
	LOSS [training: 0.08885615088420032 | validation: 0.06554627340354408]
	TIME [epoch: 9.06 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06558057411592123		[learning rate: 0.0017437]
	Learning Rate: 0.00174368
	LOSS [training: 0.06558057411592123 | validation: 0.059616044527072067]
	TIME [epoch: 9.08 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0627674102291299		[learning rate: 0.0017383]
	Learning Rate: 0.00173833
	LOSS [training: 0.0627674102291299 | validation: 0.046802714382188346]
	TIME [epoch: 9.06 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05840375558124331		[learning rate: 0.001733]
	Learning Rate: 0.00173301
	LOSS [training: 0.05840375558124331 | validation: 0.04775884763503352]
	TIME [epoch: 9.06 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07202641311407523		[learning rate: 0.0017277]
	Learning Rate: 0.00172769
	LOSS [training: 0.07202641311407523 | validation: 0.0660188573588589]
	TIME [epoch: 9.06 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07565310259656398		[learning rate: 0.0017224]
	Learning Rate: 0.0017224
	LOSS [training: 0.07565310259656398 | validation: 0.06984543541024492]
	TIME [epoch: 9.08 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09068844162460601		[learning rate: 0.0017171]
	Learning Rate: 0.00171712
	LOSS [training: 0.09068844162460601 | validation: 0.06669563326501432]
	TIME [epoch: 9.06 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061175426254992116		[learning rate: 0.0017119]
	Learning Rate: 0.00171185
	LOSS [training: 0.061175426254992116 | validation: 0.054285964522318805]
	TIME [epoch: 9.05 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05537871752448936		[learning rate: 0.0017066]
	Learning Rate: 0.00170661
	LOSS [training: 0.05537871752448936 | validation: 0.05338535032797195]
	TIME [epoch: 9.06 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06571306005654608		[learning rate: 0.0017014]
	Learning Rate: 0.00170137
	LOSS [training: 0.06571306005654608 | validation: 0.058726708930003035]
	TIME [epoch: 9.07 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05893150494441986		[learning rate: 0.0016962]
	Learning Rate: 0.00169616
	LOSS [training: 0.05893150494441986 | validation: 0.04837378037338946]
	TIME [epoch: 9.06 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0615548113466511		[learning rate: 0.001691]
	Learning Rate: 0.00169096
	LOSS [training: 0.0615548113466511 | validation: 0.055372055079135736]
	TIME [epoch: 9.05 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08769239325626625		[learning rate: 0.0016858]
	Learning Rate: 0.00168578
	LOSS [training: 0.08769239325626625 | validation: 0.19022456950319605]
	TIME [epoch: 9.06 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1824160238776519		[learning rate: 0.0016806]
	Learning Rate: 0.00168061
	LOSS [training: 0.1824160238776519 | validation: 0.17088979794697073]
	TIME [epoch: 9.06 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16479043989838044		[learning rate: 0.0016755]
	Learning Rate: 0.00167546
	LOSS [training: 0.16479043989838044 | validation: 0.10542530793651811]
	TIME [epoch: 9.07 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07462684223750729		[learning rate: 0.0016703]
	Learning Rate: 0.00167032
	LOSS [training: 0.07462684223750729 | validation: 0.05925982073978889]
	TIME [epoch: 9.05 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06390035859176108		[learning rate: 0.0016652]
	Learning Rate: 0.0016652
	LOSS [training: 0.06390035859176108 | validation: 0.042166106565251396]
	TIME [epoch: 9.05 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056147211456203126		[learning rate: 0.0016601]
	Learning Rate: 0.0016601
	LOSS [training: 0.056147211456203126 | validation: 0.05972765044147115]
	TIME [epoch: 9.05 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0703670242979271		[learning rate: 0.001655]
	Learning Rate: 0.00165501
	LOSS [training: 0.0703670242979271 | validation: 0.07320517241299423]
	TIME [epoch: 9.08 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11594162344786771		[learning rate: 0.0016499]
	Learning Rate: 0.00164993
	LOSS [training: 0.11594162344786771 | validation: 0.10493509769405927]
	TIME [epoch: 9.06 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1709929699006334		[learning rate: 0.0016449]
	Learning Rate: 0.00164488
	LOSS [training: 0.1709929699006334 | validation: 0.09229476989872128]
	TIME [epoch: 9.05 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05370627667183092		[learning rate: 0.0016398]
	Learning Rate: 0.00163983
	LOSS [training: 0.05370627667183092 | validation: 0.028672606583443325]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1089.pth
	Model improved!!!
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07975580351179022		[learning rate: 0.0016348]
	Learning Rate: 0.00163481
	LOSS [training: 0.07975580351179022 | validation: 0.04790086486653014]
	TIME [epoch: 9.07 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09531685817711286		[learning rate: 0.0016298]
	Learning Rate: 0.0016298
	LOSS [training: 0.09531685817711286 | validation: 0.06670695476807503]
	TIME [epoch: 9.04 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1299601441343757		[learning rate: 0.0016248]
	Learning Rate: 0.0016248
	LOSS [training: 0.1299601441343757 | validation: 0.3065100639170599]
	TIME [epoch: 9.05 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24966587086823583		[learning rate: 0.0016198]
	Learning Rate: 0.00161982
	LOSS [training: 0.24966587086823583 | validation: 0.10026474025244228]
	TIME [epoch: 9.04 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08880275713466038		[learning rate: 0.0016149]
	Learning Rate: 0.00161485
	LOSS [training: 0.08880275713466038 | validation: 0.0866212804837836]
	TIME [epoch: 9.06 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06900194577031335		[learning rate: 0.0016099]
	Learning Rate: 0.0016099
	LOSS [training: 0.06900194577031335 | validation: 0.048828122519726735]
	TIME [epoch: 9.06 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07437971794967345		[learning rate: 0.001605]
	Learning Rate: 0.00160497
	LOSS [training: 0.07437971794967345 | validation: 0.06001237968066435]
	TIME [epoch: 9.05 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13938002362837162		[learning rate: 0.0016]
	Learning Rate: 0.00160005
	LOSS [training: 0.13938002362837162 | validation: 0.28884317288490713]
	TIME [epoch: 9.05 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35935657304927904		[learning rate: 0.0015951]
	Learning Rate: 0.00159514
	LOSS [training: 0.35935657304927904 | validation: 0.40689073573578516]
	TIME [epoch: 9.05 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27906850215740564		[learning rate: 0.0015903]
	Learning Rate: 0.00159025
	LOSS [training: 0.27906850215740564 | validation: 0.19828057390366038]
	TIME [epoch: 9.06 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16694233899704847		[learning rate: 0.0015854]
	Learning Rate: 0.00158538
	LOSS [training: 0.16694233899704847 | validation: 0.17069580929419037]
	TIME [epoch: 9.05 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21127488644184647		[learning rate: 0.0015805]
	Learning Rate: 0.00158052
	LOSS [training: 0.21127488644184647 | validation: 0.20515220597284636]
	TIME [epoch: 9.05 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17921136246604513		[learning rate: 0.0015757]
	Learning Rate: 0.00157568
	LOSS [training: 0.17921136246604513 | validation: 0.2379543686054805]
	TIME [epoch: 9.05 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26719810460392196		[learning rate: 0.0015708]
	Learning Rate: 0.00157084
	LOSS [training: 0.26719810460392196 | validation: 0.15288042865888818]
	TIME [epoch: 9.07 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13309257146392306		[learning rate: 0.001566]
	Learning Rate: 0.00156603
	LOSS [training: 0.13309257146392306 | validation: 0.11209480470666275]
	TIME [epoch: 9.04 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13043618945420427		[learning rate: 0.0015612]
	Learning Rate: 0.00156123
	LOSS [training: 0.13043618945420427 | validation: 0.09924489259210698]
	TIME [epoch: 9.04 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09392189146725427		[learning rate: 0.0015564]
	Learning Rate: 0.00155644
	LOSS [training: 0.09392189146725427 | validation: 0.07022565491824792]
	TIME [epoch: 9.04 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0922949605340558		[learning rate: 0.0015517]
	Learning Rate: 0.00155167
	LOSS [training: 0.0922949605340558 | validation: 0.08343509880376107]
	TIME [epoch: 9.06 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10761011376604472		[learning rate: 0.0015469]
	Learning Rate: 0.00154692
	LOSS [training: 0.10761011376604472 | validation: 0.20349191194687055]
	TIME [epoch: 9.05 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1557045716190986		[learning rate: 0.0015422]
	Learning Rate: 0.00154217
	LOSS [training: 0.1557045716190986 | validation: 0.1267542116933312]
	TIME [epoch: 9.05 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2054828682564817		[learning rate: 0.0015374]
	Learning Rate: 0.00153745
	LOSS [training: 0.2054828682564817 | validation: 0.1136865824704811]
	TIME [epoch: 9.05 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08929965454907829		[learning rate: 0.0015327]
	Learning Rate: 0.00153273
	LOSS [training: 0.08929965454907829 | validation: 0.05835153633618383]
	TIME [epoch: 9.07 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06119752467670767		[learning rate: 0.001528]
	Learning Rate: 0.00152804
	LOSS [training: 0.06119752467670767 | validation: 0.06918134677792127]
	TIME [epoch: 9.05 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06830926463408687		[learning rate: 0.0015234]
	Learning Rate: 0.00152335
	LOSS [training: 0.06830926463408687 | validation: 0.04145226668109949]
	TIME [epoch: 9.05 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14078135629169802		[learning rate: 0.0015187]
	Learning Rate: 0.00151868
	LOSS [training: 0.14078135629169802 | validation: 0.09987513628366296]
	TIME [epoch: 9.05 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07966649072280325		[learning rate: 0.001514]
	Learning Rate: 0.00151403
	LOSS [training: 0.07966649072280325 | validation: 0.06823415428789259]
	TIME [epoch: 9.07 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09252771837170001		[learning rate: 0.0015094]
	Learning Rate: 0.00150938
	LOSS [training: 0.09252771837170001 | validation: 0.159734686664227]
	TIME [epoch: 9.06 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27200593514191895		[learning rate: 0.0015048]
	Learning Rate: 0.00150476
	LOSS [training: 0.27200593514191895 | validation: 0.26683577084074234]
	TIME [epoch: 9.05 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35501453535658		[learning rate: 0.0015001]
	Learning Rate: 0.00150015
	LOSS [training: 0.35501453535658 | validation: 0.36969609459545894]
	TIME [epoch: 9.05 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3569342395029274		[learning rate: 0.0014955]
	Learning Rate: 0.00149555
	LOSS [training: 0.3569342395029274 | validation: 0.14066431879670144]
	TIME [epoch: 9.06 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1241288958802671		[learning rate: 0.001491]
	Learning Rate: 0.00149096
	LOSS [training: 0.1241288958802671 | validation: 0.09118888217502713]
	TIME [epoch: 9.06 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11691465877228346		[learning rate: 0.0014864]
	Learning Rate: 0.00148639
	LOSS [training: 0.11691465877228346 | validation: 0.09677225127005684]
	TIME [epoch: 9.04 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08075146244792432		[learning rate: 0.0014818]
	Learning Rate: 0.00148184
	LOSS [training: 0.08075146244792432 | validation: 0.062117736435101115]
	TIME [epoch: 9.05 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07116356486421184		[learning rate: 0.0014773]
	Learning Rate: 0.00147729
	LOSS [training: 0.07116356486421184 | validation: 0.09026544894236507]
	TIME [epoch: 9.05 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1083601384560741		[learning rate: 0.0014728]
	Learning Rate: 0.00147276
	LOSS [training: 0.1083601384560741 | validation: 0.13004370134192558]
	TIME [epoch: 9.07 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0910848469459515		[learning rate: 0.0014682]
	Learning Rate: 0.00146825
	LOSS [training: 0.0910848469459515 | validation: 0.07309851442617865]
	TIME [epoch: 9.05 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0814162576238449		[learning rate: 0.0014637]
	Learning Rate: 0.00146375
	LOSS [training: 0.0814162576238449 | validation: 0.06057194566198851]
	TIME [epoch: 9.05 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1304627577520939		[learning rate: 0.0014593]
	Learning Rate: 0.00145926
	LOSS [training: 0.1304627577520939 | validation: 0.139453898766771]
	TIME [epoch: 9.05 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19433933475039902		[learning rate: 0.0014548]
	Learning Rate: 0.00145479
	LOSS [training: 0.19433933475039902 | validation: 0.11963812883944105]
	TIME [epoch: 9.07 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16739608569066722		[learning rate: 0.0014503]
	Learning Rate: 0.00145033
	LOSS [training: 0.16739608569066722 | validation: 0.24322755046554995]
	TIME [epoch: 9.05 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46908742962242744		[learning rate: 0.0014459]
	Learning Rate: 0.00144588
	LOSS [training: 0.46908742962242744 | validation: 0.3714994541044019]
	TIME [epoch: 9.04 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38144621885250035		[learning rate: 0.0014415]
	Learning Rate: 0.00144145
	LOSS [training: 0.38144621885250035 | validation: 0.28544110533144085]
	TIME [epoch: 9.05 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19970035040199258		[learning rate: 0.001437]
	Learning Rate: 0.00143703
	LOSS [training: 0.19970035040199258 | validation: 0.1768156992541723]
	TIME [epoch: 9.07 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19375342524800465		[learning rate: 0.0014326]
	Learning Rate: 0.00143263
	LOSS [training: 0.19375342524800465 | validation: 0.1253640139075108]
	TIME [epoch: 9.06 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1245008406335221		[learning rate: 0.0014282]
	Learning Rate: 0.00142824
	LOSS [training: 0.1245008406335221 | validation: 0.14934892314130993]
	TIME [epoch: 9.05 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14276006450902406		[learning rate: 0.0014239]
	Learning Rate: 0.00142386
	LOSS [training: 0.14276006450902406 | validation: 0.09457505521609028]
	TIME [epoch: 9.05 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10739860725459252		[learning rate: 0.0014195]
	Learning Rate: 0.00141949
	LOSS [training: 0.10739860725459252 | validation: 0.0867101928635147]
	TIME [epoch: 9.07 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09283515448081944		[learning rate: 0.0014151]
	Learning Rate: 0.00141514
	LOSS [training: 0.09283515448081944 | validation: 0.06313895044139858]
	TIME [epoch: 9.05 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06399218573863288		[learning rate: 0.0014108]
	Learning Rate: 0.0014108
	LOSS [training: 0.06399218573863288 | validation: 0.05099667846608595]
	TIME [epoch: 9.05 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06619700508150499		[learning rate: 0.0014065]
	Learning Rate: 0.00140648
	LOSS [training: 0.06619700508150499 | validation: 0.051291479841475404]
	TIME [epoch: 9.05 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047274829941888155		[learning rate: 0.0014022]
	Learning Rate: 0.00140217
	LOSS [training: 0.047274829941888155 | validation: 0.027677937581871585]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1140.pth
	Model improved!!!
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046857940130713226		[learning rate: 0.0013979]
	Learning Rate: 0.00139787
	LOSS [training: 0.046857940130713226 | validation: 0.04561783016892542]
	TIME [epoch: 9.06 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07360475021707906		[learning rate: 0.0013936]
	Learning Rate: 0.00139358
	LOSS [training: 0.07360475021707906 | validation: 0.11350737471212574]
	TIME [epoch: 9.05 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11470528437487977		[learning rate: 0.0013893]
	Learning Rate: 0.00138931
	LOSS [training: 0.11470528437487977 | validation: 0.04683513520314503]
	TIME [epoch: 9.05 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042318612028130406		[learning rate: 0.0013851]
	Learning Rate: 0.00138505
	LOSS [training: 0.042318612028130406 | validation: 0.039687059976713644]
	TIME [epoch: 9.05 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07284152967786067		[learning rate: 0.0013808]
	Learning Rate: 0.00138081
	LOSS [training: 0.07284152967786067 | validation: 0.08631730876270627]
	TIME [epoch: 9.06 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05236340715590683		[learning rate: 0.0013766]
	Learning Rate: 0.00137658
	LOSS [training: 0.05236340715590683 | validation: 0.021061940985082503]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1146.pth
	Model improved!!!
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05094853700520252		[learning rate: 0.0013724]
	Learning Rate: 0.00137236
	LOSS [training: 0.05094853700520252 | validation: 0.04980096087166978]
	TIME [epoch: 9.06 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04445711641931405		[learning rate: 0.0013681]
	Learning Rate: 0.00136815
	LOSS [training: 0.04445711641931405 | validation: 0.030622021888079082]
	TIME [epoch: 9.06 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0372459488600365		[learning rate: 0.001364]
	Learning Rate: 0.00136395
	LOSS [training: 0.0372459488600365 | validation: 0.0431553582109703]
	TIME [epoch: 9.06 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05558268877046378		[learning rate: 0.0013598]
	Learning Rate: 0.00135977
	LOSS [training: 0.05558268877046378 | validation: 0.05093476338022073]
	TIME [epoch: 9.06 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06494687490626362		[learning rate: 0.0013556]
	Learning Rate: 0.00135561
	LOSS [training: 0.06494687490626362 | validation: 0.05650712176811992]
	TIME [epoch: 9.05 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06250564134700862		[learning rate: 0.0013515]
	Learning Rate: 0.00135145
	LOSS [training: 0.06250564134700862 | validation: 0.05011312118063644]
	TIME [epoch: 9.05 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04283864467144739		[learning rate: 0.0013473]
	Learning Rate: 0.00134731
	LOSS [training: 0.04283864467144739 | validation: 0.033488788923408945]
	TIME [epoch: 9.05 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06015820648468646		[learning rate: 0.0013432]
	Learning Rate: 0.00134318
	LOSS [training: 0.06015820648468646 | validation: 0.03257163412813072]
	TIME [epoch: 9.08 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047787617771477275		[learning rate: 0.0013391]
	Learning Rate: 0.00133906
	LOSS [training: 0.047787617771477275 | validation: 0.03707217150182123]
	TIME [epoch: 9.06 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07973504558914574		[learning rate: 0.001335]
	Learning Rate: 0.00133496
	LOSS [training: 0.07973504558914574 | validation: 0.1174804183645714]
	TIME [epoch: 9.06 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13369273084153094		[learning rate: 0.0013309]
	Learning Rate: 0.00133086
	LOSS [training: 0.13369273084153094 | validation: 0.13796983291521409]
	TIME [epoch: 9.05 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15414333168413277		[learning rate: 0.0013268]
	Learning Rate: 0.00132678
	LOSS [training: 0.15414333168413277 | validation: 0.15163589765014596]
	TIME [epoch: 9.07 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13470804980820605		[learning rate: 0.0013227]
	Learning Rate: 0.00132272
	LOSS [training: 0.13470804980820605 | validation: 0.08128155433338646]
	TIME [epoch: 9.06 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09975705027030245		[learning rate: 0.0013187]
	Learning Rate: 0.00131866
	LOSS [training: 0.09975705027030245 | validation: 0.06760024247285398]
	TIME [epoch: 9.05 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11383631868596611		[learning rate: 0.0013146]
	Learning Rate: 0.00131462
	LOSS [training: 0.11383631868596611 | validation: 0.16102258574916048]
	TIME [epoch: 9.05 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.227744667541362		[learning rate: 0.0013106]
	Learning Rate: 0.00131059
	LOSS [training: 0.227744667541362 | validation: 0.16980754775239432]
	TIME [epoch: 9.06 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14608846164549508		[learning rate: 0.0013066]
	Learning Rate: 0.00130657
	LOSS [training: 0.14608846164549508 | validation: 0.11010697279026113]
	TIME [epoch: 9.07 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11195660164339101		[learning rate: 0.0013026]
	Learning Rate: 0.00130257
	LOSS [training: 0.11195660164339101 | validation: 0.06945162734831331]
	TIME [epoch: 9.06 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09824118536593925		[learning rate: 0.0012986]
	Learning Rate: 0.00129857
	LOSS [training: 0.09824118536593925 | validation: 0.15355413600814966]
	TIME [epoch: 9.06 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1265939245297665		[learning rate: 0.0012946]
	Learning Rate: 0.00129459
	LOSS [training: 0.1265939245297665 | validation: 0.0629631971742589]
	TIME [epoch: 9.07 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06673798479296426		[learning rate: 0.0012906]
	Learning Rate: 0.00129062
	LOSS [training: 0.06673798479296426 | validation: 0.06260795480023584]
	TIME [epoch: 9.07 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06612909539339516		[learning rate: 0.0012867]
	Learning Rate: 0.00128667
	LOSS [training: 0.06612909539339516 | validation: 0.052092130176712756]
	TIME [epoch: 9.06 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062086238431942255		[learning rate: 0.0012827]
	Learning Rate: 0.00128272
	LOSS [training: 0.062086238431942255 | validation: 0.04476720554906788]
	TIME [epoch: 9.05 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058158180521187666		[learning rate: 0.0012788]
	Learning Rate: 0.00127879
	LOSS [training: 0.058158180521187666 | validation: 0.038896136074787396]
	TIME [epoch: 9.06 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053669605794641265		[learning rate: 0.0012749]
	Learning Rate: 0.00127487
	LOSS [training: 0.053669605794641265 | validation: 0.03440209578669242]
	TIME [epoch: 9.07 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05510386072230709		[learning rate: 0.001271]
	Learning Rate: 0.00127096
	LOSS [training: 0.05510386072230709 | validation: 0.05591510719974482]
	TIME [epoch: 9.05 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06511719580210601		[learning rate: 0.0012671]
	Learning Rate: 0.00126707
	LOSS [training: 0.06511719580210601 | validation: 0.047847564239130856]
	TIME [epoch: 9.06 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045216954913974414		[learning rate: 0.0012632]
	Learning Rate: 0.00126318
	LOSS [training: 0.045216954913974414 | validation: 0.03616989533778603]
	TIME [epoch: 9.06 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03717595878847681		[learning rate: 0.0012593]
	Learning Rate: 0.00125931
	LOSS [training: 0.03717595878847681 | validation: 0.041752069646278936]
	TIME [epoch: 9.08 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04133695973167068		[learning rate: 0.0012555]
	Learning Rate: 0.00125545
	LOSS [training: 0.04133695973167068 | validation: 0.024595954279883127]
	TIME [epoch: 9.06 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039056504697017644		[learning rate: 0.0012516]
	Learning Rate: 0.0012516
	LOSS [training: 0.039056504697017644 | validation: 0.021436039657661204]
	TIME [epoch: 9.05 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03555359315387043		[learning rate: 0.0012478]
	Learning Rate: 0.00124777
	LOSS [training: 0.03555359315387043 | validation: 0.02656866181346832]
	TIME [epoch: 9.06 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027025354690098445		[learning rate: 0.0012439]
	Learning Rate: 0.00124394
	LOSS [training: 0.027025354690098445 | validation: 0.02373996272084253]
	TIME [epoch: 9.08 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03329201803224414		[learning rate: 0.0012401]
	Learning Rate: 0.00124013
	LOSS [training: 0.03329201803224414 | validation: 0.044752754591122955]
	TIME [epoch: 9.06 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04138820407160777		[learning rate: 0.0012363]
	Learning Rate: 0.00123633
	LOSS [training: 0.04138820407160777 | validation: 0.01955866059732188]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1181.pth
	Model improved!!!
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02894034156545918		[learning rate: 0.0012325]
	Learning Rate: 0.00123254
	LOSS [training: 0.02894034156545918 | validation: 0.02303570354535521]
	TIME [epoch: 9.06 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03196373638409809		[learning rate: 0.0012288]
	Learning Rate: 0.00122876
	LOSS [training: 0.03196373638409809 | validation: 0.021219755137663707]
	TIME [epoch: 9.07 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0283408081757614		[learning rate: 0.001225]
	Learning Rate: 0.00122499
	LOSS [training: 0.0283408081757614 | validation: 0.023165470954177942]
	TIME [epoch: 9.05 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02981570405493414		[learning rate: 0.0012212]
	Learning Rate: 0.00122124
	LOSS [training: 0.02981570405493414 | validation: 0.049364639616883366]
	TIME [epoch: 9.05 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04282215848013134		[learning rate: 0.0012175]
	Learning Rate: 0.00121749
	LOSS [training: 0.04282215848013134 | validation: 0.0500619269063487]
	TIME [epoch: 9.06 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05487245944846651		[learning rate: 0.0012138]
	Learning Rate: 0.00121376
	LOSS [training: 0.05487245944846651 | validation: 0.03457865592286927]
	TIME [epoch: 9.05 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038632245202273194		[learning rate: 0.00121]
	Learning Rate: 0.00121004
	LOSS [training: 0.038632245202273194 | validation: 0.01783879024993399]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1188.pth
	Model improved!!!
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031894229359511354		[learning rate: 0.0012063]
	Learning Rate: 0.00120633
	LOSS [training: 0.031894229359511354 | validation: 0.030483873165081485]
	TIME [epoch: 9.05 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032217931958591225		[learning rate: 0.0012026]
	Learning Rate: 0.00120263
	LOSS [training: 0.032217931958591225 | validation: 0.035651016942131575]
	TIME [epoch: 9.04 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030068241863502383		[learning rate: 0.0011989]
	Learning Rate: 0.00119895
	LOSS [training: 0.030068241863502383 | validation: 0.0350899554580147]
	TIME [epoch: 9.04 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060141644699424276		[learning rate: 0.0011953]
	Learning Rate: 0.00119527
	LOSS [training: 0.060141644699424276 | validation: 0.02246611350401635]
	TIME [epoch: 9.06 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026442997871469587		[learning rate: 0.0011916]
	Learning Rate: 0.00119161
	LOSS [training: 0.026442997871469587 | validation: 0.014884392889859129]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1193.pth
	Model improved!!!
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028685028597796237		[learning rate: 0.001188]
	Learning Rate: 0.00118795
	LOSS [training: 0.028685028597796237 | validation: 0.01978176103092262]
	TIME [epoch: 9.05 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03581202771903565		[learning rate: 0.0011843]
	Learning Rate: 0.00118431
	LOSS [training: 0.03581202771903565 | validation: 0.033288911736302586]
	TIME [epoch: 9.05 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034375983349555425		[learning rate: 0.0011807]
	Learning Rate: 0.00118068
	LOSS [training: 0.034375983349555425 | validation: 0.021940586433331417]
	TIME [epoch: 9.06 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03072198681775673		[learning rate: 0.0011771]
	Learning Rate: 0.00117706
	LOSS [training: 0.03072198681775673 | validation: 0.035113786327338185]
	TIME [epoch: 9.06 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05010306687259142		[learning rate: 0.0011735]
	Learning Rate: 0.00117346
	LOSS [training: 0.05010306687259142 | validation: 0.03754945747155654]
	TIME [epoch: 9.05 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029466406818075434		[learning rate: 0.0011699]
	Learning Rate: 0.00116986
	LOSS [training: 0.029466406818075434 | validation: 0.026882337669439565]
	TIME [epoch: 9.04 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03755856021427418		[learning rate: 0.0011663]
	Learning Rate: 0.00116627
	LOSS [training: 0.03755856021427418 | validation: 0.03065290812710767]
	TIME [epoch: 9.04 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026352054359441435		[learning rate: 0.0011627]
	Learning Rate: 0.0011627
	LOSS [training: 0.026352054359441435 | validation: 0.032445882220319355]
	TIME [epoch: 9.07 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025769870295934617		[learning rate: 0.0011591]
	Learning Rate: 0.00115913
	LOSS [training: 0.025769870295934617 | validation: 0.012714868034683394]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1202.pth
	Model improved!!!
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020438391451024367		[learning rate: 0.0011556]
	Learning Rate: 0.00115558
	LOSS [training: 0.020438391451024367 | validation: 0.019281782666549497]
	TIME [epoch: 9.05 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02803460388207362		[learning rate: 0.001152]
	Learning Rate: 0.00115204
	LOSS [training: 0.02803460388207362 | validation: 0.02892656684667978]
	TIME [epoch: 9.05 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029535171716074178		[learning rate: 0.0011485]
	Learning Rate: 0.00114851
	LOSS [training: 0.029535171716074178 | validation: 0.012295244336050693]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1205.pth
	Model improved!!!
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024464344171841516		[learning rate: 0.001145]
	Learning Rate: 0.00114499
	LOSS [training: 0.024464344171841516 | validation: 0.015169337779564205]
	TIME [epoch: 9.05 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02820564349345237		[learning rate: 0.0011415]
	Learning Rate: 0.00114148
	LOSS [training: 0.02820564349345237 | validation: 0.0213996958550706]
	TIME [epoch: 9.05 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025070484737641917		[learning rate: 0.001138]
	Learning Rate: 0.00113798
	LOSS [training: 0.025070484737641917 | validation: 0.022695159338559256]
	TIME [epoch: 9.05 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03388140387318407		[learning rate: 0.0011345]
	Learning Rate: 0.00113449
	LOSS [training: 0.03388140387318407 | validation: 0.039329239687932935]
	TIME [epoch: 9.04 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054288183208371296		[learning rate: 0.001131]
	Learning Rate: 0.00113101
	LOSS [training: 0.054288183208371296 | validation: 0.04468456931527796]
	TIME [epoch: 9.07 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03369129388766975		[learning rate: 0.0011275]
	Learning Rate: 0.00112754
	LOSS [training: 0.03369129388766975 | validation: 0.0220829910627739]
	TIME [epoch: 9.04 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027227166472778237		[learning rate: 0.0011241]
	Learning Rate: 0.00112409
	LOSS [training: 0.027227166472778237 | validation: 0.008261963943875579]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1212.pth
	Model improved!!!
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01954040865073462		[learning rate: 0.0011206]
	Learning Rate: 0.00112064
	LOSS [training: 0.01954040865073462 | validation: 0.00940478773424857]
	TIME [epoch: 9.05 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03052294895386385		[learning rate: 0.0011172]
	Learning Rate: 0.00111721
	LOSS [training: 0.03052294895386385 | validation: 0.02561902269868991]
	TIME [epoch: 9.06 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047902108343746766		[learning rate: 0.0011138]
	Learning Rate: 0.00111378
	LOSS [training: 0.047902108343746766 | validation: 0.019994468253545138]
	TIME [epoch: 9.05 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024037067197195526		[learning rate: 0.0011104]
	Learning Rate: 0.00111037
	LOSS [training: 0.024037067197195526 | validation: 0.023241938101003834]
	TIME [epoch: 9.04 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029361569490202903		[learning rate: 0.001107]
	Learning Rate: 0.00110696
	LOSS [training: 0.029361569490202903 | validation: 0.011431733950209157]
	TIME [epoch: 9.04 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06884240943505932		[learning rate: 0.0011036]
	Learning Rate: 0.00110357
	LOSS [training: 0.06884240943505932 | validation: 0.04625523788760272]
	TIME [epoch: 9.05 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04309905512859188		[learning rate: 0.0011002]
	Learning Rate: 0.00110019
	LOSS [training: 0.04309905512859188 | validation: 0.03666626105502784]
	TIME [epoch: 9.06 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031717951794329576		[learning rate: 0.0010968]
	Learning Rate: 0.00109681
	LOSS [training: 0.031717951794329576 | validation: 0.02024561060106745]
	TIME [epoch: 9.04 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03094833560498054		[learning rate: 0.0010935]
	Learning Rate: 0.00109345
	LOSS [training: 0.03094833560498054 | validation: 0.027340562592417662]
	TIME [epoch: 9.04 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053981444792119526		[learning rate: 0.0010901]
	Learning Rate: 0.0010901
	LOSS [training: 0.053981444792119526 | validation: 0.07334766498670936]
	TIME [epoch: 9.05 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07731601213958078		[learning rate: 0.0010868]
	Learning Rate: 0.00108676
	LOSS [training: 0.07731601213958078 | validation: 0.1327942304077666]
	TIME [epoch: 9.07 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1294047577666999		[learning rate: 0.0010834]
	Learning Rate: 0.00108343
	LOSS [training: 0.1294047577666999 | validation: 0.044802064688552294]
	TIME [epoch: 9.04 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047751343138282484		[learning rate: 0.0010801]
	Learning Rate: 0.00108011
	LOSS [training: 0.047751343138282484 | validation: 0.0387965937178924]
	TIME [epoch: 9.04 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035127773697357687		[learning rate: 0.0010768]
	Learning Rate: 0.0010768
	LOSS [training: 0.035127773697357687 | validation: 0.026566538092491238]
	TIME [epoch: 9.04 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0607472849696167		[learning rate: 0.0010735]
	Learning Rate: 0.00107349
	LOSS [training: 0.0607472849696167 | validation: 0.025838283418493955]
	TIME [epoch: 9.07 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04545013396632308		[learning rate: 0.0010702]
	Learning Rate: 0.0010702
	LOSS [training: 0.04545013396632308 | validation: 0.0384197976171962]
	TIME [epoch: 9.05 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053743358291159636		[learning rate: 0.0010669]
	Learning Rate: 0.00106692
	LOSS [training: 0.053743358291159636 | validation: 0.04012011751602332]
	TIME [epoch: 9.04 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06312071762137468		[learning rate: 0.0010637]
	Learning Rate: 0.00106365
	LOSS [training: 0.06312071762137468 | validation: 0.03696314284994807]
	TIME [epoch: 9.04 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054162103013799236		[learning rate: 0.0010604]
	Learning Rate: 0.00106039
	LOSS [training: 0.054162103013799236 | validation: 0.05557235643290253]
	TIME [epoch: 9.06 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057135711258983465		[learning rate: 0.0010571]
	Learning Rate: 0.00105714
	LOSS [training: 0.057135711258983465 | validation: 0.02283911915966226]
	TIME [epoch: 9.05 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02627601822731443		[learning rate: 0.0010539]
	Learning Rate: 0.0010539
	LOSS [training: 0.02627601822731443 | validation: 0.036977511432933936]
	TIME [epoch: 9.04 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030341761025376224		[learning rate: 0.0010507]
	Learning Rate: 0.00105067
	LOSS [training: 0.030341761025376224 | validation: 0.022127486592838037]
	TIME [epoch: 9.04 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07698055417434778		[learning rate: 0.0010475]
	Learning Rate: 0.00104745
	LOSS [training: 0.07698055417434778 | validation: 0.08752095519385794]
	TIME [epoch: 9.06 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12571187407511353		[learning rate: 0.0010442]
	Learning Rate: 0.00104424
	LOSS [training: 0.12571187407511353 | validation: 0.08490620463414678]
	TIME [epoch: 9.06 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06783407355089024		[learning rate: 0.001041]
	Learning Rate: 0.00104104
	LOSS [training: 0.06783407355089024 | validation: 0.05672063724426019]
	TIME [epoch: 9.04 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06147366050341534		[learning rate: 0.0010378]
	Learning Rate: 0.00103785
	LOSS [training: 0.06147366050341534 | validation: 0.04226141222075311]
	TIME [epoch: 9.05 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0595161587767303		[learning rate: 0.0010347]
	Learning Rate: 0.00103467
	LOSS [training: 0.0595161587767303 | validation: 0.03996295330229607]
	TIME [epoch: 9.06 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051515558514659165		[learning rate: 0.0010315]
	Learning Rate: 0.00103149
	LOSS [training: 0.051515558514659165 | validation: 0.04379434846131081]
	TIME [epoch: 9.06 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0403840898611333		[learning rate: 0.0010283]
	Learning Rate: 0.00102833
	LOSS [training: 0.0403840898611333 | validation: 0.045621073365948325]
	TIME [epoch: 9.05 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05653035437170374		[learning rate: 0.0010252]
	Learning Rate: 0.00102518
	LOSS [training: 0.05653035437170374 | validation: 0.04091525312006469]
	TIME [epoch: 9.05 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05237396520145401		[learning rate: 0.001022]
	Learning Rate: 0.00102204
	LOSS [training: 0.05237396520145401 | validation: 0.04689247562758083]
	TIME [epoch: 9.05 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051860272029150264		[learning rate: 0.0010189]
	Learning Rate: 0.0010189
	LOSS [training: 0.051860272029150264 | validation: 0.038121291960997436]
	TIME [epoch: 9.07 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04405428633174477		[learning rate: 0.0010158]
	Learning Rate: 0.00101578
	LOSS [training: 0.04405428633174477 | validation: 0.04014074874243705]
	TIME [epoch: 9.05 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07992164173732888		[learning rate: 0.0010127]
	Learning Rate: 0.00101267
	LOSS [training: 0.07992164173732888 | validation: 0.09929366688712589]
	TIME [epoch: 9.05 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08205095619778793		[learning rate: 0.0010096]
	Learning Rate: 0.00100956
	LOSS [training: 0.08205095619778793 | validation: 0.029901390665336324]
	TIME [epoch: 9.05 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033358207146083375		[learning rate: 0.0010065]
	Learning Rate: 0.00100647
	LOSS [training: 0.033358207146083375 | validation: 0.013112744533677962]
	TIME [epoch: 9.07 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02837346821728275		[learning rate: 0.0010034]
	Learning Rate: 0.00100338
	LOSS [training: 0.02837346821728275 | validation: 0.00923661445201667]
	TIME [epoch: 9.05 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028587439477439674		[learning rate: 0.0010003]
	Learning Rate: 0.00100031
	LOSS [training: 0.028587439477439674 | validation: 0.020326127693974846]
	TIME [epoch: 9.05 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028344165437139433		[learning rate: 0.00099724]
	Learning Rate: 0.000997241
	LOSS [training: 0.028344165437139433 | validation: 0.02989656004135774]
	TIME [epoch: 9.05 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03826461335567933		[learning rate: 0.00099418]
	Learning Rate: 0.000994184
	LOSS [training: 0.03826461335567933 | validation: 0.02373033265441397]
	TIME [epoch: 9.07 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03773761563696772		[learning rate: 0.00099114]
	Learning Rate: 0.000991136
	LOSS [training: 0.03773761563696772 | validation: 0.030302315356035767]
	TIME [epoch: 9.05 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03799812774460184		[learning rate: 0.0009881]
	Learning Rate: 0.000988098
	LOSS [training: 0.03799812774460184 | validation: 0.04219143396080456]
	TIME [epoch: 9.05 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03961834737150101		[learning rate: 0.00098507]
	Learning Rate: 0.000985069
	LOSS [training: 0.03961834737150101 | validation: 0.019163744257168495]
	TIME [epoch: 9.05 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038099305093366086		[learning rate: 0.00098205]
	Learning Rate: 0.00098205
	LOSS [training: 0.038099305093366086 | validation: 0.017733493943228994]
	TIME [epoch: 9.07 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04662681941722653		[learning rate: 0.00097904]
	Learning Rate: 0.000979039
	LOSS [training: 0.04662681941722653 | validation: 0.02236745135424687]
	TIME [epoch: 9.05 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049510722942952626		[learning rate: 0.00097604]
	Learning Rate: 0.000976038
	LOSS [training: 0.049510722942952626 | validation: 0.043883220867202075]
	TIME [epoch: 9.05 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06724863523145011		[learning rate: 0.00097305]
	Learning Rate: 0.000973046
	LOSS [training: 0.06724863523145011 | validation: 0.03426397901605118]
	TIME [epoch: 9.07 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05312628961015534		[learning rate: 0.00097006]
	Learning Rate: 0.000970063
	LOSS [training: 0.05312628961015534 | validation: 0.04081447138950221]
	TIME [epoch: 9.07 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0651728190335644		[learning rate: 0.00096709]
	Learning Rate: 0.000967089
	LOSS [training: 0.0651728190335644 | validation: 0.07878287472478544]
	TIME [epoch: 9.05 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08739043032738127		[learning rate: 0.00096412]
	Learning Rate: 0.000964125
	LOSS [training: 0.08739043032738127 | validation: 0.05758766752201108]
	TIME [epoch: 9.04 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.076603943263135		[learning rate: 0.00096117]
	Learning Rate: 0.00096117
	LOSS [training: 0.076603943263135 | validation: 0.05773938283496978]
	TIME [epoch: 9.05 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05924370010699206		[learning rate: 0.00095822]
	Learning Rate: 0.000958223
	LOSS [training: 0.05924370010699206 | validation: 0.061142883551563595]
	TIME [epoch: 9.05 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05868862724637449		[learning rate: 0.00095529]
	Learning Rate: 0.000955286
	LOSS [training: 0.05868862724637449 | validation: 0.0355344278913738]
	TIME [epoch: 9.06 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04924774480451858		[learning rate: 0.00095236]
	Learning Rate: 0.000952357
	LOSS [training: 0.04924774480451858 | validation: 0.03246861716396672]
	TIME [epoch: 9.03 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05913338708364234		[learning rate: 0.00094944]
	Learning Rate: 0.000949438
	LOSS [training: 0.05913338708364234 | validation: 0.04999761912009767]
	TIME [epoch: 9.05 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05044764826757029		[learning rate: 0.00094653]
	Learning Rate: 0.000946528
	LOSS [training: 0.05044764826757029 | validation: 0.021664810229035998]
	TIME [epoch: 9.05 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04305308309795518		[learning rate: 0.00094363]
	Learning Rate: 0.000943626
	LOSS [training: 0.04305308309795518 | validation: 0.04174739769322637]
	TIME [epoch: 9.08 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054350066745274386		[learning rate: 0.00094073]
	Learning Rate: 0.000940734
	LOSS [training: 0.054350066745274386 | validation: 0.03672392101590951]
	TIME [epoch: 9.06 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04685026089368221		[learning rate: 0.00093785]
	Learning Rate: 0.00093785
	LOSS [training: 0.04685026089368221 | validation: 0.03824943383461439]
	TIME [epoch: 9.06 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03754812106426948		[learning rate: 0.00093497]
	Learning Rate: 0.000934975
	LOSS [training: 0.03754812106426948 | validation: 0.02450216257637784]
	TIME [epoch: 9.05 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03669927841267838		[learning rate: 0.00093211]
	Learning Rate: 0.000932109
	LOSS [training: 0.03669927841267838 | validation: 0.023676324537446704]
	TIME [epoch: 9.08 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03565925345583608		[learning rate: 0.00092925]
	Learning Rate: 0.000929252
	LOSS [training: 0.03565925345583608 | validation: 0.010677527301733963]
	TIME [epoch: 9.06 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04473160378567522		[learning rate: 0.0009264]
	Learning Rate: 0.000926403
	LOSS [training: 0.04473160378567522 | validation: 0.026438985016477363]
	TIME [epoch: 9.05 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037639748147945115		[learning rate: 0.00092356]
	Learning Rate: 0.000923563
	LOSS [training: 0.037639748147945115 | validation: 0.021823785420881966]
	TIME [epoch: 9.04 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03332454921839564		[learning rate: 0.00092073]
	Learning Rate: 0.000920732
	LOSS [training: 0.03332454921839564 | validation: 0.021354219809283936]
	TIME [epoch: 9.06 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033605256606655344		[learning rate: 0.00091791]
	Learning Rate: 0.00091791
	LOSS [training: 0.033605256606655344 | validation: 0.021381286660188514]
	TIME [epoch: 9.05 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03436304452337231		[learning rate: 0.0009151]
	Learning Rate: 0.000915096
	LOSS [training: 0.03436304452337231 | validation: 0.017041741330915718]
	TIME [epoch: 9.05 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04222058084257559		[learning rate: 0.00091229]
	Learning Rate: 0.000912291
	LOSS [training: 0.04222058084257559 | validation: 0.037098867799876256]
	TIME [epoch: 9.05 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050764509507040236		[learning rate: 0.00090949]
	Learning Rate: 0.000909494
	LOSS [training: 0.050764509507040236 | validation: 0.023608827026895377]
	TIME [epoch: 9.06 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037797814663555473		[learning rate: 0.00090671]
	Learning Rate: 0.000906706
	LOSS [training: 0.037797814663555473 | validation: 0.01915991754113433]
	TIME [epoch: 9.05 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032933673489614054		[learning rate: 0.00090393]
	Learning Rate: 0.000903927
	LOSS [training: 0.032933673489614054 | validation: 0.02030110684630236]
	TIME [epoch: 9.04 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03752711325123456		[learning rate: 0.00090116]
	Learning Rate: 0.000901156
	LOSS [training: 0.03752711325123456 | validation: 0.02476852856643006]
	TIME [epoch: 9.04 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037532997111930505		[learning rate: 0.00089839]
	Learning Rate: 0.000898394
	LOSS [training: 0.037532997111930505 | validation: 0.025195502690037605]
	TIME [epoch: 9.06 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04420356819839597		[learning rate: 0.00089564]
	Learning Rate: 0.00089564
	LOSS [training: 0.04420356819839597 | validation: 0.041319869854518285]
	TIME [epoch: 9.04 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060654205144679174		[learning rate: 0.00089289]
	Learning Rate: 0.000892894
	LOSS [training: 0.060654205144679174 | validation: 0.02934796933224531]
	TIME [epoch: 9.03 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04248649699326256		[learning rate: 0.00089016]
	Learning Rate: 0.000890157
	LOSS [training: 0.04248649699326256 | validation: 0.030672052570595163]
	TIME [epoch: 9.03 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04942595825206979		[learning rate: 0.00088743]
	Learning Rate: 0.000887428
	LOSS [training: 0.04942595825206979 | validation: 0.0370082422513619]
	TIME [epoch: 9.04 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05148087949037089		[learning rate: 0.00088471]
	Learning Rate: 0.000884708
	LOSS [training: 0.05148087949037089 | validation: 0.035967354517409726]
	TIME [epoch: 9.05 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04344017450508543		[learning rate: 0.000882]
	Learning Rate: 0.000881996
	LOSS [training: 0.04344017450508543 | validation: 0.029533569021984993]
	TIME [epoch: 9.03 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03952110733804192		[learning rate: 0.00087929]
	Learning Rate: 0.000879292
	LOSS [training: 0.03952110733804192 | validation: 0.028585814900828253]
	TIME [epoch: 9.04 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034381113638913594		[learning rate: 0.0008766]
	Learning Rate: 0.000876597
	LOSS [training: 0.034381113638913594 | validation: 0.030161404268336668]
	TIME [epoch: 9.04 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05130049337918274		[learning rate: 0.00087391]
	Learning Rate: 0.00087391
	LOSS [training: 0.05130049337918274 | validation: 0.07339750299991893]
	TIME [epoch: 9.05 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07089093694790073		[learning rate: 0.00087123]
	Learning Rate: 0.000871231
	LOSS [training: 0.07089093694790073 | validation: 0.043464202309292266]
	TIME [epoch: 9.03 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052052463461457435		[learning rate: 0.00086856]
	Learning Rate: 0.00086856
	LOSS [training: 0.052052463461457435 | validation: 0.046159433821719775]
	TIME [epoch: 9.03 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05573503620673853		[learning rate: 0.0008659]
	Learning Rate: 0.000865898
	LOSS [training: 0.05573503620673853 | validation: 0.03274384831923585]
	TIME [epoch: 9.03 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058445854224754415		[learning rate: 0.00086324]
	Learning Rate: 0.000863243
	LOSS [training: 0.058445854224754415 | validation: 0.0533328754651152]
	TIME [epoch: 9.06 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0565006236585362		[learning rate: 0.0008606]
	Learning Rate: 0.000860597
	LOSS [training: 0.0565006236585362 | validation: 0.0225290812503027]
	TIME [epoch: 9.04 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04323572294123328		[learning rate: 0.00085796]
	Learning Rate: 0.000857959
	LOSS [training: 0.04323572294123328 | validation: 0.03510923876211342]
	TIME [epoch: 9.05 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03911947781369243		[learning rate: 0.00085533]
	Learning Rate: 0.000855329
	LOSS [training: 0.03911947781369243 | validation: 0.02588741498239671]
	TIME [epoch: 9.04 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03724977565510982		[learning rate: 0.00085271]
	Learning Rate: 0.000852707
	LOSS [training: 0.03724977565510982 | validation: 0.029357606535866672]
	TIME [epoch: 9.08 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041423148752013375		[learning rate: 0.00085009]
	Learning Rate: 0.000850093
	LOSS [training: 0.041423148752013375 | validation: 0.04897408667099636]
	TIME [epoch: 9.05 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07292622118087946		[learning rate: 0.00084749]
	Learning Rate: 0.000847488
	LOSS [training: 0.07292622118087946 | validation: 0.05730616777370532]
	TIME [epoch: 9.05 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0678529751748082		[learning rate: 0.00084489]
	Learning Rate: 0.00084489
	LOSS [training: 0.0678529751748082 | validation: 0.037097722496126334]
	TIME [epoch: 9.04 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038426518985602884		[learning rate: 0.0008423]
	Learning Rate: 0.0008423
	LOSS [training: 0.038426518985602884 | validation: 0.04237645778010504]
	TIME [epoch: 9.06 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046524637817396845		[learning rate: 0.00083972]
	Learning Rate: 0.000839718
	LOSS [training: 0.046524637817396845 | validation: 0.01427048762366654]
	TIME [epoch: 9.05 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03635617872587639		[learning rate: 0.00083714]
	Learning Rate: 0.000837144
	LOSS [training: 0.03635617872587639 | validation: 0.025667009277531006]
	TIME [epoch: 9.05 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034080330989738616		[learning rate: 0.00083458]
	Learning Rate: 0.000834578
	LOSS [training: 0.034080330989738616 | validation: 0.026258893741122346]
	TIME [epoch: 9.05 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04215008102776406		[learning rate: 0.00083202]
	Learning Rate: 0.000832019
	LOSS [training: 0.04215008102776406 | validation: 0.03361072458593993]
	TIME [epoch: 9.05 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053773228142744336		[learning rate: 0.00082947]
	Learning Rate: 0.000829469
	LOSS [training: 0.053773228142744336 | validation: 0.04732285702634572]
	TIME [epoch: 9.05 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041869012734868906		[learning rate: 0.00082693]
	Learning Rate: 0.000826926
	LOSS [training: 0.041869012734868906 | validation: 0.025825681496887874]
	TIME [epoch: 9.05 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03516337983900921		[learning rate: 0.00082439]
	Learning Rate: 0.000824391
	LOSS [training: 0.03516337983900921 | validation: 0.017789767088224204]
	TIME [epoch: 9.04 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033696576860369316		[learning rate: 0.00082186]
	Learning Rate: 0.000821864
	LOSS [training: 0.033696576860369316 | validation: 0.023918950803634362]
	TIME [epoch: 9.05 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03296109681700073		[learning rate: 0.00081934]
	Learning Rate: 0.000819345
	LOSS [training: 0.03296109681700073 | validation: 0.02306942960555368]
	TIME [epoch: 9.07 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030493079269184015		[learning rate: 0.00081683]
	Learning Rate: 0.000816833
	LOSS [training: 0.030493079269184015 | validation: 0.021916895228020407]
	TIME [epoch: 9.06 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035059473053947035		[learning rate: 0.00081433]
	Learning Rate: 0.000814329
	LOSS [training: 0.035059473053947035 | validation: 0.038762219148281374]
	TIME [epoch: 9.05 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05993609692333227		[learning rate: 0.00081183]
	Learning Rate: 0.000811833
	LOSS [training: 0.05993609692333227 | validation: 0.026223931190594383]
	TIME [epoch: 9.06 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039884944484730636		[learning rate: 0.00080934]
	Learning Rate: 0.000809344
	LOSS [training: 0.039884944484730636 | validation: 0.024831939370327905]
	TIME [epoch: 9.07 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0432539415765709		[learning rate: 0.00080686]
	Learning Rate: 0.000806863
	LOSS [training: 0.0432539415765709 | validation: 0.023914811649384225]
	TIME [epoch: 9.04 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0448639944260711		[learning rate: 0.00080439]
	Learning Rate: 0.00080439
	LOSS [training: 0.0448639944260711 | validation: 0.026627802922350674]
	TIME [epoch: 9.04 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047756963789695836		[learning rate: 0.00080192]
	Learning Rate: 0.000801924
	LOSS [training: 0.047756963789695836 | validation: 0.03794467416015179]
	TIME [epoch: 9.05 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04012945947371312		[learning rate: 0.00079947]
	Learning Rate: 0.000799466
	LOSS [training: 0.04012945947371312 | validation: 0.01824273260943691]
	TIME [epoch: 9.06 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036029677019057946		[learning rate: 0.00079702]
	Learning Rate: 0.000797015
	LOSS [training: 0.036029677019057946 | validation: 0.020654375810940304]
	TIME [epoch: 9.05 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030720910023222414		[learning rate: 0.00079457]
	Learning Rate: 0.000794572
	LOSS [training: 0.030720910023222414 | validation: 0.01967316475505245]
	TIME [epoch: 9.05 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034368232264949984		[learning rate: 0.00079214]
	Learning Rate: 0.000792136
	LOSS [training: 0.034368232264949984 | validation: 0.03032221436001989]
	TIME [epoch: 9.04 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03235133348995166		[learning rate: 0.00078971]
	Learning Rate: 0.000789708
	LOSS [training: 0.03235133348995166 | validation: 0.02563704776580124]
	TIME [epoch: 9.06 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036445965396245186		[learning rate: 0.00078729]
	Learning Rate: 0.000787287
	LOSS [training: 0.036445965396245186 | validation: 0.025383563191586894]
	TIME [epoch: 9.05 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029506883045945363		[learning rate: 0.00078487]
	Learning Rate: 0.000784874
	LOSS [training: 0.029506883045945363 | validation: 0.019386365447407482]
	TIME [epoch: 9.05 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028853680585862594		[learning rate: 0.00078247]
	Learning Rate: 0.000782468
	LOSS [training: 0.028853680585862594 | validation: 0.029152459144302225]
	TIME [epoch: 9.04 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03357208961102716		[learning rate: 0.00078007]
	Learning Rate: 0.00078007
	LOSS [training: 0.03357208961102716 | validation: 0.024176424033101863]
	TIME [epoch: 9.05 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03284175319959217		[learning rate: 0.00077768]
	Learning Rate: 0.000777678
	LOSS [training: 0.03284175319959217 | validation: 0.01960113226070145]
	TIME [epoch: 9.06 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03189634239904111		[learning rate: 0.00077529]
	Learning Rate: 0.000775294
	LOSS [training: 0.03189634239904111 | validation: 0.018355479038130937]
	TIME [epoch: 9.04 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030811644505306112		[learning rate: 0.00077292]
	Learning Rate: 0.000772918
	LOSS [training: 0.030811644505306112 | validation: 0.023810006973975263]
	TIME [epoch: 9.05 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02777825600374854		[learning rate: 0.00077055]
	Learning Rate: 0.000770548
	LOSS [training: 0.02777825600374854 | validation: 0.01995472300709899]
	TIME [epoch: 9.05 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025130555058648973		[learning rate: 0.00076819]
	Learning Rate: 0.000768187
	LOSS [training: 0.025130555058648973 | validation: 0.016430081157130575]
	TIME [epoch: 9.05 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025179745100258066		[learning rate: 0.00076583]
	Learning Rate: 0.000765832
	LOSS [training: 0.025179745100258066 | validation: 0.013334222599758961]
	TIME [epoch: 9.04 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03063992010945757		[learning rate: 0.00076348]
	Learning Rate: 0.000763484
	LOSS [training: 0.03063992010945757 | validation: 0.011633762584702079]
	TIME [epoch: 9.04 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02256950204425817		[learning rate: 0.00076114]
	Learning Rate: 0.000761144
	LOSS [training: 0.02256950204425817 | validation: 0.006647471771982754]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1339.pth
	Model improved!!!
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03096396551903454		[learning rate: 0.00075881]
	Learning Rate: 0.00075881
	LOSS [training: 0.03096396551903454 | validation: 0.02186907752494616]
	TIME [epoch: 9.06 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02481750972909408		[learning rate: 0.00075648]
	Learning Rate: 0.000756484
	LOSS [training: 0.02481750972909408 | validation: 0.02680578602522197]
	TIME [epoch: 9.04 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029804408972779983		[learning rate: 0.00075417]
	Learning Rate: 0.000754165
	LOSS [training: 0.029804408972779983 | validation: 0.02161025535587929]
	TIME [epoch: 9.04 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027336415494965693		[learning rate: 0.00075185]
	Learning Rate: 0.000751854
	LOSS [training: 0.027336415494965693 | validation: 0.026087021570676088]
	TIME [epoch: 9.04 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02905982882332429		[learning rate: 0.00074955]
	Learning Rate: 0.000749549
	LOSS [training: 0.02905982882332429 | validation: 0.014652769069120785]
	TIME [epoch: 9.06 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029838440514933673		[learning rate: 0.00074725]
	Learning Rate: 0.000747251
	LOSS [training: 0.029838440514933673 | validation: 0.010067696918684935]
	TIME [epoch: 9.05 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03453644777759276		[learning rate: 0.00074496]
	Learning Rate: 0.000744961
	LOSS [training: 0.03453644777759276 | validation: 0.004334209913684836]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1346.pth
	Model improved!!!
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02364018516851941		[learning rate: 0.00074268]
	Learning Rate: 0.000742677
	LOSS [training: 0.02364018516851941 | validation: 0.0268214570322921]
	TIME [epoch: 9.04 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02653447096374128		[learning rate: 0.0007404]
	Learning Rate: 0.0007404
	LOSS [training: 0.02653447096374128 | validation: 0.01462738742526598]
	TIME [epoch: 9.05 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03606530892085153		[learning rate: 0.00073813]
	Learning Rate: 0.000738131
	LOSS [training: 0.03606530892085153 | validation: 0.02810687265920822]
	TIME [epoch: 9.06 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03133293001770419		[learning rate: 0.00073587]
	Learning Rate: 0.000735868
	LOSS [training: 0.03133293001770419 | validation: 0.007600080816815876]
	TIME [epoch: 9.04 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02550935792969536		[learning rate: 0.00073361]
	Learning Rate: 0.000733612
	LOSS [training: 0.02550935792969536 | validation: 0.009715617559908964]
	TIME [epoch: 9.04 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028832485900090493		[learning rate: 0.00073136]
	Learning Rate: 0.000731364
	LOSS [training: 0.028832485900090493 | validation: 0.0252121878993513]
	TIME [epoch: 9.04 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0276471767622637		[learning rate: 0.00072912]
	Learning Rate: 0.000729122
	LOSS [training: 0.0276471767622637 | validation: 0.020645424456198942]
	TIME [epoch: 9.06 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02409588471022452		[learning rate: 0.00072689]
	Learning Rate: 0.000726886
	LOSS [training: 0.02409588471022452 | validation: 0.012699635315228178]
	TIME [epoch: 9.04 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022590033435977687		[learning rate: 0.00072466]
	Learning Rate: 0.000724658
	LOSS [training: 0.022590033435977687 | validation: 0.014303221941311624]
	TIME [epoch: 9.04 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01948175040130171		[learning rate: 0.00072244]
	Learning Rate: 0.000722437
	LOSS [training: 0.01948175040130171 | validation: 0.008351569366318787]
	TIME [epoch: 9.04 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020969539633800723		[learning rate: 0.00072022]
	Learning Rate: 0.000720223
	LOSS [training: 0.020969539633800723 | validation: 0.022151782865546553]
	TIME [epoch: 9.06 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02332516727084429		[learning rate: 0.00071801]
	Learning Rate: 0.000718015
	LOSS [training: 0.02332516727084429 | validation: 0.028043418804586488]
	TIME [epoch: 9.05 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06813996097964585		[learning rate: 0.00071581]
	Learning Rate: 0.000715814
	LOSS [training: 0.06813996097964585 | validation: 0.039127207288710955]
	TIME [epoch: 9.04 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05023890915420652		[learning rate: 0.00071362]
	Learning Rate: 0.000713619
	LOSS [training: 0.05023890915420652 | validation: 0.01999515364216407]
	TIME [epoch: 9.04 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029538519048691154		[learning rate: 0.00071143]
	Learning Rate: 0.000711432
	LOSS [training: 0.029538519048691154 | validation: 0.00516048817922855]
	TIME [epoch: 9.05 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022509019975133562		[learning rate: 0.00070925]
	Learning Rate: 0.000709251
	LOSS [training: 0.022509019975133562 | validation: 0.013058256896655738]
	TIME [epoch: 9.04 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02789687171163254		[learning rate: 0.00070708]
	Learning Rate: 0.000707077
	LOSS [training: 0.02789687171163254 | validation: 0.01600216593475848]
	TIME [epoch: 9.04 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03272973708291564		[learning rate: 0.00070491]
	Learning Rate: 0.00070491
	LOSS [training: 0.03272973708291564 | validation: 0.03371099726540679]
	TIME [epoch: 9.04 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03942587254899007		[learning rate: 0.00070275]
	Learning Rate: 0.000702748
	LOSS [training: 0.03942587254899007 | validation: 0.028797408855627434]
	TIME [epoch: 9.05 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03175038006587565		[learning rate: 0.00070059]
	Learning Rate: 0.000700594
	LOSS [training: 0.03175038006587565 | validation: 0.02195570087016325]
	TIME [epoch: 9.06 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024482294584291665		[learning rate: 0.00069845]
	Learning Rate: 0.000698447
	LOSS [training: 0.024482294584291665 | validation: 0.027438656284252225]
	TIME [epoch: 9.04 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04673872354504844		[learning rate: 0.00069631]
	Learning Rate: 0.000696306
	LOSS [training: 0.04673872354504844 | validation: 0.03703625534355574]
	TIME [epoch: 9.05 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04391049690348234		[learning rate: 0.00069417]
	Learning Rate: 0.000694171
	LOSS [training: 0.04391049690348234 | validation: 0.03356740603280714]
	TIME [epoch: 9.04 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036318755113322394		[learning rate: 0.00069204]
	Learning Rate: 0.000692043
	LOSS [training: 0.036318755113322394 | validation: 0.016895310846271362]
	TIME [epoch: 9.06 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03849864035253753		[learning rate: 0.00068992]
	Learning Rate: 0.000689922
	LOSS [training: 0.03849864035253753 | validation: 0.029065207303735338]
	TIME [epoch: 9.05 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040354876224433414		[learning rate: 0.00068781]
	Learning Rate: 0.000687807
	LOSS [training: 0.040354876224433414 | validation: 0.0365190944953978]
	TIME [epoch: 9.04 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04547027482408088		[learning rate: 0.0006857]
	Learning Rate: 0.000685699
	LOSS [training: 0.04547027482408088 | validation: 0.03405419496826805]
	TIME [epoch: 9.04 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0448449899424531		[learning rate: 0.0006836]
	Learning Rate: 0.000683597
	LOSS [training: 0.0448449899424531 | validation: 0.03606305883895419]
	TIME [epoch: 9.06 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04305864794719413		[learning rate: 0.0006815]
	Learning Rate: 0.000681501
	LOSS [training: 0.04305864794719413 | validation: 0.029141801433905747]
	TIME [epoch: 9.04 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043326428653055825		[learning rate: 0.00067941]
	Learning Rate: 0.000679412
	LOSS [training: 0.043326428653055825 | validation: 0.0319218571671856]
	TIME [epoch: 9.04 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044416770844341674		[learning rate: 0.00067733]
	Learning Rate: 0.000677329
	LOSS [training: 0.044416770844341674 | validation: 0.02812197026546117]
	TIME [epoch: 9.04 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033817920965796756		[learning rate: 0.00067525]
	Learning Rate: 0.000675253
	LOSS [training: 0.033817920965796756 | validation: 0.01652634659140511]
	TIME [epoch: 9.07 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031892540323619614		[learning rate: 0.00067318]
	Learning Rate: 0.000673183
	LOSS [training: 0.031892540323619614 | validation: 0.027428866508998416]
	TIME [epoch: 9.05 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036898409546151326		[learning rate: 0.00067112]
	Learning Rate: 0.00067112
	LOSS [training: 0.036898409546151326 | validation: 0.03278923172695524]
	TIME [epoch: 9.04 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029247176546520676		[learning rate: 0.00066906]
	Learning Rate: 0.000669062
	LOSS [training: 0.029247176546520676 | validation: 0.014436071369352706]
	TIME [epoch: 9.04 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03295277193587153		[learning rate: 0.00066701]
	Learning Rate: 0.000667011
	LOSS [training: 0.03295277193587153 | validation: 0.02377582713629528]
	TIME [epoch: 9.06 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032209861074593796		[learning rate: 0.00066497]
	Learning Rate: 0.000664967
	LOSS [training: 0.032209861074593796 | validation: 0.02316718234911499]
	TIME [epoch: 9.05 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04628420027101713		[learning rate: 0.00066293]
	Learning Rate: 0.000662929
	LOSS [training: 0.04628420027101713 | validation: 0.0347112638557983]
	TIME [epoch: 9.04 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041848808309448635		[learning rate: 0.0006609]
	Learning Rate: 0.000660896
	LOSS [training: 0.041848808309448635 | validation: 0.024699902159303243]
	TIME [epoch: 9.04 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026306338928789724		[learning rate: 0.00065887]
	Learning Rate: 0.00065887
	LOSS [training: 0.026306338928789724 | validation: 0.024079176583934447]
	TIME [epoch: 9.04 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04226619247244927		[learning rate: 0.00065685]
	Learning Rate: 0.000656851
	LOSS [training: 0.04226619247244927 | validation: 0.022943107888452018]
	TIME [epoch: 9.04 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030258568419169317		[learning rate: 0.00065484]
	Learning Rate: 0.000654837
	LOSS [training: 0.030258568419169317 | validation: 0.01891805654580584]
	TIME [epoch: 9.03 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02955548862659595		[learning rate: 0.00065283]
	Learning Rate: 0.00065283
	LOSS [training: 0.02955548862659595 | validation: 0.02019461473366209]
	TIME [epoch: 9.03 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03478663794958627		[learning rate: 0.00065083]
	Learning Rate: 0.000650829
	LOSS [training: 0.03478663794958627 | validation: 0.023746875117977434]
	TIME [epoch: 9.04 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03265365958417728		[learning rate: 0.00064883]
	Learning Rate: 0.000648834
	LOSS [training: 0.03265365958417728 | validation: 0.013374020212093714]
	TIME [epoch: 9.05 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030143559602963683		[learning rate: 0.00064684]
	Learning Rate: 0.000646845
	LOSS [training: 0.030143559602963683 | validation: 0.017459877626535992]
	TIME [epoch: 9.03 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041550723069310375		[learning rate: 0.00064486]
	Learning Rate: 0.000644862
	LOSS [training: 0.041550723069310375 | validation: 0.03201344974496899]
	TIME [epoch: 9.03 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04368632640656481		[learning rate: 0.00064289]
	Learning Rate: 0.000642885
	LOSS [training: 0.04368632640656481 | validation: 0.035041234500951327]
	TIME [epoch: 9.03 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03969818080276432		[learning rate: 0.00064091]
	Learning Rate: 0.000640914
	LOSS [training: 0.03969818080276432 | validation: 0.03242183678570466]
	TIME [epoch: 9.05 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05371971657338294		[learning rate: 0.00063895]
	Learning Rate: 0.00063895
	LOSS [training: 0.05371971657338294 | validation: 0.03254572674757143]
	TIME [epoch: 9.03 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04125769837131047		[learning rate: 0.00063699]
	Learning Rate: 0.000636991
	LOSS [training: 0.04125769837131047 | validation: 0.0337361014638157]
	TIME [epoch: 9.03 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046096723068590216		[learning rate: 0.00063504]
	Learning Rate: 0.000635038
	LOSS [training: 0.046096723068590216 | validation: 0.046714522123997196]
	TIME [epoch: 9.03 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054248791731187906		[learning rate: 0.00063309]
	Learning Rate: 0.000633092
	LOSS [training: 0.054248791731187906 | validation: 0.023766245781921356]
	TIME [epoch: 9.05 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03435394636294356		[learning rate: 0.00063115]
	Learning Rate: 0.000631151
	LOSS [training: 0.03435394636294356 | validation: 0.015810161120085535]
	TIME [epoch: 9.04 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029744982276874526		[learning rate: 0.00062922]
	Learning Rate: 0.000629216
	LOSS [training: 0.029744982276874526 | validation: 0.021882203272252647]
	TIME [epoch: 9.04 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03784512756546675		[learning rate: 0.00062729]
	Learning Rate: 0.000627287
	LOSS [training: 0.03784512756546675 | validation: 0.02392235714563193]
	TIME [epoch: 9.04 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03960545747773013		[learning rate: 0.00062536]
	Learning Rate: 0.000625365
	LOSS [training: 0.03960545747773013 | validation: 0.03208228882978702]
	TIME [epoch: 9.06 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036448675170426735		[learning rate: 0.00062345]
	Learning Rate: 0.000623448
	LOSS [training: 0.036448675170426735 | validation: 0.022515116696583744]
	TIME [epoch: 9.05 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03581596281594858		[learning rate: 0.00062154]
	Learning Rate: 0.000621537
	LOSS [training: 0.03581596281594858 | validation: 0.028385924261804286]
	TIME [epoch: 9.04 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034306188334774966		[learning rate: 0.00061963]
	Learning Rate: 0.000619631
	LOSS [training: 0.034306188334774966 | validation: 0.021002943726709078]
	TIME [epoch: 9.04 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029595539713294768		[learning rate: 0.00061773]
	Learning Rate: 0.000617732
	LOSS [training: 0.029595539713294768 | validation: 0.017846543113578656]
	TIME [epoch: 9.06 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030134162897826906		[learning rate: 0.00061584]
	Learning Rate: 0.000615838
	LOSS [training: 0.030134162897826906 | validation: 0.02935513418300826]
	TIME [epoch: 9.04 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027858187979759703		[learning rate: 0.00061395]
	Learning Rate: 0.00061395
	LOSS [training: 0.027858187979759703 | validation: 0.02631500388882761]
	TIME [epoch: 9.04 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027741588750068474		[learning rate: 0.00061207]
	Learning Rate: 0.000612068
	LOSS [training: 0.027741588750068474 | validation: 0.006309945652770064]
	TIME [epoch: 9.04 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024475717724817304		[learning rate: 0.00061019]
	Learning Rate: 0.000610192
	LOSS [training: 0.024475717724817304 | validation: 0.022836465532219116]
	TIME [epoch: 9.05 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030488314746105465		[learning rate: 0.00060832]
	Learning Rate: 0.000608322
	LOSS [training: 0.030488314746105465 | validation: 0.022148582850603192]
	TIME [epoch: 9.05 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027308454426163524		[learning rate: 0.00060646]
	Learning Rate: 0.000606457
	LOSS [training: 0.027308454426163524 | validation: 0.026943084932110263]
	TIME [epoch: 9.04 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032223029785120885		[learning rate: 0.0006046]
	Learning Rate: 0.000604598
	LOSS [training: 0.032223029785120885 | validation: 0.019411487381331905]
	TIME [epoch: 9.04 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029486106398140772		[learning rate: 0.00060274]
	Learning Rate: 0.000602745
	LOSS [training: 0.029486106398140772 | validation: 0.02904741089172213]
	TIME [epoch: 9.03 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02991238591941791		[learning rate: 0.0006009]
	Learning Rate: 0.000600897
	LOSS [training: 0.02991238591941791 | validation: 0.037356477704889465]
	TIME [epoch: 9.05 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03861201881060578		[learning rate: 0.00059905]
	Learning Rate: 0.000599055
	LOSS [training: 0.03861201881060578 | validation: 0.023212580505157086]
	TIME [epoch: 9.03 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038110365908592556		[learning rate: 0.00059722]
	Learning Rate: 0.000597219
	LOSS [training: 0.038110365908592556 | validation: 0.028739723266645926]
	TIME [epoch: 9.03 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03650708826332334		[learning rate: 0.00059539]
	Learning Rate: 0.000595388
	LOSS [training: 0.03650708826332334 | validation: 0.03139068155106984]
	TIME [epoch: 9.03 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04141573374513284		[learning rate: 0.00059356]
	Learning Rate: 0.000593563
	LOSS [training: 0.04141573374513284 | validation: 0.018333897263036775]
	TIME [epoch: 9.06 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03147290086714596		[learning rate: 0.00059174]
	Learning Rate: 0.000591743
	LOSS [training: 0.03147290086714596 | validation: 0.02670853675974452]
	TIME [epoch: 9.03 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027826402178234677		[learning rate: 0.00058993]
	Learning Rate: 0.000589929
	LOSS [training: 0.027826402178234677 | validation: 0.018513595577018354]
	TIME [epoch: 9.03 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02773577309639063		[learning rate: 0.00058812]
	Learning Rate: 0.000588121
	LOSS [training: 0.02773577309639063 | validation: 0.011026902503745436]
	TIME [epoch: 9.03 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025705889766366934		[learning rate: 0.00058632]
	Learning Rate: 0.000586318
	LOSS [training: 0.025705889766366934 | validation: 0.014669726079870962]
	TIME [epoch: 9.05 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03198230661412385		[learning rate: 0.00058452]
	Learning Rate: 0.000584521
	LOSS [training: 0.03198230661412385 | validation: 0.022355760086113632]
	TIME [epoch: 9.04 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02681616244253836		[learning rate: 0.00058273]
	Learning Rate: 0.000582729
	LOSS [training: 0.02681616244253836 | validation: 0.01820773250362969]
	TIME [epoch: 9.04 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026173444979732986		[learning rate: 0.00058094]
	Learning Rate: 0.000580943
	LOSS [training: 0.026173444979732986 | validation: 0.01279192387288714]
	TIME [epoch: 9.04 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027785608427450363		[learning rate: 0.00057916]
	Learning Rate: 0.000579162
	LOSS [training: 0.027785608427450363 | validation: 0.017742474201251017]
	TIME [epoch: 9.05 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032304507257041704		[learning rate: 0.00057739]
	Learning Rate: 0.000577386
	LOSS [training: 0.032304507257041704 | validation: 0.022769243632139405]
	TIME [epoch: 9.04 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02584252572133399		[learning rate: 0.00057562]
	Learning Rate: 0.000575616
	LOSS [training: 0.02584252572133399 | validation: 0.02632398857877992]
	TIME [epoch: 9.04 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032977939924147534		[learning rate: 0.00057385]
	Learning Rate: 0.000573852
	LOSS [training: 0.032977939924147534 | validation: 0.023476580389780885]
	TIME [epoch: 9.03 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027201071992596915		[learning rate: 0.00057209]
	Learning Rate: 0.000572093
	LOSS [training: 0.027201071992596915 | validation: 0.017414188662388246]
	TIME [epoch: 9.04 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029939133801248047		[learning rate: 0.00057034]
	Learning Rate: 0.000570339
	LOSS [training: 0.029939133801248047 | validation: 0.011389434285035202]
	TIME [epoch: 9.05 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028502966612339337		[learning rate: 0.00056859]
	Learning Rate: 0.000568591
	LOSS [training: 0.028502966612339337 | validation: 0.01840295866290507]
	TIME [epoch: 9.04 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025274034960352736		[learning rate: 0.00056685]
	Learning Rate: 0.000566848
	LOSS [training: 0.025274034960352736 | validation: 0.0181614346068857]
	TIME [epoch: 9.04 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028597499088306704		[learning rate: 0.00056511]
	Learning Rate: 0.00056511
	LOSS [training: 0.028597499088306704 | validation: 0.00885712439771295]
	TIME [epoch: 9.05 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030236411713069		[learning rate: 0.00056338]
	Learning Rate: 0.000563378
	LOSS [training: 0.030236411713069 | validation: 0.022937529837418112]
	TIME [epoch: 9.05 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040176529104937755		[learning rate: 0.00056165]
	Learning Rate: 0.000561651
	LOSS [training: 0.040176529104937755 | validation: 0.02973219763240637]
	TIME [epoch: 9.04 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035403338313978225		[learning rate: 0.00055993]
	Learning Rate: 0.000559929
	LOSS [training: 0.035403338313978225 | validation: 0.013065247970532374]
	TIME [epoch: 9.04 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028410632974127065		[learning rate: 0.00055821]
	Learning Rate: 0.000558213
	LOSS [training: 0.028410632974127065 | validation: 0.012976380982784239]
	TIME [epoch: 9.04 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02360937084909307		[learning rate: 0.0005565]
	Learning Rate: 0.000556502
	LOSS [training: 0.02360937084909307 | validation: 0.020919374714792757]
	TIME [epoch: 9.06 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028743820810833882		[learning rate: 0.0005548]
	Learning Rate: 0.000554796
	LOSS [training: 0.028743820810833882 | validation: 0.01312744034805682]
	TIME [epoch: 9.04 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028636796502671313		[learning rate: 0.0005531]
	Learning Rate: 0.000553095
	LOSS [training: 0.028636796502671313 | validation: 0.01662241082930333]
	TIME [epoch: 9.04 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03153244734101127		[learning rate: 0.0005514]
	Learning Rate: 0.0005514
	LOSS [training: 0.03153244734101127 | validation: 0.02196446366424977]
	TIME [epoch: 9.04 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03026790104341437		[learning rate: 0.00054971]
	Learning Rate: 0.000549709
	LOSS [training: 0.03026790104341437 | validation: 0.01832597046930378]
	TIME [epoch: 9.06 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043636141050266655		[learning rate: 0.00054802]
	Learning Rate: 0.000548024
	LOSS [training: 0.043636141050266655 | validation: 0.038229391945238854]
	TIME [epoch: 9.04 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0357552003735664		[learning rate: 0.00054634]
	Learning Rate: 0.000546345
	LOSS [training: 0.0357552003735664 | validation: 0.01991521995159547]
	TIME [epoch: 9.04 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03370793953992712		[learning rate: 0.00054467]
	Learning Rate: 0.00054467
	LOSS [training: 0.03370793953992712 | validation: 0.038265574546439]
	TIME [epoch: 9.04 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03658345576662415		[learning rate: 0.000543]
	Learning Rate: 0.000543
	LOSS [training: 0.03658345576662415 | validation: 0.028977095492941016]
	TIME [epoch: 9.06 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035162913922522555		[learning rate: 0.00054134]
	Learning Rate: 0.000541336
	LOSS [training: 0.035162913922522555 | validation: 0.023683668302422002]
	TIME [epoch: 9.04 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04361696907653474		[learning rate: 0.00053968]
	Learning Rate: 0.000539676
	LOSS [training: 0.04361696907653474 | validation: 0.029342683229195258]
	TIME [epoch: 9.15 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03865793328994158		[learning rate: 0.00053802]
	Learning Rate: 0.000538022
	LOSS [training: 0.03865793328994158 | validation: 0.01564005046431947]
	TIME [epoch: 9.04 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03206844552060658		[learning rate: 0.00053637]
	Learning Rate: 0.000536373
	LOSS [training: 0.03206844552060658 | validation: 0.0220222504233846]
	TIME [epoch: 9.06 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030289648349950977		[learning rate: 0.00053473]
	Learning Rate: 0.000534728
	LOSS [training: 0.030289648349950977 | validation: 0.02379073336414893]
	TIME [epoch: 9.04 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03121176607854597		[learning rate: 0.00053309]
	Learning Rate: 0.000533089
	LOSS [training: 0.03121176607854597 | validation: 0.01589599697421027]
	TIME [epoch: 9.04 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025805156201472453		[learning rate: 0.00053146]
	Learning Rate: 0.000531455
	LOSS [training: 0.025805156201472453 | validation: 0.025098190218264253]
	TIME [epoch: 9.04 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032527977653846615		[learning rate: 0.00052983]
	Learning Rate: 0.000529826
	LOSS [training: 0.032527977653846615 | validation: 0.024503770719876007]
	TIME [epoch: 9.05 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03138178711653135		[learning rate: 0.0005282]
	Learning Rate: 0.000528202
	LOSS [training: 0.03138178711653135 | validation: 0.022718878208358585]
	TIME [epoch: 9.05 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026007722091340908		[learning rate: 0.00052658]
	Learning Rate: 0.000526583
	LOSS [training: 0.026007722091340908 | validation: 0.013864794805786378]
	TIME [epoch: 9.04 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0323800930881217		[learning rate: 0.00052497]
	Learning Rate: 0.000524969
	LOSS [training: 0.0323800930881217 | validation: 0.014812860999749492]
	TIME [epoch: 9.04 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027187525754181756		[learning rate: 0.00052336]
	Learning Rate: 0.000523359
	LOSS [training: 0.027187525754181756 | validation: 0.011263033132715424]
	TIME [epoch: 9.05 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025971463264514237		[learning rate: 0.00052176]
	Learning Rate: 0.000521755
	LOSS [training: 0.025971463264514237 | validation: 0.01005925010344159]
	TIME [epoch: 9.05 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025370792714341027		[learning rate: 0.00052016]
	Learning Rate: 0.000520156
	LOSS [training: 0.025370792714341027 | validation: 0.02016938550954582]
	TIME [epoch: 9.04 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03425676661359468		[learning rate: 0.00051856]
	Learning Rate: 0.000518561
	LOSS [training: 0.03425676661359468 | validation: 0.016602964560097192]
	TIME [epoch: 9.04 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028318282628357727		[learning rate: 0.00051697]
	Learning Rate: 0.000516972
	LOSS [training: 0.028318282628357727 | validation: 0.018533909892682842]
	TIME [epoch: 9.04 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03180983334420578		[learning rate: 0.00051539]
	Learning Rate: 0.000515387
	LOSS [training: 0.03180983334420578 | validation: 0.029703862319848562]
	TIME [epoch: 9.06 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029871855565156046		[learning rate: 0.00051381]
	Learning Rate: 0.000513807
	LOSS [training: 0.029871855565156046 | validation: 0.026405162967433157]
	TIME [epoch: 9.04 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0325021747003851		[learning rate: 0.00051223]
	Learning Rate: 0.000512232
	LOSS [training: 0.0325021747003851 | validation: 0.019711693766876398]
	TIME [epoch: 9.04 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03244366381137762		[learning rate: 0.00051066]
	Learning Rate: 0.000510662
	LOSS [training: 0.03244366381137762 | validation: 0.027629085250586032]
	TIME [epoch: 9.04 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03418996043523953		[learning rate: 0.0005091]
	Learning Rate: 0.000509096
	LOSS [training: 0.03418996043523953 | validation: 0.024572768456400336]
	TIME [epoch: 9.06 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035695090759275495		[learning rate: 0.00050754]
	Learning Rate: 0.000507536
	LOSS [training: 0.035695090759275495 | validation: 0.011453910914545295]
	TIME [epoch: 9.05 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02639407787187132		[learning rate: 0.00050598]
	Learning Rate: 0.00050598
	LOSS [training: 0.02639407787187132 | validation: 0.017944538741938094]
	TIME [epoch: 9.04 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025211116767031517		[learning rate: 0.00050443]
	Learning Rate: 0.000504429
	LOSS [training: 0.025211116767031517 | validation: 0.016346841046100246]
	TIME [epoch: 9.04 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026309837483273934		[learning rate: 0.00050288]
	Learning Rate: 0.000502883
	LOSS [training: 0.026309837483273934 | validation: 0.018036208133385592]
	TIME [epoch: 9.06 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027796975837349996		[learning rate: 0.00050134]
	Learning Rate: 0.000501341
	LOSS [training: 0.027796975837349996 | validation: 0.019679395575678174]
	TIME [epoch: 9.04 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023742237248847078		[learning rate: 0.0004998]
	Learning Rate: 0.000499804
	LOSS [training: 0.023742237248847078 | validation: 0.014976721986477922]
	TIME [epoch: 9.04 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02608660759379512		[learning rate: 0.00049827]
	Learning Rate: 0.000498272
	LOSS [training: 0.02608660759379512 | validation: 0.008388929929752108]
	TIME [epoch: 9.04 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028487213922745898		[learning rate: 0.00049674]
	Learning Rate: 0.000496745
	LOSS [training: 0.028487213922745898 | validation: 0.018951638332995752]
	TIME [epoch: 9.05 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030118474189079703		[learning rate: 0.00049522]
	Learning Rate: 0.000495222
	LOSS [training: 0.030118474189079703 | validation: 0.005696204349464154]
	TIME [epoch: 9.05 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022494915011920767		[learning rate: 0.0004937]
	Learning Rate: 0.000493704
	LOSS [training: 0.022494915011920767 | validation: 0.020501889185879967]
	TIME [epoch: 9.04 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026762699986084725		[learning rate: 0.00049219]
	Learning Rate: 0.000492191
	LOSS [training: 0.026762699986084725 | validation: 0.0202539701617222]
	TIME [epoch: 9.04 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030692505605068015		[learning rate: 0.00049068]
	Learning Rate: 0.000490682
	LOSS [training: 0.030692505605068015 | validation: 0.020670011473146552]
	TIME [epoch: 9.05 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03214616135158431		[learning rate: 0.00048918]
	Learning Rate: 0.000489178
	LOSS [training: 0.03214616135158431 | validation: 0.017534733054310483]
	TIME [epoch: 9.05 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025332943964018584		[learning rate: 0.00048768]
	Learning Rate: 0.000487678
	LOSS [training: 0.025332943964018584 | validation: 0.010254454433947457]
	TIME [epoch: 9.04 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020138044242682864		[learning rate: 0.00048618]
	Learning Rate: 0.000486183
	LOSS [training: 0.020138044242682864 | validation: 0.007436161577722272]
	TIME [epoch: 9.04 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020177311627044753		[learning rate: 0.00048469]
	Learning Rate: 0.000484693
	LOSS [training: 0.020177311627044753 | validation: 0.01484528481174639]
	TIME [epoch: 9.04 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024729816966101777		[learning rate: 0.00048321]
	Learning Rate: 0.000483207
	LOSS [training: 0.024729816966101777 | validation: 0.021568551315190775]
	TIME [epoch: 9.06 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04583949235824063		[learning rate: 0.00048173]
	Learning Rate: 0.000481726
	LOSS [training: 0.04583949235824063 | validation: 0.04751707560275636]
	TIME [epoch: 9.04 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08013503966553118		[learning rate: 0.00048025]
	Learning Rate: 0.000480249
	LOSS [training: 0.08013503966553118 | validation: 0.06127493027026276]
	TIME [epoch: 9.04 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07148984403714567		[learning rate: 0.00047878]
	Learning Rate: 0.000478777
	LOSS [training: 0.07148984403714567 | validation: 0.055396192487845705]
	TIME [epoch: 9.04 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059254709318909846		[learning rate: 0.00047731]
	Learning Rate: 0.000477309
	LOSS [training: 0.059254709318909846 | validation: 0.046479045461621786]
	TIME [epoch: 9.06 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03629508707301108		[learning rate: 0.00047585]
	Learning Rate: 0.000475846
	LOSS [training: 0.03629508707301108 | validation: 0.017269468553358047]
	TIME [epoch: 9.04 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02749546913624869		[learning rate: 0.00047439]
	Learning Rate: 0.000474388
	LOSS [training: 0.02749546913624869 | validation: 0.02359555519609515]
	TIME [epoch: 9.04 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0277451021805108		[learning rate: 0.00047293]
	Learning Rate: 0.000472933
	LOSS [training: 0.0277451021805108 | validation: 0.039251215369892026]
	TIME [epoch: 9.04 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04507966213406371		[learning rate: 0.00047148]
	Learning Rate: 0.000471484
	LOSS [training: 0.04507966213406371 | validation: 0.02989845080347075]
	TIME [epoch: 9.06 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03635342909639918		[learning rate: 0.00047004]
	Learning Rate: 0.000470038
	LOSS [training: 0.03635342909639918 | validation: 0.022846465181511615]
	TIME [epoch: 9.04 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033174951612201395		[learning rate: 0.0004686]
	Learning Rate: 0.000468597
	LOSS [training: 0.033174951612201395 | validation: 0.03418791372369333]
	TIME [epoch: 9.04 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03651921898692949		[learning rate: 0.00046716]
	Learning Rate: 0.000467161
	LOSS [training: 0.03651921898692949 | validation: 0.025250867144687265]
	TIME [epoch: 9.04 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035980762366850334		[learning rate: 0.00046573]
	Learning Rate: 0.000465729
	LOSS [training: 0.035980762366850334 | validation: 0.03703028587573155]
	TIME [epoch: 9.06 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041548620628691815		[learning rate: 0.0004643]
	Learning Rate: 0.000464301
	LOSS [training: 0.041548620628691815 | validation: 0.029269496796007786]
	TIME [epoch: 9.04 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03208977605834676		[learning rate: 0.00046288]
	Learning Rate: 0.000462878
	LOSS [training: 0.03208977605834676 | validation: 0.011032181731298558]
	TIME [epoch: 9.04 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028141198384003023		[learning rate: 0.00046146]
	Learning Rate: 0.000461459
	LOSS [training: 0.028141198384003023 | validation: 0.005867149902940255]
	TIME [epoch: 9.03 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025903275115902853		[learning rate: 0.00046004]
	Learning Rate: 0.000460045
	LOSS [training: 0.025903275115902853 | validation: 0.01910061236432599]
	TIME [epoch: 9.05 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022589426354033475		[learning rate: 0.00045863]
	Learning Rate: 0.000458634
	LOSS [training: 0.022589426354033475 | validation: 0.014189825708906152]
	TIME [epoch: 9.05 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021997777379583895		[learning rate: 0.00045723]
	Learning Rate: 0.000457229
	LOSS [training: 0.021997777379583895 | validation: 0.01003758885568909]
	TIME [epoch: 9.04 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023368473837864577		[learning rate: 0.00045583]
	Learning Rate: 0.000455827
	LOSS [training: 0.023368473837864577 | validation: 0.00855693180264949]
	TIME [epoch: 9.04 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027231910707563412		[learning rate: 0.00045443]
	Learning Rate: 0.00045443
	LOSS [training: 0.027231910707563412 | validation: 0.015136910467665758]
	TIME [epoch: 9.05 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03166286743094918		[learning rate: 0.00045304]
	Learning Rate: 0.000453037
	LOSS [training: 0.03166286743094918 | validation: 0.013929963983695986]
	TIME [epoch: 9.05 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0278045824430522		[learning rate: 0.00045165]
	Learning Rate: 0.000451648
	LOSS [training: 0.0278045824430522 | validation: 0.012337018811201963]
	TIME [epoch: 9.04 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023697325511986896		[learning rate: 0.00045026]
	Learning Rate: 0.000450263
	LOSS [training: 0.023697325511986896 | validation: 0.008192924367235357]
	TIME [epoch: 9.04 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025997350982412078		[learning rate: 0.00044888]
	Learning Rate: 0.000448883
	LOSS [training: 0.025997350982412078 | validation: 0.01957903994076081]
	TIME [epoch: 9.04 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026823333997728443		[learning rate: 0.00044751]
	Learning Rate: 0.000447507
	LOSS [training: 0.026823333997728443 | validation: 0.026218068705009416]
	TIME [epoch: 9.06 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030227249872578306		[learning rate: 0.00044614]
	Learning Rate: 0.000446135
	LOSS [training: 0.030227249872578306 | validation: 0.012062898468747628]
	TIME [epoch: 9.04 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027126665165115926		[learning rate: 0.00044477]
	Learning Rate: 0.000444768
	LOSS [training: 0.027126665165115926 | validation: 0.010629609488767802]
	TIME [epoch: 9.06 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03100677802702856		[learning rate: 0.0004434]
	Learning Rate: 0.000443404
	LOSS [training: 0.03100677802702856 | validation: 0.019074128337876965]
	TIME [epoch: 9.05 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042725931491255545		[learning rate: 0.00044205]
	Learning Rate: 0.000442045
	LOSS [training: 0.042725931491255545 | validation: 0.036952230513977384]
	TIME [epoch: 9.07 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07088299649269332		[learning rate: 0.00044069]
	Learning Rate: 0.00044069
	LOSS [training: 0.07088299649269332 | validation: 0.04950147018968032]
	TIME [epoch: 9.05 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05511485191212674		[learning rate: 0.00043934]
	Learning Rate: 0.000439339
	LOSS [training: 0.05511485191212674 | validation: 0.03039870106757929]
	TIME [epoch: 9.05 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045204613031173416		[learning rate: 0.00043799]
	Learning Rate: 0.000437992
	LOSS [training: 0.045204613031173416 | validation: 0.036207892013010105]
	TIME [epoch: 9.05 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039186870044367106		[learning rate: 0.00043665]
	Learning Rate: 0.00043665
	LOSS [training: 0.039186870044367106 | validation: 0.01979292378386124]
	TIME [epoch: 9.07 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03689129368814388		[learning rate: 0.00043531]
	Learning Rate: 0.000435311
	LOSS [training: 0.03689129368814388 | validation: 0.034208752730875897]
	TIME [epoch: 9.04 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0331288911315545		[learning rate: 0.00043398]
	Learning Rate: 0.000433977
	LOSS [training: 0.0331288911315545 | validation: 0.020563724144057185]
	TIME [epoch: 9.04 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03613404372452115		[learning rate: 0.00043265]
	Learning Rate: 0.000432647
	LOSS [training: 0.03613404372452115 | validation: 0.02266171369623885]
	TIME [epoch: 9.04 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03397514670652971		[learning rate: 0.00043132]
	Learning Rate: 0.00043132
	LOSS [training: 0.03397514670652971 | validation: 0.029630653281536995]
	TIME [epoch: 9.06 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02969982140454681		[learning rate: 0.00043]
	Learning Rate: 0.000429998
	LOSS [training: 0.02969982140454681 | validation: 0.017492452745771714]
	TIME [epoch: 9.04 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028291882631126843		[learning rate: 0.00042868]
	Learning Rate: 0.00042868
	LOSS [training: 0.028291882631126843 | validation: 0.012209723132115536]
	TIME [epoch: 9.04 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026961871286047594		[learning rate: 0.00042737]
	Learning Rate: 0.000427366
	LOSS [training: 0.026961871286047594 | validation: 0.021614908013583567]
	TIME [epoch: 9.04 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028963140680568638		[learning rate: 0.00042606]
	Learning Rate: 0.000426056
	LOSS [training: 0.028963140680568638 | validation: 0.019487709641901378]
	TIME [epoch: 9.05 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04014708268215732		[learning rate: 0.00042475]
	Learning Rate: 0.00042475
	LOSS [training: 0.04014708268215732 | validation: 0.031063426255838647]
	TIME [epoch: 9.05 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03366448047236566		[learning rate: 0.00042345]
	Learning Rate: 0.000423448
	LOSS [training: 0.03366448047236566 | validation: 0.019189762301653916]
	TIME [epoch: 9.04 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02235508048877103		[learning rate: 0.00042215]
	Learning Rate: 0.00042215
	LOSS [training: 0.02235508048877103 | validation: 0.016793391916341185]
	TIME [epoch: 9.04 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021872767891129147		[learning rate: 0.00042086]
	Learning Rate: 0.000420856
	LOSS [training: 0.021872767891129147 | validation: 0.01774737982138777]
	TIME [epoch: 9.05 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031146472881512226		[learning rate: 0.00041957]
	Learning Rate: 0.000419566
	LOSS [training: 0.031146472881512226 | validation: 0.026419401284381944]
	TIME [epoch: 9.06 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030710743436353993		[learning rate: 0.00041828]
	Learning Rate: 0.00041828
	LOSS [training: 0.030710743436353993 | validation: 0.008350809922463632]
	TIME [epoch: 9.04 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019320154716446734		[learning rate: 0.000417]
	Learning Rate: 0.000416997
	LOSS [training: 0.019320154716446734 | validation: 0.011780738683414907]
	TIME [epoch: 9.04 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019790207303674694		[learning rate: 0.00041572]
	Learning Rate: 0.000415719
	LOSS [training: 0.019790207303674694 | validation: 0.01526270411139478]
	TIME [epoch: 9.04 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01974928432184761		[learning rate: 0.00041444]
	Learning Rate: 0.000414445
	LOSS [training: 0.01974928432184761 | validation: 0.022668568472174994]
	TIME [epoch: 9.06 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023536867376131414		[learning rate: 0.00041317]
	Learning Rate: 0.000413174
	LOSS [training: 0.023536867376131414 | validation: 0.01735556750397626]
	TIME [epoch: 9.04 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027991675579326213		[learning rate: 0.00041191]
	Learning Rate: 0.000411908
	LOSS [training: 0.027991675579326213 | validation: 0.02117207368531726]
	TIME [epoch: 9.04 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024789677435186157		[learning rate: 0.00041065]
	Learning Rate: 0.000410645
	LOSS [training: 0.024789677435186157 | validation: 0.008012542605331309]
	TIME [epoch: 9.03 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023265793155980367		[learning rate: 0.00040939]
	Learning Rate: 0.000409386
	LOSS [training: 0.023265793155980367 | validation: 0.02239383178913421]
	TIME [epoch: 9.06 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022160631383189192		[learning rate: 0.00040813]
	Learning Rate: 0.000408131
	LOSS [training: 0.022160631383189192 | validation: 0.011136712413008069]
	TIME [epoch: 9.04 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021714252754592284		[learning rate: 0.00040688]
	Learning Rate: 0.00040688
	LOSS [training: 0.021714252754592284 | validation: 0.01620665654802956]
	TIME [epoch: 9.03 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024572447313166806		[learning rate: 0.00040563]
	Learning Rate: 0.000405633
	LOSS [training: 0.024572447313166806 | validation: 0.012130213640895754]
	TIME [epoch: 9.04 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024707051875723723		[learning rate: 0.00040439]
	Learning Rate: 0.00040439
	LOSS [training: 0.024707051875723723 | validation: 0.013972846283898105]
	TIME [epoch: 9.06 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01886181894860977		[learning rate: 0.00040315]
	Learning Rate: 0.00040315
	LOSS [training: 0.01886181894860977 | validation: 0.015367337792127999]
	TIME [epoch: 9.04 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028436939187819345		[learning rate: 0.00040191]
	Learning Rate: 0.000401914
	LOSS [training: 0.028436939187819345 | validation: 0.018384839770763578]
	TIME [epoch: 9.04 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023720142453829994		[learning rate: 0.00040068]
	Learning Rate: 0.000400682
	LOSS [training: 0.023720142453829994 | validation: 0.021924341961995587]
	TIME [epoch: 9.04 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038335711804554376		[learning rate: 0.00039945]
	Learning Rate: 0.000399454
	LOSS [training: 0.038335711804554376 | validation: 0.025686097062223655]
	TIME [epoch: 9.05 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03330072027069426		[learning rate: 0.00039823]
	Learning Rate: 0.000398229
	LOSS [training: 0.03330072027069426 | validation: 0.02310809755144573]
	TIME [epoch: 9.05 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0292048119221535		[learning rate: 0.00039701]
	Learning Rate: 0.000397009
	LOSS [training: 0.0292048119221535 | validation: 0.023137191586305363]
	TIME [epoch: 9.03 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02603992160542413		[learning rate: 0.00039579]
	Learning Rate: 0.000395792
	LOSS [training: 0.02603992160542413 | validation: 0.027071488229767467]
	TIME [epoch: 9.03 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03588527108632059		[learning rate: 0.00039458]
	Learning Rate: 0.000394578
	LOSS [training: 0.03588527108632059 | validation: 0.01585932445501951]
	TIME [epoch: 9.04 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03280324289876085		[learning rate: 0.00039337]
	Learning Rate: 0.000393369
	LOSS [training: 0.03280324289876085 | validation: 0.02885093607019419]
	TIME [epoch: 9.05 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025674311419967965		[learning rate: 0.00039216]
	Learning Rate: 0.000392163
	LOSS [training: 0.025674311419967965 | validation: 0.016515351630488537]
	TIME [epoch: 9.04 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025812382669637268		[learning rate: 0.00039096]
	Learning Rate: 0.000390961
	LOSS [training: 0.025812382669637268 | validation: 0.023379008088903516]
	TIME [epoch: 9.04 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0359572991963545		[learning rate: 0.00038976]
	Learning Rate: 0.000389762
	LOSS [training: 0.0359572991963545 | validation: 0.027552358425370953]
	TIME [epoch: 9.04 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033464272383300395		[learning rate: 0.00038857]
	Learning Rate: 0.000388568
	LOSS [training: 0.033464272383300395 | validation: 0.01912265944683003]
	TIME [epoch: 9.06 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025503078094677317		[learning rate: 0.00038738]
	Learning Rate: 0.000387377
	LOSS [training: 0.025503078094677317 | validation: 0.01385093407391201]
	TIME [epoch: 9.04 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024921623260622267		[learning rate: 0.00038619]
	Learning Rate: 0.000386189
	LOSS [training: 0.024921623260622267 | validation: 0.014870832110143978]
	TIME [epoch: 9.04 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023040297430774303		[learning rate: 0.00038501]
	Learning Rate: 0.000385005
	LOSS [training: 0.023040297430774303 | validation: 0.01610909703176293]
	TIME [epoch: 9.03 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029962811089061077		[learning rate: 0.00038382]
	Learning Rate: 0.000383825
	LOSS [training: 0.029962811089061077 | validation: 0.02983545062817047]
	TIME [epoch: 9.06 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042041001402911754		[learning rate: 0.00038265]
	Learning Rate: 0.000382649
	LOSS [training: 0.042041001402911754 | validation: 0.02299223810912656]
	TIME [epoch: 9.04 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03317029451988809		[learning rate: 0.00038148]
	Learning Rate: 0.000381476
	LOSS [training: 0.03317029451988809 | validation: 0.021169501448258334]
	TIME [epoch: 9.04 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03348922616374804		[learning rate: 0.00038031]
	Learning Rate: 0.000380306
	LOSS [training: 0.03348922616374804 | validation: 0.035718535232948885]
	TIME [epoch: 9.04 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03117692920526639		[learning rate: 0.00037914]
	Learning Rate: 0.00037914
	LOSS [training: 0.03117692920526639 | validation: 0.018762930162815307]
	TIME [epoch: 9.05 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028309465689716512		[learning rate: 0.00037798]
	Learning Rate: 0.000377978
	LOSS [training: 0.028309465689716512 | validation: 0.02342876107365747]
	TIME [epoch: 9.04 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024486943623375494		[learning rate: 0.00037682]
	Learning Rate: 0.000376819
	LOSS [training: 0.024486943623375494 | validation: 0.009521692720660993]
	TIME [epoch: 9.04 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025896821353380846		[learning rate: 0.00037566]
	Learning Rate: 0.000375664
	LOSS [training: 0.025896821353380846 | validation: 0.017398081228664854]
	TIME [epoch: 9.04 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016748551538845042		[learning rate: 0.00037451]
	Learning Rate: 0.000374513
	LOSS [training: 0.016748551538845042 | validation: 0.01898995088360464]
	TIME [epoch: 9.06 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024547453010601433		[learning rate: 0.00037336]
	Learning Rate: 0.000373365
	LOSS [training: 0.024547453010601433 | validation: 0.016543562600163854]
	TIME [epoch: 9.04 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023287220768256105		[learning rate: 0.00037222]
	Learning Rate: 0.00037222
	LOSS [training: 0.023287220768256105 | validation: 0.02206014290266929]
	TIME [epoch: 9.04 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02270829605739594		[learning rate: 0.00037108]
	Learning Rate: 0.000371079
	LOSS [training: 0.02270829605739594 | validation: 0.021855403244439485]
	TIME [epoch: 9.04 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026549159280450697		[learning rate: 0.00036994]
	Learning Rate: 0.000369942
	LOSS [training: 0.026549159280450697 | validation: 0.01747089264992846]
	TIME [epoch: 9.05 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017916349504412597		[learning rate: 0.00036881]
	Learning Rate: 0.000368808
	LOSS [training: 0.017916349504412597 | validation: 0.01952899164746924]
	TIME [epoch: 9.05 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02335491060223104		[learning rate: 0.00036768]
	Learning Rate: 0.000367677
	LOSS [training: 0.02335491060223104 | validation: 0.017187544594200913]
	TIME [epoch: 9.03 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02847131116195223		[learning rate: 0.00036655]
	Learning Rate: 0.00036655
	LOSS [training: 0.02847131116195223 | validation: 0.006546872296696395]
	TIME [epoch: 9.05 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02353910271740665		[learning rate: 0.00036543]
	Learning Rate: 0.000365426
	LOSS [training: 0.02353910271740665 | validation: 0.01497070383099822]
	TIME [epoch: 9.04 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02450281839001513		[learning rate: 0.00036431]
	Learning Rate: 0.000364306
	LOSS [training: 0.02450281839001513 | validation: 0.012954212302301678]
	TIME [epoch: 9.05 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018138795929373955		[learning rate: 0.00036319]
	Learning Rate: 0.00036319
	LOSS [training: 0.018138795929373955 | validation: 0.010704855449722689]
	TIME [epoch: 9.03 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019634928095186306		[learning rate: 0.00036208]
	Learning Rate: 0.000362076
	LOSS [training: 0.019634928095186306 | validation: 0.01859888369218886]
	TIME [epoch: 9.03 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01887374305804765		[learning rate: 0.00036097]
	Learning Rate: 0.000360966
	LOSS [training: 0.01887374305804765 | validation: 0.012026028708218967]
	TIME [epoch: 9.04 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016630419459164467		[learning rate: 0.00035986]
	Learning Rate: 0.00035986
	LOSS [training: 0.016630419459164467 | validation: 0.010829299003682107]
	TIME [epoch: 9.06 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01558921279686605		[learning rate: 0.00035876]
	Learning Rate: 0.000358757
	LOSS [training: 0.01558921279686605 | validation: 0.005431807763874641]
	TIME [epoch: 9.04 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02011403692192486		[learning rate: 0.00035766]
	Learning Rate: 0.000357657
	LOSS [training: 0.02011403692192486 | validation: 0.004586593808306839]
	TIME [epoch: 9.04 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01495222119161187		[learning rate: 0.00035656]
	Learning Rate: 0.000356561
	LOSS [training: 0.01495222119161187 | validation: 0.015146071204602905]
	TIME [epoch: 9.03 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01838699459066716		[learning rate: 0.00035547]
	Learning Rate: 0.000355468
	LOSS [training: 0.01838699459066716 | validation: 0.016433285418550506]
	TIME [epoch: 9.06 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02257461883664795		[learning rate: 0.00035438]
	Learning Rate: 0.000354378
	LOSS [training: 0.02257461883664795 | validation: 0.017928709383935666]
	TIME [epoch: 9.04 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023674965187743396		[learning rate: 0.00035329]
	Learning Rate: 0.000353292
	LOSS [training: 0.023674965187743396 | validation: 0.017848316963873123]
	TIME [epoch: 9.03 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024992706167006676		[learning rate: 0.00035221]
	Learning Rate: 0.000352209
	LOSS [training: 0.024992706167006676 | validation: 0.00854080641945506]
	TIME [epoch: 9.03 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018331999554997473		[learning rate: 0.00035113]
	Learning Rate: 0.000351129
	LOSS [training: 0.018331999554997473 | validation: 0.012264375640899433]
	TIME [epoch: 9.05 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0195932233516104		[learning rate: 0.00035005]
	Learning Rate: 0.000350053
	LOSS [training: 0.0195932233516104 | validation: 0.011434872845976454]
	TIME [epoch: 9.04 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027153026096001044		[learning rate: 0.00034898]
	Learning Rate: 0.000348979
	LOSS [training: 0.027153026096001044 | validation: 0.0099139222305114]
	TIME [epoch: 9.03 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02640002690110723		[learning rate: 0.00034791]
	Learning Rate: 0.00034791
	LOSS [training: 0.02640002690110723 | validation: 0.01418557591072282]
	TIME [epoch: 9.03 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035380081668671876		[learning rate: 0.00034684]
	Learning Rate: 0.000346843
	LOSS [training: 0.035380081668671876 | validation: 0.016578919088826995]
	TIME [epoch: 9.05 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02494042260464852		[learning rate: 0.00034578]
	Learning Rate: 0.00034578
	LOSS [training: 0.02494042260464852 | validation: 0.015564189018397602]
	TIME [epoch: 9.04 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020749716452769636		[learning rate: 0.00034472]
	Learning Rate: 0.00034472
	LOSS [training: 0.020749716452769636 | validation: 0.009713742158961714]
	TIME [epoch: 9.04 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022088679540166446		[learning rate: 0.00034366]
	Learning Rate: 0.000343663
	LOSS [training: 0.022088679540166446 | validation: 0.004439334030970372]
	TIME [epoch: 9.04 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01699897058121563		[learning rate: 0.00034261]
	Learning Rate: 0.00034261
	LOSS [training: 0.01699897058121563 | validation: 0.013046719816230849]
	TIME [epoch: 9.04 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017802994386237232		[learning rate: 0.00034156]
	Learning Rate: 0.00034156
	LOSS [training: 0.017802994386237232 | validation: 0.007939260275225513]
	TIME [epoch: 9.05 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017510978361033405		[learning rate: 0.00034051]
	Learning Rate: 0.000340513
	LOSS [training: 0.017510978361033405 | validation: 0.01250106541036537]
	TIME [epoch: 9.03 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011541747066921551		[learning rate: 0.00033947]
	Learning Rate: 0.000339469
	LOSS [training: 0.011541747066921551 | validation: 0.007255067736768577]
	TIME [epoch: 9.04 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015202795125664493		[learning rate: 0.00033843]
	Learning Rate: 0.000338428
	LOSS [training: 0.015202795125664493 | validation: 0.009817060869224025]
	TIME [epoch: 9.04 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02569641180040726		[learning rate: 0.00033739]
	Learning Rate: 0.000337391
	LOSS [training: 0.02569641180040726 | validation: 0.01558485543420416]
	TIME [epoch: 9.06 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021444693257999976		[learning rate: 0.00033636]
	Learning Rate: 0.000336357
	LOSS [training: 0.021444693257999976 | validation: 0.010563497961350463]
	TIME [epoch: 9.04 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02021174161328446		[learning rate: 0.00033533]
	Learning Rate: 0.000335326
	LOSS [training: 0.02021174161328446 | validation: 0.014051921977456326]
	TIME [epoch: 9.03 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019634902008194045		[learning rate: 0.0003343]
	Learning Rate: 0.000334298
	LOSS [training: 0.019634902008194045 | validation: 0.007596285342270687]
	TIME [epoch: 9.03 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03082242631923428		[learning rate: 0.00033327]
	Learning Rate: 0.000333273
	LOSS [training: 0.03082242631923428 | validation: 0.028845219505737735]
	TIME [epoch: 9.06 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03184796847526853		[learning rate: 0.00033225]
	Learning Rate: 0.000332251
	LOSS [training: 0.03184796847526853 | validation: 0.021662127714356418]
	TIME [epoch: 9.04 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03409581613915873		[learning rate: 0.00033123]
	Learning Rate: 0.000331233
	LOSS [training: 0.03409581613915873 | validation: 0.02660440184674714]
	TIME [epoch: 9.04 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02597081488843054		[learning rate: 0.00033022]
	Learning Rate: 0.000330217
	LOSS [training: 0.02597081488843054 | validation: 0.005153733234022113]
	TIME [epoch: 9.04 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015986614009491674		[learning rate: 0.00032921]
	Learning Rate: 0.000329205
	LOSS [training: 0.015986614009491674 | validation: 0.01963180293347083]
	TIME [epoch: 9.06 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01888522352278205		[learning rate: 0.0003282]
	Learning Rate: 0.000328196
	LOSS [training: 0.01888522352278205 | validation: 0.011290387880535348]
	TIME [epoch: 9.04 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016114188643926473		[learning rate: 0.00032719]
	Learning Rate: 0.00032719
	LOSS [training: 0.016114188643926473 | validation: 0.00975703725653505]
	TIME [epoch: 9.03 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02184683818501565		[learning rate: 0.00032619]
	Learning Rate: 0.000326187
	LOSS [training: 0.02184683818501565 | validation: 0.007119209710181978]
	TIME [epoch: 9.04 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020108074867349567		[learning rate: 0.00032519]
	Learning Rate: 0.000325187
	LOSS [training: 0.020108074867349567 | validation: 0.006598056373422892]
	TIME [epoch: 9.05 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025842123320258936		[learning rate: 0.00032419]
	Learning Rate: 0.00032419
	LOSS [training: 0.025842123320258936 | validation: 0.018278354575159986]
	TIME [epoch: 9.04 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02540461578633209		[learning rate: 0.0003232]
	Learning Rate: 0.000323196
	LOSS [training: 0.02540461578633209 | validation: 0.013132305110554361]
	TIME [epoch: 9.03 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02501641707340448		[learning rate: 0.00032221]
	Learning Rate: 0.000322206
	LOSS [training: 0.02501641707340448 | validation: 0.005540610165499302]
	TIME [epoch: 9.03 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020156716745020998		[learning rate: 0.00032122]
	Learning Rate: 0.000321218
	LOSS [training: 0.020156716745020998 | validation: 0.012288991947446464]
	TIME [epoch: 9.05 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02015083428477747		[learning rate: 0.00032023]
	Learning Rate: 0.000320233
	LOSS [training: 0.02015083428477747 | validation: 0.005785624939966292]
	TIME [epoch: 9.05 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02035752660661535		[learning rate: 0.00031925]
	Learning Rate: 0.000319252
	LOSS [training: 0.02035752660661535 | validation: 0.012832946523448716]
	TIME [epoch: 9.04 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0226063547310609		[learning rate: 0.00031827]
	Learning Rate: 0.000318273
	LOSS [training: 0.0226063547310609 | validation: 0.004840271461306297]
	TIME [epoch: 9.04 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022808068988035602		[learning rate: 0.0003173]
	Learning Rate: 0.000317297
	LOSS [training: 0.022808068988035602 | validation: 0.009728512626213092]
	TIME [epoch: 9.04 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021170769982210725		[learning rate: 0.00031632]
	Learning Rate: 0.000316325
	LOSS [training: 0.021170769982210725 | validation: 0.011197116234763594]
	TIME [epoch: 9.05 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023413002023238032		[learning rate: 0.00031536]
	Learning Rate: 0.000315355
	LOSS [training: 0.023413002023238032 | validation: 0.017671395533371444]
	TIME [epoch: 9.04 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024709605576603955		[learning rate: 0.00031439]
	Learning Rate: 0.000314389
	LOSS [training: 0.024709605576603955 | validation: 0.026362003581227568]
	TIME [epoch: 9.03 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02514430732608598		[learning rate: 0.00031342]
	Learning Rate: 0.000313425
	LOSS [training: 0.02514430732608598 | validation: 0.009805586379026784]
	TIME [epoch: 9.04 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020227037049144286		[learning rate: 0.00031246]
	Learning Rate: 0.000312464
	LOSS [training: 0.020227037049144286 | validation: 0.014513047659543888]
	TIME [epoch: 9.06 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02147241756358964		[learning rate: 0.00031151]
	Learning Rate: 0.000311506
	LOSS [training: 0.02147241756358964 | validation: 0.015025351809488654]
	TIME [epoch: 9.04 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023408533144139966		[learning rate: 0.00031055]
	Learning Rate: 0.000310551
	LOSS [training: 0.023408533144139966 | validation: 0.00800989243798759]
	TIME [epoch: 9.04 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023184602266407596		[learning rate: 0.0003096]
	Learning Rate: 0.000309599
	LOSS [training: 0.023184602266407596 | validation: 0.006049941403903318]
	TIME [epoch: 9.04 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018080119294292648		[learning rate: 0.00030865]
	Learning Rate: 0.00030865
	LOSS [training: 0.018080119294292648 | validation: 0.014574130950293897]
	TIME [epoch: 9.06 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015348579704226432		[learning rate: 0.0003077]
	Learning Rate: 0.000307704
	LOSS [training: 0.015348579704226432 | validation: 0.010749623754008512]
	TIME [epoch: 9.04 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01978241242758102		[learning rate: 0.00030676]
	Learning Rate: 0.000306761
	LOSS [training: 0.01978241242758102 | validation: 0.012068851328331817]
	TIME [epoch: 9.04 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021584037876165568		[learning rate: 0.00030582]
	Learning Rate: 0.00030582
	LOSS [training: 0.021584037876165568 | validation: 0.009117201554085314]
	TIME [epoch: 9.04 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023588686703808353		[learning rate: 0.00030488]
	Learning Rate: 0.000304883
	LOSS [training: 0.023588686703808353 | validation: 0.00897036900705216]
	TIME [epoch: 9.06 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02260501290072037		[learning rate: 0.00030395]
	Learning Rate: 0.000303948
	LOSS [training: 0.02260501290072037 | validation: 0.009611492983582975]
	TIME [epoch: 9.04 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016162188527842743		[learning rate: 0.00030302]
	Learning Rate: 0.000303017
	LOSS [training: 0.016162188527842743 | validation: 0.007625354914115275]
	TIME [epoch: 9.04 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019230671622676828		[learning rate: 0.00030209]
	Learning Rate: 0.000302088
	LOSS [training: 0.019230671622676828 | validation: 0.017870973479131882]
	TIME [epoch: 9.04 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021502195073434448		[learning rate: 0.00030116]
	Learning Rate: 0.000301162
	LOSS [training: 0.021502195073434448 | validation: 0.016216444266799565]
	TIME [epoch: 9.06 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020515956818404988		[learning rate: 0.00030024]
	Learning Rate: 0.000300239
	LOSS [training: 0.020515956818404988 | validation: 0.011058392055638803]
	TIME [epoch: 9.04 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019147044937742802		[learning rate: 0.00029932]
	Learning Rate: 0.000299318
	LOSS [training: 0.019147044937742802 | validation: 0.00932729711559179]
	TIME [epoch: 9.04 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02020201143577595		[learning rate: 0.0002984]
	Learning Rate: 0.000298401
	LOSS [training: 0.02020201143577595 | validation: 0.008396475380215412]
	TIME [epoch: 9.03 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018092804326176805		[learning rate: 0.00029749]
	Learning Rate: 0.000297486
	LOSS [training: 0.018092804326176805 | validation: 0.008463900744174883]
	TIME [epoch: 9.05 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017880724792356528		[learning rate: 0.00029657]
	Learning Rate: 0.000296574
	LOSS [training: 0.017880724792356528 | validation: 0.010795256798007847]
	TIME [epoch: 9.05 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02164151827575323		[learning rate: 0.00029567]
	Learning Rate: 0.000295665
	LOSS [training: 0.02164151827575323 | validation: 0.011258051845940212]
	TIME [epoch: 9.03 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027470322109503963		[learning rate: 0.00029476]
	Learning Rate: 0.000294759
	LOSS [training: 0.027470322109503963 | validation: 0.01050821255533458]
	TIME [epoch: 9.04 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021646850892806088		[learning rate: 0.00029386]
	Learning Rate: 0.000293855
	LOSS [training: 0.021646850892806088 | validation: 0.012447878482654275]
	TIME [epoch: 9.04 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024974161177809377		[learning rate: 0.00029295]
	Learning Rate: 0.000292954
	LOSS [training: 0.024974161177809377 | validation: 0.009342444104230704]
	TIME [epoch: 9.05 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02560632834648881		[learning rate: 0.00029206]
	Learning Rate: 0.000292056
	LOSS [training: 0.02560632834648881 | validation: 0.005328125802331043]
	TIME [epoch: 9.04 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023286475774814658		[learning rate: 0.00029116]
	Learning Rate: 0.000291161
	LOSS [training: 0.023286475774814658 | validation: 0.006116337341016579]
	TIME [epoch: 9.04 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01756206729431025		[learning rate: 0.00029027]
	Learning Rate: 0.000290269
	LOSS [training: 0.01756206729431025 | validation: 0.01748658093971337]
	TIME [epoch: 9.04 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021743656569384314		[learning rate: 0.00028938]
	Learning Rate: 0.000289379
	LOSS [training: 0.021743656569384314 | validation: 0.003559807754449352]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1654.pth
	Model improved!!!
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02188382566887853		[learning rate: 0.00028849]
	Learning Rate: 0.000288492
	LOSS [training: 0.02188382566887853 | validation: 0.012000671860157682]
	TIME [epoch: 9.02 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02107971074342654		[learning rate: 0.00028761]
	Learning Rate: 0.000287607
	LOSS [training: 0.02107971074342654 | validation: 0.012363533016589252]
	TIME [epoch: 9.12 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0228069450299237		[learning rate: 0.00028673]
	Learning Rate: 0.000286726
	LOSS [training: 0.0228069450299237 | validation: 0.009312509892237928]
	TIME [epoch: 9.03 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023803184615549037		[learning rate: 0.00028585]
	Learning Rate: 0.000285847
	LOSS [training: 0.023803184615549037 | validation: 0.014272248725478852]
	TIME [epoch: 9.06 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023309605496804185		[learning rate: 0.00028497]
	Learning Rate: 0.000284971
	LOSS [training: 0.023309605496804185 | validation: 0.006108376118364945]
	TIME [epoch: 9.03 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01940736626236202		[learning rate: 0.0002841]
	Learning Rate: 0.000284097
	LOSS [training: 0.01940736626236202 | validation: 0.005374469428486637]
	TIME [epoch: 9.04 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02163233068062486		[learning rate: 0.00028323]
	Learning Rate: 0.000283226
	LOSS [training: 0.02163233068062486 | validation: 0.00747495083036463]
	TIME [epoch: 9.04 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021038886104871868		[learning rate: 0.00028236]
	Learning Rate: 0.000282358
	LOSS [training: 0.021038886104871868 | validation: 0.013209876950044656]
	TIME [epoch: 9.05 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024220195056538656		[learning rate: 0.00028149]
	Learning Rate: 0.000281492
	LOSS [training: 0.024220195056538656 | validation: 0.017531945597914687]
	TIME [epoch: 9.05 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02464294993159985		[learning rate: 0.00028063]
	Learning Rate: 0.000280629
	LOSS [training: 0.02464294993159985 | validation: 0.01966444749807875]
	TIME [epoch: 9.04 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025935415763058984		[learning rate: 0.00027977]
	Learning Rate: 0.000279769
	LOSS [training: 0.025935415763058984 | validation: 0.01553885892280222]
	TIME [epoch: 9.03 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021541483307405605		[learning rate: 0.00027891]
	Learning Rate: 0.000278912
	LOSS [training: 0.021541483307405605 | validation: 0.005363881424379594]
	TIME [epoch: 9.02 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026348039349344182		[learning rate: 0.00027806]
	Learning Rate: 0.000278057
	LOSS [training: 0.026348039349344182 | validation: 0.0033187425702335257]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1667.pth
	Model improved!!!
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020894293946205216		[learning rate: 0.0002772]
	Learning Rate: 0.000277204
	LOSS [training: 0.020894293946205216 | validation: 0.016142997391783067]
	TIME [epoch: 9.02 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020359903665433974		[learning rate: 0.00027635]
	Learning Rate: 0.000276355
	LOSS [training: 0.020359903665433974 | validation: 0.022884200543922394]
	TIME [epoch: 9.03 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025556448408131687		[learning rate: 0.00027551]
	Learning Rate: 0.000275507
	LOSS [training: 0.025556448408131687 | validation: 0.01580271273868927]
	TIME [epoch: 9.02 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023233218884146072		[learning rate: 0.00027466]
	Learning Rate: 0.000274663
	LOSS [training: 0.023233218884146072 | validation: 0.007150039874203293]
	TIME [epoch: 9.04 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017322349184838486		[learning rate: 0.00027382]
	Learning Rate: 0.000273821
	LOSS [training: 0.017322349184838486 | validation: 0.00646637876924558]
	TIME [epoch: 9.03 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019948368991456484		[learning rate: 0.00027298]
	Learning Rate: 0.000272982
	LOSS [training: 0.019948368991456484 | validation: 0.007477772534911711]
	TIME [epoch: 9.06 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018706372706542344		[learning rate: 0.00027214]
	Learning Rate: 0.000272145
	LOSS [training: 0.018706372706542344 | validation: 0.008012076201808608]
	TIME [epoch: 9.04 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016895758786294724		[learning rate: 0.00027131]
	Learning Rate: 0.000271311
	LOSS [training: 0.016895758786294724 | validation: 0.008647929410799405]
	TIME [epoch: 9.06 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01740836494729393		[learning rate: 0.00027048]
	Learning Rate: 0.000270479
	LOSS [training: 0.01740836494729393 | validation: 0.01703986659730393]
	TIME [epoch: 9.06 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018608062813585242		[learning rate: 0.00026965]
	Learning Rate: 0.00026965
	LOSS [training: 0.018608062813585242 | validation: 0.01943581830609714]
	TIME [epoch: 9.04 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029596293651904255		[learning rate: 0.00026882]
	Learning Rate: 0.000268823
	LOSS [training: 0.029596293651904255 | validation: 0.010768422992867989]
	TIME [epoch: 9.05 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026822357172111948		[learning rate: 0.000268]
	Learning Rate: 0.000267999
	LOSS [training: 0.026822357172111948 | validation: 0.010971588356779624]
	TIME [epoch: 9.05 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01935215015343704		[learning rate: 0.00026718]
	Learning Rate: 0.000267178
	LOSS [training: 0.01935215015343704 | validation: 0.01177804629528409]
	TIME [epoch: 9.05 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02087676363495102		[learning rate: 0.00026636]
	Learning Rate: 0.000266359
	LOSS [training: 0.02087676363495102 | validation: 0.006264285529449897]
	TIME [epoch: 9.03 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019855120040260056		[learning rate: 0.00026554]
	Learning Rate: 0.000265542
	LOSS [training: 0.019855120040260056 | validation: 0.014889396736473628]
	TIME [epoch: 9.03 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01662971925032694		[learning rate: 0.00026473]
	Learning Rate: 0.000264728
	LOSS [training: 0.01662971925032694 | validation: 0.006755394197063398]
	TIME [epoch: 9.03 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021159173841263715		[learning rate: 0.00026392]
	Learning Rate: 0.000263917
	LOSS [training: 0.021159173841263715 | validation: 0.015737120072367803]
	TIME [epoch: 9.13 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01962462008762835		[learning rate: 0.00026311]
	Learning Rate: 0.000263108
	LOSS [training: 0.01962462008762835 | validation: 0.012062313122384339]
	TIME [epoch: 9.04 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02167199809135762		[learning rate: 0.0002623]
	Learning Rate: 0.000262301
	LOSS [training: 0.02167199809135762 | validation: 0.016586471143559284]
	TIME [epoch: 9.04 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016984599054764685		[learning rate: 0.0002615]
	Learning Rate: 0.000261497
	LOSS [training: 0.016984599054764685 | validation: 0.008897178061929127]
	TIME [epoch: 9.04 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014636693316575532		[learning rate: 0.0002607]
	Learning Rate: 0.000260695
	LOSS [training: 0.014636693316575532 | validation: 0.0013683567199851508]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1688.pth
	Model improved!!!
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01635320184745196		[learning rate: 0.0002599]
	Learning Rate: 0.000259896
	LOSS [training: 0.01635320184745196 | validation: 0.020606780965709726]
	TIME [epoch: 9.04 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021161188047214872		[learning rate: 0.0002591]
	Learning Rate: 0.0002591
	LOSS [training: 0.021161188047214872 | validation: 0.0006003703033372153]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1690.pth
	Model improved!!!
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019636814939045653		[learning rate: 0.00025831]
	Learning Rate: 0.000258305
	LOSS [training: 0.019636814939045653 | validation: 0.00829472440698748]
	TIME [epoch: 9.04 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019815378113251434		[learning rate: 0.00025751]
	Learning Rate: 0.000257513
	LOSS [training: 0.019815378113251434 | validation: 0.004636860295162229]
	TIME [epoch: 9.05 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018359314647003112		[learning rate: 0.00025672]
	Learning Rate: 0.000256724
	LOSS [training: 0.018359314647003112 | validation: 0.010147409722063308]
	TIME [epoch: 9.05 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01898069883725718		[learning rate: 0.00025594]
	Learning Rate: 0.000255937
	LOSS [training: 0.01898069883725718 | validation: 0.006871267366517668]
	TIME [epoch: 9.03 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019195381326098396		[learning rate: 0.00025515]
	Learning Rate: 0.000255153
	LOSS [training: 0.019195381326098396 | validation: 0.01330446127560471]
	TIME [epoch: 9.04 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024176293817845203		[learning rate: 0.00025437]
	Learning Rate: 0.00025437
	LOSS [training: 0.024176293817845203 | validation: 0.006409626739023164]
	TIME [epoch: 9.04 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01897479725324505		[learning rate: 0.00025359]
	Learning Rate: 0.000253591
	LOSS [training: 0.01897479725324505 | validation: 0.012766175795303633]
	TIME [epoch: 9.06 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024793922690201996		[learning rate: 0.00025281]
	Learning Rate: 0.000252813
	LOSS [training: 0.024793922690201996 | validation: 0.012253876938456788]
	TIME [epoch: 9.04 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020242360532815824		[learning rate: 0.00025204]
	Learning Rate: 0.000252038
	LOSS [training: 0.020242360532815824 | validation: 0.008649300296443911]
	TIME [epoch: 9.04 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02221269344552927		[learning rate: 0.00025127]
	Learning Rate: 0.000251266
	LOSS [training: 0.02221269344552927 | validation: 0.012827198043912295]
	TIME [epoch: 9.04 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01989133155050125		[learning rate: 0.0002505]
	Learning Rate: 0.000250496
	LOSS [training: 0.01989133155050125 | validation: 0.022500286807256513]
	TIME [epoch: 9.06 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023495681738069648		[learning rate: 0.00024973]
	Learning Rate: 0.000249728
	LOSS [training: 0.023495681738069648 | validation: 0.01027655884792697]
	TIME [epoch: 9.04 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018363401697021303		[learning rate: 0.00024896]
	Learning Rate: 0.000248962
	LOSS [training: 0.018363401697021303 | validation: 0.01411098363876194]
	TIME [epoch: 9.04 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019586124365517828		[learning rate: 0.0002482]
	Learning Rate: 0.000248199
	LOSS [training: 0.019586124365517828 | validation: 0.016168675531168575]
	TIME [epoch: 9.04 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017907664663679202		[learning rate: 0.00024744]
	Learning Rate: 0.000247438
	LOSS [training: 0.017907664663679202 | validation: 0.011914226261285101]
	TIME [epoch: 9.05 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020239229679329528		[learning rate: 0.00024668]
	Learning Rate: 0.00024668
	LOSS [training: 0.020239229679329528 | validation: 0.01286516076030513]
	TIME [epoch: 9.05 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020996436655638964		[learning rate: 0.00024592]
	Learning Rate: 0.000245923
	LOSS [training: 0.020996436655638964 | validation: 0.014144739017195398]
	TIME [epoch: 9.04 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02694504740130372		[learning rate: 0.00024517]
	Learning Rate: 0.00024517
	LOSS [training: 0.02694504740130372 | validation: 0.014412727223370617]
	TIME [epoch: 9.04 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02771011374187477		[learning rate: 0.00024442]
	Learning Rate: 0.000244418
	LOSS [training: 0.02771011374187477 | validation: 0.005673145787023824]
	TIME [epoch: 9.05 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025609015718058896		[learning rate: 0.00024367]
	Learning Rate: 0.000243669
	LOSS [training: 0.025609015718058896 | validation: 0.00853016615322789]
	TIME [epoch: 9.05 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02508568662343702		[learning rate: 0.00024292]
	Learning Rate: 0.000242922
	LOSS [training: 0.02508568662343702 | validation: 0.01802178477142355]
	TIME [epoch: 9.04 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023931342951786973		[learning rate: 0.00024218]
	Learning Rate: 0.000242177
	LOSS [training: 0.023931342951786973 | validation: 0.014419950343602599]
	TIME [epoch: 9.04 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02184216284288391		[learning rate: 0.00024143]
	Learning Rate: 0.000241435
	LOSS [training: 0.02184216284288391 | validation: 0.003246802909115615]
	TIME [epoch: 9.04 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021629206314687528		[learning rate: 0.00024069]
	Learning Rate: 0.000240695
	LOSS [training: 0.021629206314687528 | validation: 0.008711924340947544]
	TIME [epoch: 9.06 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0213908192939258		[learning rate: 0.00023996]
	Learning Rate: 0.000239957
	LOSS [training: 0.0213908192939258 | validation: 0.005994389566451149]
	TIME [epoch: 9.02 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020898063612097312		[learning rate: 0.00023922]
	Learning Rate: 0.000239221
	LOSS [training: 0.020898063612097312 | validation: 0.012285918840134337]
	TIME [epoch: 9.11 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021683220041079983		[learning rate: 0.00023849]
	Learning Rate: 0.000238488
	LOSS [training: 0.021683220041079983 | validation: 0.0014414428503277178]
	TIME [epoch: 9.03 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01861020847151719		[learning rate: 0.00023776]
	Learning Rate: 0.000237757
	LOSS [training: 0.01861020847151719 | validation: 0.012875063990105304]
	TIME [epoch: 9.06 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013434511679930755		[learning rate: 0.00023703]
	Learning Rate: 0.000237028
	LOSS [training: 0.013434511679930755 | validation: 0.018330302711180767]
	TIME [epoch: 9.04 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020455921932667626		[learning rate: 0.0002363]
	Learning Rate: 0.000236302
	LOSS [training: 0.020455921932667626 | validation: 0.011702071809863842]
	TIME [epoch: 9.04 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02344491883697358		[learning rate: 0.00023558]
	Learning Rate: 0.000235577
	LOSS [training: 0.02344491883697358 | validation: -0.0028947228929798135]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1721.pth
	Model improved!!!
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019787297103019685		[learning rate: 0.00023486]
	Learning Rate: 0.000234855
	LOSS [training: 0.019787297103019685 | validation: 0.015762682320614348]
	TIME [epoch: 9.05 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017048805353832967		[learning rate: 0.00023414]
	Learning Rate: 0.000234135
	LOSS [training: 0.017048805353832967 | validation: 0.011047169136686099]
	TIME [epoch: 9.04 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017125298648787132		[learning rate: 0.00023342]
	Learning Rate: 0.000233417
	LOSS [training: 0.017125298648787132 | validation: 0.00915384450144457]
	TIME [epoch: 9.03 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018303612725168332		[learning rate: 0.0002327]
	Learning Rate: 0.000232702
	LOSS [training: 0.018303612725168332 | validation: 0.010223520087324361]
	TIME [epoch: 9.04 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014802936534761387		[learning rate: 0.00023199]
	Learning Rate: 0.000231989
	LOSS [training: 0.014802936534761387 | validation: 0.006152201251992981]
	TIME [epoch: 9.04 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02074823436588414		[learning rate: 0.00023128]
	Learning Rate: 0.000231277
	LOSS [training: 0.02074823436588414 | validation: 0.005248418471549618]
	TIME [epoch: 9.05 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020281336399860246		[learning rate: 0.00023057]
	Learning Rate: 0.000230569
	LOSS [training: 0.020281336399860246 | validation: 0.0056787552456652145]
	TIME [epoch: 9.04 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020124112725929417		[learning rate: 0.00022986]
	Learning Rate: 0.000229862
	LOSS [training: 0.020124112725929417 | validation: 0.0006391914438269898]
	TIME [epoch: 9.04 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018395311582176093		[learning rate: 0.00022916]
	Learning Rate: 0.000229157
	LOSS [training: 0.018395311582176093 | validation: 0.0033581631522995132]
	TIME [epoch: 9.03 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016260746110459877		[learning rate: 0.00022845]
	Learning Rate: 0.000228455
	LOSS [training: 0.016260746110459877 | validation: 0.010839190439759781]
	TIME [epoch: 9.06 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012914901682041763		[learning rate: 0.00022775]
	Learning Rate: 0.000227754
	LOSS [training: 0.012914901682041763 | validation: 0.011997704203793019]
	TIME [epoch: 9.04 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015482358174321382		[learning rate: 0.00022706]
	Learning Rate: 0.000227056
	LOSS [training: 0.015482358174321382 | validation: 0.007049160200504828]
	TIME [epoch: 9.04 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01767193933147864		[learning rate: 0.00022636]
	Learning Rate: 0.00022636
	LOSS [training: 0.01767193933147864 | validation: 0.0053104423068756675]
	TIME [epoch: 9.04 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017383786966720473		[learning rate: 0.00022567]
	Learning Rate: 0.000225666
	LOSS [training: 0.017383786966720473 | validation: 0.006192878600343222]
	TIME [epoch: 9.06 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019536558145845546		[learning rate: 0.00022497]
	Learning Rate: 0.000224974
	LOSS [training: 0.019536558145845546 | validation: 0.0038485735552661383]
	TIME [epoch: 9.04 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014782274691616156		[learning rate: 0.00022428]
	Learning Rate: 0.000224285
	LOSS [training: 0.014782274691616156 | validation: 0.0025214411740592858]
	TIME [epoch: 9.04 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021509023625575628		[learning rate: 0.0002236]
	Learning Rate: 0.000223597
	LOSS [training: 0.021509023625575628 | validation: 0.015152177950959368]
	TIME [epoch: 9.04 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01621046397058551		[learning rate: 0.00022291]
	Learning Rate: 0.000222912
	LOSS [training: 0.01621046397058551 | validation: 0.021580915815250196]
	TIME [epoch: 9.05 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01760289245517192		[learning rate: 0.00022223]
	Learning Rate: 0.000222229
	LOSS [training: 0.01760289245517192 | validation: 0.012011641026139597]
	TIME [epoch: 9.04 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020148584584301583		[learning rate: 0.00022155]
	Learning Rate: 0.000221547
	LOSS [training: 0.020148584584301583 | validation: 0.007945175767875843]
	TIME [epoch: 9.04 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014844899163167502		[learning rate: 0.00022087]
	Learning Rate: 0.000220868
	LOSS [training: 0.014844899163167502 | validation: 0.00859614876467563]
	TIME [epoch: 9.04 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018331737757945388		[learning rate: 0.00022019]
	Learning Rate: 0.000220191
	LOSS [training: 0.018331737757945388 | validation: 0.011893158575368348]
	TIME [epoch: 9.05 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01505932328727319		[learning rate: 0.00021952]
	Learning Rate: 0.000219516
	LOSS [training: 0.01505932328727319 | validation: 0.0010097189294598378]
	TIME [epoch: 9.06 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020339404658692252		[learning rate: 0.00021884]
	Learning Rate: 0.000218843
	LOSS [training: 0.020339404658692252 | validation: 0.011959950696254384]
	TIME [epoch: 9.04 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019134156475738434		[learning rate: 0.00021817]
	Learning Rate: 0.000218172
	LOSS [training: 0.019134156475738434 | validation: -0.00022351208280326667]
	TIME [epoch: 9.04 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019090282425424824		[learning rate: 0.0002175]
	Learning Rate: 0.000217504
	LOSS [training: 0.019090282425424824 | validation: 0.0019309463378203143]
	TIME [epoch: 9.06 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018801378412164393		[learning rate: 0.00021684]
	Learning Rate: 0.000216837
	LOSS [training: 0.018801378412164393 | validation: 0.002876275074963497]
	TIME [epoch: 9.06 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018142052657940888		[learning rate: 0.00021617]
	Learning Rate: 0.000216172
	LOSS [training: 0.018142052657940888 | validation: 0.016214783610148158]
	TIME [epoch: 9.05 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02245569274615999		[learning rate: 0.00021551]
	Learning Rate: 0.00021551
	LOSS [training: 0.02245569274615999 | validation: 0.004823024563182328]
	TIME [epoch: 9.05 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013610392665113052		[learning rate: 0.00021485]
	Learning Rate: 0.000214849
	LOSS [training: 0.013610392665113052 | validation: 0.006325132085235883]
	TIME [epoch: 9.05 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01613998186489431		[learning rate: 0.00021419]
	Learning Rate: 0.00021419
	LOSS [training: 0.01613998186489431 | validation: 0.01575276063860871]
	TIME [epoch: 9.07 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017754027628353288		[learning rate: 0.00021353]
	Learning Rate: 0.000213534
	LOSS [training: 0.017754027628353288 | validation: 0.00923109224759209]
	TIME [epoch: 9.05 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018924876517278127		[learning rate: 0.00021288]
	Learning Rate: 0.000212879
	LOSS [training: 0.018924876517278127 | validation: 0.011526493049485387]
	TIME [epoch: 9.04 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021339952382279613		[learning rate: 0.00021223]
	Learning Rate: 0.000212227
	LOSS [training: 0.021339952382279613 | validation: 0.013152470689704179]
	TIME [epoch: 9.04 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021127544223207832		[learning rate: 0.00021158]
	Learning Rate: 0.000211576
	LOSS [training: 0.021127544223207832 | validation: 0.014438466083651971]
	TIME [epoch: 9.15 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018896382239983425		[learning rate: 0.00021093]
	Learning Rate: 0.000210928
	LOSS [training: 0.018896382239983425 | validation: 0.009064987995710844]
	TIME [epoch: 9.13 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016662214026910597		[learning rate: 0.00021028]
	Learning Rate: 0.000210281
	LOSS [training: 0.016662214026910597 | validation: 0.0077049818435728145]
	TIME [epoch: 9.04 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016577257726418083		[learning rate: 0.00020964]
	Learning Rate: 0.000209636
	LOSS [training: 0.016577257726418083 | validation: 0.008879018823967293]
	TIME [epoch: 9.04 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019118667668319832		[learning rate: 0.00020899]
	Learning Rate: 0.000208994
	LOSS [training: 0.019118667668319832 | validation: 0.018633685877909326]
	TIME [epoch: 9.06 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023365733689814733		[learning rate: 0.00020835]
	Learning Rate: 0.000208353
	LOSS [training: 0.023365733689814733 | validation: 0.014582982955272203]
	TIME [epoch: 9.04 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030267097703163798		[learning rate: 0.00020771]
	Learning Rate: 0.000207714
	LOSS [training: 0.030267097703163798 | validation: 0.023662438054268223]
	TIME [epoch: 9.04 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02111426184239342		[learning rate: 0.00020708]
	Learning Rate: 0.000207078
	LOSS [training: 0.02111426184239342 | validation: 0.011017368343948269]
	TIME [epoch: 9.04 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01786747548287532		[learning rate: 0.00020644]
	Learning Rate: 0.000206443
	LOSS [training: 0.01786747548287532 | validation: 0.008783215291638589]
	TIME [epoch: 9.05 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029867378257254974		[learning rate: 0.00020581]
	Learning Rate: 0.00020581
	LOSS [training: 0.029867378257254974 | validation: 0.024469511352720394]
	TIME [epoch: 9.04 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028317972299640566		[learning rate: 0.00020518]
	Learning Rate: 0.000205179
	LOSS [training: 0.028317972299640566 | validation: 0.01175426182131635]
	TIME [epoch: 9.04 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024591611511146198		[learning rate: 0.00020455]
	Learning Rate: 0.00020455
	LOSS [training: 0.024591611511146198 | validation: 0.020493836320557075]
	TIME [epoch: 9.04 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022794382930346472		[learning rate: 0.00020392]
	Learning Rate: 0.000203923
	LOSS [training: 0.022794382930346472 | validation: 0.004732018334970231]
	TIME [epoch: 9.05 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020225029799901036		[learning rate: 0.0002033]
	Learning Rate: 0.000203298
	LOSS [training: 0.020225029799901036 | validation: 0.009675903058102127]
	TIME [epoch: 9.05 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02111934412611944		[learning rate: 0.00020267]
	Learning Rate: 0.000202675
	LOSS [training: 0.02111934412611944 | validation: 0.011413137165530725]
	TIME [epoch: 9.04 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015174394889564513		[learning rate: 0.00020205]
	Learning Rate: 0.000202054
	LOSS [training: 0.015174394889564513 | validation: 0.005009636931462079]
	TIME [epoch: 9.04 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019172611363960423		[learning rate: 0.00020143]
	Learning Rate: 0.000201434
	LOSS [training: 0.019172611363960423 | validation: 0.009796846981669419]
	TIME [epoch: 9.05 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01955603218905843		[learning rate: 0.00020082]
	Learning Rate: 0.000200817
	LOSS [training: 0.01955603218905843 | validation: 0.008279710501828647]
	TIME [epoch: 9.05 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01760953896254318		[learning rate: 0.0002002]
	Learning Rate: 0.000200201
	LOSS [training: 0.01760953896254318 | validation: 0.009592487409279774]
	TIME [epoch: 9.03 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019308003432664214		[learning rate: 0.00019959]
	Learning Rate: 0.000199588
	LOSS [training: 0.019308003432664214 | validation: 0.011238271165319448]
	TIME [epoch: 9.04 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019292450336477168		[learning rate: 0.00019898]
	Learning Rate: 0.000198976
	LOSS [training: 0.019292450336477168 | validation: 0.010848330702952717]
	TIME [epoch: 9.04 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017439025668062987		[learning rate: 0.00019837]
	Learning Rate: 0.000198366
	LOSS [training: 0.017439025668062987 | validation: 0.010436138470787878]
	TIME [epoch: 9.06 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020935979145507922		[learning rate: 0.00019776]
	Learning Rate: 0.000197758
	LOSS [training: 0.020935979145507922 | validation: 0.012693215395594603]
	TIME [epoch: 9.04 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023292697541341806		[learning rate: 0.00019715]
	Learning Rate: 0.000197151
	LOSS [training: 0.023292697541341806 | validation: 0.013717136063800341]
	TIME [epoch: 9.04 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023969308912323115		[learning rate: 0.00019655]
	Learning Rate: 0.000196547
	LOSS [training: 0.023969308912323115 | validation: 0.01526394257948235]
	TIME [epoch: 9.04 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027804278561347893		[learning rate: 0.00019594]
	Learning Rate: 0.000195945
	LOSS [training: 0.027804278561347893 | validation: 0.017827153858275897]
	TIME [epoch: 9.06 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026918986465845895		[learning rate: 0.00019534]
	Learning Rate: 0.000195344
	LOSS [training: 0.026918986465845895 | validation: 0.016668175108974562]
	TIME [epoch: 9.04 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02253548675762155		[learning rate: 0.00019475]
	Learning Rate: 0.000194745
	LOSS [training: 0.02253548675762155 | validation: 0.025223523568931566]
	TIME [epoch: 9.04 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030247836137958062		[learning rate: 0.00019415]
	Learning Rate: 0.000194148
	LOSS [training: 0.030247836137958062 | validation: 0.017642685988454587]
	TIME [epoch: 9.04 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02639292396398063		[learning rate: 0.00019355]
	Learning Rate: 0.000193553
	LOSS [training: 0.02639292396398063 | validation: 0.006211295779968495]
	TIME [epoch: 9.06 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019469523550329982		[learning rate: 0.00019296]
	Learning Rate: 0.00019296
	LOSS [training: 0.019469523550329982 | validation: 0.020549781760540772]
	TIME [epoch: 9.04 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02408761943512669		[learning rate: 0.00019237]
	Learning Rate: 0.000192368
	LOSS [training: 0.02408761943512669 | validation: 0.01321632948139028]
	TIME [epoch: 9.04 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017824673135347986		[learning rate: 0.00019178]
	Learning Rate: 0.000191778
	LOSS [training: 0.017824673135347986 | validation: 0.012057317355668826]
	TIME [epoch: 9.04 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018378535396829147		[learning rate: 0.00019119]
	Learning Rate: 0.000191191
	LOSS [training: 0.018378535396829147 | validation: 0.022348495286526344]
	TIME [epoch: 9.06 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016483174444708		[learning rate: 0.0001906]
	Learning Rate: 0.000190605
	LOSS [training: 0.016483174444708 | validation: 0.006420981468037448]
	TIME [epoch: 9.04 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018203901527585626		[learning rate: 0.00019002]
	Learning Rate: 0.00019002
	LOSS [training: 0.018203901527585626 | validation: 0.008264678892109596]
	TIME [epoch: 9.03 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017432348514595557		[learning rate: 0.00018944]
	Learning Rate: 0.000189438
	LOSS [training: 0.017432348514595557 | validation: 0.012153318830241963]
	TIME [epoch: 9.04 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022703284511955944		[learning rate: 0.00018886]
	Learning Rate: 0.000188857
	LOSS [training: 0.022703284511955944 | validation: 0.007782806564133082]
	TIME [epoch: 9.04 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015581459812956158		[learning rate: 0.00018828]
	Learning Rate: 0.000188278
	LOSS [training: 0.015581459812956158 | validation: 0.007614141583699682]
	TIME [epoch: 9.05 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022740722792424773		[learning rate: 0.0001877]
	Learning Rate: 0.000187701
	LOSS [training: 0.022740722792424773 | validation: 0.012106926620584588]
	TIME [epoch: 9.03 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019487908159537704		[learning rate: 0.00018713]
	Learning Rate: 0.000187126
	LOSS [training: 0.019487908159537704 | validation: 0.01927473082772554]
	TIME [epoch: 9.04 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016687232752844724		[learning rate: 0.00018655]
	Learning Rate: 0.000186552
	LOSS [training: 0.016687232752844724 | validation: 0.011917597372973071]
	TIME [epoch: 9.04 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017477404734377453		[learning rate: 0.00018598]
	Learning Rate: 0.00018598
	LOSS [training: 0.017477404734377453 | validation: 0.006218781667021134]
	TIME [epoch: 9.06 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01452645348037899		[learning rate: 0.00018541]
	Learning Rate: 0.00018541
	LOSS [training: 0.01452645348037899 | validation: 0.000707749670944477]
	TIME [epoch: 9.04 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016853924025079216		[learning rate: 0.00018484]
	Learning Rate: 0.000184842
	LOSS [training: 0.016853924025079216 | validation: 0.006300964110910163]
	TIME [epoch: 9.04 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017443803494425186		[learning rate: 0.00018428]
	Learning Rate: 0.000184275
	LOSS [training: 0.017443803494425186 | validation: 0.0227202542142719]
	TIME [epoch: 9.03 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01410033660076678		[learning rate: 0.00018371]
	Learning Rate: 0.00018371
	LOSS [training: 0.01410033660076678 | validation: 0.012892739878072285]
	TIME [epoch: 9.07 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01914165224336042		[learning rate: 0.00018315]
	Learning Rate: 0.000183147
	LOSS [training: 0.01914165224336042 | validation: 0.008364880535785444]
	TIME [epoch: 9.04 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019958280661365044		[learning rate: 0.00018259]
	Learning Rate: 0.000182586
	LOSS [training: 0.019958280661365044 | validation: 0.016445245113031675]
	TIME [epoch: 9.04 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01903550112282882		[learning rate: 0.00018203]
	Learning Rate: 0.000182026
	LOSS [training: 0.01903550112282882 | validation: 0.005309969078412476]
	TIME [epoch: 9.04 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01778157023950952		[learning rate: 0.00018147]
	Learning Rate: 0.000181468
	LOSS [training: 0.01778157023950952 | validation: 0.0077935000584242065]
	TIME [epoch: 9.06 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02052008293946471		[learning rate: 0.00018091]
	Learning Rate: 0.000180912
	LOSS [training: 0.02052008293946471 | validation: 0.008088945053855092]
	TIME [epoch: 9.04 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01678034219502882		[learning rate: 0.00018036]
	Learning Rate: 0.000180357
	LOSS [training: 0.01678034219502882 | validation: 0.005941274008435011]
	TIME [epoch: 9.04 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02109787788155162		[learning rate: 0.0001798]
	Learning Rate: 0.000179804
	LOSS [training: 0.02109787788155162 | validation: 0.013174176573519918]
	TIME [epoch: 9.03 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021340877405940588		[learning rate: 0.00017925]
	Learning Rate: 0.000179253
	LOSS [training: 0.021340877405940588 | validation: 0.021717312764805367]
	TIME [epoch: 9.06 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017360696998182833		[learning rate: 0.0001787]
	Learning Rate: 0.000178704
	LOSS [training: 0.017360696998182833 | validation: 0.00840720574882064]
	TIME [epoch: 9.04 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015665606125337937		[learning rate: 0.00017816]
	Learning Rate: 0.000178156
	LOSS [training: 0.015665606125337937 | validation: 0.014440299774082909]
	TIME [epoch: 9.04 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018576186162519992		[learning rate: 0.00017761]
	Learning Rate: 0.00017761
	LOSS [training: 0.018576186162519992 | validation: 0.010205235646733986]
	TIME [epoch: 9.03 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024544960926695537		[learning rate: 0.00017707]
	Learning Rate: 0.000177065
	LOSS [training: 0.024544960926695537 | validation: 0.011482001379244437]
	TIME [epoch: 9.05 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020957785845937126		[learning rate: 0.00017652]
	Learning Rate: 0.000176522
	LOSS [training: 0.020957785845937126 | validation: 0.011349209766623358]
	TIME [epoch: 9.04 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020540063113241636		[learning rate: 0.00017598]
	Learning Rate: 0.000175981
	LOSS [training: 0.020540063113241636 | validation: 0.007723713746575878]
	TIME [epoch: 9.03 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017728898556991952		[learning rate: 0.00017544]
	Learning Rate: 0.000175442
	LOSS [training: 0.017728898556991952 | validation: 0.003812968789444754]
	TIME [epoch: 9.04 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019469937387865295		[learning rate: 0.0001749]
	Learning Rate: 0.000174904
	LOSS [training: 0.019469937387865295 | validation: 0.013611709795779622]
	TIME [epoch: 9.05 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018514843773554474		[learning rate: 0.00017437]
	Learning Rate: 0.000174368
	LOSS [training: 0.018514843773554474 | validation: 0.016386657697173134]
	TIME [epoch: 9.05 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025188140343954758		[learning rate: 0.00017383]
	Learning Rate: 0.000173833
	LOSS [training: 0.025188140343954758 | validation: 0.005156229651783488]
	TIME [epoch: 9.03 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02186335631741345		[learning rate: 0.0001733]
	Learning Rate: 0.000173301
	LOSS [training: 0.02186335631741345 | validation: 0.013922020698212644]
	TIME [epoch: 9.03 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01828804222497219		[learning rate: 0.00017277]
	Learning Rate: 0.000172769
	LOSS [training: 0.01828804222497219 | validation: 0.010423907090498159]
	TIME [epoch: 9.04 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020802868102753166		[learning rate: 0.00017224]
	Learning Rate: 0.00017224
	LOSS [training: 0.020802868102753166 | validation: 0.009803338129732012]
	TIME [epoch: 9.05 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018654790847316506		[learning rate: 0.00017171]
	Learning Rate: 0.000171712
	LOSS [training: 0.018654790847316506 | validation: 0.0046903376612812955]
	TIME [epoch: 9.04 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01688209847699444		[learning rate: 0.00017119]
	Learning Rate: 0.000171185
	LOSS [training: 0.01688209847699444 | validation: 0.0052394215506475165]
	TIME [epoch: 9.04 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02119953365285495		[learning rate: 0.00017066]
	Learning Rate: 0.000170661
	LOSS [training: 0.02119953365285495 | validation: 0.015003682055447859]
	TIME [epoch: 9.04 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025828391096428222		[learning rate: 0.00017014]
	Learning Rate: 0.000170137
	LOSS [training: 0.025828391096428222 | validation: 0.015816495369900808]
	TIME [epoch: 9.06 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01907333001287959		[learning rate: 0.00016962]
	Learning Rate: 0.000169616
	LOSS [training: 0.01907333001287959 | validation: 0.005496454748934033]
	TIME [epoch: 9.04 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01896234068471086		[learning rate: 0.0001691]
	Learning Rate: 0.000169096
	LOSS [training: 0.01896234068471086 | validation: 0.008045420928331496]
	TIME [epoch: 9.04 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019302370247660856		[learning rate: 0.00016858]
	Learning Rate: 0.000168578
	LOSS [training: 0.019302370247660856 | validation: 0.008662556224055248]
	TIME [epoch: 9.03 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01697167784852478		[learning rate: 0.00016806]
	Learning Rate: 0.000168061
	LOSS [training: 0.01697167784852478 | validation: 0.00363667629717406]
	TIME [epoch: 9.06 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020917810793399882		[learning rate: 0.00016755]
	Learning Rate: 0.000167546
	LOSS [training: 0.020917810793399882 | validation: 0.007368812364043109]
	TIME [epoch: 9.04 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0200003715570016		[learning rate: 0.00016703]
	Learning Rate: 0.000167032
	LOSS [training: 0.0200003715570016 | validation: 0.0051882554596293096]
	TIME [epoch: 9.03 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01495495369647203		[learning rate: 0.00016652]
	Learning Rate: 0.00016652
	LOSS [training: 0.01495495369647203 | validation: 0.011116302251435973]
	TIME [epoch: 9.04 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015944823638654602		[learning rate: 0.00016601]
	Learning Rate: 0.00016601
	LOSS [training: 0.015944823638654602 | validation: 0.0059767483580061105]
	TIME [epoch: 9.05 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017265808328322592		[learning rate: 0.0001655]
	Learning Rate: 0.000165501
	LOSS [training: 0.017265808328322592 | validation: 0.008923381026529257]
	TIME [epoch: 9.04 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016458453311989328		[learning rate: 0.00016499]
	Learning Rate: 0.000164993
	LOSS [training: 0.016458453311989328 | validation: 0.00905439831976567]
	TIME [epoch: 9.03 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018685317600376214		[learning rate: 0.00016449]
	Learning Rate: 0.000164488
	LOSS [training: 0.018685317600376214 | validation: 0.005428948321856305]
	TIME [epoch: 9.04 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01900234375481436		[learning rate: 0.00016398]
	Learning Rate: 0.000163983
	LOSS [training: 0.01900234375481436 | validation: 0.01293799428323951]
	TIME [epoch: 9.05 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015023023706657018		[learning rate: 0.00016348]
	Learning Rate: 0.000163481
	LOSS [training: 0.015023023706657018 | validation: 0.006939400280341169]
	TIME [epoch: 9.04 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01972087370740689		[learning rate: 0.00016298]
	Learning Rate: 0.00016298
	LOSS [training: 0.01972087370740689 | validation: 0.01263297057318697]
	TIME [epoch: 9.04 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018010029345823613		[learning rate: 0.00016248]
	Learning Rate: 0.00016248
	LOSS [training: 0.018010029345823613 | validation: 0.013377763171351855]
	TIME [epoch: 9.13 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015527561420682994		[learning rate: 0.00016198]
	Learning Rate: 0.000161982
	LOSS [training: 0.015527561420682994 | validation: 0.00019473266530723224]
	TIME [epoch: 9.05 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02067885847995207		[learning rate: 0.00016149]
	Learning Rate: 0.000161485
	LOSS [training: 0.02067885847995207 | validation: 0.007561484452208499]
	TIME [epoch: 9.05 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01452418298487149		[learning rate: 0.00016099]
	Learning Rate: 0.00016099
	LOSS [training: 0.01452418298487149 | validation: 0.0012870228679682629]
	TIME [epoch: 9.04 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019157553137493778		[learning rate: 0.0001605]
	Learning Rate: 0.000160497
	LOSS [training: 0.019157553137493778 | validation: 0.00695315392514187]
	TIME [epoch: 9.04 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016212016042743284		[learning rate: 0.00016]
	Learning Rate: 0.000160005
	LOSS [training: 0.016212016042743284 | validation: 0.005723055369703285]
	TIME [epoch: 9.03 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0166027637828877		[learning rate: 0.00015951]
	Learning Rate: 0.000159514
	LOSS [training: 0.0166027637828877 | validation: 0.00672366891135477]
	TIME [epoch: 9.05 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01793274262538818		[learning rate: 0.00015903]
	Learning Rate: 0.000159025
	LOSS [training: 0.01793274262538818 | validation: 0.0102129851833064]
	TIME [epoch: 9.03 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01752094415137653		[learning rate: 0.00015854]
	Learning Rate: 0.000158538
	LOSS [training: 0.01752094415137653 | validation: 0.004579992452441149]
	TIME [epoch: 9.03 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020298913569770847		[learning rate: 0.00015805]
	Learning Rate: 0.000158052
	LOSS [training: 0.020298913569770847 | validation: 0.0023127906708640413]
	TIME [epoch: 9.04 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018361206129433774		[learning rate: 0.00015757]
	Learning Rate: 0.000157567
	LOSS [training: 0.018361206129433774 | validation: 0.008195733279383869]
	TIME [epoch: 9.06 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013406293682474767		[learning rate: 0.00015708]
	Learning Rate: 0.000157084
	LOSS [training: 0.013406293682474767 | validation: 0.007585615921456452]
	TIME [epoch: 9.03 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01769562204422834		[learning rate: 0.0001566]
	Learning Rate: 0.000156603
	LOSS [training: 0.01769562204422834 | validation: 0.01499195564282857]
	TIME [epoch: 9.03 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01720583399959184		[learning rate: 0.00015612]
	Learning Rate: 0.000156123
	LOSS [training: 0.01720583399959184 | validation: 0.005620331506676036]
	TIME [epoch: 9.04 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01694782369292592		[learning rate: 0.00015564]
	Learning Rate: 0.000155644
	LOSS [training: 0.01694782369292592 | validation: 0.0020180584348366347]
	TIME [epoch: 9.06 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016729882881710803		[learning rate: 0.00015517]
	Learning Rate: 0.000155167
	LOSS [training: 0.016729882881710803 | validation: 0.010889456475210531]
	TIME [epoch: 9.04 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018468533874830884		[learning rate: 0.00015469]
	Learning Rate: 0.000154692
	LOSS [training: 0.018468533874830884 | validation: 0.005422192119225412]
	TIME [epoch: 9.03 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02060991469108624		[learning rate: 0.00015422]
	Learning Rate: 0.000154217
	LOSS [training: 0.02060991469108624 | validation: 0.007219583334030463]
	TIME [epoch: 9.04 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016293070956205948		[learning rate: 0.00015374]
	Learning Rate: 0.000153745
	LOSS [training: 0.016293070956205948 | validation: 0.005848417340286853]
	TIME [epoch: 9.05 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018328633164417903		[learning rate: 0.00015327]
	Learning Rate: 0.000153273
	LOSS [training: 0.018328633164417903 | validation: 0.008662150203143378]
	TIME [epoch: 9.04 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025741204920811146		[learning rate: 0.0001528]
	Learning Rate: 0.000152803
	LOSS [training: 0.025741204920811146 | validation: 0.007103627085745943]
	TIME [epoch: 9.03 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014994558226415166		[learning rate: 0.00015234]
	Learning Rate: 0.000152335
	LOSS [training: 0.014994558226415166 | validation: -0.0011066570583268456]
	TIME [epoch: 9.03 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017323202680914133		[learning rate: 0.00015187]
	Learning Rate: 0.000151868
	LOSS [training: 0.017323202680914133 | validation: 0.008021794110090474]
	TIME [epoch: 9.04 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016002143006042295		[learning rate: 0.0001514]
	Learning Rate: 0.000151403
	LOSS [training: 0.016002143006042295 | validation: 0.005380002167755891]
	TIME [epoch: 9.04 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017850489163396495		[learning rate: 0.00015094]
	Learning Rate: 0.000150938
	LOSS [training: 0.017850489163396495 | validation: 0.004748460472045377]
	TIME [epoch: 9.03 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015531298982894778		[learning rate: 0.00015048]
	Learning Rate: 0.000150476
	LOSS [training: 0.015531298982894778 | validation: 0.003291803063662533]
	TIME [epoch: 9.03 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014727932446606995		[learning rate: 0.00015001]
	Learning Rate: 0.000150015
	LOSS [training: 0.014727932446606995 | validation: 0.009211519570123387]
	TIME [epoch: 9.04 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013064473653453307		[learning rate: 0.00014955]
	Learning Rate: 0.000149555
	LOSS [training: 0.013064473653453307 | validation: 0.00987723076935556]
	TIME [epoch: 9.04 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015231992768331851		[learning rate: 0.0001491]
	Learning Rate: 0.000149096
	LOSS [training: 0.015231992768331851 | validation: 0.00551023793238734]
	TIME [epoch: 9.11 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01599971592986952		[learning rate: 0.00014864]
	Learning Rate: 0.000148639
	LOSS [training: 0.01599971592986952 | validation: 0.01790589878142599]
	TIME [epoch: 9.03 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014597166088323815		[learning rate: 0.00014818]
	Learning Rate: 0.000148184
	LOSS [training: 0.014597166088323815 | validation: 0.013485882502412786]
	TIME [epoch: 9.03 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01479142686773843		[learning rate: 0.00014773]
	Learning Rate: 0.000147729
	LOSS [training: 0.01479142686773843 | validation: 0.005659246296410512]
	TIME [epoch: 9.06 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011856066447526048		[learning rate: 0.00014728]
	Learning Rate: 0.000147276
	LOSS [training: 0.011856066447526048 | validation: 0.008292047832389897]
	TIME [epoch: 9.03 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013715161958134261		[learning rate: 0.00014682]
	Learning Rate: 0.000146825
	LOSS [training: 0.013715161958134261 | validation: 0.004821588688980957]
	TIME [epoch: 9.03 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01670832857908374		[learning rate: 0.00014637]
	Learning Rate: 0.000146375
	LOSS [training: 0.01670832857908374 | validation: 0.013327638831612157]
	TIME [epoch: 9.03 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016146403337373556		[learning rate: 0.00014593]
	Learning Rate: 0.000145926
	LOSS [training: 0.016146403337373556 | validation: 0.0001979132647374239]
	TIME [epoch: 9.06 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014847258863588283		[learning rate: 0.00014548]
	Learning Rate: 0.000145479
	LOSS [training: 0.014847258863588283 | validation: 0.013969862479037417]
	TIME [epoch: 9.08 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016333756343818617		[learning rate: 0.00014503]
	Learning Rate: 0.000145033
	LOSS [training: 0.016333756343818617 | validation: -0.001559551113129205]
	TIME [epoch: 9.03 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012335718276277283		[learning rate: 0.00014459]
	Learning Rate: 0.000144588
	LOSS [training: 0.012335718276277283 | validation: 0.012470509932671322]
	TIME [epoch: 9.03 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018481280011844323		[learning rate: 0.00014415]
	Learning Rate: 0.000144145
	LOSS [training: 0.018481280011844323 | validation: 0.004286156661842085]
	TIME [epoch: 9.05 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014857064845605283		[learning rate: 0.0001437]
	Learning Rate: 0.000143703
	LOSS [training: 0.014857064845605283 | validation: 0.0027194103785664336]
	TIME [epoch: 9.04 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01678048809896629		[learning rate: 0.00014326]
	Learning Rate: 0.000143263
	LOSS [training: 0.01678048809896629 | validation: 0.009242329808527053]
	TIME [epoch: 9.04 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017374275326013912		[learning rate: 0.00014282]
	Learning Rate: 0.000142824
	LOSS [training: 0.017374275326013912 | validation: 0.01052588955616747]
	TIME [epoch: 9.03 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01634315281237904		[learning rate: 0.00014239]
	Learning Rate: 0.000142386
	LOSS [training: 0.01634315281237904 | validation: 0.014333651371216059]
	TIME [epoch: 9.05 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017675800283634382		[learning rate: 0.00014195]
	Learning Rate: 0.000141949
	LOSS [training: 0.017675800283634382 | validation: 0.006440957670771666]
	TIME [epoch: 9.04 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01466759378391543		[learning rate: 0.00014151]
	Learning Rate: 0.000141514
	LOSS [training: 0.01466759378391543 | validation: 0.00980769719300779]
	TIME [epoch: 9.04 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013766242468189532		[learning rate: 0.00014108]
	Learning Rate: 0.00014108
	LOSS [training: 0.013766242468189532 | validation: 0.005718102781958284]
	TIME [epoch: 9.03 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015932162518185022		[learning rate: 0.00014065]
	Learning Rate: 0.000140648
	LOSS [training: 0.015932162518185022 | validation: 0.0061960082909328345]
	TIME [epoch: 9.04 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02012055224767053		[learning rate: 0.00014022]
	Learning Rate: 0.000140217
	LOSS [training: 0.02012055224767053 | validation: 0.0007350326580181899]
	TIME [epoch: 9.05 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01848250993449036		[learning rate: 0.00013979]
	Learning Rate: 0.000139787
	LOSS [training: 0.01848250993449036 | validation: 0.007133017636444801]
	TIME [epoch: 9.03 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014764314677767527		[learning rate: 0.00013936]
	Learning Rate: 0.000139358
	LOSS [training: 0.014764314677767527 | validation: 0.009458921787269323]
	TIME [epoch: 9.04 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019576723928888446		[learning rate: 0.00013893]
	Learning Rate: 0.000138931
	LOSS [training: 0.019576723928888446 | validation: 0.001377777398717665]
	TIME [epoch: 9.03 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014427183577415409		[learning rate: 0.00013851]
	Learning Rate: 0.000138505
	LOSS [training: 0.014427183577415409 | validation: 0.008447612000625233]
	TIME [epoch: 9.05 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017881927267753794		[learning rate: 0.00013808]
	Learning Rate: 0.000138081
	LOSS [training: 0.017881927267753794 | validation: 0.005968507779701579]
	TIME [epoch: 9.03 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01616860979504086		[learning rate: 0.00013766]
	Learning Rate: 0.000137658
	LOSS [training: 0.01616860979504086 | validation: -0.00039054096468853824]
	TIME [epoch: 9.03 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016431445370467014		[learning rate: 0.00013724]
	Learning Rate: 0.000137236
	LOSS [training: 0.016431445370467014 | validation: 0.008405223922079102]
	TIME [epoch: 9.04 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0174275770578423		[learning rate: 0.00013681]
	Learning Rate: 0.000136815
	LOSS [training: 0.0174275770578423 | validation: 0.014832612448288143]
	TIME [epoch: 9.06 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022199840796311484		[learning rate: 0.0001364]
	Learning Rate: 0.000136395
	LOSS [training: 0.022199840796311484 | validation: 0.013750763627673093]
	TIME [epoch: 9.04 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014010652145419475		[learning rate: 0.00013598]
	Learning Rate: 0.000135977
	LOSS [training: 0.014010652145419475 | validation: 0.011171468511093957]
	TIME [epoch: 9.03 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016861623339346703		[learning rate: 0.00013556]
	Learning Rate: 0.000135561
	LOSS [training: 0.016861623339346703 | validation: -0.0005794637617253457]
	TIME [epoch: 9.03 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012791203788010807		[learning rate: 0.00013515]
	Learning Rate: 0.000135145
	LOSS [training: 0.012791203788010807 | validation: 0.011040244368720562]
	TIME [epoch: 9.06 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019494557411659515		[learning rate: 0.00013473]
	Learning Rate: 0.000134731
	LOSS [training: 0.019494557411659515 | validation: 0.007916238116729785]
	TIME [epoch: 9.05 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020229218437356082		[learning rate: 0.00013432]
	Learning Rate: 0.000134318
	LOSS [training: 0.020229218437356082 | validation: 0.011606307064487622]
	TIME [epoch: 9.04 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019932732632267226		[learning rate: 0.00013391]
	Learning Rate: 0.000133906
	LOSS [training: 0.019932732632267226 | validation: 0.011869933915574362]
	TIME [epoch: 9.04 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021327582931802664		[learning rate: 0.0001335]
	Learning Rate: 0.000133496
	LOSS [training: 0.021327582931802664 | validation: 0.014016895887355323]
	TIME [epoch: 9.07 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023576129889256094		[learning rate: 0.00013309]
	Learning Rate: 0.000133086
	LOSS [training: 0.023576129889256094 | validation: 0.01907771110746656]
	TIME [epoch: 9.13 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022472171161863275		[learning rate: 0.00013268]
	Learning Rate: 0.000132678
	LOSS [training: 0.022472171161863275 | validation: 0.009551362386925385]
	TIME [epoch: 9.04 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01885896472811924		[learning rate: 0.00013227]
	Learning Rate: 0.000132272
	LOSS [training: 0.01885896472811924 | validation: 0.013662137668489532]
	TIME [epoch: 9.04 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019121118002418565		[learning rate: 0.00013187]
	Learning Rate: 0.000131866
	LOSS [training: 0.019121118002418565 | validation: 0.010511601927567673]
	TIME [epoch: 9.05 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017352144084897853		[learning rate: 0.00013146]
	Learning Rate: 0.000131462
	LOSS [training: 0.017352144084897853 | validation: 0.013238522825071122]
	TIME [epoch: 9.05 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01843470662950354		[learning rate: 0.00013106]
	Learning Rate: 0.000131059
	LOSS [training: 0.01843470662950354 | validation: 0.00943653768721862]
	TIME [epoch: 9.04 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020927794734364652		[learning rate: 0.00013066]
	Learning Rate: 0.000130657
	LOSS [training: 0.020927794734364652 | validation: 0.01844998806386951]
	TIME [epoch: 9.04 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021644032380247435		[learning rate: 0.00013026]
	Learning Rate: 0.000130257
	LOSS [training: 0.021644032380247435 | validation: 0.014936927761290382]
	TIME [epoch: 9.05 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02443212767888136		[learning rate: 0.00012986]
	Learning Rate: 0.000129857
	LOSS [training: 0.02443212767888136 | validation: 0.015365250684096936]
	TIME [epoch: 9.05 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022664616270713114		[learning rate: 0.00012946]
	Learning Rate: 0.000129459
	LOSS [training: 0.022664616270713114 | validation: 0.020701089142424915]
	TIME [epoch: 9.04 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023756120010918917		[learning rate: 0.00012906]
	Learning Rate: 0.000129062
	LOSS [training: 0.023756120010918917 | validation: 0.01845499025465285]
	TIME [epoch: 9.04 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021706761055344137		[learning rate: 0.00012867]
	Learning Rate: 0.000128667
	LOSS [training: 0.021706761055344137 | validation: 0.007545411380431187]
	TIME [epoch: 9.05 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01882215647580754		[learning rate: 0.00012827]
	Learning Rate: 0.000128272
	LOSS [training: 0.01882215647580754 | validation: 0.012672191926208075]
	TIME [epoch: 9.06 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020762373932231522		[learning rate: 0.00012788]
	Learning Rate: 0.000127879
	LOSS [training: 0.020762373932231522 | validation: 0.010171983154546614]
	TIME [epoch: 9.04 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01805165228769442		[learning rate: 0.00012749]
	Learning Rate: 0.000127487
	LOSS [training: 0.01805165228769442 | validation: 0.008261838355641024]
	TIME [epoch: 9.05 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01627690393463038		[learning rate: 0.0001271]
	Learning Rate: 0.000127096
	LOSS [training: 0.01627690393463038 | validation: 0.008031527612895184]
	TIME [epoch: 9.05 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01967451272377128		[learning rate: 0.00012671]
	Learning Rate: 0.000126707
	LOSS [training: 0.01967451272377128 | validation: 0.019443931606892142]
	TIME [epoch: 9.07 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015434083078408068		[learning rate: 0.00012632]
	Learning Rate: 0.000126318
	LOSS [training: 0.015434083078408068 | validation: 0.007529061903210712]
	TIME [epoch: 9.05 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013953694110924387		[learning rate: 0.00012593]
	Learning Rate: 0.000125931
	LOSS [training: 0.013953694110924387 | validation: 0.014819787371498173]
	TIME [epoch: 9.05 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020498915598459424		[learning rate: 0.00012555]
	Learning Rate: 0.000125545
	LOSS [training: 0.020498915598459424 | validation: 0.016452164618822474]
	TIME [epoch: 9.04 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0193277485440873		[learning rate: 0.00012516]
	Learning Rate: 0.00012516
	LOSS [training: 0.0193277485440873 | validation: 0.010113877121085975]
	TIME [epoch: 9.07 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023459780582343274		[learning rate: 0.00012478]
	Learning Rate: 0.000124777
	LOSS [training: 0.023459780582343274 | validation: 0.01062154559213992]
	TIME [epoch: 9.04 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020672818738104757		[learning rate: 0.00012439]
	Learning Rate: 0.000124394
	LOSS [training: 0.020672818738104757 | validation: 0.005506498189074279]
	TIME [epoch: 9.05 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017844150996858783		[learning rate: 0.00012401]
	Learning Rate: 0.000124013
	LOSS [training: 0.017844150996858783 | validation: -0.004033916697713966]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1930.pth
	Model improved!!!
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01502597352273983		[learning rate: 0.00012363]
	Learning Rate: 0.000123633
	LOSS [training: 0.01502597352273983 | validation: 0.0026807832378452166]
	TIME [epoch: 9.06 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011775939613325714		[learning rate: 0.00012325]
	Learning Rate: 0.000123254
	LOSS [training: 0.011775939613325714 | validation: 0.0046818971894769515]
	TIME [epoch: 9.04 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00967466310294926		[learning rate: 0.00012288]
	Learning Rate: 0.000122876
	LOSS [training: 0.00967466310294926 | validation: 0.004390381317813684]
	TIME [epoch: 9.04 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014376215226607359		[learning rate: 0.0001225]
	Learning Rate: 0.000122499
	LOSS [training: 0.014376215226607359 | validation: 0.004901568423902662]
	TIME [epoch: 9.04 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015628834542755248		[learning rate: 0.00012212]
	Learning Rate: 0.000122124
	LOSS [training: 0.015628834542755248 | validation: 0.005439672692023955]
	TIME [epoch: 9.04 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016439865080114753		[learning rate: 0.00012175]
	Learning Rate: 0.000121749
	LOSS [training: 0.016439865080114753 | validation: 0.01031167928982858]
	TIME [epoch: 9.06 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01328919550232043		[learning rate: 0.00012138]
	Learning Rate: 0.000121376
	LOSS [training: 0.01328919550232043 | validation: 0.01015516522741913]
	TIME [epoch: 9.03 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01639441726422737		[learning rate: 0.000121]
	Learning Rate: 0.000121004
	LOSS [training: 0.01639441726422737 | validation: 0.002880438149811638]
	TIME [epoch: 9.04 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017386817560099875		[learning rate: 0.00012063]
	Learning Rate: 0.000120633
	LOSS [training: 0.017386817560099875 | validation: 0.006212505237156576]
	TIME [epoch: 9.04 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016457461074915046		[learning rate: 0.00012026]
	Learning Rate: 0.000120263
	LOSS [training: 0.016457461074915046 | validation: -0.004390874912492031]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_032358/states/model_tr_study4_1940.pth
	Model improved!!!
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0161867298132803		[learning rate: 0.00011989]
	Learning Rate: 0.000119895
	LOSS [training: 0.0161867298132803 | validation: 0.0076869070454188325]
	TIME [epoch: 9.04 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014813957653904896		[learning rate: 0.00011953]
	Learning Rate: 0.000119527
	LOSS [training: 0.014813957653904896 | validation: 0.01667568316117941]
	TIME [epoch: 9.04 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01733595613148362		[learning rate: 0.00011916]
	Learning Rate: 0.000119161
	LOSS [training: 0.01733595613148362 | validation: -0.0016859235982603098]
	TIME [epoch: 9.04 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014041415012665679		[learning rate: 0.0001188]
	Learning Rate: 0.000118795
	LOSS [training: 0.014041415012665679 | validation: 0.01724308465287541]
	TIME [epoch: 9.05 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01643045665721442		[learning rate: 0.00011843]
	Learning Rate: 0.000118431
	LOSS [training: 0.01643045665721442 | validation: 0.004544792607887154]
	TIME [epoch: 9.05 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017340188022729523		[learning rate: 0.00011807]
	Learning Rate: 0.000118068
	LOSS [training: 0.017340188022729523 | validation: 0.002880398962267618]
	TIME [epoch: 9.04 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01439859568939465		[learning rate: 0.00011771]
	Learning Rate: 0.000117706
	LOSS [training: 0.01439859568939465 | validation: 0.0029409890715933187]
	TIME [epoch: 9.04 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01657964023051468		[learning rate: 0.00011735]
	Learning Rate: 0.000117346
	LOSS [training: 0.01657964023051468 | validation: 0.008141647742015647]
	TIME [epoch: 9.04 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016059495359932993		[learning rate: 0.00011699]
	Learning Rate: 0.000116986
	LOSS [training: 0.016059495359932993 | validation: 0.004779560231819447]
	TIME [epoch: 9.06 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01727314192358237		[learning rate: 0.00011663]
	Learning Rate: 0.000116627
	LOSS [training: 0.01727314192358237 | validation: 0.006653443069724657]
	TIME [epoch: 9.05 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013531373012684218		[learning rate: 0.00011627]
	Learning Rate: 0.00011627
	LOSS [training: 0.013531373012684218 | validation: 0.006182231323816515]
	TIME [epoch: 9.04 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020608247939740656		[learning rate: 0.00011591]
	Learning Rate: 0.000115913
	LOSS [training: 0.020608247939740656 | validation: 0.009637851366655383]
	TIME [epoch: 9.05 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018949029395118545		[learning rate: 0.00011556]
	Learning Rate: 0.000115558
	LOSS [training: 0.018949029395118545 | validation: 0.006147253944934606]
	TIME [epoch: 9.06 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01569609988920341		[learning rate: 0.0001152]
	Learning Rate: 0.000115204
	LOSS [training: 0.01569609988920341 | validation: 0.003935609858744543]
	TIME [epoch: 9.05 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01233371060607921		[learning rate: 0.00011485]
	Learning Rate: 0.000114851
	LOSS [training: 0.01233371060607921 | validation: 0.0035700729549320775]
	TIME [epoch: 9.04 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01463093884385958		[learning rate: 0.0001145]
	Learning Rate: 0.000114499
	LOSS [training: 0.01463093884385958 | validation: 0.0076156766990799745]
	TIME [epoch: 9.04 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016381605957280575		[learning rate: 0.00011415]
	Learning Rate: 0.000114148
	LOSS [training: 0.016381605957280575 | validation: 0.0058128974904484735]
	TIME [epoch: 9.06 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014318067527648881		[learning rate: 0.0001138]
	Learning Rate: 0.000113798
	LOSS [training: 0.014318067527648881 | validation: 0.0022413937091358763]
	TIME [epoch: 9.06 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016177387954830605		[learning rate: 0.00011345]
	Learning Rate: 0.000113449
	LOSS [training: 0.016177387954830605 | validation: 0.0020808420669997532]
	TIME [epoch: 9.04 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01655369634500459		[learning rate: 0.0001131]
	Learning Rate: 0.000113101
	LOSS [training: 0.01655369634500459 | validation: 0.0054154207699918236]
	TIME [epoch: 9.05 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013865701437460099		[learning rate: 0.00011275]
	Learning Rate: 0.000112754
	LOSS [training: 0.013865701437460099 | validation: 0.012682532397345375]
	TIME [epoch: 9.05 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01453691018347492		[learning rate: 0.00011241]
	Learning Rate: 0.000112409
	LOSS [training: 0.01453691018347492 | validation: 0.0019876830013946852]
	TIME [epoch: 9.06 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015426731923506489		[learning rate: 0.00011206]
	Learning Rate: 0.000112064
	LOSS [training: 0.015426731923506489 | validation: 0.0035697125221111872]
	TIME [epoch: 9.04 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01808009028458455		[learning rate: 0.00011172]
	Learning Rate: 0.000111721
	LOSS [training: 0.01808009028458455 | validation: 0.010471644565109647]
	TIME [epoch: 9.05 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01576712207091953		[learning rate: 0.00011138]
	Learning Rate: 0.000111378
	LOSS [training: 0.01576712207091953 | validation: 0.007379356855142073]
	TIME [epoch: 9.05 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015804047770380473		[learning rate: 0.00011104]
	Learning Rate: 0.000111037
	LOSS [training: 0.015804047770380473 | validation: 0.006098588764292175]
	TIME [epoch: 9.06 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017200648598538384		[learning rate: 0.0001107]
	Learning Rate: 0.000110696
	LOSS [training: 0.017200648598538384 | validation: 0.008133101016350813]
	TIME [epoch: 9.05 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01678815884908882		[learning rate: 0.00011036]
	Learning Rate: 0.000110357
	LOSS [training: 0.01678815884908882 | validation: 0.0036586425699725537]
	TIME [epoch: 9.04 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014740407633954636		[learning rate: 0.00011002]
	Learning Rate: 0.000110019
	LOSS [training: 0.014740407633954636 | validation: 0.011421267683410122]
	TIME [epoch: 9.04 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014428539137385194		[learning rate: 0.00010968]
	Learning Rate: 0.000109681
	LOSS [training: 0.014428539137385194 | validation: 0.0012038300030896049]
	TIME [epoch: 9.07 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011200503036453816		[learning rate: 0.00010935]
	Learning Rate: 0.000109345
	LOSS [training: 0.011200503036453816 | validation: 0.004636945308824464]
	TIME [epoch: 9.04 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014550010616690381		[learning rate: 0.00010901]
	Learning Rate: 0.00010901
	LOSS [training: 0.014550010616690381 | validation: 0.011376175663519037]
	TIME [epoch: 9.04 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017056420932516567		[learning rate: 0.00010868]
	Learning Rate: 0.000108676
	LOSS [training: 0.017056420932516567 | validation: 0.004537807990018774]
	TIME [epoch: 9.04 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019375637745080235		[learning rate: 0.00010834]
	Learning Rate: 0.000108343
	LOSS [training: 0.019375637745080235 | validation: 0.007224425335895448]
	TIME [epoch: 9.06 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015629891879035285		[learning rate: 0.00010801]
	Learning Rate: 0.000108011
	LOSS [training: 0.015629891879035285 | validation: 0.01051004732221024]
	TIME [epoch: 9.05 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012824206631385041		[learning rate: 0.00010768]
	Learning Rate: 0.00010768
	LOSS [training: 0.012824206631385041 | validation: 0.008138988859108692]
	TIME [epoch: 9.05 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01623539184011577		[learning rate: 0.00010735]
	Learning Rate: 0.000107349
	LOSS [training: 0.01623539184011577 | validation: 0.005334160146730998]
	TIME [epoch: 9.04 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009624180462360117		[learning rate: 0.00010702]
	Learning Rate: 0.00010702
	LOSS [training: 0.009624180462360117 | validation: 0.002718545006916954]
	TIME [epoch: 9.06 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011649833899071668		[learning rate: 0.00010669]
	Learning Rate: 0.000106692
	LOSS [training: 0.011649833899071668 | validation: 0.0010891300371315316]
	TIME [epoch: 9.04 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015154280655144386		[learning rate: 0.00010637]
	Learning Rate: 0.000106365
	LOSS [training: 0.015154280655144386 | validation: 0.006374777460535002]
	TIME [epoch: 9.04 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013160643582440248		[learning rate: 0.00010604]
	Learning Rate: 0.000106039
	LOSS [training: 0.013160643582440248 | validation: 0.003351240926397752]
	TIME [epoch: 9.04 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014302322932709676		[learning rate: 0.00010571]
	Learning Rate: 0.000105714
	LOSS [training: 0.014302322932709676 | validation: 0.004424031471157532]
	TIME [epoch: 9.05 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014372714842192635		[learning rate: 0.00010539]
	Learning Rate: 0.00010539
	LOSS [training: 0.014372714842192635 | validation: 0.004365254855762187]
	TIME [epoch: 9.06 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013939565073858124		[learning rate: 0.00010507]
	Learning Rate: 0.000105067
	LOSS [training: 0.013939565073858124 | validation: 0.0058752926151586955]
	TIME [epoch: 9.04 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016507999819385145		[learning rate: 0.00010474]
	Learning Rate: 0.000104745
	LOSS [training: 0.016507999819385145 | validation: 0.006917228989066977]
	TIME [epoch: 9.04 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015524442654906736		[learning rate: 0.00010442]
	Learning Rate: 0.000104424
	LOSS [training: 0.015524442654906736 | validation: -0.0014796563869005964]
	TIME [epoch: 9.05 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01307577558120963		[learning rate: 0.0001041]
	Learning Rate: 0.000104104
	LOSS [training: 0.01307577558120963 | validation: 0.0012456375421259218]
	TIME [epoch: 9.05 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0164139488619816		[learning rate: 0.00010378]
	Learning Rate: 0.000103785
	LOSS [training: 0.0164139488619816 | validation: 0.009436836612447997]
	TIME [epoch: 9.04 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015497373933616596		[learning rate: 0.00010347]
	Learning Rate: 0.000103467
	LOSS [training: 0.015497373933616596 | validation: 0.009465230882885964]
	TIME [epoch: 9.05 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015165991314208885		[learning rate: 0.00010315]
	Learning Rate: 0.000103149
	LOSS [training: 0.015165991314208885 | validation: 0.021297185939321915]
	TIME [epoch: 9.04 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013564329351765774		[learning rate: 0.00010283]
	Learning Rate: 0.000102833
	LOSS [training: 0.013564329351765774 | validation: 0.013502489316501026]
	TIME [epoch: 9.07 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01619734155994979		[learning rate: 0.00010252]
	Learning Rate: 0.000102518
	LOSS [training: 0.01619734155994979 | validation: 0.009963879222152179]
	TIME [epoch: 9.04 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015825643662342088		[learning rate: 0.0001022]
	Learning Rate: 0.000102204
	LOSS [training: 0.015825643662342088 | validation: 0.0033224368287006396]
	TIME [epoch: 9.04 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014144819450377396		[learning rate: 0.00010189]
	Learning Rate: 0.00010189
	LOSS [training: 0.014144819450377396 | validation: -0.0013297215191279904]
	TIME [epoch: 9.04 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015486591198414617		[learning rate: 0.00010158]
	Learning Rate: 0.000101578
	LOSS [training: 0.015486591198414617 | validation: 0.0031547870725653292]
	TIME [epoch: 9.06 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014882946262599867		[learning rate: 0.00010127]
	Learning Rate: 0.000101267
	LOSS [training: 0.014882946262599867 | validation: 0.0077173512878439005]
	TIME [epoch: 9.04 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021088650603187827		[learning rate: 0.00010096]
	Learning Rate: 0.000100956
	LOSS [training: 0.021088650603187827 | validation: 0.01809664721826952]
	TIME [epoch: 9.04 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018674960430812692		[learning rate: 0.00010065]
	Learning Rate: 0.000100647
	LOSS [training: 0.018674960430812692 | validation: 0.01348358219486271]
	TIME [epoch: 9.04 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015175503823770406		[learning rate: 0.00010034]
	Learning Rate: 0.000100338
	LOSS [training: 0.015175503823770406 | validation: 0.007074602476132426]
	TIME [epoch: 9.06 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01727182344146354		[learning rate: 0.00010003]
	Learning Rate: 0.000100031
	LOSS [training: 0.01727182344146354 | validation: 0.011576859443798052]
	TIME [epoch: 9.04 sec]
Finished training in 18436.875 seconds.
