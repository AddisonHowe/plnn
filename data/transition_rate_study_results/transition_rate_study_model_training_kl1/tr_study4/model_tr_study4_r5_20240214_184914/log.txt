Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r5', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3456653020

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/10] avg loss: 10.226018140715093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.226018140715093 | validation: 10.29887551515105]
	TIME [epoch: 48.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/10] avg loss: 9.333462914608775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.333462914608775 | validation: 9.376433860792025]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/10] avg loss: 8.644996151709114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.644996151709114 | validation: 8.940227924628395]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 10/10] avg loss: 8.092296094214454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.092296094214454 | validation: 8.460714089756884]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/10] avg loss: 7.879978790639609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.879978790639609 | validation: 9.115325231760298]
	TIME [epoch: 9.07 sec]
EPOCH 6/500:
	Training over batches...
		[batch 10/10] avg loss: 7.886943502451333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.886943502451333 | validation: 8.055555896686965]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/10] avg loss: 7.056648722515169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.056648722515169 | validation: 7.227011103889109]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 10/10] avg loss: 5.586775700264264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.586775700264264 | validation: 6.539532977751971]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 10/10] avg loss: 5.111823237228802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.111823237228802 | validation: 5.5238334083277465]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 10/10] avg loss: 4.993023042236084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.993023042236084 | validation: 5.442200370096833]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 10/10] avg loss: 4.763984135839051		[learning rate: 0.0099578]
	Learning Rate: 0.0099578
	LOSS [training: 4.763984135839051 | validation: 5.281409608913446]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 10/10] avg loss: 4.578811771735659		[learning rate: 0.0099111]
	Learning Rate: 0.00991111
	LOSS [training: 4.578811771735659 | validation: 5.021470521232457]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 10/10] avg loss: 3.7931981654226092		[learning rate: 0.0098646]
	Learning Rate: 0.00986465
	LOSS [training: 3.7931981654226092 | validation: 4.19222873818736]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 10/10] avg loss: 3.2931546990623466		[learning rate: 0.0098184]
	Learning Rate: 0.0098184
	LOSS [training: 3.2931546990623466 | validation: 3.823659635366133]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 10/10] avg loss: 3.8467706721521884		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 3.8467706721521884 | validation: 4.0219065721177305]
	TIME [epoch: 9.11 sec]
EPOCH 16/500:
	Training over batches...
		[batch 10/10] avg loss: 3.0118637937470694		[learning rate: 0.0097266]
	Learning Rate: 0.00972656
	LOSS [training: 3.0118637937470694 | validation: 3.31605339576293]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 10/10] avg loss: 3.821801685670181		[learning rate: 0.009681]
	Learning Rate: 0.00968096
	LOSS [training: 3.821801685670181 | validation: 3.200194513590925]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 10/10] avg loss: 2.823076596346687		[learning rate: 0.0096356]
	Learning Rate: 0.00963557
	LOSS [training: 2.823076596346687 | validation: 2.448543635512113]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 10/10] avg loss: 2.564976747418346		[learning rate: 0.0095904]
	Learning Rate: 0.0095904
	LOSS [training: 2.564976747418346 | validation: 2.688083014477492]
	TIME [epoch: 9.1 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/10] avg loss: 2.217645924740382		[learning rate: 0.0095454]
	Learning Rate: 0.00954544
	LOSS [training: 2.217645924740382 | validation: 6.820478853218443]
	TIME [epoch: 9.07 sec]
EPOCH 21/500:
	Training over batches...
		[batch 10/10] avg loss: 3.0771434111182416		[learning rate: 0.0095007]
	Learning Rate: 0.00950069
	LOSS [training: 3.0771434111182416 | validation: 1.9874168406705035]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 10/10] avg loss: 2.24867726440433		[learning rate: 0.0094561]
	Learning Rate: 0.00945615
	LOSS [training: 2.24867726440433 | validation: 1.9561525311256998]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0994479760167484		[learning rate: 0.0094118]
	Learning Rate: 0.00941182
	LOSS [training: 2.0994479760167484 | validation: 1.693206516452801]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0089922070638275		[learning rate: 0.0093677]
	Learning Rate: 0.00936769
	LOSS [training: 2.0089922070638275 | validation: 1.531133505586583]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 10/10] avg loss: 1.896810498940009		[learning rate: 0.0093238]
	Learning Rate: 0.00932378
	LOSS [training: 1.896810498940009 | validation: 2.648195098883936]
	TIME [epoch: 9.07 sec]
EPOCH 26/500:
	Training over batches...
		[batch 10/10] avg loss: 1.766902203527004		[learning rate: 0.0092801]
	Learning Rate: 0.00928007
	LOSS [training: 1.766902203527004 | validation: 1.7447731235720931]
	TIME [epoch: 9.07 sec]
EPOCH 27/500:
	Training over batches...
		[batch 10/10] avg loss: 2.3404454817538234		[learning rate: 0.0092366]
	Learning Rate: 0.00923656
	LOSS [training: 2.3404454817538234 | validation: 1.9733074091708982]
	TIME [epoch: 9.09 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/10] avg loss: 1.729278770657998		[learning rate: 0.0091933]
	Learning Rate: 0.00919326
	LOSS [training: 1.729278770657998 | validation: 1.4314237283285536]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4134735028295713		[learning rate: 0.0091502]
	Learning Rate: 0.00915016
	LOSS [training: 1.4134735028295713 | validation: 1.1488974763359858]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5254045310173914		[learning rate: 0.0091073]
	Learning Rate: 0.00910726
	LOSS [training: 1.5254045310173914 | validation: 1.6387997491069624]
	TIME [epoch: 9.07 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2944173327721242		[learning rate: 0.0090646]
	Learning Rate: 0.00906456
	LOSS [training: 1.2944173327721242 | validation: 0.9895995579503858]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 10/10] avg loss: 1.685649946039056		[learning rate: 0.0090221]
	Learning Rate: 0.00902207
	LOSS [training: 1.685649946039056 | validation: 1.1656610696462089]
	TIME [epoch: 9.08 sec]
EPOCH 33/500:
	Training over batches...
		[batch 10/10] avg loss: 1.225950179703411		[learning rate: 0.0089798]
	Learning Rate: 0.00897977
	LOSS [training: 1.225950179703411 | validation: 1.2190136385143155]
	TIME [epoch: 9.08 sec]
EPOCH 34/500:
	Training over batches...
		[batch 10/10] avg loss: 1.062971892100437		[learning rate: 0.0089377]
	Learning Rate: 0.00893767
	LOSS [training: 1.062971892100437 | validation: 1.6906770051646962]
	TIME [epoch: 9.07 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1512539860465123		[learning rate: 0.0088958]
	Learning Rate: 0.00889577
	LOSS [training: 1.1512539860465123 | validation: 0.8831507570409779]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1912260766081564		[learning rate: 0.0088541]
	Learning Rate: 0.00885407
	LOSS [training: 1.1912260766081564 | validation: 1.0187923355357127]
	TIME [epoch: 9.09 sec]
EPOCH 37/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0852324001818618		[learning rate: 0.0088126]
	Learning Rate: 0.00881256
	LOSS [training: 1.0852324001818618 | validation: 0.7146762331491348]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0762517966790488		[learning rate: 0.0087712]
	Learning Rate: 0.00877124
	LOSS [training: 1.0762517966790488 | validation: 0.7515553471907042]
	TIME [epoch: 9.08 sec]
EPOCH 39/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4711374858008002		[learning rate: 0.0087301]
	Learning Rate: 0.00873012
	LOSS [training: 1.4711374858008002 | validation: 0.9484038584068769]
	TIME [epoch: 9.08 sec]
EPOCH 40/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9186829623814246		[learning rate: 0.0086892]
	Learning Rate: 0.00868919
	LOSS [training: 0.9186829623814246 | validation: 1.4136715774526185]
	TIME [epoch: 9.1 sec]
EPOCH 41/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9360085616000303		[learning rate: 0.0086485]
	Learning Rate: 0.00864846
	LOSS [training: 0.9360085616000303 | validation: 0.631721332401302]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_41.pth
	Model improved!!!
EPOCH 42/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9572496829447298		[learning rate: 0.0086079]
	Learning Rate: 0.00860791
	LOSS [training: 0.9572496829447298 | validation: 1.5204591573985402]
	TIME [epoch: 9.07 sec]
EPOCH 43/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8357334712565472		[learning rate: 0.0085676]
	Learning Rate: 0.00856756
	LOSS [training: 0.8357334712565472 | validation: 1.029535125825888]
	TIME [epoch: 9.06 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9379249804670231		[learning rate: 0.0085274]
	Learning Rate: 0.00852739
	LOSS [training: 0.9379249804670231 | validation: 0.94514497052046]
	TIME [epoch: 9.1 sec]
EPOCH 45/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0588332963582716		[learning rate: 0.0084874]
	Learning Rate: 0.00848742
	LOSS [training: 1.0588332963582716 | validation: 1.2931803209567732]
	TIME [epoch: 9.06 sec]
EPOCH 46/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9987464128420627		[learning rate: 0.0084476]
	Learning Rate: 0.00844763
	LOSS [training: 0.9987464128420627 | validation: 0.6869012860358268]
	TIME [epoch: 9.07 sec]
EPOCH 47/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7384582627218219		[learning rate: 0.008408]
	Learning Rate: 0.00840802
	LOSS [training: 0.7384582627218219 | validation: 0.856811173679334]
	TIME [epoch: 9.06 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8260153409539288		[learning rate: 0.0083686]
	Learning Rate: 0.0083686
	LOSS [training: 0.8260153409539288 | validation: 0.8227082465101003]
	TIME [epoch: 9.08 sec]
EPOCH 49/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8005360675189745		[learning rate: 0.0083294]
	Learning Rate: 0.00832937
	LOSS [training: 0.8005360675189745 | validation: 0.5849161157012237]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 10/10] avg loss: 0.952434985316947		[learning rate: 0.0082903]
	Learning Rate: 0.00829032
	LOSS [training: 0.952434985316947 | validation: 0.7041432676011141]
	TIME [epoch: 9.07 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7804164492963652		[learning rate: 0.0082515]
	Learning Rate: 0.00825146
	LOSS [training: 0.7804164492963652 | validation: 0.622492741679048]
	TIME [epoch: 9.07 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8271043518230954		[learning rate: 0.0082128]
	Learning Rate: 0.00821277
	LOSS [training: 0.8271043518230954 | validation: 1.1867869002911213]
	TIME [epoch: 9.08 sec]
EPOCH 53/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9743027632605337		[learning rate: 0.0081743]
	Learning Rate: 0.00817427
	LOSS [training: 0.9743027632605337 | validation: 1.1290030273674088]
	TIME [epoch: 9.07 sec]
EPOCH 54/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9921602677100045		[learning rate: 0.0081359]
	Learning Rate: 0.00813595
	LOSS [training: 0.9921602677100045 | validation: 0.7233028126502304]
	TIME [epoch: 9.06 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6932649369746333		[learning rate: 0.0080978]
	Learning Rate: 0.00809781
	LOSS [training: 0.6932649369746333 | validation: 0.654273075712199]
	TIME [epoch: 9.06 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8206731539529233		[learning rate: 0.0080598]
	Learning Rate: 0.00805984
	LOSS [training: 0.8206731539529233 | validation: 0.7260985600804315]
	TIME [epoch: 9.07 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6485611112827088		[learning rate: 0.0080221]
	Learning Rate: 0.00802206
	LOSS [training: 0.6485611112827088 | validation: 0.6885731902272944]
	TIME [epoch: 9.09 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6514611596665746		[learning rate: 0.0079844]
	Learning Rate: 0.00798445
	LOSS [training: 0.6514611596665746 | validation: 1.0700334579589201]
	TIME [epoch: 9.07 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7254472426391094		[learning rate: 0.007947]
	Learning Rate: 0.00794702
	LOSS [training: 0.7254472426391094 | validation: 1.4348209001660621]
	TIME [epoch: 9.07 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8622357462503863		[learning rate: 0.0079098]
	Learning Rate: 0.00790976
	LOSS [training: 0.8622357462503863 | validation: 1.148282183265954]
	TIME [epoch: 9.07 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7480507333202817		[learning rate: 0.0078727]
	Learning Rate: 0.00787268
	LOSS [training: 0.7480507333202817 | validation: 0.6474321943684734]
	TIME [epoch: 9.07 sec]
EPOCH 62/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7390319789396792		[learning rate: 0.0078358]
	Learning Rate: 0.00783577
	LOSS [training: 0.7390319789396792 | validation: 0.6875910889525243]
	TIME [epoch: 9.08 sec]
EPOCH 63/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6763793791714636		[learning rate: 0.007799]
	Learning Rate: 0.00779903
	LOSS [training: 0.6763793791714636 | validation: 0.5807687586153283]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_63.pth
	Model improved!!!
EPOCH 64/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5876368250232356		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 0.5876368250232356 | validation: 0.4512324277143447]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_64.pth
	Model improved!!!
EPOCH 65/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9062139463884213		[learning rate: 0.0077261]
	Learning Rate: 0.00772608
	LOSS [training: 0.9062139463884213 | validation: 1.1296379464306159]
	TIME [epoch: 9.07 sec]
EPOCH 66/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9283642551075635		[learning rate: 0.0076899]
	Learning Rate: 0.00768986
	LOSS [training: 0.9283642551075635 | validation: 0.6048112929190649]
	TIME [epoch: 9.09 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8389242720802368		[learning rate: 0.0076538]
	Learning Rate: 0.00765381
	LOSS [training: 0.8389242720802368 | validation: 0.932689253730334]
	TIME [epoch: 9.07 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9082821224481359		[learning rate: 0.0076179]
	Learning Rate: 0.00761793
	LOSS [training: 0.9082821224481359 | validation: 0.7465859357539685]
	TIME [epoch: 9.06 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6698630945230116		[learning rate: 0.0075822]
	Learning Rate: 0.00758221
	LOSS [training: 0.6698630945230116 | validation: 1.3119752038956758]
	TIME [epoch: 9.06 sec]
EPOCH 70/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0352113600996622		[learning rate: 0.0075467]
	Learning Rate: 0.00754667
	LOSS [training: 1.0352113600996622 | validation: 1.0709255322555706]
	TIME [epoch: 9.07 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6307193074143239		[learning rate: 0.0075113]
	Learning Rate: 0.00751129
	LOSS [training: 0.6307193074143239 | validation: 0.40602388184260063]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_71.pth
	Model improved!!!
EPOCH 72/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5973487776169871		[learning rate: 0.0074761]
	Learning Rate: 0.00747607
	LOSS [training: 0.5973487776169871 | validation: 0.7773045039878688]
	TIME [epoch: 9.07 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8167532649971857		[learning rate: 0.007441]
	Learning Rate: 0.00744102
	LOSS [training: 0.8167532649971857 | validation: 0.9416847142321261]
	TIME [epoch: 9.07 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7198208660445582		[learning rate: 0.0074061]
	Learning Rate: 0.00740614
	LOSS [training: 0.7198208660445582 | validation: 0.7222208724963888]
	TIME [epoch: 9.07 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6474841253363287		[learning rate: 0.0073714]
	Learning Rate: 0.00737142
	LOSS [training: 0.6474841253363287 | validation: 0.5827048472080503]
	TIME [epoch: 9.09 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6572182650619993		[learning rate: 0.0073369]
	Learning Rate: 0.00733686
	LOSS [training: 0.6572182650619993 | validation: 0.5967835967573893]
	TIME [epoch: 9.07 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/10] avg loss: 0.634152294137216		[learning rate: 0.0073025]
	Learning Rate: 0.00730246
	LOSS [training: 0.634152294137216 | validation: 0.7484431014151701]
	TIME [epoch: 9.07 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6196424234718838		[learning rate: 0.0072682]
	Learning Rate: 0.00726823
	LOSS [training: 0.6196424234718838 | validation: 0.4301492356805551]
	TIME [epoch: 9.07 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5898410568219922		[learning rate: 0.0072342]
	Learning Rate: 0.00723415
	LOSS [training: 0.5898410568219922 | validation: 0.5418128956129219]
	TIME [epoch: 9.07 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6440586495092713		[learning rate: 0.0072002]
	Learning Rate: 0.00720024
	LOSS [training: 0.6440586495092713 | validation: 0.5419869676993734]
	TIME [epoch: 9.1 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6141409495980541		[learning rate: 0.0071665]
	Learning Rate: 0.00716648
	LOSS [training: 0.6141409495980541 | validation: 0.7331501551840084]
	TIME [epoch: 9.07 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6280418107860928		[learning rate: 0.0071329]
	Learning Rate: 0.00713289
	LOSS [training: 0.6280418107860928 | validation: 0.4556101029794549]
	TIME [epoch: 9.07 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/10] avg loss: 0.515477910401		[learning rate: 0.0070994]
	Learning Rate: 0.00709945
	LOSS [training: 0.515477910401 | validation: 0.5688840860842617]
	TIME [epoch: 9.07 sec]
EPOCH 84/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5798276362392379		[learning rate: 0.0070662]
	Learning Rate: 0.00706616
	LOSS [training: 0.5798276362392379 | validation: 0.8934574181799482]
	TIME [epoch: 9.09 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5588141390571344		[learning rate: 0.007033]
	Learning Rate: 0.00703304
	LOSS [training: 0.5588141390571344 | validation: 0.36218312995379]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_85.pth
	Model improved!!!
EPOCH 86/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5694732985070688		[learning rate: 0.0070001]
	Learning Rate: 0.00700006
	LOSS [training: 0.5694732985070688 | validation: 0.846468054114363]
	TIME [epoch: 9.07 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49071304630238527		[learning rate: 0.0069672]
	Learning Rate: 0.00696725
	LOSS [training: 0.49071304630238527 | validation: 0.5690560912941836]
	TIME [epoch: 9.07 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5486123164694472		[learning rate: 0.0069346]
	Learning Rate: 0.00693458
	LOSS [training: 0.5486123164694472 | validation: 0.5512694371962652]
	TIME [epoch: 9.07 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/10] avg loss: 0.48674974140247523		[learning rate: 0.0069021]
	Learning Rate: 0.00690207
	LOSS [training: 0.48674974140247523 | validation: 0.5300903942888042]
	TIME [epoch: 9.09 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4733909353133366		[learning rate: 0.0068697]
	Learning Rate: 0.00686972
	LOSS [training: 0.4733909353133366 | validation: 0.6782858180050912]
	TIME [epoch: 9.07 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4732188331693766		[learning rate: 0.0068375]
	Learning Rate: 0.00683751
	LOSS [training: 0.4732188331693766 | validation: 0.41664121772209795]
	TIME [epoch: 9.07 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7161002851458076		[learning rate: 0.0068055]
	Learning Rate: 0.00680545
	LOSS [training: 0.7161002851458076 | validation: 0.7713958473831998]
	TIME [epoch: 9.07 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9286846432427408		[learning rate: 0.0067735]
	Learning Rate: 0.00677355
	LOSS [training: 0.9286846432427408 | validation: 0.7715412596078868]
	TIME [epoch: 9.08 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49021212456976554		[learning rate: 0.0067418]
	Learning Rate: 0.00674179
	LOSS [training: 0.49021212456976554 | validation: 0.8764638390857731]
	TIME [epoch: 9.08 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5317977012918658		[learning rate: 0.0067102]
	Learning Rate: 0.00671019
	LOSS [training: 0.5317977012918658 | validation: 0.3600215147597222]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_95.pth
	Model improved!!!
EPOCH 96/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3796103427354879		[learning rate: 0.0066787]
	Learning Rate: 0.00667873
	LOSS [training: 0.3796103427354879 | validation: 0.33503075890753997]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_96.pth
	Model improved!!!
EPOCH 97/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5528616931473517		[learning rate: 0.0066474]
	Learning Rate: 0.00664742
	LOSS [training: 0.5528616931473517 | validation: 0.32787091855249884]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_97.pth
	Model improved!!!
EPOCH 98/500:
	Training over batches...
		[batch 10/10] avg loss: 0.42087580264763746		[learning rate: 0.0066163]
	Learning Rate: 0.00661625
	LOSS [training: 0.42087580264763746 | validation: 0.3442594164324557]
	TIME [epoch: 9.09 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39301711311467963		[learning rate: 0.0065852]
	Learning Rate: 0.00658524
	LOSS [training: 0.39301711311467963 | validation: 0.8135997440811809]
	TIME [epoch: 9.07 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/10] avg loss: 0.600319579220771		[learning rate: 0.0065544]
	Learning Rate: 0.00655436
	LOSS [training: 0.600319579220771 | validation: 0.6824908445149244]
	TIME [epoch: 9.06 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40976283536153985		[learning rate: 0.0065236]
	Learning Rate: 0.00652364
	LOSS [training: 0.40976283536153985 | validation: 0.3369123500785347]
	TIME [epoch: 9.07 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5467865309011885		[learning rate: 0.0064931]
	Learning Rate: 0.00649305
	LOSS [training: 0.5467865309011885 | validation: 1.0274080595201163]
	TIME [epoch: 9.07 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/10] avg loss: 0.599211577036004		[learning rate: 0.0064626]
	Learning Rate: 0.00646261
	LOSS [training: 0.599211577036004 | validation: 0.46171646469080485]
	TIME [epoch: 9.08 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40948861925478564		[learning rate: 0.0064323]
	Learning Rate: 0.00643232
	LOSS [training: 0.40948861925478564 | validation: 0.9121993401430544]
	TIME [epoch: 9.07 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41128049534478894		[learning rate: 0.0064022]
	Learning Rate: 0.00640216
	LOSS [training: 0.41128049534478894 | validation: 0.7437486146932706]
	TIME [epoch: 9.07 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40783395792385957		[learning rate: 0.0063721]
	Learning Rate: 0.00637215
	LOSS [training: 0.40783395792385957 | validation: 0.3684589897881423]
	TIME [epoch: 9.07 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5668748329543638		[learning rate: 0.0063423]
	Learning Rate: 0.00634227
	LOSS [training: 0.5668748329543638 | validation: 0.3579327285535786]
	TIME [epoch: 9.08 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/10] avg loss: 0.493292323389544		[learning rate: 0.0063125]
	Learning Rate: 0.00631254
	LOSS [training: 0.493292323389544 | validation: 0.38032487770162715]
	TIME [epoch: 9.07 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8988842304275785		[learning rate: 0.0062829]
	Learning Rate: 0.00628295
	LOSS [training: 0.8988842304275785 | validation: 0.5098601314515159]
	TIME [epoch: 9.07 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4356300356010821		[learning rate: 0.0062535]
	Learning Rate: 0.00625349
	LOSS [training: 0.4356300356010821 | validation: 0.5502102903573607]
	TIME [epoch: 9.06 sec]
EPOCH 111/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4415475154666907		[learning rate: 0.0062242]
	Learning Rate: 0.00622417
	LOSS [training: 0.4415475154666907 | validation: 0.33237801870292116]
	TIME [epoch: 9.07 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35134600245655057		[learning rate: 0.006195]
	Learning Rate: 0.00619499
	LOSS [training: 0.35134600245655057 | validation: 0.25213165510359614]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_112.pth
	Model improved!!!
EPOCH 113/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39802013265915087		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 0.39802013265915087 | validation: 1.4582609357672927]
	TIME [epoch: 9.07 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8421911981963589		[learning rate: 0.006137]
	Learning Rate: 0.00613704
	LOSS [training: 0.8421911981963589 | validation: 0.323896967914504]
	TIME [epoch: 9.07 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4461291433457947		[learning rate: 0.0061083]
	Learning Rate: 0.00610827
	LOSS [training: 0.4461291433457947 | validation: 0.7650289651565367]
	TIME [epoch: 9.06 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39369218784948307		[learning rate: 0.0060796]
	Learning Rate: 0.00607964
	LOSS [training: 0.39369218784948307 | validation: 0.3699578809583113]
	TIME [epoch: 9.09 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35384407633339227		[learning rate: 0.0060511]
	Learning Rate: 0.00605113
	LOSS [training: 0.35384407633339227 | validation: 0.47390383039832834]
	TIME [epoch: 9.07 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5079490036298353		[learning rate: 0.0060228]
	Learning Rate: 0.00602276
	LOSS [training: 0.5079490036298353 | validation: 0.4415563338974122]
	TIME [epoch: 9.06 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0221983084752653		[learning rate: 0.0059945]
	Learning Rate: 0.00599453
	LOSS [training: 1.0221983084752653 | validation: 0.3040520529158267]
	TIME [epoch: 9.06 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6413162137702011		[learning rate: 0.0059664]
	Learning Rate: 0.00596643
	LOSS [training: 0.6413162137702011 | validation: 0.43317082965281806]
	TIME [epoch: 9.06 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3912177426499396		[learning rate: 0.0059385]
	Learning Rate: 0.00593845
	LOSS [training: 0.3912177426499396 | validation: 0.3941000352910543]
	TIME [epoch: 9.09 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4826513560137126		[learning rate: 0.0059106]
	Learning Rate: 0.00591061
	LOSS [training: 0.4826513560137126 | validation: 1.0693278261439243]
	TIME [epoch: 9.07 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/10] avg loss: 0.541721927332917		[learning rate: 0.0058829]
	Learning Rate: 0.0058829
	LOSS [training: 0.541721927332917 | validation: 0.35767965107299293]
	TIME [epoch: 9.06 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4038856229868958		[learning rate: 0.0058553]
	Learning Rate: 0.00585532
	LOSS [training: 0.4038856229868958 | validation: 1.254392687418549]
	TIME [epoch: 9.06 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7213311164999383		[learning rate: 0.0058279]
	Learning Rate: 0.00582787
	LOSS [training: 0.7213311164999383 | validation: 0.29730290496054174]
	TIME [epoch: 9.07 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4000971754083076		[learning rate: 0.0058006]
	Learning Rate: 0.00580055
	LOSS [training: 0.4000971754083076 | validation: 0.5163474088013671]
	TIME [epoch: 9.08 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4909827265052886		[learning rate: 0.0057734]
	Learning Rate: 0.00577336
	LOSS [training: 0.4909827265052886 | validation: 0.3561117240044463]
	TIME [epoch: 9.07 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35453050403975384		[learning rate: 0.0057463]
	Learning Rate: 0.00574629
	LOSS [training: 0.35453050403975384 | validation: 0.43354389894900347]
	TIME [epoch: 9.06 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33826878978070163		[learning rate: 0.0057194]
	Learning Rate: 0.00571935
	LOSS [training: 0.33826878978070163 | validation: 0.2747728762922874]
	TIME [epoch: 9.06 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3324235589367502		[learning rate: 0.0056925]
	Learning Rate: 0.00569254
	LOSS [training: 0.3324235589367502 | validation: 0.2600972514574311]
	TIME [epoch: 9.08 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3152144696301541		[learning rate: 0.0056659]
	Learning Rate: 0.00566585
	LOSS [training: 0.3152144696301541 | validation: 0.3236716087441993]
	TIME [epoch: 9.07 sec]
EPOCH 132/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33781334687737313		[learning rate: 0.0056393]
	Learning Rate: 0.00563929
	LOSS [training: 0.33781334687737313 | validation: 0.23093329760416842]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_132.pth
	Model improved!!!
EPOCH 133/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3402009571944159		[learning rate: 0.0056129]
	Learning Rate: 0.00561285
	LOSS [training: 0.3402009571944159 | validation: 0.2721912188537947]
	TIME [epoch: 9.06 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4929242384282909		[learning rate: 0.0055865]
	Learning Rate: 0.00558654
	LOSS [training: 0.4929242384282909 | validation: 0.36341516620011627]
	TIME [epoch: 9.06 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33158816712969563		[learning rate: 0.0055603]
	Learning Rate: 0.00556035
	LOSS [training: 0.33158816712969563 | validation: 0.47728029937159583]
	TIME [epoch: 9.09 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3436753283868219		[learning rate: 0.0055343]
	Learning Rate: 0.00553428
	LOSS [training: 0.3436753283868219 | validation: 0.4391926981479338]
	TIME [epoch: 9.07 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47690703676677987		[learning rate: 0.0055083]
	Learning Rate: 0.00550834
	LOSS [training: 0.47690703676677987 | validation: 0.3919496071351243]
	TIME [epoch: 9.07 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3353498485199712		[learning rate: 0.0054825]
	Learning Rate: 0.00548251
	LOSS [training: 0.3353498485199712 | validation: 0.5298708195769484]
	TIME [epoch: 9.06 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36717963070829		[learning rate: 0.0054568]
	Learning Rate: 0.00545681
	LOSS [training: 0.36717963070829 | validation: 0.5585023017641351]
	TIME [epoch: 9.08 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1725081317956074		[learning rate: 0.0054312]
	Learning Rate: 0.00543123
	LOSS [training: 1.1725081317956074 | validation: 0.4954793067332348]
	TIME [epoch: 9.06 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3566622791073314		[learning rate: 0.0054058]
	Learning Rate: 0.00540576
	LOSS [training: 0.3566622791073314 | validation: 0.23466786257287298]
	TIME [epoch: 9.07 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2544272054939738		[learning rate: 0.0053804]
	Learning Rate: 0.00538042
	LOSS [training: 0.2544272054939738 | validation: 0.260025594887403]
	TIME [epoch: 9.06 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/10] avg loss: 0.297884985425471		[learning rate: 0.0053552]
	Learning Rate: 0.0053552
	LOSS [training: 0.297884985425471 | validation: 0.24699043254610858]
	TIME [epoch: 9.06 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28021705932598284		[learning rate: 0.0053301]
	Learning Rate: 0.00533009
	LOSS [training: 0.28021705932598284 | validation: 0.23392375173857233]
	TIME [epoch: 9.09 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3061430882101732		[learning rate: 0.0053051]
	Learning Rate: 0.0053051
	LOSS [training: 0.3061430882101732 | validation: 0.27440992410095916]
	TIME [epoch: 9.06 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3981314610153614		[learning rate: 0.0052802]
	Learning Rate: 0.00528023
	LOSS [training: 0.3981314610153614 | validation: 0.24240198111814237]
	TIME [epoch: 9.06 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2778469565516203		[learning rate: 0.0052555]
	Learning Rate: 0.00525548
	LOSS [training: 0.2778469565516203 | validation: 0.18307718301811876]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_147.pth
	Model improved!!!
EPOCH 148/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5040146880801316		[learning rate: 0.0052308]
	Learning Rate: 0.00523084
	LOSS [training: 0.5040146880801316 | validation: 0.15809634811720225]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_148.pth
	Model improved!!!
EPOCH 149/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2986356103049364		[learning rate: 0.0052063]
	Learning Rate: 0.00520632
	LOSS [training: 0.2986356103049364 | validation: 0.37651630282240117]
	TIME [epoch: 9.08 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3014871066302491		[learning rate: 0.0051819]
	Learning Rate: 0.00518191
	LOSS [training: 0.3014871066302491 | validation: 0.3370158242096078]
	TIME [epoch: 9.07 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39759685057358896		[learning rate: 0.0051576]
	Learning Rate: 0.00515762
	LOSS [training: 0.39759685057358896 | validation: 0.3413217207764184]
	TIME [epoch: 9.06 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2102544364041604		[learning rate: 0.0051334]
	Learning Rate: 0.00513344
	LOSS [training: 0.2102544364041604 | validation: 0.15435812536456325]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_152.pth
	Model improved!!!
EPOCH 153/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22562487679035562		[learning rate: 0.0051094]
	Learning Rate: 0.00510937
	LOSS [training: 0.22562487679035562 | validation: 0.3379949992327501]
	TIME [epoch: 9.08 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27153663626558505		[learning rate: 0.0050854]
	Learning Rate: 0.00508542
	LOSS [training: 0.27153663626558505 | validation: 0.5740816262763907]
	TIME [epoch: 9.06 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5201770261749175		[learning rate: 0.0050616]
	Learning Rate: 0.00506158
	LOSS [training: 0.5201770261749175 | validation: 0.44184120787697295]
	TIME [epoch: 9.06 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3983333668646056		[learning rate: 0.0050378]
	Learning Rate: 0.00503785
	LOSS [training: 0.3983333668646056 | validation: 0.42751480952129506]
	TIME [epoch: 9.06 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3127759767946278		[learning rate: 0.0050142]
	Learning Rate: 0.00501423
	LOSS [training: 0.3127759767946278 | validation: 0.5648809862089288]
	TIME [epoch: 9.06 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5097428769848527		[learning rate: 0.0049907]
	Learning Rate: 0.00499072
	LOSS [training: 0.5097428769848527 | validation: 0.8283560713128733]
	TIME [epoch: 9.08 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3913247548615586		[learning rate: 0.0049673]
	Learning Rate: 0.00496732
	LOSS [training: 0.3913247548615586 | validation: 0.2272639390681075]
	TIME [epoch: 9.06 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4544121381992777		[learning rate: 0.004944]
	Learning Rate: 0.00494404
	LOSS [training: 0.4544121381992777 | validation: 0.17332582949998387]
	TIME [epoch: 9.06 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2412239956443631		[learning rate: 0.0049209]
	Learning Rate: 0.00492086
	LOSS [training: 0.2412239956443631 | validation: 0.6488535542016081]
	TIME [epoch: 9.05 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30156640108399696		[learning rate: 0.0048978]
	Learning Rate: 0.00489779
	LOSS [training: 0.30156640108399696 | validation: 0.24094400581403652]
	TIME [epoch: 9.08 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49333039493620456		[learning rate: 0.0048748]
	Learning Rate: 0.00487483
	LOSS [training: 0.49333039493620456 | validation: 0.24875841887999456]
	TIME [epoch: 9.06 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3767731905084117		[learning rate: 0.004852]
	Learning Rate: 0.00485197
	LOSS [training: 0.3767731905084117 | validation: 0.30034549655089354]
	TIME [epoch: 9.07 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24788355780888166		[learning rate: 0.0048292]
	Learning Rate: 0.00482923
	LOSS [training: 0.24788355780888166 | validation: 0.37765280895740183]
	TIME [epoch: 9.06 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2401281844879398		[learning rate: 0.0048066]
	Learning Rate: 0.00480659
	LOSS [training: 0.2401281844879398 | validation: 0.1829162837267439]
	TIME [epoch: 9.06 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28902570500361346		[learning rate: 0.0047841]
	Learning Rate: 0.00478405
	LOSS [training: 0.28902570500361346 | validation: 0.24998235774252636]
	TIME [epoch: 9.08 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23195902820042485		[learning rate: 0.0047616]
	Learning Rate: 0.00476162
	LOSS [training: 0.23195902820042485 | validation: 0.4015282952582474]
	TIME [epoch: 9.06 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3444196124703		[learning rate: 0.0047393]
	Learning Rate: 0.0047393
	LOSS [training: 0.3444196124703 | validation: 0.23967905906331577]
	TIME [epoch: 9.06 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37668894421202437		[learning rate: 0.0047171]
	Learning Rate: 0.00471708
	LOSS [training: 0.37668894421202437 | validation: 0.2493786290028177]
	TIME [epoch: 9.06 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28382258902953267		[learning rate: 0.004695]
	Learning Rate: 0.00469497
	LOSS [training: 0.28382258902953267 | validation: 0.3119559647213812]
	TIME [epoch: 9.07 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32096373025098446		[learning rate: 0.004673]
	Learning Rate: 0.00467296
	LOSS [training: 0.32096373025098446 | validation: 0.9299356429785806]
	TIME [epoch: 9.07 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33857861995656036		[learning rate: 0.0046511]
	Learning Rate: 0.00465105
	LOSS [training: 0.33857861995656036 | validation: 0.3565436152261193]
	TIME [epoch: 9.06 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35023788872069334		[learning rate: 0.0046292]
	Learning Rate: 0.00462925
	LOSS [training: 0.35023788872069334 | validation: 0.3105082695829648]
	TIME [epoch: 9.06 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5210827867054311		[learning rate: 0.0046075]
	Learning Rate: 0.00460754
	LOSS [training: 0.5210827867054311 | validation: 0.3085682885017664]
	TIME [epoch: 9.06 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2836583376994017		[learning rate: 0.0045859]
	Learning Rate: 0.00458594
	LOSS [training: 0.2836583376994017 | validation: 0.20817011672138291]
	TIME [epoch: 9.08 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4229019790201239		[learning rate: 0.0045644]
	Learning Rate: 0.00456444
	LOSS [training: 0.4229019790201239 | validation: 0.8861180407797672]
	TIME [epoch: 9.07 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3362671758007922		[learning rate: 0.004543]
	Learning Rate: 0.00454304
	LOSS [training: 0.3362671758007922 | validation: 0.23801777916719513]
	TIME [epoch: 9.06 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27160386250197466		[learning rate: 0.0045217]
	Learning Rate: 0.00452175
	LOSS [training: 0.27160386250197466 | validation: 0.28439289086295483]
	TIME [epoch: 9.06 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/10] avg loss: 0.384061320932281		[learning rate: 0.0045005]
	Learning Rate: 0.00450055
	LOSS [training: 0.384061320932281 | validation: 0.36773476960198426]
	TIME [epoch: 9.07 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29723330203015236		[learning rate: 0.0044794]
	Learning Rate: 0.00447945
	LOSS [training: 0.29723330203015236 | validation: 0.2897399955185551]
	TIME [epoch: 9.08 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24233893619992367		[learning rate: 0.0044584]
	Learning Rate: 0.00445845
	LOSS [training: 0.24233893619992367 | validation: 0.20715176581603628]
	TIME [epoch: 9.06 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23097070118430643		[learning rate: 0.0044375]
	Learning Rate: 0.00443755
	LOSS [training: 0.23097070118430643 | validation: 0.40104393824445195]
	TIME [epoch: 9.06 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3210012174074567		[learning rate: 0.0044167]
	Learning Rate: 0.00441674
	LOSS [training: 0.3210012174074567 | validation: 0.4571741824357437]
	TIME [epoch: 9.06 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5031159445328288		[learning rate: 0.004396]
	Learning Rate: 0.00439604
	LOSS [training: 0.5031159445328288 | validation: 0.38210797291614457]
	TIME [epoch: 9.07 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30834747353660086		[learning rate: 0.0043754]
	Learning Rate: 0.00437543
	LOSS [training: 0.30834747353660086 | validation: 0.4822207190545113]
	TIME [epoch: 9.06 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30084549226396473		[learning rate: 0.0043549]
	Learning Rate: 0.00435491
	LOSS [training: 0.30084549226396473 | validation: 0.14841292352639823]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_187.pth
	Model improved!!!
EPOCH 188/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2554303646084497		[learning rate: 0.0043345]
	Learning Rate: 0.0043345
	LOSS [training: 0.2554303646084497 | validation: 0.5044688134718543]
	TIME [epoch: 9.05 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23517979804147152		[learning rate: 0.0043142]
	Learning Rate: 0.00431418
	LOSS [training: 0.23517979804147152 | validation: 0.25525007705543207]
	TIME [epoch: 9.06 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39256493396670794		[learning rate: 0.004294]
	Learning Rate: 0.00429395
	LOSS [training: 0.39256493396670794 | validation: 0.30331446779630655]
	TIME [epoch: 9.08 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32346638880758916		[learning rate: 0.0042738]
	Learning Rate: 0.00427382
	LOSS [training: 0.32346638880758916 | validation: 0.2580930177237612]
	TIME [epoch: 9.05 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/10] avg loss: 0.300591525945235		[learning rate: 0.0042538]
	Learning Rate: 0.00425378
	LOSS [training: 0.300591525945235 | validation: 0.1881157290716518]
	TIME [epoch: 9.05 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20935491883518448		[learning rate: 0.0042338]
	Learning Rate: 0.00423384
	LOSS [training: 0.20935491883518448 | validation: 0.20993924166015848]
	TIME [epoch: 9.05 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3374868348473046		[learning rate: 0.004214]
	Learning Rate: 0.00421399
	LOSS [training: 0.3374868348473046 | validation: 0.12782538992607764]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_194.pth
	Model improved!!!
EPOCH 195/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22871312328096552		[learning rate: 0.0041942]
	Learning Rate: 0.00419424
	LOSS [training: 0.22871312328096552 | validation: 0.2260542514032005]
	TIME [epoch: 9.09 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2772465012831834		[learning rate: 0.0041746]
	Learning Rate: 0.00417457
	LOSS [training: 0.2772465012831834 | validation: 0.43957660436380974]
	TIME [epoch: 9.06 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22591221253753951		[learning rate: 0.004155]
	Learning Rate: 0.004155
	LOSS [training: 0.22591221253753951 | validation: 0.3070646679215009]
	TIME [epoch: 9.06 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2536318895699109		[learning rate: 0.0041355]
	Learning Rate: 0.00413552
	LOSS [training: 0.2536318895699109 | validation: 0.22779210971372404]
	TIME [epoch: 9.06 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22723985188768953		[learning rate: 0.0041161]
	Learning Rate: 0.00411614
	LOSS [training: 0.22723985188768953 | validation: 0.3095824778111774]
	TIME [epoch: 9.07 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28766538433803734		[learning rate: 0.0040968]
	Learning Rate: 0.00409684
	LOSS [training: 0.28766538433803734 | validation: 0.2762939042621538]
	TIME [epoch: 9.06 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24866323674349416		[learning rate: 0.0040776]
	Learning Rate: 0.00407763
	LOSS [training: 0.24866323674349416 | validation: 0.3233569650200121]
	TIME [epoch: 9.06 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23394226156229853		[learning rate: 0.0040585]
	Learning Rate: 0.00405852
	LOSS [training: 0.23394226156229853 | validation: 0.2904466874514477]
	TIME [epoch: 9.06 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23884270280910527		[learning rate: 0.0040395]
	Learning Rate: 0.00403949
	LOSS [training: 0.23884270280910527 | validation: 0.21201474161286965]
	TIME [epoch: 9.07 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25818562747966345		[learning rate: 0.0040206]
	Learning Rate: 0.00402055
	LOSS [training: 0.25818562747966345 | validation: 0.2918444413601706]
	TIME [epoch: 9.08 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22346137167104016		[learning rate: 0.0040017]
	Learning Rate: 0.0040017
	LOSS [training: 0.22346137167104016 | validation: 0.49700755347277725]
	TIME [epoch: 9.06 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25916845307773373		[learning rate: 0.0039829]
	Learning Rate: 0.00398294
	LOSS [training: 0.25916845307773373 | validation: 0.09252124513933123]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_206.pth
	Model improved!!!
EPOCH 207/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1467182027405799		[learning rate: 0.0039643]
	Learning Rate: 0.00396427
	LOSS [training: 0.1467182027405799 | validation: 0.1792229124895343]
	TIME [epoch: 9.06 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23967920997978723		[learning rate: 0.0039457]
	Learning Rate: 0.00394569
	LOSS [training: 0.23967920997978723 | validation: 0.3376862417594316]
	TIME [epoch: 9.07 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2383210298433152		[learning rate: 0.0039272]
	Learning Rate: 0.00392719
	LOSS [training: 0.2383210298433152 | validation: 0.17504412769200162]
	TIME [epoch: 9.06 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25486290895149394		[learning rate: 0.0039088]
	Learning Rate: 0.00390878
	LOSS [training: 0.25486290895149394 | validation: 0.13705301339826712]
	TIME [epoch: 9.06 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15380743516290113		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.15380743516290113 | validation: 0.682551859810189]
	TIME [epoch: 9.06 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22147840218124482		[learning rate: 0.0038722]
	Learning Rate: 0.00387221
	LOSS [training: 0.22147840218124482 | validation: 0.3226351840833549]
	TIME [epoch: 9.06 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22337680734943674		[learning rate: 0.0038541]
	Learning Rate: 0.00385406
	LOSS [training: 0.22337680734943674 | validation: 0.1411599412053608]
	TIME [epoch: 9.08 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24078426657458568		[learning rate: 0.003836]
	Learning Rate: 0.00383599
	LOSS [training: 0.24078426657458568 | validation: 0.2947603171148535]
	TIME [epoch: 9.05 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2658509128751908		[learning rate: 0.003818]
	Learning Rate: 0.00381801
	LOSS [training: 0.2658509128751908 | validation: 0.392981473238439]
	TIME [epoch: 9.07 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26421027578100326		[learning rate: 0.0038001]
	Learning Rate: 0.00380011
	LOSS [training: 0.26421027578100326 | validation: 0.1192386748723562]
	TIME [epoch: 9.06 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1825205866496336		[learning rate: 0.0037823]
	Learning Rate: 0.00378229
	LOSS [training: 0.1825205866496336 | validation: 0.26893442281106694]
	TIME [epoch: 9.07 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18531215260356518		[learning rate: 0.0037646]
	Learning Rate: 0.00376456
	LOSS [training: 0.18531215260356518 | validation: 0.1900975678708396]
	TIME [epoch: 9.08 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32051850045027974		[learning rate: 0.0037469]
	Learning Rate: 0.00374691
	LOSS [training: 0.32051850045027974 | validation: 0.16480796284072258]
	TIME [epoch: 9.06 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14804297283575618		[learning rate: 0.0037293]
	Learning Rate: 0.00372935
	LOSS [training: 0.14804297283575618 | validation: 0.1501439701310005]
	TIME [epoch: 9.06 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17761575175646824		[learning rate: 0.0037119]
	Learning Rate: 0.00371186
	LOSS [training: 0.17761575175646824 | validation: 0.14460811020287062]
	TIME [epoch: 9.07 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20843875284191124		[learning rate: 0.0036945]
	Learning Rate: 0.00369446
	LOSS [training: 0.20843875284191124 | validation: 0.2551838997597592]
	TIME [epoch: 9.08 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26512151364645603		[learning rate: 0.0036771]
	Learning Rate: 0.00367714
	LOSS [training: 0.26512151364645603 | validation: 0.20348158568076774]
	TIME [epoch: 9.07 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2097801610934503		[learning rate: 0.0036599]
	Learning Rate: 0.0036599
	LOSS [training: 0.2097801610934503 | validation: 0.22146747244381015]
	TIME [epoch: 9.07 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18231274489000782		[learning rate: 0.0036427]
	Learning Rate: 0.00364274
	LOSS [training: 0.18231274489000782 | validation: 0.17017759851964737]
	TIME [epoch: 9.06 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25956830298298167		[learning rate: 0.0036257]
	Learning Rate: 0.00362567
	LOSS [training: 0.25956830298298167 | validation: 0.15816776939470772]
	TIME [epoch: 9.07 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35633628674524365		[learning rate: 0.0036087]
	Learning Rate: 0.00360867
	LOSS [training: 0.35633628674524365 | validation: 0.32132252709743336]
	TIME [epoch: 9.09 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23680787766435446		[learning rate: 0.0035918]
	Learning Rate: 0.00359175
	LOSS [training: 0.23680787766435446 | validation: 0.27451923428856406]
	TIME [epoch: 9.06 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21473948408673288		[learning rate: 0.0035749]
	Learning Rate: 0.00357491
	LOSS [training: 0.21473948408673288 | validation: 0.2367185679070849]
	TIME [epoch: 9.05 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3083271404659533		[learning rate: 0.0035582]
	Learning Rate: 0.00355815
	LOSS [training: 0.3083271404659533 | validation: 0.2789580869699248]
	TIME [epoch: 9.06 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2258401788849635		[learning rate: 0.0035415]
	Learning Rate: 0.00354147
	LOSS [training: 0.2258401788849635 | validation: 0.24579674541068686]
	TIME [epoch: 9.07 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2655581239922912		[learning rate: 0.0035249]
	Learning Rate: 0.00352487
	LOSS [training: 0.2655581239922912 | validation: 0.2781569776833802]
	TIME [epoch: 9.06 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2264521612628684		[learning rate: 0.0035083]
	Learning Rate: 0.00350834
	LOSS [training: 0.2264521612628684 | validation: 0.43308017932806064]
	TIME [epoch: 9.06 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19963501613022733		[learning rate: 0.0034919]
	Learning Rate: 0.0034919
	LOSS [training: 0.19963501613022733 | validation: 0.13682041545552603]
	TIME [epoch: 9.06 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19376084511182018		[learning rate: 0.0034755]
	Learning Rate: 0.00347552
	LOSS [training: 0.19376084511182018 | validation: 0.1586258658211856]
	TIME [epoch: 9.06 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21807946019371705		[learning rate: 0.0034592]
	Learning Rate: 0.00345923
	LOSS [training: 0.21807946019371705 | validation: 0.18611141894908662]
	TIME [epoch: 9.08 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1835856211474955		[learning rate: 0.003443]
	Learning Rate: 0.00344301
	LOSS [training: 0.1835856211474955 | validation: 0.12668572832542485]
	TIME [epoch: 9.06 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19150005774295256		[learning rate: 0.0034269]
	Learning Rate: 0.00342687
	LOSS [training: 0.19150005774295256 | validation: 0.2578485675984323]
	TIME [epoch: 9.06 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23842350628511486		[learning rate: 0.0034108]
	Learning Rate: 0.00341081
	LOSS [training: 0.23842350628511486 | validation: 0.2405826030257579]
	TIME [epoch: 9.06 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/10] avg loss: 0.269510905533135		[learning rate: 0.0033948]
	Learning Rate: 0.00339482
	LOSS [training: 0.269510905533135 | validation: 0.20166844445641816]
	TIME [epoch: 9.07 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20858551661371974		[learning rate: 0.0033789]
	Learning Rate: 0.0033789
	LOSS [training: 0.20858551661371974 | validation: 0.21498999790234402]
	TIME [epoch: 9.08 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19435760584030304		[learning rate: 0.0033631]
	Learning Rate: 0.00336306
	LOSS [training: 0.19435760584030304 | validation: 0.3421801016238153]
	TIME [epoch: 9.06 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5555953880694053		[learning rate: 0.0033473]
	Learning Rate: 0.00334729
	LOSS [training: 0.5555953880694053 | validation: 0.4532245163214327]
	TIME [epoch: 9.06 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2669735431665208		[learning rate: 0.0033316]
	Learning Rate: 0.0033316
	LOSS [training: 0.2669735431665208 | validation: 0.2903187230879067]
	TIME [epoch: 9.06 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24521528287690017		[learning rate: 0.003316]
	Learning Rate: 0.00331598
	LOSS [training: 0.24521528287690017 | validation: 0.33586212888656175]
	TIME [epoch: 9.08 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21946639814163033		[learning rate: 0.0033004]
	Learning Rate: 0.00330044
	LOSS [training: 0.21946639814163033 | validation: 0.17486489431358992]
	TIME [epoch: 9.06 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19106754909324342		[learning rate: 0.003285]
	Learning Rate: 0.00328496
	LOSS [training: 0.19106754909324342 | validation: 0.2405704106428137]
	TIME [epoch: 9.05 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2146066753864116		[learning rate: 0.0032696]
	Learning Rate: 0.00326956
	LOSS [training: 0.2146066753864116 | validation: 0.26887455155970574]
	TIME [epoch: 9.05 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20111287339055153		[learning rate: 0.0032542]
	Learning Rate: 0.00325424
	LOSS [training: 0.20111287339055153 | validation: 0.15480246302080256]
	TIME [epoch: 9.06 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16043950783077565		[learning rate: 0.003239]
	Learning Rate: 0.00323898
	LOSS [training: 0.16043950783077565 | validation: 0.15982910747122392]
	TIME [epoch: 9.07 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17744771731078401		[learning rate: 0.0032238]
	Learning Rate: 0.00322379
	LOSS [training: 0.17744771731078401 | validation: 0.1806757067381613]
	TIME [epoch: 9.05 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18661887846338865		[learning rate: 0.0032087]
	Learning Rate: 0.00320868
	LOSS [training: 0.18661887846338865 | validation: 0.3469600421322724]
	TIME [epoch: 9.05 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16442091380614582		[learning rate: 0.0031936]
	Learning Rate: 0.00319364
	LOSS [training: 0.16442091380614582 | validation: 0.14108772244468365]
	TIME [epoch: 9.05 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15485788753415092		[learning rate: 0.0031787]
	Learning Rate: 0.00317867
	LOSS [training: 0.15485788753415092 | validation: 0.16748575253918146]
	TIME [epoch: 9.07 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20809033455298062		[learning rate: 0.0031638]
	Learning Rate: 0.00316376
	LOSS [training: 0.20809033455298062 | validation: 0.2902508551524411]
	TIME [epoch: 9.04 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25981655745161897		[learning rate: 0.0031489]
	Learning Rate: 0.00314893
	LOSS [training: 0.25981655745161897 | validation: 0.1530508045672347]
	TIME [epoch: 9.05 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/10] avg loss: 0.162771063640813		[learning rate: 0.0031342]
	Learning Rate: 0.00313417
	LOSS [training: 0.162771063640813 | validation: 0.12611762303207527]
	TIME [epoch: 9.05 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1397731446695643		[learning rate: 0.0031195]
	Learning Rate: 0.00311948
	LOSS [training: 0.1397731446695643 | validation: 0.37941111481605083]
	TIME [epoch: 9.05 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22479553356566057		[learning rate: 0.0031049]
	Learning Rate: 0.00310485
	LOSS [training: 0.22479553356566057 | validation: 0.16033199079353522]
	TIME [epoch: 9.07 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19437153728496703		[learning rate: 0.0030903]
	Learning Rate: 0.0030903
	LOSS [training: 0.19437153728496703 | validation: 0.09633054797709123]
	TIME [epoch: 9.05 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10556821855947414		[learning rate: 0.0030758]
	Learning Rate: 0.00307581
	LOSS [training: 0.10556821855947414 | validation: 0.13890339409298813]
	TIME [epoch: 9.05 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1569791590524235		[learning rate: 0.0030614]
	Learning Rate: 0.00306139
	LOSS [training: 0.1569791590524235 | validation: 0.12834258267798931]
	TIME [epoch: 9.05 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1389742182559121		[learning rate: 0.003047]
	Learning Rate: 0.00304704
	LOSS [training: 0.1389742182559121 | validation: 0.15302098319798121]
	TIME [epoch: 9.05 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13650745871800848		[learning rate: 0.0030328]
	Learning Rate: 0.00303275
	LOSS [training: 0.13650745871800848 | validation: 0.28243684372899625]
	TIME [epoch: 9.06 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/10] avg loss: 0.182296306119978		[learning rate: 0.0030185]
	Learning Rate: 0.00301853
	LOSS [training: 0.182296306119978 | validation: 0.09618771413518806]
	TIME [epoch: 9.05 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1926417577434641		[learning rate: 0.0030044]
	Learning Rate: 0.00300438
	LOSS [training: 0.1926417577434641 | validation: 0.4074907905511026]
	TIME [epoch: 9.05 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27823040775843283		[learning rate: 0.0029903]
	Learning Rate: 0.0029903
	LOSS [training: 0.27823040775843283 | validation: 0.2684344229624505]
	TIME [epoch: 9.06 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2038148345012329		[learning rate: 0.0029763]
	Learning Rate: 0.00297628
	LOSS [training: 0.2038148345012329 | validation: 0.19996695576725237]
	TIME [epoch: 9.08 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23964271392364248		[learning rate: 0.0029623]
	Learning Rate: 0.00296232
	LOSS [training: 0.23964271392364248 | validation: 0.165512973744572]
	TIME [epoch: 9.06 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15349535468202938		[learning rate: 0.0029484]
	Learning Rate: 0.00294844
	LOSS [training: 0.15349535468202938 | validation: 0.18571545718407906]
	TIME [epoch: 9.05 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24238880010106417		[learning rate: 0.0029346]
	Learning Rate: 0.00293461
	LOSS [training: 0.24238880010106417 | validation: 0.1909198459437785]
	TIME [epoch: 9.06 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2354176084377892		[learning rate: 0.0029209]
	Learning Rate: 0.00292086
	LOSS [training: 0.2354176084377892 | validation: 0.33037961559111795]
	TIME [epoch: 9.05 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24693455162339525		[learning rate: 0.0029072]
	Learning Rate: 0.00290716
	LOSS [training: 0.24693455162339525 | validation: 0.1993427805233977]
	TIME [epoch: 9.08 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16205026241519827		[learning rate: 0.0028935]
	Learning Rate: 0.00289353
	LOSS [training: 0.16205026241519827 | validation: 0.07195699509678044]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_274.pth
	Model improved!!!
EPOCH 275/500:
	Training over batches...
		[batch 10/10] avg loss: 0.155911601607272		[learning rate: 0.00288]
	Learning Rate: 0.00287997
	LOSS [training: 0.155911601607272 | validation: 0.19784585123231638]
	TIME [epoch: 9.06 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1419758502844464		[learning rate: 0.0028665]
	Learning Rate: 0.00286647
	LOSS [training: 0.1419758502844464 | validation: 0.09630043783382375]
	TIME [epoch: 9.05 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14528655823470465		[learning rate: 0.002853]
	Learning Rate: 0.00285303
	LOSS [training: 0.14528655823470465 | validation: 0.12189850585563874]
	TIME [epoch: 9.06 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1602939025365601		[learning rate: 0.0028397]
	Learning Rate: 0.00283965
	LOSS [training: 0.1602939025365601 | validation: 0.16675832014392594]
	TIME [epoch: 9.07 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14619805262746438		[learning rate: 0.0028263]
	Learning Rate: 0.00282634
	LOSS [training: 0.14619805262746438 | validation: 0.12618491121126985]
	TIME [epoch: 9.05 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13542778903924066		[learning rate: 0.0028131]
	Learning Rate: 0.00281309
	LOSS [training: 0.13542778903924066 | validation: 0.12685231371691935]
	TIME [epoch: 9.05 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15205850159565712		[learning rate: 0.0027999]
	Learning Rate: 0.0027999
	LOSS [training: 0.15205850159565712 | validation: 0.15962772300040595]
	TIME [epoch: 9.05 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19773684778593995		[learning rate: 0.0027868]
	Learning Rate: 0.00278678
	LOSS [training: 0.19773684778593995 | validation: 0.13885030998766396]
	TIME [epoch: 9.07 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1696221667725169		[learning rate: 0.0027737]
	Learning Rate: 0.00277371
	LOSS [training: 0.1696221667725169 | validation: 0.14285003844978678]
	TIME [epoch: 9.06 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15493137192587608		[learning rate: 0.0027607]
	Learning Rate: 0.00276071
	LOSS [training: 0.15493137192587608 | validation: 0.18236745626533257]
	TIME [epoch: 9.05 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17829386282842508		[learning rate: 0.0027478]
	Learning Rate: 0.00274776
	LOSS [training: 0.17829386282842508 | validation: 0.6714334701250719]
	TIME [epoch: 9.05 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28981952863381233		[learning rate: 0.0027349]
	Learning Rate: 0.00273488
	LOSS [training: 0.28981952863381233 | validation: 0.15220400639515147]
	TIME [epoch: 9.06 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24356181203324273		[learning rate: 0.0027221]
	Learning Rate: 0.00272206
	LOSS [training: 0.24356181203324273 | validation: 0.13590154900375018]
	TIME [epoch: 9.07 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14346842662506237		[learning rate: 0.0027093]
	Learning Rate: 0.0027093
	LOSS [training: 0.14346842662506237 | validation: 0.13315880823637805]
	TIME [epoch: 9.05 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13222045881995872		[learning rate: 0.0026966]
	Learning Rate: 0.0026966
	LOSS [training: 0.13222045881995872 | validation: 0.08715408070633875]
	TIME [epoch: 9.05 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12338146226134046		[learning rate: 0.002684]
	Learning Rate: 0.00268396
	LOSS [training: 0.12338146226134046 | validation: 0.09198855270639235]
	TIME [epoch: 9.05 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1541135730073636		[learning rate: 0.0026714]
	Learning Rate: 0.00267137
	LOSS [training: 0.1541135730073636 | validation: 0.13088911862592956]
	TIME [epoch: 9.07 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15832258209451214		[learning rate: 0.0026589]
	Learning Rate: 0.00265885
	LOSS [training: 0.15832258209451214 | validation: 0.14687542341419835]
	TIME [epoch: 9.05 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11135211552711666		[learning rate: 0.0026464]
	Learning Rate: 0.00264639
	LOSS [training: 0.11135211552711666 | validation: 0.10235732668283144]
	TIME [epoch: 9.07 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1221652455005839		[learning rate: 0.002634]
	Learning Rate: 0.00263398
	LOSS [training: 0.1221652455005839 | validation: 0.12364605064383899]
	TIME [epoch: 9.05 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11949739000348372		[learning rate: 0.0026216]
	Learning Rate: 0.00262163
	LOSS [training: 0.11949739000348372 | validation: 0.16059866259194955]
	TIME [epoch: 9.05 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1217799281830529		[learning rate: 0.0026093]
	Learning Rate: 0.00260934
	LOSS [training: 0.1217799281830529 | validation: 0.1583812915740921]
	TIME [epoch: 9.08 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1643452381279608		[learning rate: 0.0025971]
	Learning Rate: 0.00259711
	LOSS [training: 0.1643452381279608 | validation: 0.12495121077267596]
	TIME [epoch: 9.05 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12887105453793302		[learning rate: 0.0025849]
	Learning Rate: 0.00258493
	LOSS [training: 0.12887105453793302 | validation: 0.2865030837480137]
	TIME [epoch: 9.05 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21537244520970442		[learning rate: 0.0025728]
	Learning Rate: 0.00257281
	LOSS [training: 0.21537244520970442 | validation: 0.25637594370587413]
	TIME [epoch: 9.04 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1917609443782176		[learning rate: 0.0025608]
	Learning Rate: 0.00256075
	LOSS [training: 0.1917609443782176 | validation: 0.16029497799435113]
	TIME [epoch: 9.06 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15541832999925942		[learning rate: 0.0025487]
	Learning Rate: 0.00254875
	LOSS [training: 0.15541832999925942 | validation: 0.14784554111938192]
	TIME [epoch: 9.07 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11676037974663603		[learning rate: 0.0025368]
	Learning Rate: 0.0025368
	LOSS [training: 0.11676037974663603 | validation: 0.1562457803327421]
	TIME [epoch: 9.05 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19741106425362925		[learning rate: 0.0025249]
	Learning Rate: 0.0025249
	LOSS [training: 0.19741106425362925 | validation: 0.16821944466236938]
	TIME [epoch: 9.05 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13707223155116569		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.13707223155116569 | validation: 0.19907288625007707]
	TIME [epoch: 9.06 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2058270966924404		[learning rate: 0.0025013]
	Learning Rate: 0.00250129
	LOSS [training: 0.2058270966924404 | validation: 0.13851248818245582]
	TIME [epoch: 9.08 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18639743266715075		[learning rate: 0.0024896]
	Learning Rate: 0.00248956
	LOSS [training: 0.18639743266715075 | validation: 0.17270002903381404]
	TIME [epoch: 9.06 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14457149056751056		[learning rate: 0.0024779]
	Learning Rate: 0.00247789
	LOSS [training: 0.14457149056751056 | validation: 0.13371542203744732]
	TIME [epoch: 9.05 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14711392470173307		[learning rate: 0.0024663]
	Learning Rate: 0.00246627
	LOSS [training: 0.14711392470173307 | validation: 0.17078210739364383]
	TIME [epoch: 9.06 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1572898318319841		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.1572898318319841 | validation: 0.14953710792083091]
	TIME [epoch: 9.06 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14647487808164442		[learning rate: 0.0024432]
	Learning Rate: 0.0024432
	LOSS [training: 0.14647487808164442 | validation: 0.1913478443300165]
	TIME [epoch: 9.08 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19056240669501295		[learning rate: 0.0024317]
	Learning Rate: 0.00243175
	LOSS [training: 0.19056240669501295 | validation: 0.1689660322865453]
	TIME [epoch: 9.06 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17090347811469778		[learning rate: 0.0024203]
	Learning Rate: 0.00242035
	LOSS [training: 0.17090347811469778 | validation: 0.23826031274001924]
	TIME [epoch: 9.06 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17215799381232738		[learning rate: 0.002409]
	Learning Rate: 0.002409
	LOSS [training: 0.17215799381232738 | validation: 0.11740507405487638]
	TIME [epoch: 9.05 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1626923407115342		[learning rate: 0.0023977]
	Learning Rate: 0.00239771
	LOSS [training: 0.1626923407115342 | validation: 0.12381617835260678]
	TIME [epoch: 9.08 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1802265702268711		[learning rate: 0.0023865]
	Learning Rate: 0.00238647
	LOSS [training: 0.1802265702268711 | validation: 0.13006593354953244]
	TIME [epoch: 9.06 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19383374909946044		[learning rate: 0.0023753]
	Learning Rate: 0.00237528
	LOSS [training: 0.19383374909946044 | validation: 0.12429069692206188]
	TIME [epoch: 9.05 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23321699183613345		[learning rate: 0.0023641]
	Learning Rate: 0.00236414
	LOSS [training: 0.23321699183613345 | validation: 0.1620722110336718]
	TIME [epoch: 9.05 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17589022101858187		[learning rate: 0.0023531]
	Learning Rate: 0.00235306
	LOSS [training: 0.17589022101858187 | validation: 0.24901847706899666]
	TIME [epoch: 9.06 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19706338475030785		[learning rate: 0.002342]
	Learning Rate: 0.00234203
	LOSS [training: 0.19706338475030785 | validation: 0.17225316337575347]
	TIME [epoch: 9.08 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17597837626135174		[learning rate: 0.002331]
	Learning Rate: 0.00233105
	LOSS [training: 0.17597837626135174 | validation: 0.2838064875344958]
	TIME [epoch: 9.06 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1827328206377526		[learning rate: 0.0023201]
	Learning Rate: 0.00232012
	LOSS [training: 0.1827328206377526 | validation: 0.19072377818475483]
	TIME [epoch: 9.07 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20451409332386064		[learning rate: 0.0023092]
	Learning Rate: 0.00230924
	LOSS [training: 0.20451409332386064 | validation: 0.14072755980710405]
	TIME [epoch: 9.06 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14828378886597235		[learning rate: 0.0022984]
	Learning Rate: 0.00229842
	LOSS [training: 0.14828378886597235 | validation: 0.17307890175684904]
	TIME [epoch: 9.07 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16894992456038987		[learning rate: 0.0022876]
	Learning Rate: 0.00228764
	LOSS [training: 0.16894992456038987 | validation: 0.16116890564508354]
	TIME [epoch: 9.08 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16346281417666117		[learning rate: 0.0022769]
	Learning Rate: 0.00227692
	LOSS [training: 0.16346281417666117 | validation: 0.17028694832565416]
	TIME [epoch: 9.07 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16659188073473732		[learning rate: 0.0022662]
	Learning Rate: 0.00226624
	LOSS [training: 0.16659188073473732 | validation: 0.16181471546806026]
	TIME [epoch: 9.07 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15195045435040413		[learning rate: 0.0022556]
	Learning Rate: 0.00225562
	LOSS [training: 0.15195045435040413 | validation: 0.20907166909013]
	TIME [epoch: 9.06 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15616292433295012		[learning rate: 0.002245]
	Learning Rate: 0.00224504
	LOSS [training: 0.15616292433295012 | validation: 0.16114105995711336]
	TIME [epoch: 9.08 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16448679972208347		[learning rate: 0.0022345]
	Learning Rate: 0.00223452
	LOSS [training: 0.16448679972208347 | validation: 0.2687231624621236]
	TIME [epoch: 9.06 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17374419860423482		[learning rate: 0.002224]
	Learning Rate: 0.00222404
	LOSS [training: 0.17374419860423482 | validation: 0.18211518085189937]
	TIME [epoch: 9.06 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13290218724143096		[learning rate: 0.0022136]
	Learning Rate: 0.00221361
	LOSS [training: 0.13290218724143096 | validation: 0.07633057705875688]
	TIME [epoch: 9.06 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10264993570725867		[learning rate: 0.0022032]
	Learning Rate: 0.00220324
	LOSS [training: 0.10264993570725867 | validation: 0.07545499815047173]
	TIME [epoch: 9.06 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16734455628276051		[learning rate: 0.0021929]
	Learning Rate: 0.00219291
	LOSS [training: 0.16734455628276051 | validation: 0.1842455051045277]
	TIME [epoch: 9.08 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13210172854302465		[learning rate: 0.0021826]
	Learning Rate: 0.00218263
	LOSS [training: 0.13210172854302465 | validation: 0.15743256835885083]
	TIME [epoch: 9.06 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14593304201475404		[learning rate: 0.0021724]
	Learning Rate: 0.00217239
	LOSS [training: 0.14593304201475404 | validation: 0.17802228354702793]
	TIME [epoch: 9.05 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1750355104760977		[learning rate: 0.0021622]
	Learning Rate: 0.00216221
	LOSS [training: 0.1750355104760977 | validation: 0.23293441283566896]
	TIME [epoch: 9.06 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15435535895008923		[learning rate: 0.0021521]
	Learning Rate: 0.00215207
	LOSS [training: 0.15435535895008923 | validation: 0.28073234665117686]
	TIME [epoch: 9.08 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/10] avg loss: 0.222703846080535		[learning rate: 0.002142]
	Learning Rate: 0.00214198
	LOSS [training: 0.222703846080535 | validation: 0.16063410916614432]
	TIME [epoch: 9.06 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10686698212739525		[learning rate: 0.0021319]
	Learning Rate: 0.00213194
	LOSS [training: 0.10686698212739525 | validation: 0.09677415844868514]
	TIME [epoch: 9.06 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11750252570960071		[learning rate: 0.0021219]
	Learning Rate: 0.00212195
	LOSS [training: 0.11750252570960071 | validation: 0.15250527626552507]
	TIME [epoch: 9.06 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/10] avg loss: 0.142958111729866		[learning rate: 0.002112]
	Learning Rate: 0.002112
	LOSS [training: 0.142958111729866 | validation: 0.18571334478453838]
	TIME [epoch: 9.06 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15035587600853334		[learning rate: 0.0021021]
	Learning Rate: 0.0021021
	LOSS [training: 0.15035587600853334 | validation: 0.15835088678078446]
	TIME [epoch: 9.08 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14088198893830298		[learning rate: 0.0020922]
	Learning Rate: 0.00209224
	LOSS [training: 0.14088198893830298 | validation: 0.12071668935169295]
	TIME [epoch: 9.06 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1000845780530318		[learning rate: 0.0020824]
	Learning Rate: 0.00208243
	LOSS [training: 0.1000845780530318 | validation: 0.15628055548026332]
	TIME [epoch: 9.06 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17304405416183624		[learning rate: 0.0020727]
	Learning Rate: 0.00207267
	LOSS [training: 0.17304405416183624 | validation: 0.1639936739017679]
	TIME [epoch: 9.06 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/10] avg loss: 0.126423241329142		[learning rate: 0.002063]
	Learning Rate: 0.00206295
	LOSS [training: 0.126423241329142 | validation: 0.07493090425129556]
	TIME [epoch: 9.07 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10131018591493987		[learning rate: 0.0020533]
	Learning Rate: 0.00205328
	LOSS [training: 0.10131018591493987 | validation: 0.1731787843436084]
	TIME [epoch: 9.07 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12106451455418683		[learning rate: 0.0020437]
	Learning Rate: 0.00204366
	LOSS [training: 0.12106451455418683 | validation: 0.1277069976895594]
	TIME [epoch: 9.05 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09776996269302662		[learning rate: 0.0020341]
	Learning Rate: 0.00203408
	LOSS [training: 0.09776996269302662 | validation: 0.09641152238116621]
	TIME [epoch: 9.06 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1186589111437569		[learning rate: 0.0020245]
	Learning Rate: 0.00202454
	LOSS [training: 0.1186589111437569 | validation: 0.13310715475909335]
	TIME [epoch: 9.05 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13254769988051324		[learning rate: 0.002015]
	Learning Rate: 0.00201505
	LOSS [training: 0.13254769988051324 | validation: 0.1245052567553582]
	TIME [epoch: 9.08 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11448725131346674		[learning rate: 0.0020056]
	Learning Rate: 0.0020056
	LOSS [training: 0.11448725131346674 | validation: 0.10540609834351872]
	TIME [epoch: 9.06 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1285567513121379		[learning rate: 0.0019962]
	Learning Rate: 0.0019962
	LOSS [training: 0.1285567513121379 | validation: 0.1355909989664003]
	TIME [epoch: 9.06 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13857435146162833		[learning rate: 0.0019868]
	Learning Rate: 0.00198684
	LOSS [training: 0.13857435146162833 | validation: 0.1628779673012667]
	TIME [epoch: 9.06 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1287128941842916		[learning rate: 0.0019775]
	Learning Rate: 0.00197753
	LOSS [training: 0.1287128941842916 | validation: 0.14900662485184826]
	TIME [epoch: 9.06 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17751391518186008		[learning rate: 0.0019683]
	Learning Rate: 0.00196826
	LOSS [training: 0.17751391518186008 | validation: 0.25415963079285386]
	TIME [epoch: 9.08 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1325391817646248		[learning rate: 0.001959]
	Learning Rate: 0.00195903
	LOSS [training: 0.1325391817646248 | validation: 0.07656310684292525]
	TIME [epoch: 9.05 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13820665346278568		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.13820665346278568 | validation: 0.31051258861610603]
	TIME [epoch: 9.06 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20371136547177887		[learning rate: 0.0019407]
	Learning Rate: 0.0019407
	LOSS [training: 0.20371136547177887 | validation: 0.11818575438756385]
	TIME [epoch: 9.07 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12020246574372195		[learning rate: 0.0019316]
	Learning Rate: 0.00193161
	LOSS [training: 0.12020246574372195 | validation: 0.17217892096698428]
	TIME [epoch: 9.08 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18459737417161126		[learning rate: 0.0019225]
	Learning Rate: 0.00192255
	LOSS [training: 0.18459737417161126 | validation: 0.2966831588993206]
	TIME [epoch: 9.07 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8700475447269465		[learning rate: 0.0019135]
	Learning Rate: 0.00191354
	LOSS [training: 0.8700475447269465 | validation: 1.013532039634161]
	TIME [epoch: 9.06 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/10] avg loss: 0.565929615556687		[learning rate: 0.0019046]
	Learning Rate: 0.00190457
	LOSS [training: 0.565929615556687 | validation: 0.5405232818106318]
	TIME [epoch: 9.05 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4379723639563591		[learning rate: 0.0018956]
	Learning Rate: 0.00189564
	LOSS [training: 0.4379723639563591 | validation: 0.2984313899890638]
	TIME [epoch: 9.06 sec]
EPOCH 365/500:
	Training over batches...
		[batch 10/10] avg loss: 0.293287428388021		[learning rate: 0.0018867]
	Learning Rate: 0.00188675
	LOSS [training: 0.293287428388021 | validation: 0.37205683179519833]
	TIME [epoch: 9.07 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37197836565096		[learning rate: 0.0018779]
	Learning Rate: 0.0018779
	LOSS [training: 0.37197836565096 | validation: 0.24227946222271873]
	TIME [epoch: 9.06 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18103054263090257		[learning rate: 0.0018691]
	Learning Rate: 0.0018691
	LOSS [training: 0.18103054263090257 | validation: 0.15851173456100906]
	TIME [epoch: 9.04 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13312884216457982		[learning rate: 0.0018603]
	Learning Rate: 0.00186034
	LOSS [training: 0.13312884216457982 | validation: 0.10479427996819674]
	TIME [epoch: 9.04 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10261502816061854		[learning rate: 0.0018516]
	Learning Rate: 0.00185162
	LOSS [training: 0.10261502816061854 | validation: 0.1015024617722295]
	TIME [epoch: 9.07 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08923555639835551		[learning rate: 0.0018429]
	Learning Rate: 0.00184294
	LOSS [training: 0.08923555639835551 | validation: 0.0605246414087285]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_370.pth
	Model improved!!!
EPOCH 371/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06042586951256507		[learning rate: 0.0018343]
	Learning Rate: 0.0018343
	LOSS [training: 0.06042586951256507 | validation: 0.0731077632264025]
	TIME [epoch: 9.06 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10134033442403041		[learning rate: 0.0018257]
	Learning Rate: 0.0018257
	LOSS [training: 0.10134033442403041 | validation: 0.12803674184292604]
	TIME [epoch: 9.05 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08212778227466813		[learning rate: 0.0018171]
	Learning Rate: 0.00181714
	LOSS [training: 0.08212778227466813 | validation: 0.09052854879056035]
	TIME [epoch: 9.05 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1208755754783489		[learning rate: 0.0018086]
	Learning Rate: 0.00180862
	LOSS [training: 0.1208755754783489 | validation: 0.11222084969750128]
	TIME [epoch: 9.07 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11028427297077392		[learning rate: 0.0018001]
	Learning Rate: 0.00180014
	LOSS [training: 0.11028427297077392 | validation: 0.07882945459969787]
	TIME [epoch: 9.05 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06425110228686368		[learning rate: 0.0017917]
	Learning Rate: 0.0017917
	LOSS [training: 0.06425110228686368 | validation: 0.07958982067683726]
	TIME [epoch: 9.05 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09500509996581846		[learning rate: 0.0017833]
	Learning Rate: 0.0017833
	LOSS [training: 0.09500509996581846 | validation: 0.09283973464373985]
	TIME [epoch: 9.05 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0590475241098394		[learning rate: 0.0017749]
	Learning Rate: 0.00177494
	LOSS [training: 0.0590475241098394 | validation: 0.07944036620304404]
	TIME [epoch: 9.05 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11755706617647052		[learning rate: 0.0017666]
	Learning Rate: 0.00176662
	LOSS [training: 0.11755706617647052 | validation: 0.10575910584663849]
	TIME [epoch: 9.07 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18416537180224482		[learning rate: 0.0017583]
	Learning Rate: 0.00175834
	LOSS [training: 0.18416537180224482 | validation: 0.21468399924272438]
	TIME [epoch: 9.05 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16897520220146056		[learning rate: 0.0017501]
	Learning Rate: 0.00175009
	LOSS [training: 0.16897520220146056 | validation: 0.09913076926234554]
	TIME [epoch: 9.05 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09053803928197719		[learning rate: 0.0017419]
	Learning Rate: 0.00174189
	LOSS [training: 0.09053803928197719 | validation: 0.06188231425559613]
	TIME [epoch: 9.05 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23995965709024167		[learning rate: 0.0017337]
	Learning Rate: 0.00173372
	LOSS [training: 0.23995965709024167 | validation: 0.18867307381504606]
	TIME [epoch: 9.07 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33257539870378416		[learning rate: 0.0017256]
	Learning Rate: 0.00172559
	LOSS [training: 0.33257539870378416 | validation: 0.19705122100291522]
	TIME [epoch: 9.05 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22278596321879177		[learning rate: 0.0017175]
	Learning Rate: 0.0017175
	LOSS [training: 0.22278596321879177 | validation: 0.14860978982953443]
	TIME [epoch: 9.05 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1299289800883937		[learning rate: 0.0017095]
	Learning Rate: 0.00170945
	LOSS [training: 0.1299289800883937 | validation: 0.13144278571970316]
	TIME [epoch: 9.06 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11434022653329604		[learning rate: 0.0017014]
	Learning Rate: 0.00170144
	LOSS [training: 0.11434022653329604 | validation: 0.04208367345157978]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_387.pth
	Model improved!!!
EPOCH 388/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06845451338335513		[learning rate: 0.0016935]
	Learning Rate: 0.00169346
	LOSS [training: 0.06845451338335513 | validation: 0.09601844349606659]
	TIME [epoch: 9.1 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1468277175919554		[learning rate: 0.0016855]
	Learning Rate: 0.00168552
	LOSS [training: 0.1468277175919554 | validation: 0.1851972920504165]
	TIME [epoch: 9.06 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08692469982493257		[learning rate: 0.0016776]
	Learning Rate: 0.00167762
	LOSS [training: 0.08692469982493257 | validation: 0.06543785753303841]
	TIME [epoch: 9.08 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06009271747589932		[learning rate: 0.0016698]
	Learning Rate: 0.00166976
	LOSS [training: 0.06009271747589932 | validation: 0.11870027663486638]
	TIME [epoch: 9.07 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05807335716674374		[learning rate: 0.0016619]
	Learning Rate: 0.00166193
	LOSS [training: 0.05807335716674374 | validation: 0.047019299053472824]
	TIME [epoch: 9.08 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04875938024004135		[learning rate: 0.0016541]
	Learning Rate: 0.00165414
	LOSS [training: 0.04875938024004135 | validation: 0.056211481024389956]
	TIME [epoch: 9.1 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/10] avg loss: 0.052247164547901626		[learning rate: 0.0016464]
	Learning Rate: 0.00164638
	LOSS [training: 0.052247164547901626 | validation: 0.06708947971201636]
	TIME [epoch: 9.07 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09150913341054719		[learning rate: 0.0016387]
	Learning Rate: 0.00163866
	LOSS [training: 0.09150913341054719 | validation: 0.09491785526157917]
	TIME [epoch: 9.06 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08218588223989291		[learning rate: 0.001631]
	Learning Rate: 0.00163098
	LOSS [training: 0.08218588223989291 | validation: 0.10062465650863689]
	TIME [epoch: 9.06 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0649028199460284		[learning rate: 0.0016233]
	Learning Rate: 0.00162333
	LOSS [training: 0.0649028199460284 | validation: 0.08101444938429403]
	TIME [epoch: 9.09 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11010848532587078		[learning rate: 0.0016157]
	Learning Rate: 0.00161572
	LOSS [training: 0.11010848532587078 | validation: 0.1754454668920996]
	TIME [epoch: 9.05 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09179009914642566		[learning rate: 0.0016081]
	Learning Rate: 0.00160815
	LOSS [training: 0.09179009914642566 | validation: 0.1480479155474514]
	TIME [epoch: 9.06 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0769485138379176		[learning rate: 0.0016006]
	Learning Rate: 0.00160061
	LOSS [training: 0.0769485138379176 | validation: 0.08972768706967707]
	TIME [epoch: 9.05 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08570862023792261		[learning rate: 0.0015931]
	Learning Rate: 0.00159311
	LOSS [training: 0.08570862023792261 | validation: 0.09749503027922837]
	TIME [epoch: 9.06 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09240431168737151		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.09240431168737151 | validation: 0.12550713102902686]
	TIME [epoch: 9.09 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08056193001891883		[learning rate: 0.0015782]
	Learning Rate: 0.0015782
	LOSS [training: 0.08056193001891883 | validation: 0.056268884737070965]
	TIME [epoch: 9.08 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/10] avg loss: 0.065194196180475		[learning rate: 0.0015708]
	Learning Rate: 0.00157081
	LOSS [training: 0.065194196180475 | validation: 0.0815573613433401]
	TIME [epoch: 9.06 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07294913414914492		[learning rate: 0.0015634]
	Learning Rate: 0.00156344
	LOSS [training: 0.07294913414914492 | validation: 0.07005498338768078]
	TIME [epoch: 9.07 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08835375910701591		[learning rate: 0.0015561]
	Learning Rate: 0.00155611
	LOSS [training: 0.08835375910701591 | validation: 0.08430351793112102]
	TIME [epoch: 9.08 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08437095973374428		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.08437095973374428 | validation: 0.0909122846884436]
	TIME [epoch: 9.07 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05414398092804409		[learning rate: 0.0015416]
	Learning Rate: 0.00154156
	LOSS [training: 0.05414398092804409 | validation: 0.0782917020863288]
	TIME [epoch: 9.07 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06773593675363763		[learning rate: 0.0015343]
	Learning Rate: 0.00153433
	LOSS [training: 0.06773593675363763 | validation: 0.07726651606977328]
	TIME [epoch: 9.06 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/10] avg loss: 0.076719204663206		[learning rate: 0.0015271]
	Learning Rate: 0.00152714
	LOSS [training: 0.076719204663206 | validation: 0.07090231111618168]
	TIME [epoch: 9.05 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06492748118933743		[learning rate: 0.00152]
	Learning Rate: 0.00151998
	LOSS [training: 0.06492748118933743 | validation: 0.06507347568811422]
	TIME [epoch: 9.08 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04147796231211981		[learning rate: 0.0015129]
	Learning Rate: 0.00151285
	LOSS [training: 0.04147796231211981 | validation: 0.04738200800378639]
	TIME [epoch: 9.05 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07346722255158802		[learning rate: 0.0015058]
	Learning Rate: 0.00150576
	LOSS [training: 0.07346722255158802 | validation: 0.08433710028324527]
	TIME [epoch: 9.05 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/10] avg loss: 0.058099372075828624		[learning rate: 0.0014987]
	Learning Rate: 0.0014987
	LOSS [training: 0.058099372075828624 | validation: 0.05933380462331478]
	TIME [epoch: 9.06 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07921596609009214		[learning rate: 0.0014917]
	Learning Rate: 0.00149167
	LOSS [training: 0.07921596609009214 | validation: 0.07073550558194285]
	TIME [epoch: 9.06 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06285997563964194		[learning rate: 0.0014847]
	Learning Rate: 0.00148468
	LOSS [training: 0.06285997563964194 | validation: 0.06672643634048245]
	TIME [epoch: 9.06 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10985174727533523		[learning rate: 0.0014777]
	Learning Rate: 0.00147772
	LOSS [training: 0.10985174727533523 | validation: 0.15128329854888412]
	TIME [epoch: 9.05 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10247165088967877		[learning rate: 0.0014708]
	Learning Rate: 0.00147079
	LOSS [training: 0.10247165088967877 | validation: 0.13755723862643837]
	TIME [epoch: 9.06 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09561456236234847		[learning rate: 0.0014639]
	Learning Rate: 0.0014639
	LOSS [training: 0.09561456236234847 | validation: 0.13433236234178136]
	TIME [epoch: 9.06 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09991948717759631		[learning rate: 0.001457]
	Learning Rate: 0.00145703
	LOSS [training: 0.09991948717759631 | validation: 0.08621905171072794]
	TIME [epoch: 9.08 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06501207562133426		[learning rate: 0.0014502]
	Learning Rate: 0.0014502
	LOSS [training: 0.06501207562133426 | validation: 0.07078062879296526]
	TIME [epoch: 9.06 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12654637074686031		[learning rate: 0.0014434]
	Learning Rate: 0.0014434
	LOSS [training: 0.12654637074686031 | validation: 0.08465088288953629]
	TIME [epoch: 9.05 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08879806120148212		[learning rate: 0.0014366]
	Learning Rate: 0.00143664
	LOSS [training: 0.08879806120148212 | validation: 0.19072146123248127]
	TIME [epoch: 9.06 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07905886012607452		[learning rate: 0.0014299]
	Learning Rate: 0.0014299
	LOSS [training: 0.07905886012607452 | validation: 0.1021147606907784]
	TIME [epoch: 9.05 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08326227838097311		[learning rate: 0.0014232]
	Learning Rate: 0.0014232
	LOSS [training: 0.08326227838097311 | validation: 0.11409809666658977]
	TIME [epoch: 9.08 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10270188409571254		[learning rate: 0.0014165]
	Learning Rate: 0.00141653
	LOSS [training: 0.10270188409571254 | validation: 0.12463365185444415]
	TIME [epoch: 9.05 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09879156475458509		[learning rate: 0.0014099]
	Learning Rate: 0.00140989
	LOSS [training: 0.09879156475458509 | validation: 0.06117189587050323]
	TIME [epoch: 9.05 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/10] avg loss: 0.061350661074018244		[learning rate: 0.0014033]
	Learning Rate: 0.00140328
	LOSS [training: 0.061350661074018244 | validation: 0.05657107898572671]
	TIME [epoch: 9.05 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06945830211775013		[learning rate: 0.0013967]
	Learning Rate: 0.0013967
	LOSS [training: 0.06945830211775013 | validation: 0.07118420766038558]
	TIME [epoch: 9.07 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0611897136895055		[learning rate: 0.0013901]
	Learning Rate: 0.00139015
	LOSS [training: 0.0611897136895055 | validation: 0.06977930879435205]
	TIME [epoch: 9.07 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10690501181270869		[learning rate: 0.0013836]
	Learning Rate: 0.00138363
	LOSS [training: 0.10690501181270869 | validation: 0.0759820435212189]
	TIME [epoch: 9.05 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0857937471060271		[learning rate: 0.0013771]
	Learning Rate: 0.00137714
	LOSS [training: 0.0857937471060271 | validation: 0.05283627948398782]
	TIME [epoch: 9.05 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0680917174830102		[learning rate: 0.0013707]
	Learning Rate: 0.00137069
	LOSS [training: 0.0680917174830102 | validation: 0.0476775698819319]
	TIME [epoch: 9.05 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05467241043858005		[learning rate: 0.0013643]
	Learning Rate: 0.00136426
	LOSS [training: 0.05467241043858005 | validation: 0.1110887618751131]
	TIME [epoch: 9.06 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07781282638679012		[learning rate: 0.0013579]
	Learning Rate: 0.00135787
	LOSS [training: 0.07781282638679012 | validation: 0.09777723087359641]
	TIME [epoch: 9.05 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09716158279120841		[learning rate: 0.0013515]
	Learning Rate: 0.0013515
	LOSS [training: 0.09716158279120841 | validation: 0.11495284619290963]
	TIME [epoch: 9.05 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08610891465076516		[learning rate: 0.0013452]
	Learning Rate: 0.00134516
	LOSS [training: 0.08610891465076516 | validation: 0.0963748884847947]
	TIME [epoch: 9.06 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07874684848878857		[learning rate: 0.0013389]
	Learning Rate: 0.00133886
	LOSS [training: 0.07874684848878857 | validation: 0.09954789677423481]
	TIME [epoch: 9.07 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07930854599890659		[learning rate: 0.0013326]
	Learning Rate: 0.00133258
	LOSS [training: 0.07930854599890659 | validation: 0.08147233972712395]
	TIME [epoch: 9.07 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/10] avg loss: 0.059225484604238175		[learning rate: 0.0013263]
	Learning Rate: 0.00132633
	LOSS [training: 0.059225484604238175 | validation: 0.06250348218328214]
	TIME [epoch: 9.06 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06097534952834599		[learning rate: 0.0013201]
	Learning Rate: 0.00132012
	LOSS [training: 0.06097534952834599 | validation: 0.07090684269364207]
	TIME [epoch: 9.06 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/10] avg loss: 0.058961799782654624		[learning rate: 0.0013139]
	Learning Rate: 0.00131393
	LOSS [training: 0.058961799782654624 | validation: 0.062490501430478615]
	TIME [epoch: 9.05 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06522037263542106		[learning rate: 0.0013078]
	Learning Rate: 0.00130777
	LOSS [training: 0.06522037263542106 | validation: 0.05115413127103217]
	TIME [epoch: 9.08 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/10] avg loss: 0.106150531137153		[learning rate: 0.0013016]
	Learning Rate: 0.00130164
	LOSS [training: 0.106150531137153 | validation: 0.13390090690103584]
	TIME [epoch: 9.06 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08190094652725446		[learning rate: 0.0012955]
	Learning Rate: 0.00129553
	LOSS [training: 0.08190094652725446 | validation: 0.0676152777220281]
	TIME [epoch: 9.05 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04978393575746031		[learning rate: 0.0012895]
	Learning Rate: 0.00128946
	LOSS [training: 0.04978393575746031 | validation: 0.06217916986491977]
	TIME [epoch: 9.05 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08301047502947997		[learning rate: 0.0012834]
	Learning Rate: 0.00128342
	LOSS [training: 0.08301047502947997 | validation: 0.06069101845772322]
	TIME [epoch: 9.06 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07488806573128183		[learning rate: 0.0012774]
	Learning Rate: 0.0012774
	LOSS [training: 0.07488806573128183 | validation: 0.09848408791589253]
	TIME [epoch: 9.09 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06931334379535066		[learning rate: 0.0012714]
	Learning Rate: 0.00127141
	LOSS [training: 0.06931334379535066 | validation: 0.08389960308050898]
	TIME [epoch: 9.05 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07477899477227871		[learning rate: 0.0012654]
	Learning Rate: 0.00126545
	LOSS [training: 0.07477899477227871 | validation: 0.08388655154753716]
	TIME [epoch: 9.05 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07907312565143595		[learning rate: 0.0012595]
	Learning Rate: 0.00125952
	LOSS [training: 0.07907312565143595 | validation: 0.07413644731093244]
	TIME [epoch: 9.05 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07659101551216382		[learning rate: 0.0012536]
	Learning Rate: 0.00125361
	LOSS [training: 0.07659101551216382 | validation: 0.0690282271193144]
	TIME [epoch: 9.1 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06612936729530053		[learning rate: 0.0012477]
	Learning Rate: 0.00124774
	LOSS [training: 0.06612936729530053 | validation: 0.09051514207257208]
	TIME [epoch: 9.06 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1028097113941677		[learning rate: 0.0012419]
	Learning Rate: 0.00124189
	LOSS [training: 0.1028097113941677 | validation: 0.12985723352626866]
	TIME [epoch: 9.05 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08395671561202576		[learning rate: 0.0012361]
	Learning Rate: 0.00123606
	LOSS [training: 0.08395671561202576 | validation: 0.12061591850490835]
	TIME [epoch: 9.05 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07411171784278205		[learning rate: 0.0012303]
	Learning Rate: 0.00123027
	LOSS [training: 0.07411171784278205 | validation: 0.08145107642576951]
	TIME [epoch: 9.04 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07150445720538814		[learning rate: 0.0012245]
	Learning Rate: 0.0012245
	LOSS [training: 0.07150445720538814 | validation: 0.09558751863551895]
	TIME [epoch: 9.07 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10149798045672367		[learning rate: 0.0012188]
	Learning Rate: 0.00121876
	LOSS [training: 0.10149798045672367 | validation: 0.162733340003874]
	TIME [epoch: 9.05 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18540751767735192		[learning rate: 0.001213]
	Learning Rate: 0.00121305
	LOSS [training: 0.18540751767735192 | validation: 0.1076773875193634]
	TIME [epoch: 9.04 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10036257976994083		[learning rate: 0.0012074]
	Learning Rate: 0.00120736
	LOSS [training: 0.10036257976994083 | validation: 0.09337059878611689]
	TIME [epoch: 9.06 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08608768709309733		[learning rate: 0.0012017]
	Learning Rate: 0.0012017
	LOSS [training: 0.08608768709309733 | validation: 0.10875346143381266]
	TIME [epoch: 9.06 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0688317758426691		[learning rate: 0.0011961]
	Learning Rate: 0.00119607
	LOSS [training: 0.0688317758426691 | validation: 0.13217881743158702]
	TIME [epoch: 9.06 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12299669785076559		[learning rate: 0.0011905]
	Learning Rate: 0.00119046
	LOSS [training: 0.12299669785076559 | validation: 0.19957917833639677]
	TIME [epoch: 9.05 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1374166866966537		[learning rate: 0.0011849]
	Learning Rate: 0.00118488
	LOSS [training: 0.1374166866966537 | validation: 0.11397099368045038]
	TIME [epoch: 9.05 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06987160567841463		[learning rate: 0.0011793]
	Learning Rate: 0.00117932
	LOSS [training: 0.06987160567841463 | validation: 0.13258118115500875]
	TIME [epoch: 9.05 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06510822712924251		[learning rate: 0.0011738]
	Learning Rate: 0.00117379
	LOSS [training: 0.06510822712924251 | validation: 0.0620291418170652]
	TIME [epoch: 9.07 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08286616780653237		[learning rate: 0.0011683]
	Learning Rate: 0.00116829
	LOSS [training: 0.08286616780653237 | validation: 0.09753580405962556]
	TIME [epoch: 9.05 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07523897937402074		[learning rate: 0.0011628]
	Learning Rate: 0.00116281
	LOSS [training: 0.07523897937402074 | validation: 0.08776286520744553]
	TIME [epoch: 9.05 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08476714970795746		[learning rate: 0.0011574]
	Learning Rate: 0.00115736
	LOSS [training: 0.08476714970795746 | validation: 0.10876198557683489]
	TIME [epoch: 9.05 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08937605510566059		[learning rate: 0.0011519]
	Learning Rate: 0.00115194
	LOSS [training: 0.08937605510566059 | validation: 0.0549335127560389]
	TIME [epoch: 9.06 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07909418838643545		[learning rate: 0.0011465]
	Learning Rate: 0.00114654
	LOSS [training: 0.07909418838643545 | validation: 0.1707318929421029]
	TIME [epoch: 9.09 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10035588972030174		[learning rate: 0.0011412]
	Learning Rate: 0.00114116
	LOSS [training: 0.10035588972030174 | validation: 0.07574134512667696]
	TIME [epoch: 9.06 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05814243598061788		[learning rate: 0.0011358]
	Learning Rate: 0.00113581
	LOSS [training: 0.05814243598061788 | validation: 0.06099301446397212]
	TIME [epoch: 9.05 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13523832766744429		[learning rate: 0.0011305]
	Learning Rate: 0.00113049
	LOSS [training: 0.13523832766744429 | validation: 0.21343868696964183]
	TIME [epoch: 9.05 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1253329177005578		[learning rate: 0.0011252]
	Learning Rate: 0.00112519
	LOSS [training: 0.1253329177005578 | validation: 0.11044466937990147]
	TIME [epoch: 9.06 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/10] avg loss: 0.054664360214389626		[learning rate: 0.0011199]
	Learning Rate: 0.00111991
	LOSS [training: 0.054664360214389626 | validation: 0.05962575525418705]
	TIME [epoch: 9.07 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05904440864661129		[learning rate: 0.0011147]
	Learning Rate: 0.00111466
	LOSS [training: 0.05904440864661129 | validation: 0.07422891430421297]
	TIME [epoch: 9.06 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04829197143618498		[learning rate: 0.0011094]
	Learning Rate: 0.00110944
	LOSS [training: 0.04829197143618498 | validation: 0.0406566011545172]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240214_184914/states/model_tr_study4_478.pth
	Model improved!!!
EPOCH 479/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04450861854338159		[learning rate: 0.0011042]
	Learning Rate: 0.00110423
	LOSS [training: 0.04450861854338159 | validation: 0.06941944187236498]
	TIME [epoch: 9.06 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/10] avg loss: 0.039544151662559555		[learning rate: 0.0010991]
	Learning Rate: 0.00109906
	LOSS [training: 0.039544151662559555 | validation: 0.05721511405720643]
	TIME [epoch: 9.09 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0487307074302631		[learning rate: 0.0010939]
	Learning Rate: 0.0010939
	LOSS [training: 0.0487307074302631 | validation: 0.08008658047223652]
	TIME [epoch: 9.06 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/10] avg loss: 0.055298714550904425		[learning rate: 0.0010888]
	Learning Rate: 0.00108878
	LOSS [training: 0.055298714550904425 | validation: 0.13273778087662644]
	TIME [epoch: 9.06 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0860105732252959		[learning rate: 0.0010837]
	Learning Rate: 0.00108367
	LOSS [training: 0.0860105732252959 | validation: 0.07197236527719089]
	TIME [epoch: 9.05 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06044140565606265		[learning rate: 0.0010786]
	Learning Rate: 0.00107859
	LOSS [training: 0.06044140565606265 | validation: 0.05364928490478098]
	TIME [epoch: 9.05 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/10] avg loss: 0.054788058500929125		[learning rate: 0.0010735]
	Learning Rate: 0.00107354
	LOSS [training: 0.054788058500929125 | validation: 0.0743532326319656]
	TIME [epoch: 9.08 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05318998118331042		[learning rate: 0.0010685]
	Learning Rate: 0.0010685
	LOSS [training: 0.05318998118331042 | validation: 0.049069651552532505]
	TIME [epoch: 9.05 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0395627368710266		[learning rate: 0.0010635]
	Learning Rate: 0.00106349
	LOSS [training: 0.0395627368710266 | validation: 0.0459396105276181]
	TIME [epoch: 9.05 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03673023745346663		[learning rate: 0.0010585]
	Learning Rate: 0.00105851
	LOSS [training: 0.03673023745346663 | validation: 0.05293684455458798]
	TIME [epoch: 9.05 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07006143173114912		[learning rate: 0.0010535]
	Learning Rate: 0.00105354
	LOSS [training: 0.07006143173114912 | validation: 0.08690091308363518]
	TIME [epoch: 9.07 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08424900818905372		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.08424900818905372 | validation: 0.13977304884942554]
	TIME [epoch: 9.05 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09560539978318823		[learning rate: 0.0010437]
	Learning Rate: 0.00104369
	LOSS [training: 0.09560539978318823 | validation: 0.07912082564488732]
	TIME [epoch: 9.06 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07760755161741248		[learning rate: 0.0010388]
	Learning Rate: 0.0010388
	LOSS [training: 0.07760755161741248 | validation: 0.08267560641659108]
	TIME [epoch: 9.06 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07370975778145564		[learning rate: 0.0010339]
	Learning Rate: 0.00103393
	LOSS [training: 0.07370975778145564 | validation: 0.09459969396853837]
	TIME [epoch: 9.06 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06107902112261154		[learning rate: 0.0010291]
	Learning Rate: 0.00102908
	LOSS [training: 0.06107902112261154 | validation: 0.06324524791702804]
	TIME [epoch: 9.08 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06104039102162884		[learning rate: 0.0010243]
	Learning Rate: 0.00102426
	LOSS [training: 0.06104039102162884 | validation: 0.06288411692773727]
	TIME [epoch: 9.07 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/10] avg loss: 0.040182205906465276		[learning rate: 0.0010195]
	Learning Rate: 0.00101945
	LOSS [training: 0.040182205906465276 | validation: 0.07902639991248629]
	TIME [epoch: 9.06 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/10] avg loss: 0.060613832244296506		[learning rate: 0.0010147]
	Learning Rate: 0.00101467
	LOSS [training: 0.060613832244296506 | validation: 0.05447647455768713]
	TIME [epoch: 9.06 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07068681560413828		[learning rate: 0.0010099]
	Learning Rate: 0.00100992
	LOSS [training: 0.07068681560413828 | validation: 0.05243321215958104]
	TIME [epoch: 9.06 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05826410812977041		[learning rate: 0.0010052]
	Learning Rate: 0.00100518
	LOSS [training: 0.05826410812977041 | validation: 0.05720111085123075]
	TIME [epoch: 9.07 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05274600644371823		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.05274600644371823 | validation: 0.08352307016230971]
	TIME [epoch: 9.05 sec]
Finished training in 4594.674 seconds.
