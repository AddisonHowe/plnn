Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r3', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1333592912

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/10] avg loss: 8.055975327712785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.055975327712785 | validation: 6.992956775774969]
	TIME [epoch: 48.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/10] avg loss: 6.992164721476792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.992164721476792 | validation: 6.478175610229375]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/10] avg loss: 6.121777170200746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.121777170200746 | validation: 5.772291812562099]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 10/10] avg loss: 5.947523691150927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.947523691150927 | validation: 5.780945457731061]
	TIME [epoch: 9.11 sec]
EPOCH 5/500:
	Training over batches...
		[batch 10/10] avg loss: 5.825767432571056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.825767432571056 | validation: 5.688467642147446]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 10/10] avg loss: 5.629690025822411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.629690025822411 | validation: 5.390364974401395]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/10] avg loss: 5.449604190852653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.449604190852653 | validation: 4.933106430720124]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 10/10] avg loss: 4.39531902847119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.39531902847119 | validation: 3.741436127803779]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 10/10] avg loss: 3.7233449696690735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7233449696690735 | validation: 3.238456169498446]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 10/10] avg loss: 3.3367961040353995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3367961040353995 | validation: 2.7677937229597402]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 10/10] avg loss: 2.6953019368684767		[learning rate: 0.0099578]
	Learning Rate: 0.0099578
	LOSS [training: 2.6953019368684767 | validation: 4.543018396664495]
	TIME [epoch: 9.19 sec]
EPOCH 12/500:
	Training over batches...
		[batch 10/10] avg loss: 3.7396705564818986		[learning rate: 0.0099111]
	Learning Rate: 0.00991111
	LOSS [training: 3.7396705564818986 | validation: 2.504296769192143]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 10/10] avg loss: 2.2469017142505776		[learning rate: 0.0098646]
	Learning Rate: 0.00986465
	LOSS [training: 2.2469017142505776 | validation: 2.08394632076536]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 10/10] avg loss: 1.9437336237494673		[learning rate: 0.0098184]
	Learning Rate: 0.0098184
	LOSS [training: 1.9437336237494673 | validation: 1.9616554214787174]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 10/10] avg loss: 1.8088065258409547		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 1.8088065258409547 | validation: 1.5728790994131212]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4541614129111118		[learning rate: 0.0097266]
	Learning Rate: 0.00972656
	LOSS [training: 1.4541614129111118 | validation: 1.2135885498865353]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4123742601210734		[learning rate: 0.009681]
	Learning Rate: 0.00968096
	LOSS [training: 1.4123742601210734 | validation: 1.0806467133797781]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0298023226407564		[learning rate: 0.0096356]
	Learning Rate: 0.00963557
	LOSS [training: 1.0298023226407564 | validation: 0.871037654928875]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9197103925021416		[learning rate: 0.0095904]
	Learning Rate: 0.0095904
	LOSS [training: 0.9197103925021416 | validation: 1.045561441400658]
	TIME [epoch: 9.19 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0028878600881304		[learning rate: 0.0095454]
	Learning Rate: 0.00954544
	LOSS [training: 1.0028878600881304 | validation: 0.7729063185640664]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8627577136711139		[learning rate: 0.0095007]
	Learning Rate: 0.00950069
	LOSS [training: 0.8627577136711139 | validation: 0.7373668226173671]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8082720424818037		[learning rate: 0.0094561]
	Learning Rate: 0.00945615
	LOSS [training: 0.8082720424818037 | validation: 0.8306242648237482]
	TIME [epoch: 9.18 sec]
EPOCH 23/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7419415014621219		[learning rate: 0.0094118]
	Learning Rate: 0.00941182
	LOSS [training: 0.7419415014621219 | validation: 0.5973904057438599]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6649603610941143		[learning rate: 0.0093677]
	Learning Rate: 0.00936769
	LOSS [training: 0.6649603610941143 | validation: 0.6376879601168954]
	TIME [epoch: 9.16 sec]
EPOCH 25/500:
	Training over batches...
		[batch 10/10] avg loss: 0.686866958676758		[learning rate: 0.0093238]
	Learning Rate: 0.00932378
	LOSS [training: 0.686866958676758 | validation: 0.6463745082578065]
	TIME [epoch: 9.17 sec]
EPOCH 26/500:
	Training over batches...
		[batch 10/10] avg loss: 2.287411007794205		[learning rate: 0.0092801]
	Learning Rate: 0.00928007
	LOSS [training: 2.287411007794205 | validation: 3.1285844295231877]
	TIME [epoch: 9.18 sec]
EPOCH 27/500:
	Training over batches...
		[batch 10/10] avg loss: 3.537206852795078		[learning rate: 0.0092366]
	Learning Rate: 0.00923656
	LOSS [training: 3.537206852795078 | validation: 3.0409418197055187]
	TIME [epoch: 9.19 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/10] avg loss: 3.3185237105780736		[learning rate: 0.0091933]
	Learning Rate: 0.00919326
	LOSS [training: 3.3185237105780736 | validation: 3.245081339495152]
	TIME [epoch: 9.19 sec]
EPOCH 29/500:
	Training over batches...
		[batch 10/10] avg loss: 1.521129733797454		[learning rate: 0.0091502]
	Learning Rate: 0.00915016
	LOSS [training: 1.521129733797454 | validation: 0.6496398610423486]
	TIME [epoch: 9.17 sec]
EPOCH 30/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8676614938485544		[learning rate: 0.0091073]
	Learning Rate: 0.00910726
	LOSS [training: 0.8676614938485544 | validation: 0.6376828487379367]
	TIME [epoch: 9.19 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6497441094189554		[learning rate: 0.0090646]
	Learning Rate: 0.00906456
	LOSS [training: 0.6497441094189554 | validation: 0.9412804217612463]
	TIME [epoch: 9.17 sec]
EPOCH 32/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6845044154352684		[learning rate: 0.0090221]
	Learning Rate: 0.00902207
	LOSS [training: 0.6845044154352684 | validation: 0.5457153969267063]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6670500531408956		[learning rate: 0.0089798]
	Learning Rate: 0.00897977
	LOSS [training: 0.6670500531408956 | validation: 0.5943515939843431]
	TIME [epoch: 9.19 sec]
EPOCH 34/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6073162006964963		[learning rate: 0.0089377]
	Learning Rate: 0.00893767
	LOSS [training: 0.6073162006964963 | validation: 0.5841149952257991]
	TIME [epoch: 9.19 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6104332437912541		[learning rate: 0.0088958]
	Learning Rate: 0.00889577
	LOSS [training: 0.6104332437912541 | validation: 0.7832547226183895]
	TIME [epoch: 9.19 sec]
EPOCH 36/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6487324724543		[learning rate: 0.0088541]
	Learning Rate: 0.00885407
	LOSS [training: 0.6487324724543 | validation: 0.6059595950324281]
	TIME [epoch: 9.19 sec]
EPOCH 37/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7502698040227843		[learning rate: 0.0088126]
	Learning Rate: 0.00881256
	LOSS [training: 0.7502698040227843 | validation: 0.510569647038265]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7245123667449722		[learning rate: 0.0087712]
	Learning Rate: 0.00877124
	LOSS [training: 0.7245123667449722 | validation: 0.48080618904748273]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6729011788113006		[learning rate: 0.0087301]
	Learning Rate: 0.00873012
	LOSS [training: 0.6729011788113006 | validation: 0.5921377767505733]
	TIME [epoch: 9.2 sec]
EPOCH 40/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5447377775323209		[learning rate: 0.0086892]
	Learning Rate: 0.00868919
	LOSS [training: 0.5447377775323209 | validation: 0.5334118888055227]
	TIME [epoch: 9.19 sec]
EPOCH 41/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6321039628050787		[learning rate: 0.0086485]
	Learning Rate: 0.00864846
	LOSS [training: 0.6321039628050787 | validation: 0.7070885088134766]
	TIME [epoch: 9.18 sec]
EPOCH 42/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6645198776370144		[learning rate: 0.0086079]
	Learning Rate: 0.00860791
	LOSS [training: 0.6645198776370144 | validation: 0.6047231250373741]
	TIME [epoch: 9.18 sec]
EPOCH 43/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5486334169196785		[learning rate: 0.0085676]
	Learning Rate: 0.00856756
	LOSS [training: 0.5486334169196785 | validation: 0.6534781747588876]
	TIME [epoch: 9.19 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5768760514647033		[learning rate: 0.0085274]
	Learning Rate: 0.00852739
	LOSS [training: 0.5768760514647033 | validation: 0.7021331267506832]
	TIME [epoch: 9.18 sec]
EPOCH 45/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5441928077199791		[learning rate: 0.0084874]
	Learning Rate: 0.00848742
	LOSS [training: 0.5441928077199791 | validation: 0.5039737544354476]
	TIME [epoch: 9.18 sec]
EPOCH 46/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5520523467153365		[learning rate: 0.0084476]
	Learning Rate: 0.00844763
	LOSS [training: 0.5520523467153365 | validation: 0.5223524202600044]
	TIME [epoch: 9.16 sec]
EPOCH 47/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6978638754266251		[learning rate: 0.008408]
	Learning Rate: 0.00840802
	LOSS [training: 0.6978638754266251 | validation: 0.5252233246903157]
	TIME [epoch: 9.18 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6093864260936843		[learning rate: 0.0083686]
	Learning Rate: 0.0083686
	LOSS [training: 0.6093864260936843 | validation: 0.5895768679983199]
	TIME [epoch: 9.19 sec]
EPOCH 49/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5343295123370849		[learning rate: 0.0083294]
	Learning Rate: 0.00832937
	LOSS [training: 0.5343295123370849 | validation: 0.43347375811010497]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5243000945850912		[learning rate: 0.0082903]
	Learning Rate: 0.00829032
	LOSS [training: 0.5243000945850912 | validation: 0.586811186686517]
	TIME [epoch: 9.2 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/10] avg loss: 0.469954121425594		[learning rate: 0.0082515]
	Learning Rate: 0.00825146
	LOSS [training: 0.469954121425594 | validation: 0.5387699705789202]
	TIME [epoch: 9.18 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6611103580396174		[learning rate: 0.0082128]
	Learning Rate: 0.00821277
	LOSS [training: 0.6611103580396174 | validation: 0.7432591929073256]
	TIME [epoch: 9.2 sec]
EPOCH 53/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5634225175360681		[learning rate: 0.0081743]
	Learning Rate: 0.00817427
	LOSS [training: 0.5634225175360681 | validation: 0.4752818492047921]
	TIME [epoch: 9.17 sec]
EPOCH 54/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6196680597393546		[learning rate: 0.0081359]
	Learning Rate: 0.00813595
	LOSS [training: 0.6196680597393546 | validation: 0.6420948298321238]
	TIME [epoch: 9.18 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6256332005332694		[learning rate: 0.0080978]
	Learning Rate: 0.00809781
	LOSS [training: 0.6256332005332694 | validation: 0.5998864307234671]
	TIME [epoch: 9.17 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5701887392963043		[learning rate: 0.0080598]
	Learning Rate: 0.00805984
	LOSS [training: 0.5701887392963043 | validation: 0.6093244931317343]
	TIME [epoch: 9.18 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6004473504443932		[learning rate: 0.0080221]
	Learning Rate: 0.00802206
	LOSS [training: 0.6004473504443932 | validation: 0.48173854763631907]
	TIME [epoch: 9.21 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5427043342577156		[learning rate: 0.0079844]
	Learning Rate: 0.00798445
	LOSS [training: 0.5427043342577156 | validation: 0.6078450643053799]
	TIME [epoch: 9.19 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8122102660229265		[learning rate: 0.007947]
	Learning Rate: 0.00794702
	LOSS [training: 0.8122102660229265 | validation: 0.5884383317257195]
	TIME [epoch: 9.19 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/10] avg loss: 0.591622124565299		[learning rate: 0.0079098]
	Learning Rate: 0.00790976
	LOSS [training: 0.591622124565299 | validation: 0.4952309493798338]
	TIME [epoch: 9.18 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6335605771867171		[learning rate: 0.0078727]
	Learning Rate: 0.00787268
	LOSS [training: 0.6335605771867171 | validation: 0.6962824442790095]
	TIME [epoch: 9.19 sec]
EPOCH 62/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5663185067712618		[learning rate: 0.0078358]
	Learning Rate: 0.00783577
	LOSS [training: 0.5663185067712618 | validation: 0.5579707934011662]
	TIME [epoch: 9.19 sec]
EPOCH 63/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5190937245188787		[learning rate: 0.007799]
	Learning Rate: 0.00779903
	LOSS [training: 0.5190937245188787 | validation: 0.49681214353688863]
	TIME [epoch: 9.17 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5143333055344748		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 0.5143333055344748 | validation: 0.5497490741703699]
	TIME [epoch: 9.18 sec]
EPOCH 65/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4904031060045998		[learning rate: 0.0077261]
	Learning Rate: 0.00772608
	LOSS [training: 0.4904031060045998 | validation: 0.4180711973798621]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5401205803571287		[learning rate: 0.0076899]
	Learning Rate: 0.00768986
	LOSS [training: 0.5401205803571287 | validation: 0.5698111669277433]
	TIME [epoch: 9.19 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/10] avg loss: 0.570722950315546		[learning rate: 0.0076538]
	Learning Rate: 0.00765381
	LOSS [training: 0.570722950315546 | validation: 0.5120262706660206]
	TIME [epoch: 9.19 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49835465774118803		[learning rate: 0.0076179]
	Learning Rate: 0.00761793
	LOSS [training: 0.49835465774118803 | validation: 0.5233090739706663]
	TIME [epoch: 9.19 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5846881669985817		[learning rate: 0.0075822]
	Learning Rate: 0.00758221
	LOSS [training: 0.5846881669985817 | validation: 0.7215216183586137]
	TIME [epoch: 9.18 sec]
EPOCH 70/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5242045699822631		[learning rate: 0.0075467]
	Learning Rate: 0.00754667
	LOSS [training: 0.5242045699822631 | validation: 0.5027150643462439]
	TIME [epoch: 9.19 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5135603416759559		[learning rate: 0.0075113]
	Learning Rate: 0.00751129
	LOSS [training: 0.5135603416759559 | validation: 0.5304839237808867]
	TIME [epoch: 9.19 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4969899389137552		[learning rate: 0.0074761]
	Learning Rate: 0.00747607
	LOSS [training: 0.4969899389137552 | validation: 0.453914496156007]
	TIME [epoch: 9.18 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49318396784227136		[learning rate: 0.007441]
	Learning Rate: 0.00744102
	LOSS [training: 0.49318396784227136 | validation: 0.5775828354788013]
	TIME [epoch: 9.2 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49206008904791965		[learning rate: 0.0074061]
	Learning Rate: 0.00740614
	LOSS [training: 0.49206008904791965 | validation: 0.5920439207553769]
	TIME [epoch: 9.17 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5250643060144957		[learning rate: 0.0073714]
	Learning Rate: 0.00737142
	LOSS [training: 0.5250643060144957 | validation: 0.5250704377256354]
	TIME [epoch: 9.19 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5579461488116624		[learning rate: 0.0073369]
	Learning Rate: 0.00733686
	LOSS [training: 0.5579461488116624 | validation: 0.529686192637089]
	TIME [epoch: 9.2 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6063255043314448		[learning rate: 0.0073025]
	Learning Rate: 0.00730246
	LOSS [training: 0.6063255043314448 | validation: 0.4713661118795148]
	TIME [epoch: 9.19 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/10] avg loss: 0.559638826128651		[learning rate: 0.0072682]
	Learning Rate: 0.00726823
	LOSS [training: 0.559638826128651 | validation: 0.6348599767784858]
	TIME [epoch: 9.19 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5264218810136965		[learning rate: 0.0072342]
	Learning Rate: 0.00723415
	LOSS [training: 0.5264218810136965 | validation: 0.42943451393792886]
	TIME [epoch: 9.2 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4547148403534781		[learning rate: 0.0072002]
	Learning Rate: 0.00720024
	LOSS [training: 0.4547148403534781 | validation: 0.5618781881636351]
	TIME [epoch: 9.19 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5013712914133612		[learning rate: 0.0071665]
	Learning Rate: 0.00716648
	LOSS [training: 0.5013712914133612 | validation: 0.40691598174908916]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_81.pth
	Model improved!!!
EPOCH 82/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5791293325663863		[learning rate: 0.0071329]
	Learning Rate: 0.00713289
	LOSS [training: 0.5791293325663863 | validation: 0.4632909996946848]
	TIME [epoch: 9.17 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4616837651861928		[learning rate: 0.0070994]
	Learning Rate: 0.00709945
	LOSS [training: 0.4616837651861928 | validation: 0.4108550773860711]
	TIME [epoch: 9.17 sec]
EPOCH 84/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5247562286052625		[learning rate: 0.0070662]
	Learning Rate: 0.00706616
	LOSS [training: 0.5247562286052625 | validation: 0.6896409180740097]
	TIME [epoch: 9.18 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/10] avg loss: 0.48333642327696075		[learning rate: 0.007033]
	Learning Rate: 0.00703304
	LOSS [training: 0.48333642327696075 | validation: 0.9224803603262213]
	TIME [epoch: 9.19 sec]
EPOCH 86/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5465019934412737		[learning rate: 0.0070001]
	Learning Rate: 0.00700006
	LOSS [training: 0.5465019934412737 | validation: 0.4134423379656584]
	TIME [epoch: 9.18 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4387673437076768		[learning rate: 0.0069672]
	Learning Rate: 0.00696725
	LOSS [training: 0.4387673437076768 | validation: 0.5946893523028791]
	TIME [epoch: 9.19 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4411303298560495		[learning rate: 0.0069346]
	Learning Rate: 0.00693458
	LOSS [training: 0.4411303298560495 | validation: 0.513063402239902]
	TIME [epoch: 9.18 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41935277456495346		[learning rate: 0.0069021]
	Learning Rate: 0.00690207
	LOSS [training: 0.41935277456495346 | validation: 0.4355861363446142]
	TIME [epoch: 9.2 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4531243286385819		[learning rate: 0.0068697]
	Learning Rate: 0.00686972
	LOSS [training: 0.4531243286385819 | validation: 0.3985121744743322]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_90.pth
	Model improved!!!
EPOCH 91/500:
	Training over batches...
		[batch 10/10] avg loss: 0.476376459238392		[learning rate: 0.0068375]
	Learning Rate: 0.00683751
	LOSS [training: 0.476376459238392 | validation: 0.4838321557771046]
	TIME [epoch: 9.18 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4410286579757333		[learning rate: 0.0068055]
	Learning Rate: 0.00680545
	LOSS [training: 0.4410286579757333 | validation: 0.45250997279643174]
	TIME [epoch: 9.2 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4193074277541404		[learning rate: 0.0067735]
	Learning Rate: 0.00677355
	LOSS [training: 0.4193074277541404 | validation: 0.29128890856521583]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_93.pth
	Model improved!!!
EPOCH 94/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35312941089927163		[learning rate: 0.0067418]
	Learning Rate: 0.00674179
	LOSS [training: 0.35312941089927163 | validation: 0.3837554370455687]
	TIME [epoch: 9.2 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3463198065803388		[learning rate: 0.0067102]
	Learning Rate: 0.00671019
	LOSS [training: 0.3463198065803388 | validation: 0.4420441240383589]
	TIME [epoch: 9.19 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4872445958087261		[learning rate: 0.0066787]
	Learning Rate: 0.00667873
	LOSS [training: 0.4872445958087261 | validation: 0.6748580276095777]
	TIME [epoch: 9.21 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5148722207307899		[learning rate: 0.0066474]
	Learning Rate: 0.00664742
	LOSS [training: 0.5148722207307899 | validation: 0.3711868462794662]
	TIME [epoch: 9.22 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39006652720302537		[learning rate: 0.0066163]
	Learning Rate: 0.00661625
	LOSS [training: 0.39006652720302537 | validation: 0.950700341141992]
	TIME [epoch: 9.18 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5656134159961221		[learning rate: 0.0065852]
	Learning Rate: 0.00658524
	LOSS [training: 0.5656134159961221 | validation: 0.38043667480696086]
	TIME [epoch: 9.21 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/10] avg loss: 0.43272633943183425		[learning rate: 0.0065544]
	Learning Rate: 0.00655436
	LOSS [training: 0.43272633943183425 | validation: 0.33814040577444604]
	TIME [epoch: 9.19 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4368598012286539		[learning rate: 0.0065236]
	Learning Rate: 0.00652364
	LOSS [training: 0.4368598012286539 | validation: 0.32782309938965426]
	TIME [epoch: 9.15 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38299012959523965		[learning rate: 0.0064931]
	Learning Rate: 0.00649305
	LOSS [training: 0.38299012959523965 | validation: 0.49765923049211325]
	TIME [epoch: 9.15 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/10] avg loss: 0.43747528730019913		[learning rate: 0.0064626]
	Learning Rate: 0.00646261
	LOSS [training: 0.43747528730019913 | validation: 0.3154774662395601]
	TIME [epoch: 9.17 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37006152910537626		[learning rate: 0.0064323]
	Learning Rate: 0.00643232
	LOSS [training: 0.37006152910537626 | validation: 0.2990289133123906]
	TIME [epoch: 9.17 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3539025391706439		[learning rate: 0.0064022]
	Learning Rate: 0.00640216
	LOSS [training: 0.3539025391706439 | validation: 0.2848179594763466]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_105.pth
	Model improved!!!
EPOCH 106/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39341709770740874		[learning rate: 0.0063721]
	Learning Rate: 0.00637215
	LOSS [training: 0.39341709770740874 | validation: 0.4596490048521822]
	TIME [epoch: 9.19 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4141079214740044		[learning rate: 0.0063423]
	Learning Rate: 0.00634227
	LOSS [training: 0.4141079214740044 | validation: 0.3222925443272617]
	TIME [epoch: 9.17 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4010496135976866		[learning rate: 0.0063125]
	Learning Rate: 0.00631254
	LOSS [training: 0.4010496135976866 | validation: 0.34499527733540913]
	TIME [epoch: 9.2 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38170997142347546		[learning rate: 0.0062829]
	Learning Rate: 0.00628295
	LOSS [training: 0.38170997142347546 | validation: 0.37077574480104036]
	TIME [epoch: 9.21 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5379411007576597		[learning rate: 0.0062535]
	Learning Rate: 0.00625349
	LOSS [training: 0.5379411007576597 | validation: 0.38279294356201754]
	TIME [epoch: 9.22 sec]
EPOCH 111/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4043673257621915		[learning rate: 0.0062242]
	Learning Rate: 0.00622417
	LOSS [training: 0.4043673257621915 | validation: 0.4338289564768587]
	TIME [epoch: 9.22 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47979347194052213		[learning rate: 0.006195]
	Learning Rate: 0.00619499
	LOSS [training: 0.47979347194052213 | validation: 0.29694167029924223]
	TIME [epoch: 9.22 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3609183231056879		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 0.3609183231056879 | validation: 0.27307882271751827]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_113.pth
	Model improved!!!
EPOCH 114/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32160422871923733		[learning rate: 0.006137]
	Learning Rate: 0.00613704
	LOSS [training: 0.32160422871923733 | validation: 0.33893843596633405]
	TIME [epoch: 9.23 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33391439712982945		[learning rate: 0.0061083]
	Learning Rate: 0.00610827
	LOSS [training: 0.33391439712982945 | validation: 0.4236774252236465]
	TIME [epoch: 9.22 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31895125853273293		[learning rate: 0.0060796]
	Learning Rate: 0.00607964
	LOSS [training: 0.31895125853273293 | validation: 0.9647221741754664]
	TIME [epoch: 9.23 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4260498643527918		[learning rate: 0.0060511]
	Learning Rate: 0.00605113
	LOSS [training: 0.4260498643527918 | validation: 0.2637058802989829]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_117.pth
	Model improved!!!
EPOCH 118/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33017077872769873		[learning rate: 0.0060228]
	Learning Rate: 0.00602276
	LOSS [training: 0.33017077872769873 | validation: 0.3209608626978223]
	TIME [epoch: 9.19 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33514384785657014		[learning rate: 0.0059945]
	Learning Rate: 0.00599453
	LOSS [training: 0.33514384785657014 | validation: 0.3708890250162759]
	TIME [epoch: 9.16 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3967980024588202		[learning rate: 0.0059664]
	Learning Rate: 0.00596643
	LOSS [training: 0.3967980024588202 | validation: 0.41682830203436205]
	TIME [epoch: 9.19 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3385032310196999		[learning rate: 0.0059385]
	Learning Rate: 0.00593845
	LOSS [training: 0.3385032310196999 | validation: 0.25941178167852913]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_121.pth
	Model improved!!!
EPOCH 122/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2937541667789162		[learning rate: 0.0059106]
	Learning Rate: 0.00591061
	LOSS [training: 0.2937541667789162 | validation: 0.3457133206070113]
	TIME [epoch: 9.15 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4706208654851679		[learning rate: 0.0058829]
	Learning Rate: 0.0058829
	LOSS [training: 0.4706208654851679 | validation: 0.6951526993646528]
	TIME [epoch: 9.17 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3909660975057712		[learning rate: 0.0058553]
	Learning Rate: 0.00585532
	LOSS [training: 0.3909660975057712 | validation: 0.399577411907575]
	TIME [epoch: 9.2 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3522383037914959		[learning rate: 0.0058279]
	Learning Rate: 0.00582787
	LOSS [training: 0.3522383037914959 | validation: 0.2529531636822969]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_125.pth
	Model improved!!!
EPOCH 126/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29239237441891586		[learning rate: 0.0058006]
	Learning Rate: 0.00580055
	LOSS [training: 0.29239237441891586 | validation: 0.2943206385010243]
	TIME [epoch: 9.19 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28263958632436936		[learning rate: 0.0057734]
	Learning Rate: 0.00577336
	LOSS [training: 0.28263958632436936 | validation: 0.26934432860141067]
	TIME [epoch: 9.18 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27785786406203594		[learning rate: 0.0057463]
	Learning Rate: 0.00574629
	LOSS [training: 0.27785786406203594 | validation: 0.28772699058825996]
	TIME [epoch: 9.18 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5331364832018114		[learning rate: 0.0057194]
	Learning Rate: 0.00571935
	LOSS [training: 0.5331364832018114 | validation: 0.4717508226847986]
	TIME [epoch: 9.21 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5512778108429608		[learning rate: 0.0056925]
	Learning Rate: 0.00569254
	LOSS [training: 0.5512778108429608 | validation: 0.3108223543269065]
	TIME [epoch: 9.19 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41324669075885573		[learning rate: 0.0056659]
	Learning Rate: 0.00566585
	LOSS [training: 0.41324669075885573 | validation: 0.45047671834961717]
	TIME [epoch: 9.19 sec]
EPOCH 132/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34777997316749465		[learning rate: 0.0056393]
	Learning Rate: 0.00563929
	LOSS [training: 0.34777997316749465 | validation: 0.18972333615037318]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_132.pth
	Model improved!!!
EPOCH 133/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34832922825830626		[learning rate: 0.0056129]
	Learning Rate: 0.00561285
	LOSS [training: 0.34832922825830626 | validation: 0.2225844879435203]
	TIME [epoch: 9.18 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33688531841336683		[learning rate: 0.0055865]
	Learning Rate: 0.00558654
	LOSS [training: 0.33688531841336683 | validation: 0.1996892168779411]
	TIME [epoch: 9.17 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3013276103406942		[learning rate: 0.0055603]
	Learning Rate: 0.00556035
	LOSS [training: 0.3013276103406942 | validation: 0.17213719962129428]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_135.pth
	Model improved!!!
EPOCH 136/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23306570281223454		[learning rate: 0.0055343]
	Learning Rate: 0.00553428
	LOSS [training: 0.23306570281223454 | validation: 0.1856134029333741]
	TIME [epoch: 9.2 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19377958091819386		[learning rate: 0.0055083]
	Learning Rate: 0.00550834
	LOSS [training: 0.19377958091819386 | validation: 0.17744446517509688]
	TIME [epoch: 9.2 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23777762170461342		[learning rate: 0.0054825]
	Learning Rate: 0.00548251
	LOSS [training: 0.23777762170461342 | validation: 0.17820843924815286]
	TIME [epoch: 9.21 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25718664031625116		[learning rate: 0.0054568]
	Learning Rate: 0.00545681
	LOSS [training: 0.25718664031625116 | validation: 0.2071120169587865]
	TIME [epoch: 9.2 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/10] avg loss: 0.294520343667417		[learning rate: 0.0054312]
	Learning Rate: 0.00543123
	LOSS [training: 0.294520343667417 | validation: 0.3676397399974005]
	TIME [epoch: 9.2 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2935027580483371		[learning rate: 0.0054058]
	Learning Rate: 0.00540576
	LOSS [training: 0.2935027580483371 | validation: 0.5013148526135855]
	TIME [epoch: 9.19 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3683161805930378		[learning rate: 0.0053804]
	Learning Rate: 0.00538042
	LOSS [training: 0.3683161805930378 | validation: 0.23326565742351682]
	TIME [epoch: 9.19 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3456088414630189		[learning rate: 0.0053552]
	Learning Rate: 0.0053552
	LOSS [training: 0.3456088414630189 | validation: 0.33542385209145353]
	TIME [epoch: 9.19 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38322106010052914		[learning rate: 0.0053301]
	Learning Rate: 0.00533009
	LOSS [training: 0.38322106010052914 | validation: 0.2678795181116352]
	TIME [epoch: 9.19 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2330336052145769		[learning rate: 0.0053051]
	Learning Rate: 0.0053051
	LOSS [training: 0.2330336052145769 | validation: 0.1604212342864451]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_145.pth
	Model improved!!!
EPOCH 146/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26881155642069793		[learning rate: 0.0052802]
	Learning Rate: 0.00528023
	LOSS [training: 0.26881155642069793 | validation: 0.1642507837975301]
	TIME [epoch: 9.19 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3131921552121259		[learning rate: 0.0052555]
	Learning Rate: 0.00525548
	LOSS [training: 0.3131921552121259 | validation: 0.23316282846504915]
	TIME [epoch: 9.2 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2778810000255701		[learning rate: 0.0052308]
	Learning Rate: 0.00523084
	LOSS [training: 0.2778810000255701 | validation: 0.3708014404480083]
	TIME [epoch: 9.19 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2544034270043189		[learning rate: 0.0052063]
	Learning Rate: 0.00520632
	LOSS [training: 0.2544034270043189 | validation: 0.6232450382556776]
	TIME [epoch: 9.2 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9232394033984448		[learning rate: 0.0051819]
	Learning Rate: 0.00518191
	LOSS [training: 0.9232394033984448 | validation: 0.31350871607973285]
	TIME [epoch: 9.18 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3192608723494237		[learning rate: 0.0051576]
	Learning Rate: 0.00515762
	LOSS [training: 0.3192608723494237 | validation: 0.27609509724088105]
	TIME [epoch: 9.21 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2836510691648531		[learning rate: 0.0051334]
	Learning Rate: 0.00513344
	LOSS [training: 0.2836510691648531 | validation: 0.22646437858133323]
	TIME [epoch: 9.2 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3376209945178986		[learning rate: 0.0051094]
	Learning Rate: 0.00510937
	LOSS [training: 0.3376209945178986 | validation: 0.39792229345478436]
	TIME [epoch: 9.19 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28568323662885176		[learning rate: 0.0050854]
	Learning Rate: 0.00508542
	LOSS [training: 0.28568323662885176 | validation: 0.2193362381098764]
	TIME [epoch: 9.19 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20990001905419198		[learning rate: 0.0050616]
	Learning Rate: 0.00506158
	LOSS [training: 0.20990001905419198 | validation: 0.2503692665325191]
	TIME [epoch: 9.19 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31770184307185306		[learning rate: 0.0050378]
	Learning Rate: 0.00503785
	LOSS [training: 0.31770184307185306 | validation: 0.16245150747829099]
	TIME [epoch: 9.21 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2081816263783946		[learning rate: 0.0050142]
	Learning Rate: 0.00501423
	LOSS [training: 0.2081816263783946 | validation: 0.23082075764551588]
	TIME [epoch: 9.19 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38918644317995305		[learning rate: 0.0049907]
	Learning Rate: 0.00499072
	LOSS [training: 0.38918644317995305 | validation: 0.28126131714177294]
	TIME [epoch: 9.18 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18300066142182048		[learning rate: 0.0049673]
	Learning Rate: 0.00496732
	LOSS [training: 0.18300066142182048 | validation: 0.12722460123394358]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_159.pth
	Model improved!!!
EPOCH 160/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1746065057688089		[learning rate: 0.004944]
	Learning Rate: 0.00494404
	LOSS [training: 0.1746065057688089 | validation: 0.3956383626738236]
	TIME [epoch: 9.16 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22382791419530537		[learning rate: 0.0049209]
	Learning Rate: 0.00492086
	LOSS [training: 0.22382791419530537 | validation: 0.3257123856499827]
	TIME [epoch: 9.19 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2678181614768248		[learning rate: 0.0048978]
	Learning Rate: 0.00489779
	LOSS [training: 0.2678181614768248 | validation: 0.18526922826504139]
	TIME [epoch: 9.2 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19146493805653178		[learning rate: 0.0048748]
	Learning Rate: 0.00487483
	LOSS [training: 0.19146493805653178 | validation: 0.23434185253906598]
	TIME [epoch: 9.16 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16878673837746302		[learning rate: 0.004852]
	Learning Rate: 0.00485197
	LOSS [training: 0.16878673837746302 | validation: 0.11967435994908457]
	TIME [epoch: 9.18 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_164.pth
	Model improved!!!
EPOCH 165/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14994328535882864		[learning rate: 0.0048292]
	Learning Rate: 0.00482923
	LOSS [training: 0.14994328535882864 | validation: 0.20063105796956626]
	TIME [epoch: 9.21 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2313004239511285		[learning rate: 0.0048066]
	Learning Rate: 0.00480659
	LOSS [training: 0.2313004239511285 | validation: 0.16557135041170384]
	TIME [epoch: 9.2 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27759850203629777		[learning rate: 0.0047841]
	Learning Rate: 0.00478405
	LOSS [training: 0.27759850203629777 | validation: 0.19001740697932745]
	TIME [epoch: 9.19 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1868684177958428		[learning rate: 0.0047616]
	Learning Rate: 0.00476162
	LOSS [training: 0.1868684177958428 | validation: 0.18595029547786654]
	TIME [epoch: 9.19 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14338616843261817		[learning rate: 0.0047393]
	Learning Rate: 0.0047393
	LOSS [training: 0.14338616843261817 | validation: 0.20617082265705133]
	TIME [epoch: 9.2 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2619318542887047		[learning rate: 0.0047171]
	Learning Rate: 0.00471708
	LOSS [training: 0.2619318542887047 | validation: 0.09297566832111213]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_170.pth
	Model improved!!!
EPOCH 171/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23200106504881401		[learning rate: 0.004695]
	Learning Rate: 0.00469497
	LOSS [training: 0.23200106504881401 | validation: 0.1175738533952142]
	TIME [epoch: 9.19 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1622405243385833		[learning rate: 0.004673]
	Learning Rate: 0.00467296
	LOSS [training: 0.1622405243385833 | validation: 0.29663394960844847]
	TIME [epoch: 9.2 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17738496740571708		[learning rate: 0.0046511]
	Learning Rate: 0.00465105
	LOSS [training: 0.17738496740571708 | validation: 0.1279608680718249]
	TIME [epoch: 9.19 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14115806639064962		[learning rate: 0.0046292]
	Learning Rate: 0.00462925
	LOSS [training: 0.14115806639064962 | validation: 0.124604710268341]
	TIME [epoch: 9.21 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18025220361007102		[learning rate: 0.0046075]
	Learning Rate: 0.00460754
	LOSS [training: 0.18025220361007102 | validation: 0.14295476723921594]
	TIME [epoch: 9.2 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1285055539596336		[learning rate: 0.0045859]
	Learning Rate: 0.00458594
	LOSS [training: 0.1285055539596336 | validation: 0.102471262619043]
	TIME [epoch: 9.2 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2111471325186042		[learning rate: 0.0045644]
	Learning Rate: 0.00456444
	LOSS [training: 0.2111471325186042 | validation: 0.147015485467714]
	TIME [epoch: 9.2 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11262384141300519		[learning rate: 0.004543]
	Learning Rate: 0.00454304
	LOSS [training: 0.11262384141300519 | validation: 0.1918396070711079]
	TIME [epoch: 9.19 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2140784727413203		[learning rate: 0.0045217]
	Learning Rate: 0.00452175
	LOSS [training: 0.2140784727413203 | validation: 0.12275252293551309]
	TIME [epoch: 9.22 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17495405417221416		[learning rate: 0.0045005]
	Learning Rate: 0.00450055
	LOSS [training: 0.17495405417221416 | validation: 0.3107432260890626]
	TIME [epoch: 9.2 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1713207135272456		[learning rate: 0.0044794]
	Learning Rate: 0.00447945
	LOSS [training: 0.1713207135272456 | validation: 0.1922439625160191]
	TIME [epoch: 9.19 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2560260335042209		[learning rate: 0.0044584]
	Learning Rate: 0.00445845
	LOSS [training: 0.2560260335042209 | validation: 0.3154257892655262]
	TIME [epoch: 9.19 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16091902825732712		[learning rate: 0.0044375]
	Learning Rate: 0.00443755
	LOSS [training: 0.16091902825732712 | validation: 0.16854325435152576]
	TIME [epoch: 9.22 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13776675664808105		[learning rate: 0.0044167]
	Learning Rate: 0.00441674
	LOSS [training: 0.13776675664808105 | validation: 0.13975964026117121]
	TIME [epoch: 9.2 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19413348592804697		[learning rate: 0.004396]
	Learning Rate: 0.00439604
	LOSS [training: 0.19413348592804697 | validation: 0.2238007883289009]
	TIME [epoch: 9.19 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23096170768864224		[learning rate: 0.0043754]
	Learning Rate: 0.00437543
	LOSS [training: 0.23096170768864224 | validation: 0.12718381403035045]
	TIME [epoch: 9.2 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14587825142427185		[learning rate: 0.0043549]
	Learning Rate: 0.00435491
	LOSS [training: 0.14587825142427185 | validation: 0.12976411973435725]
	TIME [epoch: 9.2 sec]
EPOCH 188/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10590299053258508		[learning rate: 0.0043345]
	Learning Rate: 0.0043345
	LOSS [training: 0.10590299053258508 | validation: 0.06806861934983678]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_188.pth
	Model improved!!!
EPOCH 189/500:
	Training over batches...
		[batch 10/10] avg loss: 0.334860803868151		[learning rate: 0.0043142]
	Learning Rate: 0.00431418
	LOSS [training: 0.334860803868151 | validation: 0.2708927637444132]
	TIME [epoch: 9.2 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19918232267116598		[learning rate: 0.004294]
	Learning Rate: 0.00429395
	LOSS [training: 0.19918232267116598 | validation: 0.14006498631775272]
	TIME [epoch: 9.2 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1279368866424162		[learning rate: 0.0042738]
	Learning Rate: 0.00427382
	LOSS [training: 0.1279368866424162 | validation: 0.1719823896094454]
	TIME [epoch: 9.2 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12553139144926073		[learning rate: 0.0042538]
	Learning Rate: 0.00425378
	LOSS [training: 0.12553139144926073 | validation: 0.07052666016663287]
	TIME [epoch: 9.23 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1539482904917163		[learning rate: 0.0042338]
	Learning Rate: 0.00423384
	LOSS [training: 0.1539482904917163 | validation: 0.31950313115882784]
	TIME [epoch: 9.21 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22794686306184125		[learning rate: 0.004214]
	Learning Rate: 0.00421399
	LOSS [training: 0.22794686306184125 | validation: 0.1464552748783302]
	TIME [epoch: 9.2 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16369812051861993		[learning rate: 0.0041942]
	Learning Rate: 0.00419424
	LOSS [training: 0.16369812051861993 | validation: 0.11874168510052724]
	TIME [epoch: 9.21 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1158449550499659		[learning rate: 0.0041746]
	Learning Rate: 0.00417457
	LOSS [training: 0.1158449550499659 | validation: 0.17107981060803207]
	TIME [epoch: 9.2 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2156891657461662		[learning rate: 0.004155]
	Learning Rate: 0.004155
	LOSS [training: 0.2156891657461662 | validation: 0.1920478925558903]
	TIME [epoch: 9.21 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1598832399829886		[learning rate: 0.0041355]
	Learning Rate: 0.00413552
	LOSS [training: 0.1598832399829886 | validation: 0.14041258259797476]
	TIME [epoch: 9.2 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13311562774168562		[learning rate: 0.0041161]
	Learning Rate: 0.00411614
	LOSS [training: 0.13311562774168562 | validation: 0.10604441379473663]
	TIME [epoch: 9.19 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16668693094299641		[learning rate: 0.0040968]
	Learning Rate: 0.00409684
	LOSS [training: 0.16668693094299641 | validation: 0.13395871193334874]
	TIME [epoch: 9.18 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15249059830347894		[learning rate: 0.0040776]
	Learning Rate: 0.00407763
	LOSS [training: 0.15249059830347894 | validation: 0.14287769241245313]
	TIME [epoch: 9.2 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13907605067957454		[learning rate: 0.0040585]
	Learning Rate: 0.00405852
	LOSS [training: 0.13907605067957454 | validation: 0.236156607804976]
	TIME [epoch: 9.2 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13060262783914905		[learning rate: 0.0040395]
	Learning Rate: 0.00403949
	LOSS [training: 0.13060262783914905 | validation: 0.10706818917705269]
	TIME [epoch: 9.2 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12928124008366398		[learning rate: 0.0040206]
	Learning Rate: 0.00402055
	LOSS [training: 0.12928124008366398 | validation: 0.09800321583376251]
	TIME [epoch: 9.19 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18359835132858526		[learning rate: 0.0040017]
	Learning Rate: 0.0040017
	LOSS [training: 0.18359835132858526 | validation: 0.06748836978404257]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_205.pth
	Model improved!!!
EPOCH 206/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10032099548611029		[learning rate: 0.0039829]
	Learning Rate: 0.00398294
	LOSS [training: 0.10032099548611029 | validation: 0.07280267299939863]
	TIME [epoch: 9.23 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20988977770592238		[learning rate: 0.0039643]
	Learning Rate: 0.00396427
	LOSS [training: 0.20988977770592238 | validation: 0.17844068806926192]
	TIME [epoch: 9.2 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1608734048238471		[learning rate: 0.0039457]
	Learning Rate: 0.00394569
	LOSS [training: 0.1608734048238471 | validation: 0.14883472270364995]
	TIME [epoch: 9.2 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14920829227512555		[learning rate: 0.0039272]
	Learning Rate: 0.00392719
	LOSS [training: 0.14920829227512555 | validation: 0.12788377674898072]
	TIME [epoch: 9.2 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16690387516293426		[learning rate: 0.0039088]
	Learning Rate: 0.00390878
	LOSS [training: 0.16690387516293426 | validation: 0.09544085071171102]
	TIME [epoch: 9.22 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16865014355267777		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.16865014355267777 | validation: 0.21434254585644053]
	TIME [epoch: 9.21 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2696684851274882		[learning rate: 0.0038722]
	Learning Rate: 0.00387221
	LOSS [training: 0.2696684851274882 | validation: 0.1745655892381453]
	TIME [epoch: 9.2 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19678343350953106		[learning rate: 0.0038541]
	Learning Rate: 0.00385406
	LOSS [training: 0.19678343350953106 | validation: 0.3079596730362634]
	TIME [epoch: 9.2 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28697660317233104		[learning rate: 0.003836]
	Learning Rate: 0.00383599
	LOSS [training: 0.28697660317233104 | validation: 0.17343764766427738]
	TIME [epoch: 9.2 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15676319486945917		[learning rate: 0.003818]
	Learning Rate: 0.00381801
	LOSS [training: 0.15676319486945917 | validation: 0.08374928514424476]
	TIME [epoch: 9.21 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20632776171690415		[learning rate: 0.0038001]
	Learning Rate: 0.00380011
	LOSS [training: 0.20632776171690415 | validation: 0.14194587677331147]
	TIME [epoch: 9.21 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10995145602838115		[learning rate: 0.0037823]
	Learning Rate: 0.00378229
	LOSS [training: 0.10995145602838115 | validation: 0.11051469657976341]
	TIME [epoch: 9.2 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21185169604521348		[learning rate: 0.0037646]
	Learning Rate: 0.00376456
	LOSS [training: 0.21185169604521348 | validation: 1.2812299494528616]
	TIME [epoch: 9.2 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34375276478129707		[learning rate: 0.0037469]
	Learning Rate: 0.00374691
	LOSS [training: 0.34375276478129707 | validation: 0.1955312595279993]
	TIME [epoch: 9.22 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14534068141166762		[learning rate: 0.0037293]
	Learning Rate: 0.00372935
	LOSS [training: 0.14534068141166762 | validation: 0.10667406130423371]
	TIME [epoch: 9.21 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10842964028690769		[learning rate: 0.0037119]
	Learning Rate: 0.00371186
	LOSS [training: 0.10842964028690769 | validation: 0.0819344502649381]
	TIME [epoch: 9.21 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18260235569834674		[learning rate: 0.0036945]
	Learning Rate: 0.00369446
	LOSS [training: 0.18260235569834674 | validation: 0.07914733107361883]
	TIME [epoch: 9.21 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11880698462015442		[learning rate: 0.0036771]
	Learning Rate: 0.00367714
	LOSS [training: 0.11880698462015442 | validation: 0.0864445667877955]
	TIME [epoch: 9.19 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11974659300334016		[learning rate: 0.0036599]
	Learning Rate: 0.0036599
	LOSS [training: 0.11974659300334016 | validation: 0.0788787845195659]
	TIME [epoch: 9.21 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14624496927930622		[learning rate: 0.0036427]
	Learning Rate: 0.00364274
	LOSS [training: 0.14624496927930622 | validation: 0.17802297930760058]
	TIME [epoch: 9.2 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11254160653031382		[learning rate: 0.0036257]
	Learning Rate: 0.00362567
	LOSS [training: 0.11254160653031382 | validation: 0.09785797613784131]
	TIME [epoch: 9.19 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1388557850908231		[learning rate: 0.0036087]
	Learning Rate: 0.00360867
	LOSS [training: 0.1388557850908231 | validation: 0.19687920927904967]
	TIME [epoch: 9.21 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1419048464155502		[learning rate: 0.0035918]
	Learning Rate: 0.00359175
	LOSS [training: 0.1419048464155502 | validation: 0.07784781537157745]
	TIME [epoch: 9.22 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07779235262644138		[learning rate: 0.0035749]
	Learning Rate: 0.00357491
	LOSS [training: 0.07779235262644138 | validation: 0.3442334844993634]
	TIME [epoch: 9.21 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21667086263263485		[learning rate: 0.0035582]
	Learning Rate: 0.00355815
	LOSS [training: 0.21667086263263485 | validation: 0.17058060291594684]
	TIME [epoch: 9.2 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0847802873415811		[learning rate: 0.0035415]
	Learning Rate: 0.00354147
	LOSS [training: 0.0847802873415811 | validation: 0.1118541172063178]
	TIME [epoch: 9.2 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07126043076852709		[learning rate: 0.0035249]
	Learning Rate: 0.00352487
	LOSS [training: 0.07126043076852709 | validation: 0.06261912608590396]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_232.pth
	Model improved!!!
EPOCH 233/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13222023293403984		[learning rate: 0.0035083]
	Learning Rate: 0.00350834
	LOSS [training: 0.13222023293403984 | validation: 0.2643146664256958]
	TIME [epoch: 9.21 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15585976290614126		[learning rate: 0.0034919]
	Learning Rate: 0.0034919
	LOSS [training: 0.15585976290614126 | validation: 0.3241435235019173]
	TIME [epoch: 9.21 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24178177082116603		[learning rate: 0.0034755]
	Learning Rate: 0.00347552
	LOSS [training: 0.24178177082116603 | validation: 0.14936903338322147]
	TIME [epoch: 9.21 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11593773111038379		[learning rate: 0.0034592]
	Learning Rate: 0.00345923
	LOSS [training: 0.11593773111038379 | validation: 0.049725269858110516]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_236.pth
	Model improved!!!
EPOCH 237/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0789064861147794		[learning rate: 0.003443]
	Learning Rate: 0.00344301
	LOSS [training: 0.0789064861147794 | validation: 0.11998276242929078]
	TIME [epoch: 9.25 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06752689568115976		[learning rate: 0.0034269]
	Learning Rate: 0.00342687
	LOSS [training: 0.06752689568115976 | validation: 0.04888647562249233]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_238.pth
	Model improved!!!
EPOCH 239/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08964955576510085		[learning rate: 0.0034108]
	Learning Rate: 0.00341081
	LOSS [training: 0.08964955576510085 | validation: 0.05543088899663323]
	TIME [epoch: 9.2 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08245633685850612		[learning rate: 0.0033948]
	Learning Rate: 0.00339482
	LOSS [training: 0.08245633685850612 | validation: 0.16226522784821723]
	TIME [epoch: 9.21 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10605784904223811		[learning rate: 0.0033789]
	Learning Rate: 0.0033789
	LOSS [training: 0.10605784904223811 | validation: 0.1248623469994861]
	TIME [epoch: 9.21 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15138287943617118		[learning rate: 0.0033631]
	Learning Rate: 0.00336306
	LOSS [training: 0.15138287943617118 | validation: 0.1378568545171253]
	TIME [epoch: 9.22 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12192806501336857		[learning rate: 0.0033473]
	Learning Rate: 0.00334729
	LOSS [training: 0.12192806501336857 | validation: 0.10482449448178799]
	TIME [epoch: 9.21 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18493359852807778		[learning rate: 0.0033316]
	Learning Rate: 0.0033316
	LOSS [training: 0.18493359852807778 | validation: 0.05796149100081882]
	TIME [epoch: 9.19 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07021315046711618		[learning rate: 0.003316]
	Learning Rate: 0.00331598
	LOSS [training: 0.07021315046711618 | validation: 0.06801422613083657]
	TIME [epoch: 9.22 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1375744383988487		[learning rate: 0.0033004]
	Learning Rate: 0.00330044
	LOSS [training: 0.1375744383988487 | validation: 0.14125279940784635]
	TIME [epoch: 9.23 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13320539219974623		[learning rate: 0.003285]
	Learning Rate: 0.00328496
	LOSS [training: 0.13320539219974623 | validation: 0.11076459843848493]
	TIME [epoch: 9.23 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11447137900125401		[learning rate: 0.0032696]
	Learning Rate: 0.00326956
	LOSS [training: 0.11447137900125401 | validation: 0.12010766604396494]
	TIME [epoch: 9.22 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11010342065083267		[learning rate: 0.0032542]
	Learning Rate: 0.00325424
	LOSS [training: 0.11010342065083267 | validation: 0.05893376398710155]
	TIME [epoch: 9.2 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11755510535828187		[learning rate: 0.003239]
	Learning Rate: 0.00323898
	LOSS [training: 0.11755510535828187 | validation: 0.12843256280315357]
	TIME [epoch: 9.22 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12059679297104556		[learning rate: 0.0032238]
	Learning Rate: 0.00322379
	LOSS [training: 0.12059679297104556 | validation: 0.08623127621419986]
	TIME [epoch: 9.24 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07763912035076632		[learning rate: 0.0032087]
	Learning Rate: 0.00320868
	LOSS [training: 0.07763912035076632 | validation: 0.08299470515929439]
	TIME [epoch: 9.23 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08825486633369566		[learning rate: 0.0031936]
	Learning Rate: 0.00319364
	LOSS [training: 0.08825486633369566 | validation: 0.059108036529450694]
	TIME [epoch: 9.21 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0707993986813073		[learning rate: 0.0031787]
	Learning Rate: 0.00317867
	LOSS [training: 0.0707993986813073 | validation: 0.14201295407434517]
	TIME [epoch: 9.21 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10417353104665636		[learning rate: 0.0031638]
	Learning Rate: 0.00316376
	LOSS [training: 0.10417353104665636 | validation: 0.059351499964680546]
	TIME [epoch: 9.23 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09103732201912935		[learning rate: 0.0031489]
	Learning Rate: 0.00314893
	LOSS [training: 0.09103732201912935 | validation: 0.08262452066879694]
	TIME [epoch: 9.23 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08153316471736519		[learning rate: 0.0031342]
	Learning Rate: 0.00313417
	LOSS [training: 0.08153316471736519 | validation: 0.10658871175532286]
	TIME [epoch: 9.21 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16353191515302332		[learning rate: 0.0031195]
	Learning Rate: 0.00311948
	LOSS [training: 0.16353191515302332 | validation: 0.07924450873571048]
	TIME [epoch: 9.21 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09188612436877		[learning rate: 0.0031049]
	Learning Rate: 0.00310485
	LOSS [training: 0.09188612436877 | validation: 0.0681549632032207]
	TIME [epoch: 9.22 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07804225175878073		[learning rate: 0.0030903]
	Learning Rate: 0.0030903
	LOSS [training: 0.07804225175878073 | validation: 0.06444061413666188]
	TIME [epoch: 9.23 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1613054155355613		[learning rate: 0.0030758]
	Learning Rate: 0.00307581
	LOSS [training: 0.1613054155355613 | validation: 0.0794662443974617]
	TIME [epoch: 9.21 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11873739197824999		[learning rate: 0.0030614]
	Learning Rate: 0.00306139
	LOSS [training: 0.11873739197824999 | validation: 0.06113496626846041]
	TIME [epoch: 9.21 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09002087216620158		[learning rate: 0.003047]
	Learning Rate: 0.00304704
	LOSS [training: 0.09002087216620158 | validation: 0.1363072490140442]
	TIME [epoch: 9.21 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20805623359536138		[learning rate: 0.0030328]
	Learning Rate: 0.00303275
	LOSS [training: 0.20805623359536138 | validation: 0.21639654353933985]
	TIME [epoch: 9.22 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1194251558704589		[learning rate: 0.0030185]
	Learning Rate: 0.00301853
	LOSS [training: 0.1194251558704589 | validation: 0.14506513250113684]
	TIME [epoch: 9.21 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1263005495547527		[learning rate: 0.0030044]
	Learning Rate: 0.00300438
	LOSS [training: 0.1263005495547527 | validation: 0.22146041590432913]
	TIME [epoch: 9.21 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2938705204789943		[learning rate: 0.0029903]
	Learning Rate: 0.0029903
	LOSS [training: 0.2938705204789943 | validation: 0.32880284121247094]
	TIME [epoch: 9.21 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2197445852295064		[learning rate: 0.0029763]
	Learning Rate: 0.00297628
	LOSS [training: 0.2197445852295064 | validation: 0.16615023536066492]
	TIME [epoch: 9.21 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0999023487421152		[learning rate: 0.0029623]
	Learning Rate: 0.00296232
	LOSS [training: 0.0999023487421152 | validation: 0.08930256262543804]
	TIME [epoch: 9.22 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1704875531214092		[learning rate: 0.0029484]
	Learning Rate: 0.00294844
	LOSS [training: 0.1704875531214092 | validation: 0.20270861102689938]
	TIME [epoch: 9.22 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18415120715924335		[learning rate: 0.0029346]
	Learning Rate: 0.00293461
	LOSS [training: 0.18415120715924335 | validation: 0.20125941273719417]
	TIME [epoch: 9.2 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15661432654078386		[learning rate: 0.0029209]
	Learning Rate: 0.00292086
	LOSS [training: 0.15661432654078386 | validation: 0.29735981179906634]
	TIME [epoch: 9.23 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20081194680940156		[learning rate: 0.0029072]
	Learning Rate: 0.00290716
	LOSS [training: 0.20081194680940156 | validation: 0.167093229450942]
	TIME [epoch: 9.22 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13069734142506503		[learning rate: 0.0028935]
	Learning Rate: 0.00289353
	LOSS [training: 0.13069734142506503 | validation: 0.16198713472969334]
	TIME [epoch: 9.22 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32479229212453364		[learning rate: 0.00288]
	Learning Rate: 0.00287997
	LOSS [training: 0.32479229212453364 | validation: 0.20899911193684206]
	TIME [epoch: 9.23 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23216470412981688		[learning rate: 0.0028665]
	Learning Rate: 0.00286647
	LOSS [training: 0.23216470412981688 | validation: 0.40328342787865057]
	TIME [epoch: 9.21 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17725639821884354		[learning rate: 0.002853]
	Learning Rate: 0.00285303
	LOSS [training: 0.17725639821884354 | validation: 0.19462001592856132]
	TIME [epoch: 9.21 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17823137594950805		[learning rate: 0.0028397]
	Learning Rate: 0.00283965
	LOSS [training: 0.17823137594950805 | validation: 0.2071251670641655]
	TIME [epoch: 9.25 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15653551858095915		[learning rate: 0.0028263]
	Learning Rate: 0.00282634
	LOSS [training: 0.15653551858095915 | validation: 0.1398651923649596]
	TIME [epoch: 9.23 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17675683861393626		[learning rate: 0.0028131]
	Learning Rate: 0.00281309
	LOSS [training: 0.17675683861393626 | validation: 0.2122118012249143]
	TIME [epoch: 9.23 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34171940164377695		[learning rate: 0.0027999]
	Learning Rate: 0.0027999
	LOSS [training: 0.34171940164377695 | validation: 0.15066262474721143]
	TIME [epoch: 9.22 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1331995570926395		[learning rate: 0.0027868]
	Learning Rate: 0.00278678
	LOSS [training: 0.1331995570926395 | validation: 0.11303273959598392]
	TIME [epoch: 9.24 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22819528891816487		[learning rate: 0.0027737]
	Learning Rate: 0.00277371
	LOSS [training: 0.22819528891816487 | validation: 0.14547064911724877]
	TIME [epoch: 9.25 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14618558220080066		[learning rate: 0.0027607]
	Learning Rate: 0.00276071
	LOSS [training: 0.14618558220080066 | validation: 0.11065758729629868]
	TIME [epoch: 9.23 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10531160013799964		[learning rate: 0.0027478]
	Learning Rate: 0.00274776
	LOSS [training: 0.10531160013799964 | validation: 0.13287913039551077]
	TIME [epoch: 9.23 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1717161278413181		[learning rate: 0.0027349]
	Learning Rate: 0.00273488
	LOSS [training: 0.1717161278413181 | validation: 0.142188945503478]
	TIME [epoch: 9.21 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10647555360802283		[learning rate: 0.0027221]
	Learning Rate: 0.00272206
	LOSS [training: 0.10647555360802283 | validation: 0.15899651449784052]
	TIME [epoch: 9.26 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10692558806326624		[learning rate: 0.0027093]
	Learning Rate: 0.0027093
	LOSS [training: 0.10692558806326624 | validation: 0.08126566823825382]
	TIME [epoch: 9.23 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14914471754850267		[learning rate: 0.0026966]
	Learning Rate: 0.0026966
	LOSS [training: 0.14914471754850267 | validation: 0.10790565279863956]
	TIME [epoch: 9.22 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07913328074675437		[learning rate: 0.002684]
	Learning Rate: 0.00268396
	LOSS [training: 0.07913328074675437 | validation: 0.08214557024306864]
	TIME [epoch: 9.24 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11759053943090163		[learning rate: 0.0026714]
	Learning Rate: 0.00267137
	LOSS [training: 0.11759053943090163 | validation: 0.1529898707239437]
	TIME [epoch: 9.25 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2827756054374234		[learning rate: 0.0026589]
	Learning Rate: 0.00265885
	LOSS [training: 0.2827756054374234 | validation: 0.18529516035839905]
	TIME [epoch: 9.25 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11835652515412232		[learning rate: 0.0026464]
	Learning Rate: 0.00264639
	LOSS [training: 0.11835652515412232 | validation: 0.15954237278801697]
	TIME [epoch: 9.24 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12858226977778117		[learning rate: 0.002634]
	Learning Rate: 0.00263398
	LOSS [training: 0.12858226977778117 | validation: 0.12263713516151457]
	TIME [epoch: 9.24 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08773702213219738		[learning rate: 0.0026216]
	Learning Rate: 0.00262163
	LOSS [training: 0.08773702213219738 | validation: 0.0962557512747017]
	TIME [epoch: 9.24 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09357323822527662		[learning rate: 0.0026093]
	Learning Rate: 0.00260934
	LOSS [training: 0.09357323822527662 | validation: 0.1415064720748289]
	TIME [epoch: 9.26 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18691822592327018		[learning rate: 0.0025971]
	Learning Rate: 0.00259711
	LOSS [training: 0.18691822592327018 | validation: 0.09541236484460044]
	TIME [epoch: 9.25 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0753624113079578		[learning rate: 0.0025849]
	Learning Rate: 0.00258493
	LOSS [training: 0.0753624113079578 | validation: 0.16667748352162404]
	TIME [epoch: 9.24 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12249586622479773		[learning rate: 0.0025728]
	Learning Rate: 0.00257281
	LOSS [training: 0.12249586622479773 | validation: 0.1725495409192576]
	TIME [epoch: 9.24 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12224917828773704		[learning rate: 0.0025608]
	Learning Rate: 0.00256075
	LOSS [training: 0.12224917828773704 | validation: 0.07511180692272962]
	TIME [epoch: 9.24 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0940177633972549		[learning rate: 0.0025487]
	Learning Rate: 0.00254875
	LOSS [training: 0.0940177633972549 | validation: 0.16394265200613664]
	TIME [epoch: 9.24 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07704796676131775		[learning rate: 0.0025368]
	Learning Rate: 0.0025368
	LOSS [training: 0.07704796676131775 | validation: 0.15601947615525802]
	TIME [epoch: 9.25 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09007805077882351		[learning rate: 0.0025249]
	Learning Rate: 0.0025249
	LOSS [training: 0.09007805077882351 | validation: 0.15545596434829592]
	TIME [epoch: 9.23 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10876855164125736		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.10876855164125736 | validation: 0.10779220759873878]
	TIME [epoch: 9.22 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16341847250131442		[learning rate: 0.0025013]
	Learning Rate: 0.00250129
	LOSS [training: 0.16341847250131442 | validation: 0.13848659568358343]
	TIME [epoch: 9.25 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16461133450870252		[learning rate: 0.0024896]
	Learning Rate: 0.00248956
	LOSS [training: 0.16461133450870252 | validation: 0.16678263026582246]
	TIME [epoch: 9.22 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27292790590410004		[learning rate: 0.0024779]
	Learning Rate: 0.00247789
	LOSS [training: 0.27292790590410004 | validation: 0.3163167123371888]
	TIME [epoch: 9.22 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22873968308974976		[learning rate: 0.0024663]
	Learning Rate: 0.00246627
	LOSS [training: 0.22873968308974976 | validation: 0.2287442252393632]
	TIME [epoch: 9.23 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21706976046968932		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.21706976046968932 | validation: 0.14546161641830546]
	TIME [epoch: 9.23 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20903100808832792		[learning rate: 0.0024432]
	Learning Rate: 0.0024432
	LOSS [training: 0.20903100808832792 | validation: 0.1199290490608769]
	TIME [epoch: 9.25 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1673897888801376		[learning rate: 0.0024317]
	Learning Rate: 0.00243175
	LOSS [training: 0.1673897888801376 | validation: 0.10951144165674057]
	TIME [epoch: 9.22 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14119838469213247		[learning rate: 0.0024203]
	Learning Rate: 0.00242035
	LOSS [training: 0.14119838469213247 | validation: 0.2163496042132313]
	TIME [epoch: 9.22 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1393936913120144		[learning rate: 0.002409]
	Learning Rate: 0.002409
	LOSS [training: 0.1393936913120144 | validation: 0.14104368369421294]
	TIME [epoch: 9.22 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13048105403548266		[learning rate: 0.0023977]
	Learning Rate: 0.00239771
	LOSS [training: 0.13048105403548266 | validation: 0.11603114042656668]
	TIME [epoch: 9.26 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10248766287712774		[learning rate: 0.0023865]
	Learning Rate: 0.00238647
	LOSS [training: 0.10248766287712774 | validation: 0.07045693696957445]
	TIME [epoch: 9.23 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0683031389980173		[learning rate: 0.0023753]
	Learning Rate: 0.00237528
	LOSS [training: 0.0683031389980173 | validation: 0.07306880302900134]
	TIME [epoch: 9.22 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07960255190891993		[learning rate: 0.0023641]
	Learning Rate: 0.00236414
	LOSS [training: 0.07960255190891993 | validation: 0.06506788350334625]
	TIME [epoch: 9.22 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09388398582736082		[learning rate: 0.0023531]
	Learning Rate: 0.00235306
	LOSS [training: 0.09388398582736082 | validation: 0.08875143006843092]
	TIME [epoch: 9.23 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09347030943668323		[learning rate: 0.002342]
	Learning Rate: 0.00234203
	LOSS [training: 0.09347030943668323 | validation: 0.09823630462722598]
	TIME [epoch: 9.25 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06531685658627559		[learning rate: 0.002331]
	Learning Rate: 0.00233105
	LOSS [training: 0.06531685658627559 | validation: 0.06979387070245285]
	TIME [epoch: 9.22 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12859808907629994		[learning rate: 0.0023201]
	Learning Rate: 0.00232012
	LOSS [training: 0.12859808907629994 | validation: 0.1298895477032429]
	TIME [epoch: 9.22 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10183240632602102		[learning rate: 0.0023092]
	Learning Rate: 0.00230924
	LOSS [training: 0.10183240632602102 | validation: 0.06411208507143294]
	TIME [epoch: 9.22 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05723924966720255		[learning rate: 0.0022984]
	Learning Rate: 0.00229842
	LOSS [training: 0.05723924966720255 | validation: 0.04986213596636144]
	TIME [epoch: 9.24 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06075798033402997		[learning rate: 0.0022876]
	Learning Rate: 0.00228764
	LOSS [training: 0.06075798033402997 | validation: 0.060012217805339385]
	TIME [epoch: 9.2 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/10] avg loss: 0.050268304502809544		[learning rate: 0.0022769]
	Learning Rate: 0.00227692
	LOSS [training: 0.050268304502809544 | validation: 0.04578878126995052]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_325.pth
	Model improved!!!
EPOCH 326/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07271482104356584		[learning rate: 0.0022662]
	Learning Rate: 0.00226624
	LOSS [training: 0.07271482104356584 | validation: 0.11536462282345403]
	TIME [epoch: 9.23 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09310976855928495		[learning rate: 0.0022556]
	Learning Rate: 0.00225562
	LOSS [training: 0.09310976855928495 | validation: 0.05120390631272153]
	TIME [epoch: 9.23 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07245879688183966		[learning rate: 0.002245]
	Learning Rate: 0.00224504
	LOSS [training: 0.07245879688183966 | validation: 0.07983295819006259]
	TIME [epoch: 9.23 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05828970697873268		[learning rate: 0.0022345]
	Learning Rate: 0.00223452
	LOSS [training: 0.05828970697873268 | validation: 0.03975644551962419]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_329.pth
	Model improved!!!
EPOCH 330/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06560999092679679		[learning rate: 0.002224]
	Learning Rate: 0.00222404
	LOSS [training: 0.06560999092679679 | validation: 0.11701880138145432]
	TIME [epoch: 9.2 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08639473288310098		[learning rate: 0.0022136]
	Learning Rate: 0.00221361
	LOSS [training: 0.08639473288310098 | validation: 0.12729982613925933]
	TIME [epoch: 9.19 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07249175293968824		[learning rate: 0.0022032]
	Learning Rate: 0.00220324
	LOSS [training: 0.07249175293968824 | validation: 0.0836354402841435]
	TIME [epoch: 9.23 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1281164845934829		[learning rate: 0.0021929]
	Learning Rate: 0.00219291
	LOSS [training: 0.1281164845934829 | validation: 0.08428660438565097]
	TIME [epoch: 9.21 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12475066765200102		[learning rate: 0.0021826]
	Learning Rate: 0.00218263
	LOSS [training: 0.12475066765200102 | validation: 0.11739696035052036]
	TIME [epoch: 9.17 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18347855979368524		[learning rate: 0.0021724]
	Learning Rate: 0.00217239
	LOSS [training: 0.18347855979368524 | validation: 0.08187250197078003]
	TIME [epoch: 9.2 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09377584751262377		[learning rate: 0.0021622]
	Learning Rate: 0.00216221
	LOSS [training: 0.09377584751262377 | validation: 0.07843309056958801]
	TIME [epoch: 9.19 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17213511571909215		[learning rate: 0.0021521]
	Learning Rate: 0.00215207
	LOSS [training: 0.17213511571909215 | validation: 0.13095419828519123]
	TIME [epoch: 9.23 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3239886781613082		[learning rate: 0.002142]
	Learning Rate: 0.00214198
	LOSS [training: 0.3239886781613082 | validation: 0.28128275043058404]
	TIME [epoch: 9.2 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20621673441340307		[learning rate: 0.0021319]
	Learning Rate: 0.00213194
	LOSS [training: 0.20621673441340307 | validation: 0.2800390025180222]
	TIME [epoch: 9.2 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40094662769072115		[learning rate: 0.0021219]
	Learning Rate: 0.00212195
	LOSS [training: 0.40094662769072115 | validation: 0.23178342747385536]
	TIME [epoch: 9.2 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19927072214660493		[learning rate: 0.002112]
	Learning Rate: 0.002112
	LOSS [training: 0.19927072214660493 | validation: 0.17877838051580125]
	TIME [epoch: 9.23 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12756298669267702		[learning rate: 0.0021021]
	Learning Rate: 0.0021021
	LOSS [training: 0.12756298669267702 | validation: 0.0920685628652085]
	TIME [epoch: 9.21 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09764129185326188		[learning rate: 0.0020922]
	Learning Rate: 0.00209224
	LOSS [training: 0.09764129185326188 | validation: 0.10508548971526625]
	TIME [epoch: 9.21 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11707988661480077		[learning rate: 0.0020824]
	Learning Rate: 0.00208243
	LOSS [training: 0.11707988661480077 | validation: 0.10345579316345632]
	TIME [epoch: 9.2 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1025684725931042		[learning rate: 0.0020727]
	Learning Rate: 0.00207267
	LOSS [training: 0.1025684725931042 | validation: 0.16679540714120844]
	TIME [epoch: 9.22 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09845161433038979		[learning rate: 0.002063]
	Learning Rate: 0.00206295
	LOSS [training: 0.09845161433038979 | validation: 0.061813376517428034]
	TIME [epoch: 9.24 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06298565397052526		[learning rate: 0.0020533]
	Learning Rate: 0.00205328
	LOSS [training: 0.06298565397052526 | validation: 0.16969226426616768]
	TIME [epoch: 9.21 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14083048930036343		[learning rate: 0.0020437]
	Learning Rate: 0.00204366
	LOSS [training: 0.14083048930036343 | validation: 0.1620322946938816]
	TIME [epoch: 9.21 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1053496589832316		[learning rate: 0.0020341]
	Learning Rate: 0.00203408
	LOSS [training: 0.1053496589832316 | validation: 0.07950279623508245]
	TIME [epoch: 9.22 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10762922543980213		[learning rate: 0.0020245]
	Learning Rate: 0.00202454
	LOSS [training: 0.10762922543980213 | validation: 0.1364443817890866]
	TIME [epoch: 9.25 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1179958228822777		[learning rate: 0.002015]
	Learning Rate: 0.00201505
	LOSS [training: 0.1179958228822777 | validation: 0.13775933234893867]
	TIME [epoch: 9.23 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07353185637472932		[learning rate: 0.0020056]
	Learning Rate: 0.0020056
	LOSS [training: 0.07353185637472932 | validation: 0.0665700137687038]
	TIME [epoch: 9.24 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07437314054984005		[learning rate: 0.0019962]
	Learning Rate: 0.0019962
	LOSS [training: 0.07437314054984005 | validation: 0.10931497937010043]
	TIME [epoch: 9.23 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08230292355904298		[learning rate: 0.0019868]
	Learning Rate: 0.00198684
	LOSS [training: 0.08230292355904298 | validation: 0.06467256992760399]
	TIME [epoch: 9.23 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06697696596926252		[learning rate: 0.0019775]
	Learning Rate: 0.00197753
	LOSS [training: 0.06697696596926252 | validation: 0.1114371640002999]
	TIME [epoch: 9.26 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12182406531341357		[learning rate: 0.0019683]
	Learning Rate: 0.00196826
	LOSS [training: 0.12182406531341357 | validation: 0.052628676029174606]
	TIME [epoch: 9.23 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06522814810405252		[learning rate: 0.001959]
	Learning Rate: 0.00195903
	LOSS [training: 0.06522814810405252 | validation: 0.07100354278613695]
	TIME [epoch: 9.23 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07581232311719895		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.07581232311719895 | validation: 0.07666940125376759]
	TIME [epoch: 9.23 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07623630169815297		[learning rate: 0.0019407]
	Learning Rate: 0.0019407
	LOSS [training: 0.07623630169815297 | validation: 0.07768791257134246]
	TIME [epoch: 9.24 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06886235045689433		[learning rate: 0.0019316]
	Learning Rate: 0.00193161
	LOSS [training: 0.06886235045689433 | validation: 0.08323497937779997]
	TIME [epoch: 9.23 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/10] avg loss: 0.058518645449681515		[learning rate: 0.0019225]
	Learning Rate: 0.00192255
	LOSS [training: 0.058518645449681515 | validation: 0.055851457407009794]
	TIME [epoch: 9.23 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08198282278353548		[learning rate: 0.0019135]
	Learning Rate: 0.00191354
	LOSS [training: 0.08198282278353548 | validation: 0.045609008672965995]
	TIME [epoch: 9.23 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/10] avg loss: 0.058240720981950454		[learning rate: 0.0019046]
	Learning Rate: 0.00190457
	LOSS [training: 0.058240720981950454 | validation: 0.09901591777848498]
	TIME [epoch: 9.22 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04302557751113954		[learning rate: 0.0018956]
	Learning Rate: 0.00189564
	LOSS [training: 0.04302557751113954 | validation: 0.02638041071039248]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_364.pth
	Model improved!!!
EPOCH 365/500:
	Training over batches...
		[batch 10/10] avg loss: 0.038928746039488746		[learning rate: 0.0018867]
	Learning Rate: 0.00188675
	LOSS [training: 0.038928746039488746 | validation: 0.053468766220013425]
	TIME [epoch: 9.23 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04571747880273247		[learning rate: 0.0018779]
	Learning Rate: 0.0018779
	LOSS [training: 0.04571747880273247 | validation: 0.0801004341414667]
	TIME [epoch: 9.23 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10030777906237084		[learning rate: 0.0018691]
	Learning Rate: 0.0018691
	LOSS [training: 0.10030777906237084 | validation: 0.0663074574731678]
	TIME [epoch: 9.23 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07915002621709959		[learning rate: 0.0018603]
	Learning Rate: 0.00186034
	LOSS [training: 0.07915002621709959 | validation: 0.06955497199197576]
	TIME [epoch: 9.23 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07364630379813447		[learning rate: 0.0018516]
	Learning Rate: 0.00185162
	LOSS [training: 0.07364630379813447 | validation: 0.059934678945301294]
	TIME [epoch: 9.23 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05608130936502391		[learning rate: 0.0018429]
	Learning Rate: 0.00184294
	LOSS [training: 0.05608130936502391 | validation: 0.0696173113878732]
	TIME [epoch: 9.23 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06730599672783069		[learning rate: 0.0018343]
	Learning Rate: 0.0018343
	LOSS [training: 0.06730599672783069 | validation: 0.02926365451181901]
	TIME [epoch: 9.23 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03205069555304539		[learning rate: 0.0018257]
	Learning Rate: 0.0018257
	LOSS [training: 0.03205069555304539 | validation: 0.02749677870551612]
	TIME [epoch: 9.23 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05064174766049902		[learning rate: 0.0018171]
	Learning Rate: 0.00181714
	LOSS [training: 0.05064174766049902 | validation: 0.04511716268074307]
	TIME [epoch: 9.25 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03822914701156343		[learning rate: 0.0018086]
	Learning Rate: 0.00180862
	LOSS [training: 0.03822914701156343 | validation: 0.038317792042375017]
	TIME [epoch: 9.21 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05817882335506865		[learning rate: 0.0018001]
	Learning Rate: 0.00180014
	LOSS [training: 0.05817882335506865 | validation: 0.08132265156330022]
	TIME [epoch: 9.2 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05063983443870014		[learning rate: 0.0017917]
	Learning Rate: 0.0017917
	LOSS [training: 0.05063983443870014 | validation: 0.058171449477343214]
	TIME [epoch: 9.22 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03956811197328981		[learning rate: 0.0017833]
	Learning Rate: 0.0017833
	LOSS [training: 0.03956811197328981 | validation: 0.03490689746557958]
	TIME [epoch: 19 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04259696837022873		[learning rate: 0.0017749]
	Learning Rate: 0.00177494
	LOSS [training: 0.04259696837022873 | validation: 0.08391961905680595]
	TIME [epoch: 9.22 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0444516691599719		[learning rate: 0.0017666]
	Learning Rate: 0.00176662
	LOSS [training: 0.0444516691599719 | validation: 0.04851655708651813]
	TIME [epoch: 9.2 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04512403640107395		[learning rate: 0.0017583]
	Learning Rate: 0.00175834
	LOSS [training: 0.04512403640107395 | validation: 0.0459378186562045]
	TIME [epoch: 9.22 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0666630687977818		[learning rate: 0.0017501]
	Learning Rate: 0.00175009
	LOSS [training: 0.0666630687977818 | validation: 0.094349429461869]
	TIME [epoch: 9.21 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09515796798662693		[learning rate: 0.0017419]
	Learning Rate: 0.00174189
	LOSS [training: 0.09515796798662693 | validation: 0.06262041243147948]
	TIME [epoch: 9.24 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/10] avg loss: 0.057096135423442204		[learning rate: 0.0017337]
	Learning Rate: 0.00173372
	LOSS [training: 0.057096135423442204 | validation: 0.06908184414446641]
	TIME [epoch: 9.23 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07365148736087374		[learning rate: 0.0017256]
	Learning Rate: 0.00172559
	LOSS [training: 0.07365148736087374 | validation: 0.07496938421036098]
	TIME [epoch: 9.22 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/10] avg loss: 0.055077128766431935		[learning rate: 0.0017175]
	Learning Rate: 0.0017175
	LOSS [training: 0.055077128766431935 | validation: 0.07577424051964841]
	TIME [epoch: 9.22 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05299055766701569		[learning rate: 0.0017095]
	Learning Rate: 0.00170945
	LOSS [training: 0.05299055766701569 | validation: 0.03586537695057067]
	TIME [epoch: 9.25 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07186472763838833		[learning rate: 0.0017014]
	Learning Rate: 0.00170144
	LOSS [training: 0.07186472763838833 | validation: 0.12393803265764061]
	TIME [epoch: 9.22 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07864025333545725		[learning rate: 0.0016935]
	Learning Rate: 0.00169346
	LOSS [training: 0.07864025333545725 | validation: 0.04512949682830969]
	TIME [epoch: 9.22 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04076589501458931		[learning rate: 0.0016855]
	Learning Rate: 0.00168552
	LOSS [training: 0.04076589501458931 | validation: 0.04048849265164049]
	TIME [epoch: 9.24 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04370482799247054		[learning rate: 0.0016776]
	Learning Rate: 0.00167762
	LOSS [training: 0.04370482799247054 | validation: 0.08119250386082236]
	TIME [epoch: 9.21 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09848902145131112		[learning rate: 0.0016698]
	Learning Rate: 0.00166976
	LOSS [training: 0.09848902145131112 | validation: 0.06149186406147372]
	TIME [epoch: 9.24 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/10] avg loss: 0.055872826436492974		[learning rate: 0.0016619]
	Learning Rate: 0.00166193
	LOSS [training: 0.055872826436492974 | validation: 0.04400148447221378]
	TIME [epoch: 9.22 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/10] avg loss: 0.047404450725603474		[learning rate: 0.0016541]
	Learning Rate: 0.00165414
	LOSS [training: 0.047404450725603474 | validation: 0.03594651514154395]
	TIME [epoch: 9.54 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/10] avg loss: 0.061930305734702464		[learning rate: 0.0016464]
	Learning Rate: 0.00164638
	LOSS [training: 0.061930305734702464 | validation: 0.05947768996555873]
	TIME [epoch: 9.21 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04892795750174827		[learning rate: 0.0016387]
	Learning Rate: 0.00163866
	LOSS [training: 0.04892795750174827 | validation: 0.03438379642095238]
	TIME [epoch: 9.23 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05200117945220791		[learning rate: 0.001631]
	Learning Rate: 0.00163098
	LOSS [training: 0.05200117945220791 | validation: 0.09355332490622964]
	TIME [epoch: 9.23 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/10] avg loss: 0.046565440964952534		[learning rate: 0.0016233]
	Learning Rate: 0.00162333
	LOSS [training: 0.046565440964952534 | validation: 0.05615301357653449]
	TIME [epoch: 9.22 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08281044167266143		[learning rate: 0.0016157]
	Learning Rate: 0.00161572
	LOSS [training: 0.08281044167266143 | validation: 0.23270261419797958]
	TIME [epoch: 9.21 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15311879491745603		[learning rate: 0.0016081]
	Learning Rate: 0.00160815
	LOSS [training: 0.15311879491745603 | validation: 0.09348220360827625]
	TIME [epoch: 9.21 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0711997073846143		[learning rate: 0.0016006]
	Learning Rate: 0.00160061
	LOSS [training: 0.0711997073846143 | validation: 0.11013352412359302]
	TIME [epoch: 9.23 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17653633577009492		[learning rate: 0.0015931]
	Learning Rate: 0.00159311
	LOSS [training: 0.17653633577009492 | validation: 0.21861460424545054]
	TIME [epoch: 9.22 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09167896694321469		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.09167896694321469 | validation: 0.09053189697113748]
	TIME [epoch: 9.22 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0804546898662828		[learning rate: 0.0015782]
	Learning Rate: 0.0015782
	LOSS [training: 0.0804546898662828 | validation: 0.11539807511356431]
	TIME [epoch: 9.22 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1806845494837793		[learning rate: 0.0015708]
	Learning Rate: 0.00157081
	LOSS [training: 0.1806845494837793 | validation: 0.09772517703623831]
	TIME [epoch: 9.22 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08373838086953841		[learning rate: 0.0015634]
	Learning Rate: 0.00156344
	LOSS [training: 0.08373838086953841 | validation: 0.05208991924087339]
	TIME [epoch: 9.23 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0714514913557071		[learning rate: 0.0015561]
	Learning Rate: 0.00155611
	LOSS [training: 0.0714514913557071 | validation: 0.09276585282333524]
	TIME [epoch: 9.21 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06939205844315516		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.06939205844315516 | validation: 0.1302511857444984]
	TIME [epoch: 9.21 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0911277414025536		[learning rate: 0.0015416]
	Learning Rate: 0.00154156
	LOSS [training: 0.0911277414025536 | validation: 0.13479555192913942]
	TIME [epoch: 9.2 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09592297481555635		[learning rate: 0.0015343]
	Learning Rate: 0.00153433
	LOSS [training: 0.09592297481555635 | validation: 0.07812082023986136]
	TIME [epoch: 9.24 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12085807375530111		[learning rate: 0.0015271]
	Learning Rate: 0.00152714
	LOSS [training: 0.12085807375530111 | validation: 0.13291272814426175]
	TIME [epoch: 9.2 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07244967121562627		[learning rate: 0.00152]
	Learning Rate: 0.00151998
	LOSS [training: 0.07244967121562627 | validation: 0.04240626146556924]
	TIME [epoch: 9.21 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08160933667810825		[learning rate: 0.0015129]
	Learning Rate: 0.00151285
	LOSS [training: 0.08160933667810825 | validation: 0.05385121720980689]
	TIME [epoch: 9.2 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03939135601249573		[learning rate: 0.0015058]
	Learning Rate: 0.00150576
	LOSS [training: 0.03939135601249573 | validation: 0.08782743237688681]
	TIME [epoch: 9.24 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06308881676315628		[learning rate: 0.0014987]
	Learning Rate: 0.0014987
	LOSS [training: 0.06308881676315628 | validation: 0.052820837499309894]
	TIME [epoch: 9.22 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04606800016254018		[learning rate: 0.0014917]
	Learning Rate: 0.00149167
	LOSS [training: 0.04606800016254018 | validation: 0.0582339976034363]
	TIME [epoch: 9.24 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/10] avg loss: 0.048299727292771835		[learning rate: 0.0014847]
	Learning Rate: 0.00148468
	LOSS [training: 0.048299727292771835 | validation: 0.03609668474979775]
	TIME [epoch: 9.22 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03068521105187077		[learning rate: 0.0014777]
	Learning Rate: 0.00147772
	LOSS [training: 0.03068521105187077 | validation: 0.04949502698106925]
	TIME [epoch: 9.23 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/10] avg loss: 0.039051790338147284		[learning rate: 0.0014708]
	Learning Rate: 0.00147079
	LOSS [training: 0.039051790338147284 | validation: 0.036026360493166425]
	TIME [epoch: 9.25 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03370745466975192		[learning rate: 0.0014639]
	Learning Rate: 0.0014639
	LOSS [training: 0.03370745466975192 | validation: 0.062043813513959524]
	TIME [epoch: 9.23 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/10] avg loss: 0.056544516878199926		[learning rate: 0.001457]
	Learning Rate: 0.00145703
	LOSS [training: 0.056544516878199926 | validation: 0.0767759926303977]
	TIME [epoch: 9.24 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07833412611022521		[learning rate: 0.0014502]
	Learning Rate: 0.0014502
	LOSS [training: 0.07833412611022521 | validation: 0.10211072296601822]
	TIME [epoch: 9.22 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/10] avg loss: 0.055292682523088964		[learning rate: 0.0014434]
	Learning Rate: 0.0014434
	LOSS [training: 0.055292682523088964 | validation: 0.05035496519994449]
	TIME [epoch: 9.25 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04580679640726133		[learning rate: 0.0014366]
	Learning Rate: 0.00143664
	LOSS [training: 0.04580679640726133 | validation: 0.03922422535492357]
	TIME [epoch: 9.23 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07370458638812037		[learning rate: 0.0014299]
	Learning Rate: 0.0014299
	LOSS [training: 0.07370458638812037 | validation: 0.1008091901960905]
	TIME [epoch: 9.22 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08092922050185941		[learning rate: 0.0014232]
	Learning Rate: 0.0014232
	LOSS [training: 0.08092922050185941 | validation: 0.0706883181813996]
	TIME [epoch: 9.22 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/10] avg loss: 0.038911983388186376		[learning rate: 0.0014165]
	Learning Rate: 0.00141653
	LOSS [training: 0.038911983388186376 | validation: 0.03785423248827429]
	TIME [epoch: 9.21 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04837300105417852		[learning rate: 0.0014099]
	Learning Rate: 0.00140989
	LOSS [training: 0.04837300105417852 | validation: 0.07090584692254048]
	TIME [epoch: 9.24 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07300932583404221		[learning rate: 0.0014033]
	Learning Rate: 0.00140328
	LOSS [training: 0.07300932583404221 | validation: 0.0486900978384001]
	TIME [epoch: 9.21 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0367792526309136		[learning rate: 0.0013967]
	Learning Rate: 0.0013967
	LOSS [training: 0.0367792526309136 | validation: 0.058273734509746336]
	TIME [epoch: 9.2 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04156629899514046		[learning rate: 0.0013901]
	Learning Rate: 0.00139015
	LOSS [training: 0.04156629899514046 | validation: 0.03385159242136443]
	TIME [epoch: 9.21 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/10] avg loss: 0.044893531961928315		[learning rate: 0.0013836]
	Learning Rate: 0.00138363
	LOSS [training: 0.044893531961928315 | validation: 0.11256333521016722]
	TIME [epoch: 9.21 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06820188660805768		[learning rate: 0.0013771]
	Learning Rate: 0.00137714
	LOSS [training: 0.06820188660805768 | validation: 0.07204568517549514]
	TIME [epoch: 9.21 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/10] avg loss: 0.034306935185981186		[learning rate: 0.0013707]
	Learning Rate: 0.00137069
	LOSS [training: 0.034306935185981186 | validation: 0.055982509133883765]
	TIME [epoch: 9.22 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05165052632517012		[learning rate: 0.0013643]
	Learning Rate: 0.00136426
	LOSS [training: 0.05165052632517012 | validation: 0.08434308435684974]
	TIME [epoch: 9.21 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05293476758770708		[learning rate: 0.0013579]
	Learning Rate: 0.00135787
	LOSS [training: 0.05293476758770708 | validation: 0.04764667955254949]
	TIME [epoch: 9.21 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03172753051712532		[learning rate: 0.0013515]
	Learning Rate: 0.0013515
	LOSS [training: 0.03172753051712532 | validation: 0.05448026774026877]
	TIME [epoch: 9.23 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05162919738670422		[learning rate: 0.0013452]
	Learning Rate: 0.00134516
	LOSS [training: 0.05162919738670422 | validation: 0.05546608904270106]
	TIME [epoch: 9.22 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04100828601336394		[learning rate: 0.0013389]
	Learning Rate: 0.00133886
	LOSS [training: 0.04100828601336394 | validation: 0.031632610581129456]
	TIME [epoch: 9.21 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03609796406704823		[learning rate: 0.0013326]
	Learning Rate: 0.00133258
	LOSS [training: 0.03609796406704823 | validation: 0.03535191886500109]
	TIME [epoch: 9.22 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/10] avg loss: 0.027485924510868877		[learning rate: 0.0013263]
	Learning Rate: 0.00132633
	LOSS [training: 0.027485924510868877 | validation: 0.028074148394177306]
	TIME [epoch: 9.22 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/10] avg loss: 0.029186747227039022		[learning rate: 0.0013201]
	Learning Rate: 0.00132012
	LOSS [training: 0.029186747227039022 | validation: 0.06336016528581478]
	TIME [epoch: 9.2 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/10] avg loss: 0.048065159483056515		[learning rate: 0.0013139]
	Learning Rate: 0.00131393
	LOSS [training: 0.048065159483056515 | validation: 0.05052117425267944]
	TIME [epoch: 9.2 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05709949072194853		[learning rate: 0.0013078]
	Learning Rate: 0.00130777
	LOSS [training: 0.05709949072194853 | validation: 0.11411299847916771]
	TIME [epoch: 9.22 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12145889137701879		[learning rate: 0.0013016]
	Learning Rate: 0.00130164
	LOSS [training: 0.12145889137701879 | validation: 0.0991535634549908]
	TIME [epoch: 9.21 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06239956493090785		[learning rate: 0.0012955]
	Learning Rate: 0.00129553
	LOSS [training: 0.06239956493090785 | validation: 0.0365811146413446]
	TIME [epoch: 9.24 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/10] avg loss: 0.031004257244073536		[learning rate: 0.0012895]
	Learning Rate: 0.00128946
	LOSS [training: 0.031004257244073536 | validation: 0.04139048463933995]
	TIME [epoch: 9.23 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06211798959114789		[learning rate: 0.0012834]
	Learning Rate: 0.00128342
	LOSS [training: 0.06211798959114789 | validation: 0.056692555948409634]
	TIME [epoch: 9.21 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/10] avg loss: 0.059656009618188496		[learning rate: 0.0012774]
	Learning Rate: 0.0012774
	LOSS [training: 0.059656009618188496 | validation: 0.10719252141606472]
	TIME [epoch: 9.22 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08184244533906507		[learning rate: 0.0012714]
	Learning Rate: 0.00127141
	LOSS [training: 0.08184244533906507 | validation: 0.0792157942491932]
	TIME [epoch: 9.22 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05594355816464641		[learning rate: 0.0012654]
	Learning Rate: 0.00126545
	LOSS [training: 0.05594355816464641 | validation: 0.06831522201549352]
	TIME [epoch: 9.23 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06349162141026513		[learning rate: 0.0012595]
	Learning Rate: 0.00125952
	LOSS [training: 0.06349162141026513 | validation: 0.061384774955758406]
	TIME [epoch: 9.2 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/10] avg loss: 0.040911513716480476		[learning rate: 0.0012536]
	Learning Rate: 0.00125361
	LOSS [training: 0.040911513716480476 | validation: 0.045298661521092146]
	TIME [epoch: 9.22 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07151577162513706		[learning rate: 0.0012477]
	Learning Rate: 0.00124774
	LOSS [training: 0.07151577162513706 | validation: 0.07769270608811893]
	TIME [epoch: 9.23 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/10] avg loss: 0.047250355653037444		[learning rate: 0.0012419]
	Learning Rate: 0.00124189
	LOSS [training: 0.047250355653037444 | validation: 0.07409161274816978]
	TIME [epoch: 9.22 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/10] avg loss: 0.031159109826248126		[learning rate: 0.0012361]
	Learning Rate: 0.00123606
	LOSS [training: 0.031159109826248126 | validation: 0.054963016461669845]
	TIME [epoch: 9.21 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04293242948284962		[learning rate: 0.0012303]
	Learning Rate: 0.00123027
	LOSS [training: 0.04293242948284962 | validation: 0.03910628796503343]
	TIME [epoch: 9.22 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04247989175709118		[learning rate: 0.0012245]
	Learning Rate: 0.0012245
	LOSS [training: 0.04247989175709118 | validation: 0.04524171022579889]
	TIME [epoch: 9.2 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05239117867260538		[learning rate: 0.0012188]
	Learning Rate: 0.00121876
	LOSS [training: 0.05239117867260538 | validation: 0.06409973874527433]
	TIME [epoch: 9.2 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04333896537940812		[learning rate: 0.001213]
	Learning Rate: 0.00121305
	LOSS [training: 0.04333896537940812 | validation: 0.055359027052386406]
	TIME [epoch: 9.2 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08356007558618542		[learning rate: 0.0012074]
	Learning Rate: 0.00120736
	LOSS [training: 0.08356007558618542 | validation: 0.1073055393714426]
	TIME [epoch: 9.2 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1399269190526227		[learning rate: 0.0012017]
	Learning Rate: 0.0012017
	LOSS [training: 0.1399269190526227 | validation: 0.1110132920502312]
	TIME [epoch: 9.18 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07915023220428691		[learning rate: 0.0011961]
	Learning Rate: 0.00119607
	LOSS [training: 0.07915023220428691 | validation: 0.07980432183138426]
	TIME [epoch: 9.22 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05749573126750259		[learning rate: 0.0011905]
	Learning Rate: 0.00119046
	LOSS [training: 0.05749573126750259 | validation: 0.09366839685213754]
	TIME [epoch: 9.24 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/10] avg loss: 0.045234162849627925		[learning rate: 0.0011849]
	Learning Rate: 0.00118488
	LOSS [training: 0.045234162849627925 | validation: 0.09312490281764182]
	TIME [epoch: 9.22 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05156169047464226		[learning rate: 0.0011793]
	Learning Rate: 0.00117932
	LOSS [training: 0.05156169047464226 | validation: 0.0461186852918771]
	TIME [epoch: 9.22 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05259229623144561		[learning rate: 0.0011738]
	Learning Rate: 0.00117379
	LOSS [training: 0.05259229623144561 | validation: 0.0634160279348293]
	TIME [epoch: 9.21 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05840961335092082		[learning rate: 0.0011683]
	Learning Rate: 0.00116829
	LOSS [training: 0.05840961335092082 | validation: 0.09018094042434424]
	TIME [epoch: 9.23 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04494902848566244		[learning rate: 0.0011628]
	Learning Rate: 0.00116281
	LOSS [training: 0.04494902848566244 | validation: 0.06090046385144159]
	TIME [epoch: 9.23 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/10] avg loss: 0.042896516839968604		[learning rate: 0.0011574]
	Learning Rate: 0.00115736
	LOSS [training: 0.042896516839968604 | validation: 0.026425055569527588]
	TIME [epoch: 9.21 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/10] avg loss: 0.038343679664637885		[learning rate: 0.0011519]
	Learning Rate: 0.00115194
	LOSS [training: 0.038343679664637885 | validation: 0.03650844250000124]
	TIME [epoch: 9.21 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/10] avg loss: 0.033807263911280305		[learning rate: 0.0011465]
	Learning Rate: 0.00114654
	LOSS [training: 0.033807263911280305 | validation: 0.04180047158061736]
	TIME [epoch: 9.21 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03268545204713262		[learning rate: 0.0011412]
	Learning Rate: 0.00114116
	LOSS [training: 0.03268545204713262 | validation: 0.04046505463201916]
	TIME [epoch: 9.23 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0429354405857367		[learning rate: 0.0011358]
	Learning Rate: 0.00113581
	LOSS [training: 0.0429354405857367 | validation: 0.029661623885654305]
	TIME [epoch: 9.2 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03391621140424159		[learning rate: 0.0011305]
	Learning Rate: 0.00113049
	LOSS [training: 0.03391621140424159 | validation: 0.0566523365611242]
	TIME [epoch: 9.21 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05657612688035207		[learning rate: 0.0011252]
	Learning Rate: 0.00112519
	LOSS [training: 0.05657612688035207 | validation: 0.07179150912570728]
	TIME [epoch: 9.23 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04822649667406834		[learning rate: 0.0011199]
	Learning Rate: 0.00111991
	LOSS [training: 0.04822649667406834 | validation: 0.02325734276286129]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_476.pth
	Model improved!!!
EPOCH 477/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03030565211125576		[learning rate: 0.0011147]
	Learning Rate: 0.00111466
	LOSS [training: 0.03030565211125576 | validation: 0.023817939573388597]
	TIME [epoch: 9.18 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/10] avg loss: 0.031936927076765334		[learning rate: 0.0011094]
	Learning Rate: 0.00110944
	LOSS [training: 0.031936927076765334 | validation: 0.06694876508967443]
	TIME [epoch: 9.21 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05180951868090217		[learning rate: 0.0011042]
	Learning Rate: 0.00110423
	LOSS [training: 0.05180951868090217 | validation: 0.05924218110171588]
	TIME [epoch: 9.2 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03651837493962671		[learning rate: 0.0010991]
	Learning Rate: 0.00109906
	LOSS [training: 0.03651837493962671 | validation: 0.03876759787586584]
	TIME [epoch: 9.18 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04056048623710456		[learning rate: 0.0010939]
	Learning Rate: 0.0010939
	LOSS [training: 0.04056048623710456 | validation: 0.06653700600035797]
	TIME [epoch: 9.22 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/10] avg loss: 0.026824394135582397		[learning rate: 0.0010888]
	Learning Rate: 0.00108878
	LOSS [training: 0.026824394135582397 | validation: 0.022801393463824756]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240214_183250/states/model_tr_study4_482.pth
	Model improved!!!
EPOCH 483/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04745563310867249		[learning rate: 0.0010837]
	Learning Rate: 0.00108367
	LOSS [training: 0.04745563310867249 | validation: 0.06685792907627544]
	TIME [epoch: 9.19 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05263451849549581		[learning rate: 0.0010786]
	Learning Rate: 0.00107859
	LOSS [training: 0.05263451849549581 | validation: 0.06031933269788485]
	TIME [epoch: 9.21 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/10] avg loss: 0.040787125894637476		[learning rate: 0.0010735]
	Learning Rate: 0.00107354
	LOSS [training: 0.040787125894637476 | validation: 0.03860517785554076]
	TIME [epoch: 9.23 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03510350743417605		[learning rate: 0.0010685]
	Learning Rate: 0.0010685
	LOSS [training: 0.03510350743417605 | validation: 0.04316421559327605]
	TIME [epoch: 9.22 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/10] avg loss: 0.033366306579962986		[learning rate: 0.0010635]
	Learning Rate: 0.00106349
	LOSS [training: 0.033366306579962986 | validation: 0.04735964039272938]
	TIME [epoch: 9.22 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04092428365489838		[learning rate: 0.0010585]
	Learning Rate: 0.00105851
	LOSS [training: 0.04092428365489838 | validation: 0.0253960577400978]
	TIME [epoch: 9.2 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04405905180822507		[learning rate: 0.0010535]
	Learning Rate: 0.00105354
	LOSS [training: 0.04405905180822507 | validation: 0.0843647481227966]
	TIME [epoch: 9.23 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08311702431271824		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.08311702431271824 | validation: 0.0401707222492986]
	TIME [epoch: 9.2 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05424303567061164		[learning rate: 0.0010437]
	Learning Rate: 0.00104369
	LOSS [training: 0.05424303567061164 | validation: 0.05518722676036418]
	TIME [epoch: 9.19 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/10] avg loss: 0.041583184575646845		[learning rate: 0.0010388]
	Learning Rate: 0.0010388
	LOSS [training: 0.041583184575646845 | validation: 0.03238289052769973]
	TIME [epoch: 9.19 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/10] avg loss: 0.042249240838576174		[learning rate: 0.0010339]
	Learning Rate: 0.00103393
	LOSS [training: 0.042249240838576174 | validation: 0.04649838480839023]
	TIME [epoch: 9.18 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03435176180860937		[learning rate: 0.0010291]
	Learning Rate: 0.00102908
	LOSS [training: 0.03435176180860937 | validation: 0.03491502686257327]
	TIME [epoch: 9.21 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03228157644358847		[learning rate: 0.0010243]
	Learning Rate: 0.00102426
	LOSS [training: 0.03228157644358847 | validation: 0.027544259403565093]
	TIME [epoch: 9.24 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/10] avg loss: 0.035656973102961745		[learning rate: 0.0010195]
	Learning Rate: 0.00101945
	LOSS [training: 0.035656973102961745 | validation: 0.04557809165349341]
	TIME [epoch: 9.2 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03355222504361591		[learning rate: 0.0010147]
	Learning Rate: 0.00101467
	LOSS [training: 0.03355222504361591 | validation: 0.036362124291119846]
	TIME [epoch: 9.21 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/10] avg loss: 0.044256313373995895		[learning rate: 0.0010099]
	Learning Rate: 0.00100992
	LOSS [training: 0.044256313373995895 | validation: 0.03128329413118019]
	TIME [epoch: 9.2 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/10] avg loss: 0.040363167448555524		[learning rate: 0.0010052]
	Learning Rate: 0.00100518
	LOSS [training: 0.040363167448555524 | validation: 0.03174789509872325]
	TIME [epoch: 9.23 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04850629339355765		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.04850629339355765 | validation: 0.051841580865320064]
	TIME [epoch: 9.22 sec]
Finished training in 4675.692 seconds.
