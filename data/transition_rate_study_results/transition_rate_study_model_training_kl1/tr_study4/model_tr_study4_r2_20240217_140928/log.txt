Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r2', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1788975633

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 9.583462396948073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.583462396948073 | validation: 8.824641773003947]
	TIME [epoch: 79.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.771508412882966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.771508412882966 | validation: 8.344015387580352]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.48217255837488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.48217255837488 | validation: 8.098433475922825]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.268141434555302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.268141434555302 | validation: 7.889087327744636]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.073174915247606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.073174915247606 | validation: 7.669071573023557]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.936483911810834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.936483911810834 | validation: 7.469326123654865]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.676850196799741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.676850196799741 | validation: 7.843954445099763]
	TIME [epoch: 8.37 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.636204202188776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.636204202188776 | validation: 7.053791162760907]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.636286116402421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.636286116402421 | validation: 7.136302437536318]
	TIME [epoch: 8.36 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.324198672863844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.324198672863844 | validation: 6.7955480026659405]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.2722058770063045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.2722058770063045 | validation: 6.856560540210451]
	TIME [epoch: 8.36 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.280684005377152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.280684005377152 | validation: 7.427296143733507]
	TIME [epoch: 8.36 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.360232025627113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.360232025627113 | validation: 6.864525222975325]
	TIME [epoch: 8.36 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.104666834346385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.104666834346385 | validation: 6.773305005756582]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.042131566897838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.042131566897838 | validation: 5.952257636392994]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.830191860219659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.830191860219659 | validation: 6.223730963873068]
	TIME [epoch: 8.34 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.246280684049827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.246280684049827 | validation: 6.08746408500542]
	TIME [epoch: 8.38 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.215934880049728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.215934880049728 | validation: 5.4941265079573025]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.299668850967282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.299668850967282 | validation: 5.1305175469243185]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.202118863831295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.202118863831295 | validation: 5.2134812986102785]
	TIME [epoch: 8.34 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.408926997742995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.408926997742995 | validation: 4.757846536900397]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.001886569800653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.001886569800653 | validation: 4.397169770721015]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.6946340359815215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6946340359815215 | validation: 4.171886266629398]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.591438663654199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.591438663654199 | validation: 4.04036527366975]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.489173641961883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.489173641961883 | validation: 3.968129560645316]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.632750215807545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.632750215807545 | validation: 4.272089119170751]
	TIME [epoch: 8.37 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.146769830966192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.146769830966192 | validation: 4.114003563858519]
	TIME [epoch: 8.35 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.440196175889691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.440196175889691 | validation: 4.048572055859727]
	TIME [epoch: 8.36 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.610197511178816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.610197511178816 | validation: 4.225513617408708]
	TIME [epoch: 8.38 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.736233226554744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.736233226554744 | validation: 4.090860437320002]
	TIME [epoch: 8.38 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.416645892589192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.416645892589192 | validation: 3.889196441927239]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.426447580889769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.426447580889769 | validation: 3.942804718895835]
	TIME [epoch: 8.37 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.405094534776866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.405094534776866 | validation: 3.9456828751768733]
	TIME [epoch: 8.36 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.51359210844382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.51359210844382 | validation: 5.3026449444844825]
	TIME [epoch: 8.39 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.627738188345015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.627738188345015 | validation: 3.9470646206802273]
	TIME [epoch: 8.36 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.527917854831686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.527917854831686 | validation: 4.116642055813369]
	TIME [epoch: 8.36 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.462129596779031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.462129596779031 | validation: 3.8914276181753054]
	TIME [epoch: 8.35 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.481065643372267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.481065643372267 | validation: 3.870747372771757]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.43287264045585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.43287264045585 | validation: 3.794954389815917]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.582312631243096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.582312631243096 | validation: 3.7605775979289966]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.489488541112609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.489488541112609 | validation: 4.099471936253214]
	TIME [epoch: 8.36 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.471465468714299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.471465468714299 | validation: 3.4953501612177065]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_42.pth
	Model improved!!!
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.463068443331244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.463068443331244 | validation: 2.6320857232775396]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.253949564254714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.253949564254714 | validation: 3.6998084815678496]
	TIME [epoch: 8.35 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.788788636835202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.788788636835202 | validation: 3.314345466049807]
	TIME [epoch: 8.35 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.715134247629204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.715134247629204 | validation: 3.2051918969976416]
	TIME [epoch: 8.35 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.234853993886747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.234853993886747 | validation: 4.109166055656921]
	TIME [epoch: 8.37 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.6746907009222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6746907009222 | validation: 3.937252648860149]
	TIME [epoch: 8.35 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.76615862829333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.76615862829333 | validation: 3.7033252293199648]
	TIME [epoch: 8.34 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.386043649793337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.386043649793337 | validation: 3.663360177467363]
	TIME [epoch: 8.35 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.9113653918819367		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 3.9113653918819367 | validation: 2.7948093015744258]
	TIME [epoch: 8.37 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.395234719459496		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 3.395234719459496 | validation: 4.26994093584787]
	TIME [epoch: 8.35 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.842101125485244		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 3.842101125485244 | validation: 3.3793611057654838]
	TIME [epoch: 8.35 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.892718047253227		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 2.892718047253227 | validation: 2.5600052216372675]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_54.pth
	Model improved!!!
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.573302599224487		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 2.573302599224487 | validation: 2.5916329539702208]
	TIME [epoch: 8.38 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3834099535294526		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 2.3834099535294526 | validation: 3.4895706319149244]
	TIME [epoch: 8.35 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.9291151666373905		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 2.9291151666373905 | validation: 2.820529058213922]
	TIME [epoch: 8.35 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.614995542310246		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 2.614995542310246 | validation: 3.512307194098174]
	TIME [epoch: 8.34 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.469115152411023		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 2.469115152411023 | validation: 2.290677512041335]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_59.pth
	Model improved!!!
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.5000845846537976		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 2.5000845846537976 | validation: 2.2393783023783485]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_60.pth
	Model improved!!!
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.4893066375198813		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 2.4893066375198813 | validation: 2.5323052260482486]
	TIME [epoch: 8.35 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.5262634844277363		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 2.5262634844277363 | validation: 2.101928299414193]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_62.pth
	Model improved!!!
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2740967300262644		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 2.2740967300262644 | validation: 2.4520168683156314]
	TIME [epoch: 8.36 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.186970019654984		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 2.186970019654984 | validation: 3.141216269196848]
	TIME [epoch: 8.38 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2774345177662654		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 2.2774345177662654 | validation: 1.8505576104432053]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_65.pth
	Model improved!!!
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.4726897977760305		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 2.4726897977760305 | validation: 1.911637069373926]
	TIME [epoch: 8.37 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.104520267175161		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 2.104520267175161 | validation: 1.9126377378253814]
	TIME [epoch: 8.38 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0989121326466553		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 2.0989121326466553 | validation: 2.131783149610616]
	TIME [epoch: 8.4 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0663839356114253		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 2.0663839356114253 | validation: 3.415521575447052]
	TIME [epoch: 8.37 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3004712192075996		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 2.3004712192075996 | validation: 1.9122356985209596]
	TIME [epoch: 8.37 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1907769329969797		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 2.1907769329969797 | validation: 2.208127195830836]
	TIME [epoch: 8.37 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0233211584019486		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 2.0233211584019486 | validation: 2.007326124246128]
	TIME [epoch: 8.39 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0154856751789847		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 2.0154856751789847 | validation: 2.395758694543452]
	TIME [epoch: 8.37 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1495868112051615		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 2.1495868112051615 | validation: 2.557474486825475]
	TIME [epoch: 8.37 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9876579368952563		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 1.9876579368952563 | validation: 1.9293715375445044]
	TIME [epoch: 8.37 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8901221939885258		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 1.8901221939885258 | validation: 1.7853638437444292]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_76.pth
	Model improved!!!
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8669615156788217		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 1.8669615156788217 | validation: 1.6293394804176908]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_77.pth
	Model improved!!!
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6286674488502917		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 1.6286674488502917 | validation: 2.979044383141748]
	TIME [epoch: 8.37 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9083719614940962		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 1.9083719614940962 | validation: 1.8285429407300953]
	TIME [epoch: 8.37 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.828428812983476		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 1.828428812983476 | validation: 1.8265436988786412]
	TIME [epoch: 8.37 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7629211032188994		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 1.7629211032188994 | validation: 1.6589941363714695]
	TIME [epoch: 8.39 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8908299834617897		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 1.8908299834617897 | validation: 1.8006289683971843]
	TIME [epoch: 8.38 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7281166775849932		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 1.7281166775849932 | validation: 2.189746291067035]
	TIME [epoch: 8.36 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6718565627017121		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 1.6718565627017121 | validation: 1.6592574745342477]
	TIME [epoch: 8.36 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5861377152644494		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 1.5861377152644494 | validation: 1.3130184681802737]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_85.pth
	Model improved!!!
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.405899083230158		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 1.405899083230158 | validation: 1.4778245987151404]
	TIME [epoch: 8.37 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5568016044338386		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 1.5568016044338386 | validation: 1.439847317609154]
	TIME [epoch: 8.37 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5288194883295683		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.5288194883295683 | validation: 1.3578272528806725]
	TIME [epoch: 8.37 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4907238936143565		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.4907238936143565 | validation: 1.8211480427594946]
	TIME [epoch: 8.38 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.484217057235136		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.484217057235136 | validation: 2.3942258723775596]
	TIME [epoch: 8.39 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6170386219694055		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 1.6170386219694055 | validation: 1.8542540159595458]
	TIME [epoch: 8.37 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3845614487087317		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 1.3845614487087317 | validation: 1.498866274278892]
	TIME [epoch: 8.37 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3377093366271675		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 1.3377093366271675 | validation: 1.470095846514965]
	TIME [epoch: 8.37 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5662069361177418		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 1.5662069361177418 | validation: 1.196937009689063]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_94.pth
	Model improved!!!
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.29724352518183		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 1.29724352518183 | validation: 1.3194411212614003]
	TIME [epoch: 8.37 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2404904976885927		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.2404904976885927 | validation: 1.2835086263786009]
	TIME [epoch: 8.37 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3658324052541198		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 1.3658324052541198 | validation: 1.38488617531423]
	TIME [epoch: 8.37 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3512854886970025		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.3512854886970025 | validation: 1.5582171579960216]
	TIME [epoch: 8.39 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4570429636941802		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.4570429636941802 | validation: 1.2515246863300324]
	TIME [epoch: 8.37 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2168144991775613		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.2168144991775613 | validation: 1.5262787697850582]
	TIME [epoch: 8.37 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3403518312289524		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.3403518312289524 | validation: 1.7952063489624777]
	TIME [epoch: 8.37 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.371578531248138		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.371578531248138 | validation: 1.5421978152459077]
	TIME [epoch: 8.39 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.351387837155706		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.351387837155706 | validation: 1.2767768681599363]
	TIME [epoch: 8.39 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3080852817841286		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.3080852817841286 | validation: 1.329037890688844]
	TIME [epoch: 8.37 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0935783674587876		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 1.0935783674587876 | validation: 1.3331026178805665]
	TIME [epoch: 8.37 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4419688079671686		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 1.4419688079671686 | validation: 1.550049930475966]
	TIME [epoch: 8.37 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3369072527442492		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 1.3369072527442492 | validation: 1.3151298273567118]
	TIME [epoch: 8.4 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3594461626893328		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.3594461626893328 | validation: 1.1322070828718456]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_108.pth
	Model improved!!!
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.303637496374898		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.303637496374898 | validation: 1.22978678481847]
	TIME [epoch: 8.37 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2917277273074406		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.2917277273074406 | validation: 1.1634471065711605]
	TIME [epoch: 8.37 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3378298510219266		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.3378298510219266 | validation: 1.202155205343321]
	TIME [epoch: 8.4 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2853590657963458		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 1.2853590657963458 | validation: 1.3157938141970862]
	TIME [epoch: 8.38 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.257144215229498		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 1.257144215229498 | validation: 1.5084716512504341]
	TIME [epoch: 8.37 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2188242338760529		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 1.2188242338760529 | validation: 1.2801217390596782]
	TIME [epoch: 8.36 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3171363544030754		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.3171363544030754 | validation: 1.0529729189249284]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_115.pth
	Model improved!!!
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2640674485838943		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 1.2640674485838943 | validation: 1.098007370742534]
	TIME [epoch: 8.37 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1941051120608015		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 1.1941051120608015 | validation: 1.25989101291611]
	TIME [epoch: 8.37 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3338101682190187		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 1.3338101682190187 | validation: 1.184071086507307]
	TIME [epoch: 8.36 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.153952244893614		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 1.153952244893614 | validation: 1.1484331564075878]
	TIME [epoch: 8.36 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.384954138051659		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.384954138051659 | validation: 1.418831922970607]
	TIME [epoch: 8.38 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.297691236072787		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 1.297691236072787 | validation: 1.1846266201649143]
	TIME [epoch: 8.36 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3473367049067009		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 1.3473367049067009 | validation: 1.1838014327731305]
	TIME [epoch: 8.36 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2668769467770127		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 1.2668769467770127 | validation: 1.6134441284292516]
	TIME [epoch: 8.35 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.286037234579576		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 1.286037234579576 | validation: 1.070430337655098]
	TIME [epoch: 8.38 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2300129046703636		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 1.2300129046703636 | validation: 1.1515710067149925]
	TIME [epoch: 8.36 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2546302813996282		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 1.2546302813996282 | validation: 1.2675248022972028]
	TIME [epoch: 8.37 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2783722198672907		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 1.2783722198672907 | validation: 1.4297284012148104]
	TIME [epoch: 8.37 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2174769534208203		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.2174769534208203 | validation: 1.2645818433732678]
	TIME [epoch: 8.39 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.14466184780335		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 1.14466184780335 | validation: 1.1869879645595007]
	TIME [epoch: 8.36 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1773115186990954		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 1.1773115186990954 | validation: 1.2873569289349316]
	TIME [epoch: 8.37 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1863183628447165		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 1.1863183628447165 | validation: 1.5622040520876772]
	TIME [epoch: 8.37 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2383328390443804		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 1.2383328390443804 | validation: 1.1194840807168491]
	TIME [epoch: 8.37 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1370984975128666		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 1.1370984975128666 | validation: 1.4227267188336716]
	TIME [epoch: 8.4 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1666260931008778		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 1.1666260931008778 | validation: 1.0936200627811414]
	TIME [epoch: 8.36 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1552461671042469		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 1.1552461671042469 | validation: 1.1965478636466542]
	TIME [epoch: 8.36 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2099610434793528		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 1.2099610434793528 | validation: 1.5375984163256755]
	TIME [epoch: 8.36 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1466882614139733		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 1.1466882614139733 | validation: 1.186391360488519]
	TIME [epoch: 8.38 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0630041530715666		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.0630041530715666 | validation: 1.4569094108704133]
	TIME [epoch: 8.36 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0939399297320567		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 1.0939399297320567 | validation: 1.2986213476604553]
	TIME [epoch: 8.37 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0459306404702569		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 1.0459306404702569 | validation: 1.1123668741442083]
	TIME [epoch: 8.35 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.140679349372647		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 1.140679349372647 | validation: 1.4233870156163202]
	TIME [epoch: 8.38 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1450174802045807		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 1.1450174802045807 | validation: 1.4920425348676112]
	TIME [epoch: 8.37 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2854871847766298		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 1.2854871847766298 | validation: 1.217066661782828]
	TIME [epoch: 8.36 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.148564497909622		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 1.148564497909622 | validation: 1.2511349988195906]
	TIME [epoch: 8.36 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2302045437346565		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 1.2302045437346565 | validation: 1.90552668061762]
	TIME [epoch: 8.37 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3133615563434913		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 1.3133615563434913 | validation: 1.304705032960522]
	TIME [epoch: 8.38 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1617896124912517		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 1.1617896124912517 | validation: 1.1603522885803301]
	TIME [epoch: 8.36 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1037672155342428		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 1.1037672155342428 | validation: 1.4167740439228589]
	TIME [epoch: 8.36 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2248548856525896		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 1.2248548856525896 | validation: 1.3599985514529482]
	TIME [epoch: 8.36 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1396823167215655		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 1.1396823167215655 | validation: 1.659381056221588]
	TIME [epoch: 8.38 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1971783125097986		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 1.1971783125097986 | validation: 1.1372039240796075]
	TIME [epoch: 8.37 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.071046553662499		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 1.071046553662499 | validation: 1.6440969685446534]
	TIME [epoch: 8.36 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.316202553291133		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 1.316202553291133 | validation: 1.153250528709581]
	TIME [epoch: 8.36 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1112066255367181		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 1.1112066255367181 | validation: 1.3382932771028266]
	TIME [epoch: 8.38 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1537218560675548		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 1.1537218560675548 | validation: 1.0618276426859243]
	TIME [epoch: 8.36 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1716683438109665		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 1.1716683438109665 | validation: 1.1494286321907623]
	TIME [epoch: 8.37 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2307367964925624		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 1.2307367964925624 | validation: 1.4122875215421038]
	TIME [epoch: 8.37 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.179492748855561		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 1.179492748855561 | validation: 1.1121461537989845]
	TIME [epoch: 8.35 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.129925311779717		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 1.129925311779717 | validation: 1.2506859845169829]
	TIME [epoch: 8.38 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0901064909235934		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 1.0901064909235934 | validation: 1.2290591955175416]
	TIME [epoch: 8.35 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2476042954663407		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 1.2476042954663407 | validation: 1.0000590812936245]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_161.pth
	Model improved!!!
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1260419769184244		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 1.1260419769184244 | validation: 1.0564043824923361]
	TIME [epoch: 8.35 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0981512526652533		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 1.0981512526652533 | validation: 1.3407598695832914]
	TIME [epoch: 8.38 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1305638054844265		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 1.1305638054844265 | validation: 1.1128899218701176]
	TIME [epoch: 8.37 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2697019676519754		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 1.2697019676519754 | validation: 1.139527812497788]
	TIME [epoch: 8.37 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0890154815448558		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 1.0890154815448558 | validation: 1.1291992834219133]
	TIME [epoch: 8.36 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2228198822398506		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 1.2228198822398506 | validation: 1.2508742805912014]
	TIME [epoch: 8.39 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2093518170454831		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 1.2093518170454831 | validation: 1.1774943871599004]
	TIME [epoch: 8.36 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1435819089526842		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 1.1435819089526842 | validation: 1.2945151498333924]
	TIME [epoch: 8.36 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0639915314311403		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 1.0639915314311403 | validation: 1.2609143978629422]
	TIME [epoch: 8.36 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0866882482989364		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 1.0866882482989364 | validation: 1.3703611576189103]
	TIME [epoch: 8.35 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1712370952666702		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 1.1712370952666702 | validation: 1.2304784111879206]
	TIME [epoch: 8.38 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.157875748074609		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 1.157875748074609 | validation: 1.0839759561254105]
	TIME [epoch: 8.36 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2550082252560224		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 1.2550082252560224 | validation: 1.0004526650343222]
	TIME [epoch: 8.36 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1302382830648168		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 1.1302382830648168 | validation: 1.4253668494393388]
	TIME [epoch: 8.36 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1323192126900128		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 1.1323192126900128 | validation: 1.157848334485189]
	TIME [epoch: 8.38 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0572963919500125		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 1.0572963919500125 | validation: 0.9949925760767843]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_177.pth
	Model improved!!!
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0016411252420148		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 1.0016411252420148 | validation: 1.335569663397246]
	TIME [epoch: 8.36 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.177131412917214		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 1.177131412917214 | validation: 1.1318260337345776]
	TIME [epoch: 8.37 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0456360537437908		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 1.0456360537437908 | validation: 1.3496536826144365]
	TIME [epoch: 8.39 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1963268754335554		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 1.1963268754335554 | validation: 1.695380489479914]
	TIME [epoch: 8.37 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0458482987288624		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 1.0458482987288624 | validation: 1.2941559998062282]
	TIME [epoch: 8.37 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0372308062443623		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 1.0372308062443623 | validation: 1.1181973229794508]
	TIME [epoch: 8.36 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0143786044822591		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 1.0143786044822591 | validation: 1.7116710430153352]
	TIME [epoch: 8.37 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1264208702121359		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 1.1264208702121359 | validation: 1.2918463160911227]
	TIME [epoch: 8.37 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0864749709843646		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 1.0864749709843646 | validation: 0.9825965892682286]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_186.pth
	Model improved!!!
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.076075115014045		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 1.076075115014045 | validation: 1.4021750455307131]
	TIME [epoch: 8.37 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.121111495710986		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 1.121111495710986 | validation: 0.9950393335011322]
	TIME [epoch: 8.36 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0241442683213653		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 1.0241442683213653 | validation: 1.3724259947999267]
	TIME [epoch: 8.39 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.131077176496857		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 1.131077176496857 | validation: 1.1341484921834335]
	TIME [epoch: 8.36 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0149275888798281		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 1.0149275888798281 | validation: 1.2186188390961465]
	TIME [epoch: 8.37 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0094356466836767		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 1.0094356466836767 | validation: 1.5159182706626764]
	TIME [epoch: 8.36 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.050804798300391		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 1.050804798300391 | validation: 1.3363222256976797]
	TIME [epoch: 8.38 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0717392741007568		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 1.0717392741007568 | validation: 1.2246770732333077]
	TIME [epoch: 8.37 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9983712190620431		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.9983712190620431 | validation: 0.9686498623005195]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_195.pth
	Model improved!!!
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.034636265541304		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 1.034636265541304 | validation: 1.0646094341384282]
	TIME [epoch: 8.37 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9951897922049803		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.9951897922049803 | validation: 1.80207340327823]
	TIME [epoch: 8.39 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.237372145418966		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 1.237372145418966 | validation: 1.017865586380456]
	TIME [epoch: 8.36 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9716854571526946		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.9716854571526946 | validation: 1.0408346330397809]
	TIME [epoch: 8.36 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.970166874358623		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.970166874358623 | validation: 1.0606046044300437]
	TIME [epoch: 8.37 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0316659426068508		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 1.0316659426068508 | validation: 1.0691125051922725]
	TIME [epoch: 8.36 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1374486054235962		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 1.1374486054235962 | validation: 1.0241597188995128]
	TIME [epoch: 8.38 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0579525650290407		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 1.0579525650290407 | validation: 0.9554551473744275]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_203.pth
	Model improved!!!
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9862422997010676		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.9862422997010676 | validation: 0.9458079689999563]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_204.pth
	Model improved!!!
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0251303175989086		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 1.0251303175989086 | validation: 1.1126938355945062]
	TIME [epoch: 8.37 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9275922990566603		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.9275922990566603 | validation: 1.1941465378779466]
	TIME [epoch: 8.39 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0547863836891578		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 1.0547863836891578 | validation: 1.642035847088232]
	TIME [epoch: 8.37 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.092857599962363		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 1.092857599962363 | validation: 1.2709037051978171]
	TIME [epoch: 8.37 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9791069086341967		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.9791069086341967 | validation: 0.9360890849508516]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_209.pth
	Model improved!!!
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0334172461142024		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 1.0334172461142024 | validation: 0.9789592571004317]
	TIME [epoch: 8.39 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9911559582321108		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.9911559582321108 | validation: 0.9393243746401432]
	TIME [epoch: 8.37 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9305882724244314		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.9305882724244314 | validation: 0.9592616062752051]
	TIME [epoch: 8.37 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9935435668363517		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.9935435668363517 | validation: 0.8883766562117483]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_213.pth
	Model improved!!!
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0481405275283178		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 1.0481405275283178 | validation: 1.0111502125649414]
	TIME [epoch: 8.38 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0550948465483114		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 1.0550948465483114 | validation: 1.5324501786139466]
	TIME [epoch: 8.38 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.124262052716029		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 1.124262052716029 | validation: 1.1587570051946576]
	TIME [epoch: 8.36 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0496130469259337		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 1.0496130469259337 | validation: 1.025295243161406]
	TIME [epoch: 8.36 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0508261500874387		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 1.0508261500874387 | validation: 1.0310174545922752]
	TIME [epoch: 8.36 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9646149767654917		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.9646149767654917 | validation: 1.074412900774286]
	TIME [epoch: 8.39 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1017612889438686		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 1.1017612889438686 | validation: 1.060080631798145]
	TIME [epoch: 8.37 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0074335897748496		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 1.0074335897748496 | validation: 0.9762080812994838]
	TIME [epoch: 8.36 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0775628771615477		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 1.0775628771615477 | validation: 1.1520907708358845]
	TIME [epoch: 8.36 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9466475684700567		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.9466475684700567 | validation: 0.9492166208217169]
	TIME [epoch: 8.39 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0316126242439743		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 1.0316126242439743 | validation: 0.9125515964590464]
	TIME [epoch: 8.37 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0521619351905527		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 1.0521619351905527 | validation: 1.0587910503129112]
	TIME [epoch: 8.36 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.918302587181666		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.918302587181666 | validation: 1.0955125125710539]
	TIME [epoch: 8.37 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.042024806351691		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 1.042024806351691 | validation: 0.9466264082486077]
	TIME [epoch: 8.38 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.043148402024897		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 1.043148402024897 | validation: 0.9766359048021869]
	TIME [epoch: 8.38 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9242888279608247		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.9242888279608247 | validation: 1.081808859360382]
	TIME [epoch: 8.36 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9945140841733556		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.9945140841733556 | validation: 1.1410981807573743]
	TIME [epoch: 8.36 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9114905283760475		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.9114905283760475 | validation: 1.2370628956584206]
	TIME [epoch: 8.37 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.035820180485222		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 1.035820180485222 | validation: 1.108441883746141]
	TIME [epoch: 8.39 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9845852931614028		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.9845852931614028 | validation: 0.9942009671206306]
	TIME [epoch: 8.37 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9421708675979474		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.9421708675979474 | validation: 1.021321183900418]
	TIME [epoch: 8.36 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9346551067987485		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.9346551067987485 | validation: 1.1210367364382694]
	TIME [epoch: 8.37 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.990802924449494		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.990802924449494 | validation: 1.2301817946486646]
	TIME [epoch: 8.39 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0277109536472442		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 1.0277109536472442 | validation: 0.9832123750852655]
	TIME [epoch: 8.36 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9033041341758826		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.9033041341758826 | validation: 1.064978806125314]
	TIME [epoch: 8.36 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9868860901462906		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.9868860901462906 | validation: 0.8709197280938428]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_239.pth
	Model improved!!!
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9048342241592866		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.9048342241592866 | validation: 1.0171507024370534]
	TIME [epoch: 8.39 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0511339590957667		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 1.0511339590957667 | validation: 1.5968078301192516]
	TIME [epoch: 8.36 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0245765629330634		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 1.0245765629330634 | validation: 0.9700362523985695]
	TIME [epoch: 8.37 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9853516242928814		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.9853516242928814 | validation: 1.1981372937233634]
	TIME [epoch: 8.36 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0065511415951849		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 1.0065511415951849 | validation: 1.0122559892049674]
	TIME [epoch: 8.37 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9062705632015703		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.9062705632015703 | validation: 0.8752247237968106]
	TIME [epoch: 8.39 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9826286578816074		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.9826286578816074 | validation: 1.1652587362526892]
	TIME [epoch: 8.37 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9241037282490506		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.9241037282490506 | validation: 0.9504150421722043]
	TIME [epoch: 8.36 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9184706167867368		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.9184706167867368 | validation: 1.0721096098898042]
	TIME [epoch: 8.36 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.981007318020217		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.981007318020217 | validation: 0.858033212239272]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_249.pth
	Model improved!!!
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9119216457352601		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.9119216457352601 | validation: 0.8117653006147361]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_250.pth
	Model improved!!!
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9127148387250668		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.9127148387250668 | validation: 0.8290453238279729]
	TIME [epoch: 8.37 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8345400644921529		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.8345400644921529 | validation: 0.8752733909708894]
	TIME [epoch: 8.36 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9053317246156156		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.9053317246156156 | validation: 0.9009454501662387]
	TIME [epoch: 8.39 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8754566536517533		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.8754566536517533 | validation: 1.2241203116950894]
	TIME [epoch: 8.37 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.885610968712539		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.885610968712539 | validation: 0.8477463582519433]
	TIME [epoch: 8.36 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9569302178083605		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.9569302178083605 | validation: 0.9763003960720966]
	TIME [epoch: 8.36 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8700038247318144		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.8700038247318144 | validation: 1.0751136228183449]
	TIME [epoch: 8.36 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8832712526339606		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.8832712526339606 | validation: 1.1765947948771251]
	TIME [epoch: 8.39 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.905067103316606		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.905067103316606 | validation: 0.9589005904743528]
	TIME [epoch: 8.36 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8144812734439952		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.8144812734439952 | validation: 1.1716464878307697]
	TIME [epoch: 8.35 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8914868051970009		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.8914868051970009 | validation: 0.8634289671125471]
	TIME [epoch: 8.36 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8670018367074389		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.8670018367074389 | validation: 1.1833542798557688]
	TIME [epoch: 8.39 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8405439198974631		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.8405439198974631 | validation: 0.9067485393215726]
	TIME [epoch: 8.36 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8920045096036902		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.8920045096036902 | validation: 0.7975485440169932]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_264.pth
	Model improved!!!
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8378932089375265		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.8378932089375265 | validation: 1.1203584834532632]
	TIME [epoch: 8.36 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9031860742916287		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.9031860742916287 | validation: 0.7882285045512921]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_266.pth
	Model improved!!!
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.860244326831397		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.860244326831397 | validation: 0.800513125847943]
	TIME [epoch: 8.37 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7918688847039009		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.7918688847039009 | validation: 1.2399177535338222]
	TIME [epoch: 8.36 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9301558917009135		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.9301558917009135 | validation: 0.9276676429853372]
	TIME [epoch: 8.36 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8539285548544087		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.8539285548544087 | validation: 0.911489493367601]
	TIME [epoch: 8.38 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8408308256444561		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.8408308256444561 | validation: 1.103338937316487]
	TIME [epoch: 8.37 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8777116691427281		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.8777116691427281 | validation: 0.8167544761418264]
	TIME [epoch: 8.36 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9391258676127267		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.9391258676127267 | validation: 0.7856639552175666]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_273.pth
	Model improved!!!
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7711269710504058		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.7711269710504058 | validation: 0.8648880703232074]
	TIME [epoch: 8.37 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9138758002413422		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.9138758002413422 | validation: 0.9385770486419349]
	TIME [epoch: 8.4 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7922971860826402		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.7922971860826402 | validation: 1.0526052945960989]
	TIME [epoch: 8.37 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9401403046327976		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.9401403046327976 | validation: 0.9411081582036898]
	TIME [epoch: 8.37 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.817657513922127		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.817657513922127 | validation: 0.7897680649539108]
	TIME [epoch: 8.36 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8037795396565832		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.8037795396565832 | validation: 0.7802862632140026]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_279.pth
	Model improved!!!
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9106981798101297		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.9106981798101297 | validation: 0.7519009957920428]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_280.pth
	Model improved!!!
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7591333220980898		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.7591333220980898 | validation: 1.2020081514120045]
	TIME [epoch: 8.36 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8615304751201893		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.8615304751201893 | validation: 0.8051747210241051]
	TIME [epoch: 8.36 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8978177179571267		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.8978177179571267 | validation: 1.0114904305918382]
	TIME [epoch: 8.38 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9326093103841483		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.9326093103841483 | validation: 0.7612891489610016]
	TIME [epoch: 8.37 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8156490373800119		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.8156490373800119 | validation: 0.8116129800366734]
	TIME [epoch: 8.37 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9292889416979445		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.9292889416979445 | validation: 0.7509173550586801]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_286.pth
	Model improved!!!
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8581688500985353		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.8581688500985353 | validation: 0.7163695179520091]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_287.pth
	Model improved!!!
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8978547050057356		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.8978547050057356 | validation: 0.9060036448660291]
	TIME [epoch: 8.39 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8618785834315877		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.8618785834315877 | validation: 0.75999987088126]
	TIME [epoch: 8.35 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8135676824389078		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.8135676824389078 | validation: 0.7497779518392502]
	TIME [epoch: 8.35 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8152500471251687		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.8152500471251687 | validation: 0.817549391270927]
	TIME [epoch: 8.35 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7260615723443239		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.7260615723443239 | validation: 0.8051890977392229]
	TIME [epoch: 8.38 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.843640820669761		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.843640820669761 | validation: 0.6565654741854607]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_293.pth
	Model improved!!!
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8639921011887456		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.8639921011887456 | validation: 0.7806609856958162]
	TIME [epoch: 8.36 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8153548247196204		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.8153548247196204 | validation: 1.091684633701289]
	TIME [epoch: 8.37 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8856716919064288		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.8856716919064288 | validation: 0.6993374131684673]
	TIME [epoch: 8.39 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.853540682583626		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.853540682583626 | validation: 0.7128573442378783]
	TIME [epoch: 8.37 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7715308942616363		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.7715308942616363 | validation: 0.7988039306521201]
	TIME [epoch: 8.36 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7781075384805439		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.7781075384805439 | validation: 1.170701843033135]
	TIME [epoch: 8.37 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8018355366397284		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.8018355366397284 | validation: 0.9497795264621928]
	TIME [epoch: 8.37 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8277639618684228		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.8277639618684228 | validation: 0.9781434002558909]
	TIME [epoch: 8.39 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9884882822905482		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.9884882822905482 | validation: 0.7371845065937652]
	TIME [epoch: 8.35 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8445648508388766		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.8445648508388766 | validation: 0.6685656528550573]
	TIME [epoch: 8.37 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7980541897969614		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.7980541897969614 | validation: 0.6758704378520313]
	TIME [epoch: 8.36 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7635996238183262		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.7635996238183262 | validation: 0.7275391413072383]
	TIME [epoch: 8.39 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7802259578968849		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.7802259578968849 | validation: 0.7900022364804726]
	TIME [epoch: 8.37 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8123745024900397		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.8123745024900397 | validation: 0.6578125862823899]
	TIME [epoch: 8.36 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6793663156535145		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.6793663156535145 | validation: 0.8771558213619619]
	TIME [epoch: 8.36 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7015609236866005		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.7015609236866005 | validation: 0.832909226440234]
	TIME [epoch: 8.39 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8133853331007124		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.8133853331007124 | validation: 0.6998719245483369]
	TIME [epoch: 8.36 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8254642198539306		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.8254642198539306 | validation: 0.8400470948579266]
	TIME [epoch: 8.36 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8137449147448294		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.8137449147448294 | validation: 1.186030191415343]
	TIME [epoch: 8.37 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8046549582361905		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.8046549582361905 | validation: 0.832125725296545]
	TIME [epoch: 8.37 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8070421080147936		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.8070421080147936 | validation: 0.6670091655092312]
	TIME [epoch: 8.37 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8086443250120885		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.8086443250120885 | validation: 0.6810641127809332]
	TIME [epoch: 8.36 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7712149993721003		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.7712149993721003 | validation: 1.3694506096164287]
	TIME [epoch: 8.36 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7665035379628826		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.7665035379628826 | validation: 0.6450072056892671]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_317.pth
	Model improved!!!
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7067735429278322		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.7067735429278322 | validation: 0.9382926406742917]
	TIME [epoch: 8.39 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.806031804641884		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.806031804641884 | validation: 0.6025605618962699]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_319.pth
	Model improved!!!
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7301811010224963		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.7301811010224963 | validation: 1.5194039881472574]
	TIME [epoch: 8.38 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.841415745178711		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.841415745178711 | validation: 0.7961749300020933]
	TIME [epoch: 8.37 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.755458274818634		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.755458274818634 | validation: 0.6313023892610332]
	TIME [epoch: 8.4 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6755724292871713		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.6755724292871713 | validation: 0.6752930924394984]
	TIME [epoch: 8.37 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7357289789502096		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.7357289789502096 | validation: 0.6693381268578458]
	TIME [epoch: 8.38 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6692622908903407		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.6692622908903407 | validation: 0.7823631529839474]
	TIME [epoch: 8.38 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7869270040832973		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.7869270040832973 | validation: 0.8961140335742259]
	TIME [epoch: 8.4 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7002954584332055		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.7002954584332055 | validation: 0.6462275532549016]
	TIME [epoch: 8.38 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8005670642622217		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.8005670642622217 | validation: 0.6617772832595902]
	TIME [epoch: 8.39 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7540721171841426		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.7540721171841426 | validation: 1.2224242906543754]
	TIME [epoch: 8.37 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7869493877357012		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.7869493877357012 | validation: 0.709702751376575]
	TIME [epoch: 8.37 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.705400365196408		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.705400365196408 | validation: 0.6074478229697606]
	TIME [epoch: 8.4 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.687282218825606		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.687282218825606 | validation: 0.8803503425529134]
	TIME [epoch: 8.38 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7223038386107972		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.7223038386107972 | validation: 0.9615106103019524]
	TIME [epoch: 8.37 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6823630201856654		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.6823630201856654 | validation: 0.6034358918570537]
	TIME [epoch: 8.38 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6738538463939835		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.6738538463939835 | validation: 0.847097746945832]
	TIME [epoch: 8.41 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8104741504575204		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.8104741504575204 | validation: 1.096535270297567]
	TIME [epoch: 8.38 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7535741041407793		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.7535741041407793 | validation: 0.7802201262453881]
	TIME [epoch: 8.38 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7780446487939728		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.7780446487939728 | validation: 0.5988212016826169]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_338.pth
	Model improved!!!
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7059401367090054		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.7059401367090054 | validation: 0.6393205323982155]
	TIME [epoch: 8.4 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7704531444326301		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.7704531444326301 | validation: 1.2929637627169086]
	TIME [epoch: 8.38 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7440894057602951		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.7440894057602951 | validation: 0.5800223163385692]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_341.pth
	Model improved!!!
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6576222240729199		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.6576222240729199 | validation: 0.665958691626386]
	TIME [epoch: 8.37 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7816267087605536		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.7816267087605536 | validation: 0.6034184492535724]
	TIME [epoch: 8.37 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7735980612040343		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.7735980612040343 | validation: 0.6687834679557908]
	TIME [epoch: 8.4 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.682769135174886		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.682769135174886 | validation: 0.7772033540469672]
	TIME [epoch: 8.37 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7608928552376046		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.7608928552376046 | validation: 0.7112697199585826]
	TIME [epoch: 8.36 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7056167405207803		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.7056167405207803 | validation: 0.606491404533533]
	TIME [epoch: 8.37 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7189577093442888		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.7189577093442888 | validation: 0.6144565714148449]
	TIME [epoch: 8.39 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6681151828370453		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.6681151828370453 | validation: 0.713938176964737]
	TIME [epoch: 8.37 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6084844287619087		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.6084844287619087 | validation: 0.5346971674040106]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_350.pth
	Model improved!!!
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7762752737078674		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.7762752737078674 | validation: 0.72707150667632]
	TIME [epoch: 8.38 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7560113175005623		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.7560113175005623 | validation: 0.7956770831064197]
	TIME [epoch: 8.41 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6784560230283094		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.6784560230283094 | validation: 0.6565384077152965]
	TIME [epoch: 8.38 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7103437493500387		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.7103437493500387 | validation: 0.6087646023599039]
	TIME [epoch: 8.37 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6522188582961723		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.6522188582961723 | validation: 0.716627710859618]
	TIME [epoch: 8.37 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6724339102918689		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.6724339102918689 | validation: 0.6135361250115644]
	TIME [epoch: 8.39 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7104385563554059		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.7104385563554059 | validation: 0.718116379480904]
	TIME [epoch: 8.39 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6576692585806635		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.6576692585806635 | validation: 0.7160198707246666]
	TIME [epoch: 8.37 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6586152571691104		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.6586152571691104 | validation: 0.5238231754153653]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_359.pth
	Model improved!!!
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7227651444684597		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.7227651444684597 | validation: 0.5817388539471364]
	TIME [epoch: 8.37 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6312626095674833		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.6312626095674833 | validation: 0.6783298529500905]
	TIME [epoch: 8.4 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6179446676887463		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.6179446676887463 | validation: 0.7536053646347287]
	TIME [epoch: 8.37 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6762198484553756		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.6762198484553756 | validation: 0.5085448074871]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_363.pth
	Model improved!!!
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7482885763899456		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.7482885763899456 | validation: 0.8208734145358527]
	TIME [epoch: 8.36 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6511672743170521		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.6511672743170521 | validation: 0.7762089526176006]
	TIME [epoch: 8.4 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7350314519309367		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.7350314519309367 | validation: 0.6033696358455186]
	TIME [epoch: 8.37 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6550614612234154		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.6550614612234154 | validation: 0.5101804552073]
	TIME [epoch: 8.38 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6055461442018268		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.6055461442018268 | validation: 0.8375087001935786]
	TIME [epoch: 8.36 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6849152950698276		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.6849152950698276 | validation: 0.47696770072855976]
	TIME [epoch: 8.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_369.pth
	Model improved!!!
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.660607016258872		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.660607016258872 | validation: 0.4423607672377563]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_370.pth
	Model improved!!!
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7224847884153339		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.7224847884153339 | validation: 0.549568826768237]
	TIME [epoch: 8.37 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5552003105832884		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.5552003105832884 | validation: 0.5880592086667826]
	TIME [epoch: 8.37 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7996974273379787		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.7996974273379787 | validation: 0.9066166727519159]
	TIME [epoch: 8.37 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6551019239457461		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.6551019239457461 | validation: 0.6656228894038461]
	TIME [epoch: 8.39 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6893664141526423		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.6893664141526423 | validation: 0.7033086349268457]
	TIME [epoch: 8.37 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7300734694778821		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.7300734694778821 | validation: 0.6287174353835795]
	TIME [epoch: 8.37 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5824629832780339		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.5824629832780339 | validation: 0.9222598672468352]
	TIME [epoch: 8.36 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6942054872518537		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.6942054872518537 | validation: 0.40889772167233684]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_378.pth
	Model improved!!!
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6478002023028819		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.6478002023028819 | validation: 0.4724283743330322]
	TIME [epoch: 8.37 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5731726584323661		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.5731726584323661 | validation: 0.46439323197861726]
	TIME [epoch: 8.37 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6790761135686789		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.6790761135686789 | validation: 0.7777021221546072]
	TIME [epoch: 8.37 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.628561715338209		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.628561715338209 | validation: 0.5596276703032166]
	TIME [epoch: 8.4 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6150860871430978		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.6150860871430978 | validation: 0.6735232928394418]
	TIME [epoch: 8.38 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6800834560056337		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.6800834560056337 | validation: 0.5963519837304687]
	TIME [epoch: 8.38 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6401112647399725		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.6401112647399725 | validation: 0.5306626239896342]
	TIME [epoch: 8.37 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6251483960737199		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.6251483960737199 | validation: 0.5209621796641689]
	TIME [epoch: 8.38 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6237818953004753		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.6237818953004753 | validation: 0.6637968432394181]
	TIME [epoch: 8.39 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6036331878257342		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.6036331878257342 | validation: 0.4819028799705748]
	TIME [epoch: 8.37 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5184364344077108		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.5184364344077108 | validation: 0.6222123207937014]
	TIME [epoch: 8.38 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5106537261833495		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.5106537261833495 | validation: 0.498267417593382]
	TIME [epoch: 8.37 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5137458285489257		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.5137458285489257 | validation: 0.7212176847774416]
	TIME [epoch: 8.39 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6074690515851122		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.6074690515851122 | validation: 0.6109174788425669]
	TIME [epoch: 8.38 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5017433002394817		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.5017433002394817 | validation: 0.4983582132229136]
	TIME [epoch: 8.36 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5696887497424133		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.5696887497424133 | validation: 0.4666446862011463]
	TIME [epoch: 8.37 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.61337303154233		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.61337303154233 | validation: 0.722727797713518]
	TIME [epoch: 8.4 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5208156878272807		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.5208156878272807 | validation: 0.3596590994207228]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_396.pth
	Model improved!!!
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6194618645581922		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.6194618645581922 | validation: 0.933858443204616]
	TIME [epoch: 8.37 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6128988320375804		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.6128988320375804 | validation: 0.32240425312516086]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_398.pth
	Model improved!!!
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5291445869547966		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.5291445869547966 | validation: 0.5130531505875051]
	TIME [epoch: 8.39 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5828113555436969		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.5828113555436969 | validation: 0.5946005463952071]
	TIME [epoch: 8.37 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6026748186758629		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.6026748186758629 | validation: 0.5632097391545581]
	TIME [epoch: 8.36 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5669255791257001		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.5669255791257001 | validation: 0.5298557018535539]
	TIME [epoch: 8.38 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.585543142947526		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.585543142947526 | validation: 0.545093528317877]
	TIME [epoch: 8.37 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6486043774158103		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.6486043774158103 | validation: 0.3837555861350332]
	TIME [epoch: 8.4 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5923868753078796		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.5923868753078796 | validation: 0.3770037776249254]
	TIME [epoch: 8.36 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5377372284731627		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.5377372284731627 | validation: 0.3394307977733601]
	TIME [epoch: 8.37 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5781174575090026		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.5781174575090026 | validation: 1.0089042783602178]
	TIME [epoch: 8.36 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5902703850585543		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.5902703850585543 | validation: 0.49198466774887895]
	TIME [epoch: 8.4 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5207378759036628		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.5207378759036628 | validation: 0.7616869472478311]
	TIME [epoch: 8.37 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6306509254486199		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.6306509254486199 | validation: 0.526295137383137]
	TIME [epoch: 8.37 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5947479061286971		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.5947479061286971 | validation: 0.5302419037924812]
	TIME [epoch: 8.36 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6486154458474515		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.6486154458474515 | validation: 0.4012817405464701]
	TIME [epoch: 8.39 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.588529605609796		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.588529605609796 | validation: 0.37459538915844864]
	TIME [epoch: 8.37 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5187737679607854		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.5187737679607854 | validation: 0.6193098489689707]
	TIME [epoch: 8.37 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5756042179324721		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.5756042179324721 | validation: 0.8938000834748965]
	TIME [epoch: 8.36 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.628024586671357		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.628024586671357 | validation: 0.6829403743645676]
	TIME [epoch: 8.37 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6488200265073907		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.6488200265073907 | validation: 0.859585969180102]
	TIME [epoch: 8.39 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8092530462643177		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.8092530462643177 | validation: 0.44256088189684073]
	TIME [epoch: 8.37 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5213480663883839		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.5213480663883839 | validation: 1.0997253711710275]
	TIME [epoch: 8.37 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5859985440358629		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.5859985440358629 | validation: 0.9133719926133598]
	TIME [epoch: 8.37 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6104772349787122		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.6104772349787122 | validation: 1.0004258610115522]
	TIME [epoch: 8.39 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5444193928815444		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.5444193928815444 | validation: 0.8295249305277443]
	TIME [epoch: 8.38 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5450795806548479		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.5450795806548479 | validation: 1.073442748997988]
	TIME [epoch: 8.37 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6135670974823888		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.6135670974823888 | validation: 0.8878584511520957]
	TIME [epoch: 8.37 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6009868759714115		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.6009868759714115 | validation: 0.6826296741667033]
	TIME [epoch: 8.39 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.633166700332674		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.633166700332674 | validation: 0.6107635448505572]
	TIME [epoch: 8.38 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49579663218424896		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.49579663218424896 | validation: 0.8006320959986565]
	TIME [epoch: 8.38 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5929198299504985		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.5929198299504985 | validation: 0.32550932751367534]
	TIME [epoch: 8.37 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5093557374304248		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.5093557374304248 | validation: 0.30488901105169464]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_429.pth
	Model improved!!!
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.448032837814737		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.448032837814737 | validation: 0.8839846544134145]
	TIME [epoch: 8.4 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6690237367991464		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.6690237367991464 | validation: 0.7543781394159462]
	TIME [epoch: 8.37 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5799661587221491		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.5799661587221491 | validation: 0.49975640065294924]
	TIME [epoch: 8.37 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5338336705120506		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.5338336705120506 | validation: 0.5320623493886906]
	TIME [epoch: 8.37 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5535173695131841		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.5535173695131841 | validation: 0.3983711410786803]
	TIME [epoch: 8.39 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4435701725865064		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.4435701725865064 | validation: 0.64486841963531]
	TIME [epoch: 8.38 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6225903134374576		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.6225903134374576 | validation: 0.35200792570781314]
	TIME [epoch: 8.38 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.575654350478249		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.575654350478249 | validation: 0.37107993387675164]
	TIME [epoch: 8.37 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5835360582371267		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.5835360582371267 | validation: 0.4125750619210926]
	TIME [epoch: 8.39 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5212399196478799		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.5212399196478799 | validation: 0.9947351023840796]
	TIME [epoch: 8.38 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5847905837176097		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.5847905837176097 | validation: 0.36079707480592277]
	TIME [epoch: 8.37 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5240787294419497		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.5240787294419497 | validation: 0.42154164280766626]
	TIME [epoch: 8.37 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4503075736659435		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.4503075736659435 | validation: 0.28113268096370847]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_442.pth
	Model improved!!!
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4964786919248686		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.4964786919248686 | validation: 0.5193502785009874]
	TIME [epoch: 8.39 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44306657958228407		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.44306657958228407 | validation: 0.9737049788324357]
	TIME [epoch: 8.38 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5860533771901265		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.5860533771901265 | validation: 0.43154828745933893]
	TIME [epoch: 8.37 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5469372674858656		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.5469372674858656 | validation: 0.3289139151955575]
	TIME [epoch: 8.37 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5274348248247495		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.5274348248247495 | validation: 0.33328509657098626]
	TIME [epoch: 8.39 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5525834534872909		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.5525834534872909 | validation: 0.3756093622202177]
	TIME [epoch: 8.37 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5075931248798008		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.5075931248798008 | validation: 0.4728619956425585]
	TIME [epoch: 8.37 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5412217695326325		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.5412217695326325 | validation: 0.35943466690869963]
	TIME [epoch: 8.36 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4344613042622337		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.4344613042622337 | validation: 0.5947584866783973]
	TIME [epoch: 8.39 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42810847433565813		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.42810847433565813 | validation: 0.33919122348126274]
	TIME [epoch: 8.37 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6716566426976127		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.6716566426976127 | validation: 0.4125960915923321]
	TIME [epoch: 8.37 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4535822826559303		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.4535822826559303 | validation: 0.28414242343896345]
	TIME [epoch: 8.37 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.603029620518386		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.603029620518386 | validation: 0.42190757310751237]
	TIME [epoch: 8.38 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5066104288575128		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.5066104288575128 | validation: 0.4242355600778803]
	TIME [epoch: 8.38 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4679257786599359		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.4679257786599359 | validation: 0.5763834014651883]
	TIME [epoch: 8.36 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5858341815948813		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.5858341815948813 | validation: 0.6724971858561275]
	TIME [epoch: 8.37 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.577461275572834		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.577461275572834 | validation: 0.4212365113656052]
	TIME [epoch: 8.37 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43573700975947627		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.43573700975947627 | validation: 0.3859877631586589]
	TIME [epoch: 8.39 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4359389430876048		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.4359389430876048 | validation: 0.5602991313924504]
	TIME [epoch: 8.36 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5338552739571958		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.5338552739571958 | validation: 0.33356362022055563]
	TIME [epoch: 8.37 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4747427172709814		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.4747427172709814 | validation: 0.386978066890622]
	TIME [epoch: 8.36 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5326340324682242		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.5326340324682242 | validation: 0.3197810185367578]
	TIME [epoch: 8.4 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4719407567591866		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.4719407567591866 | validation: 0.4960671828520554]
	TIME [epoch: 8.37 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4712491551677579		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.4712491551677579 | validation: 0.3623057298864081]
	TIME [epoch: 8.37 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43752757069426573		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.43752757069426573 | validation: 0.2799357285720948]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_467.pth
	Model improved!!!
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43035045486576645		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.43035045486576645 | validation: 0.5046680649013711]
	TIME [epoch: 8.39 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4385964424402478		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.4385964424402478 | validation: 0.48409407598036297]
	TIME [epoch: 8.36 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49356154151472		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.49356154151472 | validation: 0.5335615786119747]
	TIME [epoch: 8.37 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4873152976443394		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.4873152976443394 | validation: 0.41227484885093313]
	TIME [epoch: 8.36 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5763876461173871		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.5763876461173871 | validation: 0.5565565224694703]
	TIME [epoch: 8.37 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4690907175136113		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.4690907175136113 | validation: 0.28867769478611316]
	TIME [epoch: 8.39 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45210648686142585		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.45210648686142585 | validation: 0.3410921973971158]
	TIME [epoch: 8.37 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4894420465712959		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.4894420465712959 | validation: 0.34793205384921855]
	TIME [epoch: 8.37 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4146086540438512		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.4146086540438512 | validation: 0.7195686154709292]
	TIME [epoch: 8.36 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5031715740116403		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.5031715740116403 | validation: 0.56400982617849]
	TIME [epoch: 8.39 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48712168803316913		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.48712168803316913 | validation: 0.24398420554026717]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_478.pth
	Model improved!!!
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4342364598235443		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.4342364598235443 | validation: 0.5632956390007104]
	TIME [epoch: 8.37 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47889036214226344		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.47889036214226344 | validation: 0.346852043078677]
	TIME [epoch: 8.37 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48167169704351676		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.48167169704351676 | validation: 0.5305331752968521]
	TIME [epoch: 8.39 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4837517948532172		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.4837517948532172 | validation: 0.3620402005984922]
	TIME [epoch: 8.37 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7279910606215992		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.7279910606215992 | validation: 0.6404162104067811]
	TIME [epoch: 8.36 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6255053582981598		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.6255053582981598 | validation: 0.29113489965582395]
	TIME [epoch: 8.36 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4705069608862381		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.4705069608862381 | validation: 0.28275016366306616]
	TIME [epoch: 8.36 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43777230526780136		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.43777230526780136 | validation: 0.5775297622147361]
	TIME [epoch: 8.39 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4556683697349472		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.4556683697349472 | validation: 0.3753026141101339]
	TIME [epoch: 8.36 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4036911355352383		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.4036911355352383 | validation: 0.3588116655738416]
	TIME [epoch: 8.36 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4165305595727464		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.4165305595727464 | validation: 0.5960317966910897]
	TIME [epoch: 8.36 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44786162880210395		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.44786162880210395 | validation: 0.42693385303685993]
	TIME [epoch: 8.39 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42208580726610884		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.42208580726610884 | validation: 0.33226890819878496]
	TIME [epoch: 8.37 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4781061845867359		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.4781061845867359 | validation: 0.3912729947411962]
	TIME [epoch: 8.36 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39515536415562036		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.39515536415562036 | validation: 0.543740843687768]
	TIME [epoch: 8.36 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4497846441659365		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.4497846441659365 | validation: 0.7281220513600148]
	TIME [epoch: 8.39 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48077293889610606		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.48077293889610606 | validation: 0.3813109911587814]
	TIME [epoch: 8.37 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37262956245656564		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.37262956245656564 | validation: 0.6464847865007839]
	TIME [epoch: 8.37 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44704030252379734		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.44704030252379734 | validation: 0.43697107380363887]
	TIME [epoch: 8.36 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4209249599358468		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.4209249599358468 | validation: 0.31160880952800324]
	TIME [epoch: 8.37 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4046589054122377		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.4046589054122377 | validation: 0.3146855101014636]
	TIME [epoch: 8.39 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42742167077190735		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.42742167077190735 | validation: 0.2986118972674749]
	TIME [epoch: 8.37 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43383200976700964		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.43383200976700964 | validation: 0.2513246846592612]
	TIME [epoch: 8.36 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46077348939852253		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.46077348939852253 | validation: 0.5191911400741138]
	TIME [epoch: 8.37 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35856661994710876		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.35856661994710876 | validation: 0.33650225881198814]
	TIME [epoch: 8.39 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43963690601198485		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.43963690601198485 | validation: 0.31274470052320746]
	TIME [epoch: 8.37 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4454760124538552		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.4454760124538552 | validation: 0.29263039530525436]
	TIME [epoch: 8.36 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4027955210402502		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.4027955210402502 | validation: 0.4185443347657076]
	TIME [epoch: 8.36 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38837825061662945		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.38837825061662945 | validation: 0.5092114985719811]
	TIME [epoch: 8.38 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42070325460437086		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.42070325460437086 | validation: 0.948651425944032]
	TIME [epoch: 8.37 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5208444339567826		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.5208444339567826 | validation: 0.3886135040295713]
	TIME [epoch: 8.37 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3794839292625538		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.3794839292625538 | validation: 0.27051428149166196]
	TIME [epoch: 8.37 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4340269477309012		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.4340269477309012 | validation: 0.45944667556653235]
	TIME [epoch: 8.37 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4334179109731167		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.4334179109731167 | validation: 0.5211470266408784]
	TIME [epoch: 8.37 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42537623057621365		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.42537623057621365 | validation: 0.2979082446522112]
	TIME [epoch: 8.36 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3855406779177117		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.3855406779177117 | validation: 0.6504140883185405]
	TIME [epoch: 8.37 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41653121965917234		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.41653121965917234 | validation: 0.5322792437104431]
	TIME [epoch: 8.37 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40888365174828945		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.40888365174828945 | validation: 0.417042575850618]
	TIME [epoch: 8.39 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35114132236072815		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.35114132236072815 | validation: 0.25879161180334964]
	TIME [epoch: 8.38 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38878767257531344		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.38878767257531344 | validation: 0.6227229544106136]
	TIME [epoch: 8.37 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41409923465615217		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.41409923465615217 | validation: 0.6608876001957513]
	TIME [epoch: 8.36 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41399722733385713		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.41399722733385713 | validation: 0.2546351687074472]
	TIME [epoch: 8.39 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38265062506326747		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.38265062506326747 | validation: 0.37159857276972497]
	TIME [epoch: 8.36 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49045140845693147		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.49045140845693147 | validation: 0.4313842910253405]
	TIME [epoch: 8.37 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3952423306676858		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.3952423306676858 | validation: 0.32484906458676976]
	TIME [epoch: 8.36 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35003810497665144		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.35003810497665144 | validation: 0.39822188205547404]
	TIME [epoch: 8.38 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4279510014338476		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.4279510014338476 | validation: 0.3614086179375584]
	TIME [epoch: 8.38 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37483577037096905		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.37483577037096905 | validation: 0.3044457270853376]
	TIME [epoch: 8.37 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4502025823137242		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.4502025823137242 | validation: 0.30656635383047076]
	TIME [epoch: 8.37 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3535239196283653		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.3535239196283653 | validation: 0.3881303334471853]
	TIME [epoch: 8.37 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.411537421924052		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.411537421924052 | validation: 0.3921477820786782]
	TIME [epoch: 8.38 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3857240661863058		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.3857240661863058 | validation: 0.31036387743685667]
	TIME [epoch: 8.36 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4219456228355768		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.4219456228355768 | validation: 0.41602828247519186]
	TIME [epoch: 8.37 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35623870460711865		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.35623870460711865 | validation: 0.24038234525506938]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_532.pth
	Model improved!!!
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41518471435709275		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.41518471435709275 | validation: 0.41228244055597685]
	TIME [epoch: 8.39 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39052087368148314		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.39052087368148314 | validation: 0.49168941243061165]
	TIME [epoch: 8.37 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4112179795528797		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.4112179795528797 | validation: 0.3380859817700752]
	TIME [epoch: 8.37 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3294847111517544		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.3294847111517544 | validation: 0.2659371123678329]
	TIME [epoch: 8.37 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3433397391673932		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.3433397391673932 | validation: 0.46532405449924585]
	TIME [epoch: 8.38 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3528035497541123		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.3528035497541123 | validation: 0.5780050228865266]
	TIME [epoch: 8.38 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4015898738794193		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.4015898738794193 | validation: 0.38002630919794833]
	TIME [epoch: 8.37 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39917848499090314		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.39917848499090314 | validation: 0.2912677491916726]
	TIME [epoch: 8.37 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3889581758202122		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.3889581758202122 | validation: 0.3192724666830087]
	TIME [epoch: 8.37 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4127042324253507		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.4127042324253507 | validation: 0.38013286716110983]
	TIME [epoch: 8.39 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40654858628265256		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.40654858628265256 | validation: 0.45944580218229747]
	TIME [epoch: 8.37 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48379390748207324		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.48379390748207324 | validation: 0.4268199676811706]
	TIME [epoch: 8.36 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3910287201209052		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.3910287201209052 | validation: 0.3575645000063522]
	TIME [epoch: 8.37 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39294052180236055		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.39294052180236055 | validation: 0.248670066835418]
	TIME [epoch: 8.4 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3742546410405726		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.3742546410405726 | validation: 0.3235225888161948]
	TIME [epoch: 8.37 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35407846214864364		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.35407846214864364 | validation: 0.26586424852173596]
	TIME [epoch: 8.36 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4398266064605923		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.4398266064605923 | validation: 0.3452290137813636]
	TIME [epoch: 8.37 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3417510933277816		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.3417510933277816 | validation: 0.32409841545111145]
	TIME [epoch: 8.39 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39121109921331376		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.39121109921331376 | validation: 0.2888480549917083]
	TIME [epoch: 8.37 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37161446319004693		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.37161446319004693 | validation: 0.5151687811241882]
	TIME [epoch: 8.37 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3568060552552418		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.3568060552552418 | validation: 0.7854909943130807]
	TIME [epoch: 8.37 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37488817104063427		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.37488817104063427 | validation: 0.22582812170671623]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_554.pth
	Model improved!!!
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3859578029988659		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.3859578029988659 | validation: 0.24773196989667806]
	TIME [epoch: 8.4 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36281370063173407		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.36281370063173407 | validation: 0.29591006305200085]
	TIME [epoch: 8.37 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4241713857615861		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.4241713857615861 | validation: 0.2543458906136894]
	TIME [epoch: 8.37 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.381874785627221		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.381874785627221 | validation: 0.29425002497680874]
	TIME [epoch: 8.36 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39307024194237455		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.39307024194237455 | validation: 0.24300276417387223]
	TIME [epoch: 8.39 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37243575619131847		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.37243575619131847 | validation: 0.3837160203176169]
	TIME [epoch: 8.37 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36128195539723196		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.36128195539723196 | validation: 0.4080924743407831]
	TIME [epoch: 8.36 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.390365707015895		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.390365707015895 | validation: 0.2989639050266365]
	TIME [epoch: 8.37 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.340348334263078		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.340348334263078 | validation: 0.2633870312941936]
	TIME [epoch: 8.39 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31543905053136584		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.31543905053136584 | validation: 0.31444416265449066]
	TIME [epoch: 8.37 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4604870814807695		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.4604870814807695 | validation: 0.23102029226002285]
	TIME [epoch: 8.37 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39102022944208004		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.39102022944208004 | validation: 0.26538597275012854]
	TIME [epoch: 8.36 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34069865948818256		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.34069865948818256 | validation: 0.256883989472093]
	TIME [epoch: 8.37 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3767769543784744		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.3767769543784744 | validation: 0.5236624798652493]
	TIME [epoch: 8.39 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39274538156365746		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.39274538156365746 | validation: 0.277159234294416]
	TIME [epoch: 8.36 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40273247580847193		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.40273247580847193 | validation: 0.26105054899993974]
	TIME [epoch: 8.36 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3081593693644856		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.3081593693644856 | validation: 0.36198154509308644]
	TIME [epoch: 8.36 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38319773975691235		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.38319773975691235 | validation: 0.40559355913749656]
	TIME [epoch: 8.38 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4253659628155965		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.4253659628155965 | validation: 0.25542391541898163]
	TIME [epoch: 8.37 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33774378134213157		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.33774378134213157 | validation: 0.26901282448612823]
	TIME [epoch: 8.37 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33969255298013556		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.33969255298013556 | validation: 0.2788422811704596]
	TIME [epoch: 8.36 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43118499677630595		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.43118499677630595 | validation: 0.31241458877769085]
	TIME [epoch: 8.39 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3317331815250123		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.3317331815250123 | validation: 0.3976683175011389]
	TIME [epoch: 8.36 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39759281063698115		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.39759281063698115 | validation: 0.24537185316935975]
	TIME [epoch: 8.35 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4058805626904417		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.4058805626904417 | validation: 0.313937810431385]
	TIME [epoch: 8.36 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39698481497644045		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.39698481497644045 | validation: 0.26282418405451174]
	TIME [epoch: 8.37 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3235894293127848		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.3235894293127848 | validation: 0.30357932914634955]
	TIME [epoch: 8.39 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33834673247512337		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.33834673247512337 | validation: 0.2693619072207446]
	TIME [epoch: 8.36 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37691415507266096		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.37691415507266096 | validation: 0.2792623565703206]
	TIME [epoch: 8.36 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3460041764240468		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.3460041764240468 | validation: 0.5769497886874715]
	TIME [epoch: 8.36 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3689229635567266		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.3689229635567266 | validation: 0.3191751562030565]
	TIME [epoch: 8.39 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3947277451268943		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.3947277451268943 | validation: 0.3503316890222634]
	TIME [epoch: 8.36 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3456000721557501		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.3456000721557501 | validation: 0.4676727711531109]
	TIME [epoch: 8.36 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3229133556685792		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.3229133556685792 | validation: 0.3211637764339643]
	TIME [epoch: 8.36 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33510986913557356		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.33510986913557356 | validation: 0.3183376349104775]
	TIME [epoch: 8.38 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3240136130994583		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.3240136130994583 | validation: 0.3828471709692456]
	TIME [epoch: 8.36 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34290576617801644		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.34290576617801644 | validation: 0.49378009400159434]
	TIME [epoch: 8.36 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3544763088729873		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.3544763088729873 | validation: 0.48102266678805217]
	TIME [epoch: 8.36 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3534070774307634		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.3534070774307634 | validation: 0.2726215266915097]
	TIME [epoch: 8.37 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3941713781892104		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.3941713781892104 | validation: 0.24320807454324705]
	TIME [epoch: 8.38 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2953314698920269		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.2953314698920269 | validation: 0.2426893677681491]
	TIME [epoch: 8.36 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36154026816865653		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.36154026816865653 | validation: 0.44404204871939307]
	TIME [epoch: 8.36 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3729372010745431		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.3729372010745431 | validation: 0.24610625317526835]
	TIME [epoch: 8.37 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3051779507127379		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.3051779507127379 | validation: 0.6589577461900457]
	TIME [epoch: 8.38 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44449829151673076		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.44449829151673076 | validation: 0.2507386068006729]
	TIME [epoch: 8.37 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34141859937654795		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.34141859937654795 | validation: 0.5033349224329987]
	TIME [epoch: 8.35 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4067799330004399		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.4067799330004399 | validation: 0.6133002614036662]
	TIME [epoch: 8.36 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3560035703037638		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.3560035703037638 | validation: 0.3631601155616514]
	TIME [epoch: 8.38 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3323482738411066		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.3323482738411066 | validation: 0.2513207864906831]
	TIME [epoch: 8.36 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28610602021637827		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.28610602021637827 | validation: 0.25150353359297073]
	TIME [epoch: 8.36 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31554306168763957		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.31554306168763957 | validation: 0.43279647812902067]
	TIME [epoch: 8.36 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3305512322618166		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.3305512322618166 | validation: 0.4945817588894911]
	TIME [epoch: 8.36 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36368917075215845		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.36368917075215845 | validation: 0.6239267435553333]
	TIME [epoch: 8.38 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3778581604331954		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.3778581604331954 | validation: 0.2311206396032059]
	TIME [epoch: 8.36 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32193737364283714		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.32193737364283714 | validation: 0.3270248407110151]
	TIME [epoch: 8.36 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31555907799885835		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.31555907799885835 | validation: 0.2962399788310896]
	TIME [epoch: 8.36 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34948220080744063		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.34948220080744063 | validation: 1.137686613127812]
	TIME [epoch: 8.39 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4956637896879245		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.4956637896879245 | validation: 0.4031381912399372]
	TIME [epoch: 8.36 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3404226779115638		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.3404226779115638 | validation: 0.2884913081041969]
	TIME [epoch: 8.36 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3029234862780923		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.3029234862780923 | validation: 0.29009447094070917]
	TIME [epoch: 8.35 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3497859551300936		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.3497859551300936 | validation: 0.4789472235108329]
	TIME [epoch: 8.39 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31746531480811535		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.31746531480811535 | validation: 0.3816700360381277]
	TIME [epoch: 8.36 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30062017095965177		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.30062017095965177 | validation: 0.2716993920702484]
	TIME [epoch: 8.36 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3222839071581879		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.3222839071581879 | validation: 0.300031281153459]
	TIME [epoch: 8.37 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3126922555137045		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.3126922555137045 | validation: 0.2596516382564789]
	TIME [epoch: 8.37 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3280937606508023		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.3280937606508023 | validation: 0.22200638911922546]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_620.pth
	Model improved!!!
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3406174081516087		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.3406174081516087 | validation: 0.2677109998900567]
	TIME [epoch: 8.36 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3305192968900346		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.3305192968900346 | validation: 0.3414820948453484]
	TIME [epoch: 8.36 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38271074214274364		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.38271074214274364 | validation: 0.29923545769348264]
	TIME [epoch: 8.37 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3590651696974071		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.3590651696974071 | validation: 0.26965577849777667]
	TIME [epoch: 8.38 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3083020540654004		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.3083020540654004 | validation: 0.24669822090340687]
	TIME [epoch: 8.36 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2858072460949436		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.2858072460949436 | validation: 0.22715016641871338]
	TIME [epoch: 8.37 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30621456200901764		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.30621456200901764 | validation: 0.23560604462570672]
	TIME [epoch: 8.36 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27902167456341653		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.27902167456341653 | validation: 0.407221255336441]
	TIME [epoch: 8.38 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3542477544170382		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.3542477544170382 | validation: 0.22972357935321447]
	TIME [epoch: 8.37 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3377423858921206		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.3377423858921206 | validation: 0.21381150070808086]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_630.pth
	Model improved!!!
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37094285607112615		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.37094285607112615 | validation: 0.2557504322113188]
	TIME [epoch: 8.37 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3367303663256742		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.3367303663256742 | validation: 0.26897066770758193]
	TIME [epoch: 8.38 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3250168226734337		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.3250168226734337 | validation: 0.25766806357123506]
	TIME [epoch: 8.37 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34493228274445753		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.34493228274445753 | validation: 1.0181022084360374]
	TIME [epoch: 8.36 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46014700638516803		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.46014700638516803 | validation: 0.3629862216007941]
	TIME [epoch: 8.36 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32626327424536516		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.32626327424536516 | validation: 0.2217553351696335]
	TIME [epoch: 8.36 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3239820029648187		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.3239820029648187 | validation: 0.2333716059681304]
	TIME [epoch: 8.38 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32151242326833424		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.32151242326833424 | validation: 0.48705823325137754]
	TIME [epoch: 8.37 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32300174490437666		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.32300174490437666 | validation: 0.30601145734098045]
	TIME [epoch: 8.37 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2942188918054121		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.2942188918054121 | validation: 0.3019140575723497]
	TIME [epoch: 8.37 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3225604890189181		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.3225604890189181 | validation: 0.32342363487090303]
	TIME [epoch: 8.39 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30711429735301665		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.30711429735301665 | validation: 0.27981552779764135]
	TIME [epoch: 8.37 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3485757303725148		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.3485757303725148 | validation: 0.2706858814518767]
	TIME [epoch: 8.36 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3332783392030769		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.3332783392030769 | validation: 0.2426366092555982]
	TIME [epoch: 8.36 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31501677132084377		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.31501677132084377 | validation: 0.31612513117513097]
	TIME [epoch: 8.38 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36195416079890286		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.36195416079890286 | validation: 0.3866515225860797]
	TIME [epoch: 8.36 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3144772606988802		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.3144772606988802 | validation: 0.22392244352793372]
	TIME [epoch: 8.36 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3126615628418833		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.3126615628418833 | validation: 0.2755279248801162]
	TIME [epoch: 8.36 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3313346479390014		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.3313346479390014 | validation: 0.37166847219655935]
	TIME [epoch: 8.36 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30222973888643384		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.30222973888643384 | validation: 0.38665673491396696]
	TIME [epoch: 8.38 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32835350628271787		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.32835350628271787 | validation: 0.2714377905296799]
	TIME [epoch: 8.36 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3645578207123798		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.3645578207123798 | validation: 0.42708457210512485]
	TIME [epoch: 8.37 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36001012015493655		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.36001012015493655 | validation: 0.22993479879827244]
	TIME [epoch: 8.36 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3115575745944121		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.3115575745944121 | validation: 0.24388912204149377]
	TIME [epoch: 8.39 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3264567909050387		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.3264567909050387 | validation: 0.4464571755225124]
	TIME [epoch: 8.36 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34395714081836165		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.34395714081836165 | validation: 0.26232177744123364]
	TIME [epoch: 8.36 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30746984887840456		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.30746984887840456 | validation: 0.3917361677818944]
	TIME [epoch: 8.36 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31922341537571713		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.31922341537571713 | validation: 0.2579206252890394]
	TIME [epoch: 8.39 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3506852004201586		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.3506852004201586 | validation: 0.3832669866750651]
	TIME [epoch: 8.37 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3782820214548231		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.3782820214548231 | validation: 0.25041313934816745]
	TIME [epoch: 8.36 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3005821953737073		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.3005821953737073 | validation: 0.24644928401929583]
	TIME [epoch: 8.36 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3014362191437313		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.3014362191437313 | validation: 0.26479490567982716]
	TIME [epoch: 8.36 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35496139843036306		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.35496139843036306 | validation: 0.216859400588935]
	TIME [epoch: 8.38 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.325456271036548		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.325456271036548 | validation: 0.23069241441412736]
	TIME [epoch: 8.35 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28086192868785553		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.28086192868785553 | validation: 0.2588816480385945]
	TIME [epoch: 8.36 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3358565829231536		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.3358565829231536 | validation: 0.2665154662300687]
	TIME [epoch: 8.36 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29330104424528747		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.29330104424528747 | validation: 0.3366373098914185]
	TIME [epoch: 8.38 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3156114934631752		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.3156114934631752 | validation: 0.2643234987667903]
	TIME [epoch: 8.37 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33218599157468515		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.33218599157468515 | validation: 0.23838027559893463]
	TIME [epoch: 8.35 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.294097759555063		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.294097759555063 | validation: 0.33922978959255246]
	TIME [epoch: 8.35 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3865802611918855		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.3865802611918855 | validation: 0.6518046156282962]
	TIME [epoch: 8.38 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.351272988796004		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.351272988796004 | validation: 0.2560836572406326]
	TIME [epoch: 8.36 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.312924470330415		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.312924470330415 | validation: 0.38729995087575886]
	TIME [epoch: 8.35 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3434290617951542		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.3434290617951542 | validation: 0.2513858076588167]
	TIME [epoch: 8.36 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2972975496475549		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.2972975496475549 | validation: 0.25117291711674017]
	TIME [epoch: 8.36 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2921671045535191		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.2921671045535191 | validation: 0.22504465573418236]
	TIME [epoch: 8.38 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32418640013102246		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.32418640013102246 | validation: 0.23978073994709126]
	TIME [epoch: 8.36 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3152083050933024		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.3152083050933024 | validation: 0.39831651143349334]
	TIME [epoch: 8.36 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33550650187586056		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.33550650187586056 | validation: 0.2734576322769562]
	TIME [epoch: 8.36 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2778595238885256		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.2778595238885256 | validation: 0.2176709074184219]
	TIME [epoch: 8.38 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3168573563531093		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.3168573563531093 | validation: 0.2508398711696564]
	TIME [epoch: 8.37 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29958150219082863		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.29958150219082863 | validation: 0.35602249248137585]
	TIME [epoch: 8.36 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3633293317881888		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.3633293317881888 | validation: 0.5015834848919948]
	TIME [epoch: 8.36 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2976183363497914		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.2976183363497914 | validation: 0.2714716348121774]
	TIME [epoch: 8.38 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33573340051916023		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.33573340051916023 | validation: 0.2503541686753955]
	TIME [epoch: 8.36 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3151694409686066		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.3151694409686066 | validation: 0.3683354216603547]
	TIME [epoch: 8.36 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33228574175939485		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.33228574175939485 | validation: 0.22431656817984907]
	TIME [epoch: 8.36 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2849826255233526		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.2849826255233526 | validation: 0.43653901587487914]
	TIME [epoch: 8.36 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3093626706243975		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.3093626706243975 | validation: 0.2822279473445329]
	TIME [epoch: 8.39 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2966028375013738		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.2966028375013738 | validation: 0.2636501107846224]
	TIME [epoch: 8.36 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28645857554858545		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.28645857554858545 | validation: 0.22027738508000866]
	TIME [epoch: 8.36 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28937345038092155		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.28937345038092155 | validation: 0.23823750987468334]
	TIME [epoch: 8.36 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.311840380823846		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.311840380823846 | validation: 0.31928210407371216]
	TIME [epoch: 8.39 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31288556231897674		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.31288556231897674 | validation: 0.22774100257459245]
	TIME [epoch: 8.36 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.259069073315887		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.259069073315887 | validation: 0.3213076505336928]
	TIME [epoch: 8.36 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34625709144709343		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.34625709144709343 | validation: 0.6093550721694558]
	TIME [epoch: 8.36 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3672145866248607		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.3672145866248607 | validation: 0.25362939735173284]
	TIME [epoch: 8.38 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30681262752154714		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.30681262752154714 | validation: 0.2760637912313639]
	TIME [epoch: 8.36 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2889348918895065		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.2889348918895065 | validation: 0.22311423696081323]
	TIME [epoch: 8.36 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2982370596594207		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.2982370596594207 | validation: 0.2240866015238221]
	TIME [epoch: 8.36 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2797301762525831		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.2797301762525831 | validation: 0.3192764574245554]
	TIME [epoch: 8.37 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2727897643679587		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.2727897643679587 | validation: 0.23990279157389227]
	TIME [epoch: 8.37 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2882287146874097		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.2882287146874097 | validation: 0.25048120638921356]
	TIME [epoch: 8.37 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27723696558689515		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.27723696558689515 | validation: 0.4536864607722507]
	TIME [epoch: 8.36 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30518847643922603		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.30518847643922603 | validation: 0.25488036183216944]
	TIME [epoch: 8.36 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2980335714308077		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.2980335714308077 | validation: 0.3618743168627413]
	TIME [epoch: 8.38 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2750996211855175		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.2750996211855175 | validation: 0.2502572285190144]
	TIME [epoch: 8.37 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28430145043852273		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.28430145043852273 | validation: 0.22884051234801916]
	TIME [epoch: 8.36 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28570411285298314		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.28570411285298314 | validation: 0.2483846614251149]
	TIME [epoch: 8.36 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26712865830564986		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.26712865830564986 | validation: 0.3666850758301898]
	TIME [epoch: 8.38 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34876364690445183		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.34876364690445183 | validation: 0.22395668361327575]
	TIME [epoch: 8.37 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27801630057917576		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.27801630057917576 | validation: 0.23539818044391367]
	TIME [epoch: 8.36 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28277835318948974		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.28277835318948974 | validation: 0.22465922875230626]
	TIME [epoch: 8.36 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2860118235061436		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.2860118235061436 | validation: 0.23531406077617267]
	TIME [epoch: 8.37 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3189924449699113		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.3189924449699113 | validation: 0.29044065933949503]
	TIME [epoch: 8.36 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2897023790584421		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.2897023790584421 | validation: 0.20960214887675105]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_716.pth
	Model improved!!!
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2842452351821355		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.2842452351821355 | validation: 0.22597475037182457]
	TIME [epoch: 8.36 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26757282888093736		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.26757282888093736 | validation: 0.2952266620988071]
	TIME [epoch: 8.36 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2825895469048002		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.2825895469048002 | validation: 0.3207553734644759]
	TIME [epoch: 8.38 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35772232998721626		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.35772232998721626 | validation: 0.22795301217554437]
	TIME [epoch: 8.36 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34593451697236244		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.34593451697236244 | validation: 0.22509014939234684]
	TIME [epoch: 8.36 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2980161772891586		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.2980161772891586 | validation: 0.232518765699356]
	TIME [epoch: 8.36 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2672553904699031		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.2672553904699031 | validation: 0.3253399020608473]
	TIME [epoch: 8.39 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31926338947754124		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.31926338947754124 | validation: 0.2184263816476213]
	TIME [epoch: 8.36 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2865813691881506		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.2865813691881506 | validation: 0.25430277646477756]
	TIME [epoch: 8.36 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30629963073573846		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.30629963073573846 | validation: 0.3154992794050157]
	TIME [epoch: 8.36 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.348880403433437		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.348880403433437 | validation: 0.20449548727826983]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_727.pth
	Model improved!!!
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3022090954140695		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.3022090954140695 | validation: 0.2264421455494552]
	TIME [epoch: 8.38 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24954291141686702		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.24954291141686702 | validation: 0.261772334890194]
	TIME [epoch: 8.36 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2837196995151146		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.2837196995151146 | validation: 0.22796209737392803]
	TIME [epoch: 8.36 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27034605595666167		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.27034605595666167 | validation: 0.2592307033459573]
	TIME [epoch: 8.36 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2677196933266739		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.2677196933266739 | validation: 0.25102929590852663]
	TIME [epoch: 8.38 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2799407148575993		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.2799407148575993 | validation: 0.21466147307624994]
	TIME [epoch: 8.37 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27717831490880174		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.27717831490880174 | validation: 0.23799708561248567]
	TIME [epoch: 8.36 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2828802196066728		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.2828802196066728 | validation: 0.24602607800696974]
	TIME [epoch: 8.36 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27572080960884976		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.27572080960884976 | validation: 0.2228560549449373]
	TIME [epoch: 8.39 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2755186478206618		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.2755186478206618 | validation: 0.29732704349834815]
	TIME [epoch: 8.37 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26722158750406644		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.26722158750406644 | validation: 0.23048417427729243]
	TIME [epoch: 8.36 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26914169258046733		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.26914169258046733 | validation: 0.26361000040925003]
	TIME [epoch: 8.36 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28156952882613306		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.28156952882613306 | validation: 0.41237104121741025]
	TIME [epoch: 8.38 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30283013489239624		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.30283013489239624 | validation: 0.2441838015249701]
	TIME [epoch: 8.37 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2817408660842345		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.2817408660842345 | validation: 0.24531749984032944]
	TIME [epoch: 8.37 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2994369111747911		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.2994369111747911 | validation: 0.3301946003071004]
	TIME [epoch: 8.36 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3050750269760143		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.3050750269760143 | validation: 0.22609864160266394]
	TIME [epoch: 8.37 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2910328786582461		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.2910328786582461 | validation: 0.2519871917863903]
	TIME [epoch: 8.39 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2855543253777784		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.2855543253777784 | validation: 0.2343930333942152]
	TIME [epoch: 8.37 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2734064649833419		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.2734064649833419 | validation: 0.29758495686785136]
	TIME [epoch: 8.36 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27529494834370627		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.27529494834370627 | validation: 0.27563696808298477]
	TIME [epoch: 8.36 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2594337186019757		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.2594337186019757 | validation: 0.24422736984122576]
	TIME [epoch: 8.38 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2792662397110065		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.2792662397110065 | validation: 0.28494223707102295]
	TIME [epoch: 8.37 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29790646605225224		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.29790646605225224 | validation: 0.24111028870521384]
	TIME [epoch: 8.37 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.315112477758663		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.315112477758663 | validation: 0.22713571988656875]
	TIME [epoch: 8.35 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28682281171706503		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.28682281171706503 | validation: 0.2720469562888217]
	TIME [epoch: 8.39 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3329880513131594		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.3329880513131594 | validation: 0.22503455670720418]
	TIME [epoch: 8.36 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2756920724797638		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.2756920724797638 | validation: 0.2996644968463975]
	TIME [epoch: 8.36 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2701805614179034		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.2701805614179034 | validation: 0.21464574431465572]
	TIME [epoch: 8.37 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2958449259825519		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.2958449259825519 | validation: 0.23540257566496173]
	TIME [epoch: 8.37 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26225996063559825		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.26225996063559825 | validation: 0.21737480817331734]
	TIME [epoch: 8.39 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.282968428754664		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.282968428754664 | validation: 0.38145324972851624]
	TIME [epoch: 8.37 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26721824595991844		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.26721824595991844 | validation: 0.3257249251344052]
	TIME [epoch: 8.36 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2850118149681486		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.2850118149681486 | validation: 0.25034646645419933]
	TIME [epoch: 8.36 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2850580775938674		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.2850580775938674 | validation: 0.22216433071721509]
	TIME [epoch: 8.38 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2641496326019773		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.2641496326019773 | validation: 0.22055004678469647]
	TIME [epoch: 8.36 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2803894643210103		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.2803894643210103 | validation: 0.2448196290591892]
	TIME [epoch: 8.35 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2690409929253339		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.2690409929253339 | validation: 0.2580158821114346]
	TIME [epoch: 8.36 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2604949501007945		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.2604949501007945 | validation: 0.22497982186805812]
	TIME [epoch: 8.38 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2776338563244187		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.2776338563244187 | validation: 0.23568166044596972]
	TIME [epoch: 8.37 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26435680336324		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.26435680336324 | validation: 0.2712843870408689]
	TIME [epoch: 8.36 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2610770181838026		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.2610770181838026 | validation: 0.20592096616298045]
	TIME [epoch: 8.36 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2576924737380094		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.2576924737380094 | validation: 0.24601614341608852]
	TIME [epoch: 8.36 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28055355015380795		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.28055355015380795 | validation: 0.25868250241659785]
	TIME [epoch: 8.38 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.272688029087358		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.272688029087358 | validation: 0.21868373228276486]
	TIME [epoch: 8.36 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29175350570411285		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.29175350570411285 | validation: 0.2484170184808954]
	TIME [epoch: 8.35 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26841451439519787		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.26841451439519787 | validation: 0.20893832661568326]
	TIME [epoch: 8.36 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31350984047498776		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.31350984047498776 | validation: 0.20305839077642815]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_775.pth
	Model improved!!!
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29888551162030785		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.29888551162030785 | validation: 0.39059709735806897]
	TIME [epoch: 8.36 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29844580867108006		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.29844580867108006 | validation: 0.20348458187248392]
	TIME [epoch: 8.36 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26840407624492385		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.26840407624492385 | validation: 0.21844227294019075]
	TIME [epoch: 8.36 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2728615072295736		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.2728615072295736 | validation: 0.30392697485506015]
	TIME [epoch: 8.39 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2728410475055549		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.2728410475055549 | validation: 0.2110212579182107]
	TIME [epoch: 8.36 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2622646469535849		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.2622646469535849 | validation: 0.2456027142574022]
	TIME [epoch: 8.35 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26842392187153047		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.26842392187153047 | validation: 0.2740103263871023]
	TIME [epoch: 8.35 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2671556794613387		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.2671556794613387 | validation: 0.2929013522424848]
	TIME [epoch: 8.37 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29542524261005026		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.29542524261005026 | validation: 0.23094633637753684]
	TIME [epoch: 8.37 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27779590067497606		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.27779590067497606 | validation: 0.2918021540735372]
	TIME [epoch: 8.36 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25317887350432666		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.25317887350432666 | validation: 0.22604953579749307]
	TIME [epoch: 8.36 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24267635605634438		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.24267635605634438 | validation: 0.2253904072813526]
	TIME [epoch: 8.37 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.284553351403222		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.284553351403222 | validation: 0.21389373606747697]
	TIME [epoch: 8.38 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2667228694236409		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.2667228694236409 | validation: 0.2896326066573254]
	TIME [epoch: 8.36 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29138967917945535		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.29138967917945535 | validation: 0.23368707888575052]
	TIME [epoch: 8.36 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2798123550542603		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.2798123550542603 | validation: 0.2378257682368896]
	TIME [epoch: 8.36 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27816568784723594		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.27816568784723594 | validation: 0.23501047378841036]
	TIME [epoch: 8.39 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2540617816485443		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.2540617816485443 | validation: 0.21614992334581126]
	TIME [epoch: 8.37 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2619631515300581		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.2619631515300581 | validation: 0.2206210172473278]
	TIME [epoch: 8.36 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26954202261478527		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.26954202261478527 | validation: 0.2866855501033335]
	TIME [epoch: 8.36 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2862408712633791		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.2862408712633791 | validation: 0.23467008045038384]
	TIME [epoch: 8.37 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29170289952310574		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.29170289952310574 | validation: 0.25742511981722077]
	TIME [epoch: 8.37 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25521977674485297		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.25521977674485297 | validation: 0.24313328412274451]
	TIME [epoch: 8.36 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2722092680599167		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.2722092680599167 | validation: 0.20964811476804407]
	TIME [epoch: 8.36 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26016642115765526		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.26016642115765526 | validation: 0.28628733078476903]
	TIME [epoch: 8.36 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2702160730593309		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.2702160730593309 | validation: 0.22574490862830474]
	TIME [epoch: 8.4 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26428459277353483		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.26428459277353483 | validation: 0.2069686611483708]
	TIME [epoch: 8.37 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2788588169401217		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.2788588169401217 | validation: 0.25189473092260606]
	TIME [epoch: 8.37 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30253562314225235		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.30253562314225235 | validation: 0.24458737619729884]
	TIME [epoch: 8.37 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2523190923314039		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.2523190923314039 | validation: 0.3409724105228583]
	TIME [epoch: 8.38 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27380829919584543		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.27380829919584543 | validation: 0.27199212261166184]
	TIME [epoch: 8.37 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29121723290101664		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.29121723290101664 | validation: 0.22848849188768464]
	TIME [epoch: 8.37 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26603492607108675		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.26603492607108675 | validation: 0.2071817007156399]
	TIME [epoch: 8.37 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.258452604183392		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.258452604183392 | validation: 0.23166398990054604]
	TIME [epoch: 8.38 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2506045643528771		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.2506045643528771 | validation: 0.34690277835380257]
	TIME [epoch: 8.39 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28601438539680035		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.28601438539680035 | validation: 0.31578458327755915]
	TIME [epoch: 8.37 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2942500201048165		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.2942500201048165 | validation: 0.2550309598313075]
	TIME [epoch: 8.37 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26679291251175324		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.26679291251175324 | validation: 0.22842032768469217]
	TIME [epoch: 8.37 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28410528584388195		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.28410528584388195 | validation: 0.24359707084563725]
	TIME [epoch: 8.38 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2608032088345413		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.2608032088345413 | validation: 0.2663527964897128]
	TIME [epoch: 8.36 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28103686972236314		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.28103686972236314 | validation: 0.2552875737522611]
	TIME [epoch: 8.36 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27344937444519385		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.27344937444519385 | validation: 0.2500850605085416]
	TIME [epoch: 8.36 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2665756500761692		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.2665756500761692 | validation: 0.283788783021482]
	TIME [epoch: 8.39 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2711625494317445		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.2711625494317445 | validation: 0.23510767709411454]
	TIME [epoch: 8.37 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2706928115160273		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.2706928115160273 | validation: 0.2040918316424764]
	TIME [epoch: 8.36 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26668783445081423		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.26668783445081423 | validation: 0.21354134881468526]
	TIME [epoch: 8.36 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2514646428790315		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.2514646428790315 | validation: 0.21088413154296554]
	TIME [epoch: 8.39 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27960445438686704		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.27960445438686704 | validation: 0.2066336403453693]
	TIME [epoch: 8.36 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.273198214082382		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.273198214082382 | validation: 0.2092105841354332]
	TIME [epoch: 8.37 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25828418203535325		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.25828418203535325 | validation: 0.38415391700695145]
	TIME [epoch: 8.37 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2937796326565233		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.2937796326565233 | validation: 0.21231138832279117]
	TIME [epoch: 8.37 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26360488495247725		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.26360488495247725 | validation: 0.2652003899359023]
	TIME [epoch: 8.39 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2693507436041586		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.2693507436041586 | validation: 0.32564487636624484]
	TIME [epoch: 8.36 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28514093003121016		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.28514093003121016 | validation: 0.2866081042536234]
	TIME [epoch: 8.37 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2836261900946099		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.2836261900946099 | validation: 0.3653238029912537]
	TIME [epoch: 8.36 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2675401238885257		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.2675401238885257 | validation: 0.29154859602545]
	TIME [epoch: 8.39 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2741423075515741		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.2741423075515741 | validation: 0.22421064240417324]
	TIME [epoch: 8.37 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2491242589454466		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.2491242589454466 | validation: 0.22318316338260608]
	TIME [epoch: 8.37 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2674638235817358		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.2674638235817358 | validation: 0.2498487052073492]
	TIME [epoch: 8.36 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2679666733363543		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.2679666733363543 | validation: 0.20886897490284106]
	TIME [epoch: 8.39 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25919244430276545		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.25919244430276545 | validation: 0.2443470641525441]
	TIME [epoch: 8.37 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24233437467622698		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.24233437467622698 | validation: 0.266381853605153]
	TIME [epoch: 8.37 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2503344571205611		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.2503344571205611 | validation: 0.19969543197568562]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_838.pth
	Model improved!!!
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27890157196574616		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.27890157196574616 | validation: 0.27917481308832925]
	TIME [epoch: 8.37 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26886915764261415		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.26886915764261415 | validation: 0.21719035027941824]
	TIME [epoch: 8.38 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24198678214976263		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.24198678214976263 | validation: 0.28650923692429986]
	TIME [epoch: 8.37 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26226419019727054		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.26226419019727054 | validation: 0.20214899050185936]
	TIME [epoch: 8.36 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25874388531290876		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.25874388531290876 | validation: 0.23441238129846959]
	TIME [epoch: 8.36 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26050924661226527		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.26050924661226527 | validation: 0.20798071278342045]
	TIME [epoch: 8.39 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26899643842075566		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.26899643842075566 | validation: 0.25555036048740654]
	TIME [epoch: 8.37 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29079182323372166		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.29079182323372166 | validation: 0.21306437938343104]
	TIME [epoch: 8.36 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2586043025448993		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.2586043025448993 | validation: 0.21303957126501755]
	TIME [epoch: 8.37 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2624629077086996		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.2624629077086996 | validation: 0.26794113815700676]
	TIME [epoch: 8.39 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27320791355561147		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.27320791355561147 | validation: 0.21242900379699675]
	TIME [epoch: 8.37 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24865904825612323		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.24865904825612323 | validation: 0.29204681518174913]
	TIME [epoch: 8.36 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2810653832211809		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.2810653832211809 | validation: 0.21001105490166966]
	TIME [epoch: 8.37 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24748850478336096		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.24748850478336096 | validation: 0.2367477873457144]
	TIME [epoch: 8.36 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32986599797769145		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.32986599797769145 | validation: 0.284130954958323]
	TIME [epoch: 8.39 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26118810008676446		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.26118810008676446 | validation: 0.22119297353925124]
	TIME [epoch: 8.37 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24711108549581665		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.24711108549581665 | validation: 0.2529492582899221]
	TIME [epoch: 8.36 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26339570288689307		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.26339570288689307 | validation: 0.29654349140036074]
	TIME [epoch: 8.37 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2650082089154555		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.2650082089154555 | validation: 0.27525123462507706]
	TIME [epoch: 8.39 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26294548197537676		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.26294548197537676 | validation: 0.23154713435782448]
	TIME [epoch: 8.37 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2541851397288116		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.2541851397288116 | validation: 0.21252890173363576]
	TIME [epoch: 8.36 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2477084818389929		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.2477084818389929 | validation: 0.22511102103636244]
	TIME [epoch: 8.36 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25400859050005664		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.25400859050005664 | validation: 0.2251143731436952]
	TIME [epoch: 8.39 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25623667169892317		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.25623667169892317 | validation: 0.20888701523656822]
	TIME [epoch: 8.36 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24751669809740967		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.24751669809740967 | validation: 0.2438302138310509]
	TIME [epoch: 8.37 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2502706944118655		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.2502706944118655 | validation: 0.23179288969564166]
	TIME [epoch: 8.36 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2558525177329121		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.2558525177329121 | validation: 0.26623092681492627]
	TIME [epoch: 8.38 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27261970984132305		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.27261970984132305 | validation: 0.21493610779990735]
	TIME [epoch: 8.37 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26573735835582923		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.26573735835582923 | validation: 0.22213844475798802]
	TIME [epoch: 8.38 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2477411520748521		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.2477411520748521 | validation: 0.28189446718547395]
	TIME [epoch: 8.38 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2739375724340943		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.2739375724340943 | validation: 0.2364232388940919]
	TIME [epoch: 8.36 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26665722090748817		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.26665722090748817 | validation: 0.3264734813849872]
	TIME [epoch: 8.39 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.266665918213313		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.266665918213313 | validation: 0.26224823309909684]
	TIME [epoch: 8.36 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2654404360857566		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.2654404360857566 | validation: 0.21809738366917025]
	TIME [epoch: 8.37 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24520805053625344		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.24520805053625344 | validation: 0.22375301658050123]
	TIME [epoch: 8.36 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25210045755128624		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.25210045755128624 | validation: 0.20817541660973915]
	TIME [epoch: 8.39 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24112385678836373		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.24112385678836373 | validation: 0.20372031711025176]
	TIME [epoch: 8.36 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26177787281778175		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.26177787281778175 | validation: 0.2216936147878425]
	TIME [epoch: 8.37 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24663916645684303		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.24663916645684303 | validation: 0.23450561406693446]
	TIME [epoch: 8.36 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24714775872133748		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.24714775872133748 | validation: 0.21322886720512943]
	TIME [epoch: 8.38 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25184422767434655		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.25184422767434655 | validation: 0.22978516666506169]
	TIME [epoch: 8.38 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25651672849233953		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.25651672849233953 | validation: 0.22262002594948066]
	TIME [epoch: 8.36 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25113825682182167		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.25113825682182167 | validation: 0.22840114819999352]
	TIME [epoch: 8.36 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2766594870217126		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.2766594870217126 | validation: 0.20494718169685372]
	TIME [epoch: 8.36 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2496096875394977		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.2496096875394977 | validation: 0.2074589507386321]
	TIME [epoch: 8.39 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24463596711035449		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.24463596711035449 | validation: 0.20678515708922562]
	TIME [epoch: 8.37 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23756323747465577		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.23756323747465577 | validation: 0.2012623071494458]
	TIME [epoch: 8.36 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24675888682032115		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.24675888682032115 | validation: 0.22894623088006316]
	TIME [epoch: 8.37 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2602603660136748		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.2602603660136748 | validation: 0.24702166666914732]
	TIME [epoch: 8.39 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2489103441647304		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.2489103441647304 | validation: 0.20520126916631343]
	TIME [epoch: 8.37 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2518452159378477		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.2518452159378477 | validation: 0.2197360530171248]
	TIME [epoch: 8.36 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24646616448009323		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.24646616448009323 | validation: 0.2119880118701253]
	TIME [epoch: 8.36 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26154423142517336		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.26154423142517336 | validation: 0.2368049784742356]
	TIME [epoch: 8.38 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25457164841239466		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.25457164841239466 | validation: 0.24806841925024634]
	TIME [epoch: 8.37 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2639285490036585		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.2639285490036585 | validation: 0.25859687435603435]
	TIME [epoch: 8.36 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25885038798539256		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.25885038798539256 | validation: 0.2018585836554384]
	TIME [epoch: 8.36 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2654477613138001		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.2654477613138001 | validation: 0.2130331160625736]
	TIME [epoch: 8.37 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27225192433384104		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.27225192433384104 | validation: 0.21892936796509294]
	TIME [epoch: 8.39 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2446434808658106		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.2446434808658106 | validation: 0.2216238006342407]
	TIME [epoch: 8.37 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25105338039156927		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.25105338039156927 | validation: 0.2193035412321402]
	TIME [epoch: 8.36 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25294530513082514		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.25294530513082514 | validation: 0.24235849257817876]
	TIME [epoch: 8.36 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25081759681195487		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.25081759681195487 | validation: 0.23500133712202564]
	TIME [epoch: 8.39 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2667767147962375		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.2667767147962375 | validation: 0.21711421672797038]
	TIME [epoch: 8.37 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2625528132104725		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.2625528132104725 | validation: 0.26923119847387633]
	TIME [epoch: 8.36 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2585735307144108		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.2585735307144108 | validation: 0.25631320600911794]
	TIME [epoch: 8.36 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26976254480232476		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.26976254480232476 | validation: 0.19782522782517228]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_904.pth
	Model improved!!!
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2645360136692503		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.2645360136692503 | validation: 0.21309595305335244]
	TIME [epoch: 8.37 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24049385353197578		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.24049385353197578 | validation: 0.22733652797152562]
	TIME [epoch: 8.37 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26564811421978357		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.26564811421978357 | validation: 0.2233739519289923]
	TIME [epoch: 8.36 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2527961925669876		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.2527961925669876 | validation: 0.2223655487140449]
	TIME [epoch: 8.37 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2552443000961649		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.2552443000961649 | validation: 0.2196231430702247]
	TIME [epoch: 8.38 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26900727141871383		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.26900727141871383 | validation: 0.20967051210334126]
	TIME [epoch: 8.36 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2650094920493646		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.2650094920493646 | validation: 0.2066850343826105]
	TIME [epoch: 8.36 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2389733439570482		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.2389733439570482 | validation: 0.21991931174281792]
	TIME [epoch: 8.37 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25325437891495045		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.25325437891495045 | validation: 0.24473857875850086]
	TIME [epoch: 8.39 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27003177198979605		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.27003177198979605 | validation: 0.20816985563412588]
	TIME [epoch: 8.37 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23510730925517048		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.23510730925517048 | validation: 0.2049364458233801]
	TIME [epoch: 8.36 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2745142926633459		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.2745142926633459 | validation: 0.2688831977498644]
	TIME [epoch: 8.36 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24230996185489198		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.24230996185489198 | validation: 0.22260527553243725]
	TIME [epoch: 8.38 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24004475000527922		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.24004475000527922 | validation: 0.27775314252360145]
	TIME [epoch: 8.36 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2698581792025566		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.2698581792025566 | validation: 0.29094791046386226]
	TIME [epoch: 8.37 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26059467823619753		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.26059467823619753 | validation: 0.2144785684906677]
	TIME [epoch: 8.36 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2417008060270526		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.2417008060270526 | validation: 0.20261709008488465]
	TIME [epoch: 8.37 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25348968078158773		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.25348968078158773 | validation: 0.21037177286801106]
	TIME [epoch: 8.39 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24939120160815556		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.24939120160815556 | validation: 0.25716740149311035]
	TIME [epoch: 8.37 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26341410686122285		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.26341410686122285 | validation: 0.19671828715519496]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_924.pth
	Model improved!!!
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24228459960579504		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.24228459960579504 | validation: 0.21665904632382288]
	TIME [epoch: 8.37 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2422700901794801		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.2422700901794801 | validation: 0.21274581335117754]
	TIME [epoch: 8.37 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2490796455789437		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.2490796455789437 | validation: 0.2615380536236906]
	TIME [epoch: 8.36 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24240428935967043		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.24240428935967043 | validation: 0.2231811341789924]
	TIME [epoch: 8.36 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24289913118010684		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.24289913118010684 | validation: 0.22498427870377324]
	TIME [epoch: 8.36 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24104465489780308		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.24104465489780308 | validation: 0.20637051368448414]
	TIME [epoch: 8.39 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24451188489019965		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.24451188489019965 | validation: 0.2190081871727596]
	TIME [epoch: 8.36 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24167764612721196		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.24167764612721196 | validation: 0.212619228742453]
	TIME [epoch: 8.36 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25405397173593314		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.25405397173593314 | validation: 0.20148981869507626]
	TIME [epoch: 8.37 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2407302832854608		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.2407302832854608 | validation: 0.2564270540810709]
	TIME [epoch: 8.38 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25534761052590144		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.25534761052590144 | validation: 0.2253985838572673]
	TIME [epoch: 8.37 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.255401010131351		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.255401010131351 | validation: 0.2110142823543021]
	TIME [epoch: 8.36 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24313577248137697		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.24313577248137697 | validation: 0.20820752405890092]
	TIME [epoch: 8.36 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25095635498447094		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.25095635498447094 | validation: 0.2012030265608754]
	TIME [epoch: 8.36 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24419882951045677		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.24419882951045677 | validation: 0.278811988535255]
	TIME [epoch: 8.38 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25889992188543187		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.25889992188543187 | validation: 0.24625478474168935]
	TIME [epoch: 8.36 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26065680550041226		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.26065680550041226 | validation: 0.21268010414583077]
	TIME [epoch: 8.36 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2498985921904766		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.2498985921904766 | validation: 0.22057808060826467]
	TIME [epoch: 8.36 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24799064585308223		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.24799064585308223 | validation: 0.2359291565171326]
	TIME [epoch: 8.38 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24640624396024133		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.24640624396024133 | validation: 0.20966528835830217]
	TIME [epoch: 8.36 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25186707573527495		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.25186707573527495 | validation: 0.23241460896312355]
	TIME [epoch: 8.36 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2502032399578755		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.2502032399578755 | validation: 0.23078133587161073]
	TIME [epoch: 8.36 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2560503779148121		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.2560503779148121 | validation: 0.22337252515993455]
	TIME [epoch: 8.37 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2425159350172068		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.2425159350172068 | validation: 0.26646166143874683]
	TIME [epoch: 8.37 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25729766690007655		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.25729766690007655 | validation: 0.23300449648078708]
	TIME [epoch: 8.36 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26523759252226864		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.26523759252226864 | validation: 0.20660068796828857]
	TIME [epoch: 8.36 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23451767947518914		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.23451767947518914 | validation: 0.2383630639390206]
	TIME [epoch: 8.37 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23994639591095773		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.23994639591095773 | validation: 0.2163906805340723]
	TIME [epoch: 8.39 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2492607796280772		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.2492607796280772 | validation: 0.19890026037147526]
	TIME [epoch: 8.37 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24333791823631948		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.24333791823631948 | validation: 0.20561704921884455]
	TIME [epoch: 8.37 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2569154964608136		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.2569154964608136 | validation: 0.27842937073903096]
	TIME [epoch: 8.36 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24729588321050486		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.24729588321050486 | validation: 0.2079710286547069]
	TIME [epoch: 8.39 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24704819777214118		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.24704819777214118 | validation: 0.2052167406475479]
	TIME [epoch: 8.37 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2388089311334806		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.2388089311334806 | validation: 0.2027850833085384]
	TIME [epoch: 8.36 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2398594886871499		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.2398594886871499 | validation: 0.21679068880531707]
	TIME [epoch: 8.36 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2715162536310599		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.2715162536310599 | validation: 0.21122558981224476]
	TIME [epoch: 8.38 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.258707374936868		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.258707374936868 | validation: 0.2225955500553319]
	TIME [epoch: 8.37 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24888983630411388		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.24888983630411388 | validation: 0.20115647749178617]
	TIME [epoch: 8.37 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.243497750914838		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.243497750914838 | validation: 0.23758121533460175]
	TIME [epoch: 8.37 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2637869273606976		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.2637869273606976 | validation: 0.21134431863781655]
	TIME [epoch: 8.36 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2647211198460369		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.2647211198460369 | validation: 0.20398061725357275]
	TIME [epoch: 8.39 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25172218258533235		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.25172218258533235 | validation: 0.23799184657927203]
	TIME [epoch: 8.36 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25444479435987527		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.25444479435987527 | validation: 0.20580822493649825]
	TIME [epoch: 8.37 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24815995703964688		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.24815995703964688 | validation: 0.19650974323208367]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_968.pth
	Model improved!!!
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23838477655457174		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.23838477655457174 | validation: 0.23200640601674197]
	TIME [epoch: 8.38 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2601073144988736		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.2601073144988736 | validation: 0.21009831748001345]
	TIME [epoch: 8.36 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23532494086671152		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.23532494086671152 | validation: 0.21142495351961002]
	TIME [epoch: 8.36 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2445799497895242		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.2445799497895242 | validation: 0.2772175221808957]
	TIME [epoch: 8.36 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24986407770177665		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.24986407770177665 | validation: 0.22112263963742929]
	TIME [epoch: 8.38 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2457815516619275		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.2457815516619275 | validation: 0.22481052616067787]
	TIME [epoch: 8.37 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2510720457149513		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.2510720457149513 | validation: 0.211323320069252]
	TIME [epoch: 8.35 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23739699588336044		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.23739699588336044 | validation: 0.2236972528216135]
	TIME [epoch: 8.36 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24276345553784848		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.24276345553784848 | validation: 0.22615115530954255]
	TIME [epoch: 8.37 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2451127818949273		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.2451127818949273 | validation: 0.22859577467721626]
	TIME [epoch: 8.38 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2534365409665001		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.2534365409665001 | validation: 0.2120151775214304]
	TIME [epoch: 8.36 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23828358390498425		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.23828358390498425 | validation: 0.2067643782611594]
	TIME [epoch: 8.35 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25170200787147806		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.25170200787147806 | validation: 0.2157262872817987]
	TIME [epoch: 8.36 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23799633756356312		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.23799633756356312 | validation: 0.20445895464731312]
	TIME [epoch: 8.39 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23876234898496737		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.23876234898496737 | validation: 0.21418787741886375]
	TIME [epoch: 8.37 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24834673607919583		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.24834673607919583 | validation: 0.24113947577250044]
	TIME [epoch: 8.36 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24403925294850368		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.24403925294850368 | validation: 0.21710227660847103]
	TIME [epoch: 8.36 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23879670445818263		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.23879670445818263 | validation: 0.22496071994453115]
	TIME [epoch: 8.38 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24829172659531995		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.24829172659531995 | validation: 0.22567928022628927]
	TIME [epoch: 8.36 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2616330788416857		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.2616330788416857 | validation: 0.21109092236189403]
	TIME [epoch: 8.36 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24721958689047438		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.24721958689047438 | validation: 0.22127505165924732]
	TIME [epoch: 8.36 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25678312195620656		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.25678312195620656 | validation: 0.22591447544407312]
	TIME [epoch: 8.36 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24279983133469063		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.24279983133469063 | validation: 0.20985070045533005]
	TIME [epoch: 8.39 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24841053708993172		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.24841053708993172 | validation: 0.21728573370069387]
	TIME [epoch: 8.36 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24418614700809024		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.24418614700809024 | validation: 0.2790119782700705]
	TIME [epoch: 8.36 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.254670822261515		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.254670822261515 | validation: 0.20091697439034362]
	TIME [epoch: 8.36 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2472463150850331		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.2472463150850331 | validation: 0.20435166434516322]
	TIME [epoch: 8.38 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23901520791683498		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.23901520791683498 | validation: 0.20827604092257185]
	TIME [epoch: 8.37 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23607018130448715		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.23607018130448715 | validation: 0.21620920882474648]
	TIME [epoch: 8.35 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24176360445942038		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.24176360445942038 | validation: 0.21802788871180137]
	TIME [epoch: 8.34 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2560513606766607		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.2560513606766607 | validation: 0.22354025101665548]
	TIME [epoch: 8.39 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24354593196685687		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.24354593196685687 | validation: 0.18987957722916365]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240217_140928/states/model_tr_study4_1000.pth
	Model improved!!!
Finished training in 8484.215 seconds.
