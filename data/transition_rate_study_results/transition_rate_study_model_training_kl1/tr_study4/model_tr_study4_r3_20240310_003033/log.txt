Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r3', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1341151889

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.433983964582012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.433983964582012 | validation: 7.914374742822322]
	TIME [epoch: 100 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.394438822661795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.394438822661795 | validation: 6.290521083544099]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.495731492803388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.495731492803388 | validation: 8.832653123009585]
	TIME [epoch: 11.6 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.464496112102024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.464496112102024 | validation: 4.933348276445664]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.419075519753225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.419075519753225 | validation: 5.474925299820268]
	TIME [epoch: 11.5 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.363784970771178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.363784970771178 | validation: 4.476442430687771]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.228823139490197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.228823139490197 | validation: 4.631692351364839]
	TIME [epoch: 11.5 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.899469790093788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.899469790093788 | validation: 10.41567866902926]
	TIME [epoch: 11.5 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.521049800585496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.521049800585496 | validation: 7.600655630908341]
	TIME [epoch: 11.6 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.49890636493988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.49890636493988 | validation: 9.628434891696504]
	TIME [epoch: 11.5 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.814580990029655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.814580990029655 | validation: 4.599648915939828]
	TIME [epoch: 11.5 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.423995970215643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.423995970215643 | validation: 4.226021624081122]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.033476906094332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.033476906094332 | validation: 3.950014484493278]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.712060011692149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.712060011692149 | validation: 3.733120763035128]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4112783840913328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4112783840913328 | validation: 3.723884096769071]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.541320679741841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.541320679741841 | validation: 4.020215388266279]
	TIME [epoch: 11.5 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4553871845542856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4553871845542856 | validation: 3.6410219837633764]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4366609887482227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4366609887482227 | validation: 3.5720453523314792]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2796590132240153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2796590132240153 | validation: 3.3416944201648016]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.32581847989666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.32581847989666 | validation: 3.437147986947682]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1741904343676612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1741904343676612 | validation: 3.354767999634938]
	TIME [epoch: 11.5 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2657433986927633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2657433986927633 | validation: 3.1912381477705627]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3062865020073655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3062865020073655 | validation: 4.277455489140356]
	TIME [epoch: 11.5 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6133958827591153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6133958827591153 | validation: 4.157293116967009]
	TIME [epoch: 11.5 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.444230881591533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.444230881591533 | validation: 3.5137053979606185]
	TIME [epoch: 11.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215572261099834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.215572261099834 | validation: 3.6194870907474708]
	TIME [epoch: 11.5 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0317289425019096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0317289425019096 | validation: 3.347840891640249]
	TIME [epoch: 11.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.082562439870566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.082562439870566 | validation: 2.960609846647242]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9217459838425826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9217459838425826 | validation: 2.727096757073772]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.597774547528768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.597774547528768 | validation: 2.6496669491884894]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5175223931484334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5175223931484334 | validation: 2.809847217495741]
	TIME [epoch: 11.5 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.875960917824176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.875960917824176 | validation: 3.503675953590637]
	TIME [epoch: 11.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7653169735460374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7653169735460374 | validation: 2.682100289744168]
	TIME [epoch: 11.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5528822660037407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5528822660037407 | validation: 2.5511330090255426]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.438165556504078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.438165556504078 | validation: 2.276329330164228]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2649364100144838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2649364100144838 | validation: 2.1053950629072107]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0764483639453934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0764483639453934 | validation: 2.3120602799622016]
	TIME [epoch: 11.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2415579397198764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2415579397198764 | validation: 1.8898151649343191]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9302028179519075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9302028179519075 | validation: 1.8032663782665208]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.092584773694465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.092584773694465 | validation: 1.8914477221889037]
	TIME [epoch: 11.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.135570569440318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.135570569440318 | validation: 1.676072769237127]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7679725438305673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7679725438305673 | validation: 1.7345789758683154]
	TIME [epoch: 11.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6385762456305888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6385762456305888 | validation: 1.4989978981825356]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5832283603767312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5832283603767312 | validation: 1.4264448641892415]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.18685592456047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.18685592456047 | validation: 2.182247167509296]
	TIME [epoch: 11.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4997442172998843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4997442172998843 | validation: 1.383408766794533]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4100955505625874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4100955505625874 | validation: 1.2391404157804515]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.493640791501408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.493640791501408 | validation: 1.2557957701768612]
	TIME [epoch: 11.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2076964592340318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2076964592340318 | validation: 1.6023536334570774]
	TIME [epoch: 11.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5997608655894373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5997608655894373 | validation: 1.2970081698751899]
	TIME [epoch: 11.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1963861555487345		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.1963861555487345 | validation: 1.4321198595989666]
	TIME [epoch: 11.5 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4308659329830367		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.4308659329830367 | validation: 1.3662014149332478]
	TIME [epoch: 11.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3803374639869315		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.3803374639869315 | validation: 1.0908846362850029]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1974522905512064		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.1974522905512064 | validation: 2.71661904829483]
	TIME [epoch: 11.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5966011870096186		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.5966011870096186 | validation: 1.369371453412533]
	TIME [epoch: 11.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2670473784846226		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.2670473784846226 | validation: 1.0740050368382712]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1725519176939236		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.1725519176939236 | validation: 1.5121254255803678]
	TIME [epoch: 11.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.468383236607345		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.468383236607345 | validation: 1.4184722852838252]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3187149863647019		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.3187149863647019 | validation: 0.8937114782882154]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.181113255156562		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.181113255156562 | validation: 1.1338666327095543]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1082314025106488		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.1082314025106488 | validation: 1.3421838801489951]
	TIME [epoch: 11.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0564262248973924		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.0564262248973924 | validation: 1.4249749373237621]
	TIME [epoch: 11.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0235061550435591		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.0235061550435591 | validation: 0.6743247533115937]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.26781240182558		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.26781240182558 | validation: 1.0061972594239346]
	TIME [epoch: 11.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.923304755461147		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.923304755461147 | validation: 1.0770732460164103]
	TIME [epoch: 11.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0958504694254954		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.0958504694254954 | validation: 0.7598062319562626]
	TIME [epoch: 11.5 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8720275721936291		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.8720275721936291 | validation: 1.3547268777886787]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.893062456284715		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.893062456284715 | validation: 0.7158934828968316]
	TIME [epoch: 11.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1460928607685448		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.1460928607685448 | validation: 0.7896256348715588]
	TIME [epoch: 11.5 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7480188159405123		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.7480188159405123 | validation: 0.6967291900234883]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.966640982880929		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.966640982880929 | validation: 0.7579078715841919]
	TIME [epoch: 11.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9739808218452128		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.9739808218452128 | validation: 0.7799324616669394]
	TIME [epoch: 11.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260484736677772		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.7260484736677772 | validation: 0.6472388270951782]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.929296688304786		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.929296688304786 | validation: 1.2116260860694978]
	TIME [epoch: 11.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8112143129701831		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.8112143129701831 | validation: 0.5894160070070162]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9017031693071824		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.9017031693071824 | validation: 0.5184737801765072]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0419467538482186		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.0419467538482186 | validation: 0.6228537904344672]
	TIME [epoch: 11.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0182073643358693		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.0182073643358693 | validation: 0.9390853339737294]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7903411697557079		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.7903411697557079 | validation: 0.7553794007096422]
	TIME [epoch: 11.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7241961677209698		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.7241961677209698 | validation: 0.8489170376520875]
	TIME [epoch: 11.6 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7872773965002966		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.7872773965002966 | validation: 0.6183379807802306]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6890697174171528		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.6890697174171528 | validation: 0.6560875849288406]
	TIME [epoch: 11.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7417955540179284		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.7417955540179284 | validation: 0.7773234419573108]
	TIME [epoch: 11.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.627535337887894		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.627535337887894 | validation: 0.6721229095686073]
	TIME [epoch: 11.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9224065910062479		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.9224065910062479 | validation: 0.7427492586104338]
	TIME [epoch: 11.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6618601961879684		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.6618601961879684 | validation: 0.5511912929889957]
	TIME [epoch: 11.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1364699192757148		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.1364699192757148 | validation: 1.1540700740169652]
	TIME [epoch: 11.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72390297847183		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.72390297847183 | validation: 0.46607617669463014]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5262647890023385		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.5262647890023385 | validation: 0.8060846828178668]
	TIME [epoch: 11.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6453854545087505		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.6453854545087505 | validation: 0.5728738890436859]
	TIME [epoch: 11.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6256125892339648		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.6256125892339648 | validation: 0.66951577099193]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8765234085619076		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.8765234085619076 | validation: 0.5710648454850825]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9248810419625246		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.9248810419625246 | validation: 0.7444581703807862]
	TIME [epoch: 11.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6794852756635492		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.6794852756635492 | validation: 0.6342358276261879]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6440372649607574		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.6440372649607574 | validation: 0.6833823103954987]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.639780925225256		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.639780925225256 | validation: 0.50905936218058]
	TIME [epoch: 11.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6219493259978024		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.6219493259978024 | validation: 0.5774260853928478]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.85364632865659		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.85364632865659 | validation: 1.6135829760162066]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0149565158177223		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.0149565158177223 | validation: 0.5634492282575568]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6571040627405904		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.6571040627405904 | validation: 0.6222620204297706]
	TIME [epoch: 11.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6081433380526766		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.6081433380526766 | validation: 0.5889441286021135]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5806969808226724		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.5806969808226724 | validation: 0.534048763486901]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5305524121840165		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.5305524121840165 | validation: 0.647901712042297]
	TIME [epoch: 11.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.597104769167295		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.597104769167295 | validation: 0.5944208151772273]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8637154923787705		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.8637154923787705 | validation: 0.6521722791359276]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8032288115850743		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.8032288115850743 | validation: 0.621951832102666]
	TIME [epoch: 11.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.699389354129445		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.699389354129445 | validation: 0.5036026674758138]
	TIME [epoch: 11.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6131409568158073		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.6131409568158073 | validation: 0.7667672721768983]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6227667486985936		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.6227667486985936 | validation: 0.8525875078455768]
	TIME [epoch: 11.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6372189936402417		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.6372189936402417 | validation: 0.5365936792141485]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5643510628215975		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.5643510628215975 | validation: 0.5463766620532602]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7249169354558798		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.7249169354558798 | validation: 0.9060627124896101]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8214084771917289		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.8214084771917289 | validation: 0.7485292530030097]
	TIME [epoch: 11.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6532492533063964		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.6532492533063964 | validation: 0.6090642995779909]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6076388791759448		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.6076388791759448 | validation: 0.7740265281704382]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7110552085237997		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.7110552085237997 | validation: 0.5973096631241631]
	TIME [epoch: 11.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542120088718154		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.542120088718154 | validation: 0.5485682565470142]
	TIME [epoch: 11.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193245185432924		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.7193245185432924 | validation: 0.46532798122315555]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5721309346652227		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.5721309346652227 | validation: 0.5616388199065436]
	TIME [epoch: 11.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5485896394954932		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.5485896394954932 | validation: 0.46564326013708907]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6388361496113732		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.6388361496113732 | validation: 0.7467894181901547]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5661337992783945		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.5661337992783945 | validation: 0.5813629388166973]
	TIME [epoch: 11.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5917521148401989		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.5917521148401989 | validation: 0.5473154883451523]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5435626699600895		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.5435626699600895 | validation: 0.4521419162953086]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5655241299785404		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.5655241299785404 | validation: 0.5191006250598135]
	TIME [epoch: 11.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8762404465930967		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.8762404465930967 | validation: 0.5095151241678283]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.567391073590869		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.567391073590869 | validation: 0.5103435510194119]
	TIME [epoch: 11.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7912181902320254		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.7912181902320254 | validation: 0.7664968601360851]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.595948401144676		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.595948401144676 | validation: 0.5123815275827678]
	TIME [epoch: 11.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5220629737732969		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.5220629737732969 | validation: 0.7026580495071753]
	TIME [epoch: 11.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.514052260238529		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.514052260238529 | validation: 0.5132028926381043]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46360579247220346		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.46360579247220346 | validation: 0.6601419068931353]
	TIME [epoch: 11.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6229508499010695		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.6229508499010695 | validation: 0.6010710987436287]
	TIME [epoch: 11.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5247472652876822		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.5247472652876822 | validation: 0.7207320753560913]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6193238336569761		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.6193238336569761 | validation: 0.6138880340143068]
	TIME [epoch: 11.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6548279922545082		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.6548279922545082 | validation: 0.5103806896722111]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107727558547628		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.5107727558547628 | validation: 0.46099089586291253]
	TIME [epoch: 11.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4506892463574494		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.4506892463574494 | validation: 0.45656799790159397]
	TIME [epoch: 11.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4527921354862293		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.4527921354862293 | validation: 0.7640897847586972]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5680327705192745		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.5680327705192745 | validation: 0.46646875752302996]
	TIME [epoch: 11.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5078405788021227		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.5078405788021227 | validation: 0.479528674189517]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4756362559988947		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.4756362559988947 | validation: 0.39577714080709486]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.418669276760188		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.418669276760188 | validation: 0.4292093299663724]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4361885290149282		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.4361885290149282 | validation: 0.49788475357904366]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4602505089038149		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.4602505089038149 | validation: 0.39613915489953017]
	TIME [epoch: 11.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43336341701522135		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.43336341701522135 | validation: 0.6961001581331556]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5046992776016653		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.5046992776016653 | validation: 0.7534127633174721]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5702973748632207		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.5702973748632207 | validation: 0.6457601670530021]
	TIME [epoch: 11.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5189881279821384		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.5189881279821384 | validation: 0.5077533640668691]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6330991034623079		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.6330991034623079 | validation: 0.4902879350793945]
	TIME [epoch: 11.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9666524207784688		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.9666524207784688 | validation: 0.6962731004416349]
	TIME [epoch: 11.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5995223303568783		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.5995223303568783 | validation: 0.6528750979418569]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.616581310937272		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.616581310937272 | validation: 0.7693052947408284]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5651052982522177		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.5651052982522177 | validation: 0.46291914648791027]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4545525136715967		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.4545525136715967 | validation: 0.3857850116796172]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4309051190728214		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.4309051190728214 | validation: 0.5435611900591573]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49361050219558694		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.49361050219558694 | validation: 0.49417058290274285]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49005405082112097		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.49005405082112097 | validation: 0.4301094850561361]
	TIME [epoch: 11.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4777063720959072		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.4777063720959072 | validation: 0.6353255545829979]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6073674477422126		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.6073674477422126 | validation: 1.1729854069587486]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6624854620512727		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.6624854620512727 | validation: 0.5448671081133053]
	TIME [epoch: 11.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5517523733303746		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.5517523733303746 | validation: 1.0775885619458112]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9341345395866969		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.9341345395866969 | validation: 0.9355569928907734]
	TIME [epoch: 11.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5649555622019394		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.5649555622019394 | validation: 0.4548506172652725]
	TIME [epoch: 11.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6716571801521192		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.6716571801521192 | validation: 0.9358325651099135]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.956376540710519		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.956376540710519 | validation: 0.612759979467519]
	TIME [epoch: 11.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5718043367638497		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.5718043367638497 | validation: 1.6069903990376355]
	TIME [epoch: 11.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7163075092816511		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.7163075092816511 | validation: 0.5387379984664585]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4638403540078804		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.4638403540078804 | validation: 2.813629589485292]
	TIME [epoch: 11.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1810380957392925		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.1810380957392925 | validation: 0.5619211162713137]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5230158207586687		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.5230158207586687 | validation: 0.5503399835688254]
	TIME [epoch: 11.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5359713424601757		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.5359713424601757 | validation: 0.44369381261797103]
	TIME [epoch: 11.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46656030984172636		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.46656030984172636 | validation: 0.5840967769481321]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49219761411080265		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.49219761411080265 | validation: 0.4881346488146146]
	TIME [epoch: 11.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48525005108617003		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.48525005108617003 | validation: 0.8524115380660533]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6356709395973017		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.6356709395973017 | validation: 0.5322565746644139]
	TIME [epoch: 11.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.512853175550303		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.512853175550303 | validation: 0.48009932262841526]
	TIME [epoch: 11.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5567077332305652		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.5567077332305652 | validation: 0.587821383399329]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4795208242483928		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.4795208242483928 | validation: 0.4095221000740027]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4375786369189901		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.4375786369189901 | validation: 0.3928619891890601]
	TIME [epoch: 11.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40399033759358083		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.40399033759358083 | validation: 0.45189016268593457]
	TIME [epoch: 11.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42736799653763047		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.42736799653763047 | validation: 0.47133490361900654]
	TIME [epoch: 11.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.551106790825764		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.551106790825764 | validation: 0.48088969925659164]
	TIME [epoch: 11.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49717681322850377		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.49717681322850377 | validation: 0.35076866694467035]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4020817310242605		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.4020817310242605 | validation: 0.6830275833544417]
	TIME [epoch: 11.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5206919978942277		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.5206919978942277 | validation: 0.957119382799381]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.73624573792911		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.73624573792911 | validation: 0.7284513303475005]
	TIME [epoch: 11.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6124110796061255		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.6124110796061255 | validation: 0.5789647084636055]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4554438333175903		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.4554438333175903 | validation: 0.4731552700381177]
	TIME [epoch: 11.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6641103602956376		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.6641103602956376 | validation: 0.7239576885568204]
	TIME [epoch: 11.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49717771818861145		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.49717771818861145 | validation: 0.38618449559447954]
	TIME [epoch: 11.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40953805841510393		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.40953805841510393 | validation: 0.39375522165005544]
	TIME [epoch: 11.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36738904864209515		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.36738904864209515 | validation: 0.4772564623632386]
	TIME [epoch: 11.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8062208119532582		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.8062208119532582 | validation: 0.41821434203868]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5254536332472772		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.5254536332472772 | validation: 0.6584548242360316]
	TIME [epoch: 11.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4592176077760852		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.4592176077760852 | validation: 0.3867268168835869]
	TIME [epoch: 11.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40388231869120517		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.40388231869120517 | validation: 0.4491964615122156]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5821984345297757		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.5821984345297757 | validation: 0.46449135540155106]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6107172929978237		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.6107172929978237 | validation: 0.4209094756443918]
	TIME [epoch: 11.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4370479779147931		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.4370479779147931 | validation: 0.48275395889775274]
	TIME [epoch: 11.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4009255708713484		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.4009255708713484 | validation: 0.3927795012181495]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35805576754195406		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.35805576754195406 | validation: 0.4357527151163074]
	TIME [epoch: 11.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3583400483849548		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.3583400483849548 | validation: 0.5804074866058528]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45402348149740024		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.45402348149740024 | validation: 0.33209294480789725]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33313662218437473		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.33313662218437473 | validation: 0.5926462357641851]
	TIME [epoch: 11.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45697894833703434		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.45697894833703434 | validation: 0.3980845419333485]
	TIME [epoch: 11.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44352053321219487		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.44352053321219487 | validation: 0.5247555346554665]
	TIME [epoch: 11.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4313401407037704		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.4313401407037704 | validation: 0.3636962277497016]
	TIME [epoch: 11.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4599526158151167		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.4599526158151167 | validation: 0.3349033836418204]
	TIME [epoch: 11.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41515304002276593		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.41515304002276593 | validation: 0.3583325548039982]
	TIME [epoch: 11.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47356873632641383		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.47356873632641383 | validation: 0.6867741349647575]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4129471096236693		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.4129471096236693 | validation: 0.44674568076726073]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42739700791846785		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.42739700791846785 | validation: 0.43093546848217756]
	TIME [epoch: 11.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4563049207896869		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.4563049207896869 | validation: 0.5372339045562144]
	TIME [epoch: 11.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5538666138625777		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.5538666138625777 | validation: 0.6163018365768741]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5520209639988994		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.5520209639988994 | validation: 0.3473530471116388]
	TIME [epoch: 11.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3779668611528038		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.3779668611528038 | validation: 0.5733391750665157]
	TIME [epoch: 11.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5220738697637882		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.5220738697637882 | validation: 0.40028960994708795]
	TIME [epoch: 11.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42737702624957596		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.42737702624957596 | validation: 0.38215465727924375]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36153276004821067		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.36153276004821067 | validation: 0.30905218811620666]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32082514416764485		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.32082514416764485 | validation: 0.29475289688086637]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3286755992049609		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.3286755992049609 | validation: 0.44339709229869656]
	TIME [epoch: 11.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48062924354682807		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.48062924354682807 | validation: 0.43288652214443124]
	TIME [epoch: 11.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44986881736864914		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.44986881736864914 | validation: 0.3477121879814578]
	TIME [epoch: 11.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3252036747169484		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.3252036747169484 | validation: 0.3305372155160626]
	TIME [epoch: 11.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4276962680503046		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.4276962680503046 | validation: 0.6545931821385514]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41639491569226855		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.41639491569226855 | validation: 0.29507135268120144]
	TIME [epoch: 11.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37983788446521183		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.37983788446521183 | validation: 0.35865178688564114]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3277872854500413		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.3277872854500413 | validation: 0.34415811713425576]
	TIME [epoch: 11.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29958988646270135		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.29958988646270135 | validation: 0.35472959701574697]
	TIME [epoch: 11.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5868110507529314		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.5868110507529314 | validation: 0.3156614290637998]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48688652897537604		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.48688652897537604 | validation: 0.4889935740938344]
	TIME [epoch: 11.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42740751014575035		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.42740751014575035 | validation: 0.5090048948945693]
	TIME [epoch: 11.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43358884277142146		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.43358884277142146 | validation: 0.29083437712867005]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30941437220292417		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.30941437220292417 | validation: 0.32055268299039813]
	TIME [epoch: 11.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3149162601492638		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.3149162601492638 | validation: 0.2911415530928967]
	TIME [epoch: 11.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.315388833206987		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.315388833206987 | validation: 0.43918733729326903]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976241040688002		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.3976241040688002 | validation: 0.36023235476308807]
	TIME [epoch: 11.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31120557965015816		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.31120557965015816 | validation: 0.4511875339295503]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46317424981929556		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.46317424981929556 | validation: 0.29208875959354674]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3234483452538386		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.3234483452538386 | validation: 0.33833021909475286]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30524468836747265		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.30524468836747265 | validation: 0.363411400935028]
	TIME [epoch: 11.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36849839683369684		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.36849839683369684 | validation: 0.2872049646995329]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27771568816024117		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.27771568816024117 | validation: 0.3223502987938424]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3495740198142771		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.3495740198142771 | validation: 0.28724160263106713]
	TIME [epoch: 11.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27636184600975405		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.27636184600975405 | validation: 0.31760536534998984]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35211212601942793		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.35211212601942793 | validation: 0.2665284773746101]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35748247117127063		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.35748247117127063 | validation: 0.630475558056229]
	TIME [epoch: 11.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4214333974209934		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.4214333974209934 | validation: 0.5898653094858733]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4524526578350217		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.4524526578350217 | validation: 0.3738454782159771]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3176168772273801		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.3176168772273801 | validation: 0.3272934054609793]
	TIME [epoch: 11.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6069410560034036		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.6069410560034036 | validation: 0.35805516610606497]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.316131517101893		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.316131517101893 | validation: 0.2664807939427398]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33308598355087077		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.33308598355087077 | validation: 0.3363756541795227]
	TIME [epoch: 11.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30008943185349124		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.30008943185349124 | validation: 0.2884109147101723]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2956441515837101		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.2956441515837101 | validation: 0.2892630296448241]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3688999796378154		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.3688999796378154 | validation: 0.6281436283115617]
	TIME [epoch: 11.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4822554380181707		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.4822554380181707 | validation: 0.27389900903765707]
	TIME [epoch: 11.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24698298163275045		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.24698298163275045 | validation: 0.6285238105445511]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34883324760950923		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.34883324760950923 | validation: 0.29853554282552613]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3315421100818924		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.3315421100818924 | validation: 0.35194646882593034]
	TIME [epoch: 11.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3121255318176293		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.3121255318176293 | validation: 0.26026074661259585]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3988339802890487		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.3988339802890487 | validation: 0.32245691354267975]
	TIME [epoch: 11.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30107577162195726		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.30107577162195726 | validation: 0.27495657537141754]
	TIME [epoch: 11.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2699699011597247		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.2699699011597247 | validation: 0.3285802016634413]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2507841262386492		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.2507841262386492 | validation: 0.2990145750034546]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.407614378706325		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.407614378706325 | validation: 0.34452241380728793]
	TIME [epoch: 11.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2976541819068994		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.2976541819068994 | validation: 0.3470634167257559]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33835876839775403		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.33835876839775403 | validation: 0.31383339410653044]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3182857899021253		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.3182857899021253 | validation: 0.7403522192275875]
	TIME [epoch: 11.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4909775969938575		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.4909775969938575 | validation: 0.3398673748283167]
	TIME [epoch: 11.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802477671011653		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.2802477671011653 | validation: 0.3042666088583968]
	TIME [epoch: 11.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3526849195536414		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.3526849195536414 | validation: 0.25361225628680384]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.293767039132629		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.293767039132629 | validation: 0.535932129266789]
	TIME [epoch: 11.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508274060506704		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.3508274060506704 | validation: 0.32764199229485064]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2974737118763734		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.2974737118763734 | validation: 0.2507829354012929]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_276.pth
	Model improved!!!
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3121258168383743		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.3121258168383743 | validation: 0.4368909494921641]
	TIME [epoch: 11.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3362896983187903		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.3362896983187903 | validation: 0.26323637912516357]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3011638886728838		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.3011638886728838 | validation: 0.2413992650802318]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_279.pth
	Model improved!!!
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2713230823014806		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.2713230823014806 | validation: 0.24732816550480635]
	TIME [epoch: 11.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2635608956326311		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.2635608956326311 | validation: 0.3141142493895437]
	TIME [epoch: 11.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2968215524941593		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.2968215524941593 | validation: 0.3143986623697305]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2525872175587864		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.2525872175587864 | validation: 0.21314664630682234]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_283.pth
	Model improved!!!
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2596330299614147		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.2596330299614147 | validation: 0.2505504904525951]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2822523425243831		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.2822523425243831 | validation: 0.30656370279287987]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2985673826638995		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.2985673826638995 | validation: 0.2737925979173378]
	TIME [epoch: 11.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2591193647630853		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.2591193647630853 | validation: 0.2820712249339944]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25443848653744017		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.25443848653744017 | validation: 0.24513581159890221]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2863426749639721		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.2863426749639721 | validation: 0.2828335518938259]
	TIME [epoch: 11.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3007811292661149		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.3007811292661149 | validation: 0.275825670526018]
	TIME [epoch: 11.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23980571266799006		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.23980571266799006 | validation: 0.309236431711237]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34537120831081086		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.34537120831081086 | validation: 0.4308428889816061]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2821139962784907		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.2821139962784907 | validation: 0.2771422753819949]
	TIME [epoch: 11.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853243441722844		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.2853243441722844 | validation: 0.24010406079675467]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24795577135576344		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.24795577135576344 | validation: 0.23428964375921887]
	TIME [epoch: 11.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29193312223682505		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.29193312223682505 | validation: 0.33851696419522387]
	TIME [epoch: 11.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30461725780229093		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.30461725780229093 | validation: 0.2962707680530095]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26711233380939		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.26711233380939 | validation: 0.3005905755886109]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23448533216326783		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.23448533216326783 | validation: 0.2133155050654392]
	TIME [epoch: 11.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2521196242276074		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.2521196242276074 | validation: 0.23398057372273343]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2215806151935609		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.2215806151935609 | validation: 0.3088721944526169]
	TIME [epoch: 11.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2499612824370346		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.2499612824370346 | validation: 0.22141987890831252]
	TIME [epoch: 11.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2640812259166995		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.2640812259166995 | validation: 0.24637863580962463]
	TIME [epoch: 11.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2616274018576061		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.2616274018576061 | validation: 0.283101396905939]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2564134539426309		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.2564134539426309 | validation: 0.30506728752350726]
	TIME [epoch: 11.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2662363953427461		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.2662363953427461 | validation: 0.3330551566185966]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3259418608480711		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.3259418608480711 | validation: 0.26509096500966317]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24940066060178062		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.24940066060178062 | validation: 0.2964389392386928]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30206336262976674		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.30206336262976674 | validation: 0.3720205762391913]
	TIME [epoch: 11.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26183541557171963		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.26183541557171963 | validation: 0.38244922234514717]
	TIME [epoch: 11.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32027021381227466		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.32027021381227466 | validation: 0.2359922092748918]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24788275234769724		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.24788275234769724 | validation: 0.31007297077846796]
	TIME [epoch: 11.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24540109674810406		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.24540109674810406 | validation: 0.35573690077510295]
	TIME [epoch: 11.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.309334283043374		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.309334283043374 | validation: 0.2781378673334868]
	TIME [epoch: 11.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755003887442362		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.2755003887442362 | validation: 0.19672292273107267]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24143240694549206		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.24143240694549206 | validation: 0.24146276346509468]
	TIME [epoch: 11.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26973372382075245		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.26973372382075245 | validation: 0.23182399381272475]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3820201741528812		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.3820201741528812 | validation: 0.2946004685634076]
	TIME [epoch: 11.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24136929188516842		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.24136929188516842 | validation: 0.2503691392328412]
	TIME [epoch: 11.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24964441269123328		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.24964441269123328 | validation: 0.20514832925665447]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28667986853445615		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.28667986853445615 | validation: 0.20327578958705012]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21463583183697948		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.21463583183697948 | validation: 0.32938072709152333]
	TIME [epoch: 11.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25117055195348204		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.25117055195348204 | validation: 0.24492412606704364]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2543916133865409		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.2543916133865409 | validation: 0.24067646637863696]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3022670573304176		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.3022670573304176 | validation: 0.2401148499089983]
	TIME [epoch: 11.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24350465381629943		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.24350465381629943 | validation: 0.38472280185193575]
	TIME [epoch: 11.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3363794349007356		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.3363794349007356 | validation: 0.22505863234471535]
	TIME [epoch: 11.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2996271710494609		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.2996271710494609 | validation: 0.22229668829657911]
	TIME [epoch: 11.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23303497100797943		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.23303497100797943 | validation: 0.38217325634715366]
	TIME [epoch: 11.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29476521814957124		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.29476521814957124 | validation: 0.293452909195443]
	TIME [epoch: 11.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2741761329833763		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.2741761329833763 | validation: 0.21075727677864925]
	TIME [epoch: 11.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3044480790253288		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.3044480790253288 | validation: 0.41178798792806254]
	TIME [epoch: 11.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25527954232377126		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.25527954232377126 | validation: 0.3266259895664753]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28388762047442545		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.28388762047442545 | validation: 0.21874881998822848]
	TIME [epoch: 11.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2368108133836036		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.2368108133836036 | validation: 0.4661532942851413]
	TIME [epoch: 11.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30443297159309674		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.30443297159309674 | validation: 0.3367733030083025]
	TIME [epoch: 11.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2466600718810572		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.2466600718810572 | validation: 0.388641363483967]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3421054625151875		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.3421054625151875 | validation: 0.20758769195685708]
	TIME [epoch: 11.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22901678544194387		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.22901678544194387 | validation: 0.3153804605574506]
	TIME [epoch: 11.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3373254504874795		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.3373254504874795 | validation: 0.25136973692708253]
	TIME [epoch: 11.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2593835072513043		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.2593835072513043 | validation: 0.24082547910986024]
	TIME [epoch: 11.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25735362102447745		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.25735362102447745 | validation: 0.22274244785164185]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.321915252375526		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.321915252375526 | validation: 0.3630512790078893]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3378679277365957		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.3378679277365957 | validation: 0.28651572305844164]
	TIME [epoch: 11.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38523876620958314		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.38523876620958314 | validation: 0.27062888138340413]
	TIME [epoch: 11.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22032610989707133		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.22032610989707133 | validation: 0.3383979070904862]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27271241802082086		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.27271241802082086 | validation: 0.2630743071136232]
	TIME [epoch: 11.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2599572513931937		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.2599572513931937 | validation: 0.4052980802977858]
	TIME [epoch: 11.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34547162552404964		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.34547162552404964 | validation: 0.31261997508958755]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27667281235291585		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.27667281235291585 | validation: 0.49961605447958507]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5337672901656341		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.5337672901656341 | validation: 0.27964935330994517]
	TIME [epoch: 11.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3258279596098226		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.3258279596098226 | validation: 0.2300419409785139]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30011889068797687		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.30011889068797687 | validation: 0.32092511437697757]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2675564001619265		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.2675564001619265 | validation: 0.23481719723047348]
	TIME [epoch: 11.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2408727331036489		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.2408727331036489 | validation: 0.22127536961590585]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24208578035092354		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.24208578035092354 | validation: 0.19175913958188243]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_356.pth
	Model improved!!!
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20749381493181046		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.20749381493181046 | validation: 0.19245258926024442]
	TIME [epoch: 11.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21363306050797118		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.21363306050797118 | validation: 0.44532133912837923]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2761157949433968		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.2761157949433968 | validation: 0.25418887860391426]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20639197706274748		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.20639197706274748 | validation: 0.2416519041137598]
	TIME [epoch: 11.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24050676259167936		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.24050676259167936 | validation: 0.3118351248273818]
	TIME [epoch: 11.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2500963113927903		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.2500963113927903 | validation: 0.21198230655081937]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18930039063510246		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.18930039063510246 | validation: 0.20071231319596716]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2316963090146166		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.2316963090146166 | validation: 0.3772254506608635]
	TIME [epoch: 11.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3016758396694526		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.3016758396694526 | validation: 0.3009900480131642]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2581681313571021		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.2581681313571021 | validation: 0.1696190743913083]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19158983496089654		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.19158983496089654 | validation: 0.4479481397700843]
	TIME [epoch: 11.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33990155818278966		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.33990155818278966 | validation: 0.24460472467279779]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2278359597839913		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.2278359597839913 | validation: 0.23434719796518239]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21782557549896564		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.21782557549896564 | validation: 0.26356910950828644]
	TIME [epoch: 11.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2750019144594146		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.2750019144594146 | validation: 0.2509573927580423]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510614900583101		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.2510614900583101 | validation: 0.25850435000292543]
	TIME [epoch: 11.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2197862248191571		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.2197862248191571 | validation: 0.18304485697928513]
	TIME [epoch: 11.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17638661676124168		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.17638661676124168 | validation: 0.22126534169672382]
	TIME [epoch: 11.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2025386923238562		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.2025386923238562 | validation: 0.20360596262062877]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20870442582093737		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.20870442582093737 | validation: 0.2046826094047629]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24496589359978654		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.24496589359978654 | validation: 0.15619682550001016]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_377.pth
	Model improved!!!
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23171093963556685		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.23171093963556685 | validation: 0.3633678620758281]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24830402070472646		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.24830402070472646 | validation: 0.2121474995803679]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2587956955114055		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.2587956955114055 | validation: 0.15733676608693561]
	TIME [epoch: 11.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18444409922070587		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.18444409922070587 | validation: 0.22724500892178973]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21572732783793938		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.21572732783793938 | validation: 0.2823424561078428]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2208564752718576		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.2208564752718576 | validation: 0.16774326116143648]
	TIME [epoch: 11.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20440296969124866		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.20440296969124866 | validation: 0.3042534362681467]
	TIME [epoch: 11.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3099767881841887		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.3099767881841887 | validation: 0.5722366865492604]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4685806502309252		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.4685806502309252 | validation: 0.38683886569795106]
	TIME [epoch: 11.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25797528259988756		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.25797528259988756 | validation: 0.30101953598888104]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28371365953285105		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.28371365953285105 | validation: 0.25375042661386643]
	TIME [epoch: 11.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3006102457170679		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.3006102457170679 | validation: 0.5278087680777616]
	TIME [epoch: 11.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29338780660084457		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.29338780660084457 | validation: 0.1980290646091127]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20754216825434796		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.20754216825434796 | validation: 0.3068332263192878]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23558145364458608		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.23558145364458608 | validation: 0.24336770041370778]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2144642512296808		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.2144642512296808 | validation: 0.19553752389255522]
	TIME [epoch: 11.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24015445505971772		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.24015445505971772 | validation: 0.2340584701498861]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2712807688105905		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.2712807688105905 | validation: 0.37031983573599014]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24914522996201235		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.24914522996201235 | validation: 0.29473490028081367]
	TIME [epoch: 11.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27481847382314245		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.27481847382314245 | validation: 0.2352073018422778]
	TIME [epoch: 11.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27549711093333135		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.27549711093333135 | validation: 0.3331132586916911]
	TIME [epoch: 11.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23464538660600634		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.23464538660600634 | validation: 0.1852568114070685]
	TIME [epoch: 11.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2238860125636362		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.2238860125636362 | validation: 0.14808137834814133]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16996772561581194		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.16996772561581194 | validation: 0.17419583510430856]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24456458409959106		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.24456458409959106 | validation: 0.2070437374626119]
	TIME [epoch: 11.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18603413833760618		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.18603413833760618 | validation: 0.17551321920839974]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18009603700665835		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.18009603700665835 | validation: 0.1796150972281275]
	TIME [epoch: 11.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20253406675133284		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.20253406675133284 | validation: 0.2800666721369968]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2713324000043076		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.2713324000043076 | validation: 0.18359375175383558]
	TIME [epoch: 11.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1806381962552423		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.1806381962552423 | validation: 0.19472127567543487]
	TIME [epoch: 11.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16266068100616404		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.16266068100616404 | validation: 0.17475937089790897]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1611628444633602		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.1611628444633602 | validation: 0.18214351015302158]
	TIME [epoch: 11.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20389456597647676		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.20389456597647676 | validation: 0.44116856395732856]
	TIME [epoch: 11.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26050000827775704		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.26050000827775704 | validation: 0.16511661322180765]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17373516595189376		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.17373516595189376 | validation: 0.21459906316425892]
	TIME [epoch: 11.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21614337653579427		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.21614337653579427 | validation: 0.24652795133584865]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24724427218941758		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.24724427218941758 | validation: 0.2499410986684772]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22811675117866353		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.22811675117866353 | validation: 0.3574122338952895]
	TIME [epoch: 11.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2786707735046438		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.2786707735046438 | validation: 0.3666653995501011]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28845409713165115		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.28845409713165115 | validation: 0.20558536836934946]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2396536560486097		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.2396536560486097 | validation: 0.26938819221255406]
	TIME [epoch: 11.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3471535340357628		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.3471535340357628 | validation: 0.5494875777028488]
	TIME [epoch: 11.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3403726483240866		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.3403726483240866 | validation: 0.31166717548517175]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2765889632208945		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.2765889632208945 | validation: 0.30173074954026]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2658531726434946		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.2658531726434946 | validation: 0.3167601062323424]
	TIME [epoch: 11.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25382884524852933		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.25382884524852933 | validation: 0.21926578361826884]
	TIME [epoch: 11.5 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859726337899985		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.2859726337899985 | validation: 0.40489358238202]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2786588317711223		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.2786588317711223 | validation: 0.22251571650248522]
	TIME [epoch: 11.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3031653984281728		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.3031653984281728 | validation: 0.2913067419886119]
	TIME [epoch: 11.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21958477820331693		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.21958477820331693 | validation: 0.1826245325421949]
	TIME [epoch: 11.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18457605723885293		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.18457605723885293 | validation: 0.17997181862397602]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1789210952216605		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.1789210952216605 | validation: 0.18251197955692497]
	TIME [epoch: 11.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18804086005381587		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.18804086005381587 | validation: 0.252813248931764]
	TIME [epoch: 11.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20866544037253384		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.20866544037253384 | validation: 0.19629015086829896]
	TIME [epoch: 11.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22041749476347158		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.22041749476347158 | validation: 0.19033438004630104]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23520034922619093		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.23520034922619093 | validation: 0.18485057298260923]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1745081241629011		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.1745081241629011 | validation: 0.16100205753897484]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17671448549555585		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.17671448549555585 | validation: 0.24135874116225473]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22570994699286726		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.22570994699286726 | validation: 0.19942444263230166]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20320898152979022		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.20320898152979022 | validation: 0.2026690667135308]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31216843065522815		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.31216843065522815 | validation: 0.3624933803389632]
	TIME [epoch: 11.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29685481997357527		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.29685481997357527 | validation: 0.2684374353293388]
	TIME [epoch: 11.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22122061017978595		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.22122061017978595 | validation: 0.24680630229560016]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19859895551805135		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.19859895551805135 | validation: 0.17671786598770137]
	TIME [epoch: 11.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17260505762832296		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.17260505762832296 | validation: 0.20262297914412045]
	TIME [epoch: 11.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24320471535972857		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.24320471535972857 | validation: 0.21483153398092938]
	TIME [epoch: 11.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18797476177579744		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.18797476177579744 | validation: 0.17556422819631784]
	TIME [epoch: 11.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15837874897912607		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.15837874897912607 | validation: 0.1870847097155774]
	TIME [epoch: 11.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2147399291966362		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.2147399291966362 | validation: 0.18533995705960535]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18446256941634018		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.18446256941634018 | validation: 0.16861068112063257]
	TIME [epoch: 11.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18450412269031147		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.18450412269031147 | validation: 0.16765499463209887]
	TIME [epoch: 11.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654056066587108		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.1654056066587108 | validation: 0.16525009955085365]
	TIME [epoch: 11.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1987989859078187		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.1987989859078187 | validation: 0.22447371227514254]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21729021322275732		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.21729021322275732 | validation: 0.2008513931845787]
	TIME [epoch: 11.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1871884404565216		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.1871884404565216 | validation: 0.210423923126279]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18968611993080975		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.18968611993080975 | validation: 0.17920223436596275]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590080277111956		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.1590080277111956 | validation: 0.2537840847114737]
	TIME [epoch: 11.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19012770925562797		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.19012770925562797 | validation: 0.18662039556161936]
	TIME [epoch: 11.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838042515996932		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.1838042515996932 | validation: 0.1835592750325353]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16772501238281728		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.16772501238281728 | validation: 0.1944981674311454]
	TIME [epoch: 11.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19089608921839007		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.19089608921839007 | validation: 0.1779910214125149]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2728394998254803		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.2728394998254803 | validation: 0.16180498824845138]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1583698555096032		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.1583698555096032 | validation: 0.1789853176324013]
	TIME [epoch: 11.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16871631640812768		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.16871631640812768 | validation: 0.32880632013324146]
	TIME [epoch: 11.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23401630782976082		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.23401630782976082 | validation: 0.2442518644825374]
	TIME [epoch: 11.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25533554984232826		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.25533554984232826 | validation: 0.15761266427876977]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15924468801697172		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.15924468801697172 | validation: 0.23353351213851575]
	TIME [epoch: 11.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21352759197557314		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.21352759197557314 | validation: 0.2530269399228836]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2665477096473015		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.2665477096473015 | validation: 0.21510390639361796]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31217290834014016		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.31217290834014016 | validation: 0.5384432678255134]
	TIME [epoch: 11.6 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8032216304264466		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.8032216304264466 | validation: 0.3811684852470896]
	TIME [epoch: 11.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2839443940949975		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.2839443940949975 | validation: 0.3477579781220917]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32660428166282635		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.32660428166282635 | validation: 0.2028394247249925]
	TIME [epoch: 11.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1830710329922423		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.1830710329922423 | validation: 0.18557193544158196]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24359733333181202		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.24359733333181202 | validation: 0.31964931388465706]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21055398235290046		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.21055398235290046 | validation: 0.19517293122084323]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20143807211019088		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.20143807211019088 | validation: 0.16838921431758144]
	TIME [epoch: 11.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16050617430428932		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.16050617430428932 | validation: 0.2101884439290587]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2130139447575424		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.2130139447575424 | validation: 0.3172675066721981]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22274487045561714		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.22274487045561714 | validation: 0.18722171584420882]
	TIME [epoch: 11.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17313018401114064		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.17313018401114064 | validation: 0.2755039062773515]
	TIME [epoch: 11.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27744350792979083		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.27744350792979083 | validation: 0.23259292257091374]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21838356990492652		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.21838356990492652 | validation: 0.15664278324845332]
	TIME [epoch: 11.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1568090886826144		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.1568090886826144 | validation: 0.36283845645777085]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22444791464229866		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.22444791464229866 | validation: 0.18385811968692434]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17853090626773355		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.17853090626773355 | validation: 0.23267841390343014]
	TIME [epoch: 11.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21501120567812684		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.21501120567812684 | validation: 0.1856899210324248]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20850215258340082		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.20850215258340082 | validation: 0.16878186998017417]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26296844811959996		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.26296844811959996 | validation: 0.6086745783758643]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4464500800099727		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.4464500800099727 | validation: 0.19484424287943292]
	TIME [epoch: 11.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.305029422851501		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.305029422851501 | validation: 0.33638825219763013]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20929427139524526		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.20929427139524526 | validation: 0.15249801884579178]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15479184907715954		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.15479184907715954 | validation: 0.14642485924000584]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_490.pth
	Model improved!!!
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630805149819811		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.1630805149819811 | validation: 0.16552750485885306]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17451737036858483		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.17451737036858483 | validation: 0.1904515548401273]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2773876124383079		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.2773876124383079 | validation: 0.3378517142406818]
	TIME [epoch: 11.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24793319753335044		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.24793319753335044 | validation: 0.15221369271575655]
	TIME [epoch: 11.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20229095447475212		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.20229095447475212 | validation: 0.2253036480966521]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1819816682297171		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.1819816682297171 | validation: 0.16432096720161352]
	TIME [epoch: 11.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14766099738353144		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.14766099738353144 | validation: 0.21864927270065615]
	TIME [epoch: 11.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16432570888719883		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.16432570888719883 | validation: 0.14154060908301855]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_498.pth
	Model improved!!!
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1360891698619296		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.1360891698619296 | validation: 0.14466999190223223]
	TIME [epoch: 11.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15199269910949542		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.15199269910949542 | validation: 0.1893925272677219]
	TIME [epoch: 11.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17480357614732292		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.17480357614732292 | validation: 0.15185057380872694]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14852818823000785		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.14852818823000785 | validation: 0.16416485172386786]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19409004572840793		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.19409004572840793 | validation: 0.2527228673031446]
	TIME [epoch: 11.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18039233001996516		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.18039233001996516 | validation: 0.14469255562536315]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726714914240214		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.1726714914240214 | validation: 0.186794695350063]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3025759392942731		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.3025759392942731 | validation: 0.4732947458589403]
	TIME [epoch: 11.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3348936313037538		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.3348936313037538 | validation: 0.18344607254310533]
	TIME [epoch: 11.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18167506515239373		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.18167506515239373 | validation: 0.2650931903175784]
	TIME [epoch: 11.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2111191605168834		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.2111191605168834 | validation: 0.1909188127880471]
	TIME [epoch: 11.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17440838414799		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.17440838414799 | validation: 0.1564686783862695]
	TIME [epoch: 11.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13613718164398406		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.13613718164398406 | validation: 0.1614441937747346]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15251496028803008		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.15251496028803008 | validation: 0.20911521369865813]
	TIME [epoch: 11.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1884286217127774		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.1884286217127774 | validation: 0.16451773158440877]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14913445971227168		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.14913445971227168 | validation: 0.1980235268113109]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17434070230589213		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.17434070230589213 | validation: 0.159700938817592]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1986861620369109		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.1986861620369109 | validation: 0.21256717185408075]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17877668652559364		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.17877668652559364 | validation: 0.1545350911944059]
	TIME [epoch: 11.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14506459373599392		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.14506459373599392 | validation: 0.13029611418145653]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_518.pth
	Model improved!!!
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327908078749904		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.1327908078749904 | validation: 0.11927122704813371]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_519.pth
	Model improved!!!
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1874426384897655		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.1874426384897655 | validation: 0.15574532566529473]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14054997685443832		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.14054997685443832 | validation: 0.2253642940851315]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17404633809886555		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.17404633809886555 | validation: 0.1364351969102927]
	TIME [epoch: 11.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15554399998721447		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.15554399998721447 | validation: 0.1700474694248433]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15072584230712818		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.15072584230712818 | validation: 0.20368533171174885]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3677531129286187		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.3677531129286187 | validation: 0.19419540972514548]
	TIME [epoch: 11.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15990825798288644		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.15990825798288644 | validation: 0.213591055415693]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1715909756592855		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.1715909756592855 | validation: 0.11834443623432023]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13359017279122679		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.13359017279122679 | validation: 0.12100905979277723]
	TIME [epoch: 11.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19031252182033803		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.19031252182033803 | validation: 0.2738401641428839]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17997828212775033		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.17997828212775033 | validation: 0.15233082049514618]
	TIME [epoch: 11.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14512141104124504		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.14512141104124504 | validation: 0.1548901555864999]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1412427997302784		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.1412427997302784 | validation: 0.13189605753074315]
	TIME [epoch: 11.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12274137256369846		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.12274137256369846 | validation: 0.12832517306993202]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13788056397954354		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.13788056397954354 | validation: 0.26253351978077893]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24156719464012147		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.24156719464012147 | validation: 0.17145039181854402]
	TIME [epoch: 11.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13971556364260831		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.13971556364260831 | validation: 0.13435807212507533]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15146065639295075		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.15146065639295075 | validation: 0.20721051704374546]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16361424942797714		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.16361424942797714 | validation: 0.15569593987105906]
	TIME [epoch: 11.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518069937750467		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.1518069937750467 | validation: 0.16371641731021755]
	TIME [epoch: 11.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16104094917677866		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.16104094917677866 | validation: 0.3674734604115274]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739516670766374		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.2739516670766374 | validation: 0.23827039351848933]
	TIME [epoch: 11.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2469916085200991		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.2469916085200991 | validation: 0.32055386444282447]
	TIME [epoch: 11.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27565324931528584		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.27565324931528584 | validation: 0.32660922407156906]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24197976332198415		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.24197976332198415 | validation: 0.16345341580579129]
	TIME [epoch: 11.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18009404015028968		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.18009404015028968 | validation: 0.15817176676903785]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14958465879723876		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.14958465879723876 | validation: 0.1508079924624969]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12937468351339865		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.12937468351339865 | validation: 0.1309098736556208]
	TIME [epoch: 11.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17107161486233383		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.17107161486233383 | validation: 0.17233975986400768]
	TIME [epoch: 11.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16479572353903438		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.16479572353903438 | validation: 0.18847599475079313]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19935610974748447		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.19935610974748447 | validation: 0.16194087100314494]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17003551188255978		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.17003551188255978 | validation: 0.19654040821858815]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15916456180200872		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.15916456180200872 | validation: 0.1522498687656749]
	TIME [epoch: 11.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17257224435326307		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.17257224435326307 | validation: 0.14166397249121152]
	TIME [epoch: 11.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15730213882848443		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.15730213882848443 | validation: 0.14293231414926752]
	TIME [epoch: 11.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16391211642548487		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.16391211642548487 | validation: 0.20235336521917988]
	TIME [epoch: 11.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15318890224536744		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.15318890224536744 | validation: 0.14846727020907174]
	TIME [epoch: 11.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2919262249943546		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.2919262249943546 | validation: 0.749528342651868]
	TIME [epoch: 11.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41035770916414394		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.41035770916414394 | validation: 0.17100494009655706]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14719187249579735		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.14719187249579735 | validation: 0.15845899334590666]
	TIME [epoch: 11.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1523494416153338		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1523494416153338 | validation: 0.1921815712939813]
	TIME [epoch: 11.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15605455435002058		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.15605455435002058 | validation: 0.1469185249929197]
	TIME [epoch: 11.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13435100405041403		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.13435100405041403 | validation: 0.13577232839240394]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12451108182436524		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.12451108182436524 | validation: 0.13361675950493257]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15138183929094423		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.15138183929094423 | validation: 0.14692401758261162]
	TIME [epoch: 11.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1547164026406205		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.1547164026406205 | validation: 0.1228914027574844]
	TIME [epoch: 11.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13003361540689684		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.13003361540689684 | validation: 0.12470908964749393]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329757277423969		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.1329757277423969 | validation: 0.1347641777308899]
	TIME [epoch: 11.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14749985891456793		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.14749985891456793 | validation: 0.12698234154615226]
	TIME [epoch: 11.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16428261643292724		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.16428261643292724 | validation: 0.2523145537756045]
	TIME [epoch: 11.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17092792346505203		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.17092792346505203 | validation: 0.12045908210155368]
	TIME [epoch: 11.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13596405417939617		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.13596405417939617 | validation: 0.14939069740639732]
	TIME [epoch: 11.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1658785177721488		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.1658785177721488 | validation: 0.18691181431613174]
	TIME [epoch: 11.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14000297518480673		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.14000297518480673 | validation: 0.11894234931930903]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13891899697401736		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.13891899697401736 | validation: 0.12428288223349063]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13427309183202327		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.13427309183202327 | validation: 0.22786334772521993]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18628115140757867		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.18628115140757867 | validation: 0.16396319427258965]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1493181725059132		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.1493181725059132 | validation: 0.14285400974035514]
	TIME [epoch: 11.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14026487715694366		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.14026487715694366 | validation: 0.1472854730591671]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14110189159539524		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.14110189159539524 | validation: 0.14179994463935283]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12808345901898294		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.12808345901898294 | validation: 0.13927245372810626]
	TIME [epoch: 11.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13075532003779203		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.13075532003779203 | validation: 0.14466507493749084]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13803466697918992		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.13803466697918992 | validation: 0.2554266500676444]
	TIME [epoch: 11.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17131880168042102		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.17131880168042102 | validation: 0.16905641281028683]
	TIME [epoch: 11.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566284668639398		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.1566284668639398 | validation: 0.167222172877163]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.212063823982646		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.212063823982646 | validation: 0.134943589918594]
	TIME [epoch: 11.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14762572895089604		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.14762572895089604 | validation: 0.13718930421928835]
	TIME [epoch: 11.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19588977891932097		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.19588977891932097 | validation: 0.35174793724545794]
	TIME [epoch: 11.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39477434315757487		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.39477434315757487 | validation: 0.32187117365796875]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2996480641315601		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.2996480641315601 | validation: 0.24154295234283443]
	TIME [epoch: 11.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21228534967005314		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.21228534967005314 | validation: 0.18362687790550505]
	TIME [epoch: 11.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19468143066185384		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.19468143066185384 | validation: 0.2627918512348958]
	TIME [epoch: 11.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20115850285552397		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.20115850285552397 | validation: 0.15717701924380842]
	TIME [epoch: 11.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1599145938215274		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.1599145938215274 | validation: 0.12964847540403254]
	TIME [epoch: 11.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1507865112477927		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.1507865112477927 | validation: 0.14407126813008467]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16271131541488548		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.16271131541488548 | validation: 0.14299368128206902]
	TIME [epoch: 11.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14154070372739933		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.14154070372739933 | validation: 0.23867407816787592]
	TIME [epoch: 11.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28415965411598165		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.28415965411598165 | validation: 0.20323029184594277]
	TIME [epoch: 11.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1703829506880815		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.1703829506880815 | validation: 0.1654287942098717]
	TIME [epoch: 11.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16168619477955154		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.16168619477955154 | validation: 0.15365288546482353]
	TIME [epoch: 11.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1625481036008488		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.1625481036008488 | validation: 0.18713312004986984]
	TIME [epoch: 11.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19540960445735564		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.19540960445735564 | validation: 0.1584654991135764]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418799434406543		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.1418799434406543 | validation: 0.1613334930921495]
	TIME [epoch: 11.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18552396713128502		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.18552396713128502 | validation: 0.25097562160695996]
	TIME [epoch: 11.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2002651212334613		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.2002651212334613 | validation: 0.2487824379832815]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24585909294639335		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.24585909294639335 | validation: 0.3493719110815964]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2845753817945233		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.2845753817945233 | validation: 0.29291034435548496]
	TIME [epoch: 11.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20203135777713102		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.20203135777713102 | validation: 0.26614193318060275]
	TIME [epoch: 11.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22593644251741513		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.22593644251741513 | validation: 0.18227307694843042]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15484069602596356		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.15484069602596356 | validation: 0.18650051523431174]
	TIME [epoch: 11.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17372440656474958		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.17372440656474958 | validation: 0.24917319167631846]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20586224690455612		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.20586224690455612 | validation: 0.14004361250200645]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15085561716159776		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.15085561716159776 | validation: 0.16894173005111174]
	TIME [epoch: 11.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13564183902550653		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.13564183902550653 | validation: 0.18546913196832737]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20586847130476715		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.20586847130476715 | validation: 0.17602035211496667]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1729238240846575		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.1729238240846575 | validation: 0.14567777139549842]
	TIME [epoch: 11.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14430848935879942		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.14430848935879942 | validation: 0.20087285866819668]
	TIME [epoch: 11.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16662968076790635		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.16662968076790635 | validation: 0.14129991507767523]
	TIME [epoch: 11.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452601770247177		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.1452601770247177 | validation: 0.280782278215169]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3092761561060598		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.3092761561060598 | validation: 0.25348998389302396]
	TIME [epoch: 11.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16818754007329298		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.16818754007329298 | validation: 0.1208656960010798]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12669926264308853		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.12669926264308853 | validation: 0.18327268839530894]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16766091818126197		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.16766091818126197 | validation: 0.12193300934411752]
	TIME [epoch: 11.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18230366884629504		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.18230366884629504 | validation: 0.27055719285966595]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254334791396327		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.254334791396327 | validation: 0.16060561883413854]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16494069099665445		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.16494069099665445 | validation: 0.14774434369660114]
	TIME [epoch: 11.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1241225835396092		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.1241225835396092 | validation: 0.19754411781141826]
	TIME [epoch: 11.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34962974131293667		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.34962974131293667 | validation: 0.3352572586179823]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22230523114674308		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.22230523114674308 | validation: 0.1785282989252645]
	TIME [epoch: 11.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1841707752961139		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.1841707752961139 | validation: 0.14479219992811587]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13409332849077515		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.13409332849077515 | validation: 0.12008211798949785]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13807418289194986		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.13807418289194986 | validation: 0.13054711149709042]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11699819950057938		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.11699819950057938 | validation: 0.1281612818754792]
	TIME [epoch: 11.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11741663523781998		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.11741663523781998 | validation: 0.13398612131293242]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14468650875898414		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.14468650875898414 | validation: 0.20253090805531188]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1640182768032236		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.1640182768032236 | validation: 0.14065085060685037]
	TIME [epoch: 11.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11737750437769642		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.11737750437769642 | validation: 0.18504519294380053]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16154771209150035		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.16154771209150035 | validation: 0.14282869196164494]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14013873031492702		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.14013873031492702 | validation: 0.1343867126252412]
	TIME [epoch: 11.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11962106908295703		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.11962106908295703 | validation: 0.12288976445964267]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11833159612474721		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.11833159612474721 | validation: 0.11335304669021365]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1079954479721242		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.1079954479721242 | validation: 0.1211936420206688]
	TIME [epoch: 11.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15652547010934012		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.15652547010934012 | validation: 0.22010160962202874]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20861803378121505		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.20861803378121505 | validation: 0.15901206439518273]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14783527971791738		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.14783527971791738 | validation: 0.13715582228878706]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441879373516331		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.1441879373516331 | validation: 0.27000120564708363]
	TIME [epoch: 11.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24305002678689974		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.24305002678689974 | validation: 0.1671471251243508]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12749096819427042		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.12749096819427042 | validation: 0.1381084556638096]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13670415491757607		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.13670415491757607 | validation: 0.1365828412054387]
	TIME [epoch: 11.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11200793817916321		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.11200793817916321 | validation: 0.10148284523880186]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_649.pth
	Model improved!!!
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12083843658771243		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.12083843658771243 | validation: 0.12675311917890997]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15954265226754247		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.15954265226754247 | validation: 0.1483948381791918]
	TIME [epoch: 11.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1490585539768799		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.1490585539768799 | validation: 0.178725002499353]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558009533054554		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.2558009533054554 | validation: 0.20690739797680485]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391677141825071		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.1391677141825071 | validation: 0.11084064138254761]
	TIME [epoch: 11.6 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11366241335528873		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.11366241335528873 | validation: 0.1122015929581498]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1574608419341726		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.1574608419341726 | validation: 0.22647117709020123]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17968787054782506		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.17968787054782506 | validation: 0.1409302239179028]
	TIME [epoch: 11.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12892267277989544		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.12892267277989544 | validation: 0.16885776284677328]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16362793439497492		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.16362793439497492 | validation: 0.1529521748763839]
	TIME [epoch: 11.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13913610242327987		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.13913610242327987 | validation: 0.10947695029626481]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12459883037349787		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.12459883037349787 | validation: 0.14079861465189328]
	TIME [epoch: 11.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12287727529061937		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.12287727529061937 | validation: 0.10578479719900599]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10623405854511694		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.10623405854511694 | validation: 0.14478309623796276]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17483047347214992		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.17483047347214992 | validation: 0.26402584027030507]
	TIME [epoch: 11.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18679835493876315		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.18679835493876315 | validation: 0.14771236461262113]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17528074177763486		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.17528074177763486 | validation: 0.23222302486742294]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14931016971356834		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.14931016971356834 | validation: 0.11990521419837319]
	TIME [epoch: 11.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18005934213262195		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.18005934213262195 | validation: 0.13304589846121778]
	TIME [epoch: 11.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15016832744357045		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.15016832744357045 | validation: 0.1857870314018176]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18795487156246707		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.18795487156246707 | validation: 0.19007494121536256]
	TIME [epoch: 11.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1352730852699831		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.1352730852699831 | validation: 0.17124859290073308]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15038310026476126		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.15038310026476126 | validation: 0.12817781778239687]
	TIME [epoch: 11.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128815049783428		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.128815049783428 | validation: 0.16567268299664137]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15323399830532444		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.15323399830532444 | validation: 0.15910361951252255]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586886542077272		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.1586886542077272 | validation: 0.17283424661439944]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14891230767432903		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.14891230767432903 | validation: 0.12991895684640384]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16396569456454674		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.16396569456454674 | validation: 0.18537056769258953]
	TIME [epoch: 11.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1306247165908624		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.1306247165908624 | validation: 0.10316085636695661]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15123747458831716		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.15123747458831716 | validation: 0.22602181722228337]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654339751456261		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.1654339751456261 | validation: 0.15297142625425517]
	TIME [epoch: 11.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15729660216247054		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.15729660216247054 | validation: 0.15755829362895737]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1500636652784478		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.1500636652784478 | validation: 0.12203009860267008]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12624877901702966		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.12624877901702966 | validation: 0.11971434763024569]
	TIME [epoch: 11.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1553382480133883		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.1553382480133883 | validation: 0.14656599569442574]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.145100514449424		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.145100514449424 | validation: 0.12150353762291857]
	TIME [epoch: 11.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11356251227166178		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.11356251227166178 | validation: 0.1091834063405131]
	TIME [epoch: 11.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10997033525892293		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.10997033525892293 | validation: 0.0986738756326517]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_687.pth
	Model improved!!!
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10629907655597275		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.10629907655597275 | validation: 0.09978426772750983]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10985479088321504		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.10985479088321504 | validation: 0.11473270856338694]
	TIME [epoch: 11.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10353251184903538		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.10353251184903538 | validation: 0.105932826275815]
	TIME [epoch: 11.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1213911264026054		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.1213911264026054 | validation: 0.18045810853472774]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14301561551821845		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.14301561551821845 | validation: 0.10804580147668233]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1054913646678208		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.1054913646678208 | validation: 0.10627542020074987]
	TIME [epoch: 11.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11044805904350759		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.11044805904350759 | validation: 0.10500673948491068]
	TIME [epoch: 11.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12730222178121375		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.12730222178121375 | validation: 0.1677327149061839]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19506006875906068		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.19506006875906068 | validation: 0.17892805700384862]
	TIME [epoch: 11.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15178715536717058		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.15178715536717058 | validation: 0.15526619284455068]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281356383405038		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.1281356383405038 | validation: 0.11042869086399054]
	TIME [epoch: 11.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10104776438615025		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.10104776438615025 | validation: 0.08814656121290718]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_699.pth
	Model improved!!!
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13347823127007805		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.13347823127007805 | validation: 0.16196722981332318]
	TIME [epoch: 11.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11838980178638883		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.11838980178638883 | validation: 0.10210628337850375]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09935679527225426		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.09935679527225426 | validation: 0.08637406379466064]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_702.pth
	Model improved!!!
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09160374594373225		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.09160374594373225 | validation: 0.16708297791570012]
	TIME [epoch: 11.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11615474221364791		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.11615474221364791 | validation: 0.10968437492927852]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11898806821004543		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.11898806821004543 | validation: 0.14527646049289192]
	TIME [epoch: 11.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13900483439748001		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.13900483439748001 | validation: 0.11488068472972987]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10847215136460002		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.10847215136460002 | validation: 0.11468531533268816]
	TIME [epoch: 11.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.109397592792258		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.109397592792258 | validation: 0.11074767408977715]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10411701626715553		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.10411701626715553 | validation: 0.11336100033712593]
	TIME [epoch: 11.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12155536616628512		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.12155536616628512 | validation: 0.10884581563761284]
	TIME [epoch: 11.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09781312883653388		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.09781312883653388 | validation: 0.1151994970337584]
	TIME [epoch: 11.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14579729652699389		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.14579729652699389 | validation: 0.14986531275900516]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13221486729417867		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.13221486729417867 | validation: 0.12506898378485448]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1107708453744699		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.1107708453744699 | validation: 0.20945025625482125]
	TIME [epoch: 11.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15972048528847402		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.15972048528847402 | validation: 0.16245036396499343]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13764987434414838		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.13764987434414838 | validation: 0.09825368458005375]
	TIME [epoch: 11.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09082415677821097		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.09082415677821097 | validation: 0.08726385043291401]
	TIME [epoch: 11.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07986273316722106		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.07986273316722106 | validation: 0.09833857037687617]
	TIME [epoch: 11.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09699063305510736		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.09699063305510736 | validation: 0.09189641077760541]
	TIME [epoch: 11.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261724774655954		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.1261724774655954 | validation: 0.21212311164382705]
	TIME [epoch: 11.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14835853605884539		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.14835853605884539 | validation: 0.12326223529815071]
	TIME [epoch: 11.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10848876785998787		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.10848876785998787 | validation: 0.11492788733782047]
	TIME [epoch: 11.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10150668605628688		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.10150668605628688 | validation: 0.09798177989343473]
	TIME [epoch: 11.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09069188398754902		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.09069188398754902 | validation: 0.10849900177821895]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12286486465849665		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.12286486465849665 | validation: 0.11308338593343148]
	TIME [epoch: 11.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13991625542171643		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.13991625542171643 | validation: 0.14593782077383868]
	TIME [epoch: 11.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1195448833024643		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.1195448833024643 | validation: 0.08726844834154042]
	TIME [epoch: 11.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09148918618151482		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.09148918618151482 | validation: 0.09874700647351127]
	TIME [epoch: 11.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09482108428687895		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.09482108428687895 | validation: 0.14026823022504414]
	TIME [epoch: 11.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1230391858709098		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.1230391858709098 | validation: 0.16256545117455262]
	TIME [epoch: 11.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11859415476164809		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.11859415476164809 | validation: 0.10688307151712152]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09348346877724342		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.09348346877724342 | validation: 0.09386186725819835]
	TIME [epoch: 11.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08952488207546867		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.08952488207546867 | validation: 0.08386115784622707]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_733.pth
	Model improved!!!
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08196737226892545		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.08196737226892545 | validation: 0.08878140752017032]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09500127492937976		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.09500127492937976 | validation: 0.08740972805211064]
	TIME [epoch: 11.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10270869888399031		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.10270869888399031 | validation: 0.1053122575169593]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10796288165224142		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.10796288165224142 | validation: 0.12358749619022374]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1103993195969417		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.1103993195969417 | validation: 0.11024388121211111]
	TIME [epoch: 11.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08499036898019452		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.08499036898019452 | validation: 0.09459686159021705]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08765751800853953		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.08765751800853953 | validation: 0.101933553942037]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449233887906135		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.1449233887906135 | validation: 0.1641471686761447]
	TIME [epoch: 11.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13207066167370246		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.13207066167370246 | validation: 0.14494003091680852]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10326009132272877		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.10326009132272877 | validation: 0.09426693148914489]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08758256016108634		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.08758256016108634 | validation: 0.08529000334865444]
	TIME [epoch: 11.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08620078728533574		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.08620078728533574 | validation: 0.08521869424458084]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0921950791679869		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.0921950791679869 | validation: 0.10130640440925184]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08815931705466262		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.08815931705466262 | validation: 0.08925214841383167]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07675375743676584		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.07675375743676584 | validation: 0.08236393645876618]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_748.pth
	Model improved!!!
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08381991660476074		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.08381991660476074 | validation: 0.12708354296587365]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1144325920907653		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.1144325920907653 | validation: 0.09649078654561205]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09657295076225725		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.09657295076225725 | validation: 0.08310336963398929]
	TIME [epoch: 11.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08128202286011374		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.08128202286011374 | validation: 0.07619595430457235]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_752.pth
	Model improved!!!
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09417657587542916		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.09417657587542916 | validation: 0.09877587478140115]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08841090894868889		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.08841090894868889 | validation: 0.09389563442076679]
	TIME [epoch: 11.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10419793627695532		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.10419793627695532 | validation: 0.09220695998058075]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10337231960666204		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.10337231960666204 | validation: 0.10144518749138083]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09911979336534758		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.09911979336534758 | validation: 0.09220615376694292]
	TIME [epoch: 11.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0866055571809298		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.0866055571809298 | validation: 0.10459579000149431]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08570628683772996		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.08570628683772996 | validation: 0.09255767891134281]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08887290984261424		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.08887290984261424 | validation: 0.1057142662888404]
	TIME [epoch: 11.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10954489838934199		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.10954489838934199 | validation: 0.11298201241216393]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09197665278791209		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.09197665278791209 | validation: 0.12560051709922884]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0980775238926837		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.0980775238926837 | validation: 0.08274159214810546]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08973268723196813		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.08973268723196813 | validation: 0.09229934639477488]
	TIME [epoch: 11.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323206290458632		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.08323206290458632 | validation: 0.10028739695028574]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08949404456390161		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.08949404456390161 | validation: 0.11477405338498774]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12019596848236636		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.12019596848236636 | validation: 0.14510702935747172]
	TIME [epoch: 11.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10048110248216428		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.10048110248216428 | validation: 0.08684794772669094]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1054021072468152		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.1054021072468152 | validation: 0.19819780131225107]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12563209389587163		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.12563209389587163 | validation: 0.0926469868484914]
	TIME [epoch: 11.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08106920252876018		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.08106920252876018 | validation: 0.11471878040609834]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0964733492520349		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.0964733492520349 | validation: 0.10108831935534887]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17374174131381867		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.17374174131381867 | validation: 0.1855637443503506]
	TIME [epoch: 11.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13913967307967828		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.13913967307967828 | validation: 0.09025069546373331]
	TIME [epoch: 11.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09112916374325672		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.09112916374325672 | validation: 0.12369568307763658]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1196044222482581		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.1196044222482581 | validation: 0.08544263283885754]
	TIME [epoch: 11.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07909187825329066		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.07909187825329066 | validation: 0.07924975585120463]
	TIME [epoch: 11.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07438446133519916		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.07438446133519916 | validation: 0.08965331421189823]
	TIME [epoch: 11.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09033353461875988		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.09033353461875988 | validation: 0.09111158514776936]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0881899675504029		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.0881899675504029 | validation: 0.0983088278505586]
	TIME [epoch: 11.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11383290064811313		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.11383290064811313 | validation: 0.11631390185661841]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08964537194780267		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.08964537194780267 | validation: 0.09628117484283016]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10716149371560069		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.10716149371560069 | validation: 0.11738816767850073]
	TIME [epoch: 11.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167616359496039		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.10167616359496039 | validation: 0.11599402152133749]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09890627760159547		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.09890627760159547 | validation: 0.08278716295079146]
	TIME [epoch: 11.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09117535576922611		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.09117535576922611 | validation: 0.09794648615640383]
	TIME [epoch: 11.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07870736908443221		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.07870736908443221 | validation: 0.10289357009140698]
	TIME [epoch: 11.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10722987770980473		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.10722987770980473 | validation: 0.08687143694222453]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09569978385496958		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.09569978385496958 | validation: 0.12461495957444146]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09765095631580473		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.09765095631580473 | validation: 0.08280388133409362]
	TIME [epoch: 11.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10247619782718378		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.10247619782718378 | validation: 0.07959687080133111]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07738357368002007		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.07738357368002007 | validation: 0.09526832773876037]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0761251519361123		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.0761251519361123 | validation: 0.08622949151535085]
	TIME [epoch: 11.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1017444384014178		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.1017444384014178 | validation: 0.09777497579939212]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09719966300747447		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.09719966300747447 | validation: 0.10923775468294393]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09394729782627079		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.09394729782627079 | validation: 0.08232064836783595]
	TIME [epoch: 11.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07409013816987854		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.07409013816987854 | validation: 0.09207647696479834]
	TIME [epoch: 11.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09316567646997137		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.09316567646997137 | validation: 0.08277164598839427]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08555770497935541		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.08555770497935541 | validation: 0.10703600883265246]
	TIME [epoch: 11.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09323298800761698		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.09323298800761698 | validation: 0.10829025701551867]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09011190801364327		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.09011190801364327 | validation: 0.09191640006322331]
	TIME [epoch: 11.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0858085072802335		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.0858085072802335 | validation: 0.11105183904423002]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10344356116461362		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.10344356116461362 | validation: 0.11806737297956467]
	TIME [epoch: 11.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14794125872763372		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.14794125872763372 | validation: 0.14758283400686067]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14220587128870082		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.14220587128870082 | validation: 0.13371195292801233]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09752526648578191		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.09752526648578191 | validation: 0.11062575743625847]
	TIME [epoch: 11.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08404504304741606		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.08404504304741606 | validation: 0.09437824981006272]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08368380694933014		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.08368380694933014 | validation: 0.10927348501712417]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10203722706175772		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.10203722706175772 | validation: 0.12811477299749455]
	TIME [epoch: 11.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10014973319862475		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.10014973319862475 | validation: 0.1161892557151565]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09620384467733945		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.09620384467733945 | validation: 0.07526911878687925]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_811.pth
	Model improved!!!
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07500424321939386		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.07500424321939386 | validation: 0.10770584453358968]
	TIME [epoch: 11.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11785306251702402		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.11785306251702402 | validation: 0.11915376366680595]
	TIME [epoch: 11.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11536228533662514		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.11536228533662514 | validation: 0.1011679941595568]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08063845573382172		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.08063845573382172 | validation: 0.08576907570672092]
	TIME [epoch: 11.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10036985649743964		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.10036985649743964 | validation: 0.1123307711413008]
	TIME [epoch: 11.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.114790161386564		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.114790161386564 | validation: 0.09521394225652494]
	TIME [epoch: 11.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08023604875005216		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.08023604875005216 | validation: 0.09596258266410257]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09176808427537383		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.09176808427537383 | validation: 0.10092361477731852]
	TIME [epoch: 11.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07654692048845514		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.07654692048845514 | validation: 0.08397701973663375]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07648040105235707		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.07648040105235707 | validation: 0.09598371359995568]
	TIME [epoch: 11.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1143582700058833		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.1143582700058833 | validation: 0.07292165890297182]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_822.pth
	Model improved!!!
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07401350390914524		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.07401350390914524 | validation: 0.08381453099189894]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0691763348814335		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.0691763348814335 | validation: 0.07139044411467996]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_824.pth
	Model improved!!!
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0815680124780262		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.0815680124780262 | validation: 0.08027430399763442]
	TIME [epoch: 11.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08163169469240243		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.08163169469240243 | validation: 0.10316779300797495]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0816161655579711		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.0816161655579711 | validation: 0.0829942226692453]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08417888287050393		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.08417888287050393 | validation: 0.1120240434500942]
	TIME [epoch: 11.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09018904876545332		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.09018904876545332 | validation: 0.09390211637490885]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09001477433403582		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.09001477433403582 | validation: 0.1304548179770933]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11621926697284977		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.11621926697284977 | validation: 0.09327085485602701]
	TIME [epoch: 11.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09002907251337862		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.09002907251337862 | validation: 0.08234189915001328]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0864895151631319		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.0864895151631319 | validation: 0.08657318646127961]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07999296358276609		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.07999296358276609 | validation: 0.07755984363852156]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07811910744386061		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.07811910744386061 | validation: 0.06783282088789168]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_835.pth
	Model improved!!!
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07545802270594185		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.07545802270594185 | validation: 0.08142910215251119]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08431869081678493		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.08431869081678493 | validation: 0.09512261226692525]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11508141707950911		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.11508141707950911 | validation: 0.1654422220674886]
	TIME [epoch: 11.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14221938091398145		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.14221938091398145 | validation: 0.16930253186535082]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12337538570270834		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.12337538570270834 | validation: 0.11829898622289718]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11729692203210494		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.11729692203210494 | validation: 0.10206857435747167]
	TIME [epoch: 11.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11350166943846451		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.11350166943846451 | validation: 0.13425440805811487]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11322952741346527		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.11322952741346527 | validation: 0.08628850113231945]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07309990369744741		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.07309990369744741 | validation: 0.08071172251445016]
	TIME [epoch: 11.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07258521548302346		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.07258521548302346 | validation: 0.07738047545788945]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09574500026176917		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.09574500026176917 | validation: 0.11696399468838996]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08807422592774493		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.08807422592774493 | validation: 0.08683666872105925]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06958813284927469		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.06958813284927469 | validation: 0.0756472885159124]
	TIME [epoch: 11.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08009574525017218		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.08009574525017218 | validation: 0.08092641204839916]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09295303191458652		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.09295303191458652 | validation: 0.10738567864134801]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10647629029933031		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.10647629029933031 | validation: 0.1492400241786654]
	TIME [epoch: 11.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1145470665056928		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.1145470665056928 | validation: 0.10535583532776778]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08821985191075857		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.08821985191075857 | validation: 0.0766790668349685]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0777730878441572		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.0777730878441572 | validation: 0.08688103523435597]
	TIME [epoch: 11.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07624962003503297		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.07624962003503297 | validation: 0.0909702065958555]
	TIME [epoch: 11.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09040698040945425		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.09040698040945425 | validation: 0.08826622950523703]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07678599748852324		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.07678599748852324 | validation: 0.08082295436861493]
	TIME [epoch: 11.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07321768506061391		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.07321768506061391 | validation: 0.10328684227296522]
	TIME [epoch: 11.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11874269741438355		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.11874269741438355 | validation: 0.08302943843672714]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08318501870095969		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.08318501870095969 | validation: 0.07173300983982911]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06537323044680249		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.06537323044680249 | validation: 0.06826226925026552]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0750545250366286		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.0750545250366286 | validation: 0.06961852768695072]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07110376600607143		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.07110376600607143 | validation: 0.08661083406075402]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08441086898769348		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.08441086898769348 | validation: 0.0794978662839213]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08831021622446203		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.08831021622446203 | validation: 0.08985318368703812]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07803935652772695		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.07803935652772695 | validation: 0.07388019053314644]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06990148356441436		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.06990148356441436 | validation: 0.09796750735869583]
	TIME [epoch: 11.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08796326048723668		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.08796326048723668 | validation: 0.08496369519800234]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07339874798220059		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.07339874798220059 | validation: 0.087357826382292]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08676086074070952		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.08676086074070952 | validation: 0.10316531805786654]
	TIME [epoch: 11.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09201308350969342		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.09201308350969342 | validation: 0.09438172133170916]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0879896487489951		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.0879896487489951 | validation: 0.0809918056319551]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0679120836577074		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.0679120836577074 | validation: 0.07684415520071042]
	TIME [epoch: 11.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06862438522490588		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.06862438522490588 | validation: 0.07469773593767817]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06600924411298305		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.06600924411298305 | validation: 0.08259689248851046]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06939461432625035		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.06939461432625035 | validation: 0.060203516136347605]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_876.pth
	Model improved!!!
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07254590448114176		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.07254590448114176 | validation: 0.07896636701881249]
	TIME [epoch: 11.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0749376086302271		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.0749376086302271 | validation: 0.09570865644495301]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06925912959305743		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.06925912959305743 | validation: 0.06867596343481877]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07735605836522116		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.07735605836522116 | validation: 0.091858921317099]
	TIME [epoch: 11.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08513171516097605		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.08513171516097605 | validation: 0.08463780098252553]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08257215665208038		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.08257215665208038 | validation: 0.0929238357567117]
	TIME [epoch: 11.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07491834554513185		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.07491834554513185 | validation: 0.08107019908466141]
	TIME [epoch: 11.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07876203780041963		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.07876203780041963 | validation: 0.07170148564823739]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06207051693080343		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.06207051693080343 | validation: 0.08486257051834763]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08894252023448661		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.08894252023448661 | validation: 0.12690327157958564]
	TIME [epoch: 11.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13332114054711933		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.13332114054711933 | validation: 0.07771403556146388]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07798621525282484		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.07798621525282484 | validation: 0.09493199189513941]
	TIME [epoch: 11.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0987864778497614		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.0987864778497614 | validation: 0.0668753076154353]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07093502301307687		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.07093502301307687 | validation: 0.07039367482107417]
	TIME [epoch: 11.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06547375014045062		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.06547375014045062 | validation: 0.0838813858464546]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08046231152773942		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.08046231152773942 | validation: 0.07798308557421435]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07879589292861217		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.07879589292861217 | validation: 0.11415500654788638]
	TIME [epoch: 11.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09660309095084997		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.09660309095084997 | validation: 0.08711852064596352]
	TIME [epoch: 11.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07720192952329002		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.07720192952329002 | validation: 0.0744374590795657]
	TIME [epoch: 11.6 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07595990690559075		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.07595990690559075 | validation: 0.0980527088154512]
	TIME [epoch: 11.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07001986593780024		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.07001986593780024 | validation: 0.06143136631012218]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06415505063552662		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.06415505063552662 | validation: 0.07061105173927415]
	TIME [epoch: 11.6 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0654615893046694		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.0654615893046694 | validation: 0.0773759710510539]
	TIME [epoch: 11.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07952913866395701		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.07952913866395701 | validation: 0.08294337544931298]
	TIME [epoch: 11.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0885387496742087		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.0885387496742087 | validation: 0.10552528979913196]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243944500134935		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.08243944500134935 | validation: 0.08086472948690494]
	TIME [epoch: 11.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0849616626850227		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.0849616626850227 | validation: 0.11879611161923301]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09022578620181243		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.09022578620181243 | validation: 0.08449332579688018]
	TIME [epoch: 11.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10539929607639731		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.10539929607639731 | validation: 0.11078131621284594]
	TIME [epoch: 11.6 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10221466364500212		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.10221466364500212 | validation: 0.12360806044146046]
	TIME [epoch: 11.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12812155979363338		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.12812155979363338 | validation: 0.1822616890600918]
	TIME [epoch: 11.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1434352226479596		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.1434352226479596 | validation: 0.13220690445704658]
	TIME [epoch: 11.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11035995946977845		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.11035995946977845 | validation: 0.11642151850711681]
	TIME [epoch: 11.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11319266398603109		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.11319266398603109 | validation: 0.11387469630009461]
	TIME [epoch: 11.6 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10267155343888301		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.10267155343888301 | validation: 0.10894513040221132]
	TIME [epoch: 11.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09462071751221648		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.09462071751221648 | validation: 0.08485712564486733]
	TIME [epoch: 11.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07612331022158647		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.07612331022158647 | validation: 0.08570897696651977]
	TIME [epoch: 11.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0730583215557579		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.0730583215557579 | validation: 0.0739748944136328]
	TIME [epoch: 11.6 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08299836537265079		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.08299836537265079 | validation: 0.07581753126934601]
	TIME [epoch: 11.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07209056122445706		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.07209056122445706 | validation: 0.07755508901554933]
	TIME [epoch: 11.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07474002155292839		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.07474002155292839 | validation: 0.07676397864520312]
	TIME [epoch: 11.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0893750156184939		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.0893750156184939 | validation: 0.10368240701256692]
	TIME [epoch: 11.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09195113671055757		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.09195113671055757 | validation: 0.0765678437028168]
	TIME [epoch: 11.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06884687061650752		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.06884687061650752 | validation: 0.08741921776127398]
	TIME [epoch: 11.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07788034225337295		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.07788034225337295 | validation: 0.08309758668794434]
	TIME [epoch: 11.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07375927851778952		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.07375927851778952 | validation: 0.07395942709269464]
	TIME [epoch: 11.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0751054269020055		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.0751054269020055 | validation: 0.0714432242621751]
	TIME [epoch: 11.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06472438226277122		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.06472438226277122 | validation: 0.07784129815752584]
	TIME [epoch: 11.6 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08623205672904191		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.08623205672904191 | validation: 0.10180859194670219]
	TIME [epoch: 11.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09081158718290125		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.09081158718290125 | validation: 0.10050234610802747]
	TIME [epoch: 11.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09591565337576087		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.09591565337576087 | validation: 0.10557871137716146]
	TIME [epoch: 11.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09427879356815982		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.09427879356815982 | validation: 0.10600431722335024]
	TIME [epoch: 11.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08254001401590991		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.08254001401590991 | validation: 0.07369616708630745]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06364440987129114		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.06364440987129114 | validation: 0.06711389918961382]
	TIME [epoch: 11.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06469124455229686		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.06469124455229686 | validation: 0.07490541597996085]
	TIME [epoch: 11.6 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07950869637765445		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.07950869637765445 | validation: 0.09834391220542371]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08056726945676615		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.08056726945676615 | validation: 0.08209574406191411]
	TIME [epoch: 11.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07271402134384547		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.07271402134384547 | validation: 0.06721130094388812]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06297617863419452		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.06297617863419452 | validation: 0.07120375103886095]
	TIME [epoch: 11.6 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061995244839804425		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.061995244839804425 | validation: 0.1118732962166182]
	TIME [epoch: 11.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10234109253994735		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.10234109253994735 | validation: 0.08407885163490525]
	TIME [epoch: 11.6 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0671566477463284		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.0671566477463284 | validation: 0.07495715148737958]
	TIME [epoch: 11.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07010372365376026		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.07010372365376026 | validation: 0.09081450104619936]
	TIME [epoch: 11.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776580353477331		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.0776580353477331 | validation: 0.11336479051656381]
	TIME [epoch: 11.6 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09004842041201738		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.09004842041201738 | validation: 0.07629888013025565]
	TIME [epoch: 11.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06582411942030328		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.06582411942030328 | validation: 0.0723204241146288]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07341823299050096		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.07341823299050096 | validation: 0.06877953919541283]
	TIME [epoch: 11.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0645765181648321		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.0645765181648321 | validation: 0.06944044653353176]
	TIME [epoch: 11.6 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07252448530595272		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.07252448530595272 | validation: 0.11671504006903367]
	TIME [epoch: 11.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10833358940252594		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.10833358940252594 | validation: 0.11129462206795435]
	TIME [epoch: 11.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08445050193225986		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.08445050193225986 | validation: 0.09002183974119106]
	TIME [epoch: 11.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08486502149684635		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.08486502149684635 | validation: 0.08740488525076658]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08803659251322588		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.08803659251322588 | validation: 0.09778562531392948]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08751923244214435		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.08751923244214435 | validation: 0.09468248000132257]
	TIME [epoch: 11.6 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09372690642553498		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.09372690642553498 | validation: 0.09648933916205048]
	TIME [epoch: 11.6 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07199367960697114		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.07199367960697114 | validation: 0.07597652302945004]
	TIME [epoch: 11.6 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06658132539997912		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.06658132539997912 | validation: 0.07853479191695743]
	TIME [epoch: 11.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07016106280023371		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.07016106280023371 | validation: 0.07147539320592464]
	TIME [epoch: 11.6 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06849914932966836		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.06849914932966836 | validation: 0.09127273455388568]
	TIME [epoch: 11.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07680318415158033		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.07680318415158033 | validation: 0.07148336685470624]
	TIME [epoch: 11.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06795052636100661		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.06795052636100661 | validation: 0.08300404834048568]
	TIME [epoch: 11.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07927530822981105		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.07927530822981105 | validation: 0.08178166068408649]
	TIME [epoch: 11.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06863227906607584		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.06863227906607584 | validation: 0.07078349036118102]
	TIME [epoch: 11.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07770923787282122		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.07770923787282122 | validation: 0.0791899756128783]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05901612844995931		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.05901612844995931 | validation: 0.07994953661700592]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06885196428166585		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.06885196428166585 | validation: 0.07141649028746602]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06504380596774705		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.06504380596774705 | validation: 0.09207138060112925]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06943569310609701		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.06943569310609701 | validation: 0.06519477568518695]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06230570602243042		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.06230570602243042 | validation: 0.07642263670224234]
	TIME [epoch: 11.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06712913130360224		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.06712913130360224 | validation: 0.07329102169760696]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07666763445709497		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.07666763445709497 | validation: 0.11720575926226562]
	TIME [epoch: 11.6 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08401538558356422		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.08401538558356422 | validation: 0.0720651789165566]
	TIME [epoch: 11.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06553079701726441		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.06553079701726441 | validation: 0.07105006406838864]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06216969794972633		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.06216969794972633 | validation: 0.0764519454422739]
	TIME [epoch: 11.6 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07808537101512743		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.07808537101512743 | validation: 0.08523713771891182]
	TIME [epoch: 11.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07786906544965697		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.07786906544965697 | validation: 0.0692428736624725]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06930886481695718		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.06930886481695718 | validation: 0.08076135893534762]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07609747587568869		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.07609747587568869 | validation: 0.09298342732648994]
	TIME [epoch: 11.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08084647066154943		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.08084647066154943 | validation: 0.11086460332262636]
	TIME [epoch: 11.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08112519375983782		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.08112519375983782 | validation: 0.07751391099732914]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07565257262456421		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.07565257262456421 | validation: 0.086537338194285]
	TIME [epoch: 11.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08254669253156569		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.08254669253156569 | validation: 0.10030398487948958]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07856195706792493		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.07856195706792493 | validation: 0.0828576895181474]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07344250701595137		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.07344250701595137 | validation: 0.07401987043113119]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06835058226867127		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.06835058226867127 | validation: 0.06832808980376848]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06245739906955506		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.06245739906955506 | validation: 0.07704103117712734]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07094883320914541		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.07094883320914541 | validation: 0.07877828132336925]
	TIME [epoch: 11.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0646558749151843		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.0646558749151843 | validation: 0.061890462721899075]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06597575140182405		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.06597575140182405 | validation: 0.09746774820217152]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07574746729030807		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.07574746729030807 | validation: 0.06732085882463956]
	TIME [epoch: 11.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0640761293497725		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.0640761293497725 | validation: 0.07754705119673094]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0879628988899926		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.0879628988899926 | validation: 0.09747854793776277]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09204946919096728		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.09204946919096728 | validation: 0.08314571614325936]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07062035861750747		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.07062035861750747 | validation: 0.06343307157371678]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07719968463384576		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.07719968463384576 | validation: 0.09107472375425754]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07788908578798369		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.07788908578798369 | validation: 0.07870714007783515]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06425941390839837		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.06425941390839837 | validation: 0.06356883767757056]
	TIME [epoch: 11.6 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06469591305582034		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.06469591305582034 | validation: 0.08181108877041421]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07145230010731798		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.07145230010731798 | validation: 0.06198947323949886]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062029872129749565		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.062029872129749565 | validation: 0.06583865470079299]
	TIME [epoch: 11.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06197675512277173		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.06197675512277173 | validation: 0.061481853820418104]
	TIME [epoch: 11.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06571559173089701		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.06571559173089701 | validation: 0.07065270537110638]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06683847148387714		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.06683847148387714 | validation: 0.08291331612264352]
	TIME [epoch: 11.6 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06740366465194716		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.06740366465194716 | validation: 0.07918404588534637]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07598860135044389		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.07598860135044389 | validation: 0.08980699815655871]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08697775763409049		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.08697775763409049 | validation: 0.09499097944792015]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08026074313939621		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.08026074313939621 | validation: 0.07275581295809015]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06679093564981707		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.06679093564981707 | validation: 0.07912022975017462]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08173310447800666		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.08173310447800666 | validation: 0.08734282004868531]
	TIME [epoch: 11.6 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09556956174884494		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.09556956174884494 | validation: 0.09322461875780398]
	TIME [epoch: 11.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08509982204930885		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.08509982204930885 | validation: 0.09336109214436937]
	TIME [epoch: 11.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07959167387993513		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.07959167387993513 | validation: 0.07234900021579244]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07016172844988428		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.07016172844988428 | validation: 0.09946628756783171]
	TIME [epoch: 11.6 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09865729374950022		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.09865729374950022 | validation: 0.10913074022493754]
	TIME [epoch: 11.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1020462662314737		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.1020462662314737 | validation: 0.09327468171692367]
	TIME [epoch: 11.6 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0966978201749951		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.0966978201749951 | validation: 0.0862153239576025]
	TIME [epoch: 11.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07206775116000877		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.07206775116000877 | validation: 0.07272312113582073]
	TIME [epoch: 11.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06443158382558505		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.06443158382558505 | validation: 0.06913559451547532]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07327774411666209		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.07327774411666209 | validation: 0.06708288377969504]
	TIME [epoch: 11.6 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06925952028819644		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.06925952028819644 | validation: 0.06929464220621885]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07057359551274024		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.07057359551274024 | validation: 0.07058820927246673]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06776089260886828		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.06776089260886828 | validation: 0.07022197909343618]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06649157727034799		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.06649157727034799 | validation: 0.08527672687292082]
	TIME [epoch: 11.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08071846854809729		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.08071846854809729 | validation: 0.09630247086487799]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07215522033994454		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.07215522033994454 | validation: 0.07859161559262638]
	TIME [epoch: 11.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06272375931746207		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.06272375931746207 | validation: 0.07590147375622812]
	TIME [epoch: 11.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06905436832988593		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.06905436832988593 | validation: 0.0746864050072864]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06427231445989201		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.06427231445989201 | validation: 0.06882608106407873]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06980953656253511		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.06980953656253511 | validation: 0.08101466290460223]
	TIME [epoch: 11.6 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07626104042750306		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.07626104042750306 | validation: 0.07631354106380597]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.070166967987603		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.070166967987603 | validation: 0.08770410543823377]
	TIME [epoch: 11.6 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09459871007398268		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.09459871007398268 | validation: 0.09884711321843845]
	TIME [epoch: 11.6 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07591917584544082		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.07591917584544082 | validation: 0.07065749215755456]
	TIME [epoch: 11.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06818565780756455		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.06818565780756455 | validation: 0.07642147434453771]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06303342956817518		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.06303342956817518 | validation: 0.07878629121718016]
	TIME [epoch: 11.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08487484686755861		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.08487484686755861 | validation: 0.08830751874186442]
	TIME [epoch: 11.6 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06722542150573968		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.06722542150573968 | validation: 0.07155785178957401]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0663527114132348		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.0663527114132348 | validation: 0.06828288071956223]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08073262202520444		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.08073262202520444 | validation: 0.10127148118933707]
	TIME [epoch: 11.6 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10181130941275353		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.10181130941275353 | validation: 0.07265142725781212]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06880284575782523		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.06880284575782523 | validation: 0.0648608432948106]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05930910713637584		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.05930910713637584 | validation: 0.0685325865662775]
	TIME [epoch: 11.6 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06762446648417052		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.06762446648417052 | validation: 0.09425664233580695]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07492124169693085		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.07492124169693085 | validation: 0.06755912376892431]
	TIME [epoch: 11.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0677364951081377		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.0677364951081377 | validation: 0.07047750086198874]
	TIME [epoch: 11.6 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06384460105060177		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.06384460105060177 | validation: 0.0598317558411862]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1042.pth
	Model improved!!!
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06233465701215058		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.06233465701215058 | validation: 0.07408310582325842]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06993646100178845		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.06993646100178845 | validation: 0.07225234361881705]
	TIME [epoch: 11.6 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0706710763028848		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.0706710763028848 | validation: 0.07118151927653983]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07073879688359899		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.07073879688359899 | validation: 0.07661290974939368]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06526664500685739		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.06526664500685739 | validation: 0.073168069577857]
	TIME [epoch: 11.6 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058978349813918314		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.058978349813918314 | validation: 0.07539940420898551]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056854895816219005		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.056854895816219005 | validation: 0.06852037866972499]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07001116099656303		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.07001116099656303 | validation: 0.0838898588747018]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0714294822274637		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.0714294822274637 | validation: 0.07264961825258193]
	TIME [epoch: 11.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06900930638708311		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.06900930638708311 | validation: 0.06692635134198918]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06234052545035676		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.06234052545035676 | validation: 0.06738300057624529]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06240476115474422		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.06240476115474422 | validation: 0.07093350130474738]
	TIME [epoch: 11.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057338118525058115		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.057338118525058115 | validation: 0.06655755280527091]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06874189241576584		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.06874189241576584 | validation: 0.06392899285393783]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06509532018057723		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.06509532018057723 | validation: 0.06737373749734632]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06340337023972184		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.06340337023972184 | validation: 0.06351031744632941]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07156712221643963		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.07156712221643963 | validation: 0.09010315567600057]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06679121261800079		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.06679121261800079 | validation: 0.06352572029243564]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05814039647852104		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.05814039647852104 | validation: 0.060681083077595926]
	TIME [epoch: 11.6 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0598897028890928		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.0598897028890928 | validation: 0.061761618235228556]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05747990961209708		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.05747990961209708 | validation: 0.06739557857903462]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05804396701811298		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.05804396701811298 | validation: 0.06343564009727992]
	TIME [epoch: 11.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05721472568224726		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.05721472568224726 | validation: 0.06594408315840385]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05606548730305694		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.05606548730305694 | validation: 0.06670781939283471]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06487102694450622		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.06487102694450622 | validation: 0.08746575410179301]
	TIME [epoch: 11.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08235375708851009		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.08235375708851009 | validation: 0.0892712542579692]
	TIME [epoch: 11.6 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08153919250626204		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.08153919250626204 | validation: 0.08455850400292096]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08079847907933543		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.08079847907933543 | validation: 0.07781907608170634]
	TIME [epoch: 11.6 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06088484060856141		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.06088484060856141 | validation: 0.06278653283878156]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057477233462142216		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.057477233462142216 | validation: 0.06883278213875954]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07046475042249734		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.07046475042249734 | validation: 0.07923999904716793]
	TIME [epoch: 11.6 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08245221134653713		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.08245221134653713 | validation: 0.09022472365273525]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08043347029810043		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.08043347029810043 | validation: 0.07953898726379639]
	TIME [epoch: 11.6 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08304733444920147		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.08304733444920147 | validation: 0.09505489214927479]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07510200077622473		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.07510200077622473 | validation: 0.06704291757201616]
	TIME [epoch: 11.6 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06354040887583798		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.06354040887583798 | validation: 0.06250119939019978]
	TIME [epoch: 11.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061736893142922716		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.061736893142922716 | validation: 0.061699486406547745]
	TIME [epoch: 11.6 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0593127795693308		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.0593127795693308 | validation: 0.059199898555563]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1080.pth
	Model improved!!!
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056769964214906314		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.056769964214906314 | validation: 0.07172243872170263]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060492850180992194		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.060492850180992194 | validation: 0.05261116591284218]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1082.pth
	Model improved!!!
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06260080173935978		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.06260080173935978 | validation: 0.06618343175712323]
	TIME [epoch: 11.6 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07320508894914646		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.07320508894914646 | validation: 0.09617347105862627]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08047805051702289		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.08047805051702289 | validation: 0.08153540588103907]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06431734890493788		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.06431734890493788 | validation: 0.07094671645348535]
	TIME [epoch: 11.6 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07466229221187037		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.07466229221187037 | validation: 0.06204928236320912]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0550849954095924		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.0550849954095924 | validation: 0.06238777622464991]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06235020104824101		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.06235020104824101 | validation: 0.06483669762256614]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059353456893339165		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.059353456893339165 | validation: 0.06827880665747406]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060467768297040564		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.060467768297040564 | validation: 0.0631932564098715]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05570003911070436		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.05570003911070436 | validation: 0.05587065273024809]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05751057997264326		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.05751057997264326 | validation: 0.0644597364397553]
	TIME [epoch: 11.6 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667921543903097		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.0667921543903097 | validation: 0.0707156647156058]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06920683879897783		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.06920683879897783 | validation: 0.06976426836521965]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06809831720839032		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.06809831720839032 | validation: 0.07097761016598177]
	TIME [epoch: 11.6 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06314902568856408		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.06314902568856408 | validation: 0.06163391748712641]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05715059372514582		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.05715059372514582 | validation: 0.0698979975663616]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05776902990179494		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.05776902990179494 | validation: 0.05669550638156859]
	TIME [epoch: 11.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050373878125535725		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.050373878125535725 | validation: 0.053232644245795734]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054828833931878394		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.054828833931878394 | validation: 0.0708775789347439]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06504860367949375		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.06504860367949375 | validation: 0.08230365867588538]
	TIME [epoch: 11.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07468882235648355		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.07468882235648355 | validation: 0.07871459122476815]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06592034755430567		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.06592034755430567 | validation: 0.07386829475479703]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017436989343735		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.07017436989343735 | validation: 0.06973594953261315]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058173979091045276		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.058173979091045276 | validation: 0.0716164387791667]
	TIME [epoch: 11.6 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06166064785283557		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.06166064785283557 | validation: 0.06916838183822564]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06196060817955229		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.06196060817955229 | validation: 0.07238833213190776]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05867765245821948		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.05867765245821948 | validation: 0.06857455312405801]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05996241670736305		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.05996241670736305 | validation: 0.05894517312045587]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05843577941939921		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.05843577941939921 | validation: 0.0647312986697357]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05541587419935066		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.05541587419935066 | validation: 0.05570982955326027]
	TIME [epoch: 11.6 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05279452242721381		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.05279452242721381 | validation: 0.05752891230189052]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05361387302985486		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.05361387302985486 | validation: 0.06037859204106443]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053097714841291645		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.053097714841291645 | validation: 0.057183446702318265]
	TIME [epoch: 11.6 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05309879772224938		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.05309879772224938 | validation: 0.06491094699374442]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06384866643294695		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.06384866643294695 | validation: 0.06439925700972361]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06012036141492827		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.06012036141492827 | validation: 0.0575562257940946]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060859730696108075		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.060859730696108075 | validation: 0.06784480932863858]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05943521195996899		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.05943521195996899 | validation: 0.05843897932116969]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05433380437786822		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.05433380437786822 | validation: 0.05686291060787589]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0487420095165161		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.0487420095165161 | validation: 0.05967496444635356]
	TIME [epoch: 11.6 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05609332740706884		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.05609332740706884 | validation: 0.07225370286044754]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07112367401465372		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.07112367401465372 | validation: 0.06293872040621036]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05209269947359974		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.05209269947359974 | validation: 0.06144028508962604]
	TIME [epoch: 11.6 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054840676945942995		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.054840676945942995 | validation: 0.06146168860605543]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05422426005071898		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.05422426005071898 | validation: 0.07178520120918414]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07151250585098354		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.07151250585098354 | validation: 0.10569490986918162]
	TIME [epoch: 11.6 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08704441061725622		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.08704441061725622 | validation: 0.09011154545523438]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07745933077113357		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.07745933077113357 | validation: 0.07275737500859285]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07251582584529091		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.07251582584529091 | validation: 0.06838029263980643]
	TIME [epoch: 11.6 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.065795908588616		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.065795908588616 | validation: 0.06207275919869344]
	TIME [epoch: 11.6 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05206974832961435		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.05206974832961435 | validation: 0.05894183970870334]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05669143793174314		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.05669143793174314 | validation: 0.058379964868641214]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058702612470080934		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.058702612470080934 | validation: 0.05467785632597963]
	TIME [epoch: 11.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051166655438072584		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.051166655438072584 | validation: 0.07396579780705374]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062126995241380586		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.062126995241380586 | validation: 0.06399554742763389]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06145956604072576		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.06145956604072576 | validation: 0.06212415995163832]
	TIME [epoch: 11.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06499691988105871		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.06499691988105871 | validation: 0.06546025963214504]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06403840385410528		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.06403840385410528 | validation: 0.07380083671942415]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06464705150385769		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.06464705150385769 | validation: 0.08200521366427879]
	TIME [epoch: 11.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06536535774409924		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.06536535774409924 | validation: 0.058399877066700835]
	TIME [epoch: 11.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05719516503895073		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.05719516503895073 | validation: 0.06422104265582305]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059036459103416775		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.059036459103416775 | validation: 0.05393803661859673]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05439340277106312		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.05439340277106312 | validation: 0.060932736585259564]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056428313453451125		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.056428313453451125 | validation: 0.07160445401872488]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062067044557551576		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.062067044557551576 | validation: 0.06349524008017875]
	TIME [epoch: 11.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06834018214925414		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.06834018214925414 | validation: 0.07153273433432558]
	TIME [epoch: 11.6 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05827839962914764		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.05827839962914764 | validation: 0.06788787763158256]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05652741472102761		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.05652741472102761 | validation: 0.06764285565587454]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06102116240528451		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.06102116240528451 | validation: 0.07216231570686396]
	TIME [epoch: 11.6 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06469162016919552		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.06469162016919552 | validation: 0.05836566110563147]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05544970564732931		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.05544970564732931 | validation: 0.06274546231356908]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05757008699674591		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.05757008699674591 | validation: 0.05487977129268067]
	TIME [epoch: 11.6 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05774288754210836		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.05774288754210836 | validation: 0.05584037437863163]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059260477564370806		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.059260477564370806 | validation: 0.06751891560017699]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06017178956096332		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.06017178956096332 | validation: 0.06268329448761845]
	TIME [epoch: 11.6 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062321598496410585		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.062321598496410585 | validation: 0.07861971015649379]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06128956550575639		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.06128956550575639 | validation: 0.0705233327882547]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053508013925242154		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.053508013925242154 | validation: 0.05860954679525952]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06799200528807595		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.06799200528807595 | validation: 0.07760885746032793]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06737443483760547		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.06737443483760547 | validation: 0.06294326218848582]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05300901712843045		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.05300901712843045 | validation: 0.06650252080130944]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05717330349171393		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.05717330349171393 | validation: 0.05939849901175528]
	TIME [epoch: 11.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06684855547415774		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.06684855547415774 | validation: 0.08332258807808238]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08093420815015935		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.08093420815015935 | validation: 0.0904360804283615]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0759781684299323		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.0759781684299323 | validation: 0.07531543581590225]
	TIME [epoch: 11.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056808661575622706		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.056808661575622706 | validation: 0.062392286025754265]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058869844432861765		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.058869844432861765 | validation: 0.06726126681810626]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06492060110858366		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.06492060110858366 | validation: 0.0676133752156672]
	TIME [epoch: 11.6 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06157521895077265		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.06157521895077265 | validation: 0.06866585058058142]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062367936650178875		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.062367936650178875 | validation: 0.06802691155133488]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07105407300673307		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.07105407300673307 | validation: 0.07596880174731287]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07474023810409158		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.07474023810409158 | validation: 0.0842066831983623]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07003763017971605		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.07003763017971605 | validation: 0.06431602297277336]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0564717354894093		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.0564717354894093 | validation: 0.0640491879493541]
	TIME [epoch: 11.6 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05816702762275274		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.05816702762275274 | validation: 0.06343444468308379]
	TIME [epoch: 11.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05528804026549131		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.05528804026549131 | validation: 0.0634816445791888]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06072447847529901		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.06072447847529901 | validation: 0.0619098599146313]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0598162796340831		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.0598162796340831 | validation: 0.0736255949555594]
	TIME [epoch: 11.6 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057297107823730375		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.057297107823730375 | validation: 0.0661595618866321]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05493445608241926		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.05493445608241926 | validation: 0.06604032457149282]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052507164188748574		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.052507164188748574 | validation: 0.05279495284420608]
	TIME [epoch: 11.6 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0525695921534596		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.0525695921534596 | validation: 0.06560084717688507]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054008451988527245		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.054008451988527245 | validation: 0.07081454694973438]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06447561024245368		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.06447561024245368 | validation: 0.07764212976543908]
	TIME [epoch: 11.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06998718768249712		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.06998718768249712 | validation: 0.08368999828373276]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07366888117615528		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.07366888117615528 | validation: 0.07762848770167205]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058115723808609736		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.058115723808609736 | validation: 0.06006164914277529]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05618460366773538		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.05618460366773538 | validation: 0.05656914813583248]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05973291650816308		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.05973291650816308 | validation: 0.06873315912571001]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06848413512670767		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.06848413512670767 | validation: 0.06685384440776898]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056188217453084485		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.056188217453084485 | validation: 0.06132058666289715]
	TIME [epoch: 11.6 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05516784653425445		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.05516784653425445 | validation: 0.054082524900199325]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05039172010493154		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.05039172010493154 | validation: 0.06096927865084579]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05145778768082891		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.05145778768082891 | validation: 0.06321331523882379]
	TIME [epoch: 11.6 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057228426370755765		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.057228426370755765 | validation: 0.05813209464425012]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05444221560646241		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.05444221560646241 | validation: 0.05073463209770214]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1198.pth
	Model improved!!!
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052239828749640255		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.052239828749640255 | validation: 0.05224858923490956]
	TIME [epoch: 11.6 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051636237930231615		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.051636237930231615 | validation: 0.05817020041588705]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05092920145725489		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.05092920145725489 | validation: 0.06582902262656315]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05106190413318401		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.05106190413318401 | validation: 0.06152037326339713]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05263498689431907		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.05263498689431907 | validation: 0.047233578472116185]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1203.pth
	Model improved!!!
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057441194300375274		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.057441194300375274 | validation: 0.059635291708242485]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056476330762561935		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.056476330762561935 | validation: 0.06398024512358111]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05406191350179516		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.05406191350179516 | validation: 0.05664284917182795]
	TIME [epoch: 11.6 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0528502318314248		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.0528502318314248 | validation: 0.0658955584729717]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053893341096643246		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.053893341096643246 | validation: 0.058090560124836634]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054546358704121535		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.054546358704121535 | validation: 0.05256009111533974]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05251039057039858		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.05251039057039858 | validation: 0.06741811613953172]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06063192856934887		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.06063192856934887 | validation: 0.060706932529180586]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05675184457357915		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.05675184457357915 | validation: 0.054954586899026873]
	TIME [epoch: 11.6 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053255219006073884		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.053255219006073884 | validation: 0.05504065812622444]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04971901597433577		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.04971901597433577 | validation: 0.05575794574525972]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05230712893152947		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.05230712893152947 | validation: 0.05356026624414461]
	TIME [epoch: 11.6 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051159724943437665		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.051159724943437665 | validation: 0.0575925438328716]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0506595568339418		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.0506595568339418 | validation: 0.06196878413563729]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05412680107859601		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.05412680107859601 | validation: 0.05848759806880473]
	TIME [epoch: 11.6 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05449380273222279		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.05449380273222279 | validation: 0.06673901442509847]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053945556423405046		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.053945556423405046 | validation: 0.0662595792185855]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05705212798373859		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.05705212798373859 | validation: 0.056343521231318035]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05422254553043193		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.05422254553043193 | validation: 0.05878990500647545]
	TIME [epoch: 11.6 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0535759785089276		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.0535759785089276 | validation: 0.07051351597659346]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053132853616354135		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.053132853616354135 | validation: 0.059924567168750144]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050693546014565743		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.050693546014565743 | validation: 0.05156880101855116]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05560034240306094		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.05560034240306094 | validation: 0.07089214669870757]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061474268799212736		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.061474268799212736 | validation: 0.06393518331486116]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05313897859064478		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.05313897859064478 | validation: 0.05817401184591813]
	TIME [epoch: 11.6 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05475464308658368		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.05475464308658368 | validation: 0.05919782330013511]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05485284637399809		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.05485284637399809 | validation: 0.05593165990305357]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05326000358104869		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.05326000358104869 | validation: 0.05989138939726356]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05478134520625464		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.05478134520625464 | validation: 0.061813396116364425]
	TIME [epoch: 11.6 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05027126888996021		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.05027126888996021 | validation: 0.0619141671122446]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055198021887510156		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.055198021887510156 | validation: 0.06159916380907016]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056176919365181495		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.056176919365181495 | validation: 0.07000800716481609]
	TIME [epoch: 11.6 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873106861810887		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.05873106861810887 | validation: 0.05605263561225995]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050941615036172894		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.050941615036172894 | validation: 0.0561816537906664]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05921774281577401		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.05921774281577401 | validation: 0.0727594331111524]
	TIME [epoch: 11.6 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06977469868461657		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.06977469868461657 | validation: 0.0772155000083165]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054587492211124085		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.054587492211124085 | validation: 0.062391859283628344]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05470091443033766		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.05470091443033766 | validation: 0.05047751273454686]
	TIME [epoch: 11.6 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05005084758915694		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.05005084758915694 | validation: 0.05507503437135883]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05329041078562101		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.05329041078562101 | validation: 0.057270013778580084]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05637500203116339		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.05637500203116339 | validation: 0.0633758868112841]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06575427476538928		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.06575427476538928 | validation: 0.06467595317079707]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06340464258594386		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.06340464258594386 | validation: 0.05191114847822124]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05755952620780471		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.05755952620780471 | validation: 0.07360670109417561]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05736712766242149		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.05736712766242149 | validation: 0.06430621078801627]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05866027059434767		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.05866027059434767 | validation: 0.05855383575175559]
	TIME [epoch: 11.6 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06856180382274096		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.06856180382274096 | validation: 0.06786143578049007]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05715594258173789		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.05715594258173789 | validation: 0.05641693564488052]
	TIME [epoch: 11.6 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05743946124111679		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.05743946124111679 | validation: 0.06008086874580101]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05450630343225117		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.05450630343225117 | validation: 0.0573152515080704]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05184862405610885		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.05184862405610885 | validation: 0.0590850468915016]
	TIME [epoch: 11.6 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0555166313483216		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.0555166313483216 | validation: 0.053923451481293995]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05751670462890524		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.05751670462890524 | validation: 0.07225202265311943]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06065445852399736		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.06065445852399736 | validation: 0.07606138312213132]
	TIME [epoch: 11.6 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061671581877398074		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.061671581877398074 | validation: 0.06553237838027162]
	TIME [epoch: 11.6 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05556812673183266		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.05556812673183266 | validation: 0.05565941270372115]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05322790378245544		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.05322790378245544 | validation: 0.06549683802198575]
	TIME [epoch: 11.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565337485474628		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.05565337485474628 | validation: 0.0569414165566357]
	TIME [epoch: 11.6 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05399124065044958		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.05399124065044958 | validation: 0.06461152955302635]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053059206224950826		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.053059206224950826 | validation: 0.06384601023667286]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0514444714897483		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.0514444714897483 | validation: 0.05912893171085229]
	TIME [epoch: 11.6 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0509945314176024		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.0509945314176024 | validation: 0.05980876552522847]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053525451592691016		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.053525451592691016 | validation: 0.06379287298371543]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05532241995185105		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.05532241995185105 | validation: 0.054515918313187355]
	TIME [epoch: 11.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05041796457012872		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.05041796457012872 | validation: 0.053575237844277694]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054883433453196816		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.054883433453196816 | validation: 0.07346274461534451]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06669571497586498		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.06669571497586498 | validation: 0.06388688657761614]
	TIME [epoch: 11.6 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05752824122495605		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.05752824122495605 | validation: 0.06888995944158681]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04895987773141903		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.04895987773141903 | validation: 0.05375780588227638]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05235136311017671		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.05235136311017671 | validation: 0.060446002789944185]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054679895285609854		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.054679895285609854 | validation: 0.062093666358857824]
	TIME [epoch: 11.6 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05587114029749571		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.05587114029749571 | validation: 0.05144703106083572]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05622057464598929		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.05622057464598929 | validation: 0.059917289624690284]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05244785732741293		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.05244785732741293 | validation: 0.0553483089735802]
	TIME [epoch: 11.6 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052827780995962276		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.052827780995962276 | validation: 0.061955536775756395]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048644538279994806		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.048644538279994806 | validation: 0.05905452777310795]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050065273013767335		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.050065273013767335 | validation: 0.05738842919386711]
	TIME [epoch: 11.6 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05293320640317866		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.05293320640317866 | validation: 0.05100424967190643]
	TIME [epoch: 11.6 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05382836896005089		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.05382836896005089 | validation: 0.057279804219410216]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05004005220805956		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.05004005220805956 | validation: 0.0556906083323531]
	TIME [epoch: 11.6 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05255552190132442		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.05255552190132442 | validation: 0.05536253681705782]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05024361888033757		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.05024361888033757 | validation: 0.053013867730290314]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05463175054892158		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.05463175054892158 | validation: 0.05231994150091628]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052435855576384444		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.052435855576384444 | validation: 0.05325120742493461]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055070646241605715		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.055070646241605715 | validation: 0.059943790739122295]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04959669669623041		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.04959669669623041 | validation: 0.05494575400278226]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05252538624439658		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.05252538624439658 | validation: 0.06352699377025696]
	TIME [epoch: 11.6 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04836805760942394		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.04836805760942394 | validation: 0.06175808018041705]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06103813209635207		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.06103813209635207 | validation: 0.06830186454743245]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07082587438816568		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.07082587438816568 | validation: 0.07191491225051873]
	TIME [epoch: 11.6 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06510817454146214		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.06510817454146214 | validation: 0.060586344698776266]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05881320542903119		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.05881320542903119 | validation: 0.06149137966111718]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05402245552085916		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.05402245552085916 | validation: 0.05821892531096785]
	TIME [epoch: 11.6 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05389072605572284		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.05389072605572284 | validation: 0.0583550983855466]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04866709457686319		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.04866709457686319 | validation: 0.06367100891474003]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052329618548468154		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.052329618548468154 | validation: 0.060433851504742356]
	TIME [epoch: 11.6 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051968466707195723		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.051968466707195723 | validation: 0.053993608195801866]
	TIME [epoch: 11.6 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045593106025726866		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.045593106025726866 | validation: 0.05172863369682661]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0475714174656767		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.0475714174656767 | validation: 0.05497910925409466]
	TIME [epoch: 11.6 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049950287823719006		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.049950287823719006 | validation: 0.06378640068247744]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050490633556021895		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.050490633556021895 | validation: 0.06304349623248508]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05133452775609714		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.05133452775609714 | validation: 0.05963090282098369]
	TIME [epoch: 11.6 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04839835404270436		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.04839835404270436 | validation: 0.06520977544425578]
	TIME [epoch: 11.6 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050050923980454846		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.050050923980454846 | validation: 0.061717330171024126]
	TIME [epoch: 11.6 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054164449328773956		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.054164449328773956 | validation: 0.057243774403386086]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048745328857922404		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.048745328857922404 | validation: 0.05842149992285476]
	TIME [epoch: 11.6 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050802243544095016		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.050802243544095016 | validation: 0.05883904764832243]
	TIME [epoch: 11.6 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04748066040501095		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.04748066040501095 | validation: 0.054215813251135093]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04914479429429536		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.04914479429429536 | validation: 0.051276756649057925]
	TIME [epoch: 11.6 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05092058354803007		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.05092058354803007 | validation: 0.056536172702197816]
	TIME [epoch: 11.6 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05240107329710077		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.05240107329710077 | validation: 0.04817026181737376]
	TIME [epoch: 11.6 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05255508635397281		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.05255508635397281 | validation: 0.06154274156693751]
	TIME [epoch: 11.6 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050374254059249654		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.050374254059249654 | validation: 0.048951313418416666]
	TIME [epoch: 11.6 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048245778245991466		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.048245778245991466 | validation: 0.05494698766173101]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04975495490747847		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.04975495490747847 | validation: 0.05856256712352759]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05492403393531642		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.05492403393531642 | validation: 0.06441431221657122]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05727463640381718		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.05727463640381718 | validation: 0.06290142183694532]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05819130744259795		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.05819130744259795 | validation: 0.062369003463052713]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05375354055128524		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.05375354055128524 | validation: 0.06139858880083823]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049920911300783355		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.049920911300783355 | validation: 0.06019383449366118]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04901752473209486		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.04901752473209486 | validation: 0.05514502366198856]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052799531933687804		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.052799531933687804 | validation: 0.06265568871359832]
	TIME [epoch: 11.6 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05141318885963719		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.05141318885963719 | validation: 0.05918164142633327]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05348259253777186		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.05348259253777186 | validation: 0.052259610276329055]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04792248182311129		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.04792248182311129 | validation: 0.04352501412729493]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1328.pth
	Model improved!!!
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05854183775463016		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.05854183775463016 | validation: 0.05965335948216938]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051957853321789246		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.051957853321789246 | validation: 0.057323288891316944]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05252529469037845		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.05252529469037845 | validation: 0.0505393613582158]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05227435035551613		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.05227435035551613 | validation: 0.05141544459321026]
	TIME [epoch: 11.6 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04544071947409568		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.04544071947409568 | validation: 0.06093853398378617]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04810318628328857		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.04810318628328857 | validation: 0.058320933887959184]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049919289176253004		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.049919289176253004 | validation: 0.05741112288698613]
	TIME [epoch: 11.6 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05420989073122019		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.05420989073122019 | validation: 0.0715772627259976]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051979926008939734		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.051979926008939734 | validation: 0.06016129152782582]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05498385637348057		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.05498385637348057 | validation: 0.06043303003596076]
	TIME [epoch: 11.6 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05239563894385592		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.05239563894385592 | validation: 0.06261198628760034]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05271083800748705		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.05271083800748705 | validation: 0.06557055001178397]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050171274547121406		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.050171274547121406 | validation: 0.05258503304767672]
	TIME [epoch: 11.6 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04913905918284981		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.04913905918284981 | validation: 0.04861837664238316]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05018613117902811		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.05018613117902811 | validation: 0.05275952739338574]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051555591545084815		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.051555591545084815 | validation: 0.06665325499126434]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05243165202319972		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.05243165202319972 | validation: 0.052873198017021804]
	TIME [epoch: 11.6 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05019633084713594		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.05019633084713594 | validation: 0.05138071329586439]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047401140644415425		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.047401140644415425 | validation: 0.051098510238845915]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04800403612737604		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.04800403612737604 | validation: 0.05783102842558818]
	TIME [epoch: 11.6 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0453362878250294		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.0453362878250294 | validation: 0.060217692642585204]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04679123814502127		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.04679123814502127 | validation: 0.06053658015577073]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04734717826374123		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.04734717826374123 | validation: 0.053470645937733874]
	TIME [epoch: 11.6 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05440120099586718		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.05440120099586718 | validation: 0.055180942732174255]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05277461653234794		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.05277461653234794 | validation: 0.0534516268376129]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04518411426194797		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.04518411426194797 | validation: 0.05685890434525776]
	TIME [epoch: 11.6 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05442714675424553		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.05442714675424553 | validation: 0.0547550090403876]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049866461242382545		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.049866461242382545 | validation: 0.05812149543793676]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04688903274407542		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.04688903274407542 | validation: 0.05989256898703687]
	TIME [epoch: 11.6 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04814871887950807		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.04814871887950807 | validation: 0.05465790048712624]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04937527319872634		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.04937527319872634 | validation: 0.056716305620439555]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047412141395858406		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.047412141395858406 | validation: 0.05415929256677233]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051060366821810255		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.051060366821810255 | validation: 0.04949956470165034]
	TIME [epoch: 11.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04948848729003963		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.04948848729003963 | validation: 0.05689665809888302]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06045120062319957		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.06045120062319957 | validation: 0.061178324425234534]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04974572586417911		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.04974572586417911 | validation: 0.049387060856040346]
	TIME [epoch: 11.6 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04712655158492113		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.04712655158492113 | validation: 0.04931750402692635]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049383496464824		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.049383496464824 | validation: 0.05750469798076269]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050265534347291654		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.050265534347291654 | validation: 0.05643565977524004]
	TIME [epoch: 11.6 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047629421639427925		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.047629421639427925 | validation: 0.051668418214971645]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04985150681520421		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.04985150681520421 | validation: 0.05521409138922962]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045808748095506086		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.045808748095506086 | validation: 0.048902420750070535]
	TIME [epoch: 11.6 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046185031376209516		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.046185031376209516 | validation: 0.048510986822077815]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050919876388829347		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.050919876388829347 | validation: 0.05454207599240727]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049178196419145864		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.049178196419145864 | validation: 0.05234521139725457]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04490449498887339		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.04490449498887339 | validation: 0.056696077248925045]
	TIME [epoch: 11.6 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05177786097349631		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.05177786097349631 | validation: 0.049604936785195564]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049348957071395506		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.049348957071395506 | validation: 0.0598893780020815]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04738925029060499		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.04738925029060499 | validation: 0.050144030264104904]
	TIME [epoch: 11.6 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049526832084509684		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.049526832084509684 | validation: 0.05960017762406197]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052343130804807035		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.052343130804807035 | validation: 0.05583813231692719]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05716659461848969		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.05716659461848969 | validation: 0.059397787759822095]
	TIME [epoch: 11.6 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05224218070171706		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.05224218070171706 | validation: 0.05203436154059332]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053438591926683064		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.053438591926683064 | validation: 0.053705398142782176]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05506289395859984		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.05506289395859984 | validation: 0.056932918727973604]
	TIME [epoch: 11.6 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05657259595298226		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.05657259595298226 | validation: 0.06034745911845173]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05545354231283514		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.05545354231283514 | validation: 0.060155066523937144]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04684479951884679		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.04684479951884679 | validation: 0.0517139558503481]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05141389523314014		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.05141389523314014 | validation: 0.05896856072856249]
	TIME [epoch: 11.6 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05122700707722648		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.05122700707722648 | validation: 0.06361105823248037]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056884703838804		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.056884703838804 | validation: 0.06589036526327473]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050695223294219674		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.050695223294219674 | validation: 0.06289101305780755]
	TIME [epoch: 11.6 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05774741475061084		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.05774741475061084 | validation: 0.0630084897857349]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05419591350719748		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.05419591350719748 | validation: 0.06561271369882776]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056041686796439574		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.056041686796439574 | validation: 0.06724352248283065]
	TIME [epoch: 11.6 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056930482642646385		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.056930482642646385 | validation: 0.05510583256158312]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052518426396441706		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.052518426396441706 | validation: 0.0655204248280127]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04967291131957503		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.04967291131957503 | validation: 0.05005552055948929]
	TIME [epoch: 11.6 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04928199112408743		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.04928199112408743 | validation: 0.05770937440637344]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04729493687242415		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.04729493687242415 | validation: 0.05454818521606558]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050747735296183275		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.050747735296183275 | validation: 0.04900922010422685]
	TIME [epoch: 11.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04623187733738485		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.04623187733738485 | validation: 0.05995204571902101]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04815970548267447		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.04815970548267447 | validation: 0.06043510913484716]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051627356829320493		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.051627356829320493 | validation: 0.06565847266125477]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051921008070454015		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.051921008070454015 | validation: 0.05430909218877049]
	TIME [epoch: 11.6 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04723633519826969		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.04723633519826969 | validation: 0.0577656949572001]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04600612047615179		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.04600612047615179 | validation: 0.05424180888576599]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046816884471221336		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.046816884471221336 | validation: 0.044426198702761335]
	TIME [epoch: 11.6 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04637633038400114		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.04637633038400114 | validation: 0.056945655410378715]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051310090590268906		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.051310090590268906 | validation: 0.049390889095011076]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04839177603470307		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.04839177603470307 | validation: 0.05188125316074757]
	TIME [epoch: 11.6 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04667498192268575		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.04667498192268575 | validation: 0.053246597523553374]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0460922344455789		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.0460922344455789 | validation: 0.05210573279238343]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045421853978006604		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.045421853978006604 | validation: 0.05669562448064983]
	TIME [epoch: 11.6 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04878686673740944		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.04878686673740944 | validation: 0.05526668588933426]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046410166446711545		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.046410166446711545 | validation: 0.05186744648071444]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04841172530935167		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.04841172530935167 | validation: 0.06425747585379499]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04672213171751419		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.04672213171751419 | validation: 0.056898786854096266]
	TIME [epoch: 11.6 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04932205297354063		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.04932205297354063 | validation: 0.056511100855675726]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04878916238612737		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.04878916238612737 | validation: 0.0592935389885864]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05253020322611934		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.05253020322611934 | validation: 0.061532693556835785]
	TIME [epoch: 11.6 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053290846368216245		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.053290846368216245 | validation: 0.049656202907396134]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05137824696426839		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.05137824696426839 | validation: 0.06428626069324689]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053203736837487664		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.053203736837487664 | validation: 0.05969971615040759]
	TIME [epoch: 11.6 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0524757370074665		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.0524757370074665 | validation: 0.053259757306924185]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056030119708688104		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.056030119708688104 | validation: 0.0631424883358557]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051708953543730646		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.051708953543730646 | validation: 0.060288903753726086]
	TIME [epoch: 11.6 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05527763401668643		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.05527763401668643 | validation: 0.05567810267684644]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05185569052372846		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.05185569052372846 | validation: 0.056009882064347094]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05303998469332437		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.05303998469332437 | validation: 0.0584486035123044]
	TIME [epoch: 11.6 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054658412346873915		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.054658412346873915 | validation: 0.05522276599805014]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05424881718389018		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.05424881718389018 | validation: 0.056501579655649066]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05242916372125549		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.05242916372125549 | validation: 0.058737870805808286]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0549469208486791		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.0549469208486791 | validation: 0.050797729215550015]
	TIME [epoch: 11.6 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05208860457631852		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.05208860457631852 | validation: 0.05482362605373657]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05141774159274553		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.05141774159274553 | validation: 0.05135879361335555]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05021684169972828		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.05021684169972828 | validation: 0.0513046425224195]
	TIME [epoch: 11.6 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048111799853816445		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.048111799853816445 | validation: 0.05224275810868251]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04589760335891933		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.04589760335891933 | validation: 0.05116879106102485]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050403319760603804		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.050403319760603804 | validation: 0.04858831418173411]
	TIME [epoch: 11.6 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05308414892767244		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.05308414892767244 | validation: 0.056780869888167454]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050830031933255526		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.050830031933255526 | validation: 0.05303557320052704]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047811459355583716		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.047811459355583716 | validation: 0.056046356623639916]
	TIME [epoch: 11.6 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04618773986366871		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.04618773986366871 | validation: 0.0535077334379835]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04465017524961104		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.04465017524961104 | validation: 0.052316652318617714]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04947992942013198		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.04947992942013198 | validation: 0.06068347942483152]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04917418087814381		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.04917418087814381 | validation: 0.05637502570473897]
	TIME [epoch: 11.6 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04969153582633578		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.04969153582633578 | validation: 0.06091660971923161]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04545549040031608		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.04545549040031608 | validation: 0.0582757804751963]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052467785993269477		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.052467785993269477 | validation: 0.05759655989921576]
	TIME [epoch: 11.6 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05392061306653316		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.05392061306653316 | validation: 0.05867127566476042]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050793165232367		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.050793165232367 | validation: 0.0566896889672475]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04579314503930597		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.04579314503930597 | validation: 0.04483754872021432]
	TIME [epoch: 11.6 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04646290424907429		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.04646290424907429 | validation: 0.057556315662735114]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046456009248944975		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.046456009248944975 | validation: 0.05541900014880863]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04932367030105723		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.04932367030105723 | validation: 0.06145341097094274]
	TIME [epoch: 11.6 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044051680146643964		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.044051680146643964 | validation: 0.048108398947346455]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050311576235000835		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.050311576235000835 | validation: 0.05525635101937064]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05138495139485283		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.05138495139485283 | validation: 0.05234268143965799]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05213404636129333		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.05213404636129333 | validation: 0.05366577988763772]
	TIME [epoch: 11.6 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05031926683122749		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.05031926683122749 | validation: 0.05965059212045731]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052739387182383086		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.052739387182383086 | validation: 0.05347558734047702]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056981035585155056		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.056981035585155056 | validation: 0.058330162752213185]
	TIME [epoch: 11.6 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05335389582651885		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.05335389582651885 | validation: 0.04606462592921996]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048142427149969		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.048142427149969 | validation: 0.05425454200683699]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04916842503088378		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.04916842503088378 | validation: 0.051392023482186334]
	TIME [epoch: 11.6 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0493875577249118		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.0493875577249118 | validation: 0.05621026551767437]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051952593800066074		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.051952593800066074 | validation: 0.05478280734555353]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049661574969785405		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.049661574969785405 | validation: 0.050354054742362084]
	TIME [epoch: 11.6 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05193710078261842		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.05193710078261842 | validation: 0.0563196695559601]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047620735983943584		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.047620735983943584 | validation: 0.051432196881054056]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05111783372732581		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.05111783372732581 | validation: 0.0545940591228084]
	TIME [epoch: 11.6 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048632683508280976		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.048632683508280976 | validation: 0.05654497917945913]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04727733301719006		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.04727733301719006 | validation: 0.06407840959518814]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04939442937589052		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.04939442937589052 | validation: 0.05973885598758468]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052334010760484447		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.052334010760484447 | validation: 0.0564758953615856]
	TIME [epoch: 11.6 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048523352418021706		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.048523352418021706 | validation: 0.04711639809723437]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04979274372105362		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.04979274372105362 | validation: 0.049663105936601344]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0469893457458007		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.0469893457458007 | validation: 0.04905512715281089]
	TIME [epoch: 11.6 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04512696974010248		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.04512696974010248 | validation: 0.056577832295708945]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04872470467639488		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.04872470467639488 | validation: 0.05297039973508442]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04569215615239992		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.04569215615239992 | validation: 0.051895460441031806]
	TIME [epoch: 11.6 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04831041903104785		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.04831041903104785 | validation: 0.061611154149318836]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048977431004004736		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.048977431004004736 | validation: 0.06286902727822008]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04604481011627694		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.04604481011627694 | validation: 0.044096900567259435]
	TIME [epoch: 11.6 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04940109530650982		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.04940109530650982 | validation: 0.06143190321385898]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04775486247809945		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.04775486247809945 | validation: 0.05073370827565176]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04975335212069914		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.04975335212069914 | validation: 0.05509960147440989]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04734942484647585		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.04734942484647585 | validation: 0.049066003320930814]
	TIME [epoch: 11.6 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04808929034593587		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.04808929034593587 | validation: 0.051292455575202234]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05028975601999751		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.05028975601999751 | validation: 0.04514177117658106]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04962595743849997		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.04962595743849997 | validation: 0.05453258468757832]
	TIME [epoch: 11.6 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045718660693564665		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.045718660693564665 | validation: 0.05844782115137392]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04814800853811976		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.04814800853811976 | validation: 0.0629431418030845]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04480923895461618		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.04480923895461618 | validation: 0.04349778105577554]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1493.pth
	Model improved!!!
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0483608574876915		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.0483608574876915 | validation: 0.04843979267905132]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04802259632331945		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.04802259632331945 | validation: 0.049776272374907685]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04915889377694453		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.04915889377694453 | validation: 0.05032039900206598]
	TIME [epoch: 11.6 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05197513731407569		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.05197513731407569 | validation: 0.05642790163187339]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044898747858412066		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.044898747858412066 | validation: 0.05178506186164827]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046999937313223335		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.046999937313223335 | validation: 0.061561470455205686]
	TIME [epoch: 11.6 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05076083861817639		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.05076083861817639 | validation: 0.051483309508531666]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04862086215661735		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.04862086215661735 | validation: 0.05425566895654928]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05087091131914226		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.05087091131914226 | validation: 0.052741828030148596]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045344563182424635		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.045344563182424635 | validation: 0.05401788373003196]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04739100055146176		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.04739100055146176 | validation: 0.052130710115187336]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0468487157095418		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.0468487157095418 | validation: 0.05431667942589053]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0471412182833299		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.0471412182833299 | validation: 0.04893375609971258]
	TIME [epoch: 11.6 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04857669716801819		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.04857669716801819 | validation: 0.04797847401876144]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051572838371167745		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.051572838371167745 | validation: 0.06052252291178484]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04791947892441081		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.04791947892441081 | validation: 0.049978191474664764]
	TIME [epoch: 11.6 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04800455892374156		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.04800455892374156 | validation: 0.05030067594496094]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05165647985874251		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.05165647985874251 | validation: 0.055359742856535624]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04410318931299277		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.04410318931299277 | validation: 0.056349998836757176]
	TIME [epoch: 11.6 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05049571361966383		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.05049571361966383 | validation: 0.05442239761186876]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04906001071182658		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.04906001071182658 | validation: 0.05087280204567276]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045066890179364216		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.045066890179364216 | validation: 0.051162164324106384]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0475391449879399		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.0475391449879399 | validation: 0.058470487525024276]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0470768642524569		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.0470768642524569 | validation: 0.04821046791848676]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04698858994733134		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.04698858994733134 | validation: 0.054265136717832965]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0461687605282812		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.0461687605282812 | validation: 0.05871065253270604]
	TIME [epoch: 11.6 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047631498652090085		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.047631498652090085 | validation: 0.05150619011687436]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05126234593065597		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.05126234593065597 | validation: 0.04951339788206692]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04706830018214987		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.04706830018214987 | validation: 0.06177250361963454]
	TIME [epoch: 11.6 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04947635929602642		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.04947635929602642 | validation: 0.05641290890440132]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049103287869484334		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.049103287869484334 | validation: 0.05457097223795281]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04975134730799952		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.04975134730799952 | validation: 0.05242755842705365]
	TIME [epoch: 11.6 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047570455210424266		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.047570455210424266 | validation: 0.057175705948947386]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04992217520573473		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.04992217520573473 | validation: 0.05407954219837099]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04917168312812719		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.04917168312812719 | validation: 0.05642118413759112]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05113737309819061		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.05113737309819061 | validation: 0.048765858113721326]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05062582142809663		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.05062582142809663 | validation: 0.04562927228152696]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04842685738486658		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.04842685738486658 | validation: 0.058869678935162074]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04726722770545735		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.04726722770545735 | validation: 0.056766929131823435]
	TIME [epoch: 11.6 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04844140480823227		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.04844140480823227 | validation: 0.04589066683758053]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04676998929340584		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.04676998929340584 | validation: 0.05573194709967095]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04999795897053461		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.04999795897053461 | validation: 0.054889910216228625]
	TIME [epoch: 11.6 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045188684320559475		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.045188684320559475 | validation: 0.05786079077159399]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04801058648948615		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.04801058648948615 | validation: 0.04704913230125102]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04261740590553532		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.04261740590553532 | validation: 0.05358240584087124]
	TIME [epoch: 11.6 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04833011042674501		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.04833011042674501 | validation: 0.04704636185905631]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04907206294812182		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.04907206294812182 | validation: 0.05244079694331136]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0504733816501254		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.0504733816501254 | validation: 0.04746969303501453]
	TIME [epoch: 11.6 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0471973559275786		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.0471973559275786 | validation: 0.049762144968507636]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04997456513204828		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.04997456513204828 | validation: 0.06416736333562739]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04993643106590058		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.04993643106590058 | validation: 0.05543218856741789]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0506023241485313		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.0506023241485313 | validation: 0.04814067285679629]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04932871710485369		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.04932871710485369 | validation: 0.04781144286763363]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04945146843149359		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.04945146843149359 | validation: 0.05639749728576735]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047906358887366385		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.047906358887366385 | validation: 0.04438646514676236]
	TIME [epoch: 11.6 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04745845165807723		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.04745845165807723 | validation: 0.05357633125077211]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04856814944323222		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.04856814944323222 | validation: 0.0497349785603973]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051140672775218186		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.051140672775218186 | validation: 0.05168126378777832]
	TIME [epoch: 11.6 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048900289902503814		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.048900289902503814 | validation: 0.05399818370108862]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050338158139212275		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.050338158139212275 | validation: 0.05315243768516204]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05328087896101581		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.05328087896101581 | validation: 0.0649941768043694]
	TIME [epoch: 11.6 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05347858452300117		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.05347858452300117 | validation: 0.056738326942770596]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052304492733880166		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.052304492733880166 | validation: 0.06256745279233736]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05025012166106946		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.05025012166106946 | validation: 0.05276054983963528]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04914487144684687		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.04914487144684687 | validation: 0.055472094466841586]
	TIME [epoch: 11.6 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04772970987931166		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.04772970987931166 | validation: 0.05742863785772467]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04641102583468876		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.04641102583468876 | validation: 0.05710165964902118]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05122866492404284		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.05122866492404284 | validation: 0.051815417112272735]
	TIME [epoch: 11.6 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046808225805204315		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.046808225805204315 | validation: 0.05285345301425217]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04575354346726944		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.04575354346726944 | validation: 0.051092858573686756]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043345079072334626		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.043345079072334626 | validation: 0.05222352652562995]
	TIME [epoch: 11.6 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04429501471024634		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.04429501471024634 | validation: 0.045971446119098786]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04603812620237555		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.04603812620237555 | validation: 0.06004348347494193]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046795433600705635		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.046795433600705635 | validation: 0.052914835996295935]
	TIME [epoch: 11.6 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04549476766666995		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.04549476766666995 | validation: 0.04712138969025805]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04587251343850096		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.04587251343850096 | validation: 0.04955115963106824]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04731816061844783		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.04731816061844783 | validation: 0.051571710315191324]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043523067476624495		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.043523067476624495 | validation: 0.05219292985376841]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040458077978116014		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.040458077978116014 | validation: 0.04723119426179274]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04771902616412523		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.04771902616412523 | validation: 0.05130225704022629]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04819663737145322		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.04819663737145322 | validation: 0.060461531186905476]
	TIME [epoch: 11.6 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049007640659086624		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.049007640659086624 | validation: 0.04634831903085384]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048841802688964334		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.048841802688964334 | validation: 0.048851591181260465]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04572919976578602		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.04572919976578602 | validation: 0.05634904211272475]
	TIME [epoch: 11.6 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048918845611863805		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.048918845611863805 | validation: 0.05880941758014794]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04958280081260018		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.04958280081260018 | validation: 0.06442083286995336]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04572086171217927		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.04572086171217927 | validation: 0.048215086115349845]
	TIME [epoch: 11.6 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04771831460791232		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.04771831460791232 | validation: 0.052467810336596754]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04585678442912143		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.04585678442912143 | validation: 0.05394845079461199]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0503397036359004		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.0503397036359004 | validation: 0.04792737993012319]
	TIME [epoch: 11.6 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045699324238737175		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.045699324238737175 | validation: 0.05267124116211278]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04811826516724306		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.04811826516724306 | validation: 0.055969260222672394]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04641778965182669		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.04641778965182669 | validation: 0.04925270766892833]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045663327767370504		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.045663327767370504 | validation: 0.05426355028876692]
	TIME [epoch: 11.6 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0470255898860961		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.0470255898860961 | validation: 0.05866371724641045]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04748528452281906		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.04748528452281906 | validation: 0.05814153289824968]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04876058961857243		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.04876058961857243 | validation: 0.04883215113148363]
	TIME [epoch: 11.6 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050657545763953975		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.050657545763953975 | validation: 0.059716810949706975]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04694641036683517		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.04694641036683517 | validation: 0.059052925471944635]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05359355767467275		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.05359355767467275 | validation: 0.05570529594148147]
	TIME [epoch: 11.6 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050052104931851776		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.050052104931851776 | validation: 0.05666859280093471]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04414847405012573		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.04414847405012573 | validation: 0.049348694973469255]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04689556253762077		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.04689556253762077 | validation: 0.05484946853364809]
	TIME [epoch: 11.6 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04634225855414232		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.04634225855414232 | validation: 0.04749386523712337]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04958540616836248		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.04958540616836248 | validation: 0.0568128123133172]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05557045822927098		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.05557045822927098 | validation: 0.06477652187194902]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053720455449851115		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.053720455449851115 | validation: 0.056701042295506085]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04741496040782264		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.04741496040782264 | validation: 0.05180078176806287]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049039391133701274		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.049039391133701274 | validation: 0.04991709729626497]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050473897359293016		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.050473897359293016 | validation: 0.05778957892976843]
	TIME [epoch: 11.6 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05216952288790622		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.05216952288790622 | validation: 0.05409755901500386]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04936800264391312		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.04936800264391312 | validation: 0.05215701259342947]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05221654322421883		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.05221654322421883 | validation: 0.056812308150925056]
	TIME [epoch: 11.6 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049536064675268596		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.049536064675268596 | validation: 0.05761459604503499]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050126455016018624		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.050126455016018624 | validation: 0.049868226319441274]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05173622731197672		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.05173622731197672 | validation: 0.05471663690234522]
	TIME [epoch: 11.6 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04799576380368688		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.04799576380368688 | validation: 0.05362888689497755]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04677689160325718		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.04677689160325718 | validation: 0.05041219233401153]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04561146134902709		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.04561146134902709 | validation: 0.05393627379057774]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047525784586409776		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.047525784586409776 | validation: 0.05468350320886349]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043625943299299905		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.043625943299299905 | validation: 0.04462729504815056]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04706638471423921		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.04706638471423921 | validation: 0.04762927243296887]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043672638127276425		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.043672638127276425 | validation: 0.05681413713713899]
	TIME [epoch: 11.6 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04624132684578632		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.04624132684578632 | validation: 0.0587899940202324]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04760389799379894		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.04760389799379894 | validation: 0.04841354783461346]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04484082597097058		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.04484082597097058 | validation: 0.0527534921536869]
	TIME [epoch: 11.6 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046939257813916786		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.046939257813916786 | validation: 0.065751185826819]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05032296558098803		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.05032296558098803 | validation: 0.05202993378797393]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045739114244791435		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.045739114244791435 | validation: 0.05216252998183011]
	TIME [epoch: 11.6 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04815150277467219		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.04815150277467219 | validation: 0.051589748204181614]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047471585784197204		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.047471585784197204 | validation: 0.052283460426017385]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05195426584925573		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.05195426584925573 | validation: 0.05055343949718139]
	TIME [epoch: 11.6 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04683746961689417		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.04683746961689417 | validation: 0.0496595668921067]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04603254590242713		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.04603254590242713 | validation: 0.04337970100746645]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1627.pth
	Model improved!!!
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046880575653093566		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.046880575653093566 | validation: 0.05534019319064077]
	TIME [epoch: 11.6 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04526276226740451		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.04526276226740451 | validation: 0.0507119395027339]
	TIME [epoch: 11.6 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048147283393976226		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.048147283393976226 | validation: 0.046410708090688535]
	TIME [epoch: 11.6 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04926448530793014		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.04926448530793014 | validation: 0.04915635425522697]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04678082666688567		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.04678082666688567 | validation: 0.054426940796005]
	TIME [epoch: 11.6 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04347101895493497		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.04347101895493497 | validation: 0.06379459284889062]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0449160867761524		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.0449160867761524 | validation: 0.05602997964734376]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05095202338380282		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.05095202338380282 | validation: 0.046191812144486484]
	TIME [epoch: 11.6 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04937125633428542		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.04937125633428542 | validation: 0.053567077152502966]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046171150989956306		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.046171150989956306 | validation: 0.05472554427039279]
	TIME [epoch: 11.6 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04750188744581118		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.04750188744581118 | validation: 0.05248448008134107]
	TIME [epoch: 11.6 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04414989289873768		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.04414989289873768 | validation: 0.056063013793218916]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04447919227079138		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.04447919227079138 | validation: 0.05346675749438282]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041897771753613575		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.041897771753613575 | validation: 0.04922761932379086]
	TIME [epoch: 11.6 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04662347363894095		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.04662347363894095 | validation: 0.056265575810818494]
	TIME [epoch: 11.6 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044506681768487016		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.044506681768487016 | validation: 0.05220323564315104]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0429900428143511		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.0429900428143511 | validation: 0.05347958490255367]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04523889874528244		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.04523889874528244 | validation: 0.05018536963215767]
	TIME [epoch: 11.6 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044570763589484405		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.044570763589484405 | validation: 0.05950928278806983]
	TIME [epoch: 11.6 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04162650089327677		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.04162650089327677 | validation: 0.04985939613511287]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044139371513398515		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.044139371513398515 | validation: 0.05214260123605511]
	TIME [epoch: 11.6 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0453300006536513		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.0453300006536513 | validation: 0.05373948927064218]
	TIME [epoch: 11.6 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04719788275348779		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.04719788275348779 | validation: 0.05164298456857153]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04426649701824466		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.04426649701824466 | validation: 0.05187167399708234]
	TIME [epoch: 11.6 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04891580002795323		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.04891580002795323 | validation: 0.052687491563662786]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048404468816159826		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.048404468816159826 | validation: 0.050832236194871906]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04708582345888566		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.04708582345888566 | validation: 0.052269870924704843]
	TIME [epoch: 11.6 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04637725107907612		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.04637725107907612 | validation: 0.05131219483899861]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046975398938568766		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.046975398938568766 | validation: 0.05803459518590223]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04892036882205744		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.04892036882205744 | validation: 0.05559859525618461]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049681178213481794		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.049681178213481794 | validation: 0.051655139871372685]
	TIME [epoch: 11.6 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04563815155136428		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.04563815155136428 | validation: 0.05449644522313765]
	TIME [epoch: 11.6 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045703859976982605		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.045703859976982605 | validation: 0.04909182959425459]
	TIME [epoch: 11.6 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04611999668002489		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.04611999668002489 | validation: 0.04307902954387652]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1661.pth
	Model improved!!!
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04502330408516147		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.04502330408516147 | validation: 0.04424590413869801]
	TIME [epoch: 11.6 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04414682387704729		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.04414682387704729 | validation: 0.06798937863016707]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04606441096388393		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.04606441096388393 | validation: 0.051725063850444855]
	TIME [epoch: 11.6 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048206182802052355		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.048206182802052355 | validation: 0.04961333161192465]
	TIME [epoch: 11.6 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04648483659446595		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.04648483659446595 | validation: 0.05617056701649175]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04319386480210444		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.04319386480210444 | validation: 0.04830865530292178]
	TIME [epoch: 11.6 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044340535332556025		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.044340535332556025 | validation: 0.051125500330776376]
	TIME [epoch: 11.6 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04595041917179091		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.04595041917179091 | validation: 0.054102386213121786]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04691625366295635		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.04691625366295635 | validation: 0.04928812211195698]
	TIME [epoch: 11.6 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04481143058271849		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.04481143058271849 | validation: 0.05302413884872556]
	TIME [epoch: 11.6 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04359157942046692		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.04359157942046692 | validation: 0.051426655266090256]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045543804413709935		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.045543804413709935 | validation: 0.0573532996584204]
	TIME [epoch: 11.6 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04208573328050782		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.04208573328050782 | validation: 0.05358689139873777]
	TIME [epoch: 11.6 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04580954553771727		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.04580954553771727 | validation: 0.05688332057818943]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04566340997895651		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.04566340997895651 | validation: 0.05818958555266655]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04574648512436974		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.04574648512436974 | validation: 0.05542171294295909]
	TIME [epoch: 11.6 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046910217147959656		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.046910217147959656 | validation: 0.049436667579945505]
	TIME [epoch: 11.6 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04553428909802521		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.04553428909802521 | validation: 0.059939982663295456]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05179608495443587		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.05179608495443587 | validation: 0.04801693211659042]
	TIME [epoch: 11.6 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04328410499040941		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.04328410499040941 | validation: 0.04676914412520091]
	TIME [epoch: 11.6 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04735725810009723		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.04735725810009723 | validation: 0.04766908677053089]
	TIME [epoch: 11.6 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047505358871612884		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.047505358871612884 | validation: 0.052399683623255394]
	TIME [epoch: 11.6 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04300263906012497		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.04300263906012497 | validation: 0.05833004119318454]
	TIME [epoch: 11.6 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04413104873901431		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.04413104873901431 | validation: 0.052464507226387236]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048985806226694226		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.048985806226694226 | validation: 0.053128464909826756]
	TIME [epoch: 11.6 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04595053204814948		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.04595053204814948 | validation: 0.05584926462227612]
	TIME [epoch: 11.6 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04712064788946283		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.04712064788946283 | validation: 0.05083086506086065]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04750804093053945		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.04750804093053945 | validation: 0.0509932817817964]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04854589385877302		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.04854589385877302 | validation: 0.05366150632523806]
	TIME [epoch: 11.6 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05018847672160967		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.05018847672160967 | validation: 0.04925645179803299]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047259667313329284		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.047259667313329284 | validation: 0.04845888636294464]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04564856360550017		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.04564856360550017 | validation: 0.056180302853777495]
	TIME [epoch: 11.6 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04682124016216251		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.04682124016216251 | validation: 0.04977689665012519]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045099844786142		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.045099844786142 | validation: 0.050062035617682944]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04326369571520515		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.04326369571520515 | validation: 0.05163851301947609]
	TIME [epoch: 11.6 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044212921684266424		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.044212921684266424 | validation: 0.057228442597783924]
	TIME [epoch: 11.6 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046349784597777444		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.046349784597777444 | validation: 0.05178046411289388]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04388943908279771		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.04388943908279771 | validation: 0.05251113741303597]
	TIME [epoch: 11.6 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04551674289248345		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.04551674289248345 | validation: 0.05159937804695584]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04433097812000218		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.04433097812000218 | validation: 0.05281496990446761]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04677123693563368		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.04677123693563368 | validation: 0.05332567098242842]
	TIME [epoch: 11.6 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04809558849590927		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.04809558849590927 | validation: 0.04789822554544911]
	TIME [epoch: 11.6 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04576579000804164		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.04576579000804164 | validation: 0.05541718590811222]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0489297950927684		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.0489297950927684 | validation: 0.05087839963320938]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04785925018158051		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.04785925018158051 | validation: 0.053649240386319644]
	TIME [epoch: 11.6 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04131091310684902		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.04131091310684902 | validation: 0.05273536329695576]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049855907718558315		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.049855907718558315 | validation: 0.055785642738012814]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04603837516417575		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.04603837516417575 | validation: 0.046612241200490026]
	TIME [epoch: 11.6 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04469152869690525		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.04469152869690525 | validation: 0.05306934596889232]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04649479445501003		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.04649479445501003 | validation: 0.052572374165592815]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04611315357942633		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.04611315357942633 | validation: 0.050928988731709826]
	TIME [epoch: 11.6 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04332906855701085		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.04332906855701085 | validation: 0.04607401587670859]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046925020931543236		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.046925020931543236 | validation: 0.05115788403265345]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04435954315484447		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.04435954315484447 | validation: 0.05391303701528991]
	TIME [epoch: 11.6 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046537113252215434		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.046537113252215434 | validation: 0.054785443579277386]
	TIME [epoch: 11.6 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04505581597088901		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.04505581597088901 | validation: 0.048393989489095686]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045033008528132135		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.045033008528132135 | validation: 0.05773265278541548]
	TIME [epoch: 11.6 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047890621808024246		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.047890621808024246 | validation: 0.04545717727311467]
	TIME [epoch: 11.6 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0464521181151356		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.0464521181151356 | validation: 0.050101264997230624]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04418367283468701		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.04418367283468701 | validation: 0.05705746112938705]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048206693478150625		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.048206693478150625 | validation: 0.05190476674647665]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043732732641338604		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.043732732641338604 | validation: 0.05033790422579897]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047290356400428904		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.047290356400428904 | validation: 0.04848586139514193]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04535329549164422		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.04535329549164422 | validation: 0.04785750962858761]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044381881391674934		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.044381881391674934 | validation: 0.04758685807768112]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04396566800788092		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.04396566800788092 | validation: 0.05168302623400042]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043808936938612486		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.043808936938612486 | validation: 0.05473411332677035]
	TIME [epoch: 11.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04709905879456073		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.04709905879456073 | validation: 0.053275833646271]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044129352838691446		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.044129352838691446 | validation: 0.0489694454601701]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047099905392835706		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.047099905392835706 | validation: 0.048159189397263304]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04530912337539108		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.04530912337539108 | validation: 0.05018239121509272]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04481188949380023		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.04481188949380023 | validation: 0.04757980391408663]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043543816095579814		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.043543816095579814 | validation: 0.053613181716354034]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04613142760867897		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.04613142760867897 | validation: 0.05149095674351333]
	TIME [epoch: 11.6 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04755818270537744		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.04755818270537744 | validation: 0.05213162696728521]
	TIME [epoch: 11.6 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044086530744111285		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.044086530744111285 | validation: 0.048426982015302995]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04448466584043192		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.04448466584043192 | validation: 0.04461546078947981]
	TIME [epoch: 11.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04205663873537127		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.04205663873537127 | validation: 0.051171373353072605]
	TIME [epoch: 11.6 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044609546745415854		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.044609546745415854 | validation: 0.05514248975816946]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04546829442779822		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.04546829442779822 | validation: 0.054172323631665624]
	TIME [epoch: 11.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045414819787612595		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.045414819787612595 | validation: 0.05580850061667328]
	TIME [epoch: 11.6 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04087218641477516		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.04087218641477516 | validation: 0.05030210853580032]
	TIME [epoch: 11.6 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04184841885615441		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.04184841885615441 | validation: 0.04842146367126661]
	TIME [epoch: 11.6 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04636569331716909		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.04636569331716909 | validation: 0.045683336639133924]
	TIME [epoch: 11.6 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044880981766329174		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.044880981766329174 | validation: 0.0487838326154164]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040682205609874116		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.040682205609874116 | validation: 0.04647124792992846]
	TIME [epoch: 11.6 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04346790398834438		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.04346790398834438 | validation: 0.04535909166978958]
	TIME [epoch: 11.6 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04164212307286003		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.04164212307286003 | validation: 0.0469934013560941]
	TIME [epoch: 11.6 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04434506289175644		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.04434506289175644 | validation: 0.05158943329225028]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04154038303789898		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.04154038303789898 | validation: 0.04281235576130034]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1751.pth
	Model improved!!!
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043115526226772824		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.043115526226772824 | validation: 0.045583033201619355]
	TIME [epoch: 11.6 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04366008180884475		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.04366008180884475 | validation: 0.05023896519165021]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045628559347392614		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.045628559347392614 | validation: 0.06248716475499582]
	TIME [epoch: 11.6 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04530019784962003		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.04530019784962003 | validation: 0.04561861408033601]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048906872697295586		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.048906872697295586 | validation: 0.05605234431739351]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042968103699244496		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.042968103699244496 | validation: 0.056559571046666986]
	TIME [epoch: 11.6 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04425696862234108		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.04425696862234108 | validation: 0.050844080388550206]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04193034065606201		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.04193034065606201 | validation: 0.05676035445429003]
	TIME [epoch: 11.6 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04443315322337761		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.04443315322337761 | validation: 0.05088618359397344]
	TIME [epoch: 11.6 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04395935761016941		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.04395935761016941 | validation: 0.05797433450157029]
	TIME [epoch: 11.6 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04101631348477791		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.04101631348477791 | validation: 0.045181752952370875]
	TIME [epoch: 11.6 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04175464253161563		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.04175464253161563 | validation: 0.0498236757088278]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04422958594693525		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.04422958594693525 | validation: 0.05525030450206304]
	TIME [epoch: 11.6 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04840882385559181		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.04840882385559181 | validation: 0.06054550022971034]
	TIME [epoch: 11.6 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048902869764193675		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.048902869764193675 | validation: 0.04970917322974094]
	TIME [epoch: 11.6 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042771871768238705		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.042771871768238705 | validation: 0.0479281109784338]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04298796052380156		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.04298796052380156 | validation: 0.053188571144935234]
	TIME [epoch: 11.6 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04335985162225585		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.04335985162225585 | validation: 0.0489819750060269]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04481048944803917		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.04481048944803917 | validation: 0.05126001536841532]
	TIME [epoch: 11.6 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045824223268023045		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.045824223268023045 | validation: 0.048018929183374866]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04535040545943548		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.04535040545943548 | validation: 0.05099774683309]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045333903546018905		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.045333903546018905 | validation: 0.05103957742654149]
	TIME [epoch: 11.6 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04387550083184933		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.04387550083184933 | validation: 0.05410640858068088]
	TIME [epoch: 11.6 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04491375260356897		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.04491375260356897 | validation: 0.04585998013146579]
	TIME [epoch: 11.6 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04515347554566678		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.04515347554566678 | validation: 0.058963474021889575]
	TIME [epoch: 11.6 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04210189679340441		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.04210189679340441 | validation: 0.05041599003610239]
	TIME [epoch: 11.6 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04528464746331222		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.04528464746331222 | validation: 0.053672797221649145]
	TIME [epoch: 11.6 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04489107817823545		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.04489107817823545 | validation: 0.04830654642738651]
	TIME [epoch: 11.6 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04452364337084981		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.04452364337084981 | validation: 0.05006854702577535]
	TIME [epoch: 11.6 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0450929651970854		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.0450929651970854 | validation: 0.04627676690305051]
	TIME [epoch: 11.6 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04562423693769728		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.04562423693769728 | validation: 0.051027899953189196]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0441937052471899		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.0441937052471899 | validation: 0.05211801162710133]
	TIME [epoch: 11.6 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04379077118550216		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.04379077118550216 | validation: 0.05878743381981732]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048080174455258674		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.048080174455258674 | validation: 0.052073316402364594]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04614019629196175		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.04614019629196175 | validation: 0.056415670349710456]
	TIME [epoch: 11.6 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045429572322841234		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.045429572322841234 | validation: 0.05225185318225961]
	TIME [epoch: 11.6 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043902496746037425		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.043902496746037425 | validation: 0.05202097756831291]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04600289775475087		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.04600289775475087 | validation: 0.043198277906984134]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04499491039170694		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.04499491039170694 | validation: 0.05266751156007869]
	TIME [epoch: 11.6 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04203913628289873		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.04203913628289873 | validation: 0.04983268293139077]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046887006365490855		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.046887006365490855 | validation: 0.05468961303824879]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046337609345427855		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.046337609345427855 | validation: 0.05209278748742634]
	TIME [epoch: 11.6 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04531355106794344		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.04531355106794344 | validation: 0.05799056000408839]
	TIME [epoch: 11.6 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04195172959149138		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.04195172959149138 | validation: 0.04777615684253299]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04566802053717424		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.04566802053717424 | validation: 0.053009349498322866]
	TIME [epoch: 11.6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04623028185952832		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.04623028185952832 | validation: 0.044465406270233966]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044494180225970174		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.044494180225970174 | validation: 0.056099897607783174]
	TIME [epoch: 11.6 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045918928171952665		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.045918928171952665 | validation: 0.04608108515977734]
	TIME [epoch: 11.6 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042885234649997175		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.042885234649997175 | validation: 0.05197944757087401]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04186971963039393		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.04186971963039393 | validation: 0.04672723686002036]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04697773845168066		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.04697773845168066 | validation: 0.04637453888520149]
	TIME [epoch: 11.6 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046233745140244906		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.046233745140244906 | validation: 0.055487675136008364]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04462894873684705		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.04462894873684705 | validation: 0.052205483947679064]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04345451510823677		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.04345451510823677 | validation: 0.055811266081624795]
	TIME [epoch: 11.6 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0470123427000291		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.0470123427000291 | validation: 0.05572877328283888]
	TIME [epoch: 11.6 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04463232466338247		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.04463232466338247 | validation: 0.05946666948994848]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047418665540968505		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.047418665540968505 | validation: 0.04956023191635351]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04672811573017489		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.04672811573017489 | validation: 0.051781072987708114]
	TIME [epoch: 11.6 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04394292873807809		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.04394292873807809 | validation: 0.04692348069923291]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041696481759028674		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.041696481759028674 | validation: 0.04739228803392215]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04337156819635619		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.04337156819635619 | validation: 0.048196427739448676]
	TIME [epoch: 11.6 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044626011438330865		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.044626011438330865 | validation: 0.049870389797600105]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044234960306542344		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.044234960306542344 | validation: 0.045212982415395946]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04628229598544078		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.04628229598544078 | validation: 0.05180184650583464]
	TIME [epoch: 11.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04859056872027695		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.04859056872027695 | validation: 0.04731115774872697]
	TIME [epoch: 11.6 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04277283789217584		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.04277283789217584 | validation: 0.04457997334314598]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0456715360604736		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.0456715360604736 | validation: 0.04881917195263427]
	TIME [epoch: 11.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042574578971370104		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.042574578971370104 | validation: 0.047892454408412534]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045727938939804376		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.045727938939804376 | validation: 0.05068300274327685]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04895452174936735		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.04895452174936735 | validation: 0.044423547713830294]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04419984219155071		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.04419984219155071 | validation: 0.040729603615977224]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1822.pth
	Model improved!!!
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041315356036037386		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.041315356036037386 | validation: 0.0482288801799698]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04896461216790229		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.04896461216790229 | validation: 0.04791149282200129]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04758781839371093		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.04758781839371093 | validation: 0.05328339514477108]
	TIME [epoch: 11.6 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042355235609520626		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.042355235609520626 | validation: 0.04996573063338135]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04503442440308312		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.04503442440308312 | validation: 0.04728414723944109]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043975706903904135		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.043975706903904135 | validation: 0.05682403102491211]
	TIME [epoch: 11.6 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045345380997557014		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.045345380997557014 | validation: 0.04667614169425492]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0431669283438082		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.0431669283438082 | validation: 0.054038037330265215]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0426993314544506		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.0426993314544506 | validation: 0.041843513689837304]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044910433435104466		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.044910433435104466 | validation: 0.05566106218375549]
	TIME [epoch: 11.6 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04254626854861925		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.04254626854861925 | validation: 0.0488033245872721]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046973965605681886		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.046973965605681886 | validation: 0.04521250332640637]
	TIME [epoch: 11.6 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04626515188375785		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.04626515188375785 | validation: 0.04571233087687689]
	TIME [epoch: 11.6 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04829283145226211		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.04829283145226211 | validation: 0.05822851939887851]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04555918751962984		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.04555918751962984 | validation: 0.0518663788075202]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0465243585218056		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.0465243585218056 | validation: 0.04927771181919087]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04050502741962533		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.04050502741962533 | validation: 0.04870041368658228]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04594091887988465		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.04594091887988465 | validation: 0.05226428445631804]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047238988721869636		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.047238988721869636 | validation: 0.053594163092414694]
	TIME [epoch: 11.6 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04281399130495812		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.04281399130495812 | validation: 0.05072614608425937]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045234682233275356		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.045234682233275356 | validation: 0.04506569154376086]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041665614449721194		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.041665614449721194 | validation: 0.04562355412510456]
	TIME [epoch: 11.6 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04291509671195697		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.04291509671195697 | validation: 0.046883345319447475]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039833203018050156		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.039833203018050156 | validation: 0.049408630121031444]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04351972692637397		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.04351972692637397 | validation: 0.04812579630178368]
	TIME [epoch: 11.6 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04412848166116203		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.04412848166116203 | validation: 0.04602830666240977]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04613046735805339		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.04613046735805339 | validation: 0.056043663009031124]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04483701148804832		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.04483701148804832 | validation: 0.048340219806331436]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04584032656232864		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.04584032656232864 | validation: 0.038049182589315673]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1851.pth
	Model improved!!!
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04274985662106365		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.04274985662106365 | validation: 0.04395559133901273]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04455218947278482		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.04455218947278482 | validation: 0.047600335031716505]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0448404459519661		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.0448404459519661 | validation: 0.058737760830107004]
	TIME [epoch: 11.6 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04553020373397633		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.04553020373397633 | validation: 0.05151231427850773]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04380995665306519		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.04380995665306519 | validation: 0.04517075989998998]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042544241290687734		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.042544241290687734 | validation: 0.053232031869075574]
	TIME [epoch: 11.6 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047766837012277304		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.047766837012277304 | validation: 0.04614932017552179]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04394339875837715		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.04394339875837715 | validation: 0.046982269043879865]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04343857358800986		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.04343857358800986 | validation: 0.054342330440113155]
	TIME [epoch: 11.6 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044162219606989565		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.044162219606989565 | validation: 0.04840402894461311]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048140433051794454		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.048140433051794454 | validation: 0.05456418918870796]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046520657696152684		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.046520657696152684 | validation: 0.05440461745555385]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049038337618308		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.049038337618308 | validation: 0.055564946930597846]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04017310002953548		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.04017310002953548 | validation: 0.05387236669471156]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044476131807384196		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.044476131807384196 | validation: 0.05033201254752927]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046837574069752246		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.046837574069752246 | validation: 0.04330060564170792]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04226063428032537		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.04226063428032537 | validation: 0.046635060372709695]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0447743123314015		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.0447743123314015 | validation: 0.04746002619530335]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045401806802991634		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.045401806802991634 | validation: 0.06157718262237337]
	TIME [epoch: 11.6 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04638295884240501		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.04638295884240501 | validation: 0.04857861523727018]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04640318817833397		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.04640318817833397 | validation: 0.0488517514029677]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04574800251465683		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.04574800251465683 | validation: 0.05162576818260653]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044641904824075124		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.044641904824075124 | validation: 0.05208137355099501]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04274359311560287		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.04274359311560287 | validation: 0.046073703546372705]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040410180982555124		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.040410180982555124 | validation: 0.04494334372469802]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0433173298910452		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.0433173298910452 | validation: 0.04735914172251539]
	TIME [epoch: 11.6 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04513364678242134		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.04513364678242134 | validation: 0.04882046044684535]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044341130466973244		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.044341130466973244 | validation: 0.04855640222840533]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04536548231232755		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.04536548231232755 | validation: 0.05139492608045853]
	TIME [epoch: 11.6 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04544601704499699		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.04544601704499699 | validation: 0.057196152194617655]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046018735743403566		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.046018735743403566 | validation: 0.05054578989013024]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041383151018118305		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.041383151018118305 | validation: 0.05064786861956859]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04681853673606899		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.04681853673606899 | validation: 0.04742871278837692]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04449151273340927		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.04449151273340927 | validation: 0.04654272738131933]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041666907315212914		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.041666907315212914 | validation: 0.053446183691487445]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043633395161541265		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.043633395161541265 | validation: 0.04470360854063232]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045482110295964676		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.045482110295964676 | validation: 0.05771192318012621]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043728022596774316		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.043728022596774316 | validation: 0.05123622115115907]
	TIME [epoch: 11.6 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042308275854117686		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.042308275854117686 | validation: 0.04960671611469736]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04320493228526352		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.04320493228526352 | validation: 0.05203426061413092]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044002474465786104		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.044002474465786104 | validation: 0.054694426418964784]
	TIME [epoch: 11.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590470489061372		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.04590470489061372 | validation: 0.053493043843826645]
	TIME [epoch: 11.6 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048392640272211934		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.048392640272211934 | validation: 0.05272236617735595]
	TIME [epoch: 11.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04657883053321622		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.04657883053321622 | validation: 0.04702466034157525]
	TIME [epoch: 11.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047077141931292615		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.047077141931292615 | validation: 0.04941913803991055]
	TIME [epoch: 11.6 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04458979876336207		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.04458979876336207 | validation: 0.05705677481649571]
	TIME [epoch: 11.5 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04342408679726493		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.04342408679726493 | validation: 0.0368888745775466]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240310_003033/states/model_tr_study4_1898.pth
	Model improved!!!
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04241361683739359		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.04241361683739359 | validation: 0.049952358607923006]
	TIME [epoch: 11.6 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04050810997994764		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.04050810997994764 | validation: 0.053825517478948426]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04374427485532907		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.04374427485532907 | validation: 0.0500329304070681]
	TIME [epoch: 11.5 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047034375583874716		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.047034375583874716 | validation: 0.0521142007547706]
	TIME [epoch: 11.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0454133470611886		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.0454133470611886 | validation: 0.04595216084552897]
	TIME [epoch: 11.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043830306847204015		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.043830306847204015 | validation: 0.0517442833316516]
	TIME [epoch: 11.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042812756492265305		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.042812756492265305 | validation: 0.0510718020937075]
	TIME [epoch: 11.6 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04355554310936295		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.04355554310936295 | validation: 0.05579962534901869]
	TIME [epoch: 11.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04288182153945001		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.04288182153945001 | validation: 0.05540865948032331]
	TIME [epoch: 11.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045953604331103834		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.045953604331103834 | validation: 0.04236118528151453]
	TIME [epoch: 11.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044988692591560735		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.044988692591560735 | validation: 0.052946328215482334]
	TIME [epoch: 11.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046711610906890216		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.046711610906890216 | validation: 0.05236170593630481]
	TIME [epoch: 11.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05068824241358374		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.05068824241358374 | validation: 0.040902380960149164]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04476563110272088		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.04476563110272088 | validation: 0.052959289138641646]
	TIME [epoch: 11.6 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04665963023610739		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.04665963023610739 | validation: 0.05346116301472979]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045009986496377		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.045009986496377 | validation: 0.05338277292891089]
	TIME [epoch: 11.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04573449380467023		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.04573449380467023 | validation: 0.049617740445340244]
	TIME [epoch: 11.6 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048357287047663414		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.048357287047663414 | validation: 0.045336343721449256]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04159857940088849		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.04159857940088849 | validation: 0.04686267550241194]
	TIME [epoch: 11.5 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04433900712443479		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.04433900712443479 | validation: 0.05704553680254877]
	TIME [epoch: 11.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04222570758317716		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.04222570758317716 | validation: 0.04880771671368869]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046019290859485765		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.046019290859485765 | validation: 0.045876324443255775]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043753503007360396		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.043753503007360396 | validation: 0.04317178157530289]
	TIME [epoch: 11.6 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04417453709063737		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.04417453709063737 | validation: 0.044162922244840315]
	TIME [epoch: 11.6 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04612949786281928		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.04612949786281928 | validation: 0.04779727711617469]
	TIME [epoch: 11.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04458616789074661		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.04458616789074661 | validation: 0.05021153517837418]
	TIME [epoch: 11.5 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04336332827004518		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.04336332827004518 | validation: 0.04979741972217629]
	TIME [epoch: 11.6 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046292017492597606		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.046292017492597606 | validation: 0.04977973359577323]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04497912645111161		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.04497912645111161 | validation: 0.049489772513734105]
	TIME [epoch: 11.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04209108914291568		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.04209108914291568 | validation: 0.05000258053087471]
	TIME [epoch: 11.6 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04658098346659396		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.04658098346659396 | validation: 0.047851640971745615]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045796032307536136		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.045796032307536136 | validation: 0.04897499814697683]
	TIME [epoch: 11.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046804943032214115		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.046804943032214115 | validation: 0.05409799893857224]
	TIME [epoch: 11.6 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04519541646161652		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.04519541646161652 | validation: 0.05501185378403776]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04820066072124388		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.04820066072124388 | validation: 0.04964726293085826]
	TIME [epoch: 11.5 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04654730920841769		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.04654730920841769 | validation: 0.04894924939919335]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04584414697261616		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.04584414697261616 | validation: 0.05516381096638114]
	TIME [epoch: 11.6 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04401675336201238		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.04401675336201238 | validation: 0.048203846026771247]
	TIME [epoch: 11.5 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045204429707283486		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.045204429707283486 | validation: 0.05341194987552006]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04558016253942217		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.04558016253942217 | validation: 0.05377612462437924]
	TIME [epoch: 11.6 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0456308315564244		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.0456308315564244 | validation: 0.05441505033208555]
	TIME [epoch: 11.5 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040942253703128276		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.040942253703128276 | validation: 0.055969668801920856]
	TIME [epoch: 11.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047860781058359024		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.047860781058359024 | validation: 0.046908417681387996]
	TIME [epoch: 11.6 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04318753148960723		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.04318753148960723 | validation: 0.04854935962520915]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045730184145410725		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.045730184145410725 | validation: 0.0515612526975864]
	TIME [epoch: 11.5 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04808852993762032		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.04808852993762032 | validation: 0.0470708980332151]
	TIME [epoch: 11.6 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043976108903667384		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.043976108903667384 | validation: 0.0453843160382565]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04351022457555214		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.04351022457555214 | validation: 0.05710150677831266]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04484023998823949		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.04484023998823949 | validation: 0.05501865553853663]
	TIME [epoch: 11.6 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04201940000394209		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.04201940000394209 | validation: 0.04979139357813825]
	TIME [epoch: 11.6 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046326085413930435		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.046326085413930435 | validation: 0.049663599292696835]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04300566911148369		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.04300566911148369 | validation: 0.04244171640452489]
	TIME [epoch: 11.6 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0438517468385546		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.0438517468385546 | validation: 0.0444365123747557]
	TIME [epoch: 11.5 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04855353109388604		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.04855353109388604 | validation: 0.053200408134116695]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05031609424352952		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.05031609424352952 | validation: 0.05058839180296088]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04260005325493282		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.04260005325493282 | validation: 0.053006746379290835]
	TIME [epoch: 11.6 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04564535886162593		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.04564535886162593 | validation: 0.04641351726691731]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04433169445434266		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.04433169445434266 | validation: 0.04736537408360688]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045666048997900145		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.045666048997900145 | validation: 0.05335148876399762]
	TIME [epoch: 11.6 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04343623802054078		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.04343623802054078 | validation: 0.05360343373486897]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04548945944994604		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.04548945944994604 | validation: 0.048973916158507505]
	TIME [epoch: 11.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04581681351210088		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.04581681351210088 | validation: 0.05124495273932563]
	TIME [epoch: 11.6 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04266123148911591		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.04266123148911591 | validation: 0.049459056865962574]
	TIME [epoch: 11.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04711542530461454		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.04711542530461454 | validation: 0.05229917389613418]
	TIME [epoch: 11.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0408030455174759		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.0408030455174759 | validation: 0.05029191142260062]
	TIME [epoch: 11.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04686534182866299		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.04686534182866299 | validation: 0.04285267826975349]
	TIME [epoch: 11.6 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04526328359799014		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.04526328359799014 | validation: 0.04375671022255105]
	TIME [epoch: 11.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04343228033968369		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.04343228033968369 | validation: 0.054171641226801785]
	TIME [epoch: 11.5 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04578514021606188		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.04578514021606188 | validation: 0.05416234249185095]
	TIME [epoch: 11.6 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04654657458282154		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.04654657458282154 | validation: 0.05318427970857089]
	TIME [epoch: 11.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046066938699653615		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.046066938699653615 | validation: 0.05694816764051369]
	TIME [epoch: 11.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041158544461406765		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.041158544461406765 | validation: 0.046321932587801554]
	TIME [epoch: 11.6 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04787708202695251		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.04787708202695251 | validation: 0.03958624096061147]
	TIME [epoch: 11.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0458279103410418		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.0458279103410418 | validation: 0.048718871474816884]
	TIME [epoch: 11.6 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049443084633224985		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.049443084633224985 | validation: 0.046226862201809854]
	TIME [epoch: 11.6 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044641443813374045		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.044641443813374045 | validation: 0.0449191718698756]
	TIME [epoch: 11.6 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044255896994267185		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.044255896994267185 | validation: 0.043948310609349034]
	TIME [epoch: 11.5 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04581332897475623		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.04581332897475623 | validation: 0.05628097099570084]
	TIME [epoch: 11.6 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04232345687614811		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.04232345687614811 | validation: 0.04805157190067307]
	TIME [epoch: 11.6 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04152156970275884		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.04152156970275884 | validation: 0.0439859613784993]
	TIME [epoch: 11.5 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042850492671029236		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.042850492671029236 | validation: 0.05223160670481889]
	TIME [epoch: 11.6 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04429107558060062		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.04429107558060062 | validation: 0.05989021634071598]
	TIME [epoch: 11.6 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038937635673436576		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.038937635673436576 | validation: 0.05832544050859493]
	TIME [epoch: 11.5 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046011380268368526		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.046011380268368526 | validation: 0.05040086262301051]
	TIME [epoch: 11.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0456061834753352		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.0456061834753352 | validation: 0.05327029858336161]
	TIME [epoch: 11.6 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0409468608911058		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.0409468608911058 | validation: 0.05185649806526207]
	TIME [epoch: 11.6 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042449608443705204		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.042449608443705204 | validation: 0.049778251507286486]
	TIME [epoch: 11.5 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04655625559406766		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.04655625559406766 | validation: 0.04553703345799454]
	TIME [epoch: 11.6 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04263688094217053		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.04263688094217053 | validation: 0.049929987321309544]
	TIME [epoch: 11.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04719412827575292		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.04719412827575292 | validation: 0.05492073719132229]
	TIME [epoch: 11.5 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04557737493349123		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.04557737493349123 | validation: 0.04779624641269376]
	TIME [epoch: 11.6 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04555201313035434		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.04555201313035434 | validation: 0.04585417741147163]
	TIME [epoch: 11.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04515824425468451		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.04515824425468451 | validation: 0.04613429718757433]
	TIME [epoch: 11.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04623479267379442		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.04623479267379442 | validation: 0.051348339470869815]
	TIME [epoch: 11.6 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04278123012915632		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.04278123012915632 | validation: 0.051833735841466215]
	TIME [epoch: 11.6 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04470870149247773		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.04470870149247773 | validation: 0.051478394156987566]
	TIME [epoch: 11.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04324996543130134		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.04324996543130134 | validation: 0.046271812198465476]
	TIME [epoch: 11.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04710342893254694		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.04710342893254694 | validation: 0.04928362745967808]
	TIME [epoch: 11.6 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04533931460917729		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.04533931460917729 | validation: 0.04639722649603602]
	TIME [epoch: 11.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04421732244453554		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.04421732244453554 | validation: 0.04975585859691641]
	TIME [epoch: 11.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04065091996647083		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.04065091996647083 | validation: 0.04583224293139218]
	TIME [epoch: 11.6 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04261405596403864		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.04261405596403864 | validation: 0.05522207690529327]
	TIME [epoch: 11.5 sec]
Finished training in 23309.648 seconds.
