Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r3', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1918689616

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.190007844487512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.190007844487512 | validation: 7.930903054504867]
	TIME [epoch: 79.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.004506935921702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.004506935921702 | validation: 7.854458229146314]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.233854280650864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.233854280650864 | validation: 7.165478792674552]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.913145924337731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.913145924337731 | validation: 6.414344863511519]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.888115948037554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.888115948037554 | validation: 6.450168871064885]
	TIME [epoch: 8.54 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.72839722635713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.72839722635713 | validation: 6.345679088866311]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.829358108623017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.829358108623017 | validation: 6.2682868707634345]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.439218214474065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.439218214474065 | validation: 6.191568432960242]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.495299167553466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.495299167553466 | validation: 6.270074481819989]
	TIME [epoch: 8.56 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.353349913924958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.353349913924958 | validation: 6.394273022708101]
	TIME [epoch: 8.54 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.432465152282994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.432465152282994 | validation: 6.247924849918035]
	TIME [epoch: 8.54 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.36012283175916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.36012283175916 | validation: 6.235043493570998]
	TIME [epoch: 8.58 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.2608827885793845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2608827885793845 | validation: 6.631969956990709]
	TIME [epoch: 8.55 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.2679974557967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2679974557967 | validation: 6.545807919282751]
	TIME [epoch: 8.54 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.332037357702183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.332037357702183 | validation: 6.055989956422254]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.201990684871346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.201990684871346 | validation: 7.72825204353815]
	TIME [epoch: 8.57 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.451378420598712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.451378420598712 | validation: 6.18825735232985]
	TIME [epoch: 8.54 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.261477887218003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.261477887218003 | validation: 6.103256023469891]
	TIME [epoch: 8.53 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.21019952745846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.21019952745846 | validation: 6.093131886155355]
	TIME [epoch: 8.53 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.136580097225504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.136580097225504 | validation: 6.1195939085711455]
	TIME [epoch: 8.56 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.16186171954555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.16186171954555 | validation: 6.201856343494019]
	TIME [epoch: 8.53 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.082459181137219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.082459181137219 | validation: 5.960792855292356]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.118051520050766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.118051520050766 | validation: 5.937216046020578]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.032111268012299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.032111268012299 | validation: 5.795427707620453]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.917976894530062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.917976894530062 | validation: 5.5941802030535825]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.683059640369681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.683059640369681 | validation: 5.373978990350409]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.338880087820602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.338880087820602 | validation: 5.191384313833551]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.890654945655896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.890654945655896 | validation: 3.576439688405846]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.145257683116869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.145257683116869 | validation: 3.1840581303877427]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.945520810962532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.945520810962532 | validation: 3.192062117080982]
	TIME [epoch: 8.54 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.3737028144493983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3737028144493983 | validation: 3.7172741606602338]
	TIME [epoch: 8.55 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.30567268637893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.30567268637893 | validation: 2.621921776425777]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.962787426243133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.962787426243133 | validation: 4.382746573906695]
	TIME [epoch: 8.54 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.6106977737637544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6106977737637544 | validation: 1.653671551189679]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0325885983559084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0325885983559084 | validation: 2.759274841266052]
	TIME [epoch: 8.56 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.9440511060175125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9440511060175125 | validation: 2.1551111047805516]
	TIME [epoch: 8.56 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9353589228392498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9353589228392498 | validation: 1.524953672083176]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.088361406045761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.088361406045761 | validation: 2.2283860529722705]
	TIME [epoch: 8.54 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.001436797494482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.001436797494482 | validation: 2.5215417688723827]
	TIME [epoch: 8.56 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9944280533468839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9944280533468839 | validation: 1.4277889087298368]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8543398524209713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8543398524209713 | validation: 1.850996782224568]
	TIME [epoch: 8.54 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.853707864515367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.853707864515367 | validation: 1.550860805689867]
	TIME [epoch: 8.54 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6973968193563624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6973968193563624 | validation: 1.6194275152103925]
	TIME [epoch: 8.56 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.880805030669105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.880805030669105 | validation: 1.6353840248115774]
	TIME [epoch: 8.54 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6257534616400968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6257534616400968 | validation: 1.4015201161062416]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7154887237005312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7154887237005312 | validation: 1.5277641115816867]
	TIME [epoch: 8.54 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5516290632807528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5516290632807528 | validation: 1.6840929618715097]
	TIME [epoch: 8.57 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8738595935304017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8738595935304017 | validation: 1.5025014146630844]
	TIME [epoch: 8.54 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5750300838644988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5750300838644988 | validation: 1.2967532575166172]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.63704298343253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.63704298343253 | validation: 1.5703941223727855]
	TIME [epoch: 8.54 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6517680039472324		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 1.6517680039472324 | validation: 1.7478107436334764]
	TIME [epoch: 8.56 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.576243790710188		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 1.576243790710188 | validation: 1.8624293439003807]
	TIME [epoch: 8.55 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5377846928505516		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 1.5377846928505516 | validation: 1.302726943915093]
	TIME [epoch: 8.53 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.708628949336985		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 1.708628949336985 | validation: 1.238481822485614]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_54.pth
	Model improved!!!
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.446873821028459		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 1.446873821028459 | validation: 1.8373362680335092]
	TIME [epoch: 8.56 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.640876961631259		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 1.640876961631259 | validation: 1.2094506749647156]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4720406000875532		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 1.4720406000875532 | validation: 1.5079179847494864]
	TIME [epoch: 8.52 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5100750419031463		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 1.5100750419031463 | validation: 1.5807950991873316]
	TIME [epoch: 8.54 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.432102872146505		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 1.432102872146505 | validation: 1.383842080218349]
	TIME [epoch: 8.54 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4555461236135026		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 1.4555461236135026 | validation: 1.8592270344450634]
	TIME [epoch: 8.52 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.548401818156016		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 1.548401818156016 | validation: 2.623560240252539]
	TIME [epoch: 8.52 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7890223649371897		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 1.7890223649371897 | validation: 1.3015593956223757]
	TIME [epoch: 8.54 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4182473181705617		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 1.4182473181705617 | validation: 1.68784071545217]
	TIME [epoch: 8.54 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7819371335097725		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 1.7819371335097725 | validation: 2.4179539099137086]
	TIME [epoch: 8.53 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7081175958140669		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 1.7081175958140669 | validation: 1.7672063315121789]
	TIME [epoch: 8.53 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4498212606405578		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 1.4498212606405578 | validation: 1.3756423458584472]
	TIME [epoch: 8.55 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5270385639317678		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 1.5270385639317678 | validation: 1.6054771225368865]
	TIME [epoch: 8.53 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5880672739624415		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 1.5880672739624415 | validation: 1.443544359875488]
	TIME [epoch: 8.52 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5247166382610697		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 1.5247166382610697 | validation: 1.7755975920656892]
	TIME [epoch: 8.53 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.579178280911168		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 1.579178280911168 | validation: 1.3193313522755687]
	TIME [epoch: 8.55 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4472787448001625		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.4472787448001625 | validation: 1.3964037380914478]
	TIME [epoch: 8.53 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.556821475429568		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 1.556821475429568 | validation: 1.2481150892395088]
	TIME [epoch: 8.52 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2630616912353103		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 1.2630616912353103 | validation: 1.841816464473954]
	TIME [epoch: 8.52 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.498951916874244		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 1.498951916874244 | validation: 1.1202685472472373]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_74.pth
	Model improved!!!
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3193018217391193		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 1.3193018217391193 | validation: 1.7123493174684152]
	TIME [epoch: 8.53 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6739702062980288		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 1.6739702062980288 | validation: 1.5915999193657075]
	TIME [epoch: 8.52 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.443654752984944		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 1.443654752984944 | validation: 1.3619221905570476]
	TIME [epoch: 8.53 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4125471254272515		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 1.4125471254272515 | validation: 1.933344813868581]
	TIME [epoch: 8.56 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6291295545365156		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 1.6291295545365156 | validation: 2.8456008943445674]
	TIME [epoch: 8.53 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.629094820400627		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 1.629094820400627 | validation: 2.6849387271176735]
	TIME [epoch: 8.52 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6813819472934721		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 1.6813819472934721 | validation: 1.3152880605574422]
	TIME [epoch: 8.52 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3128361437721348		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 1.3128361437721348 | validation: 1.8194412672286027]
	TIME [epoch: 8.56 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4844574162850157		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 1.4844574162850157 | validation: 1.2839251641187197]
	TIME [epoch: 8.52 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.396018037870082		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 1.396018037870082 | validation: 2.896611952238888]
	TIME [epoch: 8.52 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7170238838105392		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 1.7170238838105392 | validation: 1.3183548009752482]
	TIME [epoch: 8.53 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2856413709394954		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 1.2856413709394954 | validation: 1.2936887301863185]
	TIME [epoch: 8.56 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.478555966955079		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 1.478555966955079 | validation: 1.1729428583166635]
	TIME [epoch: 8.54 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3722163749375833		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.3722163749375833 | validation: 1.5904406672851819]
	TIME [epoch: 8.53 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3128204121846845		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.3128204121846845 | validation: 1.3277627991493302]
	TIME [epoch: 8.53 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.446966624638113		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.446966624638113 | validation: 1.2890086152755535]
	TIME [epoch: 8.55 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2980401478520078		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 1.2980401478520078 | validation: 1.1214519418163758]
	TIME [epoch: 8.53 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3761911000433966		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 1.3761911000433966 | validation: 1.4446165333906151]
	TIME [epoch: 8.53 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2749207437739773		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 1.2749207437739773 | validation: 1.4265711509086865]
	TIME [epoch: 8.55 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3241601020635048		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 1.3241601020635048 | validation: 1.163942814572765]
	TIME [epoch: 8.53 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.328129484777326		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 1.328129484777326 | validation: 1.406752240020709]
	TIME [epoch: 8.54 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2096115662374776		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.2096115662374776 | validation: 1.2016405084978405]
	TIME [epoch: 8.54 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3807095361874258		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 1.3807095361874258 | validation: 1.394828682900924]
	TIME [epoch: 8.55 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3150785389710369		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.3150785389710369 | validation: 1.8469258429587811]
	TIME [epoch: 8.54 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3016855911242233		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.3016855911242233 | validation: 1.3188360294846184]
	TIME [epoch: 8.52 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3280657696841776		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.3280657696841776 | validation: 1.3913640734844848]
	TIME [epoch: 8.52 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2620049908484305		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.2620049908484305 | validation: 1.3760337955076472]
	TIME [epoch: 8.55 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2200462074247331		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.2200462074247331 | validation: 1.795791548273924]
	TIME [epoch: 8.52 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3124635523095498		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.3124635523095498 | validation: 1.1477912319626746]
	TIME [epoch: 8.52 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2760132619635163		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.2760132619635163 | validation: 1.1757885045076422]
	TIME [epoch: 8.52 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2862384655024997		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 1.2862384655024997 | validation: 1.2756141961381768]
	TIME [epoch: 8.55 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1537249329954844		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 1.1537249329954844 | validation: 1.210081289806491]
	TIME [epoch: 8.53 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4920413569515985		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 1.4920413569515985 | validation: 1.4526225806543165]
	TIME [epoch: 8.54 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3443937816650948		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.3443937816650948 | validation: 1.3116676514357217]
	TIME [epoch: 8.53 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2570044959283633		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.2570044959283633 | validation: 1.1365126933721352]
	TIME [epoch: 8.56 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2520793922001356		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.2520793922001356 | validation: 1.3051585902215335]
	TIME [epoch: 8.53 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3977360904625673		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.3977360904625673 | validation: 1.5312989539055508]
	TIME [epoch: 8.53 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2894824367717268		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 1.2894824367717268 | validation: 0.9602791629908136]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_112.pth
	Model improved!!!
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1898303825838776		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 1.1898303825838776 | validation: 1.766548593881219]
	TIME [epoch: 8.56 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4907183595733398		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 1.4907183595733398 | validation: 1.5106782010643967]
	TIME [epoch: 8.53 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3718461851369288		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.3718461851369288 | validation: 1.317718397979641]
	TIME [epoch: 8.54 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2345587317782978		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 1.2345587317782978 | validation: 1.182304065663292]
	TIME [epoch: 8.52 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2281715508408968		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 1.2281715508408968 | validation: 1.107638988466155]
	TIME [epoch: 8.56 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.237991132964538		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 1.237991132964538 | validation: 1.7632799228756895]
	TIME [epoch: 8.53 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.341966849549613		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 1.341966849549613 | validation: 1.4277815799807643]
	TIME [epoch: 8.53 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4143520263708353		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.4143520263708353 | validation: 1.50392910998884]
	TIME [epoch: 8.54 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2574684286826963		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 1.2574684286826963 | validation: 1.2286114232071963]
	TIME [epoch: 8.55 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2368670180163246		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 1.2368670180163246 | validation: 1.2003920755607578]
	TIME [epoch: 8.53 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1887102621299774		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 1.1887102621299774 | validation: 1.478907720245089]
	TIME [epoch: 8.53 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4613878978501986		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 1.4613878978501986 | validation: 0.9730759520758596]
	TIME [epoch: 8.55 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.263379840349336		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 1.263379840349336 | validation: 1.696689824857515]
	TIME [epoch: 8.54 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3047668887856412		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 1.3047668887856412 | validation: 1.017434394026219]
	TIME [epoch: 8.52 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.183612691571629		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 1.183612691571629 | validation: 1.1741197554911027]
	TIME [epoch: 8.53 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3413591415134734		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.3413591415134734 | validation: 1.5454537097314165]
	TIME [epoch: 8.55 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2456372147781036		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 1.2456372147781036 | validation: 1.320049058918263]
	TIME [epoch: 8.54 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2691576678022902		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 1.2691576678022902 | validation: 1.0600239706038934]
	TIME [epoch: 8.53 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.211648309999394		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 1.211648309999394 | validation: 1.3463072181206108]
	TIME [epoch: 8.53 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1823008230630103		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 1.1823008230630103 | validation: 0.9709301687649174]
	TIME [epoch: 8.56 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2665383604905511		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 1.2665383604905511 | validation: 0.9430895801285955]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_133.pth
	Model improved!!!
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3145564074354534		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 1.3145564074354534 | validation: 1.2822439415453823]
	TIME [epoch: 8.54 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3160636110453967		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 1.3160636110453967 | validation: 1.242850197762161]
	TIME [epoch: 8.54 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2705352577744717		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 1.2705352577744717 | validation: 1.2372422375461956]
	TIME [epoch: 8.57 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2711274175782512		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 1.2711274175782512 | validation: 1.3374024789417214]
	TIME [epoch: 8.54 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2981266684891006		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.2981266684891006 | validation: 1.527524485161217]
	TIME [epoch: 8.53 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3068808905346614		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 1.3068808905346614 | validation: 1.0486347709365287]
	TIME [epoch: 8.53 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2169432205767365		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 1.2169432205767365 | validation: 1.3950642867049123]
	TIME [epoch: 8.56 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2563222318295015		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 1.2563222318295015 | validation: 1.2232889188299438]
	TIME [epoch: 8.53 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1634354914167442		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 1.1634354914167442 | validation: 1.6529753259381872]
	TIME [epoch: 8.53 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2888259214623		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 1.2888259214623 | validation: 1.020158511680763]
	TIME [epoch: 8.52 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3465523746563342		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 1.3465523746563342 | validation: 1.3696935063971494]
	TIME [epoch: 8.55 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2186619587126277		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 1.2186619587126277 | validation: 1.220076950924076]
	TIME [epoch: 8.52 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1981565687584008		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 1.1981565687584008 | validation: 1.4194754215340764]
	TIME [epoch: 8.52 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2803353534682302		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 1.2803353534682302 | validation: 1.126696263736946]
	TIME [epoch: 8.52 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1737617038032415		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 1.1737617038032415 | validation: 1.0087278207779526]
	TIME [epoch: 8.55 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0942486441085242		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 1.0942486441085242 | validation: 1.608499362092687]
	TIME [epoch: 8.53 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3220235223972485		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 1.3220235223972485 | validation: 1.0846382800563599]
	TIME [epoch: 8.53 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.138551079815774		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 1.138551079815774 | validation: 1.162965882341698]
	TIME [epoch: 8.53 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1177569520414994		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 1.1177569520414994 | validation: 1.0152196026166738]
	TIME [epoch: 8.56 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1795680743276076		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 1.1795680743276076 | validation: 1.3008894091759258]
	TIME [epoch: 8.52 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0624213281789583		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 1.0624213281789583 | validation: 1.1313494450105877]
	TIME [epoch: 8.52 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0483783047868875		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 1.0483783047868875 | validation: 1.156114328019605]
	TIME [epoch: 8.54 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1717750963837823		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 1.1717750963837823 | validation: 1.299809180898185]
	TIME [epoch: 8.56 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1701188202041402		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 1.1701188202041402 | validation: 1.1609502629123878]
	TIME [epoch: 8.53 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1286289675692636		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 1.1286289675692636 | validation: 0.964474269037629]
	TIME [epoch: 8.53 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2169692565471044		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 1.2169692565471044 | validation: 0.9864932474547716]
	TIME [epoch: 8.55 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2538883925456323		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 1.2538883925456323 | validation: 0.9813950438850223]
	TIME [epoch: 8.54 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9976216507111062		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.9976216507111062 | validation: 0.858426243447693]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_161.pth
	Model improved!!!
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0246905276952774		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 1.0246905276952774 | validation: 2.0962334153163296]
	TIME [epoch: 8.52 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2678372430798504		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 1.2678372430798504 | validation: 1.2637076425035505]
	TIME [epoch: 8.56 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.081792500749399		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 1.081792500749399 | validation: 0.8613742955634385]
	TIME [epoch: 8.53 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1559902021683268		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 1.1559902021683268 | validation: 1.1408692902792306]
	TIME [epoch: 8.52 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0653870905002396		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 1.0653870905002396 | validation: 0.9880633666974756]
	TIME [epoch: 8.53 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0913699591451331		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 1.0913699591451331 | validation: 1.2865187937561475]
	TIME [epoch: 8.56 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1671013828117875		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 1.1671013828117875 | validation: 0.7754104349632948]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_168.pth
	Model improved!!!
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9685184052408309		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.9685184052408309 | validation: 1.3729901036596162]
	TIME [epoch: 8.53 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1605688120043198		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 1.1605688120043198 | validation: 0.9036582452523985]
	TIME [epoch: 8.52 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1224971347216275		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 1.1224971347216275 | validation: 1.2610906646816717]
	TIME [epoch: 8.55 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1576412061328487		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 1.1576412061328487 | validation: 1.2925376115599136]
	TIME [epoch: 8.52 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1223737144779249		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 1.1223737144779249 | validation: 1.4321583361468406]
	TIME [epoch: 8.53 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1104522728342172		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 1.1104522728342172 | validation: 0.8673095144619517]
	TIME [epoch: 8.53 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.029660772030347		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 1.029660772030347 | validation: 1.0483963158486846]
	TIME [epoch: 8.56 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0715601985541103		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 1.0715601985541103 | validation: 1.0303056239307087]
	TIME [epoch: 8.52 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2008407086358786		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 1.2008407086358786 | validation: 1.0299606659615308]
	TIME [epoch: 8.53 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1575574879397803		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 1.1575574879397803 | validation: 0.9038222338307027]
	TIME [epoch: 8.53 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0627682471945261		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 1.0627682471945261 | validation: 1.557538408403419]
	TIME [epoch: 8.57 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0473989460585498		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 1.0473989460585498 | validation: 0.9231541596741408]
	TIME [epoch: 8.53 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0355896402908786		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 1.0355896402908786 | validation: 1.0471600547758024]
	TIME [epoch: 8.53 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0810515785918091		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 1.0810515785918091 | validation: 0.883215705077664]
	TIME [epoch: 8.53 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1712328077503478		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 1.1712328077503478 | validation: 0.8413114650715854]
	TIME [epoch: 8.56 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1112177645001697		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 1.1112177645001697 | validation: 1.0477200710424142]
	TIME [epoch: 8.53 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0540701758158355		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 1.0540701758158355 | validation: 1.6202060871847297]
	TIME [epoch: 8.53 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.219274209426351		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 1.219274209426351 | validation: 1.419121715242863]
	TIME [epoch: 8.54 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9990225441643666		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.9990225441643666 | validation: 0.9396817485461189]
	TIME [epoch: 8.56 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0907653412284137		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 1.0907653412284137 | validation: 1.6203784959191316]
	TIME [epoch: 8.53 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.091687202640136		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 1.091687202640136 | validation: 0.9751765531017265]
	TIME [epoch: 8.53 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2440864061332881		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 1.2440864061332881 | validation: 1.4922802083711715]
	TIME [epoch: 8.55 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0542856469459507		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 1.0542856469459507 | validation: 0.8321853777642008]
	TIME [epoch: 8.54 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.072539380538267		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 1.072539380538267 | validation: 0.8521260629926807]
	TIME [epoch: 8.54 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9089794266067257		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.9089794266067257 | validation: 0.9887071497897985]
	TIME [epoch: 8.54 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8962561660325408		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.8962561660325408 | validation: 1.0958831709843944]
	TIME [epoch: 8.55 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.080805547582724		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 1.080805547582724 | validation: 0.8160745861320828]
	TIME [epoch: 8.54 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0503105691675048		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 1.0503105691675048 | validation: 0.7589053549498552]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_196.pth
	Model improved!!!
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.901526935506784		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.901526935506784 | validation: 0.9681139385037085]
	TIME [epoch: 8.52 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2150094958590851		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 1.2150094958590851 | validation: 0.9120115989078534]
	TIME [epoch: 8.56 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9834493366116769		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.9834493366116769 | validation: 2.4923333902931404]
	TIME [epoch: 8.53 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5470504144163764		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 1.5470504144163764 | validation: 1.269874560738468]
	TIME [epoch: 8.54 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0606436415861549		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 1.0606436415861549 | validation: 2.1091940947256584]
	TIME [epoch: 8.52 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6330953837058626		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 1.6330953837058626 | validation: 1.1787024540705218]
	TIME [epoch: 8.56 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4513416876389684		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 1.4513416876389684 | validation: 2.026533954475649]
	TIME [epoch: 8.53 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.578856300921432		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 1.578856300921432 | validation: 1.1865338789932514]
	TIME [epoch: 8.53 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3668480581652926		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 1.3668480581652926 | validation: 1.3305390467495348]
	TIME [epoch: 8.53 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9565514440450726		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 1.9565514440450726 | validation: 2.1122285782178967]
	TIME [epoch: 8.56 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2649988945709971		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 1.2649988945709971 | validation: 1.1828421476619901]
	TIME [epoch: 8.53 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0882935629452595		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 1.0882935629452595 | validation: 2.0799150022409654]
	TIME [epoch: 8.53 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0467944574929757		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 2.0467944574929757 | validation: 1.2180403836385194]
	TIME [epoch: 8.53 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2132725326466725		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 1.2132725326466725 | validation: 1.0342316936890483]
	TIME [epoch: 8.56 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.888219964390253		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 1.888219964390253 | validation: 1.7291007014768183]
	TIME [epoch: 8.53 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2382660540611148		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 1.2382660540611148 | validation: 1.1755559735675745]
	TIME [epoch: 8.53 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.063807748952868		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 1.063807748952868 | validation: 1.165322881542644]
	TIME [epoch: 8.53 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3833669910365303		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 1.3833669910365303 | validation: 1.2826480171346255]
	TIME [epoch: 8.56 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7439269311386376		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 1.7439269311386376 | validation: 1.0900092444083196]
	TIME [epoch: 8.54 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6884140028938799		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 1.6884140028938799 | validation: 1.221832692297291]
	TIME [epoch: 8.53 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.275042102553559		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 1.275042102553559 | validation: 0.959389953691968]
	TIME [epoch: 8.53 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0405114959206485		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 1.0405114959206485 | validation: 1.4620294348324538]
	TIME [epoch: 8.55 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3581070081162052		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 1.3581070081162052 | validation: 0.9044952958297842]
	TIME [epoch: 8.53 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1574541814557964		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 1.1574541814557964 | validation: 1.325370273556144]
	TIME [epoch: 8.55 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0682590350490828		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 1.0682590350490828 | validation: 1.3404501971831373]
	TIME [epoch: 8.55 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.166234732552374		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 1.166234732552374 | validation: 1.158121602325336]
	TIME [epoch: 8.55 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1539760024482508		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 1.1539760024482508 | validation: 0.9749036216203573]
	TIME [epoch: 8.54 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2395293182653964		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 1.2395293182653964 | validation: 0.8704201725277908]
	TIME [epoch: 8.53 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1774426236521132		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 1.1774426236521132 | validation: 1.4345894938023862]
	TIME [epoch: 8.56 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0726066573861097		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 1.0726066573861097 | validation: 0.8844265257381781]
	TIME [epoch: 8.55 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0397095492386543		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 1.0397095492386543 | validation: 0.9743855194585552]
	TIME [epoch: 8.54 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5048815417928736		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 1.5048815417928736 | validation: 0.9148464449923414]
	TIME [epoch: 8.54 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2224619416041023		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 1.2224619416041023 | validation: 0.7623952478463742]
	TIME [epoch: 8.57 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3627690998949482		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 1.3627690998949482 | validation: 1.6928646885916754]
	TIME [epoch: 8.55 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.385639925524558		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 1.385639925524558 | validation: 1.184597393358805]
	TIME [epoch: 8.54 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3360594453409738		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 1.3360594453409738 | validation: 1.5214929572804332]
	TIME [epoch: 8.54 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2496675408220344		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 1.2496675408220344 | validation: 1.5643144591404066]
	TIME [epoch: 8.56 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.380650901872757		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 1.380650901872757 | validation: 2.569163738401306]
	TIME [epoch: 8.54 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6865078849357693		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 1.6865078849357693 | validation: 0.810271477840012]
	TIME [epoch: 8.55 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2796496841065284		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 1.2796496841065284 | validation: 1.633535310536468]
	TIME [epoch: 8.53 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.665947663048383		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 1.665947663048383 | validation: 1.1654631641219535]
	TIME [epoch: 8.57 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.789469402870353		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 1.789469402870353 | validation: 2.7741419578432893]
	TIME [epoch: 8.54 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4840509259302972		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 1.4840509259302972 | validation: 1.069504961999012]
	TIME [epoch: 8.54 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6202320718749577		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 1.6202320718749577 | validation: 2.2373115661584637]
	TIME [epoch: 8.54 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4988275820301225		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 1.4988275820301225 | validation: 0.9405962059059729]
	TIME [epoch: 8.57 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4306296398999496		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 1.4306296398999496 | validation: 2.5407571924624186]
	TIME [epoch: 8.53 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5160671814862914		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 1.5160671814862914 | validation: 0.987960197134319]
	TIME [epoch: 8.54 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6237968712826372		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 1.6237968712826372 | validation: 1.0508984892858386]
	TIME [epoch: 8.54 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8475946685462188		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 1.8475946685462188 | validation: 2.884351369342368]
	TIME [epoch: 8.57 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1907472258242935		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 2.1907472258242935 | validation: 2.649878922400595]
	TIME [epoch: 8.53 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8576880849561825		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 1.8576880849561825 | validation: 0.986422187285835]
	TIME [epoch: 8.54 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1475621118264325		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 1.1475621118264325 | validation: 1.1591568055802957]
	TIME [epoch: 8.53 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6586470314529227		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 1.6586470314529227 | validation: 1.4788562379075172]
	TIME [epoch: 8.56 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7271644521519047		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 1.7271644521519047 | validation: 1.5145516788299258]
	TIME [epoch: 8.54 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7005330357670254		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 1.7005330357670254 | validation: 1.2021236539491906]
	TIME [epoch: 8.53 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.463672631047467		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 1.463672631047467 | validation: 1.0894748007994708]
	TIME [epoch: 8.54 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1075612298382547		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 2.1075612298382547 | validation: 2.3561465532906394]
	TIME [epoch: 8.56 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.092646480658653		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 2.092646480658653 | validation: 2.127196457053641]
	TIME [epoch: 8.53 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4727233252815872		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 1.4727233252815872 | validation: 1.3109098037744134]
	TIME [epoch: 8.52 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.249076667728386		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 1.249076667728386 | validation: 2.6987149708389397]
	TIME [epoch: 8.54 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.015931633001407		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 2.015931633001407 | validation: 1.1209206333316815]
	TIME [epoch: 8.54 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.18500926725259		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 1.18500926725259 | validation: 1.2199399404897782]
	TIME [epoch: 8.53 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4506915705953733		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 1.4506915705953733 | validation: 1.3392085302029484]
	TIME [epoch: 8.52 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2600836411546812		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 1.2600836411546812 | validation: 1.914496267582416]
	TIME [epoch: 8.54 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.551678151014843		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 1.551678151014843 | validation: 1.436999862417811]
	TIME [epoch: 8.54 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7363932219422709		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 1.7363932219422709 | validation: 1.307717676921071]
	TIME [epoch: 8.53 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.330594888199886		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 1.330594888199886 | validation: 2.6686296048071094]
	TIME [epoch: 8.52 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3313561083165826		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 1.3313561083165826 | validation: 1.3326041676728306]
	TIME [epoch: 8.55 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6614459926264846		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 1.6614459926264846 | validation: 1.1138757927207106]
	TIME [epoch: 8.54 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.336726247005564		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 2.336726247005564 | validation: 2.565700688455747]
	TIME [epoch: 8.53 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9674427230983143		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 1.9674427230983143 | validation: 1.4771542101830604]
	TIME [epoch: 8.53 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.643268082056012		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 1.643268082056012 | validation: 1.491054737907656]
	TIME [epoch: 8.55 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0383804008660187		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 2.0383804008660187 | validation: 1.1103660433010147]
	TIME [epoch: 8.53 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7953454611869042		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 1.7953454611869042 | validation: 3.2530122760460825]
	TIME [epoch: 8.53 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9904438666266764		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 1.9904438666266764 | validation: 1.499388821364628]
	TIME [epoch: 8.53 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8363889693859066		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 1.8363889693859066 | validation: 1.2260556615416434]
	TIME [epoch: 8.55 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3162281659073125		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 1.3162281659073125 | validation: 1.0614551257961973]
	TIME [epoch: 8.53 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3001169445978829		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 1.3001169445978829 | validation: 0.9835959322281196]
	TIME [epoch: 8.52 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.29294007010732		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 2.29294007010732 | validation: 2.384808623843392]
	TIME [epoch: 8.53 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4322396316593098		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 1.4322396316593098 | validation: 0.8261701550854861]
	TIME [epoch: 8.57 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1999340422223892		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 1.1999340422223892 | validation: 1.3672360397378056]
	TIME [epoch: 8.54 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.445323024422105		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 2.445323024422105 | validation: 2.649790365846345]
	TIME [epoch: 8.53 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7095794582523716		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 1.7095794582523716 | validation: 1.0055579387354914]
	TIME [epoch: 8.53 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5993496148855026		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 1.5993496148855026 | validation: 1.3136952053665576]
	TIME [epoch: 8.56 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1223305019785697		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 1.1223305019785697 | validation: 1.200384400631411]
	TIME [epoch: 8.54 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2554064956299131		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 1.2554064956299131 | validation: 2.7230794013822774]
	TIME [epoch: 8.53 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9890071250084476		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 1.9890071250084476 | validation: 0.8574968111874445]
	TIME [epoch: 8.54 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9235246697578894		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 1.9235246697578894 | validation: 0.8589869438773916]
	TIME [epoch: 8.56 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9710950240276		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 1.9710950240276 | validation: 2.5631046284291665]
	TIME [epoch: 8.53 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7304133130693136		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 1.7304133130693136 | validation: 1.202116233010764]
	TIME [epoch: 8.53 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.379296297539881		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 1.379296297539881 | validation: 2.71083727594838]
	TIME [epoch: 8.55 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.5900213895420525		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 2.5900213895420525 | validation: 1.4361398992778034]
	TIME [epoch: 8.54 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5391073937388386		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 1.5391073937388386 | validation: 1.1964112547711707]
	TIME [epoch: 8.53 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3100326121045174		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 1.3100326121045174 | validation: 1.0594813910341392]
	TIME [epoch: 8.54 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0048248865400815		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 2.0048248865400815 | validation: 1.2152952343083108]
	TIME [epoch: 8.55 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8579086515908956		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 1.8579086515908956 | validation: 2.5623749085850296]
	TIME [epoch: 8.55 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.61210730202995		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 1.61210730202995 | validation: 1.80865792164865]
	TIME [epoch: 8.54 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2909070422077846		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 2.2909070422077846 | validation: 2.798867039627988]
	TIME [epoch: 8.54 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.309505986482029		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 2.309505986482029 | validation: 1.1442002404040874]
	TIME [epoch: 8.55 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.111128165043317		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 1.111128165043317 | validation: 0.9313016811475783]
	TIME [epoch: 8.53 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1244437656875523		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 1.1244437656875523 | validation: 0.9027230663882317]
	TIME [epoch: 8.53 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2690261460359387		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 1.2690261460359387 | validation: 1.4421738710303458]
	TIME [epoch: 8.54 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3698467420798814		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 1.3698467420798814 | validation: 0.9213134570965315]
	TIME [epoch: 8.55 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1094411654804983		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 1.1094411654804983 | validation: 0.8666104068969105]
	TIME [epoch: 8.54 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4946731692093835		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 1.4946731692093835 | validation: 2.091617561928062]
	TIME [epoch: 8.53 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2399514566654166		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 2.2399514566654166 | validation: 1.2529772302114737]
	TIME [epoch: 8.53 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4661348689316722		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 1.4661348689316722 | validation: 2.6696647333654098]
	TIME [epoch: 8.56 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3397743889015503		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 2.3397743889015503 | validation: 1.0948598629962034]
	TIME [epoch: 8.54 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2735699621961678		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 1.2735699621961678 | validation: 1.352112372894766]
	TIME [epoch: 8.54 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.883712354605899		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 1.883712354605899 | validation: 1.5833962831046566]
	TIME [epoch: 8.54 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2346523755305348		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 1.2346523755305348 | validation: 1.4281464419374639]
	TIME [epoch: 8.56 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2682984648751725		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 1.2682984648751725 | validation: 1.0095841813829391]
	TIME [epoch: 8.53 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.176556478600656		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 1.176556478600656 | validation: 1.2440307150967203]
	TIME [epoch: 8.54 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9909860677645088		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 1.9909860677645088 | validation: 2.600201039015251]
	TIME [epoch: 8.53 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3922293466577504		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 2.3922293466577504 | validation: 2.572828244763306]
	TIME [epoch: 8.56 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.368408984523011		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 2.368408984523011 | validation: 1.378739633029236]
	TIME [epoch: 8.53 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5068517975619264		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 1.5068517975619264 | validation: 2.6862532198929427]
	TIME [epoch: 8.54 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0117112613234043		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 2.0117112613234043 | validation: 2.661922883431015]
	TIME [epoch: 8.54 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1463504125075596		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 2.1463504125075596 | validation: 0.878455627431614]
	TIME [epoch: 8.56 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1657148416573855		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 1.1657148416573855 | validation: 0.9923734707910297]
	TIME [epoch: 8.54 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.745557086226079		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 1.745557086226079 | validation: 2.6716720123853195]
	TIME [epoch: 8.53 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7787945597642296		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 1.7787945597642296 | validation: 1.026367938261545]
	TIME [epoch: 8.54 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3739256810945302		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 1.3739256810945302 | validation: 2.7090536812065045]
	TIME [epoch: 8.56 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5711993137579372		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 1.5711993137579372 | validation: 0.8679282291088118]
	TIME [epoch: 8.54 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9655898238994869		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 1.9655898238994869 | validation: 1.1373757635592234]
	TIME [epoch: 8.53 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5808286290979001		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 1.5808286290979001 | validation: 0.9436038392075463]
	TIME [epoch: 8.55 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7098562230821066		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 1.7098562230821066 | validation: 1.110242780917748]
	TIME [epoch: 8.54 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.39359645625364		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 2.39359645625364 | validation: 2.258185194136775]
	TIME [epoch: 8.54 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3510838425564222		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 1.3510838425564222 | validation: 1.461223007231193]
	TIME [epoch: 8.54 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3981342716946155		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 2.3981342716946155 | validation: 1.010318421593177]
	TIME [epoch: 8.55 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2202688654750422		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 1.2202688654750422 | validation: 0.9719155976738714]
	TIME [epoch: 8.55 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3013803779515825		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 2.3013803779515825 | validation: 2.6704336448347945]
	TIME [epoch: 8.54 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.876043098026511		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 1.876043098026511 | validation: 0.9814616758639298]
	TIME [epoch: 8.53 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0608682009563504		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 2.0608682009563504 | validation: 1.4899558441621708]
	TIME [epoch: 8.56 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4869116504923234		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 1.4869116504923234 | validation: 1.3101695642786226]
	TIME [epoch: 8.54 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.716175837680936		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 2.716175837680936 | validation: 0.9582356025844871]
	TIME [epoch: 8.53 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2801581993681574		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 1.2801581993681574 | validation: 1.0081430708684964]
	TIME [epoch: 8.53 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7622223052040262		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 1.7622223052040262 | validation: 1.2402112803275476]
	TIME [epoch: 8.56 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2316620752515441		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 1.2316620752515441 | validation: 0.9944617819702399]
	TIME [epoch: 8.54 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1384302103653183		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 1.1384302103653183 | validation: 1.2235136133610054]
	TIME [epoch: 8.53 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.817112645498301		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 1.817112645498301 | validation: 2.237499540785322]
	TIME [epoch: 8.53 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8211819800570144		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 1.8211819800570144 | validation: 1.2040470424453589]
	TIME [epoch: 8.56 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1912286139193293		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 2.1912286139193293 | validation: 1.6835694740853058]
	TIME [epoch: 8.54 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7709980891514512		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 1.7709980891514512 | validation: 2.4974480326613935]
	TIME [epoch: 8.53 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7543324710097334		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 1.7543324710097334 | validation: 1.6278627150160028]
	TIME [epoch: 8.53 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3275508687317668		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 1.3275508687317668 | validation: 0.754657650937881]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_342.pth
	Model improved!!!
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.304085393262063		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 2.304085393262063 | validation: 0.8778449557594541]
	TIME [epoch: 8.53 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.659185229409801		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 1.659185229409801 | validation: 0.8237573961142466]
	TIME [epoch: 8.53 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0411111065491823		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 2.0411111065491823 | validation: 2.570441912569576]
	TIME [epoch: 8.53 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0161184673510344		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 2.0161184673510344 | validation: 2.791815566769878]
	TIME [epoch: 8.56 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.2370638668783394		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 3.2370638668783394 | validation: 2.7623917288554654]
	TIME [epoch: 8.53 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.34290759794832		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 3.34290759794832 | validation: 2.557036077099692]
	TIME [epoch: 8.53 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4882661845086544		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 1.4882661845086544 | validation: 0.845436778002937]
	TIME [epoch: 8.54 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3536085846903272		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 1.3536085846903272 | validation: 1.2900356062666405]
	TIME [epoch: 8.55 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.271575349028471		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 2.271575349028471 | validation: 2.6946077030604254]
	TIME [epoch: 8.52 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.308222869033032		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 2.308222869033032 | validation: 1.976409245262087]
	TIME [epoch: 8.51 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2901527305869402		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 2.2901527305869402 | validation: 2.348619870744067]
	TIME [epoch: 8.55 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6922603017487905		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 1.6922603017487905 | validation: 0.7590395001169881]
	TIME [epoch: 8.53 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9802955305327054		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.9802955305327054 | validation: 0.9139505498752178]
	TIME [epoch: 8.53 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7363500666314196		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 1.7363500666314196 | validation: 2.398277256309064]
	TIME [epoch: 8.52 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9997040181717374		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 1.9997040181717374 | validation: 1.96447606528857]
	TIME [epoch: 8.55 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9546992617408896		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 1.9546992617408896 | validation: 1.985735287970635]
	TIME [epoch: 8.54 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.4704998544156966		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 2.4704998544156966 | validation: 2.439459168356235]
	TIME [epoch: 8.53 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.791408863544556		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 1.791408863544556 | validation: 2.3741435719352704]
	TIME [epoch: 8.53 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.196821236849051		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 2.196821236849051 | validation: 2.7865836210069195]
	TIME [epoch: 8.55 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7515303703586298		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 1.7515303703586298 | validation: 2.5308144772033523]
	TIME [epoch: 8.53 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.654763542006361		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 2.654763542006361 | validation: 1.9709580461892127]
	TIME [epoch: 8.53 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8674846944680834		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 1.8674846944680834 | validation: 1.5089570698987003]
	TIME [epoch: 8.53 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4582739413008254		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 1.4582739413008254 | validation: 2.1101644092296237]
	TIME [epoch: 8.55 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.166924597667246		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 2.166924597667246 | validation: 1.2050984789958736]
	TIME [epoch: 8.54 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6378907678025727		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 1.6378907678025727 | validation: 0.9061749660856253]
	TIME [epoch: 8.52 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1961524770050684		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 1.1961524770050684 | validation: 0.8925111571707773]
	TIME [epoch: 8.53 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5390979061150396		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 1.5390979061150396 | validation: 2.5523965584981747]
	TIME [epoch: 8.56 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4324774989553222		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 1.4324774989553222 | validation: 0.9915636227667184]
	TIME [epoch: 8.53 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4072275948735027		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 1.4072275948735027 | validation: 0.7961688361492854]
	TIME [epoch: 8.53 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.131347509727202		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 2.131347509727202 | validation: 2.6146131774483763]
	TIME [epoch: 8.53 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3261747149160612		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 1.3261747149160612 | validation: 0.8943416206558275]
	TIME [epoch: 8.56 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8930206480176895		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.8930206480176895 | validation: 0.8475756225180812]
	TIME [epoch: 8.53 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.384864506256888		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 2.384864506256888 | validation: 0.8618577783901537]
	TIME [epoch: 8.54 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1436471978902272		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 1.1436471978902272 | validation: 1.0981739757045552]
	TIME [epoch: 8.54 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9150025406882285		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 1.9150025406882285 | validation: 0.892467160476809]
	TIME [epoch: 8.56 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.053390502318163		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 1.053390502318163 | validation: 1.506643718138211]
	TIME [epoch: 8.53 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3094264308382049		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 1.3094264308382049 | validation: 1.5306380369354016]
	TIME [epoch: 8.53 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4450991165533076		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 1.4450991165533076 | validation: 1.0280020563653847]
	TIME [epoch: 8.53 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4682725631580502		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 1.4682725631580502 | validation: 2.2263469925254493]
	TIME [epoch: 8.56 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6037367228653108		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 1.6037367228653108 | validation: 0.7166933800954854]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_382.pth
	Model improved!!!
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9075015598300139		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.9075015598300139 | validation: 0.7788865312123422]
	TIME [epoch: 8.54 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9125385265072369		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.9125385265072369 | validation: 0.8425170105603843]
	TIME [epoch: 8.55 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0197334698950797		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 1.0197334698950797 | validation: 1.064511903893724]
	TIME [epoch: 8.56 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9676010729278017		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.9676010729278017 | validation: 1.1294573363599514]
	TIME [epoch: 8.54 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9489064062235592		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.9489064062235592 | validation: 0.7315702940366839]
	TIME [epoch: 8.54 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1349050874518114		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 1.1349050874518114 | validation: 1.28839254514154]
	TIME [epoch: 8.55 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.069542651555165		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 1.069542651555165 | validation: 1.0187824202178084]
	TIME [epoch: 8.55 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9449597315109033		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.9449597315109033 | validation: 1.0146652561746978]
	TIME [epoch: 8.54 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.05548297862746		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 1.05548297862746 | validation: 1.3883885034245127]
	TIME [epoch: 8.54 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9573090945838318		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.9573090945838318 | validation: 0.9126290673837256]
	TIME [epoch: 8.56 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.886831709970975		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.886831709970975 | validation: 0.7205134533918615]
	TIME [epoch: 8.55 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0409991718975702		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 1.0409991718975702 | validation: 1.1522069703403746]
	TIME [epoch: 8.55 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9899684426920823		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.9899684426920823 | validation: 1.0267111183167708]
	TIME [epoch: 8.53 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.038631796575562		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 1.038631796575562 | validation: 0.6151841165427826]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_396.pth
	Model improved!!!
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0101510258966144		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 1.0101510258966144 | validation: 0.6741761028084647]
	TIME [epoch: 8.55 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1115114707165425		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 1.1115114707165425 | validation: 0.7599423756593948]
	TIME [epoch: 8.53 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8262578621967431		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.8262578621967431 | validation: 0.7205908904656373]
	TIME [epoch: 8.53 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8844379339133669		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.8844379339133669 | validation: 0.9841958761560887]
	TIME [epoch: 8.55 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9801718803345805		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.9801718803345805 | validation: 0.6292324228909477]
	TIME [epoch: 8.53 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.059035660178909		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 1.059035660178909 | validation: 0.8434758372225087]
	TIME [epoch: 8.52 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.199018635892545		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 1.199018635892545 | validation: 1.4543831992189784]
	TIME [epoch: 8.52 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.188724302071429		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 1.188724302071429 | validation: 1.1037628540655975]
	TIME [epoch: 8.55 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4655399404400042		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 1.4655399404400042 | validation: 0.739513936630969]
	TIME [epoch: 8.52 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0417008469706475		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 1.0417008469706475 | validation: 1.6565494626491275]
	TIME [epoch: 8.52 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7745680128396693		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 1.7745680128396693 | validation: 0.9714359337789513]
	TIME [epoch: 8.55 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1931403201610282		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 1.1931403201610282 | validation: 1.052705315517588]
	TIME [epoch: 8.56 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8621144306170943		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.8621144306170943 | validation: 0.7714724832272816]
	TIME [epoch: 8.54 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0606184498668552		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 1.0606184498668552 | validation: 0.8135083946483437]
	TIME [epoch: 8.54 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1290289565283205		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 1.1290289565283205 | validation: 0.8319339339805747]
	TIME [epoch: 8.53 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2417910623312889		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 1.2417910623312889 | validation: 0.7781739228128218]
	TIME [epoch: 8.55 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.086441386566673		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 1.086441386566673 | validation: 0.9759473095062767]
	TIME [epoch: 8.54 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3584016115207294		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 1.3584016115207294 | validation: 1.9436637896562685]
	TIME [epoch: 8.53 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1702521837670357		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 1.1702521837670357 | validation: 1.0159435115923285]
	TIME [epoch: 8.54 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1349758194862047		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 1.1349758194862047 | validation: 1.3298835212649132]
	TIME [epoch: 8.56 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3361387713453063		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 1.3361387713453063 | validation: 1.1178127938241569]
	TIME [epoch: 8.54 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3030990682171624		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 1.3030990682171624 | validation: 0.9297366183309621]
	TIME [epoch: 8.53 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.070651592349926		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 1.070651592349926 | validation: 0.8926567499216074]
	TIME [epoch: 8.56 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1797928566576426		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 1.1797928566576426 | validation: 0.8284520931974577]
	TIME [epoch: 8.55 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3256045171753088		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 1.3256045171753088 | validation: 0.820503291658235]
	TIME [epoch: 8.54 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.228368259219764		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 1.228368259219764 | validation: 0.9971729665650584]
	TIME [epoch: 8.53 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.201131736583641		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 1.201131736583641 | validation: 1.3847849982216418]
	TIME [epoch: 8.55 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6345117900972124		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 1.6345117900972124 | validation: 0.9056172793729336]
	TIME [epoch: 8.55 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.226536196935739		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 1.226536196935739 | validation: 1.2376101655474483]
	TIME [epoch: 8.54 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2184479286105607		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 1.2184479286105607 | validation: 0.8140239478661964]
	TIME [epoch: 8.53 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8617420897113814		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 1.8617420897113814 | validation: 1.1967727334053238]
	TIME [epoch: 8.57 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1699534870158488		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 1.1699534870158488 | validation: 1.7855447615598452]
	TIME [epoch: 8.55 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1793095824984494		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 1.1793095824984494 | validation: 0.8232294206659265]
	TIME [epoch: 8.54 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2438666421793634		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 1.2438666421793634 | validation: 1.0237587609123455]
	TIME [epoch: 8.54 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1660546211243343		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 1.1660546211243343 | validation: 0.8282197606424808]
	TIME [epoch: 8.56 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7658152883443967		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 1.7658152883443967 | validation: 1.1268246848752907]
	TIME [epoch: 8.54 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3523932565859125		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 1.3523932565859125 | validation: 0.8938215147875537]
	TIME [epoch: 8.54 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2006838475293178		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 1.2006838475293178 | validation: 0.8617491360311498]
	TIME [epoch: 8.54 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1582797288857187		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 1.1582797288857187 | validation: 1.2734503441993716]
	TIME [epoch: 8.56 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9970601518749376		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.9970601518749376 | validation: 0.8396707437806724]
	TIME [epoch: 8.54 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3212957304271005		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 1.3212957304271005 | validation: 1.2541871753463898]
	TIME [epoch: 8.53 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.233679885262233		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 1.233679885262233 | validation: 0.9151599514847539]
	TIME [epoch: 8.54 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4671099816977804		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 1.4671099816977804 | validation: 0.9577282529017903]
	TIME [epoch: 8.57 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0427769347453708		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 1.0427769347453708 | validation: 1.147752008254017]
	TIME [epoch: 8.53 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2991775828300582		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 1.2991775828300582 | validation: 1.0325513941533786]
	TIME [epoch: 8.53 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2029552525208818		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 1.2029552525208818 | validation: 2.490343106717192]
	TIME [epoch: 8.54 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8026784699308827		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 1.8026784699308827 | validation: 0.9003923620839288]
	TIME [epoch: 8.57 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1825069470980385		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 1.1825069470980385 | validation: 1.060102494479524]
	TIME [epoch: 8.53 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1157205920895414		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 1.1157205920895414 | validation: 0.9688965766082914]
	TIME [epoch: 8.53 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0298619329738208		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 1.0298619329738208 | validation: 1.2938750401549939]
	TIME [epoch: 8.53 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1550091590056701		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 1.1550091590056701 | validation: 0.9143078845633064]
	TIME [epoch: 8.55 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9285922313310906		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.9285922313310906 | validation: 1.2583516386044007]
	TIME [epoch: 8.53 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2070711815734434		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 1.2070711815734434 | validation: 1.1389046877359048]
	TIME [epoch: 8.53 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2556546385829206		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 1.2556546385829206 | validation: 1.8280456143144077]
	TIME [epoch: 8.54 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.970271197455071		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.970271197455071 | validation: 0.9236173704411657]
	TIME [epoch: 8.54 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1452796457340386		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 1.1452796457340386 | validation: 1.0019109944545945]
	TIME [epoch: 8.53 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9873578669654346		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.9873578669654346 | validation: 1.0095620260873672]
	TIME [epoch: 8.54 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1261597078264474		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 1.1261597078264474 | validation: 1.3714914211230322]
	TIME [epoch: 8.54 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0990620270387925		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 1.0990620270387925 | validation: 0.987347259807005]
	TIME [epoch: 8.54 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0688643591295832		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 1.0688643591295832 | validation: 0.836812561661867]
	TIME [epoch: 8.53 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1034287863532972		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 1.1034287863532972 | validation: 1.0327005010580508]
	TIME [epoch: 8.53 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.831577910716802		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 1.831577910716802 | validation: 1.5524218416737003]
	TIME [epoch: 8.56 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2563701252177073		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 1.2563701252177073 | validation: 1.2690063863483494]
	TIME [epoch: 8.53 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2121465496001802		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 1.2121465496001802 | validation: 0.95833878365523]
	TIME [epoch: 8.54 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1090214510196932		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 1.1090214510196932 | validation: 1.0949024967612353]
	TIME [epoch: 8.53 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.142151146013697		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 1.142151146013697 | validation: 1.0656909586406504]
	TIME [epoch: 8.56 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7204125364816387		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 1.7204125364816387 | validation: 1.2864337252204696]
	TIME [epoch: 8.53 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0492601023423036		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 1.0492601023423036 | validation: 1.0266101034085904]
	TIME [epoch: 8.53 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0179168869088409		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 1.0179168869088409 | validation: 0.789678068973641]
	TIME [epoch: 8.53 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9387892013803871		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.9387892013803871 | validation: 0.8930244186687881]
	TIME [epoch: 8.55 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9521136724882693		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.9521136724882693 | validation: 0.7234649238386585]
	TIME [epoch: 8.53 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8854486244867582		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.8854486244867582 | validation: 1.1929318165197706]
	TIME [epoch: 8.53 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1275965141962523		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 1.1275965141962523 | validation: 1.2114473068611507]
	TIME [epoch: 8.52 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0279186914964147		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 1.0279186914964147 | validation: 1.7027770930342139]
	TIME [epoch: 8.56 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4999452754398184		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 1.4999452754398184 | validation: 1.0490031902243282]
	TIME [epoch: 8.53 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1063786445722559		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 1.1063786445722559 | validation: 0.9054683585932681]
	TIME [epoch: 8.53 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.188703918395929		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 1.188703918395929 | validation: 0.904057940475475]
	TIME [epoch: 8.53 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9631614736765218		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.9631614736765218 | validation: 0.6800539108976341]
	TIME [epoch: 8.55 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0754078789336463		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 1.0754078789336463 | validation: 0.8995097652915955]
	TIME [epoch: 8.53 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8875150714340613		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.8875150714340613 | validation: 0.817991612473371]
	TIME [epoch: 8.52 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9797963785253898		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.9797963785253898 | validation: 0.9147783552784978]
	TIME [epoch: 8.54 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9450647561715779		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.9450647561715779 | validation: 1.1138495375570905]
	TIME [epoch: 8.56 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0636572681203305		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 1.0636572681203305 | validation: 0.8330736242827032]
	TIME [epoch: 8.53 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9523904244808936		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.9523904244808936 | validation: 0.9863414162271611]
	TIME [epoch: 8.54 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8692473449248321		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.8692473449248321 | validation: 1.097360224226112]
	TIME [epoch: 8.54 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.973583452686379		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.973583452686379 | validation: 0.8358915052248417]
	TIME [epoch: 8.55 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8773643885216161		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.8773643885216161 | validation: 0.8035298578560002]
	TIME [epoch: 8.53 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9582894022516756		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.9582894022516756 | validation: 0.7718604226565349]
	TIME [epoch: 8.53 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9968079475860204		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.9968079475860204 | validation: 0.7288793498658592]
	TIME [epoch: 8.54 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8397301927982264		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.8397301927982264 | validation: 0.7999026469978434]
	TIME [epoch: 8.54 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9282682501242739		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.9282682501242739 | validation: 1.2793902559842572]
	TIME [epoch: 8.53 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8899063859868406		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.8899063859868406 | validation: 0.9367719397079174]
	TIME [epoch: 8.53 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9614920310011892		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.9614920310011892 | validation: 0.898477355334139]
	TIME [epoch: 8.54 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.80454076314901		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.80454076314901 | validation: 0.7027059775419956]
	TIME [epoch: 8.54 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7708308140448423		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.7708308140448423 | validation: 0.7468497377587298]
	TIME [epoch: 8.53 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8895522333993322		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.8895522333993322 | validation: 0.728685782750623]
	TIME [epoch: 8.53 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.768740472318578		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.768740472318578 | validation: 1.5396033641063878]
	TIME [epoch: 8.55 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9723446846743512		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.9723446846743512 | validation: 1.0416781829284212]
	TIME [epoch: 8.53 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8264610777079614		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.8264610777079614 | validation: 0.7778641634606536]
	TIME [epoch: 8.53 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8106220869238548		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.8106220869238548 | validation: 1.2733830258179442]
	TIME [epoch: 8.53 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.924014693562379		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.924014693562379 | validation: 0.8084301430380749]
	TIME [epoch: 8.56 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8865269607469495		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.8865269607469495 | validation: 0.8199500451235353]
	TIME [epoch: 8.54 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0441298103168348		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 1.0441298103168348 | validation: 0.907970971262689]
	TIME [epoch: 8.53 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8383867618392896		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.8383867618392896 | validation: 0.880082048810594]
	TIME [epoch: 8.53 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7596435501731396		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.7596435501731396 | validation: 0.9655630816587332]
	TIME [epoch: 8.55 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9834230325517446		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.9834230325517446 | validation: 1.2022098502190879]
	TIME [epoch: 8.53 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9478756923006444		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.9478756923006444 | validation: 0.8390999455548993]
	TIME [epoch: 8.53 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8486597292980482		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.8486597292980482 | validation: 0.6553488356100106]
	TIME [epoch: 8.53 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8907128717273995		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.8907128717273995 | validation: 0.693674925404386]
	TIME [epoch: 8.55 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.929095050173044		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.929095050173044 | validation: 0.7864323503785217]
	TIME [epoch: 8.53 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7167139002871199		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.7167139002871199 | validation: 0.7946553646825726]
	TIME [epoch: 8.53 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9103575444293519		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.9103575444293519 | validation: 0.750733109568408]
	TIME [epoch: 8.53 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7528090223321685		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.7528090223321685 | validation: 0.6622690590731345]
	TIME [epoch: 8.56 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.873813225804078		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.873813225804078 | validation: 1.1420862060758017]
	TIME [epoch: 8.53 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9011292534401824		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.9011292534401824 | validation: 1.0230992902706608]
	TIME [epoch: 8.53 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9232759076549415		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.9232759076549415 | validation: 0.8658611629187707]
	TIME [epoch: 8.53 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.772000379349711		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.772000379349711 | validation: 0.939349921117457]
	TIME [epoch: 8.56 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7345445569982249		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.7345445569982249 | validation: 0.7909353916484215]
	TIME [epoch: 8.53 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.848643309621162		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.848643309621162 | validation: 0.6276170022492731]
	TIME [epoch: 8.53 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6915183979435705		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.6915183979435705 | validation: 0.6224324574674882]
	TIME [epoch: 8.54 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6890000249475878		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.6890000249475878 | validation: 0.8820921257508766]
	TIME [epoch: 8.55 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7804132279351927		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.7804132279351927 | validation: 0.536470597011818]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_518.pth
	Model improved!!!
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8629511708295514		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.8629511708295514 | validation: 0.8039888311595376]
	TIME [epoch: 8.53 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8093431130923576		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.8093431130923576 | validation: 1.0788208265340105]
	TIME [epoch: 8.54 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6949919448666042		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.6949919448666042 | validation: 0.6207999057787796]
	TIME [epoch: 8.54 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7549625690777216		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.7549625690777216 | validation: 0.8843194839204785]
	TIME [epoch: 8.52 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8434980395687862		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.8434980395687862 | validation: 0.6891915218533352]
	TIME [epoch: 8.52 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7422705056934477		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.7422705056934477 | validation: 0.5764404318348348]
	TIME [epoch: 8.55 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6698070287742766		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.6698070287742766 | validation: 1.141540561028827]
	TIME [epoch: 8.53 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8405909459165171		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.8405909459165171 | validation: 0.6154863368707577]
	TIME [epoch: 8.52 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.808398668432152		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.808398668432152 | validation: 0.873718649660999]
	TIME [epoch: 8.52 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7408269484779665		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.7408269484779665 | validation: 0.5120891795679241]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_528.pth
	Model improved!!!
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9464725858782173		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.9464725858782173 | validation: 0.6492102089421963]
	TIME [epoch: 8.53 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7212999142779315		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.7212999142779315 | validation: 0.7843940329236496]
	TIME [epoch: 8.53 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.763204908805301		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.763204908805301 | validation: 1.1532544632241553]
	TIME [epoch: 8.52 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8450317744339984		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.8450317744339984 | validation: 0.5565233608384115]
	TIME [epoch: 8.55 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6814993890498353		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.6814993890498353 | validation: 1.014239324321412]
	TIME [epoch: 8.53 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9260333053495889		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.9260333053495889 | validation: 1.0202423852461129]
	TIME [epoch: 8.53 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8480635968829334		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.8480635968829334 | validation: 0.7194537556971581]
	TIME [epoch: 8.52 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.801004930072964		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.801004930072964 | validation: 0.6784240807558337]
	TIME [epoch: 8.56 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8118710221775365		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.8118710221775365 | validation: 1.0091830454169122]
	TIME [epoch: 8.53 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7771138776320179		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.7771138776320179 | validation: 0.7935126738193786]
	TIME [epoch: 8.52 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7878398648164578		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.7878398648164578 | validation: 0.5872917416084866]
	TIME [epoch: 8.52 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7469754671612243		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.7469754671612243 | validation: 0.8186055609853236]
	TIME [epoch: 8.55 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6666826720475373		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.6666826720475373 | validation: 0.557427442750595]
	TIME [epoch: 8.52 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6890158898518638		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.6890158898518638 | validation: 0.8328712944006172]
	TIME [epoch: 8.52 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8089576914146978		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.8089576914146978 | validation: 0.7528390744705655]
	TIME [epoch: 8.52 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7384684799704267		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.7384684799704267 | validation: 0.8294280176646243]
	TIME [epoch: 8.55 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7472617286972584		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.7472617286972584 | validation: 0.8082383806261114]
	TIME [epoch: 8.52 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8003930770468471		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.8003930770468471 | validation: 1.2667493115997754]
	TIME [epoch: 8.52 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7098475852088606		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.7098475852088606 | validation: 0.5596173314437579]
	TIME [epoch: 8.53 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7247525439559473		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.7247525439559473 | validation: 0.532719060355682]
	TIME [epoch: 8.54 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.743032119374847		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.743032119374847 | validation: 0.5310468125130721]
	TIME [epoch: 8.52 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7240233455706219		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.7240233455706219 | validation: 0.6200157032164828]
	TIME [epoch: 8.52 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7356895683709495		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.7356895683709495 | validation: 1.2241874893475422]
	TIME [epoch: 8.54 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7569387298733291		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.7569387298733291 | validation: 0.56327251938919]
	TIME [epoch: 8.53 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6524388532582386		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.6524388532582386 | validation: 0.5684774314425874]
	TIME [epoch: 8.52 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.645070625591529		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.645070625591529 | validation: 0.7357705373493554]
	TIME [epoch: 8.52 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7717667561839576		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.7717667561839576 | validation: 0.4674620125363959]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_555.pth
	Model improved!!!
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6064683908249219		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.6064683908249219 | validation: 0.45814212825323064]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_556.pth
	Model improved!!!
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6318964022862964		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.6318964022862964 | validation: 0.800017596134685]
	TIME [epoch: 8.54 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6963671415879767		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.6963671415879767 | validation: 0.5940807657860323]
	TIME [epoch: 8.55 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5936598549911049		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.5936598549911049 | validation: 0.6900671085257428]
	TIME [epoch: 8.57 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7507814895942765		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.7507814895942765 | validation: 0.5231957691739164]
	TIME [epoch: 8.54 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6189846040724065		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.6189846040724065 | validation: 0.5280222364750158]
	TIME [epoch: 8.54 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6529215407542506		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.6529215407542506 | validation: 0.6129714672185091]
	TIME [epoch: 8.54 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5817990285507212		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.5817990285507212 | validation: 0.716188613339628]
	TIME [epoch: 8.56 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6027476237975634		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.6027476237975634 | validation: 0.528758125885529]
	TIME [epoch: 8.56 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7072632898806928		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.7072632898806928 | validation: 0.5663002743214105]
	TIME [epoch: 8.54 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6560298589380082		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.6560298589380082 | validation: 0.49498424948652275]
	TIME [epoch: 8.54 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5834728761828942		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.5834728761828942 | validation: 0.5425509074254695]
	TIME [epoch: 8.57 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5333066735397164		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.5333066735397164 | validation: 0.4692070583836443]
	TIME [epoch: 8.54 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5940819683565077		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.5940819683565077 | validation: 0.4651563464525684]
	TIME [epoch: 8.55 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5951555475883525		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.5951555475883525 | validation: 0.5405062119560908]
	TIME [epoch: 8.54 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6042364182694447		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.6042364182694447 | validation: 0.5296180308656745]
	TIME [epoch: 8.58 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6468613025049219		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.6468613025049219 | validation: 0.4786184120558921]
	TIME [epoch: 8.54 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5759782254550494		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.5759782254550494 | validation: 0.4822440044206837]
	TIME [epoch: 8.55 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6096446023401866		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.6096446023401866 | validation: 0.4754486869112516]
	TIME [epoch: 8.54 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6665336839734782		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.6665336839734782 | validation: 0.5604593991577531]
	TIME [epoch: 8.57 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.659741836993187		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.659741836993187 | validation: 0.5841904417606658]
	TIME [epoch: 8.54 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5734050957527275		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.5734050957527275 | validation: 0.6105376360439206]
	TIME [epoch: 8.54 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.596595240833513		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.596595240833513 | validation: 0.48707267581864777]
	TIME [epoch: 8.54 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6312592614494467		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.6312592614494467 | validation: 0.47453952384776416]
	TIME [epoch: 8.58 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6273503446835285		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.6273503446835285 | validation: 0.4740417016647732]
	TIME [epoch: 8.54 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6120421764223888		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.6120421764223888 | validation: 0.4151283432996669]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_581.pth
	Model improved!!!
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6224208789499065		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.6224208789499065 | validation: 0.5626099778331968]
	TIME [epoch: 8.55 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6297072632567464		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.6297072632567464 | validation: 0.7448675427771149]
	TIME [epoch: 8.57 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6400770762775613		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.6400770762775613 | validation: 0.6195020453354232]
	TIME [epoch: 8.54 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6133478850076743		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.6133478850076743 | validation: 0.6359998557508938]
	TIME [epoch: 8.55 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5505118273446149		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.5505118273446149 | validation: 0.39674749597262665]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_586.pth
	Model improved!!!
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5549386011774833		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.5549386011774833 | validation: 0.5492871484855177]
	TIME [epoch: 8.57 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6277126125634578		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.6277126125634578 | validation: 0.5012668112409219]
	TIME [epoch: 8.54 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6108996857295652		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.6108996857295652 | validation: 0.6405321411340876]
	TIME [epoch: 8.55 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5724019635998426		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.5724019635998426 | validation: 0.4435450041931552]
	TIME [epoch: 8.56 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5707795145925628		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.5707795145925628 | validation: 0.43695960188482735]
	TIME [epoch: 8.56 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.63644344693947		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.63644344693947 | validation: 0.5508806041697594]
	TIME [epoch: 8.55 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6201909669657205		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.6201909669657205 | validation: 0.4058186263719825]
	TIME [epoch: 8.55 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6339944190981621		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.6339944190981621 | validation: 0.5122647042982038]
	TIME [epoch: 8.57 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5621777534659399		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.5621777534659399 | validation: 0.6171544646977964]
	TIME [epoch: 8.55 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5458218835723571		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.5458218835723571 | validation: 0.7058580205027238]
	TIME [epoch: 8.54 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5931514794281136		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.5931514794281136 | validation: 0.5887882095457388]
	TIME [epoch: 8.54 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5749909251620711		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.5749909251620711 | validation: 0.5148600717868219]
	TIME [epoch: 8.57 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5488155668924729		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.5488155668924729 | validation: 0.48032592904032]
	TIME [epoch: 8.55 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4469514449275577		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.4469514449275577 | validation: 1.0848472760683867]
	TIME [epoch: 8.54 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6273332820325487		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.6273332820325487 | validation: 0.6538384370394705]
	TIME [epoch: 8.54 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5349419473585151		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.5349419473585151 | validation: 0.9247444076625376]
	TIME [epoch: 8.57 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6289149994983377		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.6289149994983377 | validation: 0.6566219833428699]
	TIME [epoch: 8.54 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5505605561139556		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.5505605561139556 | validation: 0.6413194870698444]
	TIME [epoch: 8.55 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5364457604564612		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.5364457604564612 | validation: 0.4827537141855853]
	TIME [epoch: 8.55 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5511678174703829		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.5511678174703829 | validation: 0.5340661454025426]
	TIME [epoch: 8.57 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4591532752965512		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.4591532752965512 | validation: 0.7343028106870149]
	TIME [epoch: 8.55 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5468545966590378		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.5468545966590378 | validation: 0.4665388560166749]
	TIME [epoch: 8.55 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4573808370917017		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.4573808370917017 | validation: 0.9198839929762066]
	TIME [epoch: 8.55 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.510894389738586		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.510894389738586 | validation: 0.4430077164754015]
	TIME [epoch: 8.58 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.517433621847654		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.517433621847654 | validation: 0.50106766748411]
	TIME [epoch: 8.55 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5347194916830443		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.5347194916830443 | validation: 0.5081947972727991]
	TIME [epoch: 8.54 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.495447534844918		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.495447534844918 | validation: 0.4428478105586943]
	TIME [epoch: 8.55 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5442097000120316		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.5442097000120316 | validation: 0.37713943161898233]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_614.pth
	Model improved!!!
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.524320450153953		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.524320450153953 | validation: 0.6245674201849044]
	TIME [epoch: 8.55 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4986018405481638		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.4986018405481638 | validation: 0.419486675024323]
	TIME [epoch: 8.54 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44793489006116716		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.44793489006116716 | validation: 0.8816717566867764]
	TIME [epoch: 8.56 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5218998983743856		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.5218998983743856 | validation: 0.7195359339214391]
	TIME [epoch: 8.56 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5809931034935076		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.5809931034935076 | validation: 0.6137033237842707]
	TIME [epoch: 8.54 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5407063549212279		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.5407063549212279 | validation: 0.3742751272581579]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_620.pth
	Model improved!!!
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5517073719143836		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.5517073719143836 | validation: 0.5182507573719294]
	TIME [epoch: 8.56 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5036900162424162		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.5036900162424162 | validation: 0.42231898494538267]
	TIME [epoch: 8.55 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5149510944324291		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.5149510944324291 | validation: 0.5286726166915636]
	TIME [epoch: 8.54 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4689606093692367		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.4689606093692367 | validation: 0.4196447065174472]
	TIME [epoch: 8.54 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4953159293760162		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.4953159293760162 | validation: 1.3644947599578843]
	TIME [epoch: 8.56 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.673826517712562		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.673826517712562 | validation: 0.4329338978328912]
	TIME [epoch: 8.55 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4742288672999064		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.4742288672999064 | validation: 0.5384901024435549]
	TIME [epoch: 8.54 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5234017840731424		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.5234017840731424 | validation: 0.49663286769104864]
	TIME [epoch: 8.57 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.513392193900342		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.513392193900342 | validation: 0.5390510772789262]
	TIME [epoch: 8.56 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4903899009222359		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.4903899009222359 | validation: 0.44860083378804344]
	TIME [epoch: 8.54 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4816208491598307		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.4816208491598307 | validation: 0.34280028821456404]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_631.pth
	Model improved!!!
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46729929508726764		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.46729929508726764 | validation: 0.5201710978533722]
	TIME [epoch: 8.54 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4847464534263509		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.4847464534263509 | validation: 0.45228196724255115]
	TIME [epoch: 8.57 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46095948323986075		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.46095948323986075 | validation: 0.35174290449621176]
	TIME [epoch: 8.55 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3824028899761751		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.3824028899761751 | validation: 0.5765765079520104]
	TIME [epoch: 8.54 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5333289702938554		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.5333289702938554 | validation: 0.7876988086283945]
	TIME [epoch: 8.54 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49957674470708324		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.49957674470708324 | validation: 0.5034155789099499]
	TIME [epoch: 8.58 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4730451380575874		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.4730451380575874 | validation: 0.38452270465365934]
	TIME [epoch: 8.55 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47761365165861003		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.47761365165861003 | validation: 0.5070784720880517]
	TIME [epoch: 8.55 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46319729226021583		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.46319729226021583 | validation: 0.4477281876904645]
	TIME [epoch: 8.55 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47709281755804034		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.47709281755804034 | validation: 0.44755584993508657]
	TIME [epoch: 8.58 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47254028004011106		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.47254028004011106 | validation: 0.5731605192574291]
	TIME [epoch: 8.55 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6258609797339142		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.6258609797339142 | validation: 0.7974282653725793]
	TIME [epoch: 8.54 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6196706847372452		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.6196706847372452 | validation: 0.3349190530979359]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_644.pth
	Model improved!!!
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5235947329885421		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.5235947329885421 | validation: 0.32515661524688594]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_645.pth
	Model improved!!!
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45694518914308146		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.45694518914308146 | validation: 0.3880370032227072]
	TIME [epoch: 8.54 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47932456757035313		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.47932456757035313 | validation: 0.41819520040180064]
	TIME [epoch: 8.54 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5034666183307047		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.5034666183307047 | validation: 0.38956217659834813]
	TIME [epoch: 8.56 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4612472870470906		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.4612472870470906 | validation: 0.4890852096284467]
	TIME [epoch: 8.56 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4480278022492367		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.4480278022492367 | validation: 0.40337385173345786]
	TIME [epoch: 8.54 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48360529843451905		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.48360529843451905 | validation: 0.33356897948906405]
	TIME [epoch: 8.54 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47249475687194753		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.47249475687194753 | validation: 0.7331712184914564]
	TIME [epoch: 8.56 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4787351118778108		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.4787351118778108 | validation: 0.3409994829022843]
	TIME [epoch: 8.55 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48035327086320645		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.48035327086320645 | validation: 0.3892030217755654]
	TIME [epoch: 8.54 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44843235627300854		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.44843235627300854 | validation: 0.3587060664557664]
	TIME [epoch: 8.55 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.421678065122563		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.421678065122563 | validation: 0.5160040034101574]
	TIME [epoch: 8.57 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47080603070247945		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.47080603070247945 | validation: 0.4201796777293584]
	TIME [epoch: 8.54 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3939881773382551		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.3939881773382551 | validation: 0.5828242403133324]
	TIME [epoch: 8.55 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4810651569753448		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.4810651569753448 | validation: 0.681581831518541]
	TIME [epoch: 8.54 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44528813714280807		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.44528813714280807 | validation: 0.6036523155319049]
	TIME [epoch: 8.57 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47151829590346256		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.47151829590346256 | validation: 0.3290261918441009]
	TIME [epoch: 8.54 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44223619102331535		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.44223619102331535 | validation: 0.3456433212411115]
	TIME [epoch: 8.54 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40656775486191454		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.40656775486191454 | validation: 0.6106701133621297]
	TIME [epoch: 8.54 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44444125221123115		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.44444125221123115 | validation: 0.3818386698571296]
	TIME [epoch: 8.57 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4497669629115915		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.4497669629115915 | validation: 0.3835545703573219]
	TIME [epoch: 8.54 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42399511857760663		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.42399511857760663 | validation: 0.35155107481487463]
	TIME [epoch: 8.54 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4026850990976757		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.4026850990976757 | validation: 0.6856754389513866]
	TIME [epoch: 8.54 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4625553304715061		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.4625553304715061 | validation: 0.4397363566254534]
	TIME [epoch: 8.57 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43348613222281146		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.43348613222281146 | validation: 0.611739806786245]
	TIME [epoch: 8.54 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4749408727459993		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.4749408727459993 | validation: 0.36540238510202927]
	TIME [epoch: 8.54 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4268100067792718		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.4268100067792718 | validation: 0.437279512129462]
	TIME [epoch: 8.55 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4307886980463026		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.4307886980463026 | validation: 0.37174617824958267]
	TIME [epoch: 8.56 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5397074737257298		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.5397074737257298 | validation: 0.3410068990274473]
	TIME [epoch: 8.54 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4307717058601671		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.4307717058601671 | validation: 0.39053059552612635]
	TIME [epoch: 8.54 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4294676323464347		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.4294676323464347 | validation: 0.3355292209398327]
	TIME [epoch: 8.55 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4250933721419595		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.4250933721419595 | validation: 0.5094983797914103]
	TIME [epoch: 8.55 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4201773630168971		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.4201773630168971 | validation: 0.468371584957087]
	TIME [epoch: 8.6 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4312265363383173		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.4312265363383173 | validation: 0.6405424403768243]
	TIME [epoch: 8.54 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5594586082198739		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.5594586082198739 | validation: 0.4740970446390911]
	TIME [epoch: 8.55 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4090081440492906		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.4090081440492906 | validation: 0.4805003581554804]
	TIME [epoch: 8.55 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38409307021043115		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.38409307021043115 | validation: 0.31855687220090156]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_681.pth
	Model improved!!!
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4252542436229625		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.4252542436229625 | validation: 0.5354594030322344]
	TIME [epoch: 8.54 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40416950420769726		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.40416950420769726 | validation: 0.6429576527927239]
	TIME [epoch: 8.56 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4995800875956403		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.4995800875956403 | validation: 0.5256305558130344]
	TIME [epoch: 8.54 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4245540321628331		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.4245540321628331 | validation: 0.41067032123517566]
	TIME [epoch: 8.53 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48492414354449187		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.48492414354449187 | validation: 0.4143426500549755]
	TIME [epoch: 8.54 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41051800142740885		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.41051800142740885 | validation: 0.2859423778641039]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_687.pth
	Model improved!!!
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3649954981553638		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.3649954981553638 | validation: 0.32753753911105143]
	TIME [epoch: 8.55 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4172740274609458		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.4172740274609458 | validation: 0.307732270430078]
	TIME [epoch: 8.53 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4094531529379563		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.4094531529379563 | validation: 0.3831997650237171]
	TIME [epoch: 8.53 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3542564161109426		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.3542564161109426 | validation: 0.469258432775471]
	TIME [epoch: 8.56 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45268980205344833		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.45268980205344833 | validation: 0.34246128830490324]
	TIME [epoch: 8.53 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36302308829661845		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.36302308829661845 | validation: 0.31439832535917134]
	TIME [epoch: 8.54 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3697992194420715		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.3697992194420715 | validation: 0.38208471944333455]
	TIME [epoch: 8.53 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38617726356925347		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.38617726356925347 | validation: 0.467171624032764]
	TIME [epoch: 8.56 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37721017467247975		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.37721017467247975 | validation: 0.3080967553093382]
	TIME [epoch: 8.53 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43209470977200065		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.43209470977200065 | validation: 0.8245558121140901]
	TIME [epoch: 8.53 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3962177483191463		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.3962177483191463 | validation: 0.5882461561460955]
	TIME [epoch: 8.53 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43100228174784777		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.43100228174784777 | validation: 0.5147639924038632]
	TIME [epoch: 8.56 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41930280238542583		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.41930280238542583 | validation: 0.4316736701657533]
	TIME [epoch: 8.54 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44001057169319174		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.44001057169319174 | validation: 0.31722033518968934]
	TIME [epoch: 8.54 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3908837838283148		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.3908837838283148 | validation: 0.3210005017846783]
	TIME [epoch: 8.54 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40862839329396927		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.40862839329396927 | validation: 0.3041086431897294]
	TIME [epoch: 8.56 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48307471674493696		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.48307471674493696 | validation: 0.5637909432019671]
	TIME [epoch: 8.53 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4221084399409323		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.4221084399409323 | validation: 0.38411736847506406]
	TIME [epoch: 8.54 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40331914008833436		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.40331914008833436 | validation: 0.28621774391596244]
	TIME [epoch: 8.54 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3418146767575136		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.3418146767575136 | validation: 0.440859551402766]
	TIME [epoch: 8.55 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36770773364929843		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.36770773364929843 | validation: 0.28893383542595996]
	TIME [epoch: 8.53 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4072706146761945		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.4072706146761945 | validation: 0.44500135820786857]
	TIME [epoch: 8.53 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3588875063058715		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.3588875063058715 | validation: 0.390225979204764]
	TIME [epoch: 8.55 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4946464385233539		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.4946464385233539 | validation: 0.36045413448609254]
	TIME [epoch: 8.54 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39559524224176784		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.39559524224176784 | validation: 0.48490590171693804]
	TIME [epoch: 8.53 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6315239841060928		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.6315239841060928 | validation: 0.3506481038011813]
	TIME [epoch: 8.54 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3299309381462346		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.3299309381462346 | validation: 0.2828849540074181]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_714.pth
	Model improved!!!
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4771114851765323		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.4771114851765323 | validation: 0.6081240301845624]
	TIME [epoch: 8.54 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40619783332335835		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.40619783332335835 | validation: 0.5005027798789072]
	TIME [epoch: 8.53 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39376166752596486		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.39376166752596486 | validation: 0.33767268734446615]
	TIME [epoch: 8.53 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38332109341426474		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.38332109341426474 | validation: 0.3382367937875237]
	TIME [epoch: 8.55 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3306723006163152		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.3306723006163152 | validation: 0.48337556787331026]
	TIME [epoch: 8.53 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38893394149831517		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.38893394149831517 | validation: 0.5311189717567489]
	TIME [epoch: 8.53 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39929193141318886		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.39929193141318886 | validation: 0.3476505950732236]
	TIME [epoch: 8.53 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3181346049655147		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.3181346049655147 | validation: 0.47800540339858977]
	TIME [epoch: 8.56 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39709266127267917		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.39709266127267917 | validation: 0.5164245689966959]
	TIME [epoch: 8.53 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41443824736838214		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.41443824736838214 | validation: 0.5599889224288652]
	TIME [epoch: 8.53 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3993884901664798		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.3993884901664798 | validation: 0.43053334105569574]
	TIME [epoch: 8.53 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48758510577644537		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.48758510577644537 | validation: 0.35505430534860555]
	TIME [epoch: 8.55 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3358828443054764		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.3358828443054764 | validation: 0.48361108251309703]
	TIME [epoch: 8.53 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.347382984639305		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.347382984639305 | validation: 0.3565355093228464]
	TIME [epoch: 8.53 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4171106206820907		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.4171106206820907 | validation: 0.32971702640695355]
	TIME [epoch: 8.52 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3910669353585113		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.3910669353585113 | validation: 0.27198587474583646]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_730.pth
	Model improved!!!
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3493929172764708		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.3493929172764708 | validation: 0.5432254870432187]
	TIME [epoch: 8.53 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4016672842781448		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.4016672842781448 | validation: 0.6558695256625517]
	TIME [epoch: 8.53 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3863920273557509		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.3863920273557509 | validation: 0.36727616539590824]
	TIME [epoch: 8.54 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35863122480976733		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.35863122480976733 | validation: 0.31998722753248077]
	TIME [epoch: 8.55 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3452867070736195		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.3452867070736195 | validation: 0.3097696425920313]
	TIME [epoch: 8.53 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3470828681366454		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.3470828681366454 | validation: 0.5853085647655711]
	TIME [epoch: 8.53 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37603011108217216		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.37603011108217216 | validation: 0.43564359913940826]
	TIME [epoch: 8.55 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37794879127424735		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.37794879127424735 | validation: 0.30237819328336185]
	TIME [epoch: 8.54 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33690463896736256		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.33690463896736256 | validation: 0.30953595046857807]
	TIME [epoch: 8.53 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36033283829275126		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.36033283829275126 | validation: 0.3954080164912036]
	TIME [epoch: 8.53 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43446067934352905		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.43446067934352905 | validation: 0.40946057824322557]
	TIME [epoch: 8.55 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36032635654585293		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.36032635654585293 | validation: 0.3853495494886826]
	TIME [epoch: 8.53 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38229333255182507		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.38229333255182507 | validation: 0.3427918362644379]
	TIME [epoch: 8.53 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35339222158659866		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.35339222158659866 | validation: 0.32054703856329214]
	TIME [epoch: 8.53 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32127359251915355		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.32127359251915355 | validation: 0.4485397305845865]
	TIME [epoch: 8.55 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3713161807655591		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.3713161807655591 | validation: 0.3203245832710233]
	TIME [epoch: 8.53 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4070200357644225		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.4070200357644225 | validation: 0.4018896826540189]
	TIME [epoch: 8.53 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3781997510013118		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.3781997510013118 | validation: 0.4909752465791822]
	TIME [epoch: 8.53 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37933086937703614		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.37933086937703614 | validation: 0.6981663827666535]
	TIME [epoch: 8.56 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44257512850334246		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.44257512850334246 | validation: 0.32926102931457946]
	TIME [epoch: 8.53 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40105411483275033		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.40105411483275033 | validation: 0.29635388746930835]
	TIME [epoch: 8.53 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33164375240397276		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.33164375240397276 | validation: 0.26433173391057446]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_752.pth
	Model improved!!!
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3480803673907563		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.3480803673907563 | validation: 0.3042829763019879]
	TIME [epoch: 8.56 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29448622437390953		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.29448622437390953 | validation: 0.3209785206149193]
	TIME [epoch: 8.52 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4326343828592439		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.4326343828592439 | validation: 0.3443368400844956]
	TIME [epoch: 8.53 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3333487312814763		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.3333487312814763 | validation: 0.5532981296191974]
	TIME [epoch: 8.52 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3766862576526996		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.3766862576526996 | validation: 0.3225783136608184]
	TIME [epoch: 8.55 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3176910161501026		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.3176910161501026 | validation: 0.48459536275047926]
	TIME [epoch: 8.52 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43467490613019655		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.43467490613019655 | validation: 0.3243481658625742]
	TIME [epoch: 8.52 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32895520397674316		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.32895520397674316 | validation: 0.3104660970513016]
	TIME [epoch: 8.53 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33456263642759715		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.33456263642759715 | validation: 0.486402071346797]
	TIME [epoch: 8.55 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45283310241352803		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.45283310241352803 | validation: 0.3815773098957356]
	TIME [epoch: 8.52 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37180855765067605		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.37180855765067605 | validation: 0.27235644582116836]
	TIME [epoch: 8.52 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3237389139418312		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.3237389139418312 | validation: 0.27826955113843654]
	TIME [epoch: 8.52 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3302792115776151		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.3302792115776151 | validation: 0.2861549448676842]
	TIME [epoch: 8.54 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39721446639511704		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.39721446639511704 | validation: 0.6669893135114788]
	TIME [epoch: 8.52 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4236418516336763		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.4236418516336763 | validation: 0.2538620448783754]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_767.pth
	Model improved!!!
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3400367993629994		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.3400367993629994 | validation: 0.2941275774721831]
	TIME [epoch: 8.54 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3141500055596365		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.3141500055596365 | validation: 0.2664574183486113]
	TIME [epoch: 8.53 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3878067893664027		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.3878067893664027 | validation: 0.30633981805002]
	TIME [epoch: 8.52 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29399073247107427		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.29399073247107427 | validation: 0.29635547869284407]
	TIME [epoch: 8.51 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3868161672893518		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.3868161672893518 | validation: 0.26175006878937684]
	TIME [epoch: 8.55 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29519205975441143		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.29519205975441143 | validation: 0.35486668725807846]
	TIME [epoch: 8.52 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33505010746909064		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.33505010746909064 | validation: 0.3526783808717612]
	TIME [epoch: 8.52 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30323100610437426		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.30323100610437426 | validation: 0.3100899977859758]
	TIME [epoch: 8.52 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30159904885705385		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.30159904885705385 | validation: 0.31029646350978995]
	TIME [epoch: 8.54 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3106665581732902		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.3106665581732902 | validation: 0.31445149645346565]
	TIME [epoch: 8.52 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32661775643246266		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.32661775643246266 | validation: 0.28463401406837247]
	TIME [epoch: 8.52 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32139247206294885		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.32139247206294885 | validation: 0.4784916900559419]
	TIME [epoch: 8.51 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3102518802284834		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.3102518802284834 | validation: 0.3217919390738663]
	TIME [epoch: 8.55 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29246072842529147		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.29246072842529147 | validation: 0.29490608389482564]
	TIME [epoch: 8.53 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34461203061409074		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.34461203061409074 | validation: 0.6202063371468219]
	TIME [epoch: 8.51 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3945303442459608		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.3945303442459608 | validation: 0.3396823898266934]
	TIME [epoch: 8.52 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37754665144607724		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.37754665144607724 | validation: 0.25167034070200367]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_784.pth
	Model improved!!!
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2942202811670929		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.2942202811670929 | validation: 0.2987643397457689]
	TIME [epoch: 8.53 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.349091375469415		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.349091375469415 | validation: 0.25984376956096344]
	TIME [epoch: 8.52 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31032201352809796		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.31032201352809796 | validation: 0.31553791218911276]
	TIME [epoch: 8.52 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30200244604282533		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.30200244604282533 | validation: 0.29300464551216665]
	TIME [epoch: 8.55 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30259755484154516		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.30259755484154516 | validation: 0.30300354469004]
	TIME [epoch: 8.52 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30364537103194195		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.30364537103194195 | validation: 0.2919707859356101]
	TIME [epoch: 8.53 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.287302632152847		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.287302632152847 | validation: 0.4244889332555488]
	TIME [epoch: 8.52 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3349491989031089		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.3349491989031089 | validation: 0.2647753808421052]
	TIME [epoch: 8.55 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34446474007256433		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.34446474007256433 | validation: 0.28846354155259113]
	TIME [epoch: 8.54 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3015656366297014		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.3015656366297014 | validation: 0.37737675184721886]
	TIME [epoch: 8.53 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3842567182817923		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.3842567182817923 | validation: 0.3408847233951394]
	TIME [epoch: 8.53 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36376506931213315		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.36376506931213315 | validation: 0.3027575195652761]
	TIME [epoch: 8.56 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29445923993464657		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.29445923993464657 | validation: 0.267361572822596]
	TIME [epoch: 8.52 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2938738758397429		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.2938738758397429 | validation: 0.3113681103981025]
	TIME [epoch: 8.53 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3300316801732929		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.3300316801732929 | validation: 0.2686477129772471]
	TIME [epoch: 8.54 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2985066523867111		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.2985066523867111 | validation: 0.2908114315342043]
	TIME [epoch: 8.54 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2951724113391009		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.2951724113391009 | validation: 0.2741970924014408]
	TIME [epoch: 8.52 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3504047469341503		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.3504047469341503 | validation: 0.2801134940029283]
	TIME [epoch: 8.52 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28723015472104796		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.28723015472104796 | validation: 0.31973172001464745]
	TIME [epoch: 8.54 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3594952166702077		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.3594952166702077 | validation: 0.2547135735346681]
	TIME [epoch: 8.54 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4086242498699716		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.4086242498699716 | validation: 0.4548458250337665]
	TIME [epoch: 8.52 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3760687757630036		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.3760687757630036 | validation: 0.32395775151272843]
	TIME [epoch: 8.52 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.307144725445528		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.307144725445528 | validation: 0.3698269511285434]
	TIME [epoch: 8.55 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.323651349950463		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.323651349950463 | validation: 0.3600449125712182]
	TIME [epoch: 8.53 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33320192047573116		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.33320192047573116 | validation: 0.37236326918636087]
	TIME [epoch: 8.53 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46890797018730374		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.46890797018730374 | validation: 0.3761293352446906]
	TIME [epoch: 8.53 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3406198952956486		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.3406198952956486 | validation: 0.27800500535891204]
	TIME [epoch: 8.56 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3424991377840604		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.3424991377840604 | validation: 0.27297322527495055]
	TIME [epoch: 8.53 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2735409110614781		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.2735409110614781 | validation: 0.28481905816231623]
	TIME [epoch: 8.51 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28278762225174436		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.28278762225174436 | validation: 0.2784936513854025]
	TIME [epoch: 8.53 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2761746958718464		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.2761746958718464 | validation: 0.29823466648336894]
	TIME [epoch: 8.55 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3265618065942908		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.3265618065942908 | validation: 0.27141015632157217]
	TIME [epoch: 8.54 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3127287271963689		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.3127287271963689 | validation: 0.31765022002075527]
	TIME [epoch: 8.52 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3171199252696026		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.3171199252696026 | validation: 0.29427269906456677]
	TIME [epoch: 8.54 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3180695086680392		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.3180695086680392 | validation: 0.3038454587148264]
	TIME [epoch: 8.55 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3144445084449639		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.3144445084449639 | validation: 0.28617948240572066]
	TIME [epoch: 8.53 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29027346328825016		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.29027346328825016 | validation: 0.25368051432661026]
	TIME [epoch: 8.52 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27489831036648954		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.27489831036648954 | validation: 0.25709766540430545]
	TIME [epoch: 8.52 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.300652939339071		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.300652939339071 | validation: 0.26032387071141594]
	TIME [epoch: 8.55 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3053725263998429		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.3053725263998429 | validation: 0.2702996105402932]
	TIME [epoch: 8.53 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2960477741156664		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.2960477741156664 | validation: 0.3434771678881726]
	TIME [epoch: 8.52 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2703387027445546		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.2703387027445546 | validation: 0.23863534295960215]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_826.pth
	Model improved!!!
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3048867700747242		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.3048867700747242 | validation: 0.3371320843683561]
	TIME [epoch: 8.55 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2891733287880859		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.2891733287880859 | validation: 0.31718108739130646]
	TIME [epoch: 8.52 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31149470886961905		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.31149470886961905 | validation: 0.2678611056388638]
	TIME [epoch: 8.52 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2891200699766422		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.2891200699766422 | validation: 0.2774468446221365]
	TIME [epoch: 8.54 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3761505621703457		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.3761505621703457 | validation: 0.47479827786057693]
	TIME [epoch: 8.54 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3000519295086216		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.3000519295086216 | validation: 0.33029343479963635]
	TIME [epoch: 8.52 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3841250805485644		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.3841250805485644 | validation: 0.3431850546030487]
	TIME [epoch: 8.53 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31230630975627344		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.31230630975627344 | validation: 0.28927795726869854]
	TIME [epoch: 8.54 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2909560869172121		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.2909560869172121 | validation: 0.2801209208569977]
	TIME [epoch: 8.54 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3010555213647552		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.3010555213647552 | validation: 0.25797357940501]
	TIME [epoch: 8.52 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3121788230037782		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.3121788230037782 | validation: 0.3416079127424208]
	TIME [epoch: 8.53 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.316581387001215		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.316581387001215 | validation: 0.3184017531041718]
	TIME [epoch: 8.55 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30354851694710605		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.30354851694710605 | validation: 0.3249339513174707]
	TIME [epoch: 8.53 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30036490332466326		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.30036490332466326 | validation: 0.2806788619137473]
	TIME [epoch: 8.53 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.357420002253484		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.357420002253484 | validation: 0.26021598570437204]
	TIME [epoch: 8.53 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30606552098990075		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.30606552098990075 | validation: 0.24539259431757304]
	TIME [epoch: 8.55 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28609882261506786		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.28609882261506786 | validation: 0.3086902430262754]
	TIME [epoch: 8.53 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3458864427830776		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.3458864427830776 | validation: 0.2571480748470257]
	TIME [epoch: 8.53 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3199796533120951		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.3199796533120951 | validation: 0.35172105381551444]
	TIME [epoch: 8.53 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3830342013203588		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.3830342013203588 | validation: 0.3694984056570824]
	TIME [epoch: 8.55 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3538918183886614		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.3538918183886614 | validation: 0.33970594964467615]
	TIME [epoch: 8.53 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34546718725738074		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.34546718725738074 | validation: 0.2732486989623016]
	TIME [epoch: 8.52 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27049171348551726		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.27049171348551726 | validation: 0.2658569594807972]
	TIME [epoch: 8.52 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28633148890966426		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.28633148890966426 | validation: 0.534523126344909]
	TIME [epoch: 8.56 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954880281434345		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.2954880281434345 | validation: 0.4107149141952181]
	TIME [epoch: 8.53 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35518707517450776		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.35518707517450776 | validation: 0.3172744639419032]
	TIME [epoch: 8.52 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31401098548027195		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.31401098548027195 | validation: 0.23991169339016735]
	TIME [epoch: 8.52 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2875835505464256		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.2875835505464256 | validation: 0.2771639272958839]
	TIME [epoch: 8.55 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3720914647475511		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.3720914647475511 | validation: 0.2953884209208151]
	TIME [epoch: 8.52 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3006776083120316		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.3006776083120316 | validation: 0.23518050630186027]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_856.pth
	Model improved!!!
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2660597953138399		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.2660597953138399 | validation: 0.27332620381184203]
	TIME [epoch: 8.53 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31980374665085465		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.31980374665085465 | validation: 0.26430624676877346]
	TIME [epoch: 8.55 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2965106790383124		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.2965106790383124 | validation: 0.3481679796454872]
	TIME [epoch: 8.52 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2932429052227801		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.2932429052227801 | validation: 0.4156787852528766]
	TIME [epoch: 8.53 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3065504449794881		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.3065504449794881 | validation: 0.359104711474886]
	TIME [epoch: 8.54 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2927968216308095		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.2927968216308095 | validation: 0.24571648047935218]
	TIME [epoch: 8.54 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2808631681959854		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.2808631681959854 | validation: 0.30010327379916485]
	TIME [epoch: 8.52 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31500913206769365		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.31500913206769365 | validation: 0.36244931125394797]
	TIME [epoch: 8.51 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2811084822981004		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.2811084822981004 | validation: 0.6359823330874491]
	TIME [epoch: 8.53 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32916853801017537		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.32916853801017537 | validation: 0.2980710545765178]
	TIME [epoch: 8.53 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2894837917773656		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.2894837917773656 | validation: 0.2681134873594624]
	TIME [epoch: 8.51 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.314888600574449		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.314888600574449 | validation: 0.36225086646247473]
	TIME [epoch: 8.51 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3453932347063266		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.3453932347063266 | validation: 0.2803335926579971]
	TIME [epoch: 8.54 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26944339758675834		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.26944339758675834 | validation: 0.2500522787967481]
	TIME [epoch: 8.52 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29449486130244		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.29449486130244 | validation: 0.2704295860891422]
	TIME [epoch: 8.51 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3366700593833983		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.3366700593833983 | validation: 0.260100426019898]
	TIME [epoch: 8.52 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27316588679777803		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.27316588679777803 | validation: 0.3610948119572507]
	TIME [epoch: 8.54 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30733675234620433		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.30733675234620433 | validation: 0.3417318280358801]
	TIME [epoch: 8.52 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2980187824517256		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.2980187824517256 | validation: 0.251636445311387]
	TIME [epoch: 8.52 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28277600954756854		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.28277600954756854 | validation: 0.2928485911544466]
	TIME [epoch: 8.52 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3208156182038285		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.3208156182038285 | validation: 0.23139020798128335]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_877.pth
	Model improved!!!
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27606122517326137		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.27606122517326137 | validation: 0.2604103846786055]
	TIME [epoch: 8.52 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2682228842071849		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.2682228842071849 | validation: 0.25486996534323547]
	TIME [epoch: 8.52 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2839902161340877		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.2839902161340877 | validation: 0.2824811809258244]
	TIME [epoch: 8.52 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29486831961702953		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.29486831961702953 | validation: 0.30695716152161545]
	TIME [epoch: 8.54 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2791567766554221		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.2791567766554221 | validation: 0.272983588254925]
	TIME [epoch: 8.51 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3126927520479085		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.3126927520479085 | validation: 0.27518892457093114]
	TIME [epoch: 8.52 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26175086853538637		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.26175086853538637 | validation: 0.24880571489598563]
	TIME [epoch: 8.52 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2974234628198028		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.2974234628198028 | validation: 0.2653368698108589]
	TIME [epoch: 8.55 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3930223597603598		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.3930223597603598 | validation: 0.2803961850948792]
	TIME [epoch: 8.52 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3221554572445432		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.3221554572445432 | validation: 0.29586010839649]
	TIME [epoch: 8.58 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25591807297759156		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.25591807297759156 | validation: 0.3679682462132535]
	TIME [epoch: 8.52 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3168238253078707		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.3168238253078707 | validation: 0.3389598508034404]
	TIME [epoch: 8.55 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28611026771543174		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.28611026771543174 | validation: 0.29666873104569236]
	TIME [epoch: 8.52 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2868869990023944		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.2868869990023944 | validation: 0.2502831126723734]
	TIME [epoch: 8.53 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2779364702263778		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.2779364702263778 | validation: 0.24918016264904636]
	TIME [epoch: 8.53 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29753655463500744		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.29753655463500744 | validation: 0.2653746991254958]
	TIME [epoch: 8.54 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30331996263807026		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.30331996263807026 | validation: 0.3163529846692554]
	TIME [epoch: 8.52 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.277574579707354		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.277574579707354 | validation: 0.24943120531009697]
	TIME [epoch: 8.51 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29236911309418673		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.29236911309418673 | validation: 0.3331582071378167]
	TIME [epoch: 8.53 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2605224515627909		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.2605224515627909 | validation: 0.26622182713138354]
	TIME [epoch: 8.54 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2865335384604061		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.2865335384604061 | validation: 0.28414388170364496]
	TIME [epoch: 8.52 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.278306048074468		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.278306048074468 | validation: 0.2646719029086466]
	TIME [epoch: 8.52 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30700514933619466		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.30700514933619466 | validation: 0.23810257886880465]
	TIME [epoch: 8.53 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24046786579852691		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.24046786579852691 | validation: 0.29113818757002174]
	TIME [epoch: 8.52 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2908352565430314		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.2908352565430314 | validation: 0.3687967484847083]
	TIME [epoch: 8.51 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2807650281944824		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.2807650281944824 | validation: 0.24219661776481655]
	TIME [epoch: 8.51 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2681213382425195		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.2681213382425195 | validation: 0.3278801977314926]
	TIME [epoch: 8.54 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27570903806052693		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.27570903806052693 | validation: 0.2941844694367849]
	TIME [epoch: 8.53 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556854822885888		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.2556854822885888 | validation: 0.24725017130686694]
	TIME [epoch: 8.52 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28067362037352256		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.28067362037352256 | validation: 0.25483669040839163]
	TIME [epoch: 8.53 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24576950010235404		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.24576950010235404 | validation: 0.25728968081171283]
	TIME [epoch: 8.54 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26008355495641655		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.26008355495641655 | validation: 0.3063431837087973]
	TIME [epoch: 8.53 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26900042370569616		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.26900042370569616 | validation: 0.2472452716107555]
	TIME [epoch: 8.52 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2518625045387465		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.2518625045387465 | validation: 0.2418781027834516]
	TIME [epoch: 8.52 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2686374613410485		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.2686374613410485 | validation: 0.2850252189715623]
	TIME [epoch: 8.54 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25924099063495404		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.25924099063495404 | validation: 0.22587834341780183]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_140928/states/model_tr_study4_913.pth
	Model improved!!!
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2766002910458517		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.2766002910458517 | validation: 0.25236778831320505]
	TIME [epoch: 8.52 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2807502734247994		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.2807502734247994 | validation: 0.2675187160316277]
	TIME [epoch: 8.51 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28454225716701875		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.28454225716701875 | validation: 0.2821847552860364]
	TIME [epoch: 8.54 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2702576375434454		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.2702576375434454 | validation: 0.22867690082795722]
	TIME [epoch: 8.52 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30927466256537595		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.30927466256537595 | validation: 0.3721628360556384]
	TIME [epoch: 8.52 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28061568163141914		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.28061568163141914 | validation: 0.3007461773110467]
	TIME [epoch: 8.52 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26723676640954336		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.26723676640954336 | validation: 0.30777966997133877]
	TIME [epoch: 8.55 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2678221692961066		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.2678221692961066 | validation: 0.27524490370827753]
	TIME [epoch: 8.51 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29183077667330615		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.29183077667330615 | validation: 0.33919085181753217]
	TIME [epoch: 8.52 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2744860692602667		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.2744860692602667 | validation: 0.3485663744418358]
	TIME [epoch: 8.52 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2684068217478875		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.2684068217478875 | validation: 0.2569663987746634]
	TIME [epoch: 8.54 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26039814719838217		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.26039814719838217 | validation: 0.26331703382164706]
	TIME [epoch: 8.52 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2922043643980376		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.2922043643980376 | validation: 0.3483571626372426]
	TIME [epoch: 8.52 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28097619707680543		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.28097619707680543 | validation: 0.24696492893988764]
	TIME [epoch: 8.53 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24090414358552192		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.24090414358552192 | validation: 0.38255282712037963]
	TIME [epoch: 8.53 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2834767757737477		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.2834767757737477 | validation: 0.3271725805762504]
	TIME [epoch: 8.53 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2805589395133955		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.2805589395133955 | validation: 0.2860254858963647]
	TIME [epoch: 8.52 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2833678246039666		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.2833678246039666 | validation: 0.29025430737980357]
	TIME [epoch: 8.54 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2587415314211492		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.2587415314211492 | validation: 0.23992956838605126]
	TIME [epoch: 8.53 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2566257361420874		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.2566257361420874 | validation: 0.23636746940663428]
	TIME [epoch: 8.52 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25423408669192965		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.25423408669192965 | validation: 0.3087089582587903]
	TIME [epoch: 8.52 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27543286393483213		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.27543286393483213 | validation: 0.2548364547476031]
	TIME [epoch: 8.55 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26334565801634086		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.26334565801634086 | validation: 0.26709118768656165]
	TIME [epoch: 8.53 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24834533216302884		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.24834533216302884 | validation: 0.25737395588016976]
	TIME [epoch: 8.52 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.257124515097126		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.257124515097126 | validation: 0.2548228634528963]
	TIME [epoch: 8.52 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2503025319534725		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.2503025319534725 | validation: 0.2845269716283425]
	TIME [epoch: 8.55 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2579154563077143		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.2579154563077143 | validation: 0.34922173584492405]
	TIME [epoch: 8.52 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2722595372212545		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.2722595372212545 | validation: 0.3920431657116735]
	TIME [epoch: 8.51 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2797347708086463		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.2797347708086463 | validation: 0.31322295907224273]
	TIME [epoch: 8.52 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2542037477508015		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.2542037477508015 | validation: 0.30645600027253783]
	TIME [epoch: 8.54 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2589238195754972		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.2589238195754972 | validation: 0.2488462317877559]
	TIME [epoch: 8.52 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24092260094096102		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.24092260094096102 | validation: 0.2533464353902065]
	TIME [epoch: 8.51 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2509817510145992		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.2509817510145992 | validation: 0.26446520014504055]
	TIME [epoch: 8.51 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2545379968581004		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.2545379968581004 | validation: 0.2380896396410902]
	TIME [epoch: 8.55 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2542968984234278		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.2542968984234278 | validation: 0.26681788744824303]
	TIME [epoch: 8.52 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.257702178675585		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.257702178675585 | validation: 0.2874247119570751]
	TIME [epoch: 8.52 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2516981052859375		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.2516981052859375 | validation: 0.2688363314162639]
	TIME [epoch: 8.52 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2805894245107127		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.2805894245107127 | validation: 0.29644344455936056]
	TIME [epoch: 8.55 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26566210504047605		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.26566210504047605 | validation: 0.2456593309977218]
	TIME [epoch: 8.52 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26524138512321904		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.26524138512321904 | validation: 0.2539621237128496]
	TIME [epoch: 8.52 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24433662833888006		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.24433662833888006 | validation: 0.2596329043037607]
	TIME [epoch: 8.52 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25411076787459225		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.25411076787459225 | validation: 0.266183898785296]
	TIME [epoch: 8.55 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2787533381120889		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.2787533381120889 | validation: 0.28325499900147]
	TIME [epoch: 8.52 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26342018437832754		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.26342018437832754 | validation: 0.26016552366648465]
	TIME [epoch: 8.52 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2552534949335338		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.2552534949335338 | validation: 0.30803021754283105]
	TIME [epoch: 8.53 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556101311836869		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.2556101311836869 | validation: 0.26385850481916817]
	TIME [epoch: 8.55 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26305730188468923		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.26305730188468923 | validation: 0.24567985401222545]
	TIME [epoch: 8.52 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27016614953931894		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.27016614953931894 | validation: 0.24231565853381146]
	TIME [epoch: 8.53 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25670222705163753		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.25670222705163753 | validation: 0.30286316347856]
	TIME [epoch: 8.54 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25645113487408777		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.25645113487408777 | validation: 0.2625318940259033]
	TIME [epoch: 8.54 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2665544222781474		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.2665544222781474 | validation: 0.3153130029378046]
	TIME [epoch: 8.53 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2518239879399719		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.2518239879399719 | validation: 0.2398086423923833]
	TIME [epoch: 8.52 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24751709958945517		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.24751709958945517 | validation: 0.3032784626437541]
	TIME [epoch: 8.54 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26253657605096115		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.26253657605096115 | validation: 0.29938292217577783]
	TIME [epoch: 8.53 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27751371290953675		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.27751371290953675 | validation: 0.3014661474052954]
	TIME [epoch: 8.52 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2714562262816852		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.2714562262816852 | validation: 0.27327936035208644]
	TIME [epoch: 8.52 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29732079320898314		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.29732079320898314 | validation: 0.3214322078363071]
	TIME [epoch: 8.54 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32779090681016615		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.32779090681016615 | validation: 0.2693030753301179]
	TIME [epoch: 8.52 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2468493337517696		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.2468493337517696 | validation: 0.2575804911128112]
	TIME [epoch: 8.52 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2476448003616575		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.2476448003616575 | validation: 0.2575538777184679]
	TIME [epoch: 8.51 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24887762729840918		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.24887762729840918 | validation: 0.2583688642564267]
	TIME [epoch: 8.55 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2516132123601031		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.2516132123601031 | validation: 0.28024693805609635]
	TIME [epoch: 8.52 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2572940701593773		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.2572940701593773 | validation: 0.2622287920901766]
	TIME [epoch: 8.53 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25306777050503576		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.25306777050503576 | validation: 0.2580922947597578]
	TIME [epoch: 8.53 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2522766177124475		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.2522766177124475 | validation: 0.2857987065363455]
	TIME [epoch: 8.55 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2646889702728791		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.2646889702728791 | validation: 0.2768328453308484]
	TIME [epoch: 8.52 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24340141209954552		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.24340141209954552 | validation: 0.2922017402890001]
	TIME [epoch: 8.52 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27206181150929265		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.27206181150929265 | validation: 0.3179041629647266]
	TIME [epoch: 8.51 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24542060268094162		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.24542060268094162 | validation: 0.23741134903017586]
	TIME [epoch: 8.55 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24923329056271185		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.24923329056271185 | validation: 0.23474677892189963]
	TIME [epoch: 8.51 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2454176357514616		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.2454176357514616 | validation: 0.23648765867874996]
	TIME [epoch: 8.51 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23376012893150241		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.23376012893150241 | validation: 0.270941846667461]
	TIME [epoch: 8.51 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23410062111725188		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.23410062111725188 | validation: 0.238589267786547]
	TIME [epoch: 8.54 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24378833420861187		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.24378833420861187 | validation: 0.27658742214336063]
	TIME [epoch: 8.51 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23989841433986273		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.23989841433986273 | validation: 0.2592458029927867]
	TIME [epoch: 8.51 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24644086764979303		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.24644086764979303 | validation: 0.30617391005558897]
	TIME [epoch: 8.52 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2596343402950002		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.2596343402950002 | validation: 0.26072851831070953]
	TIME [epoch: 8.53 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2763598417897576		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.2763598417897576 | validation: 0.2422069063273367]
	TIME [epoch: 8.51 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2560018756072339		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.2560018756072339 | validation: 0.23409009969367872]
	TIME [epoch: 8.5 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.258508016504353		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.258508016504353 | validation: 0.32592560655827163]
	TIME [epoch: 8.53 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29340128458632975		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.29340128458632975 | validation: 0.240319890819587]
	TIME [epoch: 8.52 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25163711022336255		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.25163711022336255 | validation: 0.2382210895851685]
	TIME [epoch: 8.51 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2800904405493231		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.2800904405493231 | validation: 0.2505463020351156]
	TIME [epoch: 8.51 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24902804616241364		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.24902804616241364 | validation: 0.25334595885400735]
	TIME [epoch: 8.53 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24302608770999842		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.24302608770999842 | validation: 0.2554542978794919]
	TIME [epoch: 8.51 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.270831503641226		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.270831503641226 | validation: 0.3289369496475092]
	TIME [epoch: 8.49 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24622812737892716		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.24622812737892716 | validation: 0.283227334783772]
	TIME [epoch: 8.5 sec]
Finished training in 8643.319 seconds.
