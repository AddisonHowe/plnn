Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r0', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 687083355

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.716267645219406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.716267645219406 | validation: 6.943356887141316]
	TIME [epoch: 79.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.098724541475354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.098724541475354 | validation: 6.940626655897756]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.72203652115857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.72203652115857 | validation: 6.6482608428840875]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.366649542526071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.366649542526071 | validation: 6.377384036317125]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.023644227120154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.023644227120154 | validation: 5.974123422868897]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.664075000645235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.664075000645235 | validation: 5.798524392937803]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.2119019928786825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2119019928786825 | validation: 6.731163797150014]
	TIME [epoch: 8.57 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.6605992686157816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6605992686157816 | validation: 5.6224322189875995]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.753353706247503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.753353706247503 | validation: 5.9827692390608265]
	TIME [epoch: 8.56 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.3175057045921985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3175057045921985 | validation: 5.248891578724279]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.211589976659135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.211589976659135 | validation: 6.0881029454619044]
	TIME [epoch: 8.57 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.062281400791639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.062281400791639 | validation: 5.201505240240122]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.914918324348736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.914918324348736 | validation: 4.903835343815302]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.838888680434296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.838888680434296 | validation: 5.816164029826717]
	TIME [epoch: 8.55 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.050163745929004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.050163745929004 | validation: 5.340544845927066]
	TIME [epoch: 8.57 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.827077523526558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.827077523526558 | validation: 5.152696022585243]
	TIME [epoch: 8.56 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.494118688624541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.494118688624541 | validation: 4.363807978482848]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.984501665599364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.984501665599364 | validation: 4.109950161898232]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.8474346761841582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8474346761841582 | validation: 4.110015547185952]
	TIME [epoch: 8.58 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.141274430140158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.141274430140158 | validation: 7.775893448354244]
	TIME [epoch: 8.55 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.680097554132876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.680097554132876 | validation: 6.496426310063736]
	TIME [epoch: 8.56 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.610712030368671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.610712030368671 | validation: 4.26854518601795]
	TIME [epoch: 8.82 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.731809154464703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.731809154464703 | validation: 5.594025017678524]
	TIME [epoch: 8.59 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.649619909140379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.649619909140379 | validation: 6.982268494865625]
	TIME [epoch: 8.57 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.149063192256358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.149063192256358 | validation: 5.336740459790703]
	TIME [epoch: 8.55 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.053865789695179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.053865789695179 | validation: 5.140460635128502]
	TIME [epoch: 8.57 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.448413788264143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.448413788264143 | validation: 3.9517903512299153]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.6046229133682823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6046229133682823 | validation: 3.952251355171547]
	TIME [epoch: 8.57 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.008725484932867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.008725484932867 | validation: 4.003258646681402]
	TIME [epoch: 8.56 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.603487357452042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.603487357452042 | validation: 5.191408868815991]
	TIME [epoch: 8.56 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.359256048169483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.359256048169483 | validation: 4.69763330501395]
	TIME [epoch: 8.6 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.8311280755947705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8311280755947705 | validation: 4.094877731466128]
	TIME [epoch: 8.56 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.200322956232454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.200322956232454 | validation: 3.1020932442653444]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.02133779724162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.02133779724162 | validation: 4.034595421679474]
	TIME [epoch: 8.58 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.157472411881361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.157472411881361 | validation: 3.1229405199395877]
	TIME [epoch: 8.59 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.624472608147608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.624472608147608 | validation: 2.8948348560892256]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3630013724272345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3630013724272345 | validation: 3.0546313563418055]
	TIME [epoch: 8.57 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.6447475223743533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6447475223743533 | validation: 2.4244224602282087]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.934108353594503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.934108353594503 | validation: 2.7591536163699217]
	TIME [epoch: 8.57 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.7749811545455443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7749811545455443 | validation: 2.6986325467905843]
	TIME [epoch: 8.56 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.332373225211584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.332373225211584 | validation: 4.509740209175751]
	TIME [epoch: 8.56 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.2215702082591973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2215702082591973 | validation: 3.289226691503985]
	TIME [epoch: 8.58 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.34585373466813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.34585373466813 | validation: 2.315129332135835]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2510805865690964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2510805865690964 | validation: 2.1839007204058287]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2742503598786663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2742503598786663 | validation: 1.9385163936263492]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8156349989952187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8156349989952187 | validation: 1.599567908540571]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_46.pth
	Model improved!!!
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1736629136370196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1736629136370196 | validation: 2.0182321335302214]
	TIME [epoch: 8.56 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.033292399936131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.033292399936131 | validation: 1.8437737738660473]
	TIME [epoch: 8.56 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8998396134537898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8998396134537898 | validation: 1.7955149524794427]
	TIME [epoch: 8.56 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.764773510982361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.764773510982361 | validation: 3.0083697863370054]
	TIME [epoch: 8.59 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.05000796040324		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 2.05000796040324 | validation: 2.6289846149084353]
	TIME [epoch: 8.56 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0161023400636604		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 2.0161023400636604 | validation: 1.806157716458587]
	TIME [epoch: 8.56 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7811150302490497		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 1.7811150302490497 | validation: 1.564046370867774]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_53.pth
	Model improved!!!
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7871474801508291		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 1.7871474801508291 | validation: 2.5073037133735347]
	TIME [epoch: 8.59 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.801278902329105		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 1.801278902329105 | validation: 3.1657921214336704]
	TIME [epoch: 8.55 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7881230692395118		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 1.7881230692395118 | validation: 1.4586363279222683]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8784281569677397		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 1.8784281569677397 | validation: 1.4879769603110227]
	TIME [epoch: 8.56 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.620530427833644		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 1.620530427833644 | validation: 1.8510457324319443]
	TIME [epoch: 8.57 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.56910707210295		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 1.56910707210295 | validation: 1.4573010166485525]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_59.pth
	Model improved!!!
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.785473860286413		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 1.785473860286413 | validation: 1.5240881783439026]
	TIME [epoch: 8.55 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.63437579042773		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 1.63437579042773 | validation: 1.2550662316511905]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_61.pth
	Model improved!!!
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4388128128101498		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 1.4388128128101498 | validation: 1.5996801168068964]
	TIME [epoch: 8.56 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5051232233781862		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 1.5051232233781862 | validation: 2.82923575596724]
	TIME [epoch: 8.54 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7321289068779542		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 1.7321289068779542 | validation: 1.3663722279368673]
	TIME [epoch: 8.55 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5521392424149265		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 1.5521392424149265 | validation: 1.3940650399993841]
	TIME [epoch: 8.57 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4862161193456989		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 1.4862161193456989 | validation: 1.3820085578058858]
	TIME [epoch: 8.55 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5610446616921183		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 1.5610446616921183 | validation: 2.168413527120767]
	TIME [epoch: 8.54 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4418839444564842		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 1.4418839444564842 | validation: 1.3916626933173981]
	TIME [epoch: 8.54 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4779811376382712		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 1.4779811376382712 | validation: 1.4442228473833256]
	TIME [epoch: 8.57 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7886743766209428		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 1.7886743766209428 | validation: 1.987999708871337]
	TIME [epoch: 8.55 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8286555962261724		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.8286555962261724 | validation: 1.473553422410042]
	TIME [epoch: 8.55 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5210354993993547		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 1.5210354993993547 | validation: 1.6372254307057754]
	TIME [epoch: 8.55 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0281373413374912		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 2.0281373413374912 | validation: 2.2079314802446897]
	TIME [epoch: 8.58 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5802903304861906		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 1.5802903304861906 | validation: 1.2813157317937596]
	TIME [epoch: 8.55 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3689965539250604		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 1.3689965539250604 | validation: 1.5403608866771745]
	TIME [epoch: 8.55 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.503408359758039		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 1.503408359758039 | validation: 1.187821355767267]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_76.pth
	Model improved!!!
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4120963695981315		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 1.4120963695981315 | validation: 1.1100548554056844]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_77.pth
	Model improved!!!
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.348417586072809		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 1.348417586072809 | validation: 1.7217303477797006]
	TIME [epoch: 8.55 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6015215455385767		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 1.6015215455385767 | validation: 1.166124551705645]
	TIME [epoch: 8.55 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.470411705349956		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 1.470411705349956 | validation: 1.453404093872836]
	TIME [epoch: 8.54 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3755730709351188		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 1.3755730709351188 | validation: 1.016783960345774]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_81.pth
	Model improved!!!
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7071597181622145		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 1.7071597181622145 | validation: 1.3175050979159022]
	TIME [epoch: 8.55 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2939986721776915		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 1.2939986721776915 | validation: 1.394934460594465]
	TIME [epoch: 8.54 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4534725925921237		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 1.4534725925921237 | validation: 1.183185540429631]
	TIME [epoch: 8.55 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3547407058789571		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 1.3547407058789571 | validation: 1.2591415879602186]
	TIME [epoch: 8.57 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4326720795314047		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 1.4326720795314047 | validation: 1.5645004194644891]
	TIME [epoch: 8.54 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.519427233524659		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 1.519427233524659 | validation: 1.4085513764241522]
	TIME [epoch: 8.54 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3304318611202237		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.3304318611202237 | validation: 1.0918753688400185]
	TIME [epoch: 8.57 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5446423010978894		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.5446423010978894 | validation: 1.1717425507225196]
	TIME [epoch: 8.55 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5125161104710876		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.5125161104710876 | validation: 1.3685646003797198]
	TIME [epoch: 8.54 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5220836953507622		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 1.5220836953507622 | validation: 1.020050186328669]
	TIME [epoch: 8.54 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.381782830106325		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 1.381782830106325 | validation: 1.3720408798792012]
	TIME [epoch: 8.57 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4388970468951083		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 1.4388970468951083 | validation: 1.4610741907491047]
	TIME [epoch: 8.55 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5745535485896966		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 1.5745535485896966 | validation: 1.5570319464690194]
	TIME [epoch: 8.55 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6028545140742367		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 1.6028545140742367 | validation: 1.6101744691612694]
	TIME [epoch: 8.54 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.796143690423245		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.796143690423245 | validation: 1.240215916740754]
	TIME [epoch: 8.57 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.870949896706194		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 1.870949896706194 | validation: 1.6918577903160197]
	TIME [epoch: 8.54 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6225923639981321		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.6225923639981321 | validation: 1.532431982149216]
	TIME [epoch: 8.54 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.472709579955836		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.472709579955836 | validation: 1.7635103704831363]
	TIME [epoch: 8.54 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.524060977204724		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.524060977204724 | validation: 2.5357850186669864]
	TIME [epoch: 8.57 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.77180801238103		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.77180801238103 | validation: 1.8512653545438145]
	TIME [epoch: 8.55 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5527572209151934		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.5527572209151934 | validation: 1.5631789012836335]
	TIME [epoch: 8.54 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7264628722756246		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.7264628722756246 | validation: 1.6376082871611493]
	TIME [epoch: 8.55 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5402141206310804		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.5402141206310804 | validation: 1.3586416485405102]
	TIME [epoch: 8.57 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5719623348562728		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 1.5719623348562728 | validation: 1.4897047953662463]
	TIME [epoch: 8.54 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.442480553129339		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 1.442480553129339 | validation: 1.3990755792654779]
	TIME [epoch: 8.55 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1025330397136104		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 2.1025330397136104 | validation: 1.4972774095803134]
	TIME [epoch: 8.55 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5800447583677981		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.5800447583677981 | validation: 1.3321227895670915]
	TIME [epoch: 8.58 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.275793874668874		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.275793874668874 | validation: 1.0440489543017057]
	TIME [epoch: 8.55 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.372147294848592		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.372147294848592 | validation: 1.148773659375783]
	TIME [epoch: 8.55 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3327378288007434		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.3327378288007434 | validation: 1.2695248540336068]
	TIME [epoch: 8.55 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.540023681442809		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 1.540023681442809 | validation: 1.3038714892951424]
	TIME [epoch: 8.58 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5784501350836213		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 1.5784501350836213 | validation: 1.1887874149253332]
	TIME [epoch: 8.55 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5233625657166674		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 1.5233625657166674 | validation: 1.2770347768731376]
	TIME [epoch: 8.55 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3789612989124123		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.3789612989124123 | validation: 1.2552795659502274]
	TIME [epoch: 8.56 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3390177027489285		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 1.3390177027489285 | validation: 1.4263435332796481]
	TIME [epoch: 8.58 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.779512486533963		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 1.779512486533963 | validation: 1.463888737758182]
	TIME [epoch: 8.55 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5140388053227996		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 1.5140388053227996 | validation: 1.5041576240378336]
	TIME [epoch: 8.55 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5571290371420328		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 1.5571290371420328 | validation: 1.6744465243399929]
	TIME [epoch: 8.56 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4710514014813274		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.4710514014813274 | validation: 1.518061525729703]
	TIME [epoch: 8.55 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.459643881168475		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 1.459643881168475 | validation: 1.4205106922523894]
	TIME [epoch: 8.54 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3891788472867812		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 1.3891788472867812 | validation: 1.3459622203967219]
	TIME [epoch: 8.56 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.813388345940782		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 1.813388345940782 | validation: 2.028067953457361]
	TIME [epoch: 8.57 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4029195576455542		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 1.4029195576455542 | validation: 1.2702028137758736]
	TIME [epoch: 8.55 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5905381969800911		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 1.5905381969800911 | validation: 1.3805380813116856]
	TIME [epoch: 8.55 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.445959129919012		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 1.445959129919012 | validation: 1.163916988470795]
	TIME [epoch: 8.55 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4246299934265294		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 1.4246299934265294 | validation: 1.692275454748983]
	TIME [epoch: 8.58 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4813650658383601		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.4813650658383601 | validation: 1.293597131625909]
	TIME [epoch: 8.56 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4872061275245656		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 1.4872061275245656 | validation: 1.5676473094958991]
	TIME [epoch: 8.55 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7898756975871102		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 1.7898756975871102 | validation: 1.3140991768636212]
	TIME [epoch: 8.54 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.550612236854306		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 1.550612236854306 | validation: 1.3696058645271316]
	TIME [epoch: 8.57 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5528891207654352		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 1.5528891207654352 | validation: 2.016466978502677]
	TIME [epoch: 8.55 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4884248253692216		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 1.4884248253692216 | validation: 1.2214623698010303]
	TIME [epoch: 8.54 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4693369146203257		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 1.4693369146203257 | validation: 1.290027261009249]
	TIME [epoch: 8.54 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3084821489781258		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 1.3084821489781258 | validation: 2.39172940672898]
	TIME [epoch: 8.57 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6840688995426518		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 1.6840688995426518 | validation: 1.1535898525626629]
	TIME [epoch: 8.56 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3291945666676148		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 1.3291945666676148 | validation: 1.411347977984276]
	TIME [epoch: 8.56 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6311580261845897		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.6311580261845897 | validation: 1.9283758848989865]
	TIME [epoch: 8.55 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6930731395592833		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 1.6930731395592833 | validation: 1.1468367830226938]
	TIME [epoch: 8.58 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.325740486944577		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 1.325740486944577 | validation: 1.283013724676251]
	TIME [epoch: 8.55 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3158316666858312		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 1.3158316666858312 | validation: 1.4152691739458882]
	TIME [epoch: 8.55 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5376047701155509		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 1.5376047701155509 | validation: 1.0555823955609749]
	TIME [epoch: 8.54 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2993739100309198		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 1.2993739100309198 | validation: 1.8864700706529205]
	TIME [epoch: 8.58 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5134318439378993		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 1.5134318439378993 | validation: 1.4844146358890766]
	TIME [epoch: 8.55 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.488377617124978		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 1.488377617124978 | validation: 2.4800709243424057]
	TIME [epoch: 8.55 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.479164189145544		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 1.479164189145544 | validation: 1.301485326658007]
	TIME [epoch: 8.57 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4072002433298019		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 1.4072002433298019 | validation: 1.4863161540856615]
	TIME [epoch: 8.57 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4397130198719839		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 1.4397130198719839 | validation: 1.290368280587504]
	TIME [epoch: 8.55 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5265565406416983		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 1.5265565406416983 | validation: 1.1992730821175037]
	TIME [epoch: 8.55 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3174938822604774		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 1.3174938822604774 | validation: 2.28086779064924]
	TIME [epoch: 8.56 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.608758283976427		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 1.608758283976427 | validation: 1.2803286275338723]
	TIME [epoch: 8.57 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6036586441350429		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 1.6036586441350429 | validation: 1.385482346736152]
	TIME [epoch: 8.54 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7265394709310395		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 1.7265394709310395 | validation: 3.1094516294950205]
	TIME [epoch: 8.55 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.5032843187046145		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 2.5032843187046145 | validation: 2.3765524576779544]
	TIME [epoch: 8.58 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.512710091854219		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 1.512710091854219 | validation: 1.485503751494684]
	TIME [epoch: 8.56 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.410233120337654		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 1.410233120337654 | validation: 1.3467063623793174]
	TIME [epoch: 8.56 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5514151068864674		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 1.5514151068864674 | validation: 1.6494741780815136]
	TIME [epoch: 8.55 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5686766614456977		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 1.5686766614456977 | validation: 1.3072120991428835]
	TIME [epoch: 8.58 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3268586916018532		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 1.3268586916018532 | validation: 1.4481795067602707]
	TIME [epoch: 8.56 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3771690460254664		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 1.3771690460254664 | validation: 1.0861113190735465]
	TIME [epoch: 8.55 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2865434242913465		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 1.2865434242913465 | validation: 1.1786258921504058]
	TIME [epoch: 8.55 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.175408609366503		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 1.175408609366503 | validation: 1.702072652790604]
	TIME [epoch: 8.58 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5414180075847956		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 1.5414180075847956 | validation: 1.3884813978157093]
	TIME [epoch: 8.56 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.319653708035272		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 1.319653708035272 | validation: 1.263031094106132]
	TIME [epoch: 8.56 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.512318543592411		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 1.512318543592411 | validation: 1.098441967067741]
	TIME [epoch: 8.55 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3768610593114843		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 1.3768610593114843 | validation: 1.4459387672011952]
	TIME [epoch: 8.58 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7020477136666468		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 1.7020477136666468 | validation: 1.6920146626074481]
	TIME [epoch: 8.56 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6961800681159147		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 1.6961800681159147 | validation: 1.1896092851566666]
	TIME [epoch: 8.55 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.01240434826241		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 2.01240434826241 | validation: 1.2367839497823878]
	TIME [epoch: 8.55 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3224739784286856		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 1.3224739784286856 | validation: 1.5559057054838528]
	TIME [epoch: 8.58 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3996471767146956		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 1.3996471767146956 | validation: 1.4627989298081956]
	TIME [epoch: 8.56 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2717791282078053		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 1.2717791282078053 | validation: 1.3629731446800029]
	TIME [epoch: 8.55 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2629863922324251		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 1.2629863922324251 | validation: 1.4050448191859717]
	TIME [epoch: 8.55 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6335230421089348		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 1.6335230421089348 | validation: 1.0468012025298896]
	TIME [epoch: 8.58 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.242599568893913		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 1.242599568893913 | validation: 0.9860940481500553]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_175.pth
	Model improved!!!
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6635065963260096		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 1.6635065963260096 | validation: 1.5076939885411775]
	TIME [epoch: 8.54 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3798340880032807		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 1.3798340880032807 | validation: 1.576885861527246]
	TIME [epoch: 8.57 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8020563615863843		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 1.8020563615863843 | validation: 1.221846459504054]
	TIME [epoch: 8.56 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5123394339723704		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 1.5123394339723704 | validation: 1.6079244853211847]
	TIME [epoch: 8.56 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5913774477185092		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 1.5913774477185092 | validation: 1.8613966098434487]
	TIME [epoch: 8.54 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3097401989732373		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 1.3097401989732373 | validation: 1.483775552754918]
	TIME [epoch: 8.56 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3374800778562985		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 1.3374800778562985 | validation: 1.8627966093268404]
	TIME [epoch: 8.55 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3688619799240676		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 1.3688619799240676 | validation: 1.1029614790162565]
	TIME [epoch: 8.54 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3307147498713545		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 1.3307147498713545 | validation: 0.938548433159889]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_184.pth
	Model improved!!!
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.193574692717242		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 1.193574692717242 | validation: 0.9423513842855706]
	TIME [epoch: 8.57 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.249507444200587		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 1.249507444200587 | validation: 1.247339533929663]
	TIME [epoch: 8.55 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2571858355644707		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 1.2571858355644707 | validation: 2.012488030749966]
	TIME [epoch: 8.54 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2337515445095542		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 1.2337515445095542 | validation: 0.8832100726875273]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_188.pth
	Model improved!!!
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3268890801074598		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 1.3268890801074598 | validation: 1.2422660440502662]
	TIME [epoch: 8.57 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.836769244076984		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 1.836769244076984 | validation: 2.4697295595228685]
	TIME [epoch: 8.55 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7041740962768404		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 1.7041740962768404 | validation: 1.2892916460278459]
	TIME [epoch: 8.54 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2612841583814787		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 1.2612841583814787 | validation: 2.1060989343854297]
	TIME [epoch: 8.55 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7318994586539769		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 1.7318994586539769 | validation: 2.291887949239579]
	TIME [epoch: 8.57 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3882228403482362		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 1.3882228403482362 | validation: 1.0552822722224384]
	TIME [epoch: 8.54 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3302290391531049		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 1.3302290391531049 | validation: 0.8621006979682617]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_195.pth
	Model improved!!!
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2186481227343025		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 1.2186481227343025 | validation: 0.9832159565482878]
	TIME [epoch: 8.55 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.153674971474108		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 1.153674971474108 | validation: 0.8893637322589603]
	TIME [epoch: 8.57 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2763244374108766		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 1.2763244374108766 | validation: 0.9884303929739966]
	TIME [epoch: 8.54 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1186562052696811		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 1.1186562052696811 | validation: 1.042827507064128]
	TIME [epoch: 8.55 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1926450426778428		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 1.1926450426778428 | validation: 1.1114890451974075]
	TIME [epoch: 8.54 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1416134809308771		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 1.1416134809308771 | validation: 0.9306399137537884]
	TIME [epoch: 8.58 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.229484290054289		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 1.229484290054289 | validation: 0.8701351737202648]
	TIME [epoch: 8.54 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1612715305289725		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 1.1612715305289725 | validation: 1.279912288877711]
	TIME [epoch: 8.53 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2166679020612845		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 1.2166679020612845 | validation: 0.9435041054325672]
	TIME [epoch: 8.55 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0467398939951007		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 1.0467398939951007 | validation: 1.2433336838886602]
	TIME [epoch: 8.57 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0750757756948282		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 1.0750757756948282 | validation: 1.4944431477216322]
	TIME [epoch: 8.55 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2001900167780541		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 1.2001900167780541 | validation: 2.2474478393122808]
	TIME [epoch: 8.54 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2576528146817476		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 1.2576528146817476 | validation: 0.9467102196008335]
	TIME [epoch: 8.57 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.086995043667946		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 1.086995043667946 | validation: 1.2980729012748862]
	TIME [epoch: 8.56 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.154095848562316		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 1.154095848562316 | validation: 1.0620211301178601]
	TIME [epoch: 8.55 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2319028333109372		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 1.2319028333109372 | validation: 1.1372627146115508]
	TIME [epoch: 8.55 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.167634921425144		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 1.167634921425144 | validation: 0.9296437029633482]
	TIME [epoch: 8.57 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2698094515296052		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 1.2698094515296052 | validation: 0.9625523004068155]
	TIME [epoch: 8.55 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2638497384662117		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 1.2638497384662117 | validation: 1.0284115100528333]
	TIME [epoch: 8.55 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.497943933972767		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 1.497943933972767 | validation: 1.2390290102749848]
	TIME [epoch: 8.55 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1466104876059187		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 1.1466104876059187 | validation: 1.0211780590919473]
	TIME [epoch: 8.58 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.299171933942655		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 1.299171933942655 | validation: 1.1778817301833917]
	TIME [epoch: 8.55 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1842457444780967		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 1.1842457444780967 | validation: 1.0615003801854161]
	TIME [epoch: 8.55 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.12900881186213		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 1.12900881186213 | validation: 1.1127174362088377]
	TIME [epoch: 8.54 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1573028052307277		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 1.1573028052307277 | validation: 0.8549011489606586]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_220.pth
	Model improved!!!
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2969758098313098		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 1.2969758098313098 | validation: 1.0104713497553046]
	TIME [epoch: 8.54 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1921762292327347		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 1.1921762292327347 | validation: 1.1585201185821346]
	TIME [epoch: 8.54 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2284248316604023		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 1.2284248316604023 | validation: 1.2547906322109896]
	TIME [epoch: 8.54 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2649070469801988		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 1.2649070469801988 | validation: 1.0989590253699286]
	TIME [epoch: 8.57 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.354832509835024		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 1.354832509835024 | validation: 1.1105727070992746]
	TIME [epoch: 8.54 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0932695086688735		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 1.0932695086688735 | validation: 1.0716618933093067]
	TIME [epoch: 8.54 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4267905519037978		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 1.4267905519037978 | validation: 1.0647437454765782]
	TIME [epoch: 8.54 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0812899330543524		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 1.0812899330543524 | validation: 1.0499117408189202]
	TIME [epoch: 8.56 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1700885768542433		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 1.1700885768542433 | validation: 0.8869781656613233]
	TIME [epoch: 8.54 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0871417048755512		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 1.0871417048755512 | validation: 1.1583132687306885]
	TIME [epoch: 8.54 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0866153386595443		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 1.0866153386595443 | validation: 1.5826148735722558]
	TIME [epoch: 8.55 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1342208912676202		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 1.1342208912676202 | validation: 0.783875844743241]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_232.pth
	Model improved!!!
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9180078243636722		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 1.9180078243636722 | validation: 1.170305843981104]
	TIME [epoch: 8.55 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1472389294468188		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 1.1472389294468188 | validation: 1.005288953189681]
	TIME [epoch: 8.54 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0405577058401025		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 1.0405577058401025 | validation: 1.0122624425683457]
	TIME [epoch: 8.56 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0586827020037868		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 1.0586827020037868 | validation: 1.3790034151950477]
	TIME [epoch: 8.55 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0919774578633235		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 1.0919774578633235 | validation: 0.9723140716536783]
	TIME [epoch: 8.54 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.132637393030006		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 1.132637393030006 | validation: 1.0334011243232015]
	TIME [epoch: 8.54 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0722733758649692		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 1.0722733758649692 | validation: 0.8955814808983387]
	TIME [epoch: 8.56 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0933043879324802		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 1.0933043879324802 | validation: 2.619398444591239]
	TIME [epoch: 8.55 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2080904216029387		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 1.2080904216029387 | validation: 1.40189459213118]
	TIME [epoch: 8.54 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.059611431010345		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 1.059611431010345 | validation: 1.5143679314272207]
	TIME [epoch: 8.54 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0548261535777073		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 1.0548261535777073 | validation: 1.0270257896838537]
	TIME [epoch: 8.56 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0894784616357918		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 1.0894784616357918 | validation: 0.990837758578635]
	TIME [epoch: 8.54 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1079942867346295		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 1.1079942867346295 | validation: 1.969380496752708]
	TIME [epoch: 8.52 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.09781451956056		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 1.09781451956056 | validation: 1.129739957886116]
	TIME [epoch: 8.52 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.973639826686699		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.973639826686699 | validation: 1.1860699769835874]
	TIME [epoch: 8.55 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1262411294725092		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 1.1262411294725092 | validation: 0.8483047673607771]
	TIME [epoch: 8.52 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0383026763507737		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 1.0383026763507737 | validation: 0.8227706864399222]
	TIME [epoch: 8.52 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0421187875209625		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 1.0421187875209625 | validation: 0.8876771878383337]
	TIME [epoch: 8.51 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9846622568412071		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.9846622568412071 | validation: 0.7922636527780478]
	TIME [epoch: 8.55 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.053529734639541		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 1.053529734639541 | validation: 0.8476641674681252]
	TIME [epoch: 8.53 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0985213535385199		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 1.0985213535385199 | validation: 1.0373911603920736]
	TIME [epoch: 8.52 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1279177030299103		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 1.1279177030299103 | validation: 0.9713818188584411]
	TIME [epoch: 8.51 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1176866492462365		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 1.1176866492462365 | validation: 1.6672745314325994]
	TIME [epoch: 8.55 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1940849662227824		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 1.1940849662227824 | validation: 1.4461484833100382]
	TIME [epoch: 8.52 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.113156117081218		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 1.113156117081218 | validation: 0.7419755900101492]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_257.pth
	Model improved!!!
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.002027562060432		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 1.002027562060432 | validation: 0.8050585099953009]
	TIME [epoch: 8.54 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1660211823269742		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 1.1660211823269742 | validation: 1.0775366460515887]
	TIME [epoch: 8.55 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0582210225622786		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 1.0582210225622786 | validation: 0.7515335626211531]
	TIME [epoch: 8.53 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.006389083419793		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 1.006389083419793 | validation: 0.9790061216505921]
	TIME [epoch: 8.51 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0935847126563667		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 1.0935847126563667 | validation: 0.9383709133188107]
	TIME [epoch: 8.54 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0735417900664588		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 1.0735417900664588 | validation: 0.8784403766187622]
	TIME [epoch: 8.55 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9847886909446917		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.9847886909446917 | validation: 0.8561401825478246]
	TIME [epoch: 8.52 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1006429873738346		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 1.1006429873738346 | validation: 0.7783402201641967]
	TIME [epoch: 8.53 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9289833167799806		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.9289833167799806 | validation: 0.911076441643359]
	TIME [epoch: 8.54 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4603411942177058		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 1.4603411942177058 | validation: 1.3714401048508644]
	TIME [epoch: 8.54 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0216557907430581		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 1.0216557907430581 | validation: 0.9860059475291327]
	TIME [epoch: 8.52 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9073380435928009		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.9073380435928009 | validation: 1.2667802881269088]
	TIME [epoch: 8.52 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9378017418497991		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.9378017418497991 | validation: 1.6063755126722619]
	TIME [epoch: 8.54 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1369219875021181		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 1.1369219875021181 | validation: 0.7040612138268773]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_271.pth
	Model improved!!!
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9519240020889423		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.9519240020889423 | validation: 1.024352499208649]
	TIME [epoch: 8.54 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.250490910634997		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 1.250490910634997 | validation: 1.0480789908115753]
	TIME [epoch: 8.53 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0367218257746398		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 1.0367218257746398 | validation: 0.9292986435055056]
	TIME [epoch: 8.55 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9907328433365254		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.9907328433365254 | validation: 0.9285822652714102]
	TIME [epoch: 8.52 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8941566231829704		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.8941566231829704 | validation: 0.8135226109425503]
	TIME [epoch: 8.52 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9958463018351038		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.9958463018351038 | validation: 1.3340868960331673]
	TIME [epoch: 8.53 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0426116188003776		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 1.0426116188003776 | validation: 0.8602732371611792]
	TIME [epoch: 8.55 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.040870727394949		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 1.040870727394949 | validation: 0.8519516030609562]
	TIME [epoch: 8.53 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9980892890751252		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.9980892890751252 | validation: 1.539351407160396]
	TIME [epoch: 8.52 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0194726497441144		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 1.0194726497441144 | validation: 0.7473799487189379]
	TIME [epoch: 8.53 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.928218628389191		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.928218628389191 | validation: 0.9634817322630405]
	TIME [epoch: 8.54 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9617757473167117		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.9617757473167117 | validation: 0.6757632152271291]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_283.pth
	Model improved!!!
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1437663457898157		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 1.1437663457898157 | validation: 0.6721113833963024]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_284.pth
	Model improved!!!
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8617298629666523		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.8617298629666523 | validation: 1.2972717083931706]
	TIME [epoch: 8.55 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9284806444989689		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.9284806444989689 | validation: 0.8409153936847142]
	TIME [epoch: 8.57 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8953331242929504		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.8953331242929504 | validation: 0.7906097070653832]
	TIME [epoch: 8.54 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0569399305730558		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 1.0569399305730558 | validation: 1.0553990749120201]
	TIME [epoch: 8.55 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9318756298121119		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.9318756298121119 | validation: 0.8664486020328686]
	TIME [epoch: 8.54 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8584097905189939		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.8584097905189939 | validation: 0.9022079521073709]
	TIME [epoch: 8.57 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9772885145275414		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.9772885145275414 | validation: 0.6852663595424624]
	TIME [epoch: 8.54 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9673778432975967		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.9673778432975967 | validation: 0.6893150641686666]
	TIME [epoch: 8.54 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8196028480759038		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.8196028480759038 | validation: 0.9238952546474881]
	TIME [epoch: 8.55 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2182207263306681		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 1.2182207263306681 | validation: 0.689990956455415]
	TIME [epoch: 8.56 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0359919060703415		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 1.0359919060703415 | validation: 0.9097848829695094]
	TIME [epoch: 8.54 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8793910079709344		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.8793910079709344 | validation: 0.8094315211562604]
	TIME [epoch: 8.54 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1212718232013714		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 1.1212718232013714 | validation: 0.8585197239240435]
	TIME [epoch: 8.56 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8473567972738323		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.8473567972738323 | validation: 0.6626230254755808]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_298.pth
	Model improved!!!
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1297209078518686		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 1.1297209078518686 | validation: 0.6479584871910139]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_299.pth
	Model improved!!!
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9760530922046442		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.9760530922046442 | validation: 0.8823155457293742]
	TIME [epoch: 8.54 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8310708789316529		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.8310708789316529 | validation: 0.709590318139592]
	TIME [epoch: 8.57 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.782117393599256		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.782117393599256 | validation: 0.8144689498353115]
	TIME [epoch: 8.55 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8608174185020621		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.8608174185020621 | validation: 0.8533259362514485]
	TIME [epoch: 8.55 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8759566506546463		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.8759566506546463 | validation: 0.8311105716887914]
	TIME [epoch: 8.55 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8757866228500107		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.8757866228500107 | validation: 0.6155508697515033]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_305.pth
	Model improved!!!
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.92688334557558		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.92688334557558 | validation: 0.7690486194294344]
	TIME [epoch: 8.55 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8575022324573816		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.8575022324573816 | validation: 1.822334122730786]
	TIME [epoch: 8.55 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0265095167987177		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 1.0265095167987177 | validation: 1.045682156621764]
	TIME [epoch: 8.54 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8274500217948667		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.8274500217948667 | validation: 0.779501388959932]
	TIME [epoch: 8.57 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8022666659407912		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.8022666659407912 | validation: 0.7434112157943134]
	TIME [epoch: 8.54 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8995831135328698		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.8995831135328698 | validation: 0.889053816173458]
	TIME [epoch: 8.54 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8266323771976033		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.8266323771976033 | validation: 0.8722983174968384]
	TIME [epoch: 8.54 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8346236126405678		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.8346236126405678 | validation: 1.186694126001233]
	TIME [epoch: 8.57 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.104081857404747		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 1.104081857404747 | validation: 0.8553110197639064]
	TIME [epoch: 8.54 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9825935037999068		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.9825935037999068 | validation: 0.8928323717031599]
	TIME [epoch: 8.54 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9428687454568456		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.9428687454568456 | validation: 0.8539312632033842]
	TIME [epoch: 8.55 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9134703359555172		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.9134703359555172 | validation: 0.739775404751778]
	TIME [epoch: 8.57 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7351879531265278		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.7351879531265278 | validation: 0.7551122083024496]
	TIME [epoch: 8.54 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8170346841136895		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.8170346841136895 | validation: 0.8151266596903255]
	TIME [epoch: 8.54 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7964867141862209		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.7964867141862209 | validation: 0.6710294319226617]
	TIME [epoch: 8.55 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8175619936992119		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.8175619936992119 | validation: 0.7692936288500831]
	TIME [epoch: 8.56 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8592084109921874		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.8592084109921874 | validation: 1.1087520342539237]
	TIME [epoch: 8.54 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8294554440972373		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.8294554440972373 | validation: 0.9115435706639381]
	TIME [epoch: 8.54 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0740683058105844		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 1.0740683058105844 | validation: 1.2424447671383714]
	TIME [epoch: 8.56 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0670495179218737		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 1.0670495179218737 | validation: 1.1022373766834042]
	TIME [epoch: 8.55 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9659315300111256		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.9659315300111256 | validation: 1.0902779542175995]
	TIME [epoch: 8.54 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8758090980858253		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.8758090980858253 | validation: 1.0185712904682749]
	TIME [epoch: 8.54 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8135401193433788		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.8135401193433788 | validation: 1.3192730783620865]
	TIME [epoch: 8.57 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9802290755191942		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.9802290755191942 | validation: 0.9672843441772737]
	TIME [epoch: 8.55 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9988759557002386		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.9988759557002386 | validation: 1.1456011225043423]
	TIME [epoch: 8.55 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8827816866238081		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.8827816866238081 | validation: 0.9807890932199448]
	TIME [epoch: 8.54 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9553226395274557		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.9553226395274557 | validation: 0.8991487073358362]
	TIME [epoch: 8.57 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8541343052113639		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.8541343052113639 | validation: 0.6012492981379977]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_333.pth
	Model improved!!!
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8302521491274341		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.8302521491274341 | validation: 0.5935083158017567]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_334.pth
	Model improved!!!
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7895134374522159		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.7895134374522159 | validation: 0.9154698852892621]
	TIME [epoch: 8.54 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9793124979808049		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.9793124979808049 | validation: 0.6297019372766484]
	TIME [epoch: 8.56 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7362043156524202		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.7362043156524202 | validation: 1.2918071549241694]
	TIME [epoch: 8.54 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.968563859788204		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.968563859788204 | validation: 0.6541652207155035]
	TIME [epoch: 8.53 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7820615574646437		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.7820615574646437 | validation: 0.6925116663082458]
	TIME [epoch: 8.54 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8214678930586219		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.8214678930586219 | validation: 1.0354380912066676]
	TIME [epoch: 8.56 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8277566136943509		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.8277566136943509 | validation: 0.5123364668414988]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_341.pth
	Model improved!!!
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7083585502001932		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.7083585502001932 | validation: 0.8115185226155593]
	TIME [epoch: 8.54 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7907535762295006		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.7907535762295006 | validation: 0.7726120351656318]
	TIME [epoch: 8.53 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8138761306181481		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.8138761306181481 | validation: 1.0592777649079652]
	TIME [epoch: 8.57 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8861548338790126		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.8861548338790126 | validation: 0.661351236959719]
	TIME [epoch: 8.54 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8040272754143475		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.8040272754143475 | validation: 1.373704369611894]
	TIME [epoch: 8.54 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.827139816333094		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.827139816333094 | validation: 0.722099060235258]
	TIME [epoch: 8.55 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.696917003774572		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.696917003774572 | validation: 1.0525810005912932]
	TIME [epoch: 8.56 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7599395282669803		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.7599395282669803 | validation: 0.8062056426321047]
	TIME [epoch: 8.54 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7570727625977546		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.7570727625977546 | validation: 0.5437083985114968]
	TIME [epoch: 8.54 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8946784811851558		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.8946784811851558 | validation: 0.9080914275108765]
	TIME [epoch: 8.56 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7832685656947029		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.7832685656947029 | validation: 0.8717675709706763]
	TIME [epoch: 8.55 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.826056642242602		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.826056642242602 | validation: 0.7617939610896239]
	TIME [epoch: 8.54 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7117490722545978		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.7117490722545978 | validation: 0.8443519692284789]
	TIME [epoch: 8.54 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6502909250709594		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.6502909250709594 | validation: 0.7907622686615422]
	TIME [epoch: 8.56 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7625852961917026		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.7625852961917026 | validation: 0.5644483171167283]
	TIME [epoch: 8.55 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6751008933585054		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.6751008933585054 | validation: 0.5458907436137099]
	TIME [epoch: 8.54 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6973713694992328		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.6973713694992328 | validation: 0.920265581630983]
	TIME [epoch: 8.54 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.726894257100741		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.726894257100741 | validation: 0.791040370324714]
	TIME [epoch: 8.56 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6811833034485164		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.6811833034485164 | validation: 0.8389189641201467]
	TIME [epoch: 8.54 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7118563234637743		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.7118563234637743 | validation: 0.6770166610897652]
	TIME [epoch: 8.54 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8535521859620923		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.8535521859620923 | validation: 0.9498361086328594]
	TIME [epoch: 8.54 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.677233574226009		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.677233574226009 | validation: 1.3960002329339025]
	TIME [epoch: 8.56 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0534692274289272		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 1.0534692274289272 | validation: 0.9206250445868094]
	TIME [epoch: 8.54 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7827988195514255		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.7827988195514255 | validation: 0.4469526309069095]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_365.pth
	Model improved!!!
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7040371107937168		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.7040371107937168 | validation: 1.5339352466118301]
	TIME [epoch: 8.54 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9210442185561313		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.9210442185561313 | validation: 0.8235389005580382]
	TIME [epoch: 8.56 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9102471845129803		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.9102471845129803 | validation: 1.1524638091099713]
	TIME [epoch: 8.54 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7057326417013455		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.7057326417013455 | validation: 0.4396475670474943]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_369.pth
	Model improved!!!
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7267747467153419		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.7267747467153419 | validation: 0.5449443403060243]
	TIME [epoch: 8.54 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6597644872799548		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.6597644872799548 | validation: 1.049901658441308]
	TIME [epoch: 8.56 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6616143148222509		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.6616143148222509 | validation: 0.43220493727222875]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_372.pth
	Model improved!!!
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.974781892669682		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.974781892669682 | validation: 0.5487757846138448]
	TIME [epoch: 8.54 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.834323068437954		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.834323068437954 | validation: 1.397691363504658]
	TIME [epoch: 8.54 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7823310953711753		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.7823310953711753 | validation: 0.8777425281526905]
	TIME [epoch: 8.55 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8698415615496694		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.8698415615496694 | validation: 0.3951785284974044]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_376.pth
	Model improved!!!
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7711692388512137		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.7711692388512137 | validation: 0.47731441175354467]
	TIME [epoch: 8.54 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.726167648549457		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.726167648549457 | validation: 0.4840624690899187]
	TIME [epoch: 8.55 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8543698003685994		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.8543698003685994 | validation: 0.5894842905766142]
	TIME [epoch: 8.54 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7115503174618307		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.7115503174618307 | validation: 0.5389871270801657]
	TIME [epoch: 8.53 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7713212966336411		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.7713212966336411 | validation: 0.760339753618843]
	TIME [epoch: 8.53 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8188502394597084		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.8188502394597084 | validation: 1.1223854099570554]
	TIME [epoch: 8.55 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8133481852347659		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.8133481852347659 | validation: 0.6570707033622951]
	TIME [epoch: 8.54 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9360287723197548		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.9360287723197548 | validation: 1.4846039434259737]
	TIME [epoch: 8.54 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9638880165555186		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.9638880165555186 | validation: 1.2554996629085338]
	TIME [epoch: 8.53 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8171220457416819		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.8171220457416819 | validation: 0.6849704785024426]
	TIME [epoch: 8.56 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8079221327801059		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.8079221327801059 | validation: 0.6223062387688498]
	TIME [epoch: 8.54 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6636612105531826		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.6636612105531826 | validation: 0.8751485093479625]
	TIME [epoch: 8.53 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7324942555446897		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.7324942555446897 | validation: 0.6828189782523997]
	TIME [epoch: 8.54 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6745139368840619		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.6745139368840619 | validation: 0.47865373814627776]
	TIME [epoch: 8.56 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6993658097951516		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.6993658097951516 | validation: 0.6931093625692669]
	TIME [epoch: 8.54 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.629379468318928		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.629379468318928 | validation: 0.5040906503125167]
	TIME [epoch: 8.53 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7435778419967533		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.7435778419967533 | validation: 0.7056719816704727]
	TIME [epoch: 8.53 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5882212534361109		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.5882212534361109 | validation: 1.07158948654101]
	TIME [epoch: 8.56 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8170888895256148		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.8170888895256148 | validation: 0.4165473243142366]
	TIME [epoch: 8.53 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8141142412755631		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.8141142412755631 | validation: 0.875465941898742]
	TIME [epoch: 8.53 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.873686262827644		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.873686262827644 | validation: 0.4717413923062109]
	TIME [epoch: 8.53 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8787639931626903		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.8787639931626903 | validation: 0.8497268079056799]
	TIME [epoch: 8.56 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5871245417023323		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.5871245417023323 | validation: 0.649555397192601]
	TIME [epoch: 8.53 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6147463054190112		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.6147463054190112 | validation: 0.7171045173193298]
	TIME [epoch: 8.53 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6069384068783834		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.6069384068783834 | validation: 0.6358933516761979]
	TIME [epoch: 8.53 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7202547026084871		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.7202547026084871 | validation: 0.7221477226314643]
	TIME [epoch: 8.55 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7314031915824858		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.7314031915824858 | validation: 0.5843323915053527]
	TIME [epoch: 8.53 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7328406672151064		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.7328406672151064 | validation: 0.4596845950695298]
	TIME [epoch: 8.53 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5375354319474515		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.5375354319474515 | validation: 0.3704520483416451]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_405.pth
	Model improved!!!
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7977455971032607		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.7977455971032607 | validation: 0.7302413610048173]
	TIME [epoch: 8.55 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6630472736521279		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.6630472736521279 | validation: 0.5062104587867278]
	TIME [epoch: 8.53 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5089229234170125		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.5089229234170125 | validation: 0.49634731519358155]
	TIME [epoch: 8.53 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7317246394536653		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.7317246394536653 | validation: 0.6334671950806873]
	TIME [epoch: 8.54 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5671535226926052		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.5671535226926052 | validation: 0.4101104961799118]
	TIME [epoch: 8.54 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7584208888752539		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.7584208888752539 | validation: 0.6290897106565051]
	TIME [epoch: 8.53 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5898421957994813		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.5898421957994813 | validation: 0.8629361160779383]
	TIME [epoch: 8.53 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6546935492659205		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.6546935492659205 | validation: 0.45017364942799387]
	TIME [epoch: 8.54 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6208452725611029		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.6208452725611029 | validation: 0.8514758673077859]
	TIME [epoch: 8.54 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.660103169727318		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.660103169727318 | validation: 0.4748159695452846]
	TIME [epoch: 8.53 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5546663719415388		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.5546663719415388 | validation: 0.40404194020035666]
	TIME [epoch: 8.53 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6111415456326573		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.6111415456326573 | validation: 0.5150399796411944]
	TIME [epoch: 8.55 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5076917942730171		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.5076917942730171 | validation: 0.9013526056273057]
	TIME [epoch: 8.53 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6121746566562952		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.6121746566562952 | validation: 1.7272185808955283]
	TIME [epoch: 8.53 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7359249962710191		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.7359249962710191 | validation: 0.4680539233142106]
	TIME [epoch: 8.53 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5600034509915264		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.5600034509915264 | validation: 0.6811631071176765]
	TIME [epoch: 8.55 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5744907798122022		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.5744907798122022 | validation: 1.0505959731131234]
	TIME [epoch: 8.53 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6629733096943746		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.6629733096943746 | validation: 0.6178042058966695]
	TIME [epoch: 8.52 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6253201116233562		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.6253201116233562 | validation: 0.7792423068526336]
	TIME [epoch: 8.53 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6331310284626976		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.6331310284626976 | validation: 0.33174209714892744]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_425.pth
	Model improved!!!
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49003851100353835		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.49003851100353835 | validation: 0.3198913502499976]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_426.pth
	Model improved!!!
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5952381276710377		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.5952381276710377 | validation: 0.49984180636528097]
	TIME [epoch: 8.53 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7202712384689747		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.7202712384689747 | validation: 0.2945157938548848]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_428.pth
	Model improved!!!
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5877786055824105		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.5877786055824105 | validation: 0.3450329825903955]
	TIME [epoch: 8.56 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5614346133713138		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.5614346133713138 | validation: 0.37354558294681006]
	TIME [epoch: 8.53 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5038379331645759		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.5038379331645759 | validation: 0.5451233274300606]
	TIME [epoch: 8.53 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.619216065881147		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.619216065881147 | validation: 1.5972028900153323]
	TIME [epoch: 8.53 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7951959545310988		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.7951959545310988 | validation: 0.32595704706005874]
	TIME [epoch: 8.55 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5279201994553084		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.5279201994553084 | validation: 0.40728491309494497]
	TIME [epoch: 8.53 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8091266970160607		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.8091266970160607 | validation: 0.4741183524726303]
	TIME [epoch: 8.53 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8378527583007388		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.8378527583007388 | validation: 0.6715627253275519]
	TIME [epoch: 8.54 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6849497227129187		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.6849497227129187 | validation: 0.763557464294321]
	TIME [epoch: 8.54 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5895767665634205		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.5895767665634205 | validation: 0.5912403908489245]
	TIME [epoch: 8.53 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5950803534062434		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.5950803534062434 | validation: 0.5009999815238729]
	TIME [epoch: 8.53 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6898661344299201		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.6898661344299201 | validation: 0.5841820895655768]
	TIME [epoch: 8.55 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6096313006150933		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.6096313006150933 | validation: 0.37818207366370726]
	TIME [epoch: 8.54 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5480531645621545		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.5480531645621545 | validation: 0.34202783173250084]
	TIME [epoch: 8.53 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5031575038532063		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.5031575038532063 | validation: 0.9238173548085724]
	TIME [epoch: 8.53 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5449949118579289		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.5449949118579289 | validation: 0.42927755075068863]
	TIME [epoch: 8.55 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5532723572796358		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.5532723572796358 | validation: 0.4331792741803381]
	TIME [epoch: 8.54 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.421820785154008		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.421820785154008 | validation: 0.26142935963878383]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_446.pth
	Model improved!!!
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8337221319679774		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.8337221319679774 | validation: 0.33277163269307686]
	TIME [epoch: 8.53 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4997651279869945		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.4997651279869945 | validation: 0.2898709101674819]
	TIME [epoch: 8.55 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4017340167833113		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.4017340167833113 | validation: 0.45607269308892995]
	TIME [epoch: 8.53 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6583802389241808		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.6583802389241808 | validation: 1.6593347394845375]
	TIME [epoch: 8.53 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8441788711572613		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.8441788711572613 | validation: 0.5085121994501898]
	TIME [epoch: 8.53 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7438018082788656		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.7438018082788656 | validation: 0.4004896999744789]
	TIME [epoch: 8.56 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6755770967323244		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.6755770967323244 | validation: 0.5158389334214186]
	TIME [epoch: 8.53 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5582207897106274		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.5582207897106274 | validation: 0.38706576330958775]
	TIME [epoch: 8.53 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6765218635320589		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.6765218635320589 | validation: 0.4228762019817301]
	TIME [epoch: 8.53 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6202137457044755		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.6202137457044755 | validation: 0.30499077794067886]
	TIME [epoch: 8.56 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4423030393989814		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.4423030393989814 | validation: 0.8066703042077356]
	TIME [epoch: 8.53 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5975974995270418		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.5975974995270418 | validation: 0.29829427862697394]
	TIME [epoch: 8.53 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5448861216529207		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.5448861216529207 | validation: 0.45753240512482785]
	TIME [epoch: 8.53 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6300975570412		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.6300975570412 | validation: 0.2780081512551751]
	TIME [epoch: 8.55 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4865059884263025		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.4865059884263025 | validation: 0.33124296278476173]
	TIME [epoch: 8.53 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3935852631558684		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.3935852631558684 | validation: 0.42949861005062956]
	TIME [epoch: 8.52 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5885335011833823		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.5885335011833823 | validation: 1.1571615576529277]
	TIME [epoch: 8.53 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.683579388408327		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.683579388408327 | validation: 0.4212304791781747]
	TIME [epoch: 8.55 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44767293713264655		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.44767293713264655 | validation: 0.3485297110178299]
	TIME [epoch: 8.53 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4250212377690012		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.4250212377690012 | validation: 0.4849864499044299]
	TIME [epoch: 8.53 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7155077218311658		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.7155077218311658 | validation: 0.5470864965725097]
	TIME [epoch: 8.54 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7290855042238517		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.7290855042238517 | validation: 0.2915764177848878]
	TIME [epoch: 8.54 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5422846212674345		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.5422846212674345 | validation: 0.3575613811628392]
	TIME [epoch: 8.53 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.398543658953219		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.398543658953219 | validation: 0.3150893518106632]
	TIME [epoch: 8.53 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6421257789186966		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.6421257789186966 | validation: 0.8260309313376575]
	TIME [epoch: 8.55 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5648169327670103		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.5648169327670103 | validation: 0.4334578777109977]
	TIME [epoch: 8.54 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.654038967367381		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.654038967367381 | validation: 0.6802671341929933]
	TIME [epoch: 8.53 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5147774911962009		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.5147774911962009 | validation: 0.4152532222803325]
	TIME [epoch: 8.53 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6103537247854882		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.6103537247854882 | validation: 0.3550398054465525]
	TIME [epoch: 8.55 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6839713332644376		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.6839713332644376 | validation: 0.30106055355300276]
	TIME [epoch: 8.54 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5382363662665763		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.5382363662665763 | validation: 0.28197951470211235]
	TIME [epoch: 8.53 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49220764921993626		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.49220764921993626 | validation: 0.8795272562950867]
	TIME [epoch: 8.53 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5346073755099839		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.5346073755099839 | validation: 0.45129625023173103]
	TIME [epoch: 8.55 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4168806716091959		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.4168806716091959 | validation: 0.21643759787256306]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_480.pth
	Model improved!!!
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3520866127966698		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.3520866127966698 | validation: 0.4912399634667549]
	TIME [epoch: 8.53 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5583573492085123		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.5583573492085123 | validation: 0.7531951164902189]
	TIME [epoch: 8.53 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6526315313077788		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.6526315313077788 | validation: 0.6200926057159275]
	TIME [epoch: 8.55 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6287062311676345		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.6287062311676345 | validation: 0.8349596952067313]
	TIME [epoch: 8.53 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4824095233947075		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.4824095233947075 | validation: 0.26228955295862805]
	TIME [epoch: 8.53 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5694128573153939		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.5694128573153939 | validation: 0.7645664614801652]
	TIME [epoch: 8.52 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5916447666655721		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.5916447666655721 | validation: 0.4770988260274698]
	TIME [epoch: 8.55 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4117608714079847		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.4117608714079847 | validation: 0.31530311077934725]
	TIME [epoch: 8.53 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43949064161364476		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.43949064161364476 | validation: 0.3133949275809851]
	TIME [epoch: 8.53 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4729124300016833		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.4729124300016833 | validation: 0.2715739048466377]
	TIME [epoch: 8.52 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33028711290962703		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.33028711290962703 | validation: 0.9283479322765402]
	TIME [epoch: 8.56 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6808793424786785		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.6808793424786785 | validation: 0.5774702638347986]
	TIME [epoch: 8.53 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39197176103612164		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.39197176103612164 | validation: 0.457948199304945]
	TIME [epoch: 8.53 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5385047900442941		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.5385047900442941 | validation: 1.034158394483909]
	TIME [epoch: 8.53 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5601927382428632		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.5601927382428632 | validation: 0.605516503680579]
	TIME [epoch: 8.55 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.451366875574539		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.451366875574539 | validation: 0.564552577140763]
	TIME [epoch: 8.53 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3757471511564916		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.3757471511564916 | validation: 0.2709777159136817]
	TIME [epoch: 8.53 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4333741132480252		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.4333741132480252 | validation: 0.712437457729447]
	TIME [epoch: 8.54 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3953065701687777		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.3953065701687777 | validation: 1.0409436570431558]
	TIME [epoch: 8.55 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5121381592961856		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.5121381592961856 | validation: 0.36928958448690496]
	TIME [epoch: 8.53 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3278249433486747		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.3278249433486747 | validation: 0.20011783522557477]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_501.pth
	Model improved!!!
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4063740837674712		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.4063740837674712 | validation: 0.4691009934759919]
	TIME [epoch: 8.55 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4767766632736047		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.4767766632736047 | validation: 0.8908761478474061]
	TIME [epoch: 8.54 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5358600777613958		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.5358600777613958 | validation: 0.21610007135897213]
	TIME [epoch: 8.52 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38865750790331577		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.38865750790331577 | validation: 0.23251388590232658]
	TIME [epoch: 8.53 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4189730756605984		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.4189730756605984 | validation: 0.40143859255366277]
	TIME [epoch: 8.54 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5194249392188938		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.5194249392188938 | validation: 0.4117036333759507]
	TIME [epoch: 8.53 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3419646760317012		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.3419646760317012 | validation: 0.2290970860116619]
	TIME [epoch: 8.52 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5614839004812457		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.5614839004812457 | validation: 0.3231732569951723]
	TIME [epoch: 8.52 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6530618695460937		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.6530618695460937 | validation: 0.8564098218798]
	TIME [epoch: 8.55 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4215788354804517		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.4215788354804517 | validation: 0.5364722847063982]
	TIME [epoch: 8.53 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46646729794897623		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.46646729794897623 | validation: 0.20967653419858095]
	TIME [epoch: 8.53 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38215159859495973		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.38215159859495973 | validation: 0.2248845953418434]
	TIME [epoch: 8.52 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.554224253816747		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.554224253816747 | validation: 0.48375605607030053]
	TIME [epoch: 8.55 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5853287658692351		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.5853287658692351 | validation: 0.7177370687130442]
	TIME [epoch: 8.53 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41882635768476206		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.41882635768476206 | validation: 0.2991617844007859]
	TIME [epoch: 8.53 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3761229807290612		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.3761229807290612 | validation: 0.22443404517659987]
	TIME [epoch: 8.53 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5785108437343387		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.5785108437343387 | validation: 0.28167197096700647]
	TIME [epoch: 8.55 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3893002183350297		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.3893002183350297 | validation: 2.1492929635279534]
	TIME [epoch: 8.54 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6351120140781624		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.6351120140781624 | validation: 0.22544777530500448]
	TIME [epoch: 8.53 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4129927150991586		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.4129927150991586 | validation: 0.4340658586098213]
	TIME [epoch: 8.53 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4523776299851424		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.4523776299851424 | validation: 0.5230934615121057]
	TIME [epoch: 8.56 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5842659780282137		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.5842659780282137 | validation: 0.599374492145097]
	TIME [epoch: 8.53 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.559195626037119		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.559195626037119 | validation: 0.49590214831650214]
	TIME [epoch: 8.53 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4215674228790788		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.4215674228790788 | validation: 0.2371109874437688]
	TIME [epoch: 8.53 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37178998703905936		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.37178998703905936 | validation: 0.5286284077616179]
	TIME [epoch: 8.56 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33545962408179836		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.33545962408179836 | validation: 0.31181091542832706]
	TIME [epoch: 8.53 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3119076243288955		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.3119076243288955 | validation: 0.2747083352382328]
	TIME [epoch: 8.53 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4601669087507666		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.4601669087507666 | validation: 0.19849273821599037]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_529.pth
	Model improved!!!
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43135773917498926		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.43135773917498926 | validation: 0.24685969022315224]
	TIME [epoch: 8.54 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3202277968893281		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.3202277968893281 | validation: 0.5716979674262637]
	TIME [epoch: 8.53 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42273368252057403		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.42273368252057403 | validation: 0.2752636681040656]
	TIME [epoch: 8.52 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5065124673298336		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.5065124673298336 | validation: 0.5528193704291229]
	TIME [epoch: 8.55 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31867922810293214		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.31867922810293214 | validation: 0.3223136822855278]
	TIME [epoch: 8.54 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2984742342890291		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.2984742342890291 | validation: 0.4488476558279599]
	TIME [epoch: 8.53 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.434865060053519		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.434865060053519 | validation: 0.23539085939482246]
	TIME [epoch: 8.53 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5033666345956975		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.5033666345956975 | validation: 0.2605299325477297]
	TIME [epoch: 8.54 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36272969262274485		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.36272969262274485 | validation: 0.2523764735905335]
	TIME [epoch: 8.54 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3193194866395384		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.3193194866395384 | validation: 0.21444741259001843]
	TIME [epoch: 8.53 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3670626211160593		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.3670626211160593 | validation: 0.23323738283802015]
	TIME [epoch: 8.53 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3241505689349953		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.3241505689349953 | validation: 0.20628448809608113]
	TIME [epoch: 8.55 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34864285667948314		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.34864285667948314 | validation: 0.23897027372692242]
	TIME [epoch: 8.53 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6079116539046576		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.6079116539046576 | validation: 0.5743101562781928]
	TIME [epoch: 8.53 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42918471771990496		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.42918471771990496 | validation: 0.1990700712601626]
	TIME [epoch: 8.53 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2786423917758578		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.2786423917758578 | validation: 0.4086196270140938]
	TIME [epoch: 8.55 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32656689501061875		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.32656689501061875 | validation: 0.2663517160978921]
	TIME [epoch: 8.53 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.500538409944339		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.500538409944339 | validation: 0.3839592486212634]
	TIME [epoch: 8.53 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38889642954017833		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.38889642954017833 | validation: 0.2325990331036119]
	TIME [epoch: 8.52 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31864215872568746		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.31864215872568746 | validation: 0.6215800215084186]
	TIME [epoch: 8.55 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5037019214916075		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.5037019214916075 | validation: 0.26916003285235846]
	TIME [epoch: 8.53 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24694036021892982		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.24694036021892982 | validation: 0.23709363733465066]
	TIME [epoch: 8.53 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4794011384821177		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.4794011384821177 | validation: 0.17412777151263342]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_552.pth
	Model improved!!!
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3821880638904733		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.3821880638904733 | validation: 0.32028765963415523]
	TIME [epoch: 8.55 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38147599181083003		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.38147599181083003 | validation: 0.22099086348120658]
	TIME [epoch: 8.53 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4827951633636399		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.4827951633636399 | validation: 0.2761742667898581]
	TIME [epoch: 8.52 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48773261146929914		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.48773261146929914 | validation: 0.4066840026168764]
	TIME [epoch: 8.53 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36013595385088465		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.36013595385088465 | validation: 0.27862174626270875]
	TIME [epoch: 8.55 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2464008296924484		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.2464008296924484 | validation: 0.19028992441814024]
	TIME [epoch: 8.53 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4648591433719134		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.4648591433719134 | validation: 0.5776468484597904]
	TIME [epoch: 8.53 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5669726442849853		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.5669726442849853 | validation: 0.35940146547360596]
	TIME [epoch: 8.53 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4130624651728755		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.4130624651728755 | validation: 0.44392973099151045]
	TIME [epoch: 8.54 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3113719323038495		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.3113719323038495 | validation: 0.459191341905263]
	TIME [epoch: 8.53 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34940199628156743		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.34940199628156743 | validation: 0.7705846954222894]
	TIME [epoch: 8.52 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3986561207887326		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.3986561207887326 | validation: 0.7999275196804279]
	TIME [epoch: 8.54 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4131780051201311		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.4131780051201311 | validation: 0.18008131061511257]
	TIME [epoch: 8.53 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34423436629222703		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.34423436629222703 | validation: 0.269995870737065]
	TIME [epoch: 8.53 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37106188362420606		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.37106188362420606 | validation: 0.20730860244529647]
	TIME [epoch: 8.52 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5652799082394082		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.5652799082394082 | validation: 0.39714988560957687]
	TIME [epoch: 8.54 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2735273680679147		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.2735273680679147 | validation: 0.3971896788442959]
	TIME [epoch: 8.53 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32586525996166144		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.32586525996166144 | validation: 0.16857247846318119]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_570.pth
	Model improved!!!
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24584173575665252		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.24584173575665252 | validation: 0.2818359599611381]
	TIME [epoch: 8.53 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43563494390779534		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.43563494390779534 | validation: 0.2889413192826483]
	TIME [epoch: 8.54 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3754773929447567		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.3754773929447567 | validation: 0.847943010229603]
	TIME [epoch: 8.53 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3676079623072724		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.3676079623072724 | validation: 0.1969979043392323]
	TIME [epoch: 8.52 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3614490506965119		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.3614490506965119 | validation: 0.3400400191306394]
	TIME [epoch: 8.52 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34822593970210775		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.34822593970210775 | validation: 0.22529395644098327]
	TIME [epoch: 8.54 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22636208320733792		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.22636208320733792 | validation: 0.23386000126923598]
	TIME [epoch: 8.52 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3232457383111536		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.3232457383111536 | validation: 0.22529062638892974]
	TIME [epoch: 8.52 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3218536895821771		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.3218536895821771 | validation: 0.3807962572552859]
	TIME [epoch: 8.52 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4352152725526895		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.4352152725526895 | validation: 0.25725797744027085]
	TIME [epoch: 8.54 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41030677205027405		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.41030677205027405 | validation: 0.21584387204361294]
	TIME [epoch: 8.52 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3608215546180148		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.3608215546180148 | validation: 0.6040299458902216]
	TIME [epoch: 8.53 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4251493571936347		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.4251493571936347 | validation: 0.24760616638775942]
	TIME [epoch: 8.53 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3576769836204615		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.3576769836204615 | validation: 0.1551682459368692]
	TIME [epoch: 8.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_584.pth
	Model improved!!!
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2978572583814908		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.2978572583814908 | validation: 0.17127107272081948]
	TIME [epoch: 8.54 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27775408923072903		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.27775408923072903 | validation: 0.24658203732026684]
	TIME [epoch: 8.53 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4199476220076014		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.4199476220076014 | validation: 0.3265613191611858]
	TIME [epoch: 8.53 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3282726111856516		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.3282726111856516 | validation: 0.23564166133526465]
	TIME [epoch: 8.56 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3123891652423186		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.3123891652423186 | validation: 0.2041945809933919]
	TIME [epoch: 8.54 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3171506745738919		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.3171506745738919 | validation: 0.29798623596961077]
	TIME [epoch: 8.53 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32618848575520254		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.32618848575520254 | validation: 0.2236936717399951]
	TIME [epoch: 8.53 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41351236991797746		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.41351236991797746 | validation: 0.5091041124058187]
	TIME [epoch: 8.54 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3578922815208787		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.3578922815208787 | validation: 0.33375408335494683]
	TIME [epoch: 8.53 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29824484237647203		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.29824484237647203 | validation: 0.18588211751906]
	TIME [epoch: 8.52 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3967630577203892		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.3967630577203892 | validation: 0.46789250933254856]
	TIME [epoch: 8.53 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2924061224905277		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.2924061224905277 | validation: 0.43313687796259215]
	TIME [epoch: 8.53 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3255951017021342		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.3255951017021342 | validation: 0.27643996048947433]
	TIME [epoch: 8.52 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.274546530255314		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.274546530255314 | validation: 0.22589027004794693]
	TIME [epoch: 8.52 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35069269733867686		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.35069269733867686 | validation: 0.6956928422323843]
	TIME [epoch: 8.54 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34114078404589965		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.34114078404589965 | validation: 0.18955203104296586]
	TIME [epoch: 8.53 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25060553656000534		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.25060553656000534 | validation: 0.2026655939531784]
	TIME [epoch: 8.52 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5510427007864079		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.5510427007864079 | validation: 0.22599757144819826]
	TIME [epoch: 8.52 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35538483030202905		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.35538483030202905 | validation: 0.2951922981438756]
	TIME [epoch: 8.54 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.339791122721683		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.339791122721683 | validation: 0.34560619080750676]
	TIME [epoch: 8.52 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24296131697558523		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.24296131697558523 | validation: 0.21622518231802046]
	TIME [epoch: 8.52 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2576703910512791		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.2576703910512791 | validation: 0.3347601156555028]
	TIME [epoch: 8.52 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26979839118884275		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.26979839118884275 | validation: 0.48432893888872186]
	TIME [epoch: 8.54 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3311546963055742		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.3311546963055742 | validation: 0.15945695856549996]
	TIME [epoch: 8.52 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2874930355536841		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.2874930355536841 | validation: 0.1747165229129383]
	TIME [epoch: 8.52 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4178007259811277		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.4178007259811277 | validation: 0.20814936671547252]
	TIME [epoch: 8.52 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2979925870586584		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.2979925870586584 | validation: 0.2741584419726383]
	TIME [epoch: 8.54 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3117161237049848		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.3117161237049848 | validation: 0.17377005468418494]
	TIME [epoch: 8.52 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2696740297888388		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.2696740297888388 | validation: 0.31235494534833574]
	TIME [epoch: 8.52 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27929631823341017		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.27929631823341017 | validation: 0.2415363180444991]
	TIME [epoch: 8.52 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28812059199933227		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.28812059199933227 | validation: 0.23794121870147028]
	TIME [epoch: 8.54 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28936817340017473		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.28936817340017473 | validation: 0.17897723309381708]
	TIME [epoch: 8.52 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3065715814462576		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.3065715814462576 | validation: 0.4207456820423845]
	TIME [epoch: 8.52 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3121379899577035		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.3121379899577035 | validation: 0.5378409552003071]
	TIME [epoch: 8.52 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26446937344264987		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.26446937344264987 | validation: 0.4878521213760403]
	TIME [epoch: 8.54 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4401703004317626		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.4401703004317626 | validation: 0.322461088305645]
	TIME [epoch: 8.52 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2644280590743164		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.2644280590743164 | validation: 0.1887320889220306]
	TIME [epoch: 8.52 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22137107964563846		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.22137107964563846 | validation: 0.15956652750516542]
	TIME [epoch: 8.53 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32113686335930164		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.32113686335930164 | validation: 0.46149605182088393]
	TIME [epoch: 8.54 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26460658750288985		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.26460658750288985 | validation: 0.2664943619108918]
	TIME [epoch: 8.52 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2484573671474434		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.2484573671474434 | validation: 0.17396678928697784]
	TIME [epoch: 8.52 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27872399320221836		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.27872399320221836 | validation: 0.470512638362624]
	TIME [epoch: 8.53 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30256100071214714		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.30256100071214714 | validation: 0.40833606091623587]
	TIME [epoch: 8.54 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2814298333949437		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.2814298333949437 | validation: 0.3087842000916956]
	TIME [epoch: 8.52 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3787071207225789		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.3787071207225789 | validation: 0.3047921609049145]
	TIME [epoch: 8.52 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2785448274899228		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.2785448274899228 | validation: 0.17045436727157381]
	TIME [epoch: 8.53 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24897969387669763		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.24897969387669763 | validation: 0.16807496203139863]
	TIME [epoch: 8.53 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21872360840813862		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.21872360840813862 | validation: 0.1910176745017943]
	TIME [epoch: 8.52 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2699136969126875		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.2699136969126875 | validation: 0.1433342833824129]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_633.pth
	Model improved!!!
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2093161071521532		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.2093161071521532 | validation: 0.22945678541350903]
	TIME [epoch: 8.54 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19090922233458457		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.19090922233458457 | validation: 0.1675876232349698]
	TIME [epoch: 8.54 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2750754075606717		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.2750754075606717 | validation: 0.17888323281079]
	TIME [epoch: 8.54 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19079519115693452		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.19079519115693452 | validation: 0.2864597014923975]
	TIME [epoch: 8.53 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2892520702926419		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.2892520702926419 | validation: 0.165004583455102]
	TIME [epoch: 8.55 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28599828603069916		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.28599828603069916 | validation: 0.24272481874231597]
	TIME [epoch: 8.53 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24849692770167991		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.24849692770167991 | validation: 0.20476533349334308]
	TIME [epoch: 8.53 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2247728975659255		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.2247728975659255 | validation: 0.3766191848717797]
	TIME [epoch: 8.53 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3945273058185676		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.3945273058185676 | validation: 0.2940934317155014]
	TIME [epoch: 8.55 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3854363746364392		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.3854363746364392 | validation: 0.24854535449038934]
	TIME [epoch: 8.54 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22064997101246986		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.22064997101246986 | validation: 0.29873838869558095]
	TIME [epoch: 8.53 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27131126667823274		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.27131126667823274 | validation: 0.24077173712856675]
	TIME [epoch: 8.53 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24507992432889178		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.24507992432889178 | validation: 0.21053179919310436]
	TIME [epoch: 8.55 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28724217875872704		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.28724217875872704 | validation: 0.18727237016325077]
	TIME [epoch: 8.53 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2317283772925515		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.2317283772925515 | validation: 0.2500304457115096]
	TIME [epoch: 8.53 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2306174760116114		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.2306174760116114 | validation: 0.22213800477422202]
	TIME [epoch: 8.53 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2423896333380502		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.2423896333380502 | validation: 0.18377918357194917]
	TIME [epoch: 8.56 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39524515592303594		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.39524515592303594 | validation: 0.23389711616877337]
	TIME [epoch: 8.53 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32059782866497477		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.32059782866497477 | validation: 0.2032197789232137]
	TIME [epoch: 8.53 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28470103525400275		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.28470103525400275 | validation: 0.27633505927591195]
	TIME [epoch: 8.53 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2322937843327201		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.2322937843327201 | validation: 0.2461957195566315]
	TIME [epoch: 8.55 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19147768418892736		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.19147768418892736 | validation: 0.19582621715233084]
	TIME [epoch: 8.53 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23343844700478739		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.23343844700478739 | validation: 0.20766236970624694]
	TIME [epoch: 8.53 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24838694619094764		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.24838694619094764 | validation: 0.18484642433251447]
	TIME [epoch: 8.54 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23618328895290408		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.23618328895290408 | validation: 0.3119530194502229]
	TIME [epoch: 8.54 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24140153684685398		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.24140153684685398 | validation: 0.16999363018464778]
	TIME [epoch: 8.53 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21321183933469282		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.21321183933469282 | validation: 0.2883905020676607]
	TIME [epoch: 8.53 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26099615705279466		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.26099615705279466 | validation: 0.3181403171735898]
	TIME [epoch: 8.55 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26252095023727773		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.26252095023727773 | validation: 0.275392881463682]
	TIME [epoch: 8.54 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21476127698085357		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.21476127698085357 | validation: 0.22789580593122144]
	TIME [epoch: 8.53 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25131769982819124		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.25131769982819124 | validation: 0.15248262204460017]
	TIME [epoch: 8.53 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21904590804098464		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.21904590804098464 | validation: 0.3687160674092646]
	TIME [epoch: 8.54 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27739298569389115		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.27739298569389115 | validation: 0.2275178952568191]
	TIME [epoch: 8.53 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17947227463075371		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.17947227463075371 | validation: 0.15743468549014278]
	TIME [epoch: 8.53 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2577910082224091		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.2577910082224091 | validation: 0.37016040300454767]
	TIME [epoch: 8.53 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21372745876440558		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.21372745876440558 | validation: 0.26574612647398116]
	TIME [epoch: 8.55 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25648098663162855		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.25648098663162855 | validation: 0.15381936735659593]
	TIME [epoch: 8.53 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29554530174513227		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.29554530174513227 | validation: 0.2756955794772618]
	TIME [epoch: 8.53 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2572893620235119		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.2572893620235119 | validation: 0.17208429943165804]
	TIME [epoch: 8.53 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2095550383734059		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.2095550383734059 | validation: 0.357154532181312]
	TIME [epoch: 8.55 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30483958054442484		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.30483958054442484 | validation: 0.20800079352643142]
	TIME [epoch: 8.53 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1995700477322187		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.1995700477322187 | validation: 0.3071985726312917]
	TIME [epoch: 8.52 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22222663848656468		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.22222663848656468 | validation: 0.21629954057337464]
	TIME [epoch: 8.52 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20414948954015366		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.20414948954015366 | validation: 0.3693355798567104]
	TIME [epoch: 8.55 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.268181248097215		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.268181248097215 | validation: 0.12848199973754526]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_678.pth
	Model improved!!!
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2712612996207322		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.2712612996207322 | validation: 0.13121530281237703]
	TIME [epoch: 8.53 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22023251994801996		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.22023251994801996 | validation: 0.33534297532896173]
	TIME [epoch: 8.53 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29755607072260937		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.29755607072260937 | validation: 0.24146427445998747]
	TIME [epoch: 8.54 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2417820953136168		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.2417820953136168 | validation: 0.21920559437776121]
	TIME [epoch: 8.52 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18438047570625232		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.18438047570625232 | validation: 0.16353462553204012]
	TIME [epoch: 8.53 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22438155293474046		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.22438155293474046 | validation: 0.17235364155876126]
	TIME [epoch: 8.52 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19188417895116103		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.19188417895116103 | validation: 0.17352998000326453]
	TIME [epoch: 8.55 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21403914438082844		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.21403914438082844 | validation: 0.5975593548476958]
	TIME [epoch: 8.52 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29448737937238045		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.29448737937238045 | validation: 0.11688950841938045]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_687.pth
	Model improved!!!
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.228780728621637		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.228780728621637 | validation: 0.14912678156941006]
	TIME [epoch: 8.54 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20250029640762515		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.20250029640762515 | validation: 0.19801182578146637]
	TIME [epoch: 8.54 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3650874611623208		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.3650874611623208 | validation: 0.4903926662387518]
	TIME [epoch: 8.52 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31997087247112793		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.31997087247112793 | validation: 0.17579084506879866]
	TIME [epoch: 8.53 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2063104986024557		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.2063104986024557 | validation: 0.2572695447295605]
	TIME [epoch: 8.56 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2100143507816691		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.2100143507816691 | validation: 0.16892677425793667]
	TIME [epoch: 8.54 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1993208484111147		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.1993208484111147 | validation: 0.16646998810037805]
	TIME [epoch: 8.54 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.245018615378891		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.245018615378891 | validation: 0.14329708536871627]
	TIME [epoch: 8.53 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1714294329872864		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.1714294329872864 | validation: 0.14823529234774468]
	TIME [epoch: 8.56 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23319452613414932		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.23319452613414932 | validation: 0.21116953893695248]
	TIME [epoch: 8.54 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20445256450396992		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.20445256450396992 | validation: 0.1766473152948851]
	TIME [epoch: 8.52 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2518816259471036		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.2518816259471036 | validation: 0.18115776747252937]
	TIME [epoch: 8.52 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1634815075545155		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.1634815075545155 | validation: 0.17464173921006856]
	TIME [epoch: 8.55 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23558359970078654		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.23558359970078654 | validation: 0.17557056269773275]
	TIME [epoch: 8.53 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2103537139751736		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.2103537139751736 | validation: 0.14835279690561062]
	TIME [epoch: 8.52 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24786902273665734		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.24786902273665734 | validation: 0.2641811892079676]
	TIME [epoch: 8.53 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19861504447372397		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.19861504447372397 | validation: 0.1857569135182469]
	TIME [epoch: 8.55 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2105252542677468		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.2105252542677468 | validation: 0.3649746621350069]
	TIME [epoch: 8.53 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20604044234906738		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.20604044234906738 | validation: 0.2665279699627525]
	TIME [epoch: 8.53 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18856354878635376		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.18856354878635376 | validation: 0.12580795557704108]
	TIME [epoch: 8.52 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1851041745266754		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.1851041745266754 | validation: 0.1910178898140363]
	TIME [epoch: 8.86 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1833621975433825		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.1833621975433825 | validation: 0.1307533364381349]
	TIME [epoch: 8.54 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1719631420208429		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.1719631420208429 | validation: 0.22366089898043204]
	TIME [epoch: 8.54 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23732471649688383		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.23732471649688383 | validation: 0.23198834862268777]
	TIME [epoch: 8.55 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21055106328714507		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.21055106328714507 | validation: 0.1359619255469825]
	TIME [epoch: 8.56 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1940319305003256		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.1940319305003256 | validation: 0.24852860945698252]
	TIME [epoch: 8.55 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2137998492617609		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.2137998492617609 | validation: 0.1767165539266691]
	TIME [epoch: 8.54 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15600714059582768		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.15600714059582768 | validation: 0.14294676308768117]
	TIME [epoch: 8.55 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19329087963408775		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.19329087963408775 | validation: 0.20418770238218475]
	TIME [epoch: 8.55 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28487625340455924		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.28487625340455924 | validation: 0.15596745352660463]
	TIME [epoch: 8.54 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15883044511008443		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.15883044511008443 | validation: 0.1849673133558702]
	TIME [epoch: 8.54 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19571448853947046		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.19571448853947046 | validation: 0.14612196303548552]
	TIME [epoch: 8.55 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20199562709392951		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.20199562709392951 | validation: 0.19024867201849005]
	TIME [epoch: 8.55 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23097958291373172		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.23097958291373172 | validation: 0.20331924148062172]
	TIME [epoch: 8.54 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18662071665441346		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.18662071665441346 | validation: 0.3022085321199449]
	TIME [epoch: 8.54 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27145354017715406		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.27145354017715406 | validation: 0.13250646916195774]
	TIME [epoch: 8.56 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23149596985530613		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.23149596985530613 | validation: 0.22780014786592226]
	TIME [epoch: 8.55 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18942583970546192		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.18942583970546192 | validation: 0.16750448429805564]
	TIME [epoch: 8.54 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20441040337448993		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.20441040337448993 | validation: 0.13436141538872523]
	TIME [epoch: 8.54 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18420366487994527		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.18420366487994527 | validation: 0.18831975579434057]
	TIME [epoch: 8.56 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22318436337385714		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.22318436337385714 | validation: 0.13278613687190227]
	TIME [epoch: 8.55 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21021982373274364		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.21021982373274364 | validation: 0.18875033307907713]
	TIME [epoch: 8.55 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1513508206677517		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.1513508206677517 | validation: 0.16419917308578402]
	TIME [epoch: 8.55 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22024410692744226		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.22024410692744226 | validation: 0.15502554848975764]
	TIME [epoch: 8.57 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1620192254183091		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.1620192254183091 | validation: 0.2047727655553287]
	TIME [epoch: 8.55 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2072468353422087		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.2072468353422087 | validation: 0.24946589441419545]
	TIME [epoch: 8.54 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22149366706481813		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.22149366706481813 | validation: 0.26715589809049567]
	TIME [epoch: 8.55 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1894449667278663		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.1894449667278663 | validation: 0.1132611643242982]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_735.pth
	Model improved!!!
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18182950281944654		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.18182950281944654 | validation: 0.1347805815411477]
	TIME [epoch: 8.55 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2125093509074277		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.2125093509074277 | validation: 0.3117899120552292]
	TIME [epoch: 8.54 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2698319160211901		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.2698319160211901 | validation: 0.14195842917109672]
	TIME [epoch: 8.54 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2041190609081367		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.2041190609081367 | validation: 0.13596203854092187]
	TIME [epoch: 8.57 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19600242244065696		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.19600242244065696 | validation: 0.23013623081838339]
	TIME [epoch: 8.54 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18469370877928676		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.18469370877928676 | validation: 0.20910476599558453]
	TIME [epoch: 8.54 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19662849808273253		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.19662849808273253 | validation: 0.24725929575985423]
	TIME [epoch: 8.54 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2516396437880044		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.2516396437880044 | validation: 0.26467444029372855]
	TIME [epoch: 8.57 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2019798939110063		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.2019798939110063 | validation: 0.1891217887933545]
	TIME [epoch: 8.54 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20115667321471986		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.20115667321471986 | validation: 0.24173990376091825]
	TIME [epoch: 8.54 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1924379723910407		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.1924379723910407 | validation: 0.19992472097303554]
	TIME [epoch: 8.54 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19806578231433256		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.19806578231433256 | validation: 0.22006701762339967]
	TIME [epoch: 8.56 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17392204266243688		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.17392204266243688 | validation: 0.19071099988673518]
	TIME [epoch: 8.54 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1548997586068596		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.1548997586068596 | validation: 0.19354915408297385]
	TIME [epoch: 8.54 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15667499622142458		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.15667499622142458 | validation: 0.12434012941998099]
	TIME [epoch: 8.55 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15524835505686976		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.15524835505686976 | validation: 0.18059401710139772]
	TIME [epoch: 8.55 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1675628444945465		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.1675628444945465 | validation: 0.13820779418273588]
	TIME [epoch: 8.54 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2187900281763519		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.2187900281763519 | validation: 0.2741820399888868]
	TIME [epoch: 8.55 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20403295887945067		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.20403295887945067 | validation: 0.1744871237338575]
	TIME [epoch: 8.56 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.201629072486632		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.201629072486632 | validation: 0.3379663311231431]
	TIME [epoch: 8.55 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18245783239977445		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.18245783239977445 | validation: 0.25259083362534224]
	TIME [epoch: 8.54 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17698585828519836		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.17698585828519836 | validation: 0.24582044974006267]
	TIME [epoch: 8.54 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18025619736277357		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.18025619736277357 | validation: 0.14980965730233753]
	TIME [epoch: 8.56 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16872663531001275		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.16872663531001275 | validation: 0.2774745116075942]
	TIME [epoch: 8.54 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19796772445389568		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.19796772445389568 | validation: 0.2370658528058059]
	TIME [epoch: 8.54 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20770138835480312		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.20770138835480312 | validation: 0.25771979675419215]
	TIME [epoch: 8.54 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16466670232725716		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.16466670232725716 | validation: 0.14102448976907073]
	TIME [epoch: 8.57 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18919091941407049		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.18919091941407049 | validation: 0.1393600074191968]
	TIME [epoch: 8.54 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21641771903682677		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.21641771903682677 | validation: 0.34154914708507933]
	TIME [epoch: 8.54 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21081116544161374		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.21081116544161374 | validation: 0.14638621738276475]
	TIME [epoch: 8.54 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19184743897358167		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.19184743897358167 | validation: 0.15122292924494796]
	TIME [epoch: 8.56 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14261019886488396		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.14261019886488396 | validation: 0.20890111414909016]
	TIME [epoch: 8.54 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16591007422610796		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.16591007422610796 | validation: 0.1708398714124464]
	TIME [epoch: 8.54 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1842690686002663		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.1842690686002663 | validation: 0.23440932914555512]
	TIME [epoch: 8.54 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18472176477050722		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.18472176477050722 | validation: 0.1262178824855673]
	TIME [epoch: 8.56 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18833123552599612		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.18833123552599612 | validation: 0.21564891458455468]
	TIME [epoch: 8.54 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17365824411001685		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.17365824411001685 | validation: 0.13550484430266457]
	TIME [epoch: 8.54 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2975362557870934		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.2975362557870934 | validation: 0.1285426766369118]
	TIME [epoch: 8.54 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21264708143795902		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.21264708143795902 | validation: 0.3525178811757404]
	TIME [epoch: 8.56 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19610593200897194		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.19610593200897194 | validation: 0.2107713298579379]
	TIME [epoch: 8.54 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17877861567123396		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.17877861567123396 | validation: 0.3484198322894817]
	TIME [epoch: 8.54 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19025393257152318		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.19025393257152318 | validation: 0.1209025581760572]
	TIME [epoch: 8.54 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17701234478812414		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.17701234478812414 | validation: 0.18750745056160897]
	TIME [epoch: 8.55 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1763525729292959		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.1763525729292959 | validation: 0.20783275052322475]
	TIME [epoch: 8.54 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17521869186836636		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.17521869186836636 | validation: 0.22599597426359236]
	TIME [epoch: 8.54 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1851927101619973		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.1851927101619973 | validation: 0.1954921047245683]
	TIME [epoch: 8.55 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.139328164537713		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.139328164537713 | validation: 0.19177066028391482]
	TIME [epoch: 8.55 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1558530035365396		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.1558530035365396 | validation: 0.19040878511617448]
	TIME [epoch: 8.54 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.141375921856799		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.141375921856799 | validation: 0.17401752059744025]
	TIME [epoch: 8.53 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17976560461443322		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.17976560461443322 | validation: 0.14023023603343687]
	TIME [epoch: 8.55 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16634429388963018		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.16634429388963018 | validation: 0.13838407872526884]
	TIME [epoch: 8.54 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1422062682594087		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.1422062682594087 | validation: 0.19731916100046332]
	TIME [epoch: 8.54 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16975422089516293		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.16975422089516293 | validation: 0.19361511175706705]
	TIME [epoch: 8.53 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14324399015890024		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.14324399015890024 | validation: 0.14915337451771835]
	TIME [epoch: 8.55 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15085894969362337		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.15085894969362337 | validation: 0.3483940759493275]
	TIME [epoch: 8.54 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1971391796801146		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.1971391796801146 | validation: 0.1821506934313327]
	TIME [epoch: 8.53 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1641603926055693		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.1641603926055693 | validation: 0.1704792693106582]
	TIME [epoch: 8.54 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15656092319231263		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.15656092319231263 | validation: 0.18061005728211982]
	TIME [epoch: 8.56 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18195565304276579		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.18195565304276579 | validation: 0.11639069428027596]
	TIME [epoch: 8.54 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1650727224960981		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.1650727224960981 | validation: 0.1346585526186686]
	TIME [epoch: 8.54 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1294382197980146		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.1294382197980146 | validation: 0.2201041043752996]
	TIME [epoch: 8.54 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.206052026681412		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.206052026681412 | validation: 0.14746774306261684]
	TIME [epoch: 8.56 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15908052979044424		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.15908052979044424 | validation: 0.22422998416170187]
	TIME [epoch: 8.54 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15124479753506898		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.15124479753506898 | validation: 0.11746638056344992]
	TIME [epoch: 8.54 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1441699009758163		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.1441699009758163 | validation: 0.19554172134803524]
	TIME [epoch: 8.54 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13548373729768395		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.13548373729768395 | validation: 0.19583004888859534]
	TIME [epoch: 8.56 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15688500103057512		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.15688500103057512 | validation: 0.1579250450223701]
	TIME [epoch: 8.54 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13990436215593643		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.13990436215593643 | validation: 0.12859667886853282]
	TIME [epoch: 8.53 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16343106651935563		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.16343106651935563 | validation: 0.16169323967865523]
	TIME [epoch: 8.54 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15333400157320662		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.15333400157320662 | validation: 0.13928349134221701]
	TIME [epoch: 8.56 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15558985175267206		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.15558985175267206 | validation: 0.16990088302651601]
	TIME [epoch: 8.54 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1503021575745594		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.1503021575745594 | validation: 0.30834134478133624]
	TIME [epoch: 8.53 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22073160896809457		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.22073160896809457 | validation: 0.1826698251096881]
	TIME [epoch: 8.55 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20993943608369464		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.20993943608369464 | validation: 0.1719965843255476]
	TIME [epoch: 8.55 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19791525401963986		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.19791525401963986 | validation: 0.21527777906764173]
	TIME [epoch: 8.54 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1663603172369708		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.1663603172369708 | validation: 0.1884705675569797]
	TIME [epoch: 8.53 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13832648400289443		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.13832648400289443 | validation: 0.13700585050594732]
	TIME [epoch: 8.55 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1621890080698531		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.1621890080698531 | validation: 0.1213129796495366]
	TIME [epoch: 8.55 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1265086395501517		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.1265086395501517 | validation: 0.21109670973344358]
	TIME [epoch: 8.53 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23597384697281942		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.23597384697281942 | validation: 0.10823342613713005]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_815.pth
	Model improved!!!
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1279526587194519		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.1279526587194519 | validation: 0.13204793037227375]
	TIME [epoch: 8.55 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13049201550978315		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.13049201550978315 | validation: 0.13209917944138966]
	TIME [epoch: 8.53 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17857502675015635		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.17857502675015635 | validation: 0.3008083455221071]
	TIME [epoch: 8.53 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15300122404667402		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.15300122404667402 | validation: 0.14495767571989532]
	TIME [epoch: 8.53 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1765025003616427		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.1765025003616427 | validation: 0.18334264279614315]
	TIME [epoch: 8.55 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13993784879338061		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.13993784879338061 | validation: 0.21905735747299893]
	TIME [epoch: 8.53 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14933519686152502		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.14933519686152502 | validation: 0.1682940235873806]
	TIME [epoch: 8.53 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22290587640977827		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.22290587640977827 | validation: 0.13631358567256352]
	TIME [epoch: 8.53 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12677034708574164		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.12677034708574164 | validation: 0.15901287749133508]
	TIME [epoch: 8.55 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13753930325036282		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.13753930325036282 | validation: 0.1852786021257295]
	TIME [epoch: 8.53 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13251521714267472		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.13251521714267472 | validation: 0.12826902357124673]
	TIME [epoch: 8.53 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13007303029674552		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.13007303029674552 | validation: 0.1618320962291735]
	TIME [epoch: 8.53 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1481253358510857		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.1481253358510857 | validation: 0.15282215140167976]
	TIME [epoch: 8.55 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14679248512128626		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.14679248512128626 | validation: 0.12775712941299774]
	TIME [epoch: 8.53 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14534165973033236		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.14534165973033236 | validation: 0.2367470706654381]
	TIME [epoch: 8.53 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16303709224106572		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.16303709224106572 | validation: 0.19366515533781273]
	TIME [epoch: 8.52 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15368939627865266		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.15368939627865266 | validation: 0.17796586451287413]
	TIME [epoch: 8.56 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1453896623373337		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.1453896623373337 | validation: 0.1525414642656475]
	TIME [epoch: 8.53 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14014905677452277		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.14014905677452277 | validation: 0.19742016208218155]
	TIME [epoch: 8.53 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18023681068648645		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.18023681068648645 | validation: 0.11788986661743689]
	TIME [epoch: 8.53 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14462216562587166		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.14462216562587166 | validation: 0.2119114273967483]
	TIME [epoch: 8.55 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1641327065398554		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.1641327065398554 | validation: 0.15766929681967973]
	TIME [epoch: 8.53 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13128754480614097		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.13128754480614097 | validation: 0.14666519013590723]
	TIME [epoch: 8.53 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14012432311240852		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.14012432311240852 | validation: 0.18742466312592315]
	TIME [epoch: 8.53 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13402872189361048		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.13402872189361048 | validation: 0.14850583145363302]
	TIME [epoch: 8.54 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13441691905339404		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.13441691905339404 | validation: 0.1223045039606448]
	TIME [epoch: 8.53 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1461804373295722		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.1461804373295722 | validation: 0.14775988169801713]
	TIME [epoch: 8.53 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14327645120325982		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.14327645120325982 | validation: 0.13669995783297026]
	TIME [epoch: 8.54 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15628827669676998		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.15628827669676998 | validation: 0.14045255711011623]
	TIME [epoch: 8.54 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12710098718619067		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.12710098718619067 | validation: 0.1372702521151679]
	TIME [epoch: 8.53 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13267890913140834		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.13267890913140834 | validation: 0.14509179690651133]
	TIME [epoch: 8.53 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14837351725204767		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.14837351725204767 | validation: 0.12426485607393799]
	TIME [epoch: 8.54 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15352739516765787		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.15352739516765787 | validation: 0.13438652965005166]
	TIME [epoch: 8.54 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14039011243875837		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.14039011243875837 | validation: 0.14503374170636407]
	TIME [epoch: 8.53 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11715048609450598		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.11715048609450598 | validation: 0.18301137215783098]
	TIME [epoch: 8.53 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1651244105620778		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.1651244105620778 | validation: 0.13783392795119043]
	TIME [epoch: 8.55 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14244211827232686		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.14244211827232686 | validation: 0.1256799414863679]
	TIME [epoch: 8.53 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13767205833154172		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.13767205833154172 | validation: 0.13349072168892012]
	TIME [epoch: 8.54 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14709121067634692		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.14709121067634692 | validation: 0.1640460694050329]
	TIME [epoch: 8.53 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11918038414835579		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.11918038414835579 | validation: 0.11753161149641381]
	TIME [epoch: 8.55 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1321233980761435		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.1321233980761435 | validation: 0.15069411004132716]
	TIME [epoch: 8.53 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1406852406204203		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.1406852406204203 | validation: 0.1934387138417502]
	TIME [epoch: 8.53 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12794993238547986		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.12794993238547986 | validation: 0.1330820399116611]
	TIME [epoch: 8.53 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13392825633360336		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.13392825633360336 | validation: 0.1300679735900908]
	TIME [epoch: 8.55 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14002183654693412		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.14002183654693412 | validation: 0.17063700728172626]
	TIME [epoch: 8.53 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1933898090039679		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.1933898090039679 | validation: 0.2465793842051422]
	TIME [epoch: 8.53 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2109861512873148		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.2109861512873148 | validation: 0.18357998174385382]
	TIME [epoch: 8.53 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13828916828308863		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.13828916828308863 | validation: 0.14238137652029653]
	TIME [epoch: 8.55 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14815349562389668		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.14815349562389668 | validation: 0.19425295267711812]
	TIME [epoch: 8.53 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14410578367899576		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.14410578367899576 | validation: 0.12521008850958684]
	TIME [epoch: 8.53 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15749558833258598		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.15749558833258598 | validation: 0.11421680000748324]
	TIME [epoch: 8.53 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1188580353489197		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.1188580353489197 | validation: 0.12069652770272914]
	TIME [epoch: 8.56 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15189799905649343		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.15189799905649343 | validation: 0.2170873386209538]
	TIME [epoch: 8.53 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1425738983150294		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.1425738983150294 | validation: 0.13489117588077015]
	TIME [epoch: 8.53 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1196476941595777		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.1196476941595777 | validation: 0.1052060549776232]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_140923/states/model_tr_study4_870.pth
	Model improved!!!
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15838357371893202		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.15838357371893202 | validation: 0.14899676567753248]
	TIME [epoch: 8.55 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1252041717997892		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.1252041717997892 | validation: 0.16461012203231723]
	TIME [epoch: 8.53 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14605676971795128		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.14605676971795128 | validation: 0.12264726302951848]
	TIME [epoch: 8.53 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12186328979016414		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.12186328979016414 | validation: 0.12716573305334966]
	TIME [epoch: 8.54 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11224925094492622		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.11224925094492622 | validation: 0.12469931924324358]
	TIME [epoch: 8.54 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14161854727556933		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.14161854727556933 | validation: 0.21598159769512812]
	TIME [epoch: 8.53 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1599226630896457		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.1599226630896457 | validation: 0.15956131642263086]
	TIME [epoch: 8.53 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1380246987124645		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.1380246987124645 | validation: 0.12078358127821692]
	TIME [epoch: 8.56 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13320109439335515		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.13320109439335515 | validation: 0.13169197177439476]
	TIME [epoch: 8.54 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13168165032850107		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.13168165032850107 | validation: 0.1369439516448407]
	TIME [epoch: 8.53 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15495496545236404		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.15495496545236404 | validation: 0.1480383437486988]
	TIME [epoch: 8.53 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18843416235933705		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.18843416235933705 | validation: 0.12478708265781319]
	TIME [epoch: 8.55 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12638949319354234		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.12638949319354234 | validation: 0.14763520816866213]
	TIME [epoch: 8.53 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1267363731461126		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.1267363731461126 | validation: 0.14046763268150025]
	TIME [epoch: 8.53 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13086382673723082		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.13086382673723082 | validation: 0.13601804693051883]
	TIME [epoch: 8.53 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.129179005013322		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.129179005013322 | validation: 0.17012537812352474]
	TIME [epoch: 8.55 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12994916056935502		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.12994916056935502 | validation: 0.20157476400868946]
	TIME [epoch: 8.53 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15417189212427598		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.15417189212427598 | validation: 0.14487843921852317]
	TIME [epoch: 8.53 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1391068195906394		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.1391068195906394 | validation: 0.19528124153541113]
	TIME [epoch: 8.53 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12321448491184875		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.12321448491184875 | validation: 0.12522989915993507]
	TIME [epoch: 8.55 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13643645943026167		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.13643645943026167 | validation: 0.257710673155028]
	TIME [epoch: 8.53 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17048927353247592		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.17048927353247592 | validation: 0.1388757159883452]
	TIME [epoch: 8.53 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14034431522297353		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.14034431522297353 | validation: 0.15817344236196554]
	TIME [epoch: 8.53 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15466632107631256		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.15466632107631256 | validation: 0.1287788703797262]
	TIME [epoch: 8.55 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11379129837623983		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.11379129837623983 | validation: 0.13093530559926359]
	TIME [epoch: 8.53 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12259575682184368		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.12259575682184368 | validation: 0.14924753148463862]
	TIME [epoch: 8.53 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.142018554106821		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.142018554106821 | validation: 0.13436704587755635]
	TIME [epoch: 8.53 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1214996386424434		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.1214996386424434 | validation: 0.11629673460369168]
	TIME [epoch: 8.55 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12848599631667876		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.12848599631667876 | validation: 0.19972753406985028]
	TIME [epoch: 8.53 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1380995986877949		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.1380995986877949 | validation: 0.17523769832335317]
	TIME [epoch: 8.53 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13817875157267412		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.13817875157267412 | validation: 0.1475488301571889]
	TIME [epoch: 8.53 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13814395793385031		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.13814395793385031 | validation: 0.16481449984946628]
	TIME [epoch: 8.55 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16607202169384921		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.16607202169384921 | validation: 0.18272541883376003]
	TIME [epoch: 8.53 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14229549685319326		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.14229549685319326 | validation: 0.15453170487801188]
	TIME [epoch: 8.53 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12441202735671278		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.12441202735671278 | validation: 0.13465593352488753]
	TIME [epoch: 8.54 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11113476554007184		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.11113476554007184 | validation: 0.1235771534925925]
	TIME [epoch: 8.54 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12269247509933272		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.12269247509933272 | validation: 0.11971308912596848]
	TIME [epoch: 8.53 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10170299591477142		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.10170299591477142 | validation: 0.12454980051834655]
	TIME [epoch: 8.53 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1512037188657302		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.1512037188657302 | validation: 0.1327195561521808]
	TIME [epoch: 8.54 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10797747200548735		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.10797747200548735 | validation: 0.185017031679261]
	TIME [epoch: 8.53 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13695975879812708		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.13695975879812708 | validation: 0.13712762583358445]
	TIME [epoch: 8.52 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10942867484540261		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.10942867484540261 | validation: 0.1421470115170282]
	TIME [epoch: 8.53 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12104288953439468		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.12104288953439468 | validation: 0.1584975815381106]
	TIME [epoch: 8.55 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10779473719111117		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.10779473719111117 | validation: 0.12888005251396256]
	TIME [epoch: 8.53 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1295117727253216		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.1295117727253216 | validation: 0.16307561513864832]
	TIME [epoch: 8.52 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12983470299374197		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.12983470299374197 | validation: 0.11689050423792044]
	TIME [epoch: 8.53 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15455460465141452		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.15455460465141452 | validation: 0.14499301258184566]
	TIME [epoch: 8.54 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12890186682743765		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.12890186682743765 | validation: 0.11906324261935475]
	TIME [epoch: 8.53 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12435836213354204		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.12435836213354204 | validation: 0.15665271611049456]
	TIME [epoch: 8.52 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1830554680855911		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.1830554680855911 | validation: 0.18370442182109023]
	TIME [epoch: 8.53 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12759930235411715		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.12759930235411715 | validation: 0.12988524350067035]
	TIME [epoch: 8.54 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11075964929052085		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.11075964929052085 | validation: 0.12628724583980327]
	TIME [epoch: 8.52 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13873394426058644		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.13873394426058644 | validation: 0.13289000069450702]
	TIME [epoch: 8.53 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15951938440158717		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.15951938440158717 | validation: 0.1780348355324416]
	TIME [epoch: 8.52 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1421654995290829		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.1421654995290829 | validation: 0.11609929158267357]
	TIME [epoch: 8.55 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1294235961556615		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.1294235961556615 | validation: 0.22959059179267566]
	TIME [epoch: 8.52 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12294822063367117		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.12294822063367117 | validation: 0.11539236747851261]
	TIME [epoch: 8.53 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1247746463980898		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.1247746463980898 | validation: 0.16188149129996995]
	TIME [epoch: 8.52 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15426388742441094		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.15426388742441094 | validation: 0.13272621640073753]
	TIME [epoch: 8.55 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16997079110470675		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.16997079110470675 | validation: 0.12250235612016376]
	TIME [epoch: 8.53 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11750263867821324		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.11750263867821324 | validation: 0.13318790240966927]
	TIME [epoch: 8.53 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11845884548246133		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.11845884548246133 | validation: 0.1426265132136086]
	TIME [epoch: 8.53 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12064620990569327		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.12064620990569327 | validation: 0.1924791431587386]
	TIME [epoch: 8.54 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12190774355706957		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.12190774355706957 | validation: 0.1339674037633529]
	TIME [epoch: 8.53 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11013150601514984		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.11013150601514984 | validation: 0.1935714325670377]
	TIME [epoch: 8.53 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12675396290331348		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.12675396290331348 | validation: 0.11760448690375656]
	TIME [epoch: 8.54 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12235964548040681		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.12235964548040681 | validation: 0.1327106712629328]
	TIME [epoch: 8.54 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11790572308170011		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.11790572308170011 | validation: 0.15265211628485942]
	TIME [epoch: 8.52 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12005917648147761		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.12005917648147761 | validation: 0.1310861353667008]
	TIME [epoch: 8.53 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1316288331844731		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.1316288331844731 | validation: 0.12294742094623352]
	TIME [epoch: 8.54 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13053986560273184		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.13053986560273184 | validation: 0.13512999833206368]
	TIME [epoch: 8.54 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1333669321284388		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.1333669321284388 | validation: 0.18599394828128918]
	TIME [epoch: 8.52 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11724730160295727		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.11724730160295727 | validation: 0.1206286032279619]
	TIME [epoch: 8.53 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11510703171999484		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.11510703171999484 | validation: 0.20183676098110226]
	TIME [epoch: 8.55 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13508496651603505		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.13508496651603505 | validation: 0.11123362216685004]
	TIME [epoch: 8.53 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10806330028953395		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.10806330028953395 | validation: 0.1334164852252525]
	TIME [epoch: 8.53 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1223831030528296		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.1223831030528296 | validation: 0.1592780973312815]
	TIME [epoch: 8.52 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10944338503251261		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.10944338503251261 | validation: 0.1191368910551145]
	TIME [epoch: 8.55 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12775564628148012		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.12775564628148012 | validation: 0.13728437599612736]
	TIME [epoch: 8.53 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.14662312816918527		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.14662312816918527 | validation: 0.12534783397370838]
	TIME [epoch: 8.52 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.131776539057724		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.131776539057724 | validation: 0.11471513392472885]
	TIME [epoch: 8.53 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11140417081810136		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.11140417081810136 | validation: 0.12052377897337777]
	TIME [epoch: 8.54 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11726318234263318		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.11726318234263318 | validation: 0.15389627665165134]
	TIME [epoch: 8.53 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12697930183129816		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.12697930183129816 | validation: 0.11685277304249336]
	TIME [epoch: 8.52 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13549067304462886		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.13549067304462886 | validation: 0.12344637030081937]
	TIME [epoch: 8.53 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12747035792862554		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.12747035792862554 | validation: 0.1274412145232179]
	TIME [epoch: 8.55 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11287176293761263		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.11287176293761263 | validation: 0.17041333773765305]
	TIME [epoch: 8.53 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13850727746913732		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.13850727746913732 | validation: 0.13929462494859857]
	TIME [epoch: 8.53 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12557550018812663		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.12557550018812663 | validation: 0.14952108093033611]
	TIME [epoch: 8.51 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1451388205951172		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.1451388205951172 | validation: 0.13474226042221085]
	TIME [epoch: 8.53 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11120235889362681		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.11120235889362681 | validation: 0.14147087639844616]
	TIME [epoch: 8.51 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11745524703623875		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.11745524703623875 | validation: 0.13454998535627583]
	TIME [epoch: 8.51 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13236353028581654		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.13236353028581654 | validation: 0.14651127286277882]
	TIME [epoch: 8.52 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13735499687595104		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.13735499687595104 | validation: 0.13545394173073078]
	TIME [epoch: 8.53 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11648082322561533		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.11648082322561533 | validation: 0.15731472200729033]
	TIME [epoch: 8.51 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12990085641006996		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.12990085641006996 | validation: 0.13684266560574002]
	TIME [epoch: 8.51 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11703446686399092		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.11703446686399092 | validation: 0.12509256112851821]
	TIME [epoch: 8.53 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12301848475128992		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.12301848475128992 | validation: 0.12297015140875836]
	TIME [epoch: 8.52 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13413229784518857		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.13413229784518857 | validation: 0.14816518804426176]
	TIME [epoch: 8.51 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1480933440875538		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.1480933440875538 | validation: 0.17972660078890496]
	TIME [epoch: 8.51 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12623281359324054		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.12623281359324054 | validation: 0.11806882598194784]
	TIME [epoch: 8.53 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11578695945322404		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.11578695945322404 | validation: 0.16881453248266465]
	TIME [epoch: 8.53 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12369719639545895		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.12369719639545895 | validation: 0.15723267540817829]
	TIME [epoch: 8.52 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11450992132672673		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.11450992132672673 | validation: 0.1132208142758928]
	TIME [epoch: 8.52 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10644461323607776		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.10644461323607776 | validation: 0.11975462769732151]
	TIME [epoch: 8.53 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.15991136573707262		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.15991136573707262 | validation: 0.13056373283875047]
	TIME [epoch: 8.52 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13401494991910928		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.13401494991910928 | validation: 0.16968155542571156]
	TIME [epoch: 8.52 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10877805982886882		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.10877805982886882 | validation: 0.12295391922154561]
	TIME [epoch: 8.51 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10997822758709089		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.10997822758709089 | validation: 0.13996342318465133]
	TIME [epoch: 8.54 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11902558324550434		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.11902558324550434 | validation: 0.13095445725640617]
	TIME [epoch: 8.52 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10833581999354522		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.10833581999354522 | validation: 0.11575601083026166]
	TIME [epoch: 8.52 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11788458598217617		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.11788458598217617 | validation: 0.12528446549637162]
	TIME [epoch: 8.51 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.129315534436059		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.129315534436059 | validation: 0.1813929712846505]
	TIME [epoch: 8.54 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13382393731024547		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.13382393731024547 | validation: 0.14653635693932768]
	TIME [epoch: 8.51 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1026352110285329		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.1026352110285329 | validation: 0.15183992827465562]
	TIME [epoch: 8.51 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.13880272574297278		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.13880272574297278 | validation: 0.14828519273856236]
	TIME [epoch: 8.51 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12396771451413438		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.12396771451413438 | validation: 0.13940875331633706]
	TIME [epoch: 8.54 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11212154106388608		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.11212154106388608 | validation: 0.13692288188073265]
	TIME [epoch: 8.52 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.10916751409925993		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.10916751409925993 | validation: 0.12359003126260182]
	TIME [epoch: 8.52 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11178071948796804		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.11178071948796804 | validation: 0.1256120170461234]
	TIME [epoch: 8.52 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11533932927845203		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.11533932927845203 | validation: 0.15913505773260012]
	TIME [epoch: 8.54 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11465378930834565		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.11465378930834565 | validation: 0.1393395490794127]
	TIME [epoch: 8.52 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12064884549177705		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.12064884549177705 | validation: 0.1285955260390587]
	TIME [epoch: 8.52 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11356262203714913		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.11356262203714913 | validation: 0.13767778927143026]
	TIME [epoch: 8.52 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11052089145761253		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.11052089145761253 | validation: 0.14925498810743038]
	TIME [epoch: 8.54 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12283514324626835		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.12283514324626835 | validation: 0.11759396596734359]
	TIME [epoch: 8.51 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.12592995849460017		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.12592995849460017 | validation: 0.12450184749091422]
	TIME [epoch: 8.52 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11858519615243564		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.11858519615243564 | validation: 0.14100513878166354]
	TIME [epoch: 8.52 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1204897888567709		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.1204897888567709 | validation: 0.16788335168534618]
	TIME [epoch: 8.54 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.11507080504126257		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.11507080504126257 | validation: 0.15774666610717358]
	TIME [epoch: 8.52 sec]
Finished training in 8650.182 seconds.
