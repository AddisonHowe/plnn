Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r3', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=500, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2935373086

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.8051953166581525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.8051953166581525 | validation: 6.579855949511475]
	TIME [epoch: 48.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.451555459834201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.451555459834201 | validation: 6.491652036584885]
	TIME [epoch: 9.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.703905318773918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.703905318773918 | validation: 5.1788936014175775]
	TIME [epoch: 9.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.998369730448269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.998369730448269 | validation: 4.671796554274138]
	TIME [epoch: 9.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.580971469842765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.580971469842765 | validation: 4.193067671543915]
	TIME [epoch: 9.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.300652428182313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.300652428182313 | validation: 4.431219621527895]
	TIME [epoch: 9.33 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.6687162083942315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6687162083942315 | validation: 4.506781825580781]
	TIME [epoch: 9.35 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.355438845122199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.355438845122199 | validation: 5.3209036847255025]
	TIME [epoch: 9.34 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.968354959028789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.968354959028789 | validation: 3.7035708862170074]
	TIME [epoch: 9.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.924973373367181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.924973373367181 | validation: 3.6522780915265622]
	TIME [epoch: 9.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7402772347650988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7402772347650988 | validation: 3.461653429274815]
	TIME [epoch: 9.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2465523950263218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2465523950263218 | validation: 3.2213463798913704]
	TIME [epoch: 9.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.844734011497093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.844734011497093 | validation: 2.668650407277975]
	TIME [epoch: 9.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4363462162613447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4363462162613447 | validation: 2.2658548877429814]
	TIME [epoch: 9.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9376068256187728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9376068256187728 | validation: 1.9515137889928589]
	TIME [epoch: 9.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2030420834625426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2030420834625426 | validation: 1.693936510864882]
	TIME [epoch: 9.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.462461019604086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.462461019604086 | validation: 1.1389225201962434]
	TIME [epoch: 9.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0358392900177917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0358392900177917 | validation: 1.0160516701858884]
	TIME [epoch: 9.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.267537221200152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.267537221200152 | validation: 0.7628966213584268]
	TIME [epoch: 9.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8439640791565555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8439640791565555 | validation: 3.530529692843621]
	TIME [epoch: 9.44 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8562894914836354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8562894914836354 | validation: 3.3914280412179716]
	TIME [epoch: 9.33 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3018766185337904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3018766185337904 | validation: 3.263258705653797]
	TIME [epoch: 9.33 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.023042105368238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.023042105368238 | validation: 5.3378644116018235]
	TIME [epoch: 9.33 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3322527934858748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3322527934858748 | validation: 2.8830995685222067]
	TIME [epoch: 9.33 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7418483192868752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7418483192868752 | validation: 1.176634349045024]
	TIME [epoch: 9.35 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9670855633699269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9670855633699269 | validation: 0.8850697185401999]
	TIME [epoch: 9.33 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.122697919745013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.122697919745013 | validation: 1.0558305637993284]
	TIME [epoch: 9.32 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8730119206997422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8730119206997422 | validation: 2.5010465079830033]
	TIME [epoch: 9.32 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2325732709727544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2325732709727544 | validation: 1.1070227689528875]
	TIME [epoch: 9.35 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8792744348565478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8792744348565478 | validation: 0.7875629431673399]
	TIME [epoch: 9.32 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.831258597328896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.831258597328896 | validation: 1.1006772336923953]
	TIME [epoch: 9.33 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7475912500220888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7475912500220888 | validation: 0.8519779566952457]
	TIME [epoch: 9.32 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.752947046376781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.752947046376781 | validation: 0.7916908582248116]
	TIME [epoch: 9.34 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7536467021418487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7536467021418487 | validation: 0.8378256008971559]
	TIME [epoch: 9.33 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7898991570954864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7898991570954864 | validation: 0.6096489934959086]
	TIME [epoch: 9.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8841797503147439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8841797503147439 | validation: 0.6287833787340604]
	TIME [epoch: 9.33 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.731181493644715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.731181493644715 | validation: 0.9419443059099359]
	TIME [epoch: 9.33 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8794853962627316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8794853962627316 | validation: 0.6533162542894134]
	TIME [epoch: 9.35 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8771422833584541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8771422833584541 | validation: 1.4706940937318764]
	TIME [epoch: 9.33 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8576361860571161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8576361860571161 | validation: 0.7839506877083906]
	TIME [epoch: 9.32 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6965911259858533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6965911259858533 | validation: 0.5242033544633364]
	TIME [epoch: 9.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6576418209915695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6576418209915695 | validation: 0.7876977844974475]
	TIME [epoch: 9.35 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7556181889420012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7556181889420012 | validation: 0.5477566309079456]
	TIME [epoch: 9.33 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6729264157760542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6729264157760542 | validation: 0.6410012533627045]
	TIME [epoch: 9.33 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6724645715005921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6724645715005921 | validation: 0.599572640618953]
	TIME [epoch: 9.33 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8144037885414687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8144037885414687 | validation: 0.6475172388714223]
	TIME [epoch: 9.33 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7226711535952905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7226711535952905 | validation: 0.8966814288920151]
	TIME [epoch: 9.34 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7449365597328874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7449365597328874 | validation: 0.5615560803837087]
	TIME [epoch: 9.33 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8454780127513191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8454780127513191 | validation: 0.895716331370048]
	TIME [epoch: 9.31 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6956088295922311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6956088295922311 | validation: 0.6653877680991416]
	TIME [epoch: 9.32 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8548499284859299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8548499284859299 | validation: 0.5323246511626647]
	TIME [epoch: 9.34 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6489445994654942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6489445994654942 | validation: 0.4446746982311496]
	TIME [epoch: 9.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7746313582996677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7746313582996677 | validation: 0.6054551775366122]
	TIME [epoch: 9.32 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5626278198139721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5626278198139721 | validation: 0.6545761123216486]
	TIME [epoch: 9.32 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6060146621183009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6060146621183009 | validation: 0.744313341879864]
	TIME [epoch: 9.32 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7663750100477349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7663750100477349 | validation: 0.8797053442204416]
	TIME [epoch: 9.34 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7761864340056878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7761864340056878 | validation: 0.5655838621895546]
	TIME [epoch: 9.32 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7514036986180737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7514036986180737 | validation: 0.5374959715059318]
	TIME [epoch: 9.32 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6121874454328798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6121874454328798 | validation: 0.7053949681647402]
	TIME [epoch: 9.32 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6092350422638224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6092350422638224 | validation: 0.6732787607633135]
	TIME [epoch: 9.35 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6553885702359421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6553885702359421 | validation: 0.7641768057845941]
	TIME [epoch: 9.34 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6333089836715589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6333089836715589 | validation: 0.6661356361015551]
	TIME [epoch: 9.33 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6568024208715817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6568024208715817 | validation: 0.5237253105316911]
	TIME [epoch: 9.32 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.765937882210144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.765937882210144 | validation: 0.5226771709905802]
	TIME [epoch: 9.33 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6686531468397249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6686531468397249 | validation: 0.5820024239487562]
	TIME [epoch: 9.35 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7550597498816464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7550597498816464 | validation: 0.6297494923396225]
	TIME [epoch: 9.34 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6479418505376131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6479418505376131 | validation: 0.6380111660042156]
	TIME [epoch: 9.33 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0563430794905961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0563430794905961 | validation: 0.574672028585097]
	TIME [epoch: 9.33 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6565953610477311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6565953610477311 | validation: 0.6071946038870357]
	TIME [epoch: 9.35 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.609207763765643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.609207763765643 | validation: 0.5385253206208056]
	TIME [epoch: 9.34 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.598401650925888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.598401650925888 | validation: 0.851773766465439]
	TIME [epoch: 9.32 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.625632389155553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.625632389155553 | validation: 0.7514675290083471]
	TIME [epoch: 9.32 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6232768140113272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6232768140113272 | validation: 1.045450617905387]
	TIME [epoch: 9.33 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6399251436748854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6399251436748854 | validation: 1.1002604926824247]
	TIME [epoch: 9.35 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6511643505011969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6511643505011969 | validation: 0.7678832704985077]
	TIME [epoch: 9.33 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6228363853535333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6228363853535333 | validation: 0.5646950195206235]
	TIME [epoch: 9.33 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5975206653803107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5975206653803107 | validation: 0.5173034206253078]
	TIME [epoch: 9.32 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5606711759560934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5606711759560934 | validation: 0.630783002174889]
	TIME [epoch: 9.35 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6220168888299458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6220168888299458 | validation: 1.4902411303835108]
	TIME [epoch: 9.33 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8016609386121785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8016609386121785 | validation: 0.5639477243034481]
	TIME [epoch: 9.33 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.51116021957334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.51116021957334 | validation: 0.6334331367572175]
	TIME [epoch: 9.32 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5292715189052022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5292715189052022 | validation: 0.6563006573924769]
	TIME [epoch: 9.34 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5539590256202117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5539590256202117 | validation: 0.4381063310052222]
	TIME [epoch: 9.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5942979153790786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5942979153790786 | validation: 0.5922686992706636]
	TIME [epoch: 9.45 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.571804564353648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.571804564353648 | validation: 0.5328361473092946]
	TIME [epoch: 9.32 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.535303348265668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.535303348265668 | validation: 0.6101553079592461]
	TIME [epoch: 9.32 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.501118042148127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.501118042148127 | validation: 0.4363477293820944]
	TIME [epoch: 9.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5074858611437791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5074858611437791 | validation: 0.5965000121552224]
	TIME [epoch: 9.4 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5181646217272183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5181646217272183 | validation: 0.47051187196687383]
	TIME [epoch: 9.32 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6125217736536024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6125217736536024 | validation: 0.7248867663851468]
	TIME [epoch: 9.31 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45714569725607024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45714569725607024 | validation: 0.36220849663614496]
	TIME [epoch: 9.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44131537280373234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44131537280373234 | validation: 0.4699038430727871]
	TIME [epoch: 9.33 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5946361724752715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5946361724752715 | validation: 2.909634331793832]
	TIME [epoch: 9.32 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9406313348935598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9406313348935598 | validation: 0.5794917135669739]
	TIME [epoch: 9.32 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5416902817311475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5416902817311475 | validation: 0.42843525966694385]
	TIME [epoch: 9.33 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48072617383463545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48072617383463545 | validation: 0.43230712505601565]
	TIME [epoch: 9.34 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47985351313130975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47985351313130975 | validation: 0.6316381746873283]
	TIME [epoch: 9.33 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4676471345866763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4676471345866763 | validation: 0.6729519691372365]
	TIME [epoch: 9.33 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9200954258992393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9200954258992393 | validation: 0.41486150946344047]
	TIME [epoch: 9.33 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44415519026440486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44415519026440486 | validation: 1.36474962069288]
	TIME [epoch: 9.35 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7454405280292695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7454405280292695 | validation: 0.38702932932210427]
	TIME [epoch: 9.33 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7217880730102407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7217880730102407 | validation: 0.5504514750186116]
	TIME [epoch: 9.33 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38453621535241755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38453621535241755 | validation: 0.3755601928994038]
	TIME [epoch: 9.33 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.631386908437297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.631386908437297 | validation: 0.3999859685897563]
	TIME [epoch: 9.33 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4933284357808386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4933284357808386 | validation: 0.4198110048776418]
	TIME [epoch: 9.35 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.649813656567228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.649813656567228 | validation: 0.4587112883162397]
	TIME [epoch: 9.33 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4414094592108322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4414094592108322 | validation: 0.5854747193017956]
	TIME [epoch: 9.32 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6198370220261322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6198370220261322 | validation: 0.6378162366422837]
	TIME [epoch: 9.34 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5299807609447609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5299807609447609 | validation: 0.4817814733511285]
	TIME [epoch: 9.35 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43476484797478887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43476484797478887 | validation: 0.46482733004650223]
	TIME [epoch: 9.33 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43446437090518897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43446437090518897 | validation: 0.34664238369450806]
	TIME [epoch: 9.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8068373343378037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8068373343378037 | validation: 0.47288535238969814]
	TIME [epoch: 9.41 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4772225499721559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4772225499721559 | validation: 0.6602271967991784]
	TIME [epoch: 9.33 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4642044147751531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4642044147751531 | validation: 0.3733725647125439]
	TIME [epoch: 9.35 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5671574489872235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5671574489872235 | validation: 0.8421550550400194]
	TIME [epoch: 9.32 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1967812904016846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1967812904016846 | validation: 1.0628887245150422]
	TIME [epoch: 9.33 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6247943733524153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6247943733524153 | validation: 0.5014441510787692]
	TIME [epoch: 9.32 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5298392030721379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5298392030721379 | validation: 0.6993125263211407]
	TIME [epoch: 9.35 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5516558063249988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5516558063249988 | validation: 0.31237260372941933]
	TIME [epoch: 9.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7565454356872531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7565454356872531 | validation: 0.6628567248564381]
	TIME [epoch: 9.33 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9052794328806287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9052794328806287 | validation: 1.9274583493933712]
	TIME [epoch: 9.32 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7705870697281101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7705870697281101 | validation: 0.35958203721417714]
	TIME [epoch: 9.33 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4411706422189746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4411706422189746 | validation: 0.41315543248124076]
	TIME [epoch: 9.34 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6660803647901087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6660803647901087 | validation: 0.3056699987582817]
	TIME [epoch: 9.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5386467693190357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5386467693190357 | validation: 0.4327916202694852]
	TIME [epoch: 9.33 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40160134679573567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40160134679573567 | validation: 0.3062598804670935]
	TIME [epoch: 9.32 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.663267576639565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.663267576639565 | validation: 0.5378612817771277]
	TIME [epoch: 9.36 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48813085728742356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48813085728742356 | validation: 0.4157929467239747]
	TIME [epoch: 9.33 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6158259055020923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6158259055020923 | validation: 0.37407502442303747]
	TIME [epoch: 9.34 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37284475427312447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37284475427312447 | validation: 0.9551547539704761]
	TIME [epoch: 9.33 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.538159888299885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.538159888299885 | validation: 0.3507880341787776]
	TIME [epoch: 9.34 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4897886417154019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4897886417154019 | validation: 0.3538420549119562]
	TIME [epoch: 9.36 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37264426217184143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37264426217184143 | validation: 0.4662379402948922]
	TIME [epoch: 9.33 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7934593467405274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7934593467405274 | validation: 0.9694276692728409]
	TIME [epoch: 9.33 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5394605462849917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5394605462849917 | validation: 0.3295069131112589]
	TIME [epoch: 9.33 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0956078828140257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0956078828140257 | validation: 0.47619800166310705]
	TIME [epoch: 9.35 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4441814055178176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4441814055178176 | validation: 0.36637700116223404]
	TIME [epoch: 9.33 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6351507308869742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6351507308869742 | validation: 0.36104299053675176]
	TIME [epoch: 9.34 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.461213510004152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.461213510004152 | validation: 0.6340344956100594]
	TIME [epoch: 9.33 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43807333880126736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43807333880126736 | validation: 0.4253365401039185]
	TIME [epoch: 9.36 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37153288500775056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37153288500775056 | validation: 1.169758888179445]
	TIME [epoch: 9.34 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7242464016172806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7242464016172806 | validation: 0.9133228337382864]
	TIME [epoch: 9.32 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4316520974139548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4316520974139548 | validation: 0.34515123965870503]
	TIME [epoch: 9.33 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39153012449598523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39153012449598523 | validation: 0.335069726708099]
	TIME [epoch: 9.33 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3588627113336819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3588627113336819 | validation: 0.4400569669530189]
	TIME [epoch: 9.35 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6593826061238008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6593826061238008 | validation: 0.5072109129545401]
	TIME [epoch: 9.34 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5221160021285537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5221160021285537 | validation: 0.31942928501191314]
	TIME [epoch: 9.33 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34216644382542644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34216644382542644 | validation: 0.36791922651847975]
	TIME [epoch: 9.33 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4239120223830038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4239120223830038 | validation: 0.5988826507086857]
	TIME [epoch: 9.35 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3862824409908685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3862824409908685 | validation: 0.30613194454055337]
	TIME [epoch: 9.33 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4017349184769178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4017349184769178 | validation: 0.419125862337565]
	TIME [epoch: 9.33 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3980695332861945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3980695332861945 | validation: 0.581255728614386]
	TIME [epoch: 9.32 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4473052681499654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4473052681499654 | validation: 0.30088869716195965]
	TIME [epoch: 9.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4221328647801276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4221328647801276 | validation: 0.5381224357897206]
	TIME [epoch: 9.34 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41272420354375716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41272420354375716 | validation: 0.2853001919734448]
	TIME [epoch: 9.31 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29477785087258124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29477785087258124 | validation: 0.7659353576169622]
	TIME [epoch: 9.33 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41999535234039237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41999535234039237 | validation: 0.19943141940396544]
	TIME [epoch: 9.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6597548458929925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6597548458929925 | validation: 0.49097330585855864]
	TIME [epoch: 9.34 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5417235879263241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5417235879263241 | validation: 0.27625350368113705]
	TIME [epoch: 9.31 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35306451144489137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35306451144489137 | validation: 0.3154027613765137]
	TIME [epoch: 9.33 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34933830357438106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34933830357438106 | validation: 0.22536891178269816]
	TIME [epoch: 9.32 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3475865746019267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3475865746019267 | validation: 0.28074608676871204]
	TIME [epoch: 9.32 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44215159311608865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44215159311608865 | validation: 0.7866154659661304]
	TIME [epoch: 9.34 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3570113907305285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3570113907305285 | validation: 0.247081702693491]
	TIME [epoch: 9.32 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3691409111670608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3691409111670608 | validation: 0.5318431847599405]
	TIME [epoch: 9.32 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.513686438751302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.513686438751302 | validation: 0.8624362885137544]
	TIME [epoch: 9.31 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5155927436568797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5155927436568797 | validation: 0.2647443224197715]
	TIME [epoch: 9.35 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4027661142349177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4027661142349177 | validation: 1.280445398315912]
	TIME [epoch: 9.33 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.526096751870163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.526096751870163 | validation: 0.48852586478122306]
	TIME [epoch: 9.32 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3957227142534277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3957227142534277 | validation: 0.17712916284274594]
	TIME [epoch: 9.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31859614463017555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31859614463017555 | validation: 0.30305784106255346]
	TIME [epoch: 9.32 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3826600532212849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3826600532212849 | validation: 0.4339187353301089]
	TIME [epoch: 9.32 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5102879527629651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5102879527629651 | validation: 0.3646275280760223]
	TIME [epoch: 9.33 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3821436262589039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3821436262589039 | validation: 0.28431973575389535]
	TIME [epoch: 9.33 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6434687669229573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6434687669229573 | validation: 0.4335217988401425]
	TIME [epoch: 9.33 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.343685181640168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.343685181640168 | validation: 1.0041877448637695]
	TIME [epoch: 9.34 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4364483403599787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4364483403599787 | validation: 0.35237667295303743]
	TIME [epoch: 9.31 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3594534525010374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3594534525010374 | validation: 0.24675224260651876]
	TIME [epoch: 9.33 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45774677441495204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45774677441495204 | validation: 0.31481347555128847]
	TIME [epoch: 9.32 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5800223926665213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5800223926665213 | validation: 0.7875537265276373]
	TIME [epoch: 9.32 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4310178828049339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4310178828049339 | validation: 0.331704508381255]
	TIME [epoch: 9.32 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45681337048422765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45681337048422765 | validation: 0.3020316889253601]
	TIME [epoch: 9.3 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.464625843569112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.464625843569112 | validation: 0.357378624756497]
	TIME [epoch: 9.31 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44614601649433555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44614601649433555 | validation: 0.9883383933449679]
	TIME [epoch: 9.3 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39973342415106605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39973342415106605 | validation: 0.2875020831960603]
	TIME [epoch: 9.33 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3121521256074655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3121521256074655 | validation: 0.25498348773425156]
	TIME [epoch: 9.31 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31320557110638364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31320557110638364 | validation: 0.31931107800035363]
	TIME [epoch: 9.31 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29567570912278857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29567570912278857 | validation: 0.30283158745394645]
	TIME [epoch: 9.3 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37955400701737013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37955400701737013 | validation: 0.8051284148105702]
	TIME [epoch: 9.32 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3872065288968961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3872065288968961 | validation: 0.3115091946858404]
	TIME [epoch: 9.31 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3659378342185027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3659378342185027 | validation: 1.0713341243999288]
	TIME [epoch: 9.31 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43781988519595305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43781988519595305 | validation: 0.35956042925595677]
	TIME [epoch: 9.31 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38970359320573333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38970359320573333 | validation: 0.24270261698628487]
	TIME [epoch: 9.31 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2619053215766013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2619053215766013 | validation: 0.34309166185585876]
	TIME [epoch: 9.33 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4584633477238274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4584633477238274 | validation: 0.3285847883100045]
	TIME [epoch: 9.31 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7137442747875904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7137442747875904 | validation: 1.2785020100009756]
	TIME [epoch: 9.31 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49700209264141026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49700209264141026 | validation: 0.17900527556865292]
	TIME [epoch: 9.31 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38963185658151167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38963185658151167 | validation: 0.2853078678794598]
	TIME [epoch: 11.3 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3060006716447802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3060006716447802 | validation: 0.17378660276158378]
	TIME [epoch: 9.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240217_063633/states/model_tr_study4_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24887875905312376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24887875905312376 | validation: 0.4183884355845329]
	TIME [epoch: 9.32 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25438637595940994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25438637595940994 | validation: 0.4287264415949105]
	TIME [epoch: 9.31 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24971064541859386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24971064541859386 | validation: 0.329711542436052]
	TIME [epoch: 9.31 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3219390839855892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3219390839855892 | validation: 0.4328491245379078]
	TIME [epoch: 9.34 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3551269565252276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3551269565252276 | validation: 0.6410669380926649]
	TIME [epoch: 9.32 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4507985121446775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4507985121446775 | validation: 0.2849742299960779]
	TIME [epoch: 9.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3112973458583822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3112973458583822 | validation: 0.34401128263540826]
	TIME [epoch: 9.32 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4154019219723818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4154019219723818 | validation: 0.26462528776125194]
	TIME [epoch: 9.33 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3069213683855668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3069213683855668 | validation: 0.3360000210154662]
	TIME [epoch: 9.32 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3327640565851662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3327640565851662 | validation: 0.4870974615100758]
	TIME [epoch: 9.31 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40542846128923465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40542846128923465 | validation: 0.5789659018615672]
	TIME [epoch: 9.31 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8221511364610714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8221511364610714 | validation: 0.6990916141281769]
	TIME [epoch: 9.32 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6703968463916006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6703968463916006 | validation: 0.5493284219523275]
	TIME [epoch: 9.35 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5808600347332753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5808600347332753 | validation: 0.7443878104777399]
	TIME [epoch: 9.32 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5262985329516441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5262985329516441 | validation: 0.2691101729511324]
	TIME [epoch: 9.32 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3633522287124432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3633522287124432 | validation: 0.3320117456624897]
	TIME [epoch: 9.32 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4351437175442904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4351437175442904 | validation: 0.2578378933398355]
	TIME [epoch: 9.34 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3917355768749647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3917355768749647 | validation: 0.33034722720367704]
	TIME [epoch: 9.32 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3542109403224959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3542109403224959 | validation: 0.2729194844831453]
	TIME [epoch: 9.32 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4622504599680039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4622504599680039 | validation: 0.30431384264817235]
	TIME [epoch: 9.32 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3262651516065821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3262651516065821 | validation: 0.37147846828841447]
	TIME [epoch: 9.32 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5399579827091572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5399579827091572 | validation: 0.3230619176802313]
	TIME [epoch: 9.35 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31451451981262657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31451451981262657 | validation: 0.247423477878318]
	TIME [epoch: 9.31 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2729804127926842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2729804127926842 | validation: 0.27512226974800574]
	TIME [epoch: 9.31 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32453273483816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32453273483816 | validation: 0.8915269614061496]
	TIME [epoch: 9.31 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9457960991869866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9457960991869866 | validation: 0.7453699868390178]
	TIME [epoch: 9.33 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4299531424374181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4299531424374181 | validation: 0.26915301545693293]
	TIME [epoch: 9.32 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6506481938361806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6506481938361806 | validation: 0.3935004880630052]
	TIME [epoch: 9.31 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3853049577114103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3853049577114103 | validation: 0.7223014954127401]
	TIME [epoch: 9.3 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3776108331476786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3776108331476786 | validation: 0.3623934961030975]
	TIME [epoch: 9.31 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.720151418564888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.720151418564888 | validation: 0.42882767819235074]
	TIME [epoch: 9.33 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3362098442592395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3362098442592395 | validation: 0.49651336257327583]
	TIME [epoch: 9.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5748069130607721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5748069130607721 | validation: 0.6658544554385852]
	TIME [epoch: 9.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5953048657187427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5953048657187427 | validation: 0.3666578164733261]
	TIME [epoch: 9.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3862339617815494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3862339617815494 | validation: 0.36956921158447786]
	TIME [epoch: 9.33 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5229767650763404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5229767650763404 | validation: 0.5494920944755113]
	TIME [epoch: 9.31 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40111158606716113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40111158606716113 | validation: 0.3324541615867616]
	TIME [epoch: 9.31 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3821602931608955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3821602931608955 | validation: 0.303656090585664]
	TIME [epoch: 9.31 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26996317654922936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26996317654922936 | validation: 0.3018957218875372]
	TIME [epoch: 9.32 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2896177654432838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2896177654432838 | validation: 0.2741271428002551]
	TIME [epoch: 9.33 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49507919762962443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49507919762962443 | validation: 0.5086041488771019]
	TIME [epoch: 9.31 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.403215923052828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.403215923052828 | validation: 0.3176113510316076]
	TIME [epoch: 9.31 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3219753061886731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3219753061886731 | validation: 0.27391294990133985]
	TIME [epoch: 9.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3099656098045128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3099656098045128 | validation: 0.3286946341195731]
	TIME [epoch: 9.33 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4152250260198507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4152250260198507 | validation: 0.241678230074313]
	TIME [epoch: 9.31 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3934852750860195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3934852750860195 | validation: 1.1269671755115842]
	TIME [epoch: 9.31 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4976592114556504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4976592114556504 | validation: 0.5304491395706139]
	TIME [epoch: 9.31 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4527572061954491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4527572061954491 | validation: 1.3291993066670376]
	TIME [epoch: 9.32 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.540621570758548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.540621570758548 | validation: 0.5580432157921666]
	TIME [epoch: 9.32 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38315959613205475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38315959613205475 | validation: 0.39041209509643415]
	TIME [epoch: 9.31 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38456649945171223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38456649945171223 | validation: 1.0927260168521515]
	TIME [epoch: 9.32 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5249321917444575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5249321917444575 | validation: 0.9563696534699574]
	TIME [epoch: 9.31 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1775121454540254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1775121454540254 | validation: 2.0261337339002603]
	TIME [epoch: 9.34 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6799808668509447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6799808668509447 | validation: 0.7201075399918031]
	TIME [epoch: 9.32 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5849519854577111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5849519854577111 | validation: 0.29856407153918285]
	TIME [epoch: 9.31 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3042641236931042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3042641236931042 | validation: 0.22107431799671268]
	TIME [epoch: 9.32 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26573979566514117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26573979566514117 | validation: 0.9126946557894764]
	TIME [epoch: 9.32 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3954769374813301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3954769374813301 | validation: 0.3998103984611621]
	TIME [epoch: 9.33 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49835444356306297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49835444356306297 | validation: 0.6570925380651078]
	TIME [epoch: 9.31 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6050824762889605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6050824762889605 | validation: 0.49287865180257745]
	TIME [epoch: 9.31 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5813789290293883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5813789290293883 | validation: 0.942971623722128]
	TIME [epoch: 9.31 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7422472855862629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7422472855862629 | validation: 0.40653922584217517]
	TIME [epoch: 9.33 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43479666400219824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43479666400219824 | validation: 0.42039613058797853]
	TIME [epoch: 9.31 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33551956873109134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33551956873109134 | validation: 0.31906691128345405]
	TIME [epoch: 9.32 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32553514962135716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32553514962135716 | validation: 0.39295847565927133]
	TIME [epoch: 9.31 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41265146853500323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41265146853500323 | validation: 0.34362872654526805]
	TIME [epoch: 9.33 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4540859208354216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4540859208354216 | validation: 0.4918514947114806]
	TIME [epoch: 9.32 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41456415095189164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41456415095189164 | validation: 0.3309880351538056]
	TIME [epoch: 9.32 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32017924509587314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32017924509587314 | validation: 0.4782489508629352]
	TIME [epoch: 9.32 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3835970799297825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3835970799297825 | validation: 0.3694949339710343]
	TIME [epoch: 9.32 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3713149221507086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3713149221507086 | validation: 0.8774164322296036]
	TIME [epoch: 9.35 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6730551850650233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6730551850650233 | validation: 0.9600116751262873]
	TIME [epoch: 9.32 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5207368556450132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5207368556450132 | validation: 0.3461468527854433]
	TIME [epoch: 9.32 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40134408889364537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40134408889364537 | validation: 0.8448187065288066]
	TIME [epoch: 9.32 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.593061140353359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.593061140353359 | validation: 0.4223962656742778]
	TIME [epoch: 9.33 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5990761239147927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5990761239147927 | validation: 0.2942267065598052]
	TIME [epoch: 9.33 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3748593065496356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3748593065496356 | validation: 0.45194686568577414]
	TIME [epoch: 9.32 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33431426983996354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33431426983996354 | validation: 0.6455198162818296]
	TIME [epoch: 9.31 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7645050621581186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7645050621581186 | validation: 2.74865686356074]
	TIME [epoch: 9.31 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1184775044293305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1184775044293305 | validation: 0.8766243046884927]
	TIME [epoch: 9.33 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5298762690415982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5298762690415982 | validation: 0.3065425678060757]
	TIME [epoch: 9.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4322205475152285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4322205475152285 | validation: 0.41799992171822953]
	TIME [epoch: 9.31 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8211193473319425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8211193473319425 | validation: 1.0349765086479805]
	TIME [epoch: 9.32 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9125437022282445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9125437022282445 | validation: 1.7705065893177871]
	TIME [epoch: 9.33 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8693196689020946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8693196689020946 | validation: 0.9152709058343501]
	TIME [epoch: 9.32 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.60391207929777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.60391207929777 | validation: 0.3775314647733835]
	TIME [epoch: 9.32 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40043716619843045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40043716619843045 | validation: 0.413737787581849]
	TIME [epoch: 9.33 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4022282748794547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4022282748794547 | validation: 0.730472524057824]
	TIME [epoch: 9.32 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5315926587442972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5315926587442972 | validation: 0.4011968164973835]
	TIME [epoch: 9.33 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39552479162557636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39552479162557636 | validation: 0.3828103724690636]
	TIME [epoch: 9.32 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32674658144078644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32674658144078644 | validation: 0.8466587771267508]
	TIME [epoch: 9.31 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39049259775508094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39049259775508094 | validation: 0.3088480177127991]
	TIME [epoch: 9.32 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3802102172892864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3802102172892864 | validation: 0.4459171319370169]
	TIME [epoch: 9.34 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4307658757014721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4307658757014721 | validation: 0.23562914699606452]
	TIME [epoch: 9.33 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28919401833438746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28919401833438746 | validation: 0.39978685572708816]
	TIME [epoch: 9.32 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3285331012081757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3285331012081757 | validation: 0.22285764837527577]
	TIME [epoch: 9.32 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3075673270651943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3075673270651943 | validation: 0.2814606414730413]
	TIME [epoch: 9.32 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3134247101896173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3134247101896173 | validation: 0.292448359700302]
	TIME [epoch: 9.33 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3580920101885309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3580920101885309 | validation: 0.2638044287885364]
	TIME [epoch: 9.31 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29450576217793467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29450576217793467 | validation: 0.3112393438652857]
	TIME [epoch: 9.32 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41718336129785455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41718336129785455 | validation: 0.3579729356949146]
	TIME [epoch: 9.32 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8402492392666243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8402492392666243 | validation: 0.5056735671740676]
	TIME [epoch: 9.33 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4754339678253553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4754339678253553 | validation: 0.39034510377800924]
	TIME [epoch: 9.31 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3468438454318174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3468438454318174 | validation: 0.29830532932869214]
	TIME [epoch: 9.31 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31359681491780256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31359681491780256 | validation: 0.317493193644645]
	TIME [epoch: 9.31 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3520278796972535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3520278796972535 | validation: 0.31196433134340024]
	TIME [epoch: 9.32 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38692562764529315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38692562764529315 | validation: 0.7851836685859167]
	TIME [epoch: 9.33 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8008555527520865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8008555527520865 | validation: 0.48248205347552536]
	TIME [epoch: 9.3 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.597871726566557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.597871726566557 | validation: 1.2145071552674087]
	TIME [epoch: 9.31 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8659961871689923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8659961871689923 | validation: 0.5870791580588819]
	TIME [epoch: 9.31 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.590375367223255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.590375367223255 | validation: 0.3776953815423287]
	TIME [epoch: 9.31 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39925974722227786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39925974722227786 | validation: 0.3610567539029661]
	TIME [epoch: 9.26 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8267286968035602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8267286968035602 | validation: 0.6173950525008672]
	TIME [epoch: 9.26 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49908819173390917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49908819173390917 | validation: 1.6583957329596748]
	TIME [epoch: 9.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4810798274278734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4810798274278734 | validation: 0.8724532646673624]
	TIME [epoch: 9.32 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.663648805076053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.663648805076053 | validation: 0.4840179309518553]
	TIME [epoch: 9.33 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4388060756400904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4388060756400904 | validation: 0.46716256658168054]
	TIME [epoch: 9.32 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9250323718402204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9250323718402204 | validation: 0.7021674870390475]
	TIME [epoch: 9.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4844849815060961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4844849815060961 | validation: 0.3310920098248722]
	TIME [epoch: 9.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4216580029028151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4216580029028151 | validation: 0.3200581623473658]
	TIME [epoch: 9.32 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7180468062271068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7180468062271068 | validation: 0.5146735734919731]
	TIME [epoch: 9.31 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: nan		[learning rate: 0.01]
ERROR:
nan encountered in epoch 320 (training loss).
