Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r2', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3550373882

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.802209793770842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.802209793770842 | validation: 8.315623245244428]
	TIME [epoch: 47.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.694533299234907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.694533299234907 | validation: 6.505649652745819]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.9310618845675895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9310618845675895 | validation: 5.834162440078305]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.523593610573263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.523593610573263 | validation: 5.555788325570726]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.798953375492405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.798953375492405 | validation: 4.509748110765077]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.488789693116259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.488789693116259 | validation: 4.191627143178303]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.056093026361304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.056093026361304 | validation: 4.144223721542378]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4873227029751233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4873227029751233 | validation: 3.2279316024994693]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0572705151591255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0572705151591255 | validation: 2.6174028355659016]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.511201904365664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.511201904365664 | validation: 3.0369234304199035]
	TIME [epoch: 9.09 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4149113736824495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4149113736824495 | validation: 1.796752925001527]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4689828879196454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4689828879196454 | validation: 2.743544893165101]
	TIME [epoch: 9.1 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0927537889134964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0927537889134964 | validation: 2.030798676301045]
	TIME [epoch: 9.09 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8559449331681919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8559449331681919 | validation: 1.2736676013111032]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.899524940864735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.899524940864735 | validation: 1.464108601221176]
	TIME [epoch: 9.08 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8511839883246517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8511839883246517 | validation: 1.1491995214102966]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.153852466463777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.153852466463777 | validation: 0.9450526295635351]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.248652271060265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.248652271060265 | validation: 1.0863060528375839]
	TIME [epoch: 9.08 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0867484695899925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0867484695899925 | validation: 1.0349607610321367]
	TIME [epoch: 9.08 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2776063913636473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2776063913636473 | validation: 1.0609017620589372]
	TIME [epoch: 9.1 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3468109142853573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3468109142853573 | validation: 1.5974037982238898]
	TIME [epoch: 9.09 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5909135802255983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5909135802255983 | validation: 1.2389924178014478]
	TIME [epoch: 9.08 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.316160490158786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.316160490158786 | validation: 0.823246297009146]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.669254101260557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.669254101260557 | validation: 1.7048611251184784]
	TIME [epoch: 9.09 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6466739567125175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6466739567125175 | validation: 1.5672960266838456]
	TIME [epoch: 9.11 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4725740069240634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4725740069240634 | validation: 2.270369577275225]
	TIME [epoch: 9.08 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.887995444197665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.887995444197665 | validation: 1.3703715869868098]
	TIME [epoch: 9.08 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8307607916045411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8307607916045411 | validation: 0.737536146912388]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.73328575316439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.73328575316439 | validation: 0.5730297123540044]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0337214283015757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0337214283015757 | validation: 0.9013776517552988]
	TIME [epoch: 9.08 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7231770891038123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7231770891038123 | validation: 0.9016636876603092]
	TIME [epoch: 9.07 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7403458575944845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7403458575944845 | validation: 0.5884238121692098]
	TIME [epoch: 9.07 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6605115216218913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6605115216218913 | validation: 0.577250462543263]
	TIME [epoch: 9.07 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9042266143487737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9042266143487737 | validation: 0.8202397408900421]
	TIME [epoch: 9.08 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6394391529129249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6394391529129249 | validation: 0.7428630416824655]
	TIME [epoch: 9.08 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5611484323754673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5611484323754673 | validation: 0.4363589417372483]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5049869000214304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5049869000214304 | validation: 0.5344815192075856]
	TIME [epoch: 9.09 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6754498702338647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6754498702338647 | validation: 3.912906295716855]
	TIME [epoch: 9.11 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1701796838942669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1701796838942669 | validation: 0.708337396548492]
	TIME [epoch: 9.1 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48941199596369866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48941199596369866 | validation: 0.30054848169989656]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7820304784206795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7820304784206795 | validation: 0.7681085366726155]
	TIME [epoch: 9.09 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6606586891490844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6606586891490844 | validation: 0.37283903128596135]
	TIME [epoch: 9.08 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5450657595415229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5450657595415229 | validation: 0.37166284000683103]
	TIME [epoch: 9.11 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4857908911947514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4857908911947514 | validation: 0.2879719098402132]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49505106329841686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49505106329841686 | validation: 0.37453817576923126]
	TIME [epoch: 9.08 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4881687078892657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4881687078892657 | validation: 0.5356486921424103]
	TIME [epoch: 9.08 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5049008014961945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5049008014961945 | validation: 0.6908376019539486]
	TIME [epoch: 9.08 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5173118490843719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5173118490843719 | validation: 0.2783636172745433]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4156681499056167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4156681499056167 | validation: 0.8774859332599465]
	TIME [epoch: 9.09 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4511706942032435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4511706942032435 | validation: 0.6535109864920816]
	TIME [epoch: 9.09 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.588515881627316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.588515881627316 | validation: 0.6133980851634008]
	TIME [epoch: 9.08 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5062302764277166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5062302764277166 | validation: 0.5541594462463049]
	TIME [epoch: 9.1 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3898402626444407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3898402626444407 | validation: 0.3491692670738424]
	TIME [epoch: 9.08 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5381565588522241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5381565588522241 | validation: 0.33012175174876085]
	TIME [epoch: 9.08 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4094634652905055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4094634652905055 | validation: 0.3311122067517853]
	TIME [epoch: 9.08 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4734158871238755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4734158871238755 | validation: 0.2874373439213169]
	TIME [epoch: 9.09 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34844364855635446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34844364855635446 | validation: 0.800228841034363]
	TIME [epoch: 9.1 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4498723037973432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4498723037973432 | validation: 0.17775971548956382]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4529407917013829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4529407917013829 | validation: 0.3475834705947122]
	TIME [epoch: 9.08 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6138688795071695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6138688795071695 | validation: 0.23726742583147148]
	TIME [epoch: 9.07 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40549486225794623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40549486225794623 | validation: 0.39554658592154673]
	TIME [epoch: 9.1 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5864838728029118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5864838728029118 | validation: 0.38188614579166025]
	TIME [epoch: 9.08 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43459295541225185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43459295541225185 | validation: 0.34366303509861834]
	TIME [epoch: 9.08 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3061107949652469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3061107949652469 | validation: 0.22919723921354646]
	TIME [epoch: 9.08 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43181624492267856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43181624492267856 | validation: 0.25509552164892546]
	TIME [epoch: 9.07 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3522989084714607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3522989084714607 | validation: 0.34243270353425775]
	TIME [epoch: 9.1 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39423682357591494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39423682357591494 | validation: 0.3498687916653159]
	TIME [epoch: 9.07 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46235338407191334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46235338407191334 | validation: 0.24346448693942024]
	TIME [epoch: 9.07 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36593296375526907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36593296375526907 | validation: 0.3399102994115672]
	TIME [epoch: 9.08 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30400629389537187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30400629389537187 | validation: 0.3445484666057977]
	TIME [epoch: 9.09 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5413333981022861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5413333981022861 | validation: 1.1788085360196257]
	TIME [epoch: 9.08 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7344067450893684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7344067450893684 | validation: 0.5384902292542679]
	TIME [epoch: 9.07 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7228149281798331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7228149281798331 | validation: 0.41613734472206604]
	TIME [epoch: 9.07 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.675901939419554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.675901939419554 | validation: 0.2286928882485162]
	TIME [epoch: 9.08 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4656196662258475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4656196662258475 | validation: 0.27774696307827385]
	TIME [epoch: 9.1 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46411132955193846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46411132955193846 | validation: 0.8648662043117453]
	TIME [epoch: 9.09 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6246071304038501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6246071304038501 | validation: 0.3315539323322443]
	TIME [epoch: 9.08 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5898641004671414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5898641004671414 | validation: 0.47941123361129456]
	TIME [epoch: 9.07 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40602040753488106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40602040753488106 | validation: 0.3270215977112151]
	TIME [epoch: 9.09 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43875649145229784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43875649145229784 | validation: 0.19604184233087707]
	TIME [epoch: 9.07 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33079183217833663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33079183217833663 | validation: 0.21702942426755198]
	TIME [epoch: 9.07 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4051567951016349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4051567951016349 | validation: 0.5759862604422548]
	TIME [epoch: 9.07 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33001460119289305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33001460119289305 | validation: 0.07903723737745161]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2565693609254618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2565693609254618 | validation: 0.2645323808592035]
	TIME [epoch: 9.11 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5574799838567752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5574799838567752 | validation: 0.5198491968664256]
	TIME [epoch: 9.08 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49784150512719216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49784150512719216 | validation: 0.37621360869439646]
	TIME [epoch: 9.07 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33599048686850513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33599048686850513 | validation: 0.1668837501072403]
	TIME [epoch: 9.08 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2587395617023981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2587395617023981 | validation: 0.2690536022753523]
	TIME [epoch: 9.08 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32397728632466744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32397728632466744 | validation: 0.16642418962056343]
	TIME [epoch: 9.09 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5887220158435114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5887220158435114 | validation: 0.6741234684359556]
	TIME [epoch: 9.07 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34389775020020447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34389775020020447 | validation: 0.3597476391005591]
	TIME [epoch: 9.07 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37238446422104066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37238446422104066 | validation: 0.26145002595699995]
	TIME [epoch: 9.08 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38077958118503996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38077958118503996 | validation: 0.2668345879582341]
	TIME [epoch: 9.1 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32396943888329227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32396943888329227 | validation: 0.3871937033907299]
	TIME [epoch: 9.08 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5696523637251132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5696523637251132 | validation: 0.4111317635873594]
	TIME [epoch: 9.08 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38660875355962826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38660875355962826 | validation: 0.2792262137000788]
	TIME [epoch: 9.09 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32688918136763945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32688918136763945 | validation: 0.197738588232081]
	TIME [epoch: 9.08 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3351891472012593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3351891472012593 | validation: 0.3396975131580248]
	TIME [epoch: 9.11 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39390392657625545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39390392657625545 | validation: 0.42175508890348906]
	TIME [epoch: 9.09 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3669691729514491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3669691729514491 | validation: 0.5527211016929215]
	TIME [epoch: 9.08 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42750774241240663		[learning rate: 0.0099782]
	Learning Rate: 0.00997821
	LOSS [training: 0.42750774241240663 | validation: 0.4025137817771559]
	TIME [epoch: 9.08 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2942787386581403		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 0.2942787386581403 | validation: 0.2236975536002154]
	TIME [epoch: 9.11 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42220411531346913		[learning rate: 0.00993]
	Learning Rate: 0.00992996
	LOSS [training: 0.42220411531346913 | validation: 0.526795999935529]
	TIME [epoch: 9.09 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2721211876761341		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 0.2721211876761341 | validation: 0.21720035641062763]
	TIME [epoch: 9.09 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27317065775377913		[learning rate: 0.0098819]
	Learning Rate: 0.00988194
	LOSS [training: 0.27317065775377913 | validation: 0.3677577446774998]
	TIME [epoch: 9.08 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.389617053787887		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 0.389617053787887 | validation: 0.20314327513764968]
	TIME [epoch: 9.07 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34572389187961383		[learning rate: 0.0098341]
	Learning Rate: 0.00983415
	LOSS [training: 0.34572389187961383 | validation: 0.26421640079342285]
	TIME [epoch: 9.09 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2635090993618877		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 0.2635090993618877 | validation: 0.26140594851379567]
	TIME [epoch: 9.07 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23894858766494523		[learning rate: 0.0097866]
	Learning Rate: 0.00978659
	LOSS [training: 0.23894858766494523 | validation: 0.34992633551925206]
	TIME [epoch: 9.07 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30946462210006215		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 0.30946462210006215 | validation: 0.261815363094194]
	TIME [epoch: 9.07 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25729310556343016		[learning rate: 0.0097393]
	Learning Rate: 0.00973927
	LOSS [training: 0.25729310556343016 | validation: 0.1493194950723215]
	TIME [epoch: 9.09 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30105835575047113		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 0.30105835575047113 | validation: 0.18005603725032743]
	TIME [epoch: 9.09 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25281810659819487		[learning rate: 0.0096922]
	Learning Rate: 0.00969217
	LOSS [training: 0.25281810659819487 | validation: 0.15423099659901057]
	TIME [epoch: 9.08 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24068001303155495		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 0.24068001303155495 | validation: 0.3382204165063981]
	TIME [epoch: 9.09 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2701175135789415		[learning rate: 0.0096453]
	Learning Rate: 0.0096453
	LOSS [training: 2.2701175135789415 | validation: 0.6943754577009766]
	TIME [epoch: 9.09 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3770002634319818		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 0.3770002634319818 | validation: 0.5110914413387577]
	TIME [epoch: 9.11 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5952553726270212		[learning rate: 0.0095987]
	Learning Rate: 0.00959866
	LOSS [training: 0.5952553726270212 | validation: 0.6723571021084103]
	TIME [epoch: 9.09 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38976395070909875		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 0.38976395070909875 | validation: 0.23906490597986746]
	TIME [epoch: 9.08 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3718535390373624		[learning rate: 0.0095522]
	Learning Rate: 0.00955224
	LOSS [training: 0.3718535390373624 | validation: 0.6952938027741677]
	TIME [epoch: 9.08 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38797835117641905		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 0.38797835117641905 | validation: 0.3497675816188296]
	TIME [epoch: 9.1 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2964474234371831		[learning rate: 0.009506]
	Learning Rate: 0.00950605
	LOSS [training: 0.2964474234371831 | validation: 0.2891173953073989]
	TIME [epoch: 9.09 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21508399123433314		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 0.21508399123433314 | validation: 0.22321817221898166]
	TIME [epoch: 9.08 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3241212627988778		[learning rate: 0.0094601]
	Learning Rate: 0.00946008
	LOSS [training: 0.3241212627988778 | validation: 0.24951180468706896]
	TIME [epoch: 9.07 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29075306643640786		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 0.29075306643640786 | validation: 0.398995946626882]
	TIME [epoch: 9.07 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27856013643868327		[learning rate: 0.0094143]
	Learning Rate: 0.00941433
	LOSS [training: 0.27856013643868327 | validation: 0.13190743290269819]
	TIME [epoch: 9.1 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3322647469515808		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 0.3322647469515808 | validation: 0.3842316585334631]
	TIME [epoch: 9.08 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.373937338345182		[learning rate: 0.0093688]
	Learning Rate: 0.00936881
	LOSS [training: 0.373937338345182 | validation: 0.20054544635399274]
	TIME [epoch: 9.08 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26884372179163474		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 0.26884372179163474 | validation: 0.3177536755727789]
	TIME [epoch: 9.07 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28807780136716177		[learning rate: 0.0093235]
	Learning Rate: 0.0093235
	LOSS [training: 0.28807780136716177 | validation: 0.404849134175033]
	TIME [epoch: 9.09 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32830020487047273		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 0.32830020487047273 | validation: 0.26337889615598153]
	TIME [epoch: 9.11 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28883314184182685		[learning rate: 0.0092784]
	Learning Rate: 0.00927841
	LOSS [training: 0.28883314184182685 | validation: 0.20616926777971217]
	TIME [epoch: 9.07 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.245185164857679		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 0.245185164857679 | validation: 0.18528081734715923]
	TIME [epoch: 9.08 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22696841547127405		[learning rate: 0.0092335]
	Learning Rate: 0.00923354
	LOSS [training: 0.22696841547127405 | validation: 0.29282017067708577]
	TIME [epoch: 9.07 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30496460502109		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 0.30496460502109 | validation: 0.155487442489103]
	TIME [epoch: 9.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24446396110355245		[learning rate: 0.0091889]
	Learning Rate: 0.00918889
	LOSS [training: 0.24446396110355245 | validation: 0.15543363178089276]
	TIME [epoch: 9.09 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2443191344379816		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 0.2443191344379816 | validation: 0.2656569910905171]
	TIME [epoch: 9.08 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2731370160316611		[learning rate: 0.0091445]
	Learning Rate: 0.00914446
	LOSS [training: 0.2731370160316611 | validation: 0.34664029353932546]
	TIME [epoch: 9.07 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8032564577008905		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 0.8032564577008905 | validation: 0.6962883659580973]
	TIME [epoch: 9.08 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5280961013594554		[learning rate: 0.0091002]
	Learning Rate: 0.00910024
	LOSS [training: 0.5280961013594554 | validation: 0.9861310142208584]
	TIME [epoch: 9.09 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6733644532947146		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.6733644532947146 | validation: 0.23853382559135966]
	TIME [epoch: 9.07 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36789067320584995		[learning rate: 0.0090562]
	Learning Rate: 0.00905623
	LOSS [training: 0.36789067320584995 | validation: 0.5126155077238497]
	TIME [epoch: 9.08 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4014807890332076		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 0.4014807890332076 | validation: 0.20392972012125749]
	TIME [epoch: 9.09 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2301916518005777		[learning rate: 0.0090124]
	Learning Rate: 0.00901243
	LOSS [training: 0.2301916518005777 | validation: 0.2294212133022055]
	TIME [epoch: 9.11 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25087552216478215		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 0.25087552216478215 | validation: 0.23486112516785043]
	TIME [epoch: 9.09 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22358482492779003		[learning rate: 0.0089689]
	Learning Rate: 0.00896885
	LOSS [training: 0.22358482492779003 | validation: 0.11915536443367353]
	TIME [epoch: 9.08 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18049029104124206		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 0.18049029104124206 | validation: 0.2795778897105292]
	TIME [epoch: 9.07 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24623311003422263		[learning rate: 0.0089255]
	Learning Rate: 0.00892548
	LOSS [training: 0.24623311003422263 | validation: 0.2601652745914843]
	TIME [epoch: 9.08 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.308775431761541		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 0.308775431761541 | validation: 0.12595153687568006]
	TIME [epoch: 9.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3028390055269485		[learning rate: 0.0088823]
	Learning Rate: 0.00888232
	LOSS [training: 0.3028390055269485 | validation: 0.2054997102213898]
	TIME [epoch: 9.08 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3031372372661313		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 0.3031372372661313 | validation: 0.25377938908644815]
	TIME [epoch: 9.09 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1729115642991676		[learning rate: 0.0088394]
	Learning Rate: 0.00883936
	LOSS [training: 0.1729115642991676 | validation: 0.12598354348020502]
	TIME [epoch: 9.07 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20587702174689587		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 0.20587702174689587 | validation: 0.2892544400083074]
	TIME [epoch: 9.09 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26033590059932854		[learning rate: 0.0087966]
	Learning Rate: 0.00879662
	LOSS [training: 0.26033590059932854 | validation: 0.22833308441297429]
	TIME [epoch: 9.09 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20655054713672288		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 0.20655054713672288 | validation: 0.477912292746788]
	TIME [epoch: 9.07 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22178049368056243		[learning rate: 0.0087541]
	Learning Rate: 0.00875408
	LOSS [training: 0.22178049368056243 | validation: 0.16591677458861026]
	TIME [epoch: 9.08 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17720974207426105		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 0.17720974207426105 | validation: 0.19528407302603273]
	TIME [epoch: 9.08 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3109061757970212		[learning rate: 0.0087117]
	Learning Rate: 0.00871175
	LOSS [training: 0.3109061757970212 | validation: 0.1473073218177567]
	TIME [epoch: 9.11 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1548990133128005		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 0.1548990133128005 | validation: 0.20141749121376018]
	TIME [epoch: 9.09 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4137188638132989		[learning rate: 0.0086696]
	Learning Rate: 0.00866962
	LOSS [training: 0.4137188638132989 | validation: 0.24474948023277002]
	TIME [epoch: 9.07 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23186581415219526		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.23186581415219526 | validation: 0.2060349681264453]
	TIME [epoch: 9.08 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2384206874288271		[learning rate: 0.0086277]
	Learning Rate: 0.00862769
	LOSS [training: 0.2384206874288271 | validation: 0.5542344036904611]
	TIME [epoch: 9.07 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3742551540894309		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.3742551540894309 | validation: 0.1506745385406286]
	TIME [epoch: 9.1 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1731370727846322		[learning rate: 0.008586]
	Learning Rate: 0.00858597
	LOSS [training: 0.1731370727846322 | validation: 0.3996310979832145]
	TIME [epoch: 9.07 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2166814383593089		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 0.2166814383593089 | validation: 0.20142809833434455]
	TIME [epoch: 9.08 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24264907764370358		[learning rate: 0.0085445]
	Learning Rate: 0.00854445
	LOSS [training: 0.24264907764370358 | validation: 0.11193126853008895]
	TIME [epoch: 9.09 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3019081669577949		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 0.3019081669577949 | validation: 0.2079224697506059]
	TIME [epoch: 9.08 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42908011093715503		[learning rate: 0.0085031]
	Learning Rate: 0.00850313
	LOSS [training: 0.42908011093715503 | validation: 0.20123158463426316]
	TIME [epoch: 9.09 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22002422379513925		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.22002422379513925 | validation: 0.17162848597405417]
	TIME [epoch: 9.09 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1975276995100516		[learning rate: 0.008462]
	Learning Rate: 0.00846201
	LOSS [training: 0.1975276995100516 | validation: 0.18582283691317147]
	TIME [epoch: 9.08 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21764989507360988		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 0.21764989507360988 | validation: 0.2255208325380361]
	TIME [epoch: 9.09 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19575124348744777		[learning rate: 0.0084211]
	Learning Rate: 0.00842109
	LOSS [training: 0.19575124348744777 | validation: 0.2891116029510601]
	TIME [epoch: 9.1 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31199067393669744		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 0.31199067393669744 | validation: 0.10066913595881971]
	TIME [epoch: 9.08 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.208222781977546		[learning rate: 0.0083804]
	Learning Rate: 0.00838037
	LOSS [training: 0.208222781977546 | validation: 0.15636664723066807]
	TIME [epoch: 9.09 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19078739372290726		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 0.19078739372290726 | validation: 0.23393618891595275]
	TIME [epoch: 9.08 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.271138003038944		[learning rate: 0.0083398]
	Learning Rate: 0.00833984
	LOSS [training: 0.271138003038944 | validation: 0.21263527945808663]
	TIME [epoch: 9.1 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19067042336188952		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.19067042336188952 | validation: 0.19492679099976984]
	TIME [epoch: 9.09 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2159381167294226		[learning rate: 0.0082995]
	Learning Rate: 0.00829951
	LOSS [training: 0.2159381167294226 | validation: 0.20139132053080264]
	TIME [epoch: 9.08 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.310976620989604		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.310976620989604 | validation: 0.4336940960436809]
	TIME [epoch: 9.07 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44301783300631836		[learning rate: 0.0082594]
	Learning Rate: 0.00825938
	LOSS [training: 0.44301783300631836 | validation: 0.5324161253378642]
	TIME [epoch: 9.07 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34677755251435055		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.34677755251435055 | validation: 0.46299539934861667]
	TIME [epoch: 9.1 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22099103046680643		[learning rate: 0.0082194]
	Learning Rate: 0.00821944
	LOSS [training: 0.22099103046680643 | validation: 0.14308851764486863]
	TIME [epoch: 9.09 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1322478207922645		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.1322478207922645 | validation: 0.10678647517998086]
	TIME [epoch: 9.08 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40222314779751195		[learning rate: 0.0081797]
	Learning Rate: 0.00817969
	LOSS [training: 0.40222314779751195 | validation: 0.3348347291120631]
	TIME [epoch: 9.08 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40296578409468087		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.40296578409468087 | validation: 0.23575584331543759]
	TIME [epoch: 9.09 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21000763259559432		[learning rate: 0.0081401]
	Learning Rate: 0.00814013
	LOSS [training: 0.21000763259559432 | validation: 0.17771751222519996]
	TIME [epoch: 9.09 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.274696966458166		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.274696966458166 | validation: 0.17542139271580628]
	TIME [epoch: 9.08 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2865282778168812		[learning rate: 0.0081008]
	Learning Rate: 0.00810077
	LOSS [training: 0.2865282778168812 | validation: 0.41185358963165497]
	TIME [epoch: 9.08 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35528489460833873		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.35528489460833873 | validation: 0.16583359849818685]
	TIME [epoch: 9.07 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19061590197180836		[learning rate: 0.0080616]
	Learning Rate: 0.0080616
	LOSS [training: 0.19061590197180836 | validation: 0.1314543316378487]
	TIME [epoch: 9.08 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3524144173788941		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.3524144173788941 | validation: 0.20066335171930139]
	TIME [epoch: 9.08 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1878037076412235		[learning rate: 0.0080226]
	Learning Rate: 0.00802261
	LOSS [training: 0.1878037076412235 | validation: 0.22868739321620452]
	TIME [epoch: 9.07 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3671155892872038		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.3671155892872038 | validation: 0.25201515209117314]
	TIME [epoch: 9.07 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22422803631260213		[learning rate: 0.0079838]
	Learning Rate: 0.00798382
	LOSS [training: 0.22422803631260213 | validation: 0.713126478074695]
	TIME [epoch: 9.08 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41033573599711176		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.41033573599711176 | validation: 0.14030874969425908]
	TIME [epoch: 9.11 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20591466488441953		[learning rate: 0.0079452]
	Learning Rate: 0.00794521
	LOSS [training: 0.20591466488441953 | validation: 0.16088815796555772]
	TIME [epoch: 9.09 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26032371506174234		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.26032371506174234 | validation: 0.1674097807451363]
	TIME [epoch: 9.08 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18088545973926068		[learning rate: 0.0079068]
	Learning Rate: 0.00790679
	LOSS [training: 0.18088545973926068 | validation: 0.2204209330162633]
	TIME [epoch: 9.07 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26344994675452227		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.26344994675452227 | validation: 0.5274373021993268]
	TIME [epoch: 9.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23168241193985759		[learning rate: 0.0078685]
	Learning Rate: 0.00786855
	LOSS [training: 0.23168241193985759 | validation: 0.23053363831360169]
	TIME [epoch: 9.09 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19442792564515263		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.19442792564515263 | validation: 0.20584000018146092]
	TIME [epoch: 9.08 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2649444487743507		[learning rate: 0.0078305]
	Learning Rate: 0.0078305
	LOSS [training: 0.2649444487743507 | validation: 0.16948797533190918]
	TIME [epoch: 9.08 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21310607716991595		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.21310607716991595 | validation: 0.20744619170287584]
	TIME [epoch: 9.08 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19729727007409997		[learning rate: 0.0077926]
	Learning Rate: 0.00779263
	LOSS [training: 0.19729727007409997 | validation: 0.1749050649339391]
	TIME [epoch: 9.1 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2675434866145761		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.2675434866145761 | validation: 0.16563766122300355]
	TIME [epoch: 9.1 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18642155862829807		[learning rate: 0.0077549]
	Learning Rate: 0.00775495
	LOSS [training: 0.18642155862829807 | validation: 0.18210428934774062]
	TIME [epoch: 9.08 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3565034397623189		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.3565034397623189 | validation: 0.5110543395165016]
	TIME [epoch: 9.08 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4915431759756704		[learning rate: 0.0077174]
	Learning Rate: 0.00771745
	LOSS [training: 0.4915431759756704 | validation: 0.45195969676277525]
	TIME [epoch: 9.1 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32735425055839384		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.32735425055839384 | validation: 0.10763597506379553]
	TIME [epoch: 9.1 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14947489148761517		[learning rate: 0.0076801]
	Learning Rate: 0.00768013
	LOSS [training: 0.14947489148761517 | validation: 0.2746734140608897]
	TIME [epoch: 9.1 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19435439849824682		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.19435439849824682 | validation: 0.14240189390193764]
	TIME [epoch: 9.09 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17251177045009544		[learning rate: 0.007643]
	Learning Rate: 0.00764299
	LOSS [training: 0.17251177045009544 | validation: 0.1409881910632995]
	TIME [epoch: 9.07 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2263182194841536		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.2263182194841536 | validation: 0.15978087203510333]
	TIME [epoch: 9.09 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22881242463857002		[learning rate: 0.007606]
	Learning Rate: 0.00760603
	LOSS [training: 0.22881242463857002 | validation: 0.10511255244996262]
	TIME [epoch: 9.08 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23061699924009935		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.23061699924009935 | validation: 0.25434350821797075]
	TIME [epoch: 9.08 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3051766365753478		[learning rate: 0.0075692]
	Learning Rate: 0.00756925
	LOSS [training: 0.3051766365753478 | validation: 0.15663617658781237]
	TIME [epoch: 9.08 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32009011415044425		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.32009011415044425 | validation: 0.34721223721803096]
	TIME [epoch: 9.09 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26691183122705003		[learning rate: 0.0075326]
	Learning Rate: 0.00753264
	LOSS [training: 0.26691183122705003 | validation: 0.1480491823457667]
	TIME [epoch: 9.08 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3480741893758891		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.3480741893758891 | validation: 0.19861711248215408]
	TIME [epoch: 9.08 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1936094128033979		[learning rate: 0.0074962]
	Learning Rate: 0.00749622
	LOSS [training: 0.1936094128033979 | validation: 0.1589120281783069]
	TIME [epoch: 9.07 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19320392289420113		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.19320392289420113 | validation: 0.16591351990300424]
	TIME [epoch: 9.08 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1500594564680667		[learning rate: 0.00746]
	Learning Rate: 0.00745997
	LOSS [training: 0.1500594564680667 | validation: 0.12587582377718834]
	TIME [epoch: 9.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1917552754831957		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.1917552754831957 | validation: 0.33256392187211425]
	TIME [epoch: 9.08 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2839364831802388		[learning rate: 0.0074239]
	Learning Rate: 0.00742389
	LOSS [training: 0.2839364831802388 | validation: 0.22096769587434995]
	TIME [epoch: 9.07 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35416056288569797		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.35416056288569797 | validation: 0.35376160694197745]
	TIME [epoch: 9.07 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3749170598449167		[learning rate: 0.007388]
	Learning Rate: 0.00738799
	LOSS [training: 1.3749170598449167 | validation: 1.353499929961198]
	TIME [epoch: 9.08 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5259014234701895		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.5259014234701895 | validation: 0.23909860726930326]
	TIME [epoch: 9.09 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2580696729331408		[learning rate: 0.0073523]
	Learning Rate: 0.00735226
	LOSS [training: 0.2580696729331408 | validation: 0.2507406202400819]
	TIME [epoch: 9.06 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2952347347820664		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.2952347347820664 | validation: 0.2176273810692013]
	TIME [epoch: 9.07 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.289703080989365		[learning rate: 0.0073167]
	Learning Rate: 0.00731671
	LOSS [training: 0.289703080989365 | validation: 0.1976466455121769]
	TIME [epoch: 9.07 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2127592930203997		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.2127592930203997 | validation: 0.11183626329744903]
	TIME [epoch: 9.08 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.195478985461922		[learning rate: 0.0072813]
	Learning Rate: 0.00728133
	LOSS [training: 0.195478985461922 | validation: 0.28843108539531925]
	TIME [epoch: 9.07 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29233248052493627		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.29233248052493627 | validation: 0.4335743690886231]
	TIME [epoch: 9.06 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3098541694464811		[learning rate: 0.0072461]
	Learning Rate: 0.00724612
	LOSS [training: 0.3098541694464811 | validation: 0.09983543643727247]
	TIME [epoch: 9.07 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13496275664309634		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.13496275664309634 | validation: 0.15198376756795967]
	TIME [epoch: 9.07 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20591841341716433		[learning rate: 0.0072111]
	Learning Rate: 0.00721107
	LOSS [training: 0.20591841341716433 | validation: 0.1288952666546811]
	TIME [epoch: 9.09 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2626012638311299		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.2626012638311299 | validation: 0.42080257389026055]
	TIME [epoch: 9.09 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22272703885631867		[learning rate: 0.0071762]
	Learning Rate: 0.0071762
	LOSS [training: 0.22272703885631867 | validation: 0.20082037510205858]
	TIME [epoch: 9.07 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16847152336111199		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.16847152336111199 | validation: 0.10558425025475332]
	TIME [epoch: 9.07 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28931357189383383		[learning rate: 0.0071415]
	Learning Rate: 0.0071415
	LOSS [training: 0.28931357189383383 | validation: 0.194044664700042]
	TIME [epoch: 9.09 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17949047693417058		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.17949047693417058 | validation: 0.12073204115976566]
	TIME [epoch: 9.07 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17117327891969958		[learning rate: 0.007107]
	Learning Rate: 0.00710696
	LOSS [training: 0.17117327891969958 | validation: 0.36377303638772485]
	TIME [epoch: 9.07 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14857128507830053		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.14857128507830053 | validation: 0.1435099142740236]
	TIME [epoch: 9.07 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3132480492918133		[learning rate: 0.0070726]
	Learning Rate: 0.0070726
	LOSS [training: 0.3132480492918133 | validation: 0.23806170918121286]
	TIME [epoch: 9.07 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2542175976340233		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.2542175976340233 | validation: 0.12550196428383914]
	TIME [epoch: 9.09 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14037320067028825		[learning rate: 0.0070384]
	Learning Rate: 0.0070384
	LOSS [training: 0.14037320067028825 | validation: 0.21306169037874326]
	TIME [epoch: 9.07 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24890507262982492		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.24890507262982492 | validation: 0.10074642329428041]
	TIME [epoch: 9.07 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18556385323468005		[learning rate: 0.0070044]
	Learning Rate: 0.00700436
	LOSS [training: 0.18556385323468005 | validation: 0.18585343880214483]
	TIME [epoch: 9.08 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26090723290358964		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.26090723290358964 | validation: 0.19186511655596758]
	TIME [epoch: 9.07 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28184090301579534		[learning rate: 0.0069705]
	Learning Rate: 0.00697049
	LOSS [training: 0.28184090301579534 | validation: 0.3606579519987699]
	TIME [epoch: 9.1 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4277112024162707		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.4277112024162707 | validation: 0.24377083541341893]
	TIME [epoch: 9.07 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25644875314579296		[learning rate: 0.0069368]
	Learning Rate: 0.00693678
	LOSS [training: 0.25644875314579296 | validation: 0.14778649940554778]
	TIME [epoch: 9.07 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3494122540493232		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.3494122540493232 | validation: 0.3664743850311196]
	TIME [epoch: 9.06 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45974761847159895		[learning rate: 0.0069032]
	Learning Rate: 0.00690323
	LOSS [training: 0.45974761847159895 | validation: 0.22749640666023857]
	TIME [epoch: 9.09 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13194303398028925		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.13194303398028925 | validation: 0.09733729865190952]
	TIME [epoch: 9.07 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14330882658458896		[learning rate: 0.0068699]
	Learning Rate: 0.00686985
	LOSS [training: 0.14330882658458896 | validation: 0.12298472029730978]
	TIME [epoch: 9.07 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12970329524933685		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.12970329524933685 | validation: 0.12762797908247744]
	TIME [epoch: 9.07 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17409431949276488		[learning rate: 0.0068366]
	Learning Rate: 0.00683663
	LOSS [training: 0.17409431949276488 | validation: 0.2945438912746011]
	TIME [epoch: 9.07 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20036044801005864		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.20036044801005864 | validation: 0.10261363281918172]
	TIME [epoch: 9.09 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12285722226473668		[learning rate: 0.0068036]
	Learning Rate: 0.00680357
	LOSS [training: 0.12285722226473668 | validation: 0.14817807369111258]
	TIME [epoch: 9.08 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14134641414956597		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.14134641414956597 | validation: 0.15475350117880016]
	TIME [epoch: 9.08 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14955531296050223		[learning rate: 0.0067707]
	Learning Rate: 0.00677067
	LOSS [training: 0.14955531296050223 | validation: 0.2806055689347272]
	TIME [epoch: 9.08 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21375629588045464		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.21375629588045464 | validation: 0.14595560111118094]
	TIME [epoch: 9.1 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25452525567618606		[learning rate: 0.0067379]
	Learning Rate: 0.00673793
	LOSS [training: 0.25452525567618606 | validation: 0.647084038085247]
	TIME [epoch: 9.08 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9337634720250044		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.9337634720250044 | validation: 0.5277507583454]
	TIME [epoch: 9.08 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2887506445667639		[learning rate: 0.0067053]
	Learning Rate: 0.00670534
	LOSS [training: 0.2887506445667639 | validation: 0.2195512139712838]
	TIME [epoch: 9.07 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2721004209392656		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.2721004209392656 | validation: 0.3692692803598681]
	TIME [epoch: 9.07 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2997804686954241		[learning rate: 0.0066729]
	Learning Rate: 0.00667292
	LOSS [training: 0.2997804686954241 | validation: 0.16840953199191397]
	TIME [epoch: 9.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18681199027075818		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.18681199027075818 | validation: 0.18946151056231364]
	TIME [epoch: 9.08 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1474823962271407		[learning rate: 0.0066406]
	Learning Rate: 0.00664065
	LOSS [training: 0.1474823962271407 | validation: 0.12338086385702104]
	TIME [epoch: 9.08 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15494796070124495		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.15494796070124495 | validation: 0.1237152986246311]
	TIME [epoch: 9.08 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1304472691843765		[learning rate: 0.0066085]
	Learning Rate: 0.00660854
	LOSS [training: 0.1304472691843765 | validation: 0.1680852034640123]
	TIME [epoch: 9.08 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24175920023037292		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.24175920023037292 | validation: 0.10360621468625567]
	TIME [epoch: 9.09 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13702254910985803		[learning rate: 0.0065766]
	Learning Rate: 0.00657658
	LOSS [training: 0.13702254910985803 | validation: 0.13147656053784412]
	TIME [epoch: 9.08 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22195340910874206		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.22195340910874206 | validation: 0.1812181205422459]
	TIME [epoch: 9.08 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15609125920076367		[learning rate: 0.0065448]
	Learning Rate: 0.00654477
	LOSS [training: 0.15609125920076367 | validation: 0.13769752157190507]
	TIME [epoch: 9.09 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3668705275260954		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.3668705275260954 | validation: 0.759352286275909]
	TIME [epoch: 9.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.575245435496754		[learning rate: 0.0065131]
	Learning Rate: 0.00651313
	LOSS [training: 0.575245435496754 | validation: 0.5084266285963082]
	TIME [epoch: 9.08 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37701221608962643		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.37701221608962643 | validation: 0.21354065471641248]
	TIME [epoch: 9.07 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37068996788516706		[learning rate: 0.0064816]
	Learning Rate: 0.00648163
	LOSS [training: 0.37068996788516706 | validation: 0.7730129531015069]
	TIME [epoch: 9.08 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4642897399582117		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.4642897399582117 | validation: 0.12948963120311793]
	TIME [epoch: 9.08 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16535738417392926		[learning rate: 0.0064503]
	Learning Rate: 0.00645029
	LOSS [training: 0.16535738417392926 | validation: 0.07616445953793546]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_281.pth
	Model improved!!!
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7665553962758431		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.7665553962758431 | validation: 0.31705621031442066]
	TIME [epoch: 9.07 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4410089611040939		[learning rate: 0.0064191]
	Learning Rate: 0.00641909
	LOSS [training: 0.4410089611040939 | validation: 0.2148931631405018]
	TIME [epoch: 9.05 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21402959221440293		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.21402959221440293 | validation: 0.1684162238022403]
	TIME [epoch: 9.06 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17190132218077628		[learning rate: 0.0063881]
	Learning Rate: 0.00638805
	LOSS [training: 0.17190132218077628 | validation: 0.17940255843915437]
	TIME [epoch: 9.08 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18900156145847982		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.18900156145847982 | validation: 0.2282918926929501]
	TIME [epoch: 9.06 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24267778790085778		[learning rate: 0.0063572]
	Learning Rate: 0.00635716
	LOSS [training: 0.24267778790085778 | validation: 0.26055505396114315]
	TIME [epoch: 9.07 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5925741656534275		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.5925741656534275 | validation: 0.4297863051214487]
	TIME [epoch: 9.06 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3823122190849441		[learning rate: 0.0063264]
	Learning Rate: 0.00632642
	LOSS [training: 0.3823122190849441 | validation: 0.18795023186103776]
	TIME [epoch: 9.06 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20591881338860887		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.20591881338860887 | validation: 0.21352969535211277]
	TIME [epoch: 9.08 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17771589335100757		[learning rate: 0.0062958]
	Learning Rate: 0.00629582
	LOSS [training: 0.17771589335100757 | validation: 0.11042481065020787]
	TIME [epoch: 9.06 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19508592659356952		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.19508592659356952 | validation: 0.20068599768900958]
	TIME [epoch: 9.06 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30500440792347033		[learning rate: 0.0062654]
	Learning Rate: 0.00626538
	LOSS [training: 0.30500440792347033 | validation: 0.32298516674551764]
	TIME [epoch: 9.05 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23893992186645016		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.23893992186645016 | validation: 0.16571887851062034]
	TIME [epoch: 9.08 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14997255365013387		[learning rate: 0.0062351]
	Learning Rate: 0.00623508
	LOSS [training: 0.14997255365013387 | validation: 0.15140831214153347]
	TIME [epoch: 9.06 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18257349116408764		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.18257349116408764 | validation: 0.1085592429019668]
	TIME [epoch: 9.06 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11951006722246475		[learning rate: 0.0062049]
	Learning Rate: 0.00620493
	LOSS [training: 0.11951006722246475 | validation: 0.14461476637415055]
	TIME [epoch: 9.06 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1837690906846657		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.1837690906846657 | validation: 0.16865414796817907]
	TIME [epoch: 9.06 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.212674909853399		[learning rate: 0.0061749]
	Learning Rate: 0.00617492
	LOSS [training: 0.212674909853399 | validation: 0.17611892549785307]
	TIME [epoch: 9.08 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15690455658821462		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.15690455658821462 | validation: 0.24130682572718543]
	TIME [epoch: 9.07 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25537493973674974		[learning rate: 0.0061451]
	Learning Rate: 0.00614506
	LOSS [training: 0.25537493973674974 | validation: 0.19100618812850817]
	TIME [epoch: 9.06 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2066571165601696		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.2066571165601696 | validation: 0.23734464780003128]
	TIME [epoch: 9.07 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19653405251493122		[learning rate: 0.0061153]
	Learning Rate: 0.00611535
	LOSS [training: 0.19653405251493122 | validation: 0.14805451486730276]
	TIME [epoch: 9.06 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1742808908903128		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.1742808908903128 | validation: 0.18285634916509586]
	TIME [epoch: 9.08 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28221460197373166		[learning rate: 0.0060858]
	Learning Rate: 0.00608577
	LOSS [training: 0.28221460197373166 | validation: 0.2655201930719572]
	TIME [epoch: 9.06 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16824081749273384		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.16824081749273384 | validation: 0.12286277171072674]
	TIME [epoch: 9.05 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1483243502645219		[learning rate: 0.0060563]
	Learning Rate: 0.00605634
	LOSS [training: 0.1483243502645219 | validation: 0.11710214688486759]
	TIME [epoch: 9.06 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15226386470952127		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.15226386470952127 | validation: 0.11623711496438255]
	TIME [epoch: 9.08 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15913461335331647		[learning rate: 0.0060271]
	Learning Rate: 0.00602706
	LOSS [training: 0.15913461335331647 | validation: 0.30027514554091683]
	TIME [epoch: 9.06 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19911140895909962		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.19911140895909962 | validation: 0.14983478365810166]
	TIME [epoch: 9.06 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18058793651290705		[learning rate: 0.0059979]
	Learning Rate: 0.00599791
	LOSS [training: 0.18058793651290705 | validation: 0.12493710474194358]
	TIME [epoch: 9.06 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16153545670273012		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.16153545670273012 | validation: 0.24370287304447158]
	TIME [epoch: 9.06 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19928886438020754		[learning rate: 0.0059689]
	Learning Rate: 0.00596891
	LOSS [training: 0.19928886438020754 | validation: 0.11517765169874215]
	TIME [epoch: 9.09 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23411759299530704		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.23411759299530704 | validation: 0.22567423909378737]
	TIME [epoch: 9.06 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1721936721110154		[learning rate: 0.00594]
	Learning Rate: 0.00594004
	LOSS [training: 0.1721936721110154 | validation: 0.09371904568931172]
	TIME [epoch: 9.06 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13798507917447286		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.13798507917447286 | validation: 0.1425424481382327]
	TIME [epoch: 9.05 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16230816951721422		[learning rate: 0.0059113]
	Learning Rate: 0.00591132
	LOSS [training: 0.16230816951721422 | validation: 0.10806417633698315]
	TIME [epoch: 9.07 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12904738579072864		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.12904738579072864 | validation: 0.1642638160915006]
	TIME [epoch: 9.05 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14506052159296268		[learning rate: 0.0058827]
	Learning Rate: 0.00588273
	LOSS [training: 0.14506052159296268 | validation: 0.1964232848336103]
	TIME [epoch: 9.04 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2528751523562582		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.2528751523562582 | validation: 0.1730134904701009]
	TIME [epoch: 9.06 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.138191462050081		[learning rate: 0.0058543]
	Learning Rate: 0.00585428
	LOSS [training: 0.138191462050081 | validation: 0.09385874761439898]
	TIME [epoch: 9.05 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1239206037548424		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.1239206037548424 | validation: 0.09650996075512647]
	TIME [epoch: 9.07 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12290461008365731		[learning rate: 0.005826]
	Learning Rate: 0.00582597
	LOSS [training: 0.12290461008365731 | validation: 0.23047276836869768]
	TIME [epoch: 9.06 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23010059035798608		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.23010059035798608 | validation: 0.18889059847721001]
	TIME [epoch: 9.05 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21648757762274135		[learning rate: 0.0057978]
	Learning Rate: 0.0057978
	LOSS [training: 0.21648757762274135 | validation: 0.258642514608333]
	TIME [epoch: 9.05 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17200277317064125		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.17200277317064125 | validation: 0.19708430104848818]
	TIME [epoch: 9.07 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14502420239745656		[learning rate: 0.0057698]
	Learning Rate: 0.00576976
	LOSS [training: 0.14502420239745656 | validation: 0.11960862828537053]
	TIME [epoch: 9.06 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30689463700033526		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.30689463700033526 | validation: 0.20639581154268632]
	TIME [epoch: 9.05 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3354605306037908		[learning rate: 0.0057419]
	Learning Rate: 0.00574186
	LOSS [training: 0.3354605306037908 | validation: 0.2854981335207494]
	TIME [epoch: 9.05 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1929846236206624		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.1929846236206624 | validation: 0.18446694603577948]
	TIME [epoch: 9.05 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16045520236738253		[learning rate: 0.0057141]
	Learning Rate: 0.00571409
	LOSS [training: 0.16045520236738253 | validation: 0.11403893180977766]
	TIME [epoch: 9.06 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19503919757717136		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.19503919757717136 | validation: 0.15002840794738076]
	TIME [epoch: 9.05 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.189490013983118		[learning rate: 0.0056865]
	Learning Rate: 0.00568646
	LOSS [training: 0.189490013983118 | validation: 0.14913358960456571]
	TIME [epoch: 9.05 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2744086980527075		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.2744086980527075 | validation: 0.18505743364192362]
	TIME [epoch: 9.05 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35343453451542933		[learning rate: 0.005659]
	Learning Rate: 0.00565896
	LOSS [training: 0.35343453451542933 | validation: 0.19454791203845984]
	TIME [epoch: 9.06 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4690578466787542		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.4690578466787542 | validation: 0.7432079244987966]
	TIME [epoch: 9.06 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7330773641897546		[learning rate: 0.0056316]
	Learning Rate: 0.0056316
	LOSS [training: 0.7330773641897546 | validation: 0.3485287544311631]
	TIME [epoch: 9.06 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2700991708043263		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.2700991708043263 | validation: 0.13824068697009959]
	TIME [epoch: 9.05 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4765801475783686		[learning rate: 0.0056044]
	Learning Rate: 0.00560436
	LOSS [training: 0.4765801475783686 | validation: 0.444904917942028]
	TIME [epoch: 9.05 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30450230906129777		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.30450230906129777 | validation: 0.21787694799215934]
	TIME [epoch: 9.08 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19642351593984586		[learning rate: 0.0055773]
	Learning Rate: 0.00557726
	LOSS [training: 0.19642351593984586 | validation: 0.14414420483029522]
	TIME [epoch: 9.06 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31118849879195043		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.31118849879195043 | validation: 0.20868756616852563]
	TIME [epoch: 9.06 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1538498449061737		[learning rate: 0.0055503]
	Learning Rate: 0.00555029
	LOSS [training: 0.1538498449061737 | validation: 0.19078862594379803]
	TIME [epoch: 9.05 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14761622599240937		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.14761622599240937 | validation: 0.2549008908304185]
	TIME [epoch: 9.05 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5687383635448555		[learning rate: 0.0055235]
	Learning Rate: 0.00552345
	LOSS [training: 0.5687383635448555 | validation: 0.5240783923861253]
	TIME [epoch: 9.07 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5085198415074236		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.5085198415074236 | validation: 0.1737803692358093]
	TIME [epoch: 9.05 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17707974883880465		[learning rate: 0.0054967]
	Learning Rate: 0.00549674
	LOSS [training: 0.17707974883880465 | validation: 0.16773611547121142]
	TIME [epoch: 9.05 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20445870195171517		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.20445870195171517 | validation: 0.15009919137126926]
	TIME [epoch: 9.05 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1564723912958345		[learning rate: 0.0054702]
	Learning Rate: 0.00547016
	LOSS [training: 0.1564723912958345 | validation: 0.7113186490149969]
	TIME [epoch: 9.07 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3168388378005317		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.3168388378005317 | validation: 0.20710470757474886]
	TIME [epoch: 9.06 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20610469594559336		[learning rate: 0.0054437]
	Learning Rate: 0.00544371
	LOSS [training: 0.20610469594559336 | validation: 0.14363274477254592]
	TIME [epoch: 9.05 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15030385370900184		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.15030385370900184 | validation: 0.23311119088427806]
	TIME [epoch: 9.05 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15336085974918268		[learning rate: 0.0054174]
	Learning Rate: 0.00541738
	LOSS [training: 0.15336085974918268 | validation: 0.14984613952001752]
	TIME [epoch: 9.06 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17437418920958256		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.17437418920958256 | validation: 0.18119076986959842]
	TIME [epoch: 9.07 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17095434890271005		[learning rate: 0.0053912]
	Learning Rate: 0.00539118
	LOSS [training: 0.17095434890271005 | validation: 0.11234272768506388]
	TIME [epoch: 9.07 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11068748800057464		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.11068748800057464 | validation: 0.09249173692486756]
	TIME [epoch: 9.05 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15086201363610097		[learning rate: 0.0053651]
	Learning Rate: 0.00536511
	LOSS [training: 0.15086201363610097 | validation: 0.1424612430757296]
	TIME [epoch: 9.05 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18566458698859947		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.18566458698859947 | validation: 0.12451762468530861]
	TIME [epoch: 9.06 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12173631796803693		[learning rate: 0.0053392]
	Learning Rate: 0.00533917
	LOSS [training: 0.12173631796803693 | validation: 0.12777856725263775]
	TIME [epoch: 9.06 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13190158600343457		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.13190158600343457 | validation: 0.11008216768076304]
	TIME [epoch: 9.06 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12679311766528562		[learning rate: 0.0053133]
	Learning Rate: 0.00531335
	LOSS [training: 0.12679311766528562 | validation: 0.14082057699821593]
	TIME [epoch: 9.06 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11985139034698408		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.11985139034698408 | validation: 0.10857593696415366]
	TIME [epoch: 9.06 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16020168396409923		[learning rate: 0.0052877]
	Learning Rate: 0.00528766
	LOSS [training: 0.16020168396409923 | validation: 0.27903549111229514]
	TIME [epoch: 9.07 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24688029639086423		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.24688029639086423 | validation: 0.17071205104476342]
	TIME [epoch: 9.06 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14910320274713315		[learning rate: 0.0052621]
	Learning Rate: 0.00526209
	LOSS [training: 0.14910320274713315 | validation: 0.1409492532298972]
	TIME [epoch: 9.06 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23677176627330287		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.23677176627330287 | validation: 0.1842336672080978]
	TIME [epoch: 9.06 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15826938968978937		[learning rate: 0.0052366]
	Learning Rate: 0.00523664
	LOSS [training: 0.15826938968978937 | validation: 0.1247654538350968]
	TIME [epoch: 9.06 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15636828095983743		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.15636828095983743 | validation: 0.2402351648210747]
	TIME [epoch: 9.08 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.158949941375093		[learning rate: 0.0052113]
	Learning Rate: 0.00521132
	LOSS [training: 0.158949941375093 | validation: 0.15982625957748237]
	TIME [epoch: 9.05 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13488482973470614		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.13488482973470614 | validation: 0.15979761183896724]
	TIME [epoch: 9.06 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14655764175555835		[learning rate: 0.0051861]
	Learning Rate: 0.00518611
	LOSS [training: 0.14655764175555835 | validation: 0.12904326053972073]
	TIME [epoch: 9.06 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13727765685741503		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.13727765685741503 | validation: 0.111690379121278]
	TIME [epoch: 9.07 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1240019045675762		[learning rate: 0.005161]
	Learning Rate: 0.00516104
	LOSS [training: 0.1240019045675762 | validation: 0.19645655155451625]
	TIME [epoch: 9.07 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17475295806279445		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.17475295806279445 | validation: 0.0705177055071777]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13866353470550571		[learning rate: 0.0051361]
	Learning Rate: 0.00513608
	LOSS [training: 0.13866353470550571 | validation: 0.08004394877937532]
	TIME [epoch: 9.06 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11483275671588263		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.11483275671588263 | validation: 0.07657596214397425]
	TIME [epoch: 9.05 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09825217049656726		[learning rate: 0.0051112]
	Learning Rate: 0.00511124
	LOSS [training: 0.09825217049656726 | validation: 0.1339749084120912]
	TIME [epoch: 9.07 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.142154562934011		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.142154562934011 | validation: 0.13857566877968752]
	TIME [epoch: 9.05 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1571523245878283		[learning rate: 0.0050865]
	Learning Rate: 0.00508652
	LOSS [training: 0.1571523245878283 | validation: 0.09821707300534593]
	TIME [epoch: 9.06 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12163591178498478		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.12163591178498478 | validation: 0.1048458741815365]
	TIME [epoch: 9.06 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13422116183118538		[learning rate: 0.0050619]
	Learning Rate: 0.00506193
	LOSS [training: 0.13422116183118538 | validation: 0.11200034435744693]
	TIME [epoch: 9.08 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11733534426558909		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.11733534426558909 | validation: 0.1389836266203587]
	TIME [epoch: 9.05 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12476372823634792		[learning rate: 0.0050374]
	Learning Rate: 0.00503745
	LOSS [training: 0.12476372823634792 | validation: 0.09484719743040992]
	TIME [epoch: 9.05 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11811064664843932		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.11811064664843932 | validation: 0.14674580345888252]
	TIME [epoch: 9.05 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15000469948476078		[learning rate: 0.0050131]
	Learning Rate: 0.00501309
	LOSS [training: 0.15000469948476078 | validation: 0.2556224433506731]
	TIME [epoch: 9.05 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14582560434341327		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.14582560434341327 | validation: 0.1420045853685018]
	TIME [epoch: 9.08 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12570617119208696		[learning rate: 0.0049888]
	Learning Rate: 0.00498884
	LOSS [training: 0.12570617119208696 | validation: 0.08649251338282377]
	TIME [epoch: 9.05 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12306149731931197		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.12306149731931197 | validation: 0.1197139715932958]
	TIME [epoch: 9.04 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31006912989342295		[learning rate: 0.0049647]
	Learning Rate: 0.00496472
	LOSS [training: 0.31006912989342295 | validation: 0.1920115183556733]
	TIME [epoch: 9.04 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17246909883004474		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.17246909883004474 | validation: 0.2648771596934034]
	TIME [epoch: 9.06 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23104906694853738		[learning rate: 0.0049407]
	Learning Rate: 0.00494071
	LOSS [training: 0.23104906694853738 | validation: 0.27877050393875813]
	TIME [epoch: 9.06 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2798307834542313		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.2798307834542313 | validation: 0.25212111014904715]
	TIME [epoch: 9.05 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28047053141208		[learning rate: 0.0049168]
	Learning Rate: 0.00491682
	LOSS [training: 0.28047053141208 | validation: 0.20666819060295627]
	TIME [epoch: 9.05 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30818289579543384		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.30818289579543384 | validation: 0.1880602374067027]
	TIME [epoch: 9.04 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20241250095520852		[learning rate: 0.004893]
	Learning Rate: 0.00489304
	LOSS [training: 0.20241250095520852 | validation: 0.1898963230637258]
	TIME [epoch: 9.07 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19985852364133666		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.19985852364133666 | validation: 0.12431884675057918]
	TIME [epoch: 9.05 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1327205223978834		[learning rate: 0.0048694]
	Learning Rate: 0.00486938
	LOSS [training: 0.1327205223978834 | validation: 0.1286418745845363]
	TIME [epoch: 9.04 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13496790574247275		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.13496790574247275 | validation: 0.09813896020859177]
	TIME [epoch: 9.05 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12351121136701385		[learning rate: 0.0048458]
	Learning Rate: 0.00484583
	LOSS [training: 0.12351121136701385 | validation: 0.11213689690748713]
	TIME [epoch: 9.05 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12410250284894934		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.12410250284894934 | validation: 0.10362138761797454]
	TIME [epoch: 9.07 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1643007368773946		[learning rate: 0.0048224]
	Learning Rate: 0.0048224
	LOSS [training: 0.1643007368773946 | validation: 0.09841107209875333]
	TIME [epoch: 9.06 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15831130857062328		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.15831130857062328 | validation: 0.0950661241597221]
	TIME [epoch: 9.05 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16253557453950732		[learning rate: 0.0047991]
	Learning Rate: 0.00479908
	LOSS [training: 0.16253557453950732 | validation: 0.24934406891135438]
	TIME [epoch: 9.05 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39047210206186056		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.39047210206186056 | validation: 0.1776848952275119]
	TIME [epoch: 9.06 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1772469360659636		[learning rate: 0.0047759]
	Learning Rate: 0.00477587
	LOSS [training: 0.1772469360659636 | validation: 0.21759595205448123]
	TIME [epoch: 9.05 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24011337301905047		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.24011337301905047 | validation: 0.20440843578896883]
	TIME [epoch: 9.06 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22558787771644573		[learning rate: 0.0047528]
	Learning Rate: 0.00475278
	LOSS [training: 0.22558787771644573 | validation: 0.14684554511172204]
	TIME [epoch: 9.06 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18867361174587194		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.18867361174587194 | validation: 0.11570761252687634]
	TIME [epoch: 9.06 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16056565980189036		[learning rate: 0.0047298]
	Learning Rate: 0.00472979
	LOSS [training: 0.16056565980189036 | validation: 0.12116944214541864]
	TIME [epoch: 9.07 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1238490219984163		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.1238490219984163 | validation: 0.07672978624371493]
	TIME [epoch: 9.05 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09808190656376453		[learning rate: 0.0047069]
	Learning Rate: 0.00470692
	LOSS [training: 0.09808190656376453 | validation: 0.14491249534743317]
	TIME [epoch: 9.05 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12729277504378111		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.12729277504378111 | validation: 0.10989042885147815]
	TIME [epoch: 9.05 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13739104233203073		[learning rate: 0.0046842]
	Learning Rate: 0.00468416
	LOSS [training: 0.13739104233203073 | validation: 0.11489594645491422]
	TIME [epoch: 9.07 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18229290526264935		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.18229290526264935 | validation: 0.1525818053036591]
	TIME [epoch: 9.05 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13522492706548522		[learning rate: 0.0046615]
	Learning Rate: 0.00466151
	LOSS [training: 0.13522492706548522 | validation: 0.12702493850954238]
	TIME [epoch: 9.05 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15093338612537846		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.15093338612537846 | validation: 0.18005934261166356]
	TIME [epoch: 9.05 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15940167668155703		[learning rate: 0.004639]
	Learning Rate: 0.00463896
	LOSS [training: 0.15940167668155703 | validation: 0.12919175639720173]
	TIME [epoch: 9.05 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1659062405319985		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.1659062405319985 | validation: 0.16078586841883624]
	TIME [epoch: 9.07 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1682575516244888		[learning rate: 0.0046165]
	Learning Rate: 0.00461653
	LOSS [training: 0.1682575516244888 | validation: 0.1903290620396173]
	TIME [epoch: 9.06 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14271400012485944		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.14271400012485944 | validation: 0.1062858552752575]
	TIME [epoch: 9.06 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15056367406968563		[learning rate: 0.0045942]
	Learning Rate: 0.00459421
	LOSS [training: 0.15056367406968563 | validation: 0.130833967741493]
	TIME [epoch: 9.06 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12574726612903897		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.12574726612903897 | validation: 0.09034894318533243]
	TIME [epoch: 9.05 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12680185508894676		[learning rate: 0.004572]
	Learning Rate: 0.00457199
	LOSS [training: 0.12680185508894676 | validation: 0.10549557551730297]
	TIME [epoch: 9.07 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14639451894320016		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.14639451894320016 | validation: 0.14450916734600705]
	TIME [epoch: 9.05 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.175794683323105		[learning rate: 0.0045499]
	Learning Rate: 0.00454988
	LOSS [training: 0.175794683323105 | validation: 0.07059634914674454]
	TIME [epoch: 9.05 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1212503070307663		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.1212503070307663 | validation: 0.09924738313350465]
	TIME [epoch: 9.05 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13210241250556023		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.13210241250556023 | validation: 0.16683155742188754]
	TIME [epoch: 9.06 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19165244409732202		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.19165244409732202 | validation: 0.12251353892047996]
	TIME [epoch: 9.05 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15550852503248264		[learning rate: 0.004506]
	Learning Rate: 0.00450598
	LOSS [training: 0.15550852503248264 | validation: 0.12699954425395196]
	TIME [epoch: 9.05 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14288360114272702		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.14288360114272702 | validation: 0.1371650080133966]
	TIME [epoch: 9.04 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14651346724941852		[learning rate: 0.0044842]
	Learning Rate: 0.00448419
	LOSS [training: 0.14651346724941852 | validation: 0.09657775821191705]
	TIME [epoch: 9.05 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16258593079526915		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.16258593079526915 | validation: 0.11024777365534078]
	TIME [epoch: 9.07 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11938370232927162		[learning rate: 0.0044625]
	Learning Rate: 0.00446251
	LOSS [training: 0.11938370232927162 | validation: 0.1729553271384794]
	TIME [epoch: 9.06 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17192249975102608		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.17192249975102608 | validation: 0.11437208764327904]
	TIME [epoch: 9.05 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21906554024290728		[learning rate: 0.0044409]
	Learning Rate: 0.00444093
	LOSS [training: 0.21906554024290728 | validation: 0.222396139540127]
	TIME [epoch: 9.04 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18042676797453205		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.18042676797453205 | validation: 0.21773513650966086]
	TIME [epoch: 9.07 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19879737461810226		[learning rate: 0.0044195]
	Learning Rate: 0.00441945
	LOSS [training: 0.19879737461810226 | validation: 0.18409125005380567]
	TIME [epoch: 9.05 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.155072547638114		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.155072547638114 | validation: 0.24862817321349495]
	TIME [epoch: 9.05 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12439716074533191		[learning rate: 0.0043981]
	Learning Rate: 0.00439808
	LOSS [training: 0.12439716074533191 | validation: 0.109446789249913]
	TIME [epoch: 9.05 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09007447510425212		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.09007447510425212 | validation: 0.08234940483054068]
	TIME [epoch: 9.05 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11705795293874717		[learning rate: 0.0043768]
	Learning Rate: 0.00437681
	LOSS [training: 0.11705795293874717 | validation: 0.08073913602679587]
	TIME [epoch: 9.07 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14956891792674815		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.14956891792674815 | validation: 0.08090651348761503]
	TIME [epoch: 9.05 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1075434585593709		[learning rate: 0.0043556]
	Learning Rate: 0.00435565
	LOSS [training: 0.1075434585593709 | validation: 0.06205142712116986]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_443.pth
	Model improved!!!
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14175987506624904		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.14175987506624904 | validation: 0.099263438260865]
	TIME [epoch: 9.05 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12942031240583604		[learning rate: 0.0043346]
	Learning Rate: 0.00433458
	LOSS [training: 0.12942031240583604 | validation: 0.12536424152262743]
	TIME [epoch: 9.06 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1497555877222454		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.1497555877222454 | validation: 0.1438837834488485]
	TIME [epoch: 9.07 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2018285190850711		[learning rate: 0.0043136]
	Learning Rate: 0.00431362
	LOSS [training: 0.2018285190850711 | validation: 0.11622773600202546]
	TIME [epoch: 9.05 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14149391239385722		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.14149391239385722 | validation: 0.22256409473645877]
	TIME [epoch: 9.04 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17612625818328428		[learning rate: 0.0042928]
	Learning Rate: 0.00429276
	LOSS [training: 0.17612625818328428 | validation: 0.10044682063277949]
	TIME [epoch: 9.04 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12595413149177787		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.12595413149177787 | validation: 0.13253612764597048]
	TIME [epoch: 9.05 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13144923388259705		[learning rate: 0.004272]
	Learning Rate: 0.004272
	LOSS [training: 0.13144923388259705 | validation: 0.099164054798248]
	TIME [epoch: 9.04 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12266972657746958		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.12266972657746958 | validation: 0.06652542042946259]
	TIME [epoch: 9.05 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13133402960925236		[learning rate: 0.0042513]
	Learning Rate: 0.00425134
	LOSS [training: 0.13133402960925236 | validation: 0.11762659120485823]
	TIME [epoch: 9.05 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11536140991470349		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.11536140991470349 | validation: 0.0723268069545546]
	TIME [epoch: 9.05 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11214447887179416		[learning rate: 0.0042308]
	Learning Rate: 0.00423079
	LOSS [training: 0.11214447887179416 | validation: 0.10289269864538311]
	TIME [epoch: 9.06 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12879469809399716		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.12879469809399716 | validation: 0.13143776996630827]
	TIME [epoch: 9.05 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13940592879392705		[learning rate: 0.0042103]
	Learning Rate: 0.00421033
	LOSS [training: 0.13940592879392705 | validation: 0.08671320341911723]
	TIME [epoch: 9.04 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13225131209455818		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.13225131209455818 | validation: 0.10931187583201343]
	TIME [epoch: 9.04 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16833371177143486		[learning rate: 0.00419]
	Learning Rate: 0.00418997
	LOSS [training: 0.16833371177143486 | validation: 0.12432919306483292]
	TIME [epoch: 9.06 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1407350501281775		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.1407350501281775 | validation: 0.07622006675964654]
	TIME [epoch: 9.05 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10673990295977945		[learning rate: 0.0041697]
	Learning Rate: 0.0041697
	LOSS [training: 0.10673990295977945 | validation: 0.10986087196736602]
	TIME [epoch: 9.05 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11314056643251988		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.11314056643251988 | validation: 0.13453660774425322]
	TIME [epoch: 9.04 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10413435257488239		[learning rate: 0.0041495]
	Learning Rate: 0.00414954
	LOSS [training: 0.10413435257488239 | validation: 0.09093478180205722]
	TIME [epoch: 9.04 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11445320578725451		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.11445320578725451 | validation: 0.06066131123206985]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_464.pth
	Model improved!!!
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10159369694744666		[learning rate: 0.0041295]
	Learning Rate: 0.00412947
	LOSS [training: 0.10159369694744666 | validation: 0.12479669562600056]
	TIME [epoch: 9.06 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1584287431247036		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.1584287431247036 | validation: 0.2220729161846962]
	TIME [epoch: 9.06 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3825321342446707		[learning rate: 0.0041095]
	Learning Rate: 0.0041095
	LOSS [training: 0.3825321342446707 | validation: 0.2052518904628745]
	TIME [epoch: 9.06 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2740527761665649		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.2740527761665649 | validation: 0.25550542020910394]
	TIME [epoch: 9.07 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20085447586539124		[learning rate: 0.0040896]
	Learning Rate: 0.00408963
	LOSS [training: 0.20085447586539124 | validation: 0.14428466837287318]
	TIME [epoch: 9.06 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3047593884854611		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.3047593884854611 | validation: 0.4134425405743939]
	TIME [epoch: 9.06 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6664423750333801		[learning rate: 0.0040699]
	Learning Rate: 0.00406985
	LOSS [training: 0.6664423750333801 | validation: 0.5086262357253644]
	TIME [epoch: 9.06 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32545446481498846		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.32545446481498846 | validation: 0.1721202773208955]
	TIME [epoch: 9.07 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1701526036070323		[learning rate: 0.0040502]
	Learning Rate: 0.00405017
	LOSS [training: 0.1701526036070323 | validation: 0.07299319933485002]
	TIME [epoch: 9.09 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13263426634959402		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.13263426634959402 | validation: 0.10504557747490711]
	TIME [epoch: 9.07 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1347894807230752		[learning rate: 0.0040306]
	Learning Rate: 0.00403059
	LOSS [training: 0.1347894807230752 | validation: 0.15065279887658833]
	TIME [epoch: 9.06 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12517260705743646		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.12517260705743646 | validation: 0.10538617168388201]
	TIME [epoch: 9.06 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13751744013478487		[learning rate: 0.0040111]
	Learning Rate: 0.0040111
	LOSS [training: 0.13751744013478487 | validation: 0.127533301494217]
	TIME [epoch: 9.07 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10303992778288293		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.10303992778288293 | validation: 0.07088809934239924]
	TIME [epoch: 9.07 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12548740073491535		[learning rate: 0.0039917]
	Learning Rate: 0.0039917
	LOSS [training: 0.12548740073491535 | validation: 0.06185189506843296]
	TIME [epoch: 9.07 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11320937866698404		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.11320937866698404 | validation: 0.07943648172725364]
	TIME [epoch: 9.06 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07287374023028682		[learning rate: 0.0039724]
	Learning Rate: 0.0039724
	LOSS [training: 0.07287374023028682 | validation: 0.15217162832703485]
	TIME [epoch: 9.06 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16541266900683235		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.16541266900683235 | validation: 0.10967088566322833]
	TIME [epoch: 9.08 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13880879938291196		[learning rate: 0.0039532]
	Learning Rate: 0.00395319
	LOSS [training: 0.13880879938291196 | validation: 0.14457929901784544]
	TIME [epoch: 9.06 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1919038698784276		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.1919038698784276 | validation: 0.21714384090515984]
	TIME [epoch: 9.06 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1787651480398054		[learning rate: 0.0039341]
	Learning Rate: 0.00393407
	LOSS [training: 0.1787651480398054 | validation: 0.10910509595637567]
	TIME [epoch: 9.07 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12658870420121687		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.12658870420121687 | validation: 0.11742728147186687]
	TIME [epoch: 9.07 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13729554714560765		[learning rate: 0.003915]
	Learning Rate: 0.00391505
	LOSS [training: 0.13729554714560765 | validation: 0.12467858528792958]
	TIME [epoch: 9.09 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09876393223675314		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.09876393223675314 | validation: 0.12466099070741443]
	TIME [epoch: 9.06 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11024573219844598		[learning rate: 0.0038961]
	Learning Rate: 0.00389611
	LOSS [training: 0.11024573219844598 | validation: 0.09523711989526555]
	TIME [epoch: 9.06 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10352165896790236		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.10352165896790236 | validation: 0.09975397079877321]
	TIME [epoch: 9.06 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1010131588054112		[learning rate: 0.0038773]
	Learning Rate: 0.00387727
	LOSS [training: 0.1010131588054112 | validation: 0.08941023550100868]
	TIME [epoch: 9.08 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10794082371392036		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.10794082371392036 | validation: 0.11113817806044943]
	TIME [epoch: 9.07 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1200877613744169		[learning rate: 0.0038585]
	Learning Rate: 0.00385852
	LOSS [training: 0.1200877613744169 | validation: 0.13898066803307518]
	TIME [epoch: 9.07 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13381096200607867		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.13381096200607867 | validation: 0.11981980270201914]
	TIME [epoch: 9.06 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12795075718298343		[learning rate: 0.0038399]
	Learning Rate: 0.00383986
	LOSS [training: 0.12795075718298343 | validation: 0.09979260013499933]
	TIME [epoch: 9.06 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11648829302700121		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.11648829302700121 | validation: 0.11279726406694703]
	TIME [epoch: 9.08 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12357098958867677		[learning rate: 0.0038213]
	Learning Rate: 0.00382129
	LOSS [training: 0.12357098958867677 | validation: 0.10771311623096899]
	TIME [epoch: 9.06 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11252923713770471		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.11252923713770471 | validation: 0.1357446750127876]
	TIME [epoch: 9.06 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1325851241760742		[learning rate: 0.0038028]
	Learning Rate: 0.00380282
	LOSS [training: 0.1325851241760742 | validation: 0.08226381798922619]
	TIME [epoch: 9.06 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10937166670016274		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.10937166670016274 | validation: 0.09768189209883764]
	TIME [epoch: 9.08 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10747538114755173		[learning rate: 0.0037844]
	Learning Rate: 0.00378443
	LOSS [training: 0.10747538114755173 | validation: 0.10701944412347242]
	TIME [epoch: 9.06 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1118711697838071		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.1118711697838071 | validation: 0.0979337907438122]
	TIME [epoch: 9.06 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07985312881073323		[learning rate: 0.0037661]
	Learning Rate: 0.00376613
	LOSS [training: 0.07985312881073323 | validation: 0.11026626380935169]
	TIME [epoch: 9.05 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1292185161146575		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.1292185161146575 | validation: 0.1082402046821784]
	TIME [epoch: 9.05 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13846811423986521		[learning rate: 0.0037479]
	Learning Rate: 0.00374791
	LOSS [training: 0.13846811423986521 | validation: 0.072722840816565]
	TIME [epoch: 9.08 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08573433875633969		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.08573433875633969 | validation: 0.09937856947739168]
	TIME [epoch: 9.06 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10717564885283004		[learning rate: 0.0037298]
	Learning Rate: 0.00372979
	LOSS [training: 0.10717564885283004 | validation: 0.07309562404000527]
	TIME [epoch: 9.06 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1159505816214067		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.1159505816214067 | validation: 0.10415658173308529]
	TIME [epoch: 9.05 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09590746095741412		[learning rate: 0.0037118]
	Learning Rate: 0.00371175
	LOSS [training: 0.09590746095741412 | validation: 0.07051453724791171]
	TIME [epoch: 9.05 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09644033263128868		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.09644033263128868 | validation: 0.09033230223806563]
	TIME [epoch: 9.08 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1155780234880704		[learning rate: 0.0036938]
	Learning Rate: 0.0036938
	LOSS [training: 0.1155780234880704 | validation: 0.11647313433716146]
	TIME [epoch: 9.05 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13255792005660505		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.13255792005660505 | validation: 0.09914934135605905]
	TIME [epoch: 9.06 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14393375431346617		[learning rate: 0.0036759]
	Learning Rate: 0.00367594
	LOSS [training: 0.14393375431346617 | validation: 0.09101596105225376]
	TIME [epoch: 9.06 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10913117961940655		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.10913117961940655 | validation: 0.07485622739426867]
	TIME [epoch: 9.07 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11201280058700747		[learning rate: 0.0036582]
	Learning Rate: 0.00365816
	LOSS [training: 0.11201280058700747 | validation: 0.11466346805062415]
	TIME [epoch: 9.06 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12373731813412825		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.12373731813412825 | validation: 0.12211844262846908]
	TIME [epoch: 9.05 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13274832013650764		[learning rate: 0.0036405]
	Learning Rate: 0.00364047
	LOSS [training: 0.13274832013650764 | validation: 0.09912119072669892]
	TIME [epoch: 9.06 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12042069572794097		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.12042069572794097 | validation: 0.10835033942561484]
	TIME [epoch: 9.05 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19628240179625717		[learning rate: 0.0036229]
	Learning Rate: 0.00362287
	LOSS [training: 0.19628240179625717 | validation: 0.11057424830644139]
	TIME [epoch: 9.07 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12489087637840224		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.12489087637840224 | validation: 0.17251143158448512]
	TIME [epoch: 9.06 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20496620513954117		[learning rate: 0.0036053]
	Learning Rate: 0.00360535
	LOSS [training: 0.20496620513954117 | validation: 0.1360906220468246]
	TIME [epoch: 9.05 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.177129103663987		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.177129103663987 | validation: 0.09855226131751467]
	TIME [epoch: 9.06 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12390244455064665		[learning rate: 0.0035879]
	Learning Rate: 0.00358791
	LOSS [training: 0.12390244455064665 | validation: 0.14239356878767667]
	TIME [epoch: 9.07 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1735633135078535		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.1735633135078535 | validation: 0.15954232702715496]
	TIME [epoch: 9.05 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19674224456628614		[learning rate: 0.0035706]
	Learning Rate: 0.00357056
	LOSS [training: 0.19674224456628614 | validation: 0.10196791661296128]
	TIME [epoch: 9.06 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11731839360056431		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.11731839360056431 | validation: 0.08119539319893557]
	TIME [epoch: 9.06 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.226193952559092		[learning rate: 0.0035533]
	Learning Rate: 0.0035533
	LOSS [training: 0.226193952559092 | validation: 0.07831825535947298]
	TIME [epoch: 9.06 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10172787138755354		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.10172787138755354 | validation: 0.09411491018036983]
	TIME [epoch: 9.07 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15590212080301388		[learning rate: 0.0035361]
	Learning Rate: 0.00353611
	LOSS [training: 0.15590212080301388 | validation: 0.14995942655234673]
	TIME [epoch: 9.05 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17327888872071479		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.17327888872071479 | validation: 0.14976897109005863]
	TIME [epoch: 9.05 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12046123425460682		[learning rate: 0.003519]
	Learning Rate: 0.00351901
	LOSS [training: 0.12046123425460682 | validation: 0.09259060757583286]
	TIME [epoch: 9.05 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1156293558593903		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.1156293558593903 | validation: 0.0969518403080464]
	TIME [epoch: 9.07 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10859066587498607		[learning rate: 0.003502]
	Learning Rate: 0.003502
	LOSS [training: 0.10859066587498607 | validation: 0.08830970203756405]
	TIME [epoch: 9.06 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12023585841572648		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.12023585841572648 | validation: 0.16205742425309183]
	TIME [epoch: 9.05 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14604600384151423		[learning rate: 0.0034851]
	Learning Rate: 0.00348506
	LOSS [training: 0.14604600384151423 | validation: 0.09926710175525118]
	TIME [epoch: 9.05 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10807151920689122		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.10807151920689122 | validation: 0.08108340015738041]
	TIME [epoch: 9.05 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1106044229700162		[learning rate: 0.0034682]
	Learning Rate: 0.00346821
	LOSS [training: 0.1106044229700162 | validation: 0.1379183426099511]
	TIME [epoch: 9.08 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11892231925875366		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.11892231925875366 | validation: 0.11216177634833524]
	TIME [epoch: 9.07 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2769575095665682		[learning rate: 0.0034514]
	Learning Rate: 0.00345144
	LOSS [training: 0.2769575095665682 | validation: 0.336346430672692]
	TIME [epoch: 9.06 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3270139251212462		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.3270139251212462 | validation: 0.18564157634435813]
	TIME [epoch: 9.06 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17037711430926364		[learning rate: 0.0034347]
	Learning Rate: 0.00343475
	LOSS [training: 0.17037711430926364 | validation: 0.13940720796746042]
	TIME [epoch: 9.06 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21239048909237793		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.21239048909237793 | validation: 0.11986236657906364]
	TIME [epoch: 9.07 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12571026491986345		[learning rate: 0.0034181]
	Learning Rate: 0.00341814
	LOSS [training: 0.12571026491986345 | validation: 0.08519922715704265]
	TIME [epoch: 9.05 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1494804654524899		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.1494804654524899 | validation: 0.12912787780505994]
	TIME [epoch: 9.05 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19515021652530953		[learning rate: 0.0034016]
	Learning Rate: 0.00340161
	LOSS [training: 0.19515021652530953 | validation: 0.15090357163518953]
	TIME [epoch: 9.06 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3538092641514651		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.3538092641514651 | validation: 0.3112691545164846]
	TIME [epoch: 9.07 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20961321043414038		[learning rate: 0.0033852]
	Learning Rate: 0.00338516
	LOSS [training: 0.20961321043414038 | validation: 0.14416210246330524]
	TIME [epoch: 9.05 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14590882018280554		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.14590882018280554 | validation: 0.1839827186311142]
	TIME [epoch: 9.06 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1327580313428565		[learning rate: 0.0033688]
	Learning Rate: 0.00336879
	LOSS [training: 0.1327580313428565 | validation: 0.10387144713267782]
	TIME [epoch: 9.05 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11300316667451567		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.11300316667451567 | validation: 0.1380444279485208]
	TIME [epoch: 9.05 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18635152300758784		[learning rate: 0.0033525]
	Learning Rate: 0.0033525
	LOSS [training: 0.18635152300758784 | validation: 0.21600904182247896]
	TIME [epoch: 9.08 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18477313933964315		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.18477313933964315 | validation: 0.1195744427347861]
	TIME [epoch: 9.06 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15588559213540726		[learning rate: 0.0033363]
	Learning Rate: 0.00333629
	LOSS [training: 0.15588559213540726 | validation: 0.12657186472685344]
	TIME [epoch: 9.07 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1306599182266192		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.1306599182266192 | validation: 0.28717849869229706]
	TIME [epoch: 9.05 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1981692078352425		[learning rate: 0.0033202]
	Learning Rate: 0.00332015
	LOSS [training: 0.1981692078352425 | validation: 0.0995823135247379]
	TIME [epoch: 9.07 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12863197450482172		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.12863197450482172 | validation: 0.10273419321937144]
	TIME [epoch: 9.05 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20313414192887896		[learning rate: 0.0033041]
	Learning Rate: 0.0033041
	LOSS [training: 0.20313414192887896 | validation: 0.2618151828523392]
	TIME [epoch: 9.05 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3112885199071661		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.3112885199071661 | validation: 0.15052888914076773]
	TIME [epoch: 9.05 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14822529134283338		[learning rate: 0.0032881]
	Learning Rate: 0.00328812
	LOSS [training: 0.14822529134283338 | validation: 0.12107683702610214]
	TIME [epoch: 9.05 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11416073165558523		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.11416073165558523 | validation: 0.11175675869752809]
	TIME [epoch: 9.07 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10338588079031678		[learning rate: 0.0032722]
	Learning Rate: 0.00327222
	LOSS [training: 0.10338588079031678 | validation: 0.12013240447133806]
	TIME [epoch: 9.06 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2844934684600785		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.2844934684600785 | validation: 0.24252343708284446]
	TIME [epoch: 9.05 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29825472210755566		[learning rate: 0.0032564]
	Learning Rate: 0.00325639
	LOSS [training: 0.29825472210755566 | validation: 0.15901356738423622]
	TIME [epoch: 9.06 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18113674528545137		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.18113674528545137 | validation: 0.14058683765020447]
	TIME [epoch: 9.06 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2701187421301813		[learning rate: 0.0032406]
	Learning Rate: 0.00324065
	LOSS [training: 0.2701187421301813 | validation: 0.3248553850426288]
	TIME [epoch: 9.08 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22912933333081878		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.22912933333081878 | validation: 0.24197773483657775]
	TIME [epoch: 9.06 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3023341230665137		[learning rate: 0.003225]
	Learning Rate: 0.00322497
	LOSS [training: 0.3023341230665137 | validation: 0.2376861689815054]
	TIME [epoch: 9.06 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6577299191820613		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.6577299191820613 | validation: 0.48462680859454643]
	TIME [epoch: 9.06 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3281109478006994		[learning rate: 0.0032094]
	Learning Rate: 0.00320938
	LOSS [training: 0.3281109478006994 | validation: 0.2635033808170016]
	TIME [epoch: 9.08 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25646117994995987		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.25646117994995987 | validation: 0.2644117991747994]
	TIME [epoch: 9.07 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5563053726958519		[learning rate: 0.0031939]
	Learning Rate: 0.00319386
	LOSS [training: 0.5563053726958519 | validation: 0.20382381540314198]
	TIME [epoch: 9.06 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2375817017412853		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.2375817017412853 | validation: 0.26128945841920526]
	TIME [epoch: 9.07 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22731286823190655		[learning rate: 0.0031784]
	Learning Rate: 0.00317841
	LOSS [training: 0.22731286823190655 | validation: 0.08921128686140833]
	TIME [epoch: 9.08 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11337605945995147		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.11337605945995147 | validation: 0.08957055636456818]
	TIME [epoch: 9.09 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0905838838880174		[learning rate: 0.003163]
	Learning Rate: 0.00316304
	LOSS [training: 0.0905838838880174 | validation: 0.11216205741837747]
	TIME [epoch: 9.08 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09606800576908427		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.09606800576908427 | validation: 0.14093202766180368]
	TIME [epoch: 9.07 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19013765533171753		[learning rate: 0.0031477]
	Learning Rate: 0.00314775
	LOSS [training: 0.19013765533171753 | validation: 0.5928582167984364]
	TIME [epoch: 9.07 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4043822426810886		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.4043822426810886 | validation: 0.2521670048408364]
	TIME [epoch: 9.08 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1629771485105155		[learning rate: 0.0031325]
	Learning Rate: 0.00313253
	LOSS [training: 0.1629771485105155 | validation: 0.1991006352246691]
	TIME [epoch: 9.07 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30430000147143826		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.30430000147143826 | validation: 0.3008904970211792]
	TIME [epoch: 9.06 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31075570169482425		[learning rate: 0.0031174]
	Learning Rate: 0.00311738
	LOSS [training: 0.31075570169482425 | validation: 0.1826140113579809]
	TIME [epoch: 9.07 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14966972404224133		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.14966972404224133 | validation: 0.1139278153795508]
	TIME [epoch: 9.06 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1508768141519407		[learning rate: 0.0031023]
	Learning Rate: 0.0031023
	LOSS [training: 0.1508768141519407 | validation: 0.17055307158791866]
	TIME [epoch: 9.09 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16173290614653263		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.16173290614653263 | validation: 0.09440567073583653]
	TIME [epoch: 9.07 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09316557452532476		[learning rate: 0.0030873]
	Learning Rate: 0.0030873
	LOSS [training: 0.09316557452532476 | validation: 0.06347102732548643]
	TIME [epoch: 9.07 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0823589442398244		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.0823589442398244 | validation: 0.0841252029129941]
	TIME [epoch: 9.07 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2312074352384225		[learning rate: 0.0030724]
	Learning Rate: 0.00307237
	LOSS [training: 0.2312074352384225 | validation: 0.2290718726038701]
	TIME [epoch: 9.09 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24098009385107955		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.24098009385107955 | validation: 0.13033221806569295]
	TIME [epoch: 9.07 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11274033579958338		[learning rate: 0.0030575]
	Learning Rate: 0.00305751
	LOSS [training: 0.11274033579958338 | validation: 0.11502424984428614]
	TIME [epoch: 9.07 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2194107817606475		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.2194107817606475 | validation: 0.12437055454685504]
	TIME [epoch: 9.07 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14488317602896744		[learning rate: 0.0030427]
	Learning Rate: 0.00304273
	LOSS [training: 0.14488317602896744 | validation: 0.10829808605093631]
	TIME [epoch: 9.08 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11391824698246918		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.11391824698246918 | validation: 0.09535163947566236]
	TIME [epoch: 9.09 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.096783402599985		[learning rate: 0.003028]
	Learning Rate: 0.00302801
	LOSS [training: 0.096783402599985 | validation: 0.07824201037764075]
	TIME [epoch: 9.08 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1105522618441068		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.1105522618441068 | validation: 0.17872855973233978]
	TIME [epoch: 9.07 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17504876511977333		[learning rate: 0.0030134]
	Learning Rate: 0.00301337
	LOSS [training: 0.17504876511977333 | validation: 0.11013015943170568]
	TIME [epoch: 9.07 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09353507624814181		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.09353507624814181 | validation: 0.08274121612734738]
	TIME [epoch: 9.07 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10909064390460596		[learning rate: 0.0029988]
	Learning Rate: 0.0029988
	LOSS [training: 0.10909064390460596 | validation: 0.0642182461007848]
	TIME [epoch: 9.09 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1062443632470516		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.1062443632470516 | validation: 0.09214326427226795]
	TIME [epoch: 9.07 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14438838347680855		[learning rate: 0.0029843]
	Learning Rate: 0.0029843
	LOSS [training: 0.14438838347680855 | validation: 0.11744333404896362]
	TIME [epoch: 9.08 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16566021159323244		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.16566021159323244 | validation: 0.11077341758437131]
	TIME [epoch: 9.07 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2217559542889799		[learning rate: 0.0029699]
	Learning Rate: 0.00296987
	LOSS [training: 0.2217559542889799 | validation: 0.19121097272227516]
	TIME [epoch: 9.09 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1654633221293627		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.1654633221293627 | validation: 0.08493933292927888]
	TIME [epoch: 9.07 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10357911692941839		[learning rate: 0.0029555]
	Learning Rate: 0.0029555
	LOSS [training: 0.10357911692941839 | validation: 0.11346279452345553]
	TIME [epoch: 9.07 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13777273849211252		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.13777273849211252 | validation: 0.09761392752139023]
	TIME [epoch: 9.08 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15938023438643298		[learning rate: 0.0029412]
	Learning Rate: 0.00294121
	LOSS [training: 0.15938023438643298 | validation: 0.10522450352270837]
	TIME [epoch: 9.08 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1313894457038532		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.1313894457038532 | validation: 0.07615745038538638]
	TIME [epoch: 9.1 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09896716925165268		[learning rate: 0.002927]
	Learning Rate: 0.00292699
	LOSS [training: 0.09896716925165268 | validation: 0.08159006830721494]
	TIME [epoch: 9.07 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10823355057204971		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.10823355057204971 | validation: 0.10720381631720835]
	TIME [epoch: 9.07 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10086726784679208		[learning rate: 0.0029128]
	Learning Rate: 0.00291283
	LOSS [training: 0.10086726784679208 | validation: 0.07037861937756001]
	TIME [epoch: 9.08 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13034879759394788		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.13034879759394788 | validation: 0.08756487076285097]
	TIME [epoch: 9.09 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1578728833889303		[learning rate: 0.0028987]
	Learning Rate: 0.00289875
	LOSS [training: 0.1578728833889303 | validation: 0.09750593462496314]
	TIME [epoch: 9.07 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0783441117680397		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.0783441117680397 | validation: 0.06944275213412822]
	TIME [epoch: 9.07 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08694045223516007		[learning rate: 0.0028847]
	Learning Rate: 0.00288473
	LOSS [training: 0.08694045223516007 | validation: 0.06155998783086901]
	TIME [epoch: 9.07 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06925955979083329		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.06925955979083329 | validation: 0.08692067067916176]
	TIME [epoch: 9.07 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08656621039209457		[learning rate: 0.0028708]
	Learning Rate: 0.00287078
	LOSS [training: 0.08656621039209457 | validation: 0.11194378633022385]
	TIME [epoch: 9.09 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08307079254519452		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.08307079254519452 | validation: 0.058952483915873766]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07732932945914453		[learning rate: 0.0028569]
	Learning Rate: 0.0028569
	LOSS [training: 0.07732932945914453 | validation: 0.10976038202067903]
	TIME [epoch: 9.06 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08431622413537201		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.08431622413537201 | validation: 0.12040060954011737]
	TIME [epoch: 9.05 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08583393743962839		[learning rate: 0.0028431]
	Learning Rate: 0.00284308
	LOSS [training: 0.08583393743962839 | validation: 0.09413410626682828]
	TIME [epoch: 9.08 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0766472893831084		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.0766472893831084 | validation: 0.05419843337818667]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_620.pth
	Model improved!!!
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07135237785895043		[learning rate: 0.0028293]
	Learning Rate: 0.00282933
	LOSS [training: 0.07135237785895043 | validation: 0.02412495194154341]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_621.pth
	Model improved!!!
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051895175540430584		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.051895175540430584 | validation: 0.08546754082964125]
	TIME [epoch: 9.05 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08048295483801399		[learning rate: 0.0028157]
	Learning Rate: 0.00281565
	LOSS [training: 0.08048295483801399 | validation: 0.0581601163677988]
	TIME [epoch: 9.05 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07906470138393198		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.07906470138393198 | validation: 0.05983181772084433]
	TIME [epoch: 9.06 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1016542764779639		[learning rate: 0.002802]
	Learning Rate: 0.00280204
	LOSS [training: 0.1016542764779639 | validation: 0.12700544853612922]
	TIME [epoch: 9.05 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1470441741182775		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.1470441741182775 | validation: 0.18911217216822093]
	TIME [epoch: 9.04 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1959486645161864		[learning rate: 0.0027885]
	Learning Rate: 0.00278849
	LOSS [training: 0.1959486645161864 | validation: 0.1018244385191795]
	TIME [epoch: 9.05 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09168175052947487		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.09168175052947487 | validation: 0.056949539576338123]
	TIME [epoch: 9.05 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059179885024818524		[learning rate: 0.002775]
	Learning Rate: 0.002775
	LOSS [training: 0.059179885024818524 | validation: 0.048157725740460976]
	TIME [epoch: 9.05 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05989213450249327		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.05989213450249327 | validation: 0.044087252173990635]
	TIME [epoch: 9.05 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10368172268144005		[learning rate: 0.0027616]
	Learning Rate: 0.00276158
	LOSS [training: 0.10368172268144005 | validation: 0.04251383673521155]
	TIME [epoch: 9.05 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05361763693816446		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.05361763693816446 | validation: 0.19841306506960985]
	TIME [epoch: 9.05 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10739001818616074		[learning rate: 0.0027482]
	Learning Rate: 0.00274823
	LOSS [training: 0.10739001818616074 | validation: 0.09935929009427215]
	TIME [epoch: 9.06 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10981178700711547		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.10981178700711547 | validation: 0.06083412832467744]
	TIME [epoch: 9.04 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06628091118638633		[learning rate: 0.0027349]
	Learning Rate: 0.00273494
	LOSS [training: 0.06628091118638633 | validation: 0.049283403710171106]
	TIME [epoch: 9.04 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05930967895070012		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.05930967895070012 | validation: 0.0430088870046276]
	TIME [epoch: 9.04 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06205248178183763		[learning rate: 0.0027217]
	Learning Rate: 0.00272171
	LOSS [training: 0.06205248178183763 | validation: 0.0442844325538135]
	TIME [epoch: 9.04 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08027565049831412		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.08027565049831412 | validation: 0.05501848675989276]
	TIME [epoch: 9.06 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08973934646662436		[learning rate: 0.0027086]
	Learning Rate: 0.00270855
	LOSS [training: 0.08973934646662436 | validation: 0.06405068385784052]
	TIME [epoch: 9.04 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06410646860503041		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.06410646860503041 | validation: 0.030131625065810408]
	TIME [epoch: 9.05 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06898537516353502		[learning rate: 0.0026955]
	Learning Rate: 0.00269545
	LOSS [training: 0.06898537516353502 | validation: 0.0850973936776021]
	TIME [epoch: 9.04 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.063424728921307		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.063424728921307 | validation: 0.04430537486602125]
	TIME [epoch: 9.06 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0752559030703975		[learning rate: 0.0026824]
	Learning Rate: 0.00268242
	LOSS [training: 0.0752559030703975 | validation: 0.07786732755503933]
	TIME [epoch: 9.05 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0770740206377528		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.0770740206377528 | validation: 0.07489392519626924]
	TIME [epoch: 9.05 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07044523192789562		[learning rate: 0.0026694]
	Learning Rate: 0.00266945
	LOSS [training: 0.07044523192789562 | validation: 0.07163320020474903]
	TIME [epoch: 9.05 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0882705942424292		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.0882705942424292 | validation: 0.07470322399957718]
	TIME [epoch: 9.05 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06370152604016326		[learning rate: 0.0026565]
	Learning Rate: 0.00265654
	LOSS [training: 0.06370152604016326 | validation: 0.05606024461641204]
	TIME [epoch: 9.06 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07678471246779069		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.07678471246779069 | validation: 0.04592339160133179]
	TIME [epoch: 9.05 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.071679584036205		[learning rate: 0.0026437]
	Learning Rate: 0.00264369
	LOSS [training: 0.071679584036205 | validation: 0.03492119119482412]
	TIME [epoch: 9.04 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05849013057032291		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.05849013057032291 | validation: 0.03722027947551673]
	TIME [epoch: 9.05 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06368058689846239		[learning rate: 0.0026309]
	Learning Rate: 0.00263091
	LOSS [training: 0.06368058689846239 | validation: 0.0532707486340272]
	TIME [epoch: 9.06 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12752237620912038		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.12752237620912038 | validation: 0.12926974923827714]
	TIME [epoch: 9.05 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19921025368943585		[learning rate: 0.0026182]
	Learning Rate: 0.00261818
	LOSS [training: 0.19921025368943585 | validation: 0.13011466074253664]
	TIME [epoch: 9.04 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20097492913826082		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.20097492913826082 | validation: 0.19397237740227277]
	TIME [epoch: 9.04 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13937298639862097		[learning rate: 0.0026055]
	Learning Rate: 0.00260552
	LOSS [training: 0.13937298639862097 | validation: 0.11307053005554096]
	TIME [epoch: 9.04 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16200044153126603		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.16200044153126603 | validation: 0.16966402685752666]
	TIME [epoch: 9.06 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13815036011078202		[learning rate: 0.0025929]
	Learning Rate: 0.00259292
	LOSS [training: 0.13815036011078202 | validation: 0.07816615185389485]
	TIME [epoch: 9.05 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09233647193203125		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.09233647193203125 | validation: 0.13798154684488695]
	TIME [epoch: 9.05 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10338703014283276		[learning rate: 0.0025804]
	Learning Rate: 0.00258038
	LOSS [training: 0.10338703014283276 | validation: 0.0846573677656935]
	TIME [epoch: 9.05 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059384710765404525		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.059384710765404525 | validation: 0.06083466007345332]
	TIME [epoch: 9.05 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06275980288926745		[learning rate: 0.0025679]
	Learning Rate: 0.0025679
	LOSS [training: 0.06275980288926745 | validation: 0.06911478410733991]
	TIME [epoch: 9.06 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060845909796220544		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.060845909796220544 | validation: 0.06815554953219405]
	TIME [epoch: 9.04 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07799997388304632		[learning rate: 0.0025555]
	Learning Rate: 0.00255549
	LOSS [training: 0.07799997388304632 | validation: 0.052111336963151844]
	TIME [epoch: 9.04 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07715887366485341		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.07715887366485341 | validation: 0.0591238891432511]
	TIME [epoch: 9.04 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05814293755640567		[learning rate: 0.0025431]
	Learning Rate: 0.00254313
	LOSS [training: 0.05814293755640567 | validation: 0.03296765533393969]
	TIME [epoch: 9.06 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06875584608884218		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.06875584608884218 | validation: 0.04955125876439758]
	TIME [epoch: 9.04 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0874127289936017		[learning rate: 0.0025308]
	Learning Rate: 0.00253083
	LOSS [training: 0.0874127289936017 | validation: 0.06898170355929535]
	TIME [epoch: 9.04 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0709807143092819		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.0709807143092819 | validation: 0.059703384246977124]
	TIME [epoch: 9.04 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07127162696695724		[learning rate: 0.0025186]
	Learning Rate: 0.00251859
	LOSS [training: 0.07127162696695724 | validation: 0.03901725815503522]
	TIME [epoch: 9.05 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06295200766696843		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.06295200766696843 | validation: 0.05269521413416679]
	TIME [epoch: 9.07 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05833822193513213		[learning rate: 0.0025064]
	Learning Rate: 0.00250641
	LOSS [training: 0.05833822193513213 | validation: 0.027938247548859173]
	TIME [epoch: 9.06 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06407182655237904		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.06407182655237904 | validation: 0.056848347994116546]
	TIME [epoch: 9.06 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07779068553971095		[learning rate: 0.0024943]
	Learning Rate: 0.00249429
	LOSS [training: 0.07779068553971095 | validation: 0.052334438367349224]
	TIME [epoch: 9.04 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08404444035242184		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.08404444035242184 | validation: 0.16111004549052962]
	TIME [epoch: 9.06 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1214711930541273		[learning rate: 0.0024822]
	Learning Rate: 0.00248223
	LOSS [training: 0.1214711930541273 | validation: 0.12425669035134178]
	TIME [epoch: 9.04 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12098892523134985		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.12098892523134985 | validation: 0.09754089504861706]
	TIME [epoch: 9.04 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09989439835354108		[learning rate: 0.0024702]
	Learning Rate: 0.00247023
	LOSS [training: 0.09989439835354108 | validation: 0.09885323040721603]
	TIME [epoch: 9.05 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10214823685459906		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.10214823685459906 | validation: 0.0807362934144846]
	TIME [epoch: 9.05 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09588097092133245		[learning rate: 0.0024583]
	Learning Rate: 0.00245828
	LOSS [training: 0.09588097092133245 | validation: 0.06700993940930881]
	TIME [epoch: 9.07 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10996100186785532		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.10996100186785532 | validation: 0.14204877887248735]
	TIME [epoch: 9.05 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1459216600307666		[learning rate: 0.0024464]
	Learning Rate: 0.00244639
	LOSS [training: 0.1459216600307666 | validation: 0.12085027377292257]
	TIME [epoch: 9.04 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13536581872050277		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.13536581872050277 | validation: 0.11478259541346653]
	TIME [epoch: 9.05 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11349771645661651		[learning rate: 0.0024346]
	Learning Rate: 0.00243456
	LOSS [training: 0.11349771645661651 | validation: 0.07714415792356073]
	TIME [epoch: 9.06 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0775824819661054		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.0775824819661054 | validation: 0.06413662900994367]
	TIME [epoch: 9.06 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07307324504193613		[learning rate: 0.0024228]
	Learning Rate: 0.00242279
	LOSS [training: 0.07307324504193613 | validation: 0.11406964436632988]
	TIME [epoch: 9.05 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09063221916370083		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.09063221916370083 | validation: 0.07164873908853917]
	TIME [epoch: 9.04 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08168159944684635		[learning rate: 0.0024111]
	Learning Rate: 0.00241107
	LOSS [training: 0.08168159944684635 | validation: 0.05614886205597917]
	TIME [epoch: 9.04 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06904970717151283		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.06904970717151283 | validation: 0.05074301220340706]
	TIME [epoch: 9.06 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08371279147399409		[learning rate: 0.0023994]
	Learning Rate: 0.00239941
	LOSS [training: 0.08371279147399409 | validation: 0.048751390219995236]
	TIME [epoch: 9.04 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0648611012602576		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.0648611012602576 | validation: 0.04669822673091695]
	TIME [epoch: 9.05 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12676202504723466		[learning rate: 0.0023878]
	Learning Rate: 0.00238781
	LOSS [training: 0.12676202504723466 | validation: 0.09357422863889048]
	TIME [epoch: 9.04 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10441384931843553		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.10441384931843553 | validation: 0.07039061429030691]
	TIME [epoch: 9.04 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10877632111362152		[learning rate: 0.0023763]
	Learning Rate: 0.00237626
	LOSS [training: 0.10877632111362152 | validation: 0.07338585507618187]
	TIME [epoch: 9.06 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09846940144777452		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.09846940144777452 | validation: 0.0833460029421551]
	TIME [epoch: 9.04 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09234054161291733		[learning rate: 0.0023648]
	Learning Rate: 0.00236477
	LOSS [training: 0.09234054161291733 | validation: 0.0980884634527456]
	TIME [epoch: 9.04 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06440293204800582		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.06440293204800582 | validation: 0.07472229273319506]
	TIME [epoch: 9.05 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07606134024797799		[learning rate: 0.0023533]
	Learning Rate: 0.00235334
	LOSS [training: 0.07606134024797799 | validation: 0.04357328999592893]
	TIME [epoch: 9.07 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05890927855576348		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.05890927855576348 | validation: 0.04561833570703498]
	TIME [epoch: 9.05 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07641110572404035		[learning rate: 0.002342]
	Learning Rate: 0.00234196
	LOSS [training: 0.07641110572404035 | validation: 0.0471508937941985]
	TIME [epoch: 9.04 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07124264648135885		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.07124264648135885 | validation: 0.044618334286580116]
	TIME [epoch: 9.04 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08506140798620443		[learning rate: 0.0023306]
	Learning Rate: 0.00233063
	LOSS [training: 0.08506140798620443 | validation: 0.10718341297781328]
	TIME [epoch: 9.04 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08284951711885806		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.08284951711885806 | validation: 0.09954442033681002]
	TIME [epoch: 9.06 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07083520569952423		[learning rate: 0.0023194]
	Learning Rate: 0.00231936
	LOSS [training: 0.07083520569952423 | validation: 0.07793222570780048]
	TIME [epoch: 9.04 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07320781105017884		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.07320781105017884 | validation: 0.04350399120940794]
	TIME [epoch: 9.04 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08458317906257903		[learning rate: 0.0023081]
	Learning Rate: 0.00230815
	LOSS [training: 0.08458317906257903 | validation: 0.1256558747012595]
	TIME [epoch: 9.05 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10521799765157276		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.10521799765157276 | validation: 0.03170881784462287]
	TIME [epoch: 9.06 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053322001245007765		[learning rate: 0.002297]
	Learning Rate: 0.00229698
	LOSS [training: 0.053322001245007765 | validation: 0.02717866138907274]
	TIME [epoch: 9.04 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0713638891660367		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.0713638891660367 | validation: 0.08174116001450521]
	TIME [epoch: 9.04 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10182749960620005		[learning rate: 0.0022859]
	Learning Rate: 0.00228588
	LOSS [training: 0.10182749960620005 | validation: 0.057476556805227216]
	TIME [epoch: 9.04 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.077262310355725		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.077262310355725 | validation: 0.07236381725985704]
	TIME [epoch: 9.05 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29341483608792973		[learning rate: 0.0022748]
	Learning Rate: 0.00227482
	LOSS [training: 0.29341483608792973 | validation: 0.22464563440688132]
	TIME [epoch: 9.06 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2056849527695884		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.2056849527695884 | validation: 0.1836320240895566]
	TIME [epoch: 9.05 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13817494423935223		[learning rate: 0.0022638]
	Learning Rate: 0.00226382
	LOSS [training: 0.13817494423935223 | validation: 0.07892485035627536]
	TIME [epoch: 9.05 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09903868243590627		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.09903868243590627 | validation: 0.13417859341605748]
	TIME [epoch: 9.04 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1506446499641306		[learning rate: 0.0022529]
	Learning Rate: 0.00225287
	LOSS [training: 0.1506446499641306 | validation: 0.0709783433874511]
	TIME [epoch: 9.04 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08120584437935574		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.08120584437935574 | validation: 0.05987712018184195]
	TIME [epoch: 9.05 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09399916943103484		[learning rate: 0.002242]
	Learning Rate: 0.00224198
	LOSS [training: 0.09399916943103484 | validation: 0.11515007652698639]
	TIME [epoch: 9.04 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09466425991557006		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.09466425991557006 | validation: 0.044145847503038335]
	TIME [epoch: 9.05 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05724214935660501		[learning rate: 0.0022311]
	Learning Rate: 0.00223114
	LOSS [training: 0.05724214935660501 | validation: 0.03369378083996718]
	TIME [epoch: 9.04 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1029913797859543		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.1029913797859543 | validation: 0.0916722162279831]
	TIME [epoch: 9.06 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08946554416180502		[learning rate: 0.0022203]
	Learning Rate: 0.00222035
	LOSS [training: 0.08946554416180502 | validation: 0.07383206162027128]
	TIME [epoch: 9.04 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0765989961667776		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.0765989961667776 | validation: 0.056457409630864194]
	TIME [epoch: 9.05 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07575838101680188		[learning rate: 0.0022096]
	Learning Rate: 0.00220961
	LOSS [training: 0.07575838101680188 | validation: 0.04086574279735081]
	TIME [epoch: 9.05 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04942275330893252		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.04942275330893252 | validation: 0.07194624540537119]
	TIME [epoch: 9.05 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05983876536645538		[learning rate: 0.0021989]
	Learning Rate: 0.00219893
	LOSS [training: 0.05983876536645538 | validation: 0.06727316284123014]
	TIME [epoch: 9.07 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06629528213150318		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.06629528213150318 | validation: 0.05257556438364541]
	TIME [epoch: 9.04 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05701016282439837		[learning rate: 0.0021883]
	Learning Rate: 0.00218829
	LOSS [training: 0.05701016282439837 | validation: 0.044171032244904956]
	TIME [epoch: 9.04 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0750873236047905		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.0750873236047905 | validation: 0.05727123309818728]
	TIME [epoch: 9.04 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08800871258594976		[learning rate: 0.0021777]
	Learning Rate: 0.00217771
	LOSS [training: 0.08800871258594976 | validation: 0.06858353453957554]
	TIME [epoch: 9.05 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0490950703552777		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.0490950703552777 | validation: 0.07365530085491201]
	TIME [epoch: 9.05 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07147728180383764		[learning rate: 0.0021672]
	Learning Rate: 0.00216718
	LOSS [training: 0.07147728180383764 | validation: 0.09061970653267676]
	TIME [epoch: 9.05 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05780650711075754		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.05780650711075754 | validation: 0.03138364256849212]
	TIME [epoch: 9.04 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04697731776342083		[learning rate: 0.0021567]
	Learning Rate: 0.0021567
	LOSS [training: 0.04697731776342083 | validation: 0.039564165954378554]
	TIME [epoch: 9.04 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08096894800376851		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.08096894800376851 | validation: 0.020852206568957185]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_734.pth
	Model improved!!!
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05092122585307616		[learning rate: 0.0021463]
	Learning Rate: 0.00214627
	LOSS [training: 0.05092122585307616 | validation: 0.06792016239756378]
	TIME [epoch: 9.05 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10888880219154858		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.10888880219154858 | validation: 0.08506628738764845]
	TIME [epoch: 9.05 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07201085050908693		[learning rate: 0.0021359]
	Learning Rate: 0.00213589
	LOSS [training: 0.07201085050908693 | validation: 0.05176406981534436]
	TIME [epoch: 9.05 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07302450344110083		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.07302450344110083 | validation: 0.08558926949679821]
	TIME [epoch: 9.06 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08763975871851132		[learning rate: 0.0021256]
	Learning Rate: 0.00212556
	LOSS [training: 0.08763975871851132 | validation: 0.07723700196940052]
	TIME [epoch: 9.05 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1175662136860585		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.1175662136860585 | validation: 0.1338539746860183]
	TIME [epoch: 9.04 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13281843795009507		[learning rate: 0.0021153]
	Learning Rate: 0.00211528
	LOSS [training: 0.13281843795009507 | validation: 0.06776690231986839]
	TIME [epoch: 9.04 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10091938690342203		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.10091938690342203 | validation: 0.07046010912045059]
	TIME [epoch: 9.04 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0818480333559662		[learning rate: 0.0021051]
	Learning Rate: 0.00210505
	LOSS [training: 0.0818480333559662 | validation: 0.056931798290788885]
	TIME [epoch: 9.06 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07628068163148494		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.07628068163148494 | validation: 0.07074336970541606]
	TIME [epoch: 9.04 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07326102503023998		[learning rate: 0.0020949]
	Learning Rate: 0.00209487
	LOSS [training: 0.07326102503023998 | validation: 0.0448151625484556]
	TIME [epoch: 9.04 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08396357705396904		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.08396357705396904 | validation: 0.05395725755839391]
	TIME [epoch: 9.04 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06583598037570136		[learning rate: 0.0020847]
	Learning Rate: 0.00208474
	LOSS [training: 0.06583598037570136 | validation: 0.028983203899348886]
	TIME [epoch: 9.04 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04425827036365989		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.04425827036365989 | validation: 0.04348988127843112]
	TIME [epoch: 9.06 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07703633769118969		[learning rate: 0.0020747]
	Learning Rate: 0.00207466
	LOSS [training: 0.07703633769118969 | validation: 0.07228441740687393]
	TIME [epoch: 9.04 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06532039155164103		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.06532039155164103 | validation: 0.045507123124852264]
	TIME [epoch: 9.06 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05074648337043051		[learning rate: 0.0020646]
	Learning Rate: 0.00206463
	LOSS [training: 0.05074648337043051 | validation: 0.04861040298513428]
	TIME [epoch: 9.05 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07831590607210438		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.07831590607210438 | validation: 0.03323459805078397]
	TIME [epoch: 9.06 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06822381736177523		[learning rate: 0.0020546]
	Learning Rate: 0.00205465
	LOSS [training: 0.06822381736177523 | validation: 0.07506251275132328]
	TIME [epoch: 9.05 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09619843571805943		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.09619843571805943 | validation: 0.037942355539676925]
	TIME [epoch: 9.04 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08753775813991174		[learning rate: 0.0020447]
	Learning Rate: 0.00204471
	LOSS [training: 0.08753775813991174 | validation: 0.07726148400137278]
	TIME [epoch: 9.04 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07705941876698436		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.07705941876698436 | validation: 0.05120754340978949]
	TIME [epoch: 9.05 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0729902651589325		[learning rate: 0.0020348]
	Learning Rate: 0.00203482
	LOSS [training: 0.0729902651589325 | validation: 0.08803945677813851]
	TIME [epoch: 9.06 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22667735223891444		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.22667735223891444 | validation: 0.17641607611523796]
	TIME [epoch: 9.05 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12131126298525399		[learning rate: 0.002025]
	Learning Rate: 0.00202498
	LOSS [training: 0.12131126298525399 | validation: 0.06879029322286115]
	TIME [epoch: 9.04 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09508195842669447		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.09508195842669447 | validation: 0.05562812188863227]
	TIME [epoch: 9.04 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08781016503019208		[learning rate: 0.0020152]
	Learning Rate: 0.00201519
	LOSS [training: 0.08781016503019208 | validation: 0.11731446464747652]
	TIME [epoch: 9.06 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13755207747783055		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.13755207747783055 | validation: 0.06488102444303928]
	TIME [epoch: 9.04 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07291454384021359		[learning rate: 0.0020054]
	Learning Rate: 0.00200544
	LOSS [training: 0.07291454384021359 | validation: 0.05034054170978673]
	TIME [epoch: 9.05 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06530867317131712		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.06530867317131712 | validation: 0.0531161142457038]
	TIME [epoch: 9.05 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050294560278522235		[learning rate: 0.0019957]
	Learning Rate: 0.00199575
	LOSS [training: 0.050294560278522235 | validation: 0.042186723264178494]
	TIME [epoch: 9.04 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05713720536546828		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.05713720536546828 | validation: 0.07449596999270244]
	TIME [epoch: 9.06 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06953915475373679		[learning rate: 0.0019861]
	Learning Rate: 0.00198609
	LOSS [training: 0.06953915475373679 | validation: 0.05076788349619217]
	TIME [epoch: 9.04 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08151557621425815		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.08151557621425815 | validation: 0.0664447413908514]
	TIME [epoch: 9.04 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06017016580177355		[learning rate: 0.0019765]
	Learning Rate: 0.00197649
	LOSS [training: 0.06017016580177355 | validation: 0.060530497823183343]
	TIME [epoch: 9.04 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0790372218118302		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.0790372218118302 | validation: 0.04436036995090629]
	TIME [epoch: 9.05 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07220846894909075		[learning rate: 0.0019669]
	Learning Rate: 0.00196693
	LOSS [training: 0.07220846894909075 | validation: 0.0936920389019818]
	TIME [epoch: 9.07 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07803150871648531		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.07803150871648531 | validation: 0.059500236314946366]
	TIME [epoch: 9.04 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06573395226014812		[learning rate: 0.0019574]
	Learning Rate: 0.00195742
	LOSS [training: 0.06573395226014812 | validation: 0.05159030309741948]
	TIME [epoch: 9.04 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08553963903951493		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.08553963903951493 | validation: 0.06525541544977538]
	TIME [epoch: 9.05 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0665069918699258		[learning rate: 0.001948]
	Learning Rate: 0.00194796
	LOSS [training: 0.0665069918699258 | validation: 0.034726734957857386]
	TIME [epoch: 9.06 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06753002018504262		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.06753002018504262 | validation: 0.048728153610008956]
	TIME [epoch: 9.05 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05768177994158476		[learning rate: 0.0019385]
	Learning Rate: 0.00193854
	LOSS [training: 0.05768177994158476 | validation: 0.06235358452645924]
	TIME [epoch: 9.05 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07660684091291202		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.07660684091291202 | validation: 0.060729545430597526]
	TIME [epoch: 9.05 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05085944704054814		[learning rate: 0.0019292]
	Learning Rate: 0.00192916
	LOSS [training: 0.05085944704054814 | validation: 0.03315362121513505]
	TIME [epoch: 9.04 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04288652570685018		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.04288652570685018 | validation: 0.02500036535984617]
	TIME [epoch: 9.05 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03343115234008792		[learning rate: 0.0019198]
	Learning Rate: 0.00191983
	LOSS [training: 0.03343115234008792 | validation: 0.04141268016790607]
	TIME [epoch: 9.04 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05697386602457323		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.05697386602457323 | validation: 0.04746059125065196]
	TIME [epoch: 9.04 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07535621334301142		[learning rate: 0.0019105]
	Learning Rate: 0.00191055
	LOSS [training: 0.07535621334301142 | validation: 0.05348719490614766]
	TIME [epoch: 9.05 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05103405142692739		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.05103405142692739 | validation: 0.05369526922217911]
	TIME [epoch: 9.06 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0663539984897441		[learning rate: 0.0019013]
	Learning Rate: 0.00190131
	LOSS [training: 0.0663539984897441 | validation: 0.03768357602908039]
	TIME [epoch: 9.04 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06344562039526878		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.06344562039526878 | validation: 0.03247046041982182]
	TIME [epoch: 9.05 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06066236093623763		[learning rate: 0.0018921]
	Learning Rate: 0.00189211
	LOSS [training: 0.06066236093623763 | validation: 0.053273003887279444]
	TIME [epoch: 9.04 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06935989288982834		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.06935989288982834 | validation: 0.07067882629868838]
	TIME [epoch: 9.05 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046200345346334624		[learning rate: 0.001883]
	Learning Rate: 0.00188296
	LOSS [training: 0.046200345346334624 | validation: 0.02472286026875776]
	TIME [epoch: 9.07 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05957713499758741		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.05957713499758741 | validation: 0.0480604077412126]
	TIME [epoch: 9.05 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05852984219521721		[learning rate: 0.0018739]
	Learning Rate: 0.00187386
	LOSS [training: 0.05852984219521721 | validation: 0.018189104030617825]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_791.pth
	Model improved!!!
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06539879621715941		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.06539879621715941 | validation: 0.0534257275216848]
	TIME [epoch: 9.04 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05179343853739223		[learning rate: 0.0018648]
	Learning Rate: 0.0018648
	LOSS [training: 0.05179343853739223 | validation: 0.04325460816337829]
	TIME [epoch: 9.05 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06498726472059395		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.06498726472059395 | validation: 0.04277675465027608]
	TIME [epoch: 9.05 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0971946843533327		[learning rate: 0.0018558]
	Learning Rate: 0.00185578
	LOSS [training: 0.0971946843533327 | validation: 0.07184785413690511]
	TIME [epoch: 9.03 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08957418377337131		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.08957418377337131 | validation: 0.1028858195945157]
	TIME [epoch: 9.04 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08005229321701542		[learning rate: 0.0018468]
	Learning Rate: 0.0018468
	LOSS [training: 0.08005229321701542 | validation: 0.04727596318227008]
	TIME [epoch: 9.04 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08692607517505857		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.08692607517505857 | validation: 0.05420997389689297]
	TIME [epoch: 9.06 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06245184792314383		[learning rate: 0.0018379]
	Learning Rate: 0.00183787
	LOSS [training: 0.06245184792314383 | validation: 0.05181315070435771]
	TIME [epoch: 9.04 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07486307518919631		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.07486307518919631 | validation: 0.061088200911114984]
	TIME [epoch: 9.04 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07405595834830989		[learning rate: 0.001829]
	Learning Rate: 0.00182899
	LOSS [training: 0.07405595834830989 | validation: 0.045443656321577375]
	TIME [epoch: 9.04 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05710061832958566		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.05710061832958566 | validation: 0.04037117594664737]
	TIME [epoch: 9.05 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05172102055520846		[learning rate: 0.0018201]
	Learning Rate: 0.00182014
	LOSS [training: 0.05172102055520846 | validation: 0.045296240823386805]
	TIME [epoch: 9.07 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06110710689911032		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.06110710689911032 | validation: 0.044183660620653264]
	TIME [epoch: 9.06 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04639765392323082		[learning rate: 0.0018113]
	Learning Rate: 0.00181134
	LOSS [training: 0.04639765392323082 | validation: 0.018876378398829902]
	TIME [epoch: 9.04 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05797192694769121		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.05797192694769121 | validation: 0.038268734933580906]
	TIME [epoch: 9.04 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05379228007261303		[learning rate: 0.0018026]
	Learning Rate: 0.00180258
	LOSS [training: 0.05379228007261303 | validation: 0.04660133999410357]
	TIME [epoch: 9.06 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054694084924580756		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.054694084924580756 | validation: 0.037780495800349895]
	TIME [epoch: 9.04 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05403539455041632		[learning rate: 0.0017939]
	Learning Rate: 0.00179386
	LOSS [training: 0.05403539455041632 | validation: 0.05691223952079413]
	TIME [epoch: 9.05 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06445657020249575		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.06445657020249575 | validation: 0.03512437546496388]
	TIME [epoch: 9.05 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05152672426573578		[learning rate: 0.0017852]
	Learning Rate: 0.00178519
	LOSS [training: 0.05152672426573578 | validation: 0.02223266833412096]
	TIME [epoch: 9.05 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0587112846302079		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.0587112846302079 | validation: 0.04118485586838172]
	TIME [epoch: 9.06 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05708599601361074		[learning rate: 0.0017766]
	Learning Rate: 0.00177656
	LOSS [training: 0.05708599601361074 | validation: 0.028800781413868246]
	TIME [epoch: 9.04 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057213082751634094		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.057213082751634094 | validation: 0.04584773682022111]
	TIME [epoch: 9.04 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052257180646404666		[learning rate: 0.001768]
	Learning Rate: 0.00176797
	LOSS [training: 0.052257180646404666 | validation: 0.04841946046492538]
	TIME [epoch: 9.04 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053311262900216184		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.053311262900216184 | validation: 0.032643721325953425]
	TIME [epoch: 9.07 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06062824189945883		[learning rate: 0.0017594]
	Learning Rate: 0.00175942
	LOSS [training: 0.06062824189945883 | validation: 0.021167150101166994]
	TIME [epoch: 9.05 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05834260247200605		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.05834260247200605 | validation: 0.03818051408140253]
	TIME [epoch: 9.04 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04404740335468692		[learning rate: 0.0017509]
	Learning Rate: 0.00175091
	LOSS [training: 0.04404740335468692 | validation: 0.03224814064708606]
	TIME [epoch: 9.04 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04691416017761238		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.04691416017761238 | validation: 0.021227465414590745]
	TIME [epoch: 9.04 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05613154403261448		[learning rate: 0.0017424]
	Learning Rate: 0.00174244
	LOSS [training: 0.05613154403261448 | validation: 0.037517054396283375]
	TIME [epoch: 9.06 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07698787583860203		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.07698787583860203 | validation: 0.026536203413531603]
	TIME [epoch: 9.04 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06524833022581397		[learning rate: 0.001734]
	Learning Rate: 0.00173401
	LOSS [training: 0.06524833022581397 | validation: 0.055463269927221205]
	TIME [epoch: 9.04 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08761765502296662		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.08761765502296662 | validation: 0.07486433229971748]
	TIME [epoch: 9.04 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20403545882115384		[learning rate: 0.0017256]
	Learning Rate: 0.00172563
	LOSS [training: 0.20403545882115384 | validation: 0.2735484588554393]
	TIME [epoch: 9.04 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18398729523422444		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.18398729523422444 | validation: 0.08849190943056363]
	TIME [epoch: 9.06 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0895233150082763		[learning rate: 0.0017173]
	Learning Rate: 0.00171728
	LOSS [training: 0.0895233150082763 | validation: 0.09676128738619491]
	TIME [epoch: 9.05 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1004765136298947		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.1004765136298947 | validation: 0.0727142367791446]
	TIME [epoch: 9.05 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08215435893356379		[learning rate: 0.001709]
	Learning Rate: 0.00170898
	LOSS [training: 0.08215435893356379 | validation: 0.03363174393308505]
	TIME [epoch: 9.05 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049725499160331185		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.049725499160331185 | validation: 0.0263292801075871]
	TIME [epoch: 9.06 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06087164367028993		[learning rate: 0.0017007]
	Learning Rate: 0.00170072
	LOSS [training: 0.06087164367028993 | validation: 0.035217985880584626]
	TIME [epoch: 9.05 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06363246863051653		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.06363246863051653 | validation: 0.021365702543968378]
	TIME [epoch: 9.04 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04274483088433338		[learning rate: 0.0016925]
	Learning Rate: 0.00169249
	LOSS [training: 0.04274483088433338 | validation: 0.030202889597996538]
	TIME [epoch: 9.04 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06667146644487204		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.06667146644487204 | validation: 0.03981033148964396]
	TIME [epoch: 9.04 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06303859158086882		[learning rate: 0.0016843]
	Learning Rate: 0.00168431
	LOSS [training: 0.06303859158086882 | validation: 0.022668338228227343]
	TIME [epoch: 9.06 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04411021663712343		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.04411021663712343 | validation: 0.06838762665810341]
	TIME [epoch: 9.04 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055975383738366455		[learning rate: 0.0016762]
	Learning Rate: 0.00167616
	LOSS [training: 0.055975383738366455 | validation: 0.023120853363427302]
	TIME [epoch: 9.04 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09121797587633314		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.09121797587633314 | validation: 0.03876059669880914]
	TIME [epoch: 9.04 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03980931871231265		[learning rate: 0.0016681]
	Learning Rate: 0.00166806
	LOSS [training: 0.03980931871231265 | validation: 0.016944283973751487]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_839.pth
	Model improved!!!
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04073667320611571		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.04073667320611571 | validation: 0.05660257779279691]
	TIME [epoch: 9.05 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10906789898620713		[learning rate: 0.00166]
	Learning Rate: 0.00165999
	LOSS [training: 0.10906789898620713 | validation: 0.04824362804446253]
	TIME [epoch: 9.04 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04205709108953197		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.04205709108953197 | validation: 0.019850266870435007]
	TIME [epoch: 9.04 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04058902936482215		[learning rate: 0.001652]
	Learning Rate: 0.00165196
	LOSS [training: 0.04058902936482215 | validation: 0.030341073073968362]
	TIME [epoch: 9.04 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04856735180137243		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.04856735180137243 | validation: 0.06866106654947063]
	TIME [epoch: 9.06 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08940386596897558		[learning rate: 0.001644]
	Learning Rate: 0.00164397
	LOSS [training: 0.08940386596897558 | validation: 0.10977715715924194]
	TIME [epoch: 9.04 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08188961522241732		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.08188961522241732 | validation: 0.037276702140560704]
	TIME [epoch: 9.04 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05364015779458744		[learning rate: 0.001636]
	Learning Rate: 0.00163602
	LOSS [training: 0.05364015779458744 | validation: 0.03104269242807632]
	TIME [epoch: 9.04 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036918626747332144		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.036918626747332144 | validation: 0.034906660959064494]
	TIME [epoch: 9.05 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04937183061808027		[learning rate: 0.0016281]
	Learning Rate: 0.00162811
	LOSS [training: 0.04937183061808027 | validation: 0.07336627410127851]
	TIME [epoch: 9.05 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036051886008178644		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.036051886008178644 | validation: 0.023190996262809453]
	TIME [epoch: 9.04 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032598778554620456		[learning rate: 0.0016202]
	Learning Rate: 0.00162024
	LOSS [training: 0.032598778554620456 | validation: 0.02898908100020557]
	TIME [epoch: 9.03 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06769778153035706		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.06769778153035706 | validation: 0.0750473336382953]
	TIME [epoch: 9.04 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04515639930929391		[learning rate: 0.0016124]
	Learning Rate: 0.0016124
	LOSS [training: 0.04515639930929391 | validation: 0.026376562372878526]
	TIME [epoch: 9.06 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035458253775720996		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.035458253775720996 | validation: 0.027794429453074712]
	TIME [epoch: 9.04 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030704223211566295		[learning rate: 0.0016046]
	Learning Rate: 0.00160461
	LOSS [training: 0.030704223211566295 | validation: 0.05116032184578935]
	TIME [epoch: 9.04 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04233138708189155		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.04233138708189155 | validation: 0.027519929155240652]
	TIME [epoch: 9.04 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0481576691599573		[learning rate: 0.0015968]
	Learning Rate: 0.00159685
	LOSS [training: 0.0481576691599573 | validation: 0.04119714691327073]
	TIME [epoch: 9.05 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060771214300927266		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.060771214300927266 | validation: 0.0521714710885494]
	TIME [epoch: 9.06 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07045046037185042		[learning rate: 0.0015891]
	Learning Rate: 0.00158912
	LOSS [training: 0.07045046037185042 | validation: 0.04470008385007386]
	TIME [epoch: 9.04 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05105446139521709		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.05105446139521709 | validation: 0.05978272891037232]
	TIME [epoch: 9.04 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06043565018761578		[learning rate: 0.0015814]
	Learning Rate: 0.00158144
	LOSS [training: 0.06043565018761578 | validation: 0.04251241666160783]
	TIME [epoch: 9.04 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055020593752136485		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.055020593752136485 | validation: 0.04533707567560441]
	TIME [epoch: 9.06 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05329264994054066		[learning rate: 0.0015738]
	Learning Rate: 0.00157379
	LOSS [training: 0.05329264994054066 | validation: 0.04039278262935874]
	TIME [epoch: 9.05 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06087429535846428		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.06087429535846428 | validation: 0.05293221274184838]
	TIME [epoch: 9.04 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042007985876772964		[learning rate: 0.0015662]
	Learning Rate: 0.00156618
	LOSS [training: 0.042007985876772964 | validation: 0.02917547663836302]
	TIME [epoch: 9.05 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05354094161861821		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.05354094161861821 | validation: 0.029054316833248918]
	TIME [epoch: 9.04 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036953554026836484		[learning rate: 0.0015586]
	Learning Rate: 0.00155861
	LOSS [training: 0.036953554026836484 | validation: 0.020808655682634916]
	TIME [epoch: 9.06 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039057579644938896		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.039057579644938896 | validation: 0.03955848882493525]
	TIME [epoch: 9.06 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04326068167301624		[learning rate: 0.0015511]
	Learning Rate: 0.00155107
	LOSS [training: 0.04326068167301624 | validation: 0.03356388542356113]
	TIME [epoch: 9.06 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05159417962845895		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.05159417962845895 | validation: 0.03231444279009414]
	TIME [epoch: 9.06 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052415094115523496		[learning rate: 0.0015436]
	Learning Rate: 0.00154357
	LOSS [training: 0.052415094115523496 | validation: 0.028913969971774027]
	TIME [epoch: 9.06 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06426295881534888		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.06426295881534888 | validation: 0.047787987464274866]
	TIME [epoch: 9.05 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06818975080465753		[learning rate: 0.0015361]
	Learning Rate: 0.00153611
	LOSS [training: 0.06818975080465753 | validation: 0.04837588099946334]
	TIME [epoch: 9.04 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06281559879069257		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.06281559879069257 | validation: 0.030759248173915864]
	TIME [epoch: 9.05 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04952883011404169		[learning rate: 0.0015287]
	Learning Rate: 0.00152868
	LOSS [training: 0.04952883011404169 | validation: 0.057425326879232186]
	TIME [epoch: 9.05 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04795525128309473		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.04795525128309473 | validation: 0.03415627961162252]
	TIME [epoch: 9.06 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04613362014095902		[learning rate: 0.0015213]
	Learning Rate: 0.00152128
	LOSS [training: 0.04613362014095902 | validation: 0.035347954315371716]
	TIME [epoch: 9.05 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0595230784882691		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.0595230784882691 | validation: 0.046470206387548396]
	TIME [epoch: 9.04 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0423875161653656		[learning rate: 0.0015139]
	Learning Rate: 0.00151393
	LOSS [training: 0.0423875161653656 | validation: 0.038317088508913244]
	TIME [epoch: 9.04 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03872152605088763		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.03872152605088763 | validation: 0.008136968244426857]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_880.pth
	Model improved!!!
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04491494149126521		[learning rate: 0.0015066]
	Learning Rate: 0.00150661
	LOSS [training: 0.04491494149126521 | validation: 0.029014515508860757]
	TIME [epoch: 9.06 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045170775625050986		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.045170775625050986 | validation: 0.05580207905787486]
	TIME [epoch: 9.05 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07773388393980471		[learning rate: 0.0014993]
	Learning Rate: 0.00149932
	LOSS [training: 0.07773388393980471 | validation: 0.04605515913174026]
	TIME [epoch: 9.05 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051010644167354624		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.051010644167354624 | validation: 0.0621871144313481]
	TIME [epoch: 9.05 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04606414613142503		[learning rate: 0.0014921]
	Learning Rate: 0.00149207
	LOSS [training: 0.04606414613142503 | validation: 0.017417456705357985]
	TIME [epoch: 9.07 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04145848835420631		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.04145848835420631 | validation: 0.04645946515677612]
	TIME [epoch: 9.04 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04890518343579055		[learning rate: 0.0014849]
	Learning Rate: 0.00148486
	LOSS [training: 0.04890518343579055 | validation: 0.018923060817068262]
	TIME [epoch: 9.05 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03486482575626572		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.03486482575626572 | validation: 0.03753365646091497]
	TIME [epoch: 9.04 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041757285558426935		[learning rate: 0.0014777]
	Learning Rate: 0.00147768
	LOSS [training: 0.041757285558426935 | validation: 0.0461485053640556]
	TIME [epoch: 9.04 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04769737089687667		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.04769737089687667 | validation: 0.04353357804357673]
	TIME [epoch: 9.05 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038057553299743356		[learning rate: 0.0014705]
	Learning Rate: 0.00147053
	LOSS [training: 0.038057553299743356 | validation: 0.01989365392059768]
	TIME [epoch: 9.03 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03845444820917051		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.03845444820917051 | validation: 0.0281067263815065]
	TIME [epoch: 9.04 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034652630797765205		[learning rate: 0.0014634]
	Learning Rate: 0.00146342
	LOSS [training: 0.034652630797765205 | validation: 0.036144609316467305]
	TIME [epoch: 9.04 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039822671224473215		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.039822671224473215 | validation: 0.02041527192916926]
	TIME [epoch: 9.06 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029172438901078235		[learning rate: 0.0014563]
	Learning Rate: 0.00145634
	LOSS [training: 0.029172438901078235 | validation: 0.02647685050037671]
	TIME [epoch: 9.05 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036205315782933525		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.036205315782933525 | validation: 0.022492057089788284]
	TIME [epoch: 9.04 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04118562160128998		[learning rate: 0.0014493]
	Learning Rate: 0.0014493
	LOSS [training: 0.04118562160128998 | validation: 0.021411726922365457]
	TIME [epoch: 9.04 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03363326365937901		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.03363326365937901 | validation: 0.024451759528970475]
	TIME [epoch: 9.04 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03168162820151979		[learning rate: 0.0014423]
	Learning Rate: 0.00144229
	LOSS [training: 0.03168162820151979 | validation: 0.05217846898465636]
	TIME [epoch: 9.06 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04547588047600222		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.04547588047600222 | validation: 0.06310455761433817]
	TIME [epoch: 9.04 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04339040596608719		[learning rate: 0.0014353]
	Learning Rate: 0.00143532
	LOSS [training: 0.04339040596608719 | validation: 0.018691598344112426]
	TIME [epoch: 9.04 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0406263243753114		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.0406263243753114 | validation: 0.02161670979947338]
	TIME [epoch: 9.04 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06324410923168665		[learning rate: 0.0014284]
	Learning Rate: 0.00142837
	LOSS [training: 0.06324410923168665 | validation: 0.06701134448956911]
	TIME [epoch: 9.06 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057970293664117656		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.057970293664117656 | validation: 0.039276728299237534]
	TIME [epoch: 9.04 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0537219905472943		[learning rate: 0.0014215]
	Learning Rate: 0.00142147
	LOSS [training: 0.0537219905472943 | validation: 0.06830916988493775]
	TIME [epoch: 9.04 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.078470303028895		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.078470303028895 | validation: 0.04319149091397106]
	TIME [epoch: 9.04 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054542808784890276		[learning rate: 0.0014146]
	Learning Rate: 0.00141459
	LOSS [training: 0.054542808784890276 | validation: 0.045789178146927]
	TIME [epoch: 9.04 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04543459556335882		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.04543459556335882 | validation: 0.03944584313894766]
	TIME [epoch: 9.07 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04820327453480376		[learning rate: 0.0014078]
	Learning Rate: 0.00140775
	LOSS [training: 0.04820327453480376 | validation: 0.025791593788709544]
	TIME [epoch: 9.05 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05594958143868443		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.05594958143868443 | validation: 0.05314901891070279]
	TIME [epoch: 9.05 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05660458078521928		[learning rate: 0.0014009]
	Learning Rate: 0.00140094
	LOSS [training: 0.05660458078521928 | validation: 0.03514683593350561]
	TIME [epoch: 9.04 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04509430703222483		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.04509430703222483 | validation: 0.009939939111747072]
	TIME [epoch: 9.04 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037773258399638764		[learning rate: 0.0013942]
	Learning Rate: 0.00139417
	LOSS [training: 0.037773258399638764 | validation: 0.03724551782068446]
	TIME [epoch: 9.08 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05638770181835888		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.05638770181835888 | validation: 0.03200213660047543]
	TIME [epoch: 9.04 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04378696686731627		[learning rate: 0.0013874]
	Learning Rate: 0.00138743
	LOSS [training: 0.04378696686731627 | validation: 0.026213081845721017]
	TIME [epoch: 9.05 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03389543013154003		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.03389543013154003 | validation: 0.03260840604168274]
	TIME [epoch: 9.05 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047409035129345786		[learning rate: 0.0013807]
	Learning Rate: 0.00138072
	LOSS [training: 0.047409035129345786 | validation: 0.03917656779083185]
	TIME [epoch: 9.07 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04407164883178284		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.04407164883178284 | validation: 0.05505217828298173]
	TIME [epoch: 9.05 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04408790502061406		[learning rate: 0.001374]
	Learning Rate: 0.00137404
	LOSS [training: 0.04408790502061406 | validation: 0.021702834387222522]
	TIME [epoch: 9.04 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0569940766327651		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.0569940766327651 | validation: 0.08917930312719019]
	TIME [epoch: 9.05 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10349636960164714		[learning rate: 0.0013674]
	Learning Rate: 0.0013674
	LOSS [training: 0.10349636960164714 | validation: 0.03444997186678092]
	TIME [epoch: 9.06 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03816212125561755		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.03816212125561755 | validation: 0.01027469314399511]
	TIME [epoch: 9.08 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033291096773778416		[learning rate: 0.0013608]
	Learning Rate: 0.00136078
	LOSS [training: 0.033291096773778416 | validation: 0.03172127772577866]
	TIME [epoch: 9.05 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03315473993721798		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.03315473993721798 | validation: 0.005411299202289379]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_924.pth
	Model improved!!!
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02479405574337513		[learning rate: 0.0013542]
	Learning Rate: 0.0013542
	LOSS [training: 0.02479405574337513 | validation: 0.014852429000212622]
	TIME [epoch: 9.06 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04237306039259338		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.04237306039259338 | validation: 0.03169697814323847]
	TIME [epoch: 9.08 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10236643947576134		[learning rate: 0.0013477]
	Learning Rate: 0.00134766
	LOSS [training: 0.10236643947576134 | validation: 0.06762206035888628]
	TIME [epoch: 9.07 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08592134238397835		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.08592134238397835 | validation: 0.06743664138922956]
	TIME [epoch: 9.07 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0663051433420792		[learning rate: 0.0013411]
	Learning Rate: 0.00134114
	LOSS [training: 0.0663051433420792 | validation: 0.027277318979512924]
	TIME [epoch: 9.06 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049440710763277114		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.049440710763277114 | validation: 0.048467770258482784]
	TIME [epoch: 9.07 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06879485285857974		[learning rate: 0.0013347]
	Learning Rate: 0.00133465
	LOSS [training: 0.06879485285857974 | validation: 0.07051999261196283]
	TIME [epoch: 9.09 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06694337193838908		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.06694337193838908 | validation: 0.0496598893932233]
	TIME [epoch: 9.07 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07538884071885404		[learning rate: 0.0013282]
	Learning Rate: 0.0013282
	LOSS [training: 0.07538884071885404 | validation: 0.07249084635215522]
	TIME [epoch: 9.07 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09077432015298267		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.09077432015298267 | validation: 0.05051717344243252]
	TIME [epoch: 9.07 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048671940122404035		[learning rate: 0.0013218]
	Learning Rate: 0.00132178
	LOSS [training: 0.048671940122404035 | validation: 0.04409923404048516]
	TIME [epoch: 9.09 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033725323325848336		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.033725323325848336 | validation: 0.025530446705507484]
	TIME [epoch: 9.08 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0341490562334064		[learning rate: 0.0013154]
	Learning Rate: 0.00131538
	LOSS [training: 0.0341490562334064 | validation: 0.03815678619795744]
	TIME [epoch: 9.07 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04359742114404077		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.04359742114404077 | validation: 0.007034870571002046]
	TIME [epoch: 9.07 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033510111116027155		[learning rate: 0.001309]
	Learning Rate: 0.00130902
	LOSS [training: 0.033510111116027155 | validation: 0.028563060416220615]
	TIME [epoch: 9.07 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034801355717699864		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.034801355717699864 | validation: 0.015013936244505578]
	TIME [epoch: 9.09 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0340648475231236		[learning rate: 0.0013027]
	Learning Rate: 0.00130269
	LOSS [training: 0.0340648475231236 | validation: 0.018587119082570436]
	TIME [epoch: 9.07 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035385598976260396		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.035385598976260396 | validation: 0.027318535911636178]
	TIME [epoch: 9.07 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041826239921707		[learning rate: 0.0012964]
	Learning Rate: 0.00129639
	LOSS [training: 0.041826239921707 | validation: 0.019714692149100294]
	TIME [epoch: 9.07 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03699519867860501		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.03699519867860501 | validation: 0.022953235176574768]
	TIME [epoch: 9.08 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04585890322341723		[learning rate: 0.0012901]
	Learning Rate: 0.00129012
	LOSS [training: 0.04585890322341723 | validation: 0.043271614205322884]
	TIME [epoch: 9.07 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10466696409894383		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.10466696409894383 | validation: 0.13818705071899426]
	TIME [epoch: 9.07 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11972684070537391		[learning rate: 0.0012839]
	Learning Rate: 0.00128389
	LOSS [training: 0.11972684070537391 | validation: 0.08111020174764422]
	TIME [epoch: 9.06 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09309030710779906		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.09309030710779906 | validation: 0.07017828566099389]
	TIME [epoch: 9.07 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0835454107621051		[learning rate: 0.0012777]
	Learning Rate: 0.00127768
	LOSS [training: 0.0835454107621051 | validation: 0.05703444203868753]
	TIME [epoch: 9.09 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062194688186000116		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.062194688186000116 | validation: 0.04514890834909764]
	TIME [epoch: 9.07 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05583673086937245		[learning rate: 0.0012715]
	Learning Rate: 0.0012715
	LOSS [training: 0.05583673086937245 | validation: 0.04786504071175794]
	TIME [epoch: 9.06 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07055367486082713		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.07055367486082713 | validation: 0.03832969758234171]
	TIME [epoch: 9.06 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06301673880670863		[learning rate: 0.0012653]
	Learning Rate: 0.00126535
	LOSS [training: 0.06301673880670863 | validation: 0.029505722502185246]
	TIME [epoch: 9.06 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08306704612051832		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.08306704612051832 | validation: 0.14730062751832007]
	TIME [epoch: 9.08 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1299849703363769		[learning rate: 0.0012592]
	Learning Rate: 0.00125923
	LOSS [training: 0.1299849703363769 | validation: 0.057471238733694155]
	TIME [epoch: 9.06 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15901917396904106		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.15901917396904106 | validation: 0.25106056528769505]
	TIME [epoch: 9.06 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3843510763586918		[learning rate: 0.0012531]
	Learning Rate: 0.00125314
	LOSS [training: 0.3843510763586918 | validation: 0.2318232994742107]
	TIME [epoch: 9.06 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2617494080497201		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.2617494080497201 | validation: 0.19940589179085325]
	TIME [epoch: 9.08 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16183978404147473		[learning rate: 0.0012471]
	Learning Rate: 0.00124708
	LOSS [training: 0.16183978404147473 | validation: 0.10791427745709119]
	TIME [epoch: 9.07 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11373315317786674		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.11373315317786674 | validation: 0.12427524922152888]
	TIME [epoch: 9.05 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1696005772008066		[learning rate: 0.0012411]
	Learning Rate: 0.00124105
	LOSS [training: 0.1696005772008066 | validation: 0.11258539777926672]
	TIME [epoch: 9.06 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10850263694127868		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.10850263694127868 | validation: 0.06834528166054775]
	TIME [epoch: 9.06 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09378393188422876		[learning rate: 0.001235]
	Learning Rate: 0.00123505
	LOSS [training: 0.09378393188422876 | validation: 0.049830619691987]
	TIME [epoch: 9.08 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06754233770131214		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.06754233770131214 | validation: 0.0702313602986489]
	TIME [epoch: 9.06 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08282381078349235		[learning rate: 0.0012291]
	Learning Rate: 0.00122908
	LOSS [training: 0.08282381078349235 | validation: 0.047127064309962316]
	TIME [epoch: 9.06 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05094629553481245		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.05094629553481245 | validation: 0.08110967636832184]
	TIME [epoch: 9.06 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0709004084058069		[learning rate: 0.0012231]
	Learning Rate: 0.00122313
	LOSS [training: 0.0709004084058069 | validation: 0.057752650292357446]
	TIME [epoch: 9.08 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07883352803525348		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.07883352803525348 | validation: 0.08520226257559116]
	TIME [epoch: 9.06 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15055046230647048		[learning rate: 0.0012172]
	Learning Rate: 0.00121722
	LOSS [training: 0.15055046230647048 | validation: 0.10784071378186945]
	TIME [epoch: 9.06 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14860585304193275		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.14860585304193275 | validation: 0.12081250403805999]
	TIME [epoch: 9.05 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09711725579548436		[learning rate: 0.0012113]
	Learning Rate: 0.00121133
	LOSS [training: 0.09711725579548436 | validation: 0.07393397024820045]
	TIME [epoch: 9.06 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12958616978077317		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.12958616978077317 | validation: 0.11814975331933929]
	TIME [epoch: 9.08 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14018769403195114		[learning rate: 0.0012055]
	Learning Rate: 0.00120547
	LOSS [training: 0.14018769403195114 | validation: 0.1271064656688909]
	TIME [epoch: 9.07 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18694054364485185		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.18694054364485185 | validation: 0.2203365540619907]
	TIME [epoch: 9.08 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21659855792414792		[learning rate: 0.0011996]
	Learning Rate: 0.00119964
	LOSS [training: 0.21659855792414792 | validation: 0.1279284576639892]
	TIME [epoch: 9.07 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1499261439006318		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.1499261439006318 | validation: 0.13668283738179304]
	TIME [epoch: 9.08 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13295634233539547		[learning rate: 0.0011938]
	Learning Rate: 0.00119384
	LOSS [training: 0.13295634233539547 | validation: 0.07827264246588259]
	TIME [epoch: 9.08 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10426501016998421		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.10426501016998421 | validation: 0.11261251837937765]
	TIME [epoch: 9.07 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29109511769035856		[learning rate: 0.0011881]
	Learning Rate: 0.00118807
	LOSS [training: 0.29109511769035856 | validation: 0.4061815103837295]
	TIME [epoch: 9.08 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40613914721656325		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.40613914721656325 | validation: 0.26174309472834334]
	TIME [epoch: 9.07 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23904888081747364		[learning rate: 0.0011823]
	Learning Rate: 0.00118232
	LOSS [training: 0.23904888081747364 | validation: 0.2105267221094297]
	TIME [epoch: 9.1 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2690246776762788		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.2690246776762788 | validation: 0.32579815249958444]
	TIME [epoch: 9.08 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.268600926059493		[learning rate: 0.0011766]
	Learning Rate: 0.00117661
	LOSS [training: 0.268600926059493 | validation: 0.21697391414584025]
	TIME [epoch: 9.07 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18831919756021878		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.18831919756021878 | validation: 0.1538595244798906]
	TIME [epoch: 9.08 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2027554888209388		[learning rate: 0.0011709]
	Learning Rate: 0.00117092
	LOSS [training: 0.2027554888209388 | validation: 0.2063403961703082]
	TIME [epoch: 9.07 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.215187479102065		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.215187479102065 | validation: 0.18384107753224532]
	TIME [epoch: 9.1 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2656134026311753		[learning rate: 0.0011653]
	Learning Rate: 0.00116526
	LOSS [training: 0.2656134026311753 | validation: 0.17090129938389506]
	TIME [epoch: 9.08 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1607276070707089		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.1607276070707089 | validation: 0.17586853774353095]
	TIME [epoch: 9.08 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19418919552468666		[learning rate: 0.0011596]
	Learning Rate: 0.00115962
	LOSS [training: 0.19418919552468666 | validation: 0.1876689123968599]
	TIME [epoch: 9.08 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18619283311793247		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.18619283311793247 | validation: 0.11461260907884904]
	TIME [epoch: 9.09 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11621525389006002		[learning rate: 0.001154]
	Learning Rate: 0.00115401
	LOSS [training: 0.11621525389006002 | validation: 0.07719708170266776]
	TIME [epoch: 9.08 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09764101168945313		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.09764101168945313 | validation: 0.06503489257566833]
	TIME [epoch: 9.08 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07162200071467037		[learning rate: 0.0011484]
	Learning Rate: 0.00114843
	LOSS [training: 0.07162200071467037 | validation: 0.0472751538864622]
	TIME [epoch: 9.07 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07167966664056458		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.07167966664056458 | validation: 0.047556691651977345]
	TIME [epoch: 9.07 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05594490258422537		[learning rate: 0.0011429]
	Learning Rate: 0.00114288
	LOSS [training: 0.05594490258422537 | validation: 0.06692002087992104]
	TIME [epoch: 9.09 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07932388766873263		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.07932388766873263 | validation: 0.07334220019487914]
	TIME [epoch: 9.08 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07032031167423698		[learning rate: 0.0011374]
	Learning Rate: 0.00113735
	LOSS [training: 0.07032031167423698 | validation: 0.07532335313116023]
	TIME [epoch: 9.08 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05046041498254925		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.05046041498254925 | validation: 0.03476264243220077]
	TIME [epoch: 9.07 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0355822734609246		[learning rate: 0.0011319]
	Learning Rate: 0.00113185
	LOSS [training: 0.0355822734609246 | validation: 0.02104548167913585]
	TIME [epoch: 9.09 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04138447429526039		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.04138447429526039 | validation: 0.039443116688865285]
	TIME [epoch: 9.09 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05421426253301097		[learning rate: 0.0011264]
	Learning Rate: 0.00112638
	LOSS [training: 0.05421426253301097 | validation: 0.05249845788062457]
	TIME [epoch: 9.08 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04124109532107443		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.04124109532107443 | validation: 0.043436422849081724]
	TIME [epoch: 9.08 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06437700852757441		[learning rate: 0.0011209]
	Learning Rate: 0.00112093
	LOSS [training: 0.06437700852757441 | validation: 0.06573683984472486]
	TIME [epoch: 9.07 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08386281205483057		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.08386281205483057 | validation: 0.052245034867517734]
	TIME [epoch: 9.08 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04496539164212681		[learning rate: 0.0011155]
	Learning Rate: 0.00111551
	LOSS [training: 0.04496539164212681 | validation: 0.03617937262281541]
	TIME [epoch: 9.06 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04786668054657103		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.04786668054657103 | validation: 0.035737714761836785]
	TIME [epoch: 9.06 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05465895433635515		[learning rate: 0.0011101]
	Learning Rate: 0.00111012
	LOSS [training: 0.05465895433635515 | validation: 0.061618857977661576]
	TIME [epoch: 9.06 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08881949722849698		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.08881949722849698 | validation: 0.0768085000592286]
	TIME [epoch: 9.07 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08649974737554145		[learning rate: 0.0011047]
	Learning Rate: 0.00110475
	LOSS [training: 0.08649974737554145 | validation: 0.08139730561707496]
	TIME [epoch: 9.08 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06698400658903009		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.06698400658903009 | validation: 0.03161880377109075]
	TIME [epoch: 9.06 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04660291048733413		[learning rate: 0.0010994]
	Learning Rate: 0.00109941
	LOSS [training: 0.04660291048733413 | validation: 0.03688504123506478]
	TIME [epoch: 9.06 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06201401648221018		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.06201401648221018 | validation: 0.0811195206548419]
	TIME [epoch: 9.06 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09324218565680618		[learning rate: 0.0010941]
	Learning Rate: 0.00109409
	LOSS [training: 0.09324218565680618 | validation: 0.07623041762521476]
	TIME [epoch: 9.09 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06259975008744703		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.06259975008744703 | validation: 0.05701554717514414]
	TIME [epoch: 9.07 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053792077630257874		[learning rate: 0.0010888]
	Learning Rate: 0.0010888
	LOSS [training: 0.053792077630257874 | validation: 0.03887470801109587]
	TIME [epoch: 9.07 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0482364149066047		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.0482364149066047 | validation: 0.03512447919591383]
	TIME [epoch: 9.06 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04427911401418345		[learning rate: 0.0010835]
	Learning Rate: 0.00108353
	LOSS [training: 0.04427911401418345 | validation: 0.07318059357435391]
	TIME [epoch: 9.06 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06932845741884514		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.06932845741884514 | validation: 0.03799744407588888]
	TIME [epoch: 9.08 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05757485687892714		[learning rate: 0.0010783]
	Learning Rate: 0.00107829
	LOSS [training: 0.05757485687892714 | validation: 0.041122746929185064]
	TIME [epoch: 9.07 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05854857208351061		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.05854857208351061 | validation: 0.057513137442739726]
	TIME [epoch: 9.07 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056338094803966454		[learning rate: 0.0010731]
	Learning Rate: 0.00107308
	LOSS [training: 0.056338094803966454 | validation: 0.04678684423658644]
	TIME [epoch: 9.07 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07391199177922206		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.07391199177922206 | validation: 0.06475520657910491]
	TIME [epoch: 9.09 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05639275780087651		[learning rate: 0.0010679]
	Learning Rate: 0.00106789
	LOSS [training: 0.05639275780087651 | validation: 0.04491531671796336]
	TIME [epoch: 9.07 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04230595654959425		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.04230595654959425 | validation: 0.02434169672843085]
	TIME [epoch: 9.07 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04051486894313126		[learning rate: 0.0010627]
	Learning Rate: 0.00106273
	LOSS [training: 0.04051486894313126 | validation: 0.03876624013207661]
	TIME [epoch: 9.07 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04343898935045802		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.04343898935045802 | validation: 0.0250075473381876]
	TIME [epoch: 9.08 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03044502793429905		[learning rate: 0.0010576]
	Learning Rate: 0.00105759
	LOSS [training: 0.03044502793429905 | validation: 0.01877394616593109]
	TIME [epoch: 9.1 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02824509725506149		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.02824509725506149 | validation: 0.018856326432806374]
	TIME [epoch: 9.08 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03549112144110349		[learning rate: 0.0010525]
	Learning Rate: 0.00105247
	LOSS [training: 0.03549112144110349 | validation: 0.03586781108640222]
	TIME [epoch: 9.08 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0480010064238471		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.0480010064238471 | validation: 0.027007902006293508]
	TIME [epoch: 9.07 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03219616959239695		[learning rate: 0.0010474]
	Learning Rate: 0.00104738
	LOSS [training: 0.03219616959239695 | validation: 0.01792779128676767]
	TIME [epoch: 9.09 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03755522092318293		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.03755522092318293 | validation: 0.02572765989694879]
	TIME [epoch: 9.07 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05273662902283753		[learning rate: 0.0010423]
	Learning Rate: 0.00104232
	LOSS [training: 0.05273662902283753 | validation: 0.020985105748714334]
	TIME [epoch: 9.08 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030698263082311116		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.030698263082311116 | validation: 0.015100015429344846]
	TIME [epoch: 9.07 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032404777870749454		[learning rate: 0.0010373]
	Learning Rate: 0.00103728
	LOSS [training: 0.032404777870749454 | validation: 0.01272064146613508]
	TIME [epoch: 9.08 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0317382127290912		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.0317382127290912 | validation: 0.008956462723191727]
	TIME [epoch: 9.09 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03514818709220948		[learning rate: 0.0010323]
	Learning Rate: 0.00103226
	LOSS [training: 0.03514818709220948 | validation: 0.04279929323635005]
	TIME [epoch: 9.07 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02614664894707051		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.02614664894707051 | validation: 0.022793337900361792]
	TIME [epoch: 9.07 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037510923480744404		[learning rate: 0.0010273]
	Learning Rate: 0.00102727
	LOSS [training: 0.037510923480744404 | validation: 0.032675383538458794]
	TIME [epoch: 9.07 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04012248466591802		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.04012248466591802 | validation: 0.020708472397570184]
	TIME [epoch: 9.08 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02543463232035507		[learning rate: 0.0010223]
	Learning Rate: 0.0010223
	LOSS [training: 0.02543463232035507 | validation: 0.006862228072690119]
	TIME [epoch: 9.09 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02607391481444187		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.02607391481444187 | validation: 0.011006833782851505]
	TIME [epoch: 9.08 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024037527582044513		[learning rate: 0.0010174]
	Learning Rate: 0.00101736
	LOSS [training: 0.024037527582044513 | validation: 0.01349739766892028]
	TIME [epoch: 9.07 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022188098276401388		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.022188098276401388 | validation: 0.010151324337590794]
	TIME [epoch: 9.06 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025606718978554953		[learning rate: 0.0010124]
	Learning Rate: 0.00101244
	LOSS [training: 0.025606718978554953 | validation: 0.029080979819321853]
	TIME [epoch: 9.08 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03244412196409037		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.03244412196409037 | validation: 0.018650358870885453]
	TIME [epoch: 9.05 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022741361559063866		[learning rate: 0.0010075]
	Learning Rate: 0.00100754
	LOSS [training: 0.022741361559063866 | validation: 0.03948410681851164]
	TIME [epoch: 9.05 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037604903405680165		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.037604903405680165 | validation: 0.012260966005037406]
	TIME [epoch: 9.06 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030687449742140282		[learning rate: 0.0010027]
	Learning Rate: 0.00100267
	LOSS [training: 0.030687449742140282 | validation: 0.025061184320432035]
	TIME [epoch: 9.05 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0350550108372152		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.0350550108372152 | validation: 0.02089647385085179]
	TIME [epoch: 9.07 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036771094768451876		[learning rate: 0.00099782]
	Learning Rate: 0.000997821
	LOSS [training: 0.036771094768451876 | validation: 0.03447890749343006]
	TIME [epoch: 9.06 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03667884696563146		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.03667884696563146 | validation: 0.030170105731528556]
	TIME [epoch: 9.05 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04013917210440791		[learning rate: 0.000993]
	Learning Rate: 0.000992996
	LOSS [training: 0.04013917210440791 | validation: 0.032337435972906524]
	TIME [epoch: 9.06 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06072502331706142		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.06072502331706142 | validation: 0.06340172806083981]
	TIME [epoch: 9.08 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06893424045871235		[learning rate: 0.00098819]
	Learning Rate: 0.000988194
	LOSS [training: 0.06893424045871235 | validation: 0.046640966665745576]
	TIME [epoch: 9.06 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04654965433367457		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.04654965433367457 | validation: 0.05399765935857278]
	TIME [epoch: 9.05 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04266713633015008		[learning rate: 0.00098341]
	Learning Rate: 0.000983415
	LOSS [training: 0.04266713633015008 | validation: 0.032267837222406226]
	TIME [epoch: 9.06 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025774536761568028		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.025774536761568028 | validation: 0.014970641762889057]
	TIME [epoch: 9.06 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0460586272045334		[learning rate: 0.00097866]
	Learning Rate: 0.000978659
	LOSS [training: 0.0460586272045334 | validation: 0.019295986794045577]
	TIME [epoch: 9.07 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04855072500680006		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 0.04855072500680006 | validation: 0.035809132122887354]
	TIME [epoch: 9.06 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04807284183035953		[learning rate: 0.00097393]
	Learning Rate: 0.000973927
	LOSS [training: 0.04807284183035953 | validation: 0.02161192601240968]
	TIME [epoch: 9.05 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04497025701947784		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.04497025701947784 | validation: 0.03779967936827719]
	TIME [epoch: 9.05 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03051763782152307		[learning rate: 0.00096922]
	Learning Rate: 0.000969217
	LOSS [training: 0.03051763782152307 | validation: 0.01880800533681808]
	TIME [epoch: 9.07 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02621012716056171		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.02621012716056171 | validation: 0.021484329823533117]
	TIME [epoch: 9.05 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026815792364047446		[learning rate: 0.00096453]
	Learning Rate: 0.00096453
	LOSS [training: 0.026815792364047446 | validation: 0.02186472627263816]
	TIME [epoch: 9.05 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03593689593466179		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.03593689593466179 | validation: 0.043761794232740486]
	TIME [epoch: 9.06 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043951903817510345		[learning rate: 0.00095987]
	Learning Rate: 0.000959866
	LOSS [training: 0.043951903817510345 | validation: 0.03754697257050494]
	TIME [epoch: 9.06 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0455062479130986		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.0455062479130986 | validation: 0.01928905655527281]
	TIME [epoch: 9.09 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02746422941736354		[learning rate: 0.00095522]
	Learning Rate: 0.000955224
	LOSS [training: 0.02746422941736354 | validation: 0.014156946115297334]
	TIME [epoch: 9.06 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028573941971706828		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.028573941971706828 | validation: 0.025686428258221553]
	TIME [epoch: 9.05 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02948882913548271		[learning rate: 0.0009506]
	Learning Rate: 0.000950605
	LOSS [training: 0.02948882913548271 | validation: 0.032217581294864]
	TIME [epoch: 9.05 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0570133469580021		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.0570133469580021 | validation: 0.082973162823398]
	TIME [epoch: 9.05 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07938436118460598		[learning rate: 0.00094601]
	Learning Rate: 0.000946008
	LOSS [training: 0.07938436118460598 | validation: 0.05231680184786989]
	TIME [epoch: 9.08 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07237174683532295		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.07237174683532295 | validation: 0.04917817571660671]
	TIME [epoch: 9.05 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04730590696417179		[learning rate: 0.00094143]
	Learning Rate: 0.000941433
	LOSS [training: 0.04730590696417179 | validation: 0.02699163914790488]
	TIME [epoch: 9.06 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03938671230141623		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.03938671230141623 | validation: 0.015575522753342112]
	TIME [epoch: 9.06 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041551638447793145		[learning rate: 0.00093688]
	Learning Rate: 0.00093688
	LOSS [training: 0.041551638447793145 | validation: 0.0510377196703367]
	TIME [epoch: 9.07 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04140257227026095		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.04140257227026095 | validation: 0.029751112858662575]
	TIME [epoch: 9.06 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05856712738400525		[learning rate: 0.00093235]
	Learning Rate: 0.00093235
	LOSS [training: 0.05856712738400525 | validation: 0.04457239087962429]
	TIME [epoch: 9.06 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058155983950076116		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.058155983950076116 | validation: 0.03517614886499093]
	TIME [epoch: 9.06 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02727697173965051		[learning rate: 0.00092784]
	Learning Rate: 0.000927841
	LOSS [training: 0.02727697173965051 | validation: 0.011801722877298889]
	TIME [epoch: 9.06 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026412786556845452		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.026412786556845452 | validation: 0.017510032694736374]
	TIME [epoch: 9.08 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02806849197876205		[learning rate: 0.00092335]
	Learning Rate: 0.000923354
	LOSS [training: 0.02806849197876205 | validation: 0.025554224533923697]
	TIME [epoch: 9.06 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02386527161010289		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.02386527161010289 | validation: 0.021442594873839805]
	TIME [epoch: 9.05 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032729218859333484		[learning rate: 0.00091889]
	Learning Rate: 0.000918889
	LOSS [training: 0.032729218859333484 | validation: 0.0010040382001422238]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_1085.pth
	Model improved!!!
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02610030548436431		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.02610030548436431 | validation: 0.012514490982341534]
	TIME [epoch: 9.07 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02975033128285045		[learning rate: 0.00091445]
	Learning Rate: 0.000914446
	LOSS [training: 0.02975033128285045 | validation: 0.034096980918446276]
	TIME [epoch: 9.06 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024344843713901457		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.024344843713901457 | validation: 0.00622163064334086]
	TIME [epoch: 9.05 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027979547026101153		[learning rate: 0.00091002]
	Learning Rate: 0.000910024
	LOSS [training: 0.027979547026101153 | validation: 0.008563747462077937]
	TIME [epoch: 9.05 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034740821645783154		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.034740821645783154 | validation: 0.023320824514444432]
	TIME [epoch: 9.05 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05154668505025456		[learning rate: 0.00090562]
	Learning Rate: 0.000905623
	LOSS [training: 0.05154668505025456 | validation: 0.04700797692339916]
	TIME [epoch: 9.07 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03719875345958796		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.03719875345958796 | validation: 0.019537178325811717]
	TIME [epoch: 9.05 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027620291544541133		[learning rate: 0.00090124]
	Learning Rate: 0.000901243
	LOSS [training: 0.027620291544541133 | validation: 0.03327361933071314]
	TIME [epoch: 9.05 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04313801610378996		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.04313801610378996 | validation: 0.02579550836316412]
	TIME [epoch: 9.05 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03546383557238959		[learning rate: 0.00089689]
	Learning Rate: 0.000896885
	LOSS [training: 0.03546383557238959 | validation: 0.047806320069600144]
	TIME [epoch: 9.06 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0416604814359378		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.0416604814359378 | validation: 0.025382763773422877]
	TIME [epoch: 9.05 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04745949312870144		[learning rate: 0.00089255]
	Learning Rate: 0.000892548
	LOSS [training: 0.04745949312870144 | validation: 0.04176335963582602]
	TIME [epoch: 9.05 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03757174782530195		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.03757174782530195 | validation: 0.026558664585221523]
	TIME [epoch: 9.05 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05539921624515588		[learning rate: 0.00088823]
	Learning Rate: 0.000888232
	LOSS [training: 0.05539921624515588 | validation: 0.049527543199272606]
	TIME [epoch: 9.05 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03889430022084532		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.03889430022084532 | validation: 0.022741581447878828]
	TIME [epoch: 9.06 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031027236487377978		[learning rate: 0.00088394]
	Learning Rate: 0.000883936
	LOSS [training: 0.031027236487377978 | validation: 0.02835572900652586]
	TIME [epoch: 9.05 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04319848888357895		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.04319848888357895 | validation: 0.04951705029521825]
	TIME [epoch: 9.05 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0450273842683717		[learning rate: 0.00087966]
	Learning Rate: 0.000879662
	LOSS [training: 0.0450273842683717 | validation: 0.03046356403689577]
	TIME [epoch: 9.05 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03807786190604708		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.03807786190604708 | validation: 0.023117262622270672]
	TIME [epoch: 9.05 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04121124255125454		[learning rate: 0.00087541]
	Learning Rate: 0.000875408
	LOSS [training: 0.04121124255125454 | validation: 0.029369526255139545]
	TIME [epoch: 9.06 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03329205371975464		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.03329205371975464 | validation: 0.01735750829757625]
	TIME [epoch: 9.05 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03540981887900878		[learning rate: 0.00087117]
	Learning Rate: 0.000871175
	LOSS [training: 0.03540981887900878 | validation: 0.017160849000653122]
	TIME [epoch: 9.04 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025473477917590203		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.025473477917590203 | validation: 0.008927643208236875]
	TIME [epoch: 9.05 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029817512567760475		[learning rate: 0.00086696]
	Learning Rate: 0.000866962
	LOSS [training: 0.029817512567760475 | validation: 0.016492644165830784]
	TIME [epoch: 9.06 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026501920454596588		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.026501920454596588 | validation: 0.010280181058914685]
	TIME [epoch: 9.05 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027885333559927773		[learning rate: 0.00086277]
	Learning Rate: 0.000862769
	LOSS [training: 0.027885333559927773 | validation: 0.024039191702761725]
	TIME [epoch: 9.05 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03810298906281112		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.03810298906281112 | validation: 0.018724543387754918]
	TIME [epoch: 9.04 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031673660620747265		[learning rate: 0.0008586]
	Learning Rate: 0.000858597
	LOSS [training: 0.031673660620747265 | validation: 0.04163366657156409]
	TIME [epoch: 9.04 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05220286559482327		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.05220286559482327 | validation: 0.05658547338906175]
	TIME [epoch: 9.06 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03839896083134136		[learning rate: 0.00085445]
	Learning Rate: 0.000854445
	LOSS [training: 0.03839896083134136 | validation: 0.01977735204609219]
	TIME [epoch: 9.05 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030828360993865007		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.030828360993865007 | validation: 0.01965772866552573]
	TIME [epoch: 9.05 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03517552344428003		[learning rate: 0.00085031]
	Learning Rate: 0.000850313
	LOSS [training: 0.03517552344428003 | validation: 0.028074874542154286]
	TIME [epoch: 9.04 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035403647260596416		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.035403647260596416 | validation: 0.021655912573357756]
	TIME [epoch: 9.07 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04158713952267599		[learning rate: 0.0008462]
	Learning Rate: 0.000846201
	LOSS [training: 0.04158713952267599 | validation: 0.030538188081676063]
	TIME [epoch: 9.06 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037671781424513655		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.037671781424513655 | validation: 0.017699241085655112]
	TIME [epoch: 9.05 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03249007474021631		[learning rate: 0.00084211]
	Learning Rate: 0.000842109
	LOSS [training: 0.03249007474021631 | validation: 0.025281777072015225]
	TIME [epoch: 9.05 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04674013744575186		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.04674013744575186 | validation: 0.03742270824399743]
	TIME [epoch: 9.05 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04160189033790936		[learning rate: 0.00083804]
	Learning Rate: 0.000838037
	LOSS [training: 0.04160189033790936 | validation: 0.039192377946699414]
	TIME [epoch: 9.08 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03283002227810477		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.03283002227810477 | validation: 0.024179650395622074]
	TIME [epoch: 9.06 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03730923043046887		[learning rate: 0.00083398]
	Learning Rate: 0.000833984
	LOSS [training: 0.03730923043046887 | validation: 0.06551627869063992]
	TIME [epoch: 9.06 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04000477732862849		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.04000477732862849 | validation: 0.020529964714343867]
	TIME [epoch: 9.06 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03983694459647524		[learning rate: 0.00082995]
	Learning Rate: 0.000829951
	LOSS [training: 0.03983694459647524 | validation: 0.028324863960828076]
	TIME [epoch: 9.06 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03904024888215382		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.03904024888215382 | validation: 0.02787317579496938]
	TIME [epoch: 9.05 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039767569899100894		[learning rate: 0.00082594]
	Learning Rate: 0.000825938
	LOSS [training: 0.039767569899100894 | validation: 0.03773931618903305]
	TIME [epoch: 9.04 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030138947882816507		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.030138947882816507 | validation: 0.018260561110509103]
	TIME [epoch: 9.05 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025494659672372723		[learning rate: 0.00082194]
	Learning Rate: 0.000821944
	LOSS [training: 0.025494659672372723 | validation: 0.029082578025030923]
	TIME [epoch: 9.05 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034231644448106655		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.034231644448106655 | validation: 0.029999150441428302]
	TIME [epoch: 9.07 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02938887508090926		[learning rate: 0.00081797]
	Learning Rate: 0.000817969
	LOSS [training: 0.02938887508090926 | validation: 0.012040562101802882]
	TIME [epoch: 9.08 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026114437053326757		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.026114437053326757 | validation: 0.016925398468579954]
	TIME [epoch: 9.07 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0369410481498673		[learning rate: 0.00081401]
	Learning Rate: 0.000814014
	LOSS [training: 0.0369410481498673 | validation: 0.022204045882970123]
	TIME [epoch: 9.07 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03354509644976848		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.03354509644976848 | validation: 0.02335264012871678]
	TIME [epoch: 9.05 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036488071274521285		[learning rate: 0.00081008]
	Learning Rate: 0.000810077
	LOSS [training: 0.036488071274521285 | validation: 0.024989996750888893]
	TIME [epoch: 9.06 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030679790974246474		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.030679790974246474 | validation: 0.014025407280229983]
	TIME [epoch: 9.04 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03194542087630061		[learning rate: 0.00080616]
	Learning Rate: 0.00080616
	LOSS [training: 0.03194542087630061 | validation: 0.020494782603080387]
	TIME [epoch: 9.05 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037138050074169635		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.037138050074169635 | validation: 0.030098033033239505]
	TIME [epoch: 9.04 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03474643165075346		[learning rate: 0.00080226]
	Learning Rate: 0.000802261
	LOSS [training: 0.03474643165075346 | validation: 0.0294691345423339]
	TIME [epoch: 9.07 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029471997319351507		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.029471997319351507 | validation: 0.04633659252025875]
	TIME [epoch: 9.06 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030742277375768002		[learning rate: 0.00079838]
	Learning Rate: 0.000798382
	LOSS [training: 0.030742277375768002 | validation: 0.017559091931661094]
	TIME [epoch: 9.04 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021822027453387804		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.021822027453387804 | validation: 0.014339639561392168]
	TIME [epoch: 9.05 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035219315835440926		[learning rate: 0.00079452]
	Learning Rate: 0.000794521
	LOSS [training: 0.035219315835440926 | validation: 0.01177660909371708]
	TIME [epoch: 9.05 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03681556723650292		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.03681556723650292 | validation: 0.025718866123757456]
	TIME [epoch: 9.08 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043483315921244006		[learning rate: 0.00079068]
	Learning Rate: 0.000790679
	LOSS [training: 0.043483315921244006 | validation: 0.04609635225917427]
	TIME [epoch: 9.07 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04619183848559638		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.04619183848559638 | validation: 0.020502438809698827]
	TIME [epoch: 9.06 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030197011416445513		[learning rate: 0.00078686]
	Learning Rate: 0.000786855
	LOSS [training: 0.030197011416445513 | validation: 0.016569595578001205]
	TIME [epoch: 9.04 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02852314753821187		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.02852314753821187 | validation: 0.01570262009928046]
	TIME [epoch: 9.06 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027515563195725817		[learning rate: 0.00078305]
	Learning Rate: 0.00078305
	LOSS [training: 0.027515563195725817 | validation: 0.009799579737305962]
	TIME [epoch: 9.05 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03226902555743879		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.03226902555743879 | validation: 0.023254990456768217]
	TIME [epoch: 9.04 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025721451614826224		[learning rate: 0.00077926]
	Learning Rate: 0.000779263
	LOSS [training: 0.025721451614826224 | validation: 0.02007569271349309]
	TIME [epoch: 9.04 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023979876219744924		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.023979876219744924 | validation: 0.02451112481640159]
	TIME [epoch: 9.06 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0283908317485759		[learning rate: 0.00077549]
	Learning Rate: 0.000775495
	LOSS [training: 0.0283908317485759 | validation: 0.007407185980451333]
	TIME [epoch: 9.06 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03241027474795234		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.03241027474795234 | validation: 0.020479819851982984]
	TIME [epoch: 9.05 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024227908051090485		[learning rate: 0.00077174]
	Learning Rate: 0.000771745
	LOSS [training: 0.024227908051090485 | validation: 0.025741989775827097]
	TIME [epoch: 9.06 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0314551343006101		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.0314551343006101 | validation: 0.033225060415612725]
	TIME [epoch: 9.05 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027562730404879072		[learning rate: 0.00076801]
	Learning Rate: 0.000768013
	LOSS [training: 0.027562730404879072 | validation: 0.02278891343587974]
	TIME [epoch: 9.07 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024503099031502048		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.024503099031502048 | validation: 0.015743400937451343]
	TIME [epoch: 9.07 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026500577277161715		[learning rate: 0.0007643]
	Learning Rate: 0.000764299
	LOSS [training: 0.026500577277161715 | validation: 0.017650328712018354]
	TIME [epoch: 9.05 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026508420065600485		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.026508420065600485 | validation: 0.01799295359539731]
	TIME [epoch: 9.06 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02825493359701055		[learning rate: 0.0007606]
	Learning Rate: 0.000760603
	LOSS [training: 0.02825493359701055 | validation: 0.02174144009607036]
	TIME [epoch: 9.05 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040204846189958		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.040204846189958 | validation: 0.027526511077906313]
	TIME [epoch: 9.08 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02965830662917295		[learning rate: 0.00075692]
	Learning Rate: 0.000756925
	LOSS [training: 0.02965830662917295 | validation: 0.019195518272142487]
	TIME [epoch: 9.06 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023957759190397457		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.023957759190397457 | validation: 0.01252013329638602]
	TIME [epoch: 9.05 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029716012314386697		[learning rate: 0.00075326]
	Learning Rate: 0.000753264
	LOSS [training: 0.029716012314386697 | validation: 0.039627508309987604]
	TIME [epoch: 9.07 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04946780744113113		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.04946780744113113 | validation: 0.030918932312089975]
	TIME [epoch: 9.06 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03360347430597123		[learning rate: 0.00074962]
	Learning Rate: 0.000749622
	LOSS [training: 0.03360347430597123 | validation: 0.015820891314274676]
	TIME [epoch: 9.08 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021791138127440143		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.021791138127440143 | validation: 0.026586763229593885]
	TIME [epoch: 9.06 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029622170784478107		[learning rate: 0.000746]
	Learning Rate: 0.000745997
	LOSS [training: 0.029622170784478107 | validation: 0.020274564998673337]
	TIME [epoch: 9.05 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035432059802643856		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.035432059802643856 | validation: 0.03130924077432727]
	TIME [epoch: 9.07 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03606690607424765		[learning rate: 0.00074239]
	Learning Rate: 0.000742389
	LOSS [training: 0.03606690607424765 | validation: 0.01633910205599403]
	TIME [epoch: 9.08 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027646504964889858		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.027646504964889858 | validation: 0.009734934160308987]
	TIME [epoch: 9.07 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02227437473221942		[learning rate: 0.0007388]
	Learning Rate: 0.000738799
	LOSS [training: 0.02227437473221942 | validation: -0.0049307184256821915]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_1175.pth
	Model improved!!!
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0299918564209253		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.0299918564209253 | validation: 0.018923084023419003]
	TIME [epoch: 9.04 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028227829551186696		[learning rate: 0.00073523]
	Learning Rate: 0.000735226
	LOSS [training: 0.028227829551186696 | validation: 0.015936835252182077]
	TIME [epoch: 9.04 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06121576439458824		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.06121576439458824 | validation: 0.038080777685024846]
	TIME [epoch: 9.06 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05716389334602802		[learning rate: 0.00073167]
	Learning Rate: 0.000731671
	LOSS [training: 0.05716389334602802 | validation: 0.04474006489514199]
	TIME [epoch: 9.05 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057283959874410616		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.057283959874410616 | validation: 0.0316985688653396]
	TIME [epoch: 9.06 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05021494984436954		[learning rate: 0.00072813]
	Learning Rate: 0.000728133
	LOSS [training: 0.05021494984436954 | validation: 0.04299274913064505]
	TIME [epoch: 9.04 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05290401406909072		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.05290401406909072 | validation: 0.032810822354917224]
	TIME [epoch: 9.06 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05830807481230589		[learning rate: 0.00072461]
	Learning Rate: 0.000724612
	LOSS [training: 0.05830807481230589 | validation: 0.04345090087030815]
	TIME [epoch: 9.04 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062052653959242934		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.062052653959242934 | validation: 0.055638532469974834]
	TIME [epoch: 9.04 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04105087240614258		[learning rate: 0.00072111]
	Learning Rate: 0.000721107
	LOSS [training: 0.04105087240614258 | validation: 0.025681139942472155]
	TIME [epoch: 9.05 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04270093794871845		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.04270093794871845 | validation: 0.044222276541259445]
	TIME [epoch: 9.04 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035532733042132295		[learning rate: 0.00071762]
	Learning Rate: 0.00071762
	LOSS [training: 0.035532733042132295 | validation: 0.020023765774431004]
	TIME [epoch: 9.08 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030910302490574172		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.030910302490574172 | validation: 0.020770142322390626]
	TIME [epoch: 9.05 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03422107598246307		[learning rate: 0.00071415]
	Learning Rate: 0.00071415
	LOSS [training: 0.03422107598246307 | validation: 0.02508123367118169]
	TIME [epoch: 9.05 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03541094232552324		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.03541094232552324 | validation: 0.018810557139336357]
	TIME [epoch: 9.04 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024891634116537355		[learning rate: 0.0007107]
	Learning Rate: 0.000710697
	LOSS [training: 0.024891634116537355 | validation: 0.013961339887400432]
	TIME [epoch: 9.05 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028210861718027815		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.028210861718027815 | validation: 0.02122259303870244]
	TIME [epoch: 9.06 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02585551327563284		[learning rate: 0.00070726]
	Learning Rate: 0.00070726
	LOSS [training: 0.02585551327563284 | validation: 0.025044280272227215]
	TIME [epoch: 9.05 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04290819919235531		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.04290819919235531 | validation: 0.053535519415165655]
	TIME [epoch: 9.05 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06270391529190986		[learning rate: 0.00070384]
	Learning Rate: 0.00070384
	LOSS [training: 0.06270391529190986 | validation: 0.05403048341416859]
	TIME [epoch: 9.05 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05853916777090189		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.05853916777090189 | validation: 0.02788535537390051]
	TIME [epoch: 9.06 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04509057375622104		[learning rate: 0.00070044]
	Learning Rate: 0.000700436
	LOSS [training: 0.04509057375622104 | validation: 0.03684355936815467]
	TIME [epoch: 9.07 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032278969662364335		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.032278969662364335 | validation: 0.03484938648139442]
	TIME [epoch: 9.06 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03252964178632474		[learning rate: 0.00069705]
	Learning Rate: 0.000697049
	LOSS [training: 0.03252964178632474 | validation: 0.02600408954698627]
	TIME [epoch: 9.05 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03885053231196399		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.03885053231196399 | validation: 0.0292373237027496]
	TIME [epoch: 9.07 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030120178748302383		[learning rate: 0.00069368]
	Learning Rate: 0.000693678
	LOSS [training: 0.030120178748302383 | validation: 0.010998245704097393]
	TIME [epoch: 9.07 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03036280295471306		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.03036280295471306 | validation: 0.021238023112918843]
	TIME [epoch: 9.05 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03661631861586066		[learning rate: 0.00069032]
	Learning Rate: 0.000690324
	LOSS [training: 0.03661631861586066 | validation: 0.014424402738250356]
	TIME [epoch: 9.04 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022591152296222168		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.022591152296222168 | validation: 0.018324284099919506]
	TIME [epoch: 9.04 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036402776191277804		[learning rate: 0.00068699]
	Learning Rate: 0.000686985
	LOSS [training: 0.036402776191277804 | validation: 0.0401625995181846]
	TIME [epoch: 9.07 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0361268016048088		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.0361268016048088 | validation: 0.021002946817715775]
	TIME [epoch: 9.06 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04206430969432035		[learning rate: 0.00068366]
	Learning Rate: 0.000683663
	LOSS [training: 0.04206430969432035 | validation: 0.016590103172267716]
	TIME [epoch: 9.06 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03776128825603571		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.03776128825603571 | validation: 0.026216560768527297]
	TIME [epoch: 9.05 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04750013482608324		[learning rate: 0.00068036]
	Learning Rate: 0.000680357
	LOSS [training: 0.04750013482608324 | validation: 0.029313965640919724]
	TIME [epoch: 9.06 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034438336927148025		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.034438336927148025 | validation: 0.021267865642315868]
	TIME [epoch: 9.08 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022626739276971907		[learning rate: 0.00067707]
	Learning Rate: 0.000677067
	LOSS [training: 0.022626739276971907 | validation: 0.022711619034071137]
	TIME [epoch: 9.05 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029146268529794718		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.029146268529794718 | validation: 0.023793580414496664]
	TIME [epoch: 9.06 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02609705922355257		[learning rate: 0.00067379]
	Learning Rate: 0.000673793
	LOSS [training: 0.02609705922355257 | validation: -0.0004745705781038006]
	TIME [epoch: 9.05 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026255172801829423		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.026255172801829423 | validation: 0.006520638381404074]
	TIME [epoch: 9.07 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021988337567934994		[learning rate: 0.00067053]
	Learning Rate: 0.000670534
	LOSS [training: 0.021988337567934994 | validation: 0.015312663396068914]
	TIME [epoch: 9.05 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01941630570210501		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.01941630570210501 | validation: 0.020363255298670727]
	TIME [epoch: 9.04 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027339306578801136		[learning rate: 0.00066729]
	Learning Rate: 0.000667292
	LOSS [training: 0.027339306578801136 | validation: 0.015435029727888027]
	TIME [epoch: 9.06 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02541211753163586		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.02541211753163586 | validation: 0.016684217541827726]
	TIME [epoch: 9.05 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024396653124330547		[learning rate: 0.00066406]
	Learning Rate: 0.000664065
	LOSS [training: 0.024396653124330547 | validation: 0.01885694977675159]
	TIME [epoch: 9.07 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02033539311470131		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.02033539311470131 | validation: 0.007414571242417372]
	TIME [epoch: 9.07 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01813923799077418		[learning rate: 0.00066085]
	Learning Rate: 0.000660854
	LOSS [training: 0.01813923799077418 | validation: 0.009663336949060214]
	TIME [epoch: 9.04 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016642120317403072		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.016642120317403072 | validation: 0.007833669217427721]
	TIME [epoch: 9.05 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017517274898830752		[learning rate: 0.00065766]
	Learning Rate: 0.000657658
	LOSS [training: 0.017517274898830752 | validation: 0.006875621800195067]
	TIME [epoch: 9.06 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026569429655902366		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.026569429655902366 | validation: 0.040412074143128425]
	TIME [epoch: 9.06 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02585205506308878		[learning rate: 0.00065448]
	Learning Rate: 0.000654478
	LOSS [training: 0.02585205506308878 | validation: 0.017853341407525126]
	TIME [epoch: 9.05 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02238662643506193		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.02238662643506193 | validation: 0.019232671208979476]
	TIME [epoch: 9.06 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020508135262836142		[learning rate: 0.00065131]
	Learning Rate: 0.000651313
	LOSS [training: 0.020508135262836142 | validation: 0.016437391367924666]
	TIME [epoch: 9.05 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019535763133620664		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.019535763133620664 | validation: 0.01569015218573989]
	TIME [epoch: 9.07 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02394883680096046		[learning rate: 0.00064816]
	Learning Rate: 0.000648163
	LOSS [training: 0.02394883680096046 | validation: 0.012178302394206482]
	TIME [epoch: 9.07 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037311227358855		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.037311227358855 | validation: 0.041089451064610885]
	TIME [epoch: 9.06 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040523977532227876		[learning rate: 0.00064503]
	Learning Rate: 0.000645029
	LOSS [training: 0.040523977532227876 | validation: 0.028797501255438354]
	TIME [epoch: 9.05 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04264194963901921		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.04264194963901921 | validation: 0.035658659224113924]
	TIME [epoch: 9.06 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049743411784870226		[learning rate: 0.00064191]
	Learning Rate: 0.000641909
	LOSS [training: 0.049743411784870226 | validation: 0.03259831029551334]
	TIME [epoch: 9.07 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05986931852976346		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.05986931852976346 | validation: 0.04730249393348964]
	TIME [epoch: 9.05 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03948443068465399		[learning rate: 0.00063881]
	Learning Rate: 0.000638805
	LOSS [training: 0.03948443068465399 | validation: 0.024976364483393194]
	TIME [epoch: 9.05 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03496641480190716		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.03496641480190716 | validation: 0.020239171865555634]
	TIME [epoch: 9.06 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02622251990626927		[learning rate: 0.00063572]
	Learning Rate: 0.000635716
	LOSS [training: 0.02622251990626927 | validation: 0.01437207023936975]
	TIME [epoch: 9.07 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02708662987904989		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.02708662987904989 | validation: 0.010701824617593341]
	TIME [epoch: 9.07 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027156748118274832		[learning rate: 0.00063264]
	Learning Rate: 0.000632642
	LOSS [training: 0.027156748118274832 | validation: 0.024029219797854627]
	TIME [epoch: 9.06 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017955281236315252		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.017955281236315252 | validation: 0.009679746909149755]
	TIME [epoch: 9.07 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019443092745130446		[learning rate: 0.00062958]
	Learning Rate: 0.000629582
	LOSS [training: 0.019443092745130446 | validation: 0.020564985524178285]
	TIME [epoch: 9.05 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02150065134608254		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.02150065134608254 | validation: 0.025578582034865755]
	TIME [epoch: 9.07 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02941949304934075		[learning rate: 0.00062654]
	Learning Rate: 0.000626538
	LOSS [training: 0.02941949304934075 | validation: 0.027041723514505157]
	TIME [epoch: 9.06 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030104500408193468		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.030104500408193468 | validation: 0.023887131097134084]
	TIME [epoch: 9.05 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020726086164180403		[learning rate: 0.00062351]
	Learning Rate: 0.000623508
	LOSS [training: 0.020726086164180403 | validation: 0.0029648930892860856]
	TIME [epoch: 9.05 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024055275660518176		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.024055275660518176 | validation: 0.019103891479794056]
	TIME [epoch: 9.07 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03357084587985687		[learning rate: 0.00062049]
	Learning Rate: 0.000620493
	LOSS [training: 0.03357084587985687 | validation: 0.007240593740213689]
	TIME [epoch: 9.06 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027556670112018095		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.027556670112018095 | validation: 0.036545060006978214]
	TIME [epoch: 9.06 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0392268667241265		[learning rate: 0.00061749]
	Learning Rate: 0.000617492
	LOSS [training: 0.0392268667241265 | validation: 0.0055369654824385705]
	TIME [epoch: 9.05 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022967545592422298		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.022967545592422298 | validation: 0.010153922790008518]
	TIME [epoch: 9.05 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023645683659929733		[learning rate: 0.00061451]
	Learning Rate: 0.000614506
	LOSS [training: 0.023645683659929733 | validation: 0.010360499610471807]
	TIME [epoch: 9.07 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024488447141980074		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: 0.024488447141980074 | validation: 0.008374366605460447]
	TIME [epoch: 9.05 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02966236411892139		[learning rate: 0.00061153]
	Learning Rate: 0.000611535
	LOSS [training: 0.02966236411892139 | validation: 0.016179991560352394]
	TIME [epoch: 9.06 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02095351432219113		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.02095351432219113 | validation: 0.017985250374438874]
	TIME [epoch: 9.05 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023174694682636658		[learning rate: 0.00060858]
	Learning Rate: 0.000608577
	LOSS [training: 0.023174694682636658 | validation: 0.013133413583446784]
	TIME [epoch: 9.05 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02453181033475176		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.02453181033475176 | validation: 0.006844438773425689]
	TIME [epoch: 9.07 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022469715465231004		[learning rate: 0.00060563]
	Learning Rate: 0.000605634
	LOSS [training: 0.022469715465231004 | validation: 0.038089170226295044]
	TIME [epoch: 9.04 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04462935822078796		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.04462935822078796 | validation: 0.039516585374508695]
	TIME [epoch: 9.05 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050601393493086844		[learning rate: 0.00060271]
	Learning Rate: 0.000602706
	LOSS [training: 0.050601393493086844 | validation: 0.02858334663004393]
	TIME [epoch: 9.04 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044062415470635		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.044062415470635 | validation: 0.034325216810721745]
	TIME [epoch: 9.06 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025416113660411983		[learning rate: 0.00059979]
	Learning Rate: 0.000599791
	LOSS [training: 0.025416113660411983 | validation: 0.01966359586396061]
	TIME [epoch: 9.06 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024623214881419164		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.024623214881419164 | validation: 0.018915398306173597]
	TIME [epoch: 9.04 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02367806507567188		[learning rate: 0.00059689]
	Learning Rate: 0.000596891
	LOSS [training: 0.02367806507567188 | validation: 0.02463856726223701]
	TIME [epoch: 9.05 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03775927370525349		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.03775927370525349 | validation: 0.03932140289880985]
	TIME [epoch: 9.06 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04755012194562732		[learning rate: 0.000594]
	Learning Rate: 0.000594004
	LOSS [training: 0.04755012194562732 | validation: 0.016584982836467328]
	TIME [epoch: 9.09 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034961387239520955		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.034961387239520955 | validation: 0.013685035103750645]
	TIME [epoch: 9.07 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03689755060351022		[learning rate: 0.00059113]
	Learning Rate: 0.000591132
	LOSS [training: 0.03689755060351022 | validation: 0.019641295277805886]
	TIME [epoch: 9.05 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022715004932698606		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.022715004932698606 | validation: 0.012755205344044132]
	TIME [epoch: 9.05 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019303608035523008		[learning rate: 0.00058827]
	Learning Rate: 0.000588273
	LOSS [training: 0.019303608035523008 | validation: 0.0159763247898536]
	TIME [epoch: 9.06 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021772896679758468		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.021772896679758468 | validation: 0.01787805944385264]
	TIME [epoch: 9.05 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02828720589974907		[learning rate: 0.00058543]
	Learning Rate: 0.000585428
	LOSS [training: 0.02828720589974907 | validation: 0.014812943517288794]
	TIME [epoch: 9.06 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023195903196339233		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.023195903196339233 | validation: 0.005003366898014136]
	TIME [epoch: 9.05 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01909164753683121		[learning rate: 0.0005826]
	Learning Rate: 0.000582597
	LOSS [training: 0.01909164753683121 | validation: 0.005153755072864382]
	TIME [epoch: 9.05 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023912085508711548		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.023912085508711548 | validation: 0.015270240681676022]
	TIME [epoch: 9.07 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026936988944884825		[learning rate: 0.00057978]
	Learning Rate: 0.00057978
	LOSS [training: 0.026936988944884825 | validation: 0.01820548459896076]
	TIME [epoch: 9.05 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025319426739731737		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.025319426739731737 | validation: 0.025598593622074603]
	TIME [epoch: 9.05 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02895520443413823		[learning rate: 0.00057698]
	Learning Rate: 0.000576976
	LOSS [training: 0.02895520443413823 | validation: 0.018494722475169312]
	TIME [epoch: 9.06 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026346009390027587		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.026346009390027587 | validation: 0.02572486712829477]
	TIME [epoch: 9.07 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023601390286702377		[learning rate: 0.00057419]
	Learning Rate: 0.000574186
	LOSS [training: 0.023601390286702377 | validation: 0.016863116434137175]
	TIME [epoch: 9.07 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019322705480371894		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.019322705480371894 | validation: 0.009067156191236611]
	TIME [epoch: 9.05 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03385457988907706		[learning rate: 0.00057141]
	Learning Rate: 0.000571409
	LOSS [training: 0.03385457988907706 | validation: 0.020423053944217548]
	TIME [epoch: 9.06 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043100204170817204		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.043100204170817204 | validation: 0.024195234483935874]
	TIME [epoch: 9.04 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04266826906714104		[learning rate: 0.00056865]
	Learning Rate: 0.000568646
	LOSS [training: 0.04266826906714104 | validation: 0.037464407935113964]
	TIME [epoch: 9.08 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06577909000693134		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.06577909000693134 | validation: 0.06426956993501501]
	TIME [epoch: 9.05 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0759653406348916		[learning rate: 0.0005659]
	Learning Rate: 0.000565896
	LOSS [training: 0.0759653406348916 | validation: 0.05863581698355731]
	TIME [epoch: 9.05 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06903084050228254		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.06903084050228254 | validation: 0.048987040852589536]
	TIME [epoch: 9.05 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0642659086439354		[learning rate: 0.00056316]
	Learning Rate: 0.00056316
	LOSS [training: 0.0642659086439354 | validation: 0.032898507674761296]
	TIME [epoch: 9.05 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049753355837218835		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.049753355837218835 | validation: 0.02169197258406283]
	TIME [epoch: 9.07 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04220603169110081		[learning rate: 0.00056044]
	Learning Rate: 0.000560436
	LOSS [training: 0.04220603169110081 | validation: 0.03191942195522908]
	TIME [epoch: 9.05 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040662471217050175		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.040662471217050175 | validation: 0.032776758882621465]
	TIME [epoch: 9.07 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03945616745198782		[learning rate: 0.00055773]
	Learning Rate: 0.000557726
	LOSS [training: 0.03945616745198782 | validation: 0.029303334629217366]
	TIME [epoch: 9.06 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03758032548022203		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.03758032548022203 | validation: 0.02792208690455666]
	TIME [epoch: 9.07 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04381942143338223		[learning rate: 0.00055503]
	Learning Rate: 0.000555029
	LOSS [training: 0.04381942143338223 | validation: 0.03949428922674575]
	TIME [epoch: 9.05 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03372845819575891		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.03372845819575891 | validation: 0.024020826775502685]
	TIME [epoch: 9.06 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045410076515828714		[learning rate: 0.00055235]
	Learning Rate: 0.000552345
	LOSS [training: 0.045410076515828714 | validation: 0.031254428764328976]
	TIME [epoch: 9.04 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044182359289508984		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.044182359289508984 | validation: 0.025050118887837]
	TIME [epoch: 9.05 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042197817250629516		[learning rate: 0.00054967]
	Learning Rate: 0.000549674
	LOSS [training: 0.042197817250629516 | validation: 0.03135108079929247]
	TIME [epoch: 9.08 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0395384907628475		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.0395384907628475 | validation: 0.028103287898487272]
	TIME [epoch: 9.05 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040188332008614616		[learning rate: 0.00054702]
	Learning Rate: 0.000547016
	LOSS [training: 0.040188332008614616 | validation: 0.026208206690478124]
	TIME [epoch: 9.05 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04571165395384611		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.04571165395384611 | validation: 0.029696881070999187]
	TIME [epoch: 9.05 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040326093146088794		[learning rate: 0.00054437]
	Learning Rate: 0.000544371
	LOSS [training: 0.040326093146088794 | validation: 0.01990571395944132]
	TIME [epoch: 9.07 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03382646479537838		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.03382646479537838 | validation: 0.024261462265336153]
	TIME [epoch: 9.05 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041349272325585114		[learning rate: 0.00054174]
	Learning Rate: 0.000541738
	LOSS [training: 0.041349272325585114 | validation: 0.02602095163270792]
	TIME [epoch: 9.04 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036138002391285576		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.036138002391285576 | validation: 0.025264730005756932]
	TIME [epoch: 9.06 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03758768030776664		[learning rate: 0.00053912]
	Learning Rate: 0.000539118
	LOSS [training: 0.03758768030776664 | validation: 0.028129050803466095]
	TIME [epoch: 9.05 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029193969093631998		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.029193969093631998 | validation: 0.03052889468992677]
	TIME [epoch: 9.08 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0294590123746993		[learning rate: 0.00053651]
	Learning Rate: 0.000536511
	LOSS [training: 0.0294590123746993 | validation: 0.019293893759046103]
	TIME [epoch: 9.05 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03311301165058801		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.03311301165058801 | validation: 0.00923042936491132]
	TIME [epoch: 9.05 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030805838502136574		[learning rate: 0.00053392]
	Learning Rate: 0.000533917
	LOSS [training: 0.030805838502136574 | validation: 0.023817326388200742]
	TIME [epoch: 9.05 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029923484745971497		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.029923484745971497 | validation: 0.019097672704752797]
	TIME [epoch: 9.06 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033531921305622506		[learning rate: 0.00053134]
	Learning Rate: 0.000531335
	LOSS [training: 0.033531921305622506 | validation: 0.02903390445241798]
	TIME [epoch: 9.07 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0581580198633451		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.0581580198633451 | validation: 0.041208867516621894]
	TIME [epoch: 9.07 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043273122114647115		[learning rate: 0.00052877]
	Learning Rate: 0.000528766
	LOSS [training: 0.043273122114647115 | validation: 0.0353534257249827]
	TIME [epoch: 9.06 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05365343163350013		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.05365343163350013 | validation: 0.0453690096014577]
	TIME [epoch: 9.05 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060248180914911686		[learning rate: 0.00052621]
	Learning Rate: 0.000526208
	LOSS [training: 0.060248180914911686 | validation: 0.07068158232817812]
	TIME [epoch: 9.07 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06797345498938191		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.06797345498938191 | validation: 0.034551066455364904]
	TIME [epoch: 9.06 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040102188193882025		[learning rate: 0.00052366]
	Learning Rate: 0.000523664
	LOSS [training: 0.040102188193882025 | validation: 0.03236051857809012]
	TIME [epoch: 9.05 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04220589964828207		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.04220589964828207 | validation: 0.022953231506485323]
	TIME [epoch: 9.06 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043217487673823406		[learning rate: 0.00052113]
	Learning Rate: 0.000521132
	LOSS [training: 0.043217487673823406 | validation: 0.034528421729219175]
	TIME [epoch: 9.06 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038841413671671196		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.038841413671671196 | validation: 0.015589489677066089]
	TIME [epoch: 9.06 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033702858530770194		[learning rate: 0.00051861]
	Learning Rate: 0.000518611
	LOSS [training: 0.033702858530770194 | validation: 0.01721209364617781]
	TIME [epoch: 9.06 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05277317688344897		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.05277317688344897 | validation: 0.06002082866774419]
	TIME [epoch: 9.06 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05310035511052924		[learning rate: 0.0005161]
	Learning Rate: 0.000516104
	LOSS [training: 0.05310035511052924 | validation: 0.024026462478597965]
	TIME [epoch: 9.06 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039558346916216944		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.039558346916216944 | validation: 0.01827462449776051]
	TIME [epoch: 9.08 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03209095597688597		[learning rate: 0.00051361]
	Learning Rate: 0.000513608
	LOSS [training: 0.03209095597688597 | validation: 0.022791936887029175]
	TIME [epoch: 9.06 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030761266383110258		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.030761266383110258 | validation: 0.022635489402112543]
	TIME [epoch: 9.06 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04357305350675476		[learning rate: 0.00051112]
	Learning Rate: 0.000511124
	LOSS [training: 0.04357305350675476 | validation: 0.037364605549304125]
	TIME [epoch: 9.05 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036950978577756075		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.036950978577756075 | validation: 0.017149249864140115]
	TIME [epoch: 9.04 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029361717030070077		[learning rate: 0.00050865]
	Learning Rate: 0.000508652
	LOSS [training: 0.029361717030070077 | validation: 0.026030761162785822]
	TIME [epoch: 9.08 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03103838682660457		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.03103838682660457 | validation: 0.02215333714619378]
	TIME [epoch: 9.06 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03376647775614637		[learning rate: 0.00050619]
	Learning Rate: 0.000506193
	LOSS [training: 0.03376647775614637 | validation: 0.021456771008680132]
	TIME [epoch: 9.07 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02866402588015888		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.02866402588015888 | validation: 0.01263440576576612]
	TIME [epoch: 9.06 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025058090460566042		[learning rate: 0.00050374]
	Learning Rate: 0.000503745
	LOSS [training: 0.025058090460566042 | validation: 0.010403320723737255]
	TIME [epoch: 9.08 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031147679878274787		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.031147679878274787 | validation: 0.030884614397526666]
	TIME [epoch: 9.05 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034557014417261965		[learning rate: 0.00050131]
	Learning Rate: 0.000501309
	LOSS [training: 0.034557014417261965 | validation: 0.01653660252184008]
	TIME [epoch: 9.06 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02702246018898637		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: 0.02702246018898637 | validation: 0.01767749028597438]
	TIME [epoch: 9.05 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01933195341237376		[learning rate: 0.00049888]
	Learning Rate: 0.000498885
	LOSS [training: 0.01933195341237376 | validation: 0.012351497300161392]
	TIME [epoch: 9.06 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0294692524297979		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.0294692524297979 | validation: 0.01335387438522952]
	TIME [epoch: 9.07 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022874224382517044		[learning rate: 0.00049647]
	Learning Rate: 0.000496472
	LOSS [training: 0.022874224382517044 | validation: 0.011749670522652375]
	TIME [epoch: 9.07 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02513994476578829		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.02513994476578829 | validation: 0.016353150446680377]
	TIME [epoch: 9.05 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01987216490209162		[learning rate: 0.00049407]
	Learning Rate: 0.000494071
	LOSS [training: 0.01987216490209162 | validation: 0.0022985361671071384]
	TIME [epoch: 9.05 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0185068222447319		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.0185068222447319 | validation: 0.01906541948682451]
	TIME [epoch: 9.06 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023487019700482604		[learning rate: 0.00049168]
	Learning Rate: 0.000491682
	LOSS [training: 0.023487019700482604 | validation: 0.010705518427719276]
	TIME [epoch: 9.06 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02848562982891973		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.02848562982891973 | validation: 0.008442213078547249]
	TIME [epoch: 9.06 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022471934950524075		[learning rate: 0.0004893]
	Learning Rate: 0.000489304
	LOSS [training: 0.022471934950524075 | validation: 0.017500521639859126]
	TIME [epoch: 9.04 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023645370669949328		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.023645370669949328 | validation: 0.015501713595210277]
	TIME [epoch: 9.05 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0302357768503629		[learning rate: 0.00048694]
	Learning Rate: 0.000486938
	LOSS [training: 0.0302357768503629 | validation: 0.020617434457504615]
	TIME [epoch: 9.07 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03387807161894293		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.03387807161894293 | validation: 0.02797851531145059]
	TIME [epoch: 9.06 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033360383842579985		[learning rate: 0.00048458]
	Learning Rate: 0.000484583
	LOSS [training: 0.033360383842579985 | validation: 0.018571654378547176]
	TIME [epoch: 9.05 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026486007025859758		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.026486007025859758 | validation: 0.025143302967738604]
	TIME [epoch: 9.05 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02119862643605746		[learning rate: 0.00048224]
	Learning Rate: 0.00048224
	LOSS [training: 0.02119862643605746 | validation: 0.010755216421905866]
	TIME [epoch: 9.05 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027707309226133563		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.027707309226133563 | validation: 0.008603782148348293]
	TIME [epoch: 9.08 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02325952202442067		[learning rate: 0.00047991]
	Learning Rate: 0.000479908
	LOSS [training: 0.02325952202442067 | validation: 0.013660939181702147]
	TIME [epoch: 9.05 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025459472852887598		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: 0.025459472852887598 | validation: 0.019530154581223647]
	TIME [epoch: 9.06 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025020782249816124		[learning rate: 0.00047759]
	Learning Rate: 0.000477587
	LOSS [training: 0.025020782249816124 | validation: 0.019632588702923018]
	TIME [epoch: 9.06 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038003188252969625		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.038003188252969625 | validation: 0.030879137834504574]
	TIME [epoch: 9.07 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036124247456197446		[learning rate: 0.00047528]
	Learning Rate: 0.000475278
	LOSS [training: 0.036124247456197446 | validation: 0.028188399623960768]
	TIME [epoch: 9.07 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030359067304649184		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.030359067304649184 | validation: 0.014690154772800761]
	TIME [epoch: 9.06 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02901556459300384		[learning rate: 0.00047298]
	Learning Rate: 0.000472979
	LOSS [training: 0.02901556459300384 | validation: 0.004938148544836662]
	TIME [epoch: 9.06 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021527485306149195		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.021527485306149195 | validation: 0.01295748251022178]
	TIME [epoch: 9.06 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026225571237987366		[learning rate: 0.00047069]
	Learning Rate: 0.000470692
	LOSS [training: 0.026225571237987366 | validation: 0.01384608978209211]
	TIME [epoch: 9.07 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022014148331248297		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: 0.022014148331248297 | validation: 0.014611863396479633]
	TIME [epoch: 9.06 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03181949228249599		[learning rate: 0.00046842]
	Learning Rate: 0.000468416
	LOSS [training: 0.03181949228249599 | validation: 0.030195942840233095]
	TIME [epoch: 9.06 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037157073544790274		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: 0.037157073544790274 | validation: 0.019721489800175344]
	TIME [epoch: 9.06 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030419860054922497		[learning rate: 0.00046615]
	Learning Rate: 0.000466151
	LOSS [training: 0.030419860054922497 | validation: 0.015496653702499655]
	TIME [epoch: 9.08 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025732915280604736		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 0.025732915280604736 | validation: 0.017634070216062458]
	TIME [epoch: 9.06 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02527860957348891		[learning rate: 0.0004639]
	Learning Rate: 0.000463896
	LOSS [training: 0.02527860957348891 | validation: 0.021470466091304152]
	TIME [epoch: 9.07 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026302575319488264		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: 0.026302575319488264 | validation: 0.004053354340260916]
	TIME [epoch: 9.06 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021697991152611337		[learning rate: 0.00046165]
	Learning Rate: 0.000461653
	LOSS [training: 0.021697991152611337 | validation: 0.00032762689186736655]
	TIME [epoch: 9.06 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018774825631646973		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.018774825631646973 | validation: 0.005178341242698426]
	TIME [epoch: 9.09 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01746461563878186		[learning rate: 0.00045942]
	Learning Rate: 0.000459421
	LOSS [training: 0.01746461563878186 | validation: 0.007852913369593486]
	TIME [epoch: 9.07 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02559828740576303		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.02559828740576303 | validation: 0.01605023124326388]
	TIME [epoch: 9.07 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026367905149361416		[learning rate: 0.0004572]
	Learning Rate: 0.000457199
	LOSS [training: 0.026367905149361416 | validation: 0.024223622570338624]
	TIME [epoch: 9.06 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0264449323142818		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.0264449323142818 | validation: 0.017730913812261495]
	TIME [epoch: 9.06 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021290035743694438		[learning rate: 0.00045499]
	Learning Rate: 0.000454988
	LOSS [training: 0.021290035743694438 | validation: 0.000894526128537243]
	TIME [epoch: 9.08 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02209257839719684		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: 0.02209257839719684 | validation: 0.012747267538698315]
	TIME [epoch: 9.06 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019963476993820582		[learning rate: 0.00045279]
	Learning Rate: 0.000452788
	LOSS [training: 0.019963476993820582 | validation: 0.011853548380507827]
	TIME [epoch: 9.06 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01984258028605071		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.01984258028605071 | validation: 0.004417750090429646]
	TIME [epoch: 9.06 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022518522879179874		[learning rate: 0.0004506]
	Learning Rate: 0.000450598
	LOSS [training: 0.022518522879179874 | validation: 0.019554529827653436]
	TIME [epoch: 9.07 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020179643204493947		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: 0.020179643204493947 | validation: 0.009991596981886501]
	TIME [epoch: 9.07 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025641661458378085		[learning rate: 0.00044842]
	Learning Rate: 0.000448419
	LOSS [training: 0.025641661458378085 | validation: 0.01983919643634926]
	TIME [epoch: 9.05 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025980899830616206		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.025980899830616206 | validation: 0.023746445714727227]
	TIME [epoch: 9.06 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024328537581789482		[learning rate: 0.00044625]
	Learning Rate: 0.000446251
	LOSS [training: 0.024328537581789482 | validation: 0.016186194638105694]
	TIME [epoch: 9.07 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02817873933210624		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.02817873933210624 | validation: 0.01782286487620701]
	TIME [epoch: 9.08 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02403876069147651		[learning rate: 0.00044409]
	Learning Rate: 0.000444093
	LOSS [training: 0.02403876069147651 | validation: 0.004941412891684763]
	TIME [epoch: 9.06 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02487035677423905		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: 0.02487035677423905 | validation: 0.006581113494556066]
	TIME [epoch: 9.05 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02448171660418007		[learning rate: 0.00044195]
	Learning Rate: 0.000441945
	LOSS [training: 0.02448171660418007 | validation: 0.021121930713783217]
	TIME [epoch: 9.06 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03220257327610326		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.03220257327610326 | validation: 0.016585321023050433]
	TIME [epoch: 9.08 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024532938484440867		[learning rate: 0.00043981]
	Learning Rate: 0.000439808
	LOSS [training: 0.024532938484440867 | validation: 0.03321126069617386]
	TIME [epoch: 9.06 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036203508509730906		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.036203508509730906 | validation: 0.017150720626390822]
	TIME [epoch: 9.06 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023964722725218636		[learning rate: 0.00043768]
	Learning Rate: 0.000437681
	LOSS [training: 0.023964722725218636 | validation: 0.018673437231284035]
	TIME [epoch: 9.05 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028286394821183225		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: 0.028286394821183225 | validation: 0.027100368176353005]
	TIME [epoch: 9.06 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03428348295566579		[learning rate: 0.00043556]
	Learning Rate: 0.000435565
	LOSS [training: 0.03428348295566579 | validation: 0.030536824841653848]
	TIME [epoch: 9.08 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02901874372326091		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: 0.02901874372326091 | validation: 0.02655873494087476]
	TIME [epoch: 9.06 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02928995570239823		[learning rate: 0.00043346]
	Learning Rate: 0.000433458
	LOSS [training: 0.02928995570239823 | validation: 0.026525498789637197]
	TIME [epoch: 9.06 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03161885306330794		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.03161885306330794 | validation: 0.03109092232187259]
	TIME [epoch: 9.07 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027423028987582615		[learning rate: 0.00043136]
	Learning Rate: 0.000431362
	LOSS [training: 0.027423028987582615 | validation: 0.01706996306823426]
	TIME [epoch: 9.09 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028290914311867737		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.028290914311867737 | validation: 0.015193178864612161]
	TIME [epoch: 9.07 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03158778186392004		[learning rate: 0.00042928]
	Learning Rate: 0.000429276
	LOSS [training: 0.03158778186392004 | validation: 0.013524339643554428]
	TIME [epoch: 9.06 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024927193313448504		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: 0.024927193313448504 | validation: 0.016756001255470193]
	TIME [epoch: 9.06 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024429637499920248		[learning rate: 0.0004272]
	Learning Rate: 0.0004272
	LOSS [training: 0.024429637499920248 | validation: 0.006784782840698037]
	TIME [epoch: 9.06 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02414989641844061		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.02414989641844061 | validation: 0.011450514516767964]
	TIME [epoch: 9.07 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022439168501324346		[learning rate: 0.00042513]
	Learning Rate: 0.000425134
	LOSS [training: 0.022439168501324346 | validation: 0.014855947609989754]
	TIME [epoch: 9.07 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024845775983503807		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: 0.024845775983503807 | validation: 0.022350467632228012]
	TIME [epoch: 9.06 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02312907709374953		[learning rate: 0.00042308]
	Learning Rate: 0.000423079
	LOSS [training: 0.02312907709374953 | validation: 0.014713499525346913]
	TIME [epoch: 9.06 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01893739297097999		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.01893739297097999 | validation: 0.005310545300143342]
	TIME [epoch: 9.06 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026825931196989818		[learning rate: 0.00042103]
	Learning Rate: 0.000421033
	LOSS [training: 0.026825931196989818 | validation: 0.014335886786350992]
	TIME [epoch: 9.07 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019079552008368833		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: 0.019079552008368833 | validation: 0.0123090306070196]
	TIME [epoch: 9.05 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01415088991225206		[learning rate: 0.000419]
	Learning Rate: 0.000418997
	LOSS [training: 0.01415088991225206 | validation: 0.004264658792299278]
	TIME [epoch: 9.06 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016945018009316637		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.016945018009316637 | validation: 0.009614115630709751]
	TIME [epoch: 9.07 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01605247204178397		[learning rate: 0.00041697]
	Learning Rate: 0.00041697
	LOSS [training: 0.01605247204178397 | validation: 0.008819436376081128]
	TIME [epoch: 9.09 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019209443627987578		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.019209443627987578 | validation: -0.0010471198068669838]
	TIME [epoch: 9.06 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020706942404776062		[learning rate: 0.00041495]
	Learning Rate: 0.000414954
	LOSS [training: 0.020706942404776062 | validation: 0.016519526164786046]
	TIME [epoch: 9.06 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022265147378212273		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.022265147378212273 | validation: 0.01994614288765928]
	TIME [epoch: 9.05 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025022694845246544		[learning rate: 0.00041295]
	Learning Rate: 0.000412947
	LOSS [training: 0.025022694845246544 | validation: 0.02167955991784805]
	TIME [epoch: 9.05 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027645134716820906		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.027645134716820906 | validation: 0.022645989723469866]
	TIME [epoch: 9.07 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037904435107811586		[learning rate: 0.00041095]
	Learning Rate: 0.00041095
	LOSS [training: 0.037904435107811586 | validation: 0.025903141288775775]
	TIME [epoch: 9.06 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03065699913977324		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.03065699913977324 | validation: 0.02133827813550962]
	TIME [epoch: 9.06 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04061924935788597		[learning rate: 0.00040896]
	Learning Rate: 0.000408963
	LOSS [training: 0.04061924935788597 | validation: 0.028156871580825714]
	TIME [epoch: 9.05 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03802128762406899		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.03802128762406899 | validation: 0.017721501535759743]
	TIME [epoch: 9.07 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035528937789641786		[learning rate: 0.00040699]
	Learning Rate: 0.000406986
	LOSS [training: 0.035528937789641786 | validation: 0.01417918491178637]
	TIME [epoch: 9.06 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02425978011865556		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.02425978011865556 | validation: 0.009885547354170012]
	TIME [epoch: 9.05 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02528761178452963		[learning rate: 0.00040502]
	Learning Rate: 0.000405017
	LOSS [training: 0.02528761178452963 | validation: 0.013123445057852453]
	TIME [epoch: 9.05 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025143427616363824		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.025143427616363824 | validation: 0.020318200076197952]
	TIME [epoch: 9.06 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03476102377554939		[learning rate: 0.00040306]
	Learning Rate: 0.000403059
	LOSS [training: 0.03476102377554939 | validation: 0.013083604916214103]
	TIME [epoch: 9.07 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0420020166166222		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.0420020166166222 | validation: 0.03894291927690868]
	TIME [epoch: 9.06 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05648028148305617		[learning rate: 0.00040111]
	Learning Rate: 0.00040111
	LOSS [training: 0.05648028148305617 | validation: 0.040556912842524606]
	TIME [epoch: 9.05 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06409367819860874		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.06409367819860874 | validation: 0.062012047970376946]
	TIME [epoch: 9.06 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07849610786538597		[learning rate: 0.00039917]
	Learning Rate: 0.00039917
	LOSS [training: 0.07849610786538597 | validation: 0.04623707403893969]
	TIME [epoch: 9.07 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06714196061791736		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.06714196061791736 | validation: 0.05709461029777873]
	TIME [epoch: 9.06 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0705685044490998		[learning rate: 0.00039724]
	Learning Rate: 0.00039724
	LOSS [training: 0.0705685044490998 | validation: 0.04775346558907406]
	TIME [epoch: 9.06 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06482980472554753		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.06482980472554753 | validation: 0.046049660610923075]
	TIME [epoch: 9.06 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05547570385434495		[learning rate: 0.00039532]
	Learning Rate: 0.000395319
	LOSS [training: 0.05547570385434495 | validation: 0.026475821207462603]
	TIME [epoch: 9.06 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036925771214826465		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.036925771214826465 | validation: 0.02312852772791491]
	TIME [epoch: 9.08 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03290055048909456		[learning rate: 0.00039341]
	Learning Rate: 0.000393407
	LOSS [training: 0.03290055048909456 | validation: 0.012347248804909033]
	TIME [epoch: 9.06 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024218652365040637		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.024218652365040637 | validation: 0.009095498541911634]
	TIME [epoch: 9.07 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025024639411188244		[learning rate: 0.0003915]
	Learning Rate: 0.000391505
	LOSS [training: 0.025024639411188244 | validation: 0.008560379685918804]
	TIME [epoch: 9.06 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023689470859276005		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.023689470859276005 | validation: 0.005626210113939321]
	TIME [epoch: 9.07 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022947679333499144		[learning rate: 0.00038961]
	Learning Rate: 0.000389611
	LOSS [training: 0.022947679333499144 | validation: 0.013127995178960255]
	TIME [epoch: 9.08 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024418361079976227		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.024418361079976227 | validation: 0.01450593933185577]
	TIME [epoch: 9.06 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02430929062788958		[learning rate: 0.00038773]
	Learning Rate: 0.000387727
	LOSS [training: 0.02430929062788958 | validation: 0.014795305450311689]
	TIME [epoch: 9.06 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0205939589098732		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 0.0205939589098732 | validation: 0.015149771841343942]
	TIME [epoch: 9.05 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021063876739324014		[learning rate: 0.00038585]
	Learning Rate: 0.000385852
	LOSS [training: 0.021063876739324014 | validation: 0.008027103697464889]
	TIME [epoch: 9.08 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02256489878205299		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.02256489878205299 | validation: 0.013263869335974945]
	TIME [epoch: 9.06 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021879561156977465		[learning rate: 0.00038399]
	Learning Rate: 0.000383986
	LOSS [training: 0.021879561156977465 | validation: 0.010196874579177239]
	TIME [epoch: 9.05 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03174985289824984		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.03174985289824984 | validation: 0.018923943111616687]
	TIME [epoch: 9.06 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03180755674237069		[learning rate: 0.00038213]
	Learning Rate: 0.000382129
	LOSS [training: 0.03180755674237069 | validation: 0.019152527296285717]
	TIME [epoch: 9.06 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02622024579145301		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.02622024579145301 | validation: 0.021503377344660273]
	TIME [epoch: 9.08 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01890283585829794		[learning rate: 0.00038028]
	Learning Rate: 0.000380282
	LOSS [training: 0.01890283585829794 | validation: 0.004645478383711308]
	TIME [epoch: 9.06 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020370383359535137		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.020370383359535137 | validation: 0.0076279258109337444]
	TIME [epoch: 9.06 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019256426008296072		[learning rate: 0.00037844]
	Learning Rate: 0.000378443
	LOSS [training: 0.019256426008296072 | validation: 0.011141260094464322]
	TIME [epoch: 9.07 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02117981855196127		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.02117981855196127 | validation: 0.03151615028338017]
	TIME [epoch: 9.07 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03910495300756465		[learning rate: 0.00037661]
	Learning Rate: 0.000376612
	LOSS [training: 0.03910495300756465 | validation: 0.020465088464046148]
	TIME [epoch: 9.06 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031083315341110425		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: 0.031083315341110425 | validation: 0.01600954026253571]
	TIME [epoch: 9.05 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024654843866411723		[learning rate: 0.00037479]
	Learning Rate: 0.000374791
	LOSS [training: 0.024654843866411723 | validation: 0.025807801784066223]
	TIME [epoch: 9.05 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02206755809589841		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.02206755809589841 | validation: 0.012601793108701444]
	TIME [epoch: 9.07 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018379595478134565		[learning rate: 0.00037298]
	Learning Rate: 0.000372979
	LOSS [training: 0.018379595478134565 | validation: 0.030677579206623635]
	TIME [epoch: 9.07 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020019602172145788		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.020019602172145788 | validation: 0.013088402270908517]
	TIME [epoch: 9.06 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021331695689603632		[learning rate: 0.00037118]
	Learning Rate: 0.000371175
	LOSS [training: 0.021331695689603632 | validation: 0.014311718687018176]
	TIME [epoch: 9.06 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017547145014986498		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.017547145014986498 | validation: 0.014496678375724655]
	TIME [epoch: 9.05 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018139628475834405		[learning rate: 0.00036938]
	Learning Rate: 0.00036938
	LOSS [training: 0.018139628475834405 | validation: 0.021066477075772035]
	TIME [epoch: 9.07 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021192018549670906		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.021192018549670906 | validation: 0.015603488759443746]
	TIME [epoch: 9.07 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021188034521104925		[learning rate: 0.00036759]
	Learning Rate: 0.000367594
	LOSS [training: 0.021188034521104925 | validation: 0.01684018199236344]
	TIME [epoch: 9.06 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023733310951337433		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: 0.023733310951337433 | validation: 0.011488681840133581]
	TIME [epoch: 9.07 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022270878840128065		[learning rate: 0.00036582]
	Learning Rate: 0.000365816
	LOSS [training: 0.022270878840128065 | validation: 0.018300095293706256]
	TIME [epoch: 9.06 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02217238391384278		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.02217238391384278 | validation: 0.018590165842043073]
	TIME [epoch: 9.07 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020787359017202318		[learning rate: 0.00036405]
	Learning Rate: 0.000364047
	LOSS [training: 0.020787359017202318 | validation: 0.01909018369912006]
	TIME [epoch: 9.06 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016942832767494344		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.016942832767494344 | validation: 0.017661705366215828]
	TIME [epoch: 9.05 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026454573777837314		[learning rate: 0.00036229]
	Learning Rate: 0.000362287
	LOSS [training: 0.026454573777837314 | validation: 0.020771318792461593]
	TIME [epoch: 9.06 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02078758148336033		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: 0.02078758148336033 | validation: 0.00969480599905204]
	TIME [epoch: 9.05 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017376943330708834		[learning rate: 0.00036053]
	Learning Rate: 0.000360535
	LOSS [training: 0.017376943330708834 | validation: -0.00019166113538570317]
	TIME [epoch: 9.07 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012211634594668161		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.012211634594668161 | validation: 0.01189531515567226]
	TIME [epoch: 9.06 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020964128530430216		[learning rate: 0.00035879]
	Learning Rate: 0.000358791
	LOSS [training: 0.020964128530430216 | validation: 0.02367570474489445]
	TIME [epoch: 9.05 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027356680361436053		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.027356680361436053 | validation: 0.015980158173522524]
	TIME [epoch: 9.05 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03256288724799185		[learning rate: 0.00035706]
	Learning Rate: 0.000357056
	LOSS [training: 0.03256288724799185 | validation: 0.009452068379996069]
	TIME [epoch: 9.07 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0280033122068089		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.0280033122068089 | validation: 0.012488476508986561]
	TIME [epoch: 9.07 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02511637762690045		[learning rate: 0.00035533]
	Learning Rate: 0.00035533
	LOSS [training: 0.02511637762690045 | validation: 0.022216003579269523]
	TIME [epoch: 9.07 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026794190522060383		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.026794190522060383 | validation: 0.019442270443764943]
	TIME [epoch: 9.06 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023547384046315463		[learning rate: 0.00035361]
	Learning Rate: 0.000353611
	LOSS [training: 0.023547384046315463 | validation: 0.009598664008545438]
	TIME [epoch: 9.06 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03284481181608242		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: 0.03284481181608242 | validation: 0.01824336745792051]
	TIME [epoch: 9.08 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0410939245627049		[learning rate: 0.0003519]
	Learning Rate: 0.000351901
	LOSS [training: 0.0410939245627049 | validation: 0.020482410795474807]
	TIME [epoch: 9.07 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031834956060764634		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: 0.031834956060764634 | validation: 0.013458707173621251]
	TIME [epoch: 9.06 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02541080891094667		[learning rate: 0.0003502]
	Learning Rate: 0.0003502
	LOSS [training: 0.02541080891094667 | validation: 0.014207709510307386]
	TIME [epoch: 9.06 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029925965690826957		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.029925965690826957 | validation: 0.014844336055282778]
	TIME [epoch: 9.08 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025680135759573862		[learning rate: 0.00034851]
	Learning Rate: 0.000348506
	LOSS [training: 0.025680135759573862 | validation: 0.014710587093787163]
	TIME [epoch: 9.05 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02037001744986384		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.02037001744986384 | validation: 0.02020245059896035]
	TIME [epoch: 9.06 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029051863029928134		[learning rate: 0.00034682]
	Learning Rate: 0.000346821
	LOSS [training: 0.029051863029928134 | validation: 0.019494748394255364]
	TIME [epoch: 9.06 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02568856207074277		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: 0.02568856207074277 | validation: 0.019633280362853625]
	TIME [epoch: 9.06 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028882869362336593		[learning rate: 0.00034514]
	Learning Rate: 0.000345144
	LOSS [training: 0.028882869362336593 | validation: 0.015525836398402089]
	TIME [epoch: 9.09 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05176901236230811		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: 0.05176901236230811 | validation: 0.052248958804392634]
	TIME [epoch: 9.07 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05241801792508451		[learning rate: 0.00034347]
	Learning Rate: 0.000343475
	LOSS [training: 0.05241801792508451 | validation: 0.02517431619475681]
	TIME [epoch: 9.07 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0322412116747519		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.0322412116747519 | validation: 0.019484076800071227]
	TIME [epoch: 9.06 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028220947731297304		[learning rate: 0.00034181]
	Learning Rate: 0.000341814
	LOSS [training: 0.028220947731297304 | validation: 0.013770958478725608]
	TIME [epoch: 9.06 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020398151029727602		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.020398151029727602 | validation: 0.014544763378499033]
	TIME [epoch: 9.07 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024077732887550905		[learning rate: 0.00034016]
	Learning Rate: 0.000340161
	LOSS [training: 0.024077732887550905 | validation: 0.013073663435587801]
	TIME [epoch: 9.06 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019966317503576005		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: 0.019966317503576005 | validation: 0.007010613374456603]
	TIME [epoch: 9.06 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028327562948922257		[learning rate: 0.00033852]
	Learning Rate: 0.000338516
	LOSS [training: 0.028327562948922257 | validation: 0.019997253279077812]
	TIME [epoch: 9.06 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033858101318999065		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.033858101318999065 | validation: 0.020973408499987238]
	TIME [epoch: 9.08 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029000273526217906		[learning rate: 0.00033688]
	Learning Rate: 0.000336879
	LOSS [training: 0.029000273526217906 | validation: 0.020818630138527014]
	TIME [epoch: 9.06 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01832534851425344		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.01832534851425344 | validation: 0.0013256981790814339]
	TIME [epoch: 9.06 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024183019341256558		[learning rate: 0.00033525]
	Learning Rate: 0.00033525
	LOSS [training: 0.024183019341256558 | validation: 0.0158905818328888]
	TIME [epoch: 9.06 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03227382279458373		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: 0.03227382279458373 | validation: 0.021115744791181966]
	TIME [epoch: 9.07 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02813753843605893		[learning rate: 0.00033363]
	Learning Rate: 0.000333629
	LOSS [training: 0.02813753843605893 | validation: 0.022313872548765094]
	TIME [epoch: 9.08 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03692835837313604		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.03692835837313604 | validation: 0.027513882996238928]
	TIME [epoch: 9.07 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051105725960646387		[learning rate: 0.00033202]
	Learning Rate: 0.000332015
	LOSS [training: 0.051105725960646387 | validation: 0.0352654510037667]
	TIME [epoch: 9.06 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04936465748373322		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.04936465748373322 | validation: 0.04100544277514788]
	TIME [epoch: 9.05 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049031351427262115		[learning rate: 0.00033041]
	Learning Rate: 0.00033041
	LOSS [training: 0.049031351427262115 | validation: 0.02897460763702318]
	TIME [epoch: 9.07 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0420598031443112		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: 0.0420598031443112 | validation: 0.03458854153271636]
	TIME [epoch: 9.06 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05464266260479441		[learning rate: 0.00032881]
	Learning Rate: 0.000328812
	LOSS [training: 0.05464266260479441 | validation: 0.039612490047988114]
	TIME [epoch: 9.06 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05038398859026431		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: 0.05038398859026431 | validation: 0.034232946098398456]
	TIME [epoch: 9.06 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04193716635524804		[learning rate: 0.00032722]
	Learning Rate: 0.000327222
	LOSS [training: 0.04193716635524804 | validation: 0.0259388923905982]
	TIME [epoch: 9.06 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033069078248042325		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.033069078248042325 | validation: 0.017607593607524157]
	TIME [epoch: 9.07 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027852344800137773		[learning rate: 0.00032564]
	Learning Rate: 0.000325639
	LOSS [training: 0.027852344800137773 | validation: 0.015364610752651763]
	TIME [epoch: 9.05 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019755922414908		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: 0.019755922414908 | validation: 0.016412185005474457]
	TIME [epoch: 9.05 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023451970526880882		[learning rate: 0.00032406]
	Learning Rate: 0.000324065
	LOSS [training: 0.023451970526880882 | validation: 0.016806420811526057]
	TIME [epoch: 9.06 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02523197059152369		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: 0.02523197059152369 | validation: 0.012867552531336864]
	TIME [epoch: 9.07 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018942183138291234		[learning rate: 0.0003225]
	Learning Rate: 0.000322497
	LOSS [training: 0.018942183138291234 | validation: 0.00935809757250261]
	TIME [epoch: 9.06 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0204358491549824		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: 0.0204358491549824 | validation: 0.010035872847390347]
	TIME [epoch: 9.05 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021763417953541205		[learning rate: 0.00032094]
	Learning Rate: 0.000320938
	LOSS [training: 0.021763417953541205 | validation: 0.010627937432760545]
	TIME [epoch: 9.06 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022462565358515266		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: 0.022462565358515266 | validation: 0.01044729513392392]
	TIME [epoch: 9.05 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019258972829205055		[learning rate: 0.00031939]
	Learning Rate: 0.000319386
	LOSS [training: 0.019258972829205055 | validation: 0.009118143123177585]
	TIME [epoch: 9.07 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01680224643515158		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.01680224643515158 | validation: 0.008312118440240657]
	TIME [epoch: 9.06 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02251780573578289		[learning rate: 0.00031784]
	Learning Rate: 0.000317841
	LOSS [training: 0.02251780573578289 | validation: 0.0072257894644364795]
	TIME [epoch: 9.05 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01990363064791764		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.01990363064791764 | validation: 0.0121979124150079]
	TIME [epoch: 9.05 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016577633098891112		[learning rate: 0.0003163]
	Learning Rate: 0.000316304
	LOSS [training: 0.016577633098891112 | validation: 0.008620627705406874]
	TIME [epoch: 9.06 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015626656103284158		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.015626656103284158 | validation: 0.007887992785262494]
	TIME [epoch: 9.07 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017736943348400574		[learning rate: 0.00031477]
	Learning Rate: 0.000314775
	LOSS [training: 0.017736943348400574 | validation: 0.010295372799071282]
	TIME [epoch: 9.05 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017137543643162834		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.017137543643162834 | validation: 0.013025311313227322]
	TIME [epoch: 9.06 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014810681019449342		[learning rate: 0.00031325]
	Learning Rate: 0.000313253
	LOSS [training: 0.014810681019449342 | validation: 0.003597332475912484]
	TIME [epoch: 9.06 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01696801412821228		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.01696801412821228 | validation: 0.001752463871068098]
	TIME [epoch: 9.09 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01668640030215882		[learning rate: 0.00031174]
	Learning Rate: 0.000311738
	LOSS [training: 0.01668640030215882 | validation: 0.0012137395875087631]
	TIME [epoch: 9.06 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014986732923214702		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: 0.014986732923214702 | validation: 0.0016985617700318596]
	TIME [epoch: 9.05 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015343663355636555		[learning rate: 0.00031023]
	Learning Rate: 0.00031023
	LOSS [training: 0.015343663355636555 | validation: 0.00828806154513723]
	TIME [epoch: 9.05 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010818874860111351		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: 0.010818874860111351 | validation: 0.0005783875223828638]
	TIME [epoch: 9.06 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015213917551496689		[learning rate: 0.00030873]
	Learning Rate: 0.00030873
	LOSS [training: 0.015213917551496689 | validation: 0.012384897108996169]
	TIME [epoch: 9.08 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014950853204984807		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.014950853204984807 | validation: 0.002116161939963331]
	TIME [epoch: 9.05 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016226646350899977		[learning rate: 0.00030724]
	Learning Rate: 0.000307237
	LOSS [training: 0.016226646350899977 | validation: -0.0004649070122309622]
	TIME [epoch: 9.06 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013341424550105419		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: 0.013341424550105419 | validation: -0.0017428158175935783]
	TIME [epoch: 9.06 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010170033840857077		[learning rate: 0.00030575]
	Learning Rate: 0.000305751
	LOSS [training: 0.010170033840857077 | validation: 0.0024758920214309065]
	TIME [epoch: 9.07 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00984394523528164		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: 0.00984394523528164 | validation: 0.006285204584928453]
	TIME [epoch: 9.06 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013727364035068468		[learning rate: 0.00030427]
	Learning Rate: 0.000304273
	LOSS [training: 0.013727364035068468 | validation: -0.0020248417642787205]
	TIME [epoch: 9.06 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01599854818852679		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.01599854818852679 | validation: 0.01890033980683241]
	TIME [epoch: 9.06 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013952590037549468		[learning rate: 0.0003028]
	Learning Rate: 0.000302801
	LOSS [training: 0.013952590037549468 | validation: 0.007997994335948165]
	TIME [epoch: 9.07 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011710238142828292		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: 0.011710238142828292 | validation: 0.0018579970907697417]
	TIME [epoch: 9.08 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014575553097866182		[learning rate: 0.00030134]
	Learning Rate: 0.000301337
	LOSS [training: 0.014575553097866182 | validation: 0.011332015653853495]
	TIME [epoch: 9.06 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018823193993527505		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.018823193993527505 | validation: -0.0008295708005376978]
	TIME [epoch: 9.05 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019531223232336532		[learning rate: 0.00029988]
	Learning Rate: 0.00029988
	LOSS [training: 0.019531223232336532 | validation: -0.0009302902742417929]
	TIME [epoch: 9.06 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014605670828147978		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: 0.014605670828147978 | validation: -0.0026910330895502004]
	TIME [epoch: 9.08 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016762026822466757		[learning rate: 0.00029843]
	Learning Rate: 0.00029843
	LOSS [training: 0.016762026822466757 | validation: -0.006475240863787663]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_1549.pth
	Model improved!!!
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01457008245736247		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: 0.01457008245736247 | validation: 0.001655670516333386]
	TIME [epoch: 9.06 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011146032072526495		[learning rate: 0.00029699]
	Learning Rate: 0.000296987
	LOSS [training: 0.011146032072526495 | validation: -0.003345486938742986]
	TIME [epoch: 9.05 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007994758171895499		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.007994758171895499 | validation: 0.010616416030016172]
	TIME [epoch: 9.05 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014058249757766367		[learning rate: 0.00029555]
	Learning Rate: 0.00029555
	LOSS [training: 0.014058249757766367 | validation: -0.0007925306743344325]
	TIME [epoch: 9.08 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011787932325666611		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: 0.011787932325666611 | validation: 0.00545352797921625]
	TIME [epoch: 9.06 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014750677972465048		[learning rate: 0.00029412]
	Learning Rate: 0.000294121
	LOSS [training: 0.014750677972465048 | validation: 0.01314405656595928]
	TIME [epoch: 9.07 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023287915714775693		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: 0.023287915714775693 | validation: 0.004387636319910693]
	TIME [epoch: 9.06 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022852593487740935		[learning rate: 0.0002927]
	Learning Rate: 0.000292699
	LOSS [training: 0.022852593487740935 | validation: 0.01366301249374206]
	TIME [epoch: 9.08 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024058424625811495		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: 0.024058424625811495 | validation: 0.014036459727681111]
	TIME [epoch: 9.06 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02202615535087441		[learning rate: 0.00029128]
	Learning Rate: 0.000291283
	LOSS [training: 0.02202615535087441 | validation: 0.01396432554049464]
	TIME [epoch: 9.05 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023324585501512708		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: 0.023324585501512708 | validation: 0.010587055084329128]
	TIME [epoch: 9.06 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01507719292216424		[learning rate: 0.00028987]
	Learning Rate: 0.000289875
	LOSS [training: 0.01507719292216424 | validation: 0.006379456557108274]
	TIME [epoch: 9.06 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013774314957115156		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: 0.013774314957115156 | validation: 0.0033288928582949997]
	TIME [epoch: 9.07 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02070350290710022		[learning rate: 0.00028847]
	Learning Rate: 0.000288473
	LOSS [training: 0.02070350290710022 | validation: 0.01632653259737952]
	TIME [epoch: 9.06 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018329019448700606		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: 0.018329019448700606 | validation: 0.008680703940677301]
	TIME [epoch: 9.05 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02143594493466285		[learning rate: 0.00028708]
	Learning Rate: 0.000287078
	LOSS [training: 0.02143594493466285 | validation: 0.003766200203235167]
	TIME [epoch: 9.06 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023954014946690243		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: 0.023954014946690243 | validation: 0.014392863038328419]
	TIME [epoch: 9.06 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02491205421252354		[learning rate: 0.00028569]
	Learning Rate: 0.00028569
	LOSS [training: 0.02491205421252354 | validation: 0.016552721678027633]
	TIME [epoch: 9.08 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022121746011206703		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: 0.022121746011206703 | validation: 0.009840102604761388]
	TIME [epoch: 9.07 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027796775603409558		[learning rate: 0.00028431]
	Learning Rate: 0.000284308
	LOSS [training: 0.027796775603409558 | validation: 0.0042387266078066175]
	TIME [epoch: 9.06 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0163282197302591		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: 0.0163282197302591 | validation: 0.012092881478787407]
	TIME [epoch: 9.07 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014324477072753241		[learning rate: 0.00028293]
	Learning Rate: 0.000282933
	LOSS [training: 0.014324477072753241 | validation: 0.004196171365741738]
	TIME [epoch: 9.07 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014120552173368255		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.014120552173368255 | validation: 0.00841620429091157]
	TIME [epoch: 9.06 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01735416563522932		[learning rate: 0.00028157]
	Learning Rate: 0.000281565
	LOSS [training: 0.01735416563522932 | validation: -0.00019610624309887234]
	TIME [epoch: 9.06 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015997149594789633		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: 0.015997149594789633 | validation: 0.011986994337987627]
	TIME [epoch: 9.06 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015460017080327137		[learning rate: 0.0002802]
	Learning Rate: 0.000280204
	LOSS [training: 0.015460017080327137 | validation: -0.0036615982222944895]
	TIME [epoch: 9.06 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012920373147940903		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: 0.012920373147940903 | validation: 0.0008584975064836972]
	TIME [epoch: 9.08 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011717958472275372		[learning rate: 0.00027885]
	Learning Rate: 0.000278849
	LOSS [training: 0.011717958472275372 | validation: 0.014432895922945194]
	TIME [epoch: 9.06 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013723583402852447		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: 0.013723583402852447 | validation: 0.005970938254903025]
	TIME [epoch: 9.05 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019459149100632577		[learning rate: 0.0002775]
	Learning Rate: 0.0002775
	LOSS [training: 0.019459149100632577 | validation: 0.010255408757804771]
	TIME [epoch: 9.06 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022315123218817935		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: 0.022315123218817935 | validation: 0.014452646702061676]
	TIME [epoch: 9.08 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01850249331750882		[learning rate: 0.00027616]
	Learning Rate: 0.000276158
	LOSS [training: 0.01850249331750882 | validation: 0.009327598700647173]
	TIME [epoch: 9.07 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01577766278127966		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: 0.01577766278127966 | validation: 0.003884005045124217]
	TIME [epoch: 9.06 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01820941349476471		[learning rate: 0.00027482]
	Learning Rate: 0.000274823
	LOSS [training: 0.01820941349476471 | validation: 0.0044319777375417]
	TIME [epoch: 9.06 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01182911662814681		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: 0.01182911662814681 | validation: 0.005586412656624043]
	TIME [epoch: 9.06 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014029574828517489		[learning rate: 0.00027349]
	Learning Rate: 0.000273494
	LOSS [training: 0.014029574828517489 | validation: -0.00027081165083461204]
	TIME [epoch: 9.08 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013158799192883463		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: 0.013158799192883463 | validation: 0.0036574222536759375]
	TIME [epoch: 9.06 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013870835278260298		[learning rate: 0.00027217]
	Learning Rate: 0.000272171
	LOSS [training: 0.013870835278260298 | validation: 0.008388341892892818]
	TIME [epoch: 9.05 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012998259052181807		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 0.012998259052181807 | validation: 0.006658782056422015]
	TIME [epoch: 9.06 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0217639477986753		[learning rate: 0.00027086]
	Learning Rate: 0.000270855
	LOSS [training: 0.0217639477986753 | validation: 0.004183015030141747]
	TIME [epoch: 9.07 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02288673108322177		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: 0.02288673108322177 | validation: 0.025432162347351177]
	TIME [epoch: 9.06 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04069558676861779		[learning rate: 0.00026955]
	Learning Rate: 0.000269545
	LOSS [training: 0.04069558676861779 | validation: 0.0403114246784269]
	TIME [epoch: 9.06 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048939460770910805		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: 0.048939460770910805 | validation: 0.026000376039155195]
	TIME [epoch: 9.05 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024479444444242594		[learning rate: 0.00026824]
	Learning Rate: 0.000268242
	LOSS [training: 0.024479444444242594 | validation: 0.00499351665300755]
	TIME [epoch: 9.06 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021499998616480335		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: 0.021499998616480335 | validation: 0.00818622007663887]
	TIME [epoch: 9.08 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017595423943751524		[learning rate: 0.00026694]
	Learning Rate: 0.000266945
	LOSS [training: 0.017595423943751524 | validation: 0.009692903261733065]
	TIME [epoch: 9.07 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020381620399912165		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.020381620399912165 | validation: 0.014436012203862696]
	TIME [epoch: 9.07 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029818162833676026		[learning rate: 0.00026565]
	Learning Rate: 0.000265654
	LOSS [training: 0.029818162833676026 | validation: 0.01887985307615911]
	TIME [epoch: 9.05 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021821861874569002		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.021821861874569002 | validation: 0.02011941754166996]
	TIME [epoch: 9.05 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025214358693152493		[learning rate: 0.00026437]
	Learning Rate: 0.000264369
	LOSS [training: 0.025214358693152493 | validation: 0.019754224308720748]
	TIME [epoch: 9.07 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028855371710761774		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: 0.028855371710761774 | validation: 0.011838607436112017]
	TIME [epoch: 9.06 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0358048070006587		[learning rate: 0.00026309]
	Learning Rate: 0.000263091
	LOSS [training: 0.0358048070006587 | validation: 0.022427597079480402]
	TIME [epoch: 9.06 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03157784473518907		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: 0.03157784473518907 | validation: 0.01778477776805752]
	TIME [epoch: 9.05 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017582882645086263		[learning rate: 0.00026182]
	Learning Rate: 0.000261818
	LOSS [training: 0.017582882645086263 | validation: 0.014777125492211574]
	TIME [epoch: 9.07 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016406676746781326		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: 0.016406676746781326 | validation: 0.0023214241458676477]
	TIME [epoch: 9.05 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018124687608528867		[learning rate: 0.00026055]
	Learning Rate: 0.000260552
	LOSS [training: 0.018124687608528867 | validation: 0.008380545484111364]
	TIME [epoch: 9.05 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01934937340992828		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: 0.01934937340992828 | validation: 0.007225785491059224]
	TIME [epoch: 9.05 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02362100772484612		[learning rate: 0.00025929]
	Learning Rate: 0.000259292
	LOSS [training: 0.02362100772484612 | validation: 0.018408297000941046]
	TIME [epoch: 9.05 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031839458019559876		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.031839458019559876 | validation: 0.018396367955067196]
	TIME [epoch: 9.08 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03669007863188363		[learning rate: 0.00025804]
	Learning Rate: 0.000258038
	LOSS [training: 0.03669007863188363 | validation: 0.022712482325568897]
	TIME [epoch: 9.06 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041276109324072406		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: 0.041276109324072406 | validation: 0.037109555372895994]
	TIME [epoch: 9.05 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03729776187813356		[learning rate: 0.00025679]
	Learning Rate: 0.00025679
	LOSS [training: 0.03729776187813356 | validation: 0.010902604761191498]
	TIME [epoch: 9.06 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03129365081394854		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: 0.03129365081394854 | validation: 0.021582480187610435]
	TIME [epoch: 9.07 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03311704588628612		[learning rate: 0.00025555]
	Learning Rate: 0.000255549
	LOSS [training: 0.03311704588628612 | validation: 0.016969532898159563]
	TIME [epoch: 9.06 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02708092770248393		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: 0.02708092770248393 | validation: 0.017208148863459862]
	TIME [epoch: 9.05 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030317920421888973		[learning rate: 0.00025431]
	Learning Rate: 0.000254313
	LOSS [training: 0.030317920421888973 | validation: 0.019734500534266924]
	TIME [epoch: 9.05 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02361144661291021		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: 0.02361144661291021 | validation: 0.008589808564270924]
	TIME [epoch: 9.06 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020155271869682963		[learning rate: 0.00025308]
	Learning Rate: 0.000253083
	LOSS [training: 0.020155271869682963 | validation: 0.010704669248663886]
	TIME [epoch: 9.07 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021580461551764813		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: 0.021580461551764813 | validation: 0.017199425327921805]
	TIME [epoch: 9.05 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01705258906069877		[learning rate: 0.00025186]
	Learning Rate: 0.000251859
	LOSS [training: 0.01705258906069877 | validation: 0.012458274980131627]
	TIME [epoch: 9.05 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02146242655554652		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.02146242655554652 | validation: 0.012839303247029778]
	TIME [epoch: 9.06 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015903597248132815		[learning rate: 0.00025064]
	Learning Rate: 0.000250641
	LOSS [training: 0.015903597248132815 | validation: -0.0001061587184285138]
	TIME [epoch: 9.07 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017154466127546807		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: 0.017154466127546807 | validation: 0.0052804516375363165]
	TIME [epoch: 9.06 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01730098598282607		[learning rate: 0.00024943]
	Learning Rate: 0.000249429
	LOSS [training: 0.01730098598282607 | validation: 0.005182257528610092]
	TIME [epoch: 9.06 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017486244991488566		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: 0.017486244991488566 | validation: -0.0007480147485107947]
	TIME [epoch: 9.07 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016748883396105033		[learning rate: 0.00024822]
	Learning Rate: 0.000248223
	LOSS [training: 0.016748883396105033 | validation: 0.012888819718117615]
	TIME [epoch: 9.05 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018722728891621607		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: 0.018722728891621607 | validation: 0.010393597479840248]
	TIME [epoch: 9.07 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014163028565475794		[learning rate: 0.00024702]
	Learning Rate: 0.000247023
	LOSS [training: 0.014163028565475794 | validation: 0.012570700450891302]
	TIME [epoch: 9.05 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015324655207571241		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: 0.015324655207571241 | validation: 0.010789860575784488]
	TIME [epoch: 9.05 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015916170451696774		[learning rate: 0.00024583]
	Learning Rate: 0.000245828
	LOSS [training: 0.015916170451696774 | validation: 0.0009271989815952319]
	TIME [epoch: 9.06 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015690920047694536		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.015690920047694536 | validation: -0.0017900021726743806]
	TIME [epoch: 9.05 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012751645580492682		[learning rate: 0.00024464]
	Learning Rate: 0.000244639
	LOSS [training: 0.012751645580492682 | validation: -0.003946561316121347]
	TIME [epoch: 9.08 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014198144793409717		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.014198144793409717 | validation: 0.0034135326744356527]
	TIME [epoch: 9.06 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014256547651467185		[learning rate: 0.00024346]
	Learning Rate: 0.000243456
	LOSS [training: 0.014256547651467185 | validation: 0.002142629862371691]
	TIME [epoch: 9.06 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011326892460717072		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.011326892460717072 | validation: -0.0013506278721436328]
	TIME [epoch: 9.06 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014248975000886382		[learning rate: 0.00024228]
	Learning Rate: 0.000242279
	LOSS [training: 0.014248975000886382 | validation: 0.00703074133233392]
	TIME [epoch: 9.08 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012652706123298506		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: 0.012652706123298506 | validation: 0.0074375667684685835]
	TIME [epoch: 9.06 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013058313424904128		[learning rate: 0.00024111]
	Learning Rate: 0.000241107
	LOSS [training: 0.013058313424904128 | validation: 0.0012934232811822556]
	TIME [epoch: 9.05 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011645637815271045		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: 0.011645637815271045 | validation: -0.0040613481104717795]
	TIME [epoch: 9.05 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01430972511980107		[learning rate: 0.00023994]
	Learning Rate: 0.000239941
	LOSS [training: 0.01430972511980107 | validation: 0.003929641804009832]
	TIME [epoch: 9.06 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019558549137151972		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: 0.019558549137151972 | validation: 0.004814561108731562]
	TIME [epoch: 9.07 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016466101476799572		[learning rate: 0.00023878]
	Learning Rate: 0.000238781
	LOSS [training: 0.016466101476799572 | validation: -0.002235225296689268]
	TIME [epoch: 9.06 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014003294167507455		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: 0.014003294167507455 | validation: 0.007520717599868955]
	TIME [epoch: 9.06 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012763676781719746		[learning rate: 0.00023763]
	Learning Rate: 0.000237626
	LOSS [training: 0.012763676781719746 | validation: 0.003771005428953248]
	TIME [epoch: 9.05 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012112545220772252		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: 0.012112545220772252 | validation: 0.003526483521569283]
	TIME [epoch: 9.07 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013948013032421564		[learning rate: 0.00023648]
	Learning Rate: 0.000236477
	LOSS [training: 0.013948013032421564 | validation: 0.005996091361612328]
	TIME [epoch: 9.06 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014836854808980221		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.014836854808980221 | validation: 0.0054345042852283225]
	TIME [epoch: 9.06 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0218117048765746		[learning rate: 0.00023533]
	Learning Rate: 0.000235334
	LOSS [training: 0.0218117048765746 | validation: 0.016002855874661853]
	TIME [epoch: 9.07 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017020784115187423		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.017020784115187423 | validation: 0.002321379931300789]
	TIME [epoch: 9.06 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01619446689290317		[learning rate: 0.0002342]
	Learning Rate: 0.000234196
	LOSS [training: 0.01619446689290317 | validation: 0.00994359985910359]
	TIME [epoch: 9.08 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013054537461787747		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: 0.013054537461787747 | validation: 0.003626494230473739]
	TIME [epoch: 9.05 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016835104164381234		[learning rate: 0.00023306]
	Learning Rate: 0.000233063
	LOSS [training: 0.016835104164381234 | validation: -0.00014908457604065123]
	TIME [epoch: 9.05 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012191952627551291		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: 0.012191952627551291 | validation: -0.0023921484369862295]
	TIME [epoch: 9.06 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016394530014661006		[learning rate: 0.00023194]
	Learning Rate: 0.000231936
	LOSS [training: 0.016394530014661006 | validation: 0.018849231723436933]
	TIME [epoch: 9.07 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016226278280075498		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: 0.016226278280075498 | validation: 0.008539786019726454]
	TIME [epoch: 9.06 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013539743923464676		[learning rate: 0.00023081]
	Learning Rate: 0.000230814
	LOSS [training: 0.013539743923464676 | validation: 0.001708046358390521]
	TIME [epoch: 9.06 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015606107883872683		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: 0.015606107883872683 | validation: 0.011198658685213352]
	TIME [epoch: 9.05 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015200052241863563		[learning rate: 0.0002297]
	Learning Rate: 0.000229698
	LOSS [training: 0.015200052241863563 | validation: 0.016263904196256045]
	TIME [epoch: 9.05 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016047907978989022		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: 0.016047907978989022 | validation: 0.0030197876741215723]
	TIME [epoch: 9.07 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013662713130915539		[learning rate: 0.00022859]
	Learning Rate: 0.000228588
	LOSS [training: 0.013662713130915539 | validation: 0.00500182691594094]
	TIME [epoch: 9.05 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013762160861215195		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: 0.013762160861215195 | validation: -0.00032485459134504017]
	TIME [epoch: 9.06 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008269172820109841		[learning rate: 0.00022748]
	Learning Rate: 0.000227482
	LOSS [training: 0.008269172820109841 | validation: -0.0005208287780680385]
	TIME [epoch: 9.06 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011834462001769776		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: 0.011834462001769776 | validation: 0.006718939881062569]
	TIME [epoch: 9.07 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008487149829664274		[learning rate: 0.00022638]
	Learning Rate: 0.000226382
	LOSS [training: 0.008487149829664274 | validation: 0.006707205105292139]
	TIME [epoch: 9.08 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010042869535337643		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: 0.010042869535337643 | validation: -0.006642786798757071]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_1664.pth
	Model improved!!!
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017632810789703808		[learning rate: 0.00022529]
	Learning Rate: 0.000225287
	LOSS [training: 0.017632810789703808 | validation: 0.003399691378895482]
	TIME [epoch: 9.05 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010284162773993983		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: 0.010284162773993983 | validation: 0.00924139896788924]
	TIME [epoch: 9.05 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017995563330964342		[learning rate: 0.0002242]
	Learning Rate: 0.000224198
	LOSS [training: 0.017995563330964342 | validation: -0.003173435660629558]
	TIME [epoch: 9.08 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015155133708991377		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: 0.015155133708991377 | validation: 0.010339016630394215]
	TIME [epoch: 9.05 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013962091242114403		[learning rate: 0.00022311]
	Learning Rate: 0.000223114
	LOSS [training: 0.013962091242114403 | validation: 0.00526529935105086]
	TIME [epoch: 9.06 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012417967716696073		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: 0.012417967716696073 | validation: 0.010226764794078054]
	TIME [epoch: 9.05 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013029164359545393		[learning rate: 0.00022203]
	Learning Rate: 0.000222035
	LOSS [training: 0.013029164359545393 | validation: 0.002405915695325846]
	TIME [epoch: 9.05 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011784819242118882		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.011784819242118882 | validation: 0.007195830320728791]
	TIME [epoch: 9.07 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010153763924960403		[learning rate: 0.00022096]
	Learning Rate: 0.000220961
	LOSS [training: 0.010153763924960403 | validation: 0.0002306834767539245]
	TIME [epoch: 9.06 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012256126525033884		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: 0.012256126525033884 | validation: 0.008871381390448279]
	TIME [epoch: 9.06 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016129405517871863		[learning rate: 0.00021989]
	Learning Rate: 0.000219893
	LOSS [training: 0.016129405517871863 | validation: 3.733876381688001e-05]
	TIME [epoch: 9.06 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01781837342195139		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: 0.01781837342195139 | validation: 0.014237901478757517]
	TIME [epoch: 9.07 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018197649185084958		[learning rate: 0.00021883]
	Learning Rate: 0.000218829
	LOSS [training: 0.018197649185084958 | validation: 0.0052098161312790076]
	TIME [epoch: 9.06 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01608368486127563		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: 0.01608368486127563 | validation: 0.007561665322109594]
	TIME [epoch: 9.05 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018968737266795557		[learning rate: 0.00021777]
	Learning Rate: 0.000217771
	LOSS [training: 0.018968737266795557 | validation: 0.011087446810242697]
	TIME [epoch: 9.05 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017384403005575966		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: 0.017384403005575966 | validation: 0.009605884788612414]
	TIME [epoch: 9.05 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017882391640459062		[learning rate: 0.00021672]
	Learning Rate: 0.000216718
	LOSS [training: 0.017882391640459062 | validation: 0.0034594537065444496]
	TIME [epoch: 9.07 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013026937857281245		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: 0.013026937857281245 | validation: 0.012543746363982089]
	TIME [epoch: 9.06 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015429306367262682		[learning rate: 0.00021567]
	Learning Rate: 0.00021567
	LOSS [training: 0.015429306367262682 | validation: 0.003059427640709683]
	TIME [epoch: 9.05 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019482917735416178		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: 0.019482917735416178 | validation: 0.009426185997467591]
	TIME [epoch: 9.04 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01836217536909172		[learning rate: 0.00021463]
	Learning Rate: 0.000214627
	LOSS [training: 0.01836217536909172 | validation: 0.006653138686881797]
	TIME [epoch: 9.07 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013912078669296151		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: 0.013912078669296151 | validation: 0.006287155256850158]
	TIME [epoch: 9.06 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011059119551844174		[learning rate: 0.00021359]
	Learning Rate: 0.000213589
	LOSS [training: 0.011059119551844174 | validation: 0.00044338026553708033]
	TIME [epoch: 9.06 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008709911250237186		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.008709911250237186 | validation: 0.00228374242623163]
	TIME [epoch: 9.06 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013508269447448484		[learning rate: 0.00021256]
	Learning Rate: 0.000212556
	LOSS [training: 0.013508269447448484 | validation: 0.004731003520085747]
	TIME [epoch: 9.05 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0074207216434904605		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.0074207216434904605 | validation: 0.003906801843780765]
	TIME [epoch: 9.07 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006813702985300136		[learning rate: 0.00021153]
	Learning Rate: 0.000211528
	LOSS [training: 0.006813702985300136 | validation: -0.005227864033282344]
	TIME [epoch: 9.05 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017117680527153588		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.017117680527153588 | validation: 0.0022529657617602413]
	TIME [epoch: 9.06 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012528676326314459		[learning rate: 0.00021051]
	Learning Rate: 0.000210505
	LOSS [training: 0.012528676326314459 | validation: -0.0038355826387712643]
	TIME [epoch: 9.05 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011386368318101131		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.011386368318101131 | validation: 0.004504357155701608]
	TIME [epoch: 9.06 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009104370122046592		[learning rate: 0.00020949]
	Learning Rate: 0.000209487
	LOSS [training: 0.009104370122046592 | validation: 0.004475143100642938]
	TIME [epoch: 9.07 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0049893885587146275		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.0049893885587146275 | validation: -0.0020238262039357557]
	TIME [epoch: 9.05 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01027188953201904		[learning rate: 0.00020847]
	Learning Rate: 0.000208474
	LOSS [training: 0.01027188953201904 | validation: -0.0017127099791959337]
	TIME [epoch: 9.05 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011089709942490495		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.011089709942490495 | validation: 0.010579049793973805]
	TIME [epoch: 9.05 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012092657907364511		[learning rate: 0.00020747]
	Learning Rate: 0.000207466
	LOSS [training: 0.012092657907364511 | validation: -0.004156160263946302]
	TIME [epoch: 9.07 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009133308403473952		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: 0.009133308403473952 | validation: -0.0003199735506774562]
	TIME [epoch: 9.06 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007456635307882174		[learning rate: 0.00020646]
	Learning Rate: 0.000206463
	LOSS [training: 0.007456635307882174 | validation: -0.0037093979406768547]
	TIME [epoch: 9.06 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012025172709101788		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.012025172709101788 | validation: 0.0008934741223433256]
	TIME [epoch: 9.05 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009533051284726776		[learning rate: 0.00020546]
	Learning Rate: 0.000205465
	LOSS [training: 0.009533051284726776 | validation: 0.004856780128013697]
	TIME [epoch: 9.05 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009203853238786513		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.009203853238786513 | validation: 0.0028806494278349614]
	TIME [epoch: 9.07 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012698994586425181		[learning rate: 0.00020447]
	Learning Rate: 0.000204471
	LOSS [training: 0.012698994586425181 | validation: 0.014019646243255452]
	TIME [epoch: 9.05 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021186807852548596		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: 0.021186807852548596 | validation: 0.013989854195149955]
	TIME [epoch: 9.05 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019608054105799144		[learning rate: 0.00020348]
	Learning Rate: 0.000203482
	LOSS [training: 0.019608054105799144 | validation: 0.009670311110428884]
	TIME [epoch: 9.06 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013940762785401978		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: 0.013940762785401978 | validation: 0.00860952861759516]
	TIME [epoch: 9.07 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016666602212142313		[learning rate: 0.0002025]
	Learning Rate: 0.000202498
	LOSS [training: 0.016666602212142313 | validation: 0.007312930258569312]
	TIME [epoch: 9.05 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015049917972779941		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.015049917972779941 | validation: 0.01677542302359785]
	TIME [epoch: 9.05 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016920368917383296		[learning rate: 0.00020152]
	Learning Rate: 0.000201519
	LOSS [training: 0.016920368917383296 | validation: -0.0012976937744903455]
	TIME [epoch: 9.06 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015071082532060676		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.015071082532060676 | validation: 0.007462000030322654]
	TIME [epoch: 9.06 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013716917486982042		[learning rate: 0.00020054]
	Learning Rate: 0.000200544
	LOSS [training: 0.013716917486982042 | validation: 0.0008435035396263018]
	TIME [epoch: 9.08 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010637690706821249		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.010637690706821249 | validation: 0.0074017912360352335]
	TIME [epoch: 9.06 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0126600965954865		[learning rate: 0.00019957]
	Learning Rate: 0.000199575
	LOSS [training: 0.0126600965954865 | validation: -0.00044981240428276943]
	TIME [epoch: 9.06 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010799657240083561		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: 0.010799657240083561 | validation: 0.00535960034039514]
	TIME [epoch: 9.05 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012342592065112127		[learning rate: 0.00019861]
	Learning Rate: 0.000198609
	LOSS [training: 0.012342592065112127 | validation: 0.0009329166263965785]
	TIME [epoch: 9.07 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014004992154005427		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: 0.014004992154005427 | validation: -0.007350448315469676]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_1718.pth
	Model improved!!!
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013854230276661583		[learning rate: 0.00019765]
	Learning Rate: 0.000197649
	LOSS [training: 0.013854230276661583 | validation: 0.0026425131880033056]
	TIME [epoch: 9.05 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014888938749688885		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: 0.014888938749688885 | validation: 0.002999457882874493]
	TIME [epoch: 9.05 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01741020089122515		[learning rate: 0.00019669]
	Learning Rate: 0.000196693
	LOSS [training: 0.01741020089122515 | validation: 0.007249882647750631]
	TIME [epoch: 9.05 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013069482758808922		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: 0.013069482758808922 | validation: 0.013828702612302318]
	TIME [epoch: 9.07 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013903074177521017		[learning rate: 0.00019574]
	Learning Rate: 0.000195742
	LOSS [training: 0.013903074177521017 | validation: 0.002554787884542575]
	TIME [epoch: 9.05 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010798258338328601		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: 0.010798258338328601 | validation: -0.0011607441048103778]
	TIME [epoch: 9.05 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016520196026077103		[learning rate: 0.0001948]
	Learning Rate: 0.000194796
	LOSS [training: 0.016520196026077103 | validation: -0.0013692598497645697]
	TIME [epoch: 9.06 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015139926057511984		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: 0.015139926057511984 | validation: 0.010724043578467898]
	TIME [epoch: 9.07 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01067484737615965		[learning rate: 0.00019385]
	Learning Rate: 0.000193853
	LOSS [training: 0.01067484737615965 | validation: 0.003020477983725763]
	TIME [epoch: 9.08 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006602558937951149		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: 0.006602558937951149 | validation: 0.0005576271530712174]
	TIME [epoch: 9.07 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013246736758794906		[learning rate: 0.00019292]
	Learning Rate: 0.000192916
	LOSS [training: 0.013246736758794906 | validation: 0.008341257885758093]
	TIME [epoch: 9.05 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009229108127637031		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: 0.009229108127637031 | validation: -0.001746576847578011]
	TIME [epoch: 9.05 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012132935115947782		[learning rate: 0.00019198]
	Learning Rate: 0.000191983
	LOSS [training: 0.012132935115947782 | validation: 0.008366726951101647]
	TIME [epoch: 9.08 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017022011552353812		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: 0.017022011552353812 | validation: 0.0005651843083993674]
	TIME [epoch: 9.06 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011095838925166173		[learning rate: 0.00019105]
	Learning Rate: 0.000191055
	LOSS [training: 0.011095838925166173 | validation: 0.0009738546311966068]
	TIME [epoch: 9.06 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01280143153063453		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: 0.01280143153063453 | validation: 0.004402326712857813]
	TIME [epoch: 9.06 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013263086807713237		[learning rate: 0.00019013]
	Learning Rate: 0.000190131
	LOSS [training: 0.013263086807713237 | validation: -0.0010405547061764255]
	TIME [epoch: 9.06 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006214952456873987		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: 0.006214952456873987 | validation: 0.0035899236283304103]
	TIME [epoch: 9.1 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01272717569677711		[learning rate: 0.00018921]
	Learning Rate: 0.000189211
	LOSS [training: 0.01272717569677711 | validation: 0.0024861755300374473]
	TIME [epoch: 9.04 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012414593646816269		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: 0.012414593646816269 | validation: 0.002208662184730692]
	TIME [epoch: 9.05 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008759236728652642		[learning rate: 0.0001883]
	Learning Rate: 0.000188296
	LOSS [training: 0.008759236728652642 | validation: 0.0007422006607422161]
	TIME [epoch: 9.04 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007242743153949208		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: 0.007242743153949208 | validation: -0.0061454710686728664]
	TIME [epoch: 9.07 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013093229438126085		[learning rate: 0.00018739]
	Learning Rate: 0.000187386
	LOSS [training: 0.013093229438126085 | validation: 0.011293341884673241]
	TIME [epoch: 9.07 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012028588577988279		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: 0.012028588577988279 | validation: 0.003751342206648419]
	TIME [epoch: 9.05 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012495291719524444		[learning rate: 0.00018648]
	Learning Rate: 0.00018648
	LOSS [training: 0.012495291719524444 | validation: 0.0012135728556743343]
	TIME [epoch: 9.06 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01284631526665842		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: 0.01284631526665842 | validation: 0.006151622981471041]
	TIME [epoch: 9.06 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014609719432212998		[learning rate: 0.00018558]
	Learning Rate: 0.000185578
	LOSS [training: 0.014609719432212998 | validation: -0.002467106822282838]
	TIME [epoch: 9.07 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010784463788241968		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: 0.010784463788241968 | validation: -0.0004611046871523588]
	TIME [epoch: 9.05 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01120729258111496		[learning rate: 0.00018468]
	Learning Rate: 0.00018468
	LOSS [training: 0.01120729258111496 | validation: -0.010820373281568131]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_1747.pth
	Model improved!!!
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007988463278161976		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: 0.007988463278161976 | validation: -0.0025439305912007054]
	TIME [epoch: 9.05 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009399051614496565		[learning rate: 0.00018379]
	Learning Rate: 0.000183787
	LOSS [training: 0.009399051614496565 | validation: 0.0015044361291751212]
	TIME [epoch: 9.07 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007213334437347847		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: 0.007213334437347847 | validation: 0.005795590480100102]
	TIME [epoch: 9.06 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01142115533142826		[learning rate: 0.0001829]
	Learning Rate: 0.000182899
	LOSS [training: 0.01142115533142826 | validation: 0.001516739918694884]
	TIME [epoch: 9.05 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010288454719756061		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: 0.010288454719756061 | validation: -0.0073124791214841875]
	TIME [epoch: 9.06 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012179207164533534		[learning rate: 0.00018201]
	Learning Rate: 0.000182014
	LOSS [training: 0.012179207164533534 | validation: -0.00020031825497753009]
	TIME [epoch: 9.05 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008369153323152368		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: 0.008369153323152368 | validation: -0.0033698308306272877]
	TIME [epoch: 9.07 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01264261414469775		[learning rate: 0.00018113]
	Learning Rate: 0.000181134
	LOSS [training: 0.01264261414469775 | validation: 0.000300376781922555]
	TIME [epoch: 9.05 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009242853704725825		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: 0.009242853704725825 | validation: 0.0017232160973838855]
	TIME [epoch: 9.05 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010577249708273099		[learning rate: 0.00018026]
	Learning Rate: 0.000180258
	LOSS [training: 0.010577249708273099 | validation: 0.003746444781908412]
	TIME [epoch: 9.06 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012548362494343135		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: 0.012548362494343135 | validation: 0.0063104785744652475]
	TIME [epoch: 9.07 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010593300024286356		[learning rate: 0.00017939]
	Learning Rate: 0.000179386
	LOSS [training: 0.010593300024286356 | validation: 0.0034306844126022794]
	TIME [epoch: 9.06 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009337465553637245		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: 0.009337465553637245 | validation: -0.007498606504176187]
	TIME [epoch: 9.06 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009573690190180506		[learning rate: 0.00017852]
	Learning Rate: 0.000178519
	LOSS [training: 0.009573690190180506 | validation: -0.002179265206255235]
	TIME [epoch: 9.06 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009648223833799596		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: 0.009648223833799596 | validation: 0.008028673950600754]
	TIME [epoch: 9.05 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008898234719849418		[learning rate: 0.00017766]
	Learning Rate: 0.000177656
	LOSS [training: 0.008898234719849418 | validation: 0.008914634588107321]
	TIME [epoch: 9.08 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006184004307985492		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: 0.006184004307985492 | validation: -0.0020541063146612614]
	TIME [epoch: 9.06 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012289149770261597		[learning rate: 0.0001768]
	Learning Rate: 0.000176797
	LOSS [training: 0.012289149770261597 | validation: -0.005680339798771512]
	TIME [epoch: 9.07 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012973537803036289		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: 0.012973537803036289 | validation: 0.001659318839707998]
	TIME [epoch: 9.07 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013605924330982839		[learning rate: 0.00017594]
	Learning Rate: 0.000175942
	LOSS [training: 0.013605924330982839 | validation: -0.0016064479713576395]
	TIME [epoch: 9.07 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008841369803279871		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: 0.008841369803279871 | validation: 0.008231362214450269]
	TIME [epoch: 9.08 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008786999007890846		[learning rate: 0.00017509]
	Learning Rate: 0.000175091
	LOSS [training: 0.008786999007890846 | validation: 0.007363288317179805]
	TIME [epoch: 9.06 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0121256425095132		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: 0.0121256425095132 | validation: 0.0004802627331730475]
	TIME [epoch: 9.05 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0073928054915659205		[learning rate: 0.00017424]
	Learning Rate: 0.000174244
	LOSS [training: 0.0073928054915659205 | validation: -0.003677894523726438]
	TIME [epoch: 9.06 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006915649270955294		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: 0.006915649270955294 | validation: 0.00515133174435051]
	TIME [epoch: 9.08 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011630405365452979		[learning rate: 0.0001734]
	Learning Rate: 0.000173401
	LOSS [training: 0.011630405365452979 | validation: 0.0002504921062422771]
	TIME [epoch: 9.07 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01370547118761386		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.01370547118761386 | validation: -0.0067241716931869654]
	TIME [epoch: 9.07 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007123055861558192		[learning rate: 0.00017256]
	Learning Rate: 0.000172563
	LOSS [training: 0.007123055861558192 | validation: -0.00020665364113892364]
	TIME [epoch: 9.06 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010310165446734935		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: 0.010310165446734935 | validation: 0.005429704250758842]
	TIME [epoch: 9.06 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007759041122768534		[learning rate: 0.00017173]
	Learning Rate: 0.000171728
	LOSS [training: 0.007759041122768534 | validation: -0.0018166171469398648]
	TIME [epoch: 9.09 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012962543589185133		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: 0.012962543589185133 | validation: 0.006809960017627797]
	TIME [epoch: 9.07 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011168719467437483		[learning rate: 0.0001709]
	Learning Rate: 0.000170898
	LOSS [training: 0.011168719467437483 | validation: 0.0016266432446320322]
	TIME [epoch: 9.08 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011927870664680536		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.011927870664680536 | validation: -0.000642116667807491]
	TIME [epoch: 9.07 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012696510410560644		[learning rate: 0.00017007]
	Learning Rate: 0.000170072
	LOSS [training: 0.012696510410560644 | validation: 0.0015486560963034607]
	TIME [epoch: 9.09 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010313024888744051		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: 0.010313024888744051 | validation: -0.0048696808335987815]
	TIME [epoch: 9.07 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010763308207954085		[learning rate: 0.00016925]
	Learning Rate: 0.000169249
	LOSS [training: 0.010763308207954085 | validation: 0.0028200916545169544]
	TIME [epoch: 9.06 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008820383978655012		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: 0.008820383978655012 | validation: 0.00022139303667112324]
	TIME [epoch: 9.06 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015034080852544934		[learning rate: 0.00016843]
	Learning Rate: 0.000168431
	LOSS [training: 0.015034080852544934 | validation: -0.005201058169137305]
	TIME [epoch: 9.06 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012153295067384677		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.012153295067384677 | validation: -0.0027190743748675894]
	TIME [epoch: 9.08 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00878894717897937		[learning rate: 0.00016762]
	Learning Rate: 0.000167616
	LOSS [training: 0.00878894717897937 | validation: 0.008172174637444091]
	TIME [epoch: 9.07 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007689488964822254		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.007689488964822254 | validation: 0.0028133664268196806]
	TIME [epoch: 9.06 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013087479163874172		[learning rate: 0.00016681]
	Learning Rate: 0.000166806
	LOSS [training: 0.013087479163874172 | validation: 0.008562144445593375]
	TIME [epoch: 9.07 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0141919915512338		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: 0.0141919915512338 | validation: 0.004508786884988409]
	TIME [epoch: 9.08 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007823298167476848		[learning rate: 0.000166]
	Learning Rate: 0.000165999
	LOSS [training: 0.007823298167476848 | validation: 0.0011368078908170227]
	TIME [epoch: 9.07 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013500772936036017		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: 0.013500772936036017 | validation: -0.00020971156049144428]
	TIME [epoch: 9.08 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01613823057213895		[learning rate: 0.0001652]
	Learning Rate: 0.000165196
	LOSS [training: 0.01613823057213895 | validation: 0.004968670304031631]
	TIME [epoch: 9.08 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016524064202403037		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: 0.016524064202403037 | validation: 0.005362338122946916]
	TIME [epoch: 9.08 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012619177261564186		[learning rate: 0.0001644]
	Learning Rate: 0.000164397
	LOSS [training: 0.012619177261564186 | validation: 0.0113285151496531]
	TIME [epoch: 9.09 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010858112673793666		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: 0.010858112673793666 | validation: 0.000494216158456069]
	TIME [epoch: 9.06 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011489270379474403		[learning rate: 0.0001636]
	Learning Rate: 0.000163602
	LOSS [training: 0.011489270379474403 | validation: 0.01221521469893496]
	TIME [epoch: 9.06 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014678826895615171		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: 0.014678826895615171 | validation: 0.008881271555544246]
	TIME [epoch: 9.06 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014482477416971307		[learning rate: 0.00016281]
	Learning Rate: 0.000162811
	LOSS [training: 0.014482477416971307 | validation: 0.004990113976994548]
	TIME [epoch: 9.08 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015808559787118558		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: 0.015808559787118558 | validation: 0.00150220692727836]
	TIME [epoch: 9.08 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006012435914762617		[learning rate: 0.00016202]
	Learning Rate: 0.000162024
	LOSS [training: 0.006012435914762617 | validation: 0.00906715704735842]
	TIME [epoch: 9.06 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010444583621146227		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: 0.010444583621146227 | validation: 0.01213226706831086]
	TIME [epoch: 9.06 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007769993906985906		[learning rate: 0.00016124]
	Learning Rate: 0.00016124
	LOSS [training: 0.007769993906985906 | validation: 0.0035161077669203095]
	TIME [epoch: 9.05 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009318711017867198		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: 0.009318711017867198 | validation: -0.005587607114941826]
	TIME [epoch: 9.08 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006585464873058047		[learning rate: 0.00016046]
	Learning Rate: 0.000160461
	LOSS [training: 0.006585464873058047 | validation: -0.0024106229318482035]
	TIME [epoch: 9.07 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010157959791838034		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: 0.010157959791838034 | validation: -0.0026034703699625316]
	TIME [epoch: 9.06 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006116020833156737		[learning rate: 0.00015968]
	Learning Rate: 0.000159685
	LOSS [training: 0.006116020833156737 | validation: 0.008563340399360091]
	TIME [epoch: 9.07 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012468481706049805		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.012468481706049805 | validation: 0.004437053741125902]
	TIME [epoch: 9.05 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010705279006199596		[learning rate: 0.00015891]
	Learning Rate: 0.000158912
	LOSS [training: 0.010705279006199596 | validation: 0.0008132321198979944]
	TIME [epoch: 9.08 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007377731327726907		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: 0.007377731327726907 | validation: 0.00033776989819255844]
	TIME [epoch: 9.06 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007205523628236536		[learning rate: 0.00015814]
	Learning Rate: 0.000158144
	LOSS [training: 0.007205523628236536 | validation: -5.985569292706137e-05]
	TIME [epoch: 9.06 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009087108572278004		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: 0.009087108572278004 | validation: -0.0007143821048899895]
	TIME [epoch: 9.06 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011753943467807972		[learning rate: 0.00015738]
	Learning Rate: 0.000157379
	LOSS [training: 0.011753943467807972 | validation: -0.0049161358388972575]
	TIME [epoch: 9.08 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007350897163584285		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.007350897163584285 | validation: -0.005811113132947588]
	TIME [epoch: 9.06 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01001085055242099		[learning rate: 0.00015662]
	Learning Rate: 0.000156618
	LOSS [training: 0.01001085055242099 | validation: -0.00028504479622771693]
	TIME [epoch: 9.06 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014596276882016803		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: 0.014596276882016803 | validation: 0.001332356868308324]
	TIME [epoch: 9.05 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010779078497750175		[learning rate: 0.00015586]
	Learning Rate: 0.000155861
	LOSS [training: 0.010779078497750175 | validation: 0.007706343853504881]
	TIME [epoch: 9.06 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0128493560070887		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: 0.0128493560070887 | validation: -0.006793462820338831]
	TIME [epoch: 9.08 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008820076017417956		[learning rate: 0.00015511]
	Learning Rate: 0.000155107
	LOSS [training: 0.008820076017417956 | validation: -0.004086539750098379]
	TIME [epoch: 9.06 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007011448203441279		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.007011448203441279 | validation: 0.001355573291520104]
	TIME [epoch: 9.06 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015903061284129293		[learning rate: 0.00015436]
	Learning Rate: 0.000154357
	LOSS [training: 0.015903061284129293 | validation: 0.0028576770971100317]
	TIME [epoch: 9.05 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010071184548874807		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.010071184548874807 | validation: 0.0017445576386077644]
	TIME [epoch: 9.09 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013151595323724535		[learning rate: 0.00015361]
	Learning Rate: 0.000153611
	LOSS [training: 0.013151595323724535 | validation: -0.0013028905146291758]
	TIME [epoch: 9.06 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011855642029197967		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: 0.011855642029197967 | validation: -0.0022449918303653676]
	TIME [epoch: 9.05 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007710965924440802		[learning rate: 0.00015287]
	Learning Rate: 0.000152868
	LOSS [training: 0.007710965924440802 | validation: 0.0069662767679670974]
	TIME [epoch: 9.06 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01057914013983673		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: 0.01057914013983673 | validation: 0.002452768378782442]
	TIME [epoch: 9.06 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00896980268118122		[learning rate: 0.00015213]
	Learning Rate: 0.000152128
	LOSS [training: 0.00896980268118122 | validation: 0.007031829505573333]
	TIME [epoch: 9.08 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008983983420795028		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: 0.008983983420795028 | validation: 0.004746416051005911]
	TIME [epoch: 9.06 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015350102570254518		[learning rate: 0.00015139]
	Learning Rate: 0.000151393
	LOSS [training: 0.015350102570254518 | validation: 0.010288615235713835]
	TIME [epoch: 9.06 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016330804578358633		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: 0.016330804578358633 | validation: 0.0053494975768214196]
	TIME [epoch: 9.06 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012831412518519044		[learning rate: 0.00015066]
	Learning Rate: 0.000150661
	LOSS [training: 0.012831412518519044 | validation: 0.002056619011601293]
	TIME [epoch: 9.08 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012477510285626164		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: 0.012477510285626164 | validation: 0.011127540540228617]
	TIME [epoch: 9.09 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014908552726770155		[learning rate: 0.00014993]
	Learning Rate: 0.000149932
	LOSS [training: 0.014908552726770155 | validation: 0.004181893652412516]
	TIME [epoch: 9.07 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016757858627555456		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: 0.016757858627555456 | validation: 0.0005669099095201922]
	TIME [epoch: 9.07 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013272100944213137		[learning rate: 0.00014921]
	Learning Rate: 0.000149207
	LOSS [training: 0.013272100944213137 | validation: 0.002298497170207155]
	TIME [epoch: 9.06 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011617094610279868		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: 0.011617094610279868 | validation: 0.007146753577702109]
	TIME [epoch: 9.08 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009313037184022228		[learning rate: 0.00014849]
	Learning Rate: 0.000148486
	LOSS [training: 0.009313037184022228 | validation: 0.0031743017633494635]
	TIME [epoch: 9.06 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010976476930183485		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: 0.010976476930183485 | validation: 0.010903123005847011]
	TIME [epoch: 9.06 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011109689758158407		[learning rate: 0.00014777]
	Learning Rate: 0.000147768
	LOSS [training: 0.011109689758158407 | validation: 0.007344111440767453]
	TIME [epoch: 9.06 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0098766289377296		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.0098766289377296 | validation: -0.004590250572329625]
	TIME [epoch: 9.06 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01231072824288525		[learning rate: 0.00014705]
	Learning Rate: 0.000147053
	LOSS [training: 0.01231072824288525 | validation: -0.003907847749142619]
	TIME [epoch: 9.08 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01233022395910321		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: 0.01233022395910321 | validation: -0.003546642910062663]
	TIME [epoch: 9.06 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009762122899354785		[learning rate: 0.00014634]
	Learning Rate: 0.000146342
	LOSS [training: 0.009762122899354785 | validation: -0.0021858207835262844]
	TIME [epoch: 9.06 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006240114911204492		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.006240114911204492 | validation: 0.003254207274279679]
	TIME [epoch: 9.06 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010585446866302264		[learning rate: 0.00014563]
	Learning Rate: 0.000145634
	LOSS [training: 0.010585446866302264 | validation: -0.005587133300967235]
	TIME [epoch: 9.08 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00926927280287115		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.00926927280287115 | validation: -0.0029496274749382947]
	TIME [epoch: 9.08 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00778860572883854		[learning rate: 0.00014493]
	Learning Rate: 0.00014493
	LOSS [training: 0.00778860572883854 | validation: 0.015743877544550568]
	TIME [epoch: 9.06 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011355547348596898		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: 0.011355547348596898 | validation: 0.003920975719025131]
	TIME [epoch: 9.06 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014618729434948404		[learning rate: 0.00014423]
	Learning Rate: 0.000144229
	LOSS [training: 0.014618729434948404 | validation: 0.001088308154122088]
	TIME [epoch: 9.06 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01563066459756892		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.01563066459756892 | validation: -0.002495713288204017]
	TIME [epoch: 9.08 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010708252848572972		[learning rate: 0.00014353]
	Learning Rate: 0.000143532
	LOSS [training: 0.010708252848572972 | validation: 0.00048722625872090006]
	TIME [epoch: 9.06 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009085049233007386		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.009085049233007386 | validation: 0.011931979585984439]
	TIME [epoch: 9.06 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010550588907844254		[learning rate: 0.00014284]
	Learning Rate: 0.000142837
	LOSS [training: 0.010550588907844254 | validation: 0.0032749497185630893]
	TIME [epoch: 9.06 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012227920946843416		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.012227920946843416 | validation: 0.005418404012870823]
	TIME [epoch: 9.07 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01514583861759482		[learning rate: 0.00014215]
	Learning Rate: 0.000142147
	LOSS [training: 0.01514583861759482 | validation: 0.006397748266156588]
	TIME [epoch: 9.06 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012655150501336943		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: 0.012655150501336943 | validation: 0.007594194934429173]
	TIME [epoch: 9.05 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01365797629887503		[learning rate: 0.00014146]
	Learning Rate: 0.000141459
	LOSS [training: 0.01365797629887503 | validation: 0.008094731162248594]
	TIME [epoch: 9.06 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009039068249804307		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: 0.009039068249804307 | validation: -0.003240286177396413]
	TIME [epoch: 9.07 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011250224670301213		[learning rate: 0.00014078]
	Learning Rate: 0.000140775
	LOSS [training: 0.011250224670301213 | validation: 0.0009487833589944495]
	TIME [epoch: 9.09 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011393088786754515		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: 0.011393088786754515 | validation: -0.00946025103831341]
	TIME [epoch: 9.07 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01279659929883219		[learning rate: 0.00014009]
	Learning Rate: 0.000140094
	LOSS [training: 0.01279659929883219 | validation: 0.002130374395923315]
	TIME [epoch: 9.06 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007755299943226225		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: 0.007755299943226225 | validation: 0.004935176776498804]
	TIME [epoch: 9.05 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00813141286716059		[learning rate: 0.00013942]
	Learning Rate: 0.000139417
	LOSS [training: 0.00813141286716059 | validation: 0.002807567295888631]
	TIME [epoch: 9.07 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015464445161067524		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: 0.015464445161067524 | validation: 0.004585544338132466]
	TIME [epoch: 9.07 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004375967588487982		[learning rate: 0.00013874]
	Learning Rate: 0.000138743
	LOSS [training: 0.004375967588487982 | validation: -0.007380817112479974]
	TIME [epoch: 9.06 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00901987120998302		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: 0.00901987120998302 | validation: 7.185730889253355e-05]
	TIME [epoch: 9.06 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010029293051918391		[learning rate: 0.00013807]
	Learning Rate: 0.000138072
	LOSS [training: 0.010029293051918391 | validation: -0.004232817822960663]
	TIME [epoch: 9.06 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009140710538873617		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: 0.009140710538873617 | validation: 0.012351251073449213]
	TIME [epoch: 9.07 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008631302208131948		[learning rate: 0.0001374]
	Learning Rate: 0.000137404
	LOSS [training: 0.008631302208131948 | validation: -0.004966687943770834]
	TIME [epoch: 9.06 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011577971863803214		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: 0.011577971863803214 | validation: -0.0003143362305556069]
	TIME [epoch: 9.06 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015290402916174076		[learning rate: 0.00013674]
	Learning Rate: 0.00013674
	LOSS [training: 0.015290402916174076 | validation: 0.005758605308039365]
	TIME [epoch: 9.07 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016723528167998068		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: 0.016723528167998068 | validation: 0.0024095504545267083]
	TIME [epoch: 9.06 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00943628556042132		[learning rate: 0.00013608]
	Learning Rate: 0.000136078
	LOSS [training: 0.00943628556042132 | validation: 0.008520117817676942]
	TIME [epoch: 9.09 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0133495885994377		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: 0.0133495885994377 | validation: -0.00467733045115425]
	TIME [epoch: 9.07 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011467846977438665		[learning rate: 0.00013542]
	Learning Rate: 0.00013542
	LOSS [training: 0.011467846977438665 | validation: 0.007601766752048147]
	TIME [epoch: 9.06 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011235721763745056		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: 0.011235721763745056 | validation: 0.00629235545212774]
	TIME [epoch: 9.06 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013222896277823776		[learning rate: 0.00013477]
	Learning Rate: 0.000134766
	LOSS [training: 0.013222896277823776 | validation: 0.008013834899827408]
	TIME [epoch: 9.08 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010591982339592212		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: 0.010591982339592212 | validation: 0.0033056113477840003]
	TIME [epoch: 9.07 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009234996188547588		[learning rate: 0.00013411]
	Learning Rate: 0.000134114
	LOSS [training: 0.009234996188547588 | validation: -0.0045185474642412665]
	TIME [epoch: 9.06 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011525065152601285		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: 0.011525065152601285 | validation: -0.002948964809575595]
	TIME [epoch: 9.06 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00914651181974055		[learning rate: 0.00013347]
	Learning Rate: 0.000133465
	LOSS [training: 0.00914651181974055 | validation: -0.002348707566016421]
	TIME [epoch: 9.06 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012169995782219787		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.012169995782219787 | validation: 0.000948006359926765]
	TIME [epoch: 9.07 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008955577626439958		[learning rate: 0.00013282]
	Learning Rate: 0.00013282
	LOSS [training: 0.008955577626439958 | validation: 0.007102463027427653]
	TIME [epoch: 9.06 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010345653717027484		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: 0.010345653717027484 | validation: -0.0022498116995096134]
	TIME [epoch: 9.07 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007957693705035887		[learning rate: 0.00013218]
	Learning Rate: 0.000132178
	LOSS [training: 0.007957693705035887 | validation: -0.0032988079125913644]
	TIME [epoch: 9.06 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009488199223482327		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: 0.009488199223482327 | validation: -0.00476377094647019]
	TIME [epoch: 9.08 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006308878047699841		[learning rate: 0.00013154]
	Learning Rate: 0.000131538
	LOSS [training: 0.006308878047699841 | validation: -0.0029336601040111337]
	TIME [epoch: 9.06 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011620455198186396		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: 0.011620455198186396 | validation: 0.0014439314763941683]
	TIME [epoch: 9.06 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013719588889554065		[learning rate: 0.0001309]
	Learning Rate: 0.000130902
	LOSS [training: 0.013719588889554065 | validation: -0.0003376830911910578]
	TIME [epoch: 9.06 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010767470228127478		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: 0.010767470228127478 | validation: -0.0015159589653717563]
	TIME [epoch: 9.05 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009613229374884433		[learning rate: 0.00013027]
	Learning Rate: 0.000130269
	LOSS [training: 0.009613229374884433 | validation: 0.0035024462060898208]
	TIME [epoch: 9.08 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011777220440999747		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: 0.011777220440999747 | validation: 0.0007907228786403716]
	TIME [epoch: 9.06 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009402330998400588		[learning rate: 0.00012964]
	Learning Rate: 0.000129639
	LOSS [training: 0.009402330998400588 | validation: 0.00796535817801949]
	TIME [epoch: 9.06 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011558321152914901		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: 0.011558321152914901 | validation: 0.004542889424127207]
	TIME [epoch: 9.06 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007013635712188033		[learning rate: 0.00012901]
	Learning Rate: 0.000129012
	LOSS [training: 0.007013635712188033 | validation: 0.004041806113966274]
	TIME [epoch: 9.06 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00948991897917644		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.00948991897917644 | validation: 0.00720818658993596]
	TIME [epoch: 9.07 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009552437577090678		[learning rate: 0.00012839]
	Learning Rate: 0.000128389
	LOSS [training: 0.009552437577090678 | validation: -0.005002344771176255]
	TIME [epoch: 9.06 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014558522289336037		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: 0.014558522289336037 | validation: 0.004262776210735326]
	TIME [epoch: 9.06 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005859183547708285		[learning rate: 0.00012777]
	Learning Rate: 0.000127768
	LOSS [training: 0.005859183547708285 | validation: 0.005567322830176701]
	TIME [epoch: 9.06 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010319349981461412		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: 0.010319349981461412 | validation: 0.0004260470364749468]
	TIME [epoch: 9.08 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008777311324062492		[learning rate: 0.00012715]
	Learning Rate: 0.00012715
	LOSS [training: 0.008777311324062492 | validation: 0.006706188867842072]
	TIME [epoch: 9.06 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009385659749934902		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: 0.009385659749934902 | validation: -0.00011896678248088876]
	TIME [epoch: 9.05 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009359466301537833		[learning rate: 0.00012653]
	Learning Rate: 0.000126535
	LOSS [training: 0.009359466301537833 | validation: -0.0034553359268992495]
	TIME [epoch: 9.06 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006934390274354961		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: 0.006934390274354961 | validation: -0.006612919903310088]
	TIME [epoch: 9.06 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010401848010809114		[learning rate: 0.00012592]
	Learning Rate: 0.000125923
	LOSS [training: 0.010401848010809114 | validation: -0.004444837089398577]
	TIME [epoch: 9.08 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009958887282000872		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: 0.009958887282000872 | validation: -0.0005591036110142805]
	TIME [epoch: 9.06 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010413544996624436		[learning rate: 0.00012531]
	Learning Rate: 0.000125314
	LOSS [training: 0.010413544996624436 | validation: 0.00220447598640374]
	TIME [epoch: 9.06 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012558251008273869		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: 0.012558251008273869 | validation: -0.0018350346116504052]
	TIME [epoch: 9.06 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009686690265762092		[learning rate: 0.00012471]
	Learning Rate: 0.000124708
	LOSS [training: 0.009686690265762092 | validation: 0.0032204615975042687]
	TIME [epoch: 9.08 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008445958617392817		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: 0.008445958617392817 | validation: 0.0015749820687993529]
	TIME [epoch: 9.06 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0077842243583568695		[learning rate: 0.00012411]
	Learning Rate: 0.000124105
	LOSS [training: 0.0077842243583568695 | validation: 0.008617071366972621]
	TIME [epoch: 9.06 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009751114756016106		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.009751114756016106 | validation: 0.00010276199550786954]
	TIME [epoch: 9.06 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008455898181063789		[learning rate: 0.0001235]
	Learning Rate: 0.000123505
	LOSS [training: 0.008455898181063789 | validation: 0.007234784625572984]
	TIME [epoch: 9.06 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006771776398380935		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: 0.006771776398380935 | validation: 0.004211442032402372]
	TIME [epoch: 9.08 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008175577019937482		[learning rate: 0.00012291]
	Learning Rate: 0.000122908
	LOSS [training: 0.008175577019937482 | validation: 0.0022913817341028934]
	TIME [epoch: 9.06 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008998391632315195		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: 0.008998391632315195 | validation: 0.004398654200622428]
	TIME [epoch: 9.06 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003902721079121159		[learning rate: 0.00012231]
	Learning Rate: 0.000122313
	LOSS [training: 0.003902721079121159 | validation: -5.261548805746141e-05]
	TIME [epoch: 9.06 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01122376289489305		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: 0.01122376289489305 | validation: -0.006100157540495707]
	TIME [epoch: 9.08 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010500651963649335		[learning rate: 0.00012172]
	Learning Rate: 0.000121722
	LOSS [training: 0.010500651963649335 | validation: -0.0005820693992510365]
	TIME [epoch: 9.07 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010908037484115896		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: 0.010908037484115896 | validation: 0.010911795185982547]
	TIME [epoch: 9.06 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009403013819390947		[learning rate: 0.00012113]
	Learning Rate: 0.000121133
	LOSS [training: 0.009403013819390947 | validation: 0.006065665355042579]
	TIME [epoch: 9.06 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012902207394654096		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: 0.012902207394654096 | validation: -0.008442679407063815]
	TIME [epoch: 9.06 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01487542489546439		[learning rate: 0.00012055]
	Learning Rate: 0.000120547
	LOSS [training: 0.01487542489546439 | validation: 0.003489576384794255]
	TIME [epoch: 9.08 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00887807848038146		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: 0.00887807848038146 | validation: 0.009225765380590377]
	TIME [epoch: 9.08 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008874328256692692		[learning rate: 0.00011996]
	Learning Rate: 0.000119964
	LOSS [training: 0.008874328256692692 | validation: -0.0012425835172750828]
	TIME [epoch: 9.07 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00725386992752435		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: 0.00725386992752435 | validation: -0.00345729767530897]
	TIME [epoch: 9.07 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007057645577943224		[learning rate: 0.00011938]
	Learning Rate: 0.000119384
	LOSS [training: 0.007057645577943224 | validation: -0.00495629966578985]
	TIME [epoch: 9.07 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011733003485556167		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: 0.011733003485556167 | validation: 0.005088682946972432]
	TIME [epoch: 9.07 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011442938084037289		[learning rate: 0.00011881]
	Learning Rate: 0.000118807
	LOSS [training: 0.011442938084037289 | validation: -0.004293047195334653]
	TIME [epoch: 9.06 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011455872575727704		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: 0.011455872575727704 | validation: -0.00600324549338164]
	TIME [epoch: 9.06 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008330245394957457		[learning rate: 0.00011823]
	Learning Rate: 0.000118232
	LOSS [training: 0.008330245394957457 | validation: -0.005497240746279159]
	TIME [epoch: 9.06 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007244366695598798		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: 0.007244366695598798 | validation: 0.0027313835945105345]
	TIME [epoch: 9.08 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007173735127888907		[learning rate: 0.00011766]
	Learning Rate: 0.000117661
	LOSS [training: 0.007173735127888907 | validation: 0.008045217461800785]
	TIME [epoch: 9.06 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007081660503774387		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: 0.007081660503774387 | validation: 0.00733539984005197]
	TIME [epoch: 9.06 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009142874237267526		[learning rate: 0.00011709]
	Learning Rate: 0.000117092
	LOSS [training: 0.009142874237267526 | validation: 0.0010800947649101747]
	TIME [epoch: 9.06 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013205075063423596		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: 0.013205075063423596 | validation: 0.0010025527341077794]
	TIME [epoch: 9.06 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011140845740643867		[learning rate: 0.00011653]
	Learning Rate: 0.000116526
	LOSS [training: 0.011140845740643867 | validation: -0.0006406872733030538]
	TIME [epoch: 9.08 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008676740218580153		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: 0.008676740218580153 | validation: 0.0015502728415463123]
	TIME [epoch: 9.07 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010463167331756148		[learning rate: 0.00011596]
	Learning Rate: 0.000115962
	LOSS [training: 0.010463167331756148 | validation: 0.002414139532002718]
	TIME [epoch: 9.08 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009246639009198731		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: 0.009246639009198731 | validation: 0.010349635183354019]
	TIME [epoch: 9.06 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01032549716090476		[learning rate: 0.0001154]
	Learning Rate: 0.000115401
	LOSS [training: 0.01032549716090476 | validation: -0.0058250070744917705]
	TIME [epoch: 9.07 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012787659296741449		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: 0.012787659296741449 | validation: 0.003063833040996432]
	TIME [epoch: 9.06 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010129013675925783		[learning rate: 0.00011484]
	Learning Rate: 0.000114843
	LOSS [training: 0.010129013675925783 | validation: 0.0017208650546083528]
	TIME [epoch: 9.06 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009465108219949813		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: 0.009465108219949813 | validation: 0.0049970685595358685]
	TIME [epoch: 9.06 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00812455241956614		[learning rate: 0.00011429]
	Learning Rate: 0.000114288
	LOSS [training: 0.00812455241956614 | validation: -0.0019523391548869284]
	TIME [epoch: 9.06 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01197560122488333		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: 0.01197560122488333 | validation: 0.00018068559577714798]
	TIME [epoch: 9.07 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013959650383243788		[learning rate: 0.00011374]
	Learning Rate: 0.000113735
	LOSS [training: 0.013959650383243788 | validation: 0.0018017627140913329]
	TIME [epoch: 9.06 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006694242650820813		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: 0.006694242650820813 | validation: 0.005741409324164507]
	TIME [epoch: 9.06 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011379028672600494		[learning rate: 0.00011319]
	Learning Rate: 0.000113185
	LOSS [training: 0.011379028672600494 | validation: -0.001201453382957796]
	TIME [epoch: 9.07 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005757212738717323		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: 0.005757212738717323 | validation: -0.00537478474109699]
	TIME [epoch: 9.09 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006488293249694502		[learning rate: 0.00011264]
	Learning Rate: 0.000112638
	LOSS [training: 0.006488293249694502 | validation: 0.002937345542530818]
	TIME [epoch: 9.07 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011660673220010713		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: 0.011660673220010713 | validation: -0.002828181471518942]
	TIME [epoch: 9.07 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011341275736042378		[learning rate: 0.00011209]
	Learning Rate: 0.000112093
	LOSS [training: 0.011341275736042378 | validation: -0.0008352006094256336]
	TIME [epoch: 9.06 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013391183899871586		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: 0.013391183899871586 | validation: 0.008151563089259772]
	TIME [epoch: 9.06 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009269483979156595		[learning rate: 0.00011155]
	Learning Rate: 0.000111551
	LOSS [training: 0.009269483979156595 | validation: 0.0031703172933637523]
	TIME [epoch: 9.08 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0162755597391793		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: 0.0162755597391793 | validation: 0.0004058229600235896]
	TIME [epoch: 9.06 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011850485933260898		[learning rate: 0.00011101]
	Learning Rate: 0.000111012
	LOSS [training: 0.011850485933260898 | validation: 0.003320993567852654]
	TIME [epoch: 9.06 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009675931275033838		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: 0.009675931275033838 | validation: 0.0029294913957270356]
	TIME [epoch: 9.05 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011629970082873104		[learning rate: 0.00011047]
	Learning Rate: 0.000110475
	LOSS [training: 0.011629970082873104 | validation: 0.0028707573876196033]
	TIME [epoch: 9.08 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0073850112411242745		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: 0.0073850112411242745 | validation: -0.0020213495155296615]
	TIME [epoch: 9.06 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007152371038628669		[learning rate: 0.00010994]
	Learning Rate: 0.000109941
	LOSS [training: 0.007152371038628669 | validation: -0.007631301308232045]
	TIME [epoch: 9.06 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01158656549377619		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.01158656549377619 | validation: -0.008986806603027921]
	TIME [epoch: 9.06 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013245341132685263		[learning rate: 0.00010941]
	Learning Rate: 0.000109409
	LOSS [training: 0.013245341132685263 | validation: -0.0066867693599778205]
	TIME [epoch: 9.06 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008533788608866975		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: 0.008533788608866975 | validation: 0.0013654477593412504]
	TIME [epoch: 9.08 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00838210654473991		[learning rate: 0.00010888]
	Learning Rate: 0.00010888
	LOSS [training: 0.00838210654473991 | validation: -0.002791350243230176]
	TIME [epoch: 9.07 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007824633110450225		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: 0.007824633110450225 | validation: 0.0024822287432130245]
	TIME [epoch: 9.06 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0069029253665725265		[learning rate: 0.00010835]
	Learning Rate: 0.000108353
	LOSS [training: 0.0069029253665725265 | validation: 0.00579610100753446]
	TIME [epoch: 9.06 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010571199974016903		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: 0.010571199974016903 | validation: -0.0020996492895953315]
	TIME [epoch: 9.07 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009482780837857628		[learning rate: 0.00010783]
	Learning Rate: 0.000107829
	LOSS [training: 0.009482780837857628 | validation: 0.0008003840408850791]
	TIME [epoch: 9.08 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009996447523388482		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: 0.009996447523388482 | validation: -0.0007776897481543432]
	TIME [epoch: 9.06 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007562824772321114		[learning rate: 0.00010731]
	Learning Rate: 0.000107308
	LOSS [training: 0.007562824772321114 | validation: 0.0022981276770905556]
	TIME [epoch: 9.06 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007762291787282656		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: 0.007762291787282656 | validation: -0.009737554720260026]
	TIME [epoch: 9.06 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008175200777732103		[learning rate: 0.00010679]
	Learning Rate: 0.000106789
	LOSS [training: 0.008175200777732103 | validation: -0.005478786528987136]
	TIME [epoch: 9.07 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008760513945578639		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: 0.008760513945578639 | validation: -0.0021038489072990186]
	TIME [epoch: 9.06 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009659668516643006		[learning rate: 0.00010627]
	Learning Rate: 0.000106273
	LOSS [training: 0.009659668516643006 | validation: 0.005134809720590851]
	TIME [epoch: 9.06 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012458120684207473		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: 0.012458120684207473 | validation: -0.0014918323881201977]
	TIME [epoch: 9.06 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012334780316214175		[learning rate: 0.00010576]
	Learning Rate: 0.000105759
	LOSS [training: 0.012334780316214175 | validation: 0.00753748891942116]
	TIME [epoch: 9.06 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012278633441597414		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: 0.012278633441597414 | validation: 0.009730992793604214]
	TIME [epoch: 9.08 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008863856055447181		[learning rate: 0.00010525]
	Learning Rate: 0.000105247
	LOSS [training: 0.008863856055447181 | validation: -0.00032320692336178073]
	TIME [epoch: 9.05 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010890611418510384		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.010890611418510384 | validation: 0.0072572786640242816]
	TIME [epoch: 9.06 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00495959509828692		[learning rate: 0.00010474]
	Learning Rate: 0.000104738
	LOSS [training: 0.00495959509828692 | validation: -0.005646716146029673]
	TIME [epoch: 9.05 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010173947432172998		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.010173947432172998 | validation: 0.0004508451137338954]
	TIME [epoch: 9.07 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004532327227407159		[learning rate: 0.00010423]
	Learning Rate: 0.000104232
	LOSS [training: 0.004532327227407159 | validation: -0.0020121641754128235]
	TIME [epoch: 9.06 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006165413007554704		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: 0.006165413007554704 | validation: -0.0015544661761497142]
	TIME [epoch: 9.05 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0095805933552381		[learning rate: 0.00010373]
	Learning Rate: 0.000103728
	LOSS [training: 0.0095805933552381 | validation: -0.003883683675572228]
	TIME [epoch: 9.06 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009140693275978303		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: 0.009140693275978303 | validation: -0.008561263576577173]
	TIME [epoch: 9.05 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005897784739739154		[learning rate: 0.00010323]
	Learning Rate: 0.000103226
	LOSS [training: 0.005897784739739154 | validation: 0.0016187334768533502]
	TIME [epoch: 9.07 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0069045840043949714		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: 0.0069045840043949714 | validation: 0.00038694571181293496]
	TIME [epoch: 9.06 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01124231215333587		[learning rate: 0.00010273]
	Learning Rate: 0.000102727
	LOSS [training: 0.01124231215333587 | validation: 0.0012680645060248112]
	TIME [epoch: 9.07 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00643507433950042		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: 0.00643507433950042 | validation: 6.0531859809406785e-05]
	TIME [epoch: 9.07 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013839566218343513		[learning rate: 0.00010223]
	Learning Rate: 0.00010223
	LOSS [training: 0.013839566218343513 | validation: -0.0035161996380042373]
	TIME [epoch: 9.09 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013422953413828107		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: 0.013422953413828107 | validation: 0.0036714748374725784]
	TIME [epoch: 9.06 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013011667854505962		[learning rate: 0.00010174]
	Learning Rate: 0.000101736
	LOSS [training: 0.013011667854505962 | validation: -0.0023684794647893686]
	TIME [epoch: 9.06 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013312502990242179		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: 0.013312502990242179 | validation: 0.002901398751654501]
	TIME [epoch: 9.05 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008531601108686691		[learning rate: 0.00010124]
	Learning Rate: 0.000101244
	LOSS [training: 0.008531601108686691 | validation: 0.007082313833892281]
	TIME [epoch: 9.06 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008912160079907088		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: 0.008912160079907088 | validation: -0.012504974370049778]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r2_20240219_183142/states/model_tr_study4_1996.pth
	Model improved!!!
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006633064726665956		[learning rate: 0.00010075]
	Learning Rate: 0.000100754
	LOSS [training: 0.006633064726665956 | validation: 0.0004837021032819365]
	TIME [epoch: 9.09 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007757197341300192		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.007757197341300192 | validation: -0.007913275396906757]
	TIME [epoch: 9.08 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008814656192839053		[learning rate: 0.00010027]
	Learning Rate: 0.000100267
	LOSS [training: 0.008814656192839053 | validation: 0.008179617850302523]
	TIME [epoch: 9.07 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007383595901211894		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.007383595901211894 | validation: -0.0008457274372583559]
	TIME [epoch: 9.09 sec]
Finished training in 18235.712 seconds.
