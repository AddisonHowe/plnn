Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r1', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3096224591

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/10] avg loss: 8.391606479580478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.391606479580478 | validation: 8.24940687914295]
	TIME [epoch: 48.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/10] avg loss: 7.499742625039052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.499742625039052 | validation: 6.624980414530199]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/10] avg loss: 6.445784805417394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.445784805417394 | validation: 6.6147826594449946]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 10/10] avg loss: 5.817915496158086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.817915496158086 | validation: 5.559748239981989]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/10] avg loss: 5.197944437704996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.197944437704996 | validation: 4.336080398389388]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 10/10] avg loss: 4.432456074760456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.432456074760456 | validation: 3.92671520132838]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/10] avg loss: 3.741735839857455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.741735839857455 | validation: 3.3039570859487304]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 10/10] avg loss: 3.191804172501639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.191804172501639 | validation: 3.050159864034214]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 10/10] avg loss: 3.098402435383293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.098402435383293 | validation: 2.5283748264752797]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 10/10] avg loss: 2.3826806266900635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3826806266900635 | validation: 2.122401514500641]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 10/10] avg loss: 2.3684092953634317		[learning rate: 0.0099578]
	Learning Rate: 0.0099578
	LOSS [training: 2.3684092953634317 | validation: 3.7110536909130554]
	TIME [epoch: 9.1 sec]
EPOCH 12/500:
	Training over batches...
		[batch 10/10] avg loss: 3.414186928728584		[learning rate: 0.0099111]
	Learning Rate: 0.00991111
	LOSS [training: 3.414186928728584 | validation: 3.5704858655735223]
	TIME [epoch: 9.13 sec]
EPOCH 13/500:
	Training over batches...
		[batch 10/10] avg loss: 3.5727957251298044		[learning rate: 0.0098646]
	Learning Rate: 0.00986465
	LOSS [training: 3.5727957251298044 | validation: 4.009184147471615]
	TIME [epoch: 9.1 sec]
EPOCH 14/500:
	Training over batches...
		[batch 10/10] avg loss: 3.316540473084624		[learning rate: 0.0098184]
	Learning Rate: 0.0098184
	LOSS [training: 3.316540473084624 | validation: 3.4017061657420915]
	TIME [epoch: 9.1 sec]
EPOCH 15/500:
	Training over batches...
		[batch 10/10] avg loss: 3.2504378175836273		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 3.2504378175836273 | validation: 3.222807423461241]
	TIME [epoch: 9.11 sec]
EPOCH 16/500:
	Training over batches...
		[batch 10/10] avg loss: 2.606541085515328		[learning rate: 0.0097266]
	Learning Rate: 0.00972656
	LOSS [training: 2.606541085515328 | validation: 1.6023114108781256]
	TIME [epoch: 9.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4226062219852698		[learning rate: 0.009681]
	Learning Rate: 0.00968096
	LOSS [training: 1.4226062219852698 | validation: 1.196962987538729]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 10/10] avg loss: 1.494487724543315		[learning rate: 0.0096356]
	Learning Rate: 0.00963557
	LOSS [training: 1.494487724543315 | validation: 0.9552453768772204]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9068656958612145		[learning rate: 0.0095904]
	Learning Rate: 0.0095904
	LOSS [training: 0.9068656958612145 | validation: 0.6093855055184327]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7745862156130755		[learning rate: 0.0095454]
	Learning Rate: 0.00954544
	LOSS [training: 0.7745862156130755 | validation: 0.7241754718502746]
	TIME [epoch: 9.1 sec]
EPOCH 21/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9139252416977591		[learning rate: 0.0095007]
	Learning Rate: 0.00950069
	LOSS [training: 0.9139252416977591 | validation: 0.6384245922292857]
	TIME [epoch: 9.12 sec]
EPOCH 22/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6391288616122651		[learning rate: 0.0094561]
	Learning Rate: 0.00945615
	LOSS [training: 0.6391288616122651 | validation: 0.7267168435918214]
	TIME [epoch: 9.1 sec]
EPOCH 23/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7126866980836667		[learning rate: 0.0094118]
	Learning Rate: 0.00941182
	LOSS [training: 0.7126866980836667 | validation: 0.7758940124264198]
	TIME [epoch: 9.09 sec]
EPOCH 24/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6354941955369787		[learning rate: 0.0093677]
	Learning Rate: 0.00936769
	LOSS [training: 0.6354941955369787 | validation: 0.5489703705752824]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5885750737993038		[learning rate: 0.0093238]
	Learning Rate: 0.00932378
	LOSS [training: 0.5885750737993038 | validation: 0.6192070879724652]
	TIME [epoch: 9.12 sec]
EPOCH 26/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7286112886717925		[learning rate: 0.0092801]
	Learning Rate: 0.00928007
	LOSS [training: 0.7286112886717925 | validation: 0.7784634827722862]
	TIME [epoch: 9.1 sec]
EPOCH 27/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5961183301804004		[learning rate: 0.0092366]
	Learning Rate: 0.00923656
	LOSS [training: 0.5961183301804004 | validation: 0.5463417406654767]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6501187666596129		[learning rate: 0.0091933]
	Learning Rate: 0.00919326
	LOSS [training: 0.6501187666596129 | validation: 0.6945363610101194]
	TIME [epoch: 9.1 sec]
EPOCH 29/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7833750980829545		[learning rate: 0.0091502]
	Learning Rate: 0.00915016
	LOSS [training: 0.7833750980829545 | validation: 0.49191440967091005]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5968564150009341		[learning rate: 0.0091073]
	Learning Rate: 0.00910726
	LOSS [training: 0.5968564150009341 | validation: 0.5300156107700731]
	TIME [epoch: 9.12 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47748682919291346		[learning rate: 0.0090646]
	Learning Rate: 0.00906456
	LOSS [training: 0.47748682919291346 | validation: 0.4914816842084584]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 10/10] avg loss: 0.570184866580931		[learning rate: 0.0090221]
	Learning Rate: 0.00902207
	LOSS [training: 0.570184866580931 | validation: 0.6451879914992678]
	TIME [epoch: 9.1 sec]
EPOCH 33/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5354129246363989		[learning rate: 0.0089798]
	Learning Rate: 0.00897977
	LOSS [training: 0.5354129246363989 | validation: 0.4790495256835996]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 10/10] avg loss: 0.837896389669295		[learning rate: 0.0089377]
	Learning Rate: 0.00893767
	LOSS [training: 0.837896389669295 | validation: 0.9194492575387283]
	TIME [epoch: 9.12 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6422031018308048		[learning rate: 0.0088958]
	Learning Rate: 0.00889577
	LOSS [training: 0.6422031018308048 | validation: 0.5539178409557564]
	TIME [epoch: 9.11 sec]
EPOCH 36/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4828245238867356		[learning rate: 0.0088541]
	Learning Rate: 0.00885407
	LOSS [training: 0.4828245238867356 | validation: 0.4620434412670727]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5080487364223292		[learning rate: 0.0088126]
	Learning Rate: 0.00881256
	LOSS [training: 0.5080487364223292 | validation: 0.43367165099207483]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5073491473481808		[learning rate: 0.0087712]
	Learning Rate: 0.00877124
	LOSS [training: 0.5073491473481808 | validation: 0.4848081996848125]
	TIME [epoch: 9.1 sec]
EPOCH 39/500:
	Training over batches...
		[batch 10/10] avg loss: 0.557284008180717		[learning rate: 0.0087301]
	Learning Rate: 0.00873012
	LOSS [training: 0.557284008180717 | validation: 0.456560377038797]
	TIME [epoch: 9.13 sec]
EPOCH 40/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5805618200616192		[learning rate: 0.0086892]
	Learning Rate: 0.00868919
	LOSS [training: 0.5805618200616192 | validation: 0.48365471974739793]
	TIME [epoch: 9.1 sec]
EPOCH 41/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6720793883097277		[learning rate: 0.0086485]
	Learning Rate: 0.00864846
	LOSS [training: 0.6720793883097277 | validation: 0.5363662969930972]
	TIME [epoch: 9.1 sec]
EPOCH 42/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5755259976046492		[learning rate: 0.0086079]
	Learning Rate: 0.00860791
	LOSS [training: 0.5755259976046492 | validation: 0.4918136054736779]
	TIME [epoch: 9.1 sec]
EPOCH 43/500:
	Training over batches...
		[batch 10/10] avg loss: 0.490429772077872		[learning rate: 0.0085676]
	Learning Rate: 0.00856756
	LOSS [training: 0.490429772077872 | validation: 0.40647163913940426]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_43.pth
	Model improved!!!
EPOCH 44/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4824550052690643		[learning rate: 0.0085274]
	Learning Rate: 0.00852739
	LOSS [training: 0.4824550052690643 | validation: 0.4858758262795625]
	TIME [epoch: 9.11 sec]
EPOCH 45/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5436723939476094		[learning rate: 0.0084874]
	Learning Rate: 0.00848742
	LOSS [training: 0.5436723939476094 | validation: 0.9650261723790199]
	TIME [epoch: 9.11 sec]
EPOCH 46/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5711039271635563		[learning rate: 0.0084476]
	Learning Rate: 0.00844763
	LOSS [training: 0.5711039271635563 | validation: 0.5332298579842676]
	TIME [epoch: 9.1 sec]
EPOCH 47/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5070248356637613		[learning rate: 0.008408]
	Learning Rate: 0.00840802
	LOSS [training: 0.5070248356637613 | validation: 0.5434263032946021]
	TIME [epoch: 9.11 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6156875246303507		[learning rate: 0.0083686]
	Learning Rate: 0.0083686
	LOSS [training: 0.6156875246303507 | validation: 1.0048130800408752]
	TIME [epoch: 9.12 sec]
EPOCH 49/500:
	Training over batches...
		[batch 10/10] avg loss: 0.621716863512151		[learning rate: 0.0083294]
	Learning Rate: 0.00832937
	LOSS [training: 0.621716863512151 | validation: 0.625199098943968]
	TIME [epoch: 9.11 sec]
EPOCH 50/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5279252493059878		[learning rate: 0.0082903]
	Learning Rate: 0.00829032
	LOSS [training: 0.5279252493059878 | validation: 0.4826420471481861]
	TIME [epoch: 9.1 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5931794206307972		[learning rate: 0.0082515]
	Learning Rate: 0.00825146
	LOSS [training: 0.5931794206307972 | validation: 0.6898254153036638]
	TIME [epoch: 9.1 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5313158506287237		[learning rate: 0.0082128]
	Learning Rate: 0.00821277
	LOSS [training: 0.5313158506287237 | validation: 0.40133749670671404]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41839256862700547		[learning rate: 0.0081743]
	Learning Rate: 0.00817427
	LOSS [training: 0.41839256862700547 | validation: 0.36909602249290174]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40899491164548757		[learning rate: 0.0081359]
	Learning Rate: 0.00813595
	LOSS [training: 0.40899491164548757 | validation: 1.464399463221211]
	TIME [epoch: 9.11 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5222214901425994		[learning rate: 0.0080978]
	Learning Rate: 0.00809781
	LOSS [training: 0.5222214901425994 | validation: 0.3546536144757717]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_55.pth
	Model improved!!!
EPOCH 56/500:
	Training over batches...
		[batch 10/10] avg loss: 0.48975883214710925		[learning rate: 0.0080598]
	Learning Rate: 0.00805984
	LOSS [training: 0.48975883214710925 | validation: 0.46804133675893644]
	TIME [epoch: 9.1 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3955145533743051		[learning rate: 0.0080221]
	Learning Rate: 0.00802206
	LOSS [training: 0.3955145533743051 | validation: 0.33087017773840866]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_57.pth
	Model improved!!!
EPOCH 58/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38548032849589353		[learning rate: 0.0079844]
	Learning Rate: 0.00798445
	LOSS [training: 0.38548032849589353 | validation: 0.633564642974403]
	TIME [epoch: 9.1 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41879612357049495		[learning rate: 0.007947]
	Learning Rate: 0.00794702
	LOSS [training: 0.41879612357049495 | validation: 0.36586476289523184]
	TIME [epoch: 9.1 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45995555217918793		[learning rate: 0.0079098]
	Learning Rate: 0.00790976
	LOSS [training: 0.45995555217918793 | validation: 0.5896897410153956]
	TIME [epoch: 9.1 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/10] avg loss: 0.42612126199240385		[learning rate: 0.0078727]
	Learning Rate: 0.00787268
	LOSS [training: 0.42612126199240385 | validation: 0.32149526550932306]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_61.pth
	Model improved!!!
EPOCH 62/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36473821824315295		[learning rate: 0.0078358]
	Learning Rate: 0.00783577
	LOSS [training: 0.36473821824315295 | validation: 0.24396172372304717]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37127946882681995		[learning rate: 0.007799]
	Learning Rate: 0.00779903
	LOSS [training: 0.37127946882681995 | validation: 0.32870146467366756]
	TIME [epoch: 9.1 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3789405528068267		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 0.3789405528068267 | validation: 0.9733223475125816]
	TIME [epoch: 9.1 sec]
EPOCH 65/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3722477697564078		[learning rate: 0.0077261]
	Learning Rate: 0.00772608
	LOSS [training: 0.3722477697564078 | validation: 0.24794170634390883]
	TIME [epoch: 9.09 sec]
EPOCH 66/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40645996052675504		[learning rate: 0.0076899]
	Learning Rate: 0.00768986
	LOSS [training: 0.40645996052675504 | validation: 0.3722983040421268]
	TIME [epoch: 9.12 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32291124520097614		[learning rate: 0.0076538]
	Learning Rate: 0.00765381
	LOSS [training: 0.32291124520097614 | validation: 0.392469551965302]
	TIME [epoch: 9.09 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3784406493315568		[learning rate: 0.0076179]
	Learning Rate: 0.00761793
	LOSS [training: 0.3784406493315568 | validation: 0.2807652892151671]
	TIME [epoch: 9.1 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6375400411672538		[learning rate: 0.0075822]
	Learning Rate: 0.00758221
	LOSS [training: 0.6375400411672538 | validation: 0.5853239397646257]
	TIME [epoch: 9.1 sec]
EPOCH 70/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37006872455479717		[learning rate: 0.0075467]
	Learning Rate: 0.00754667
	LOSS [training: 0.37006872455479717 | validation: 0.5980671827948396]
	TIME [epoch: 9.1 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/10] avg loss: 0.43686797651400067		[learning rate: 0.0075113]
	Learning Rate: 0.00751129
	LOSS [training: 0.43686797651400067 | validation: 0.4408242821777857]
	TIME [epoch: 9.12 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5415968719387652		[learning rate: 0.0074761]
	Learning Rate: 0.00747607
	LOSS [training: 0.5415968719387652 | validation: 0.25806204439591396]
	TIME [epoch: 9.1 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2841394035925754		[learning rate: 0.007441]
	Learning Rate: 0.00744102
	LOSS [training: 0.2841394035925754 | validation: 0.24399453223769169]
	TIME [epoch: 9.1 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36414060924033864		[learning rate: 0.0074061]
	Learning Rate: 0.00740614
	LOSS [training: 0.36414060924033864 | validation: 0.32870141793847596]
	TIME [epoch: 9.1 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7179635251992131		[learning rate: 0.0073714]
	Learning Rate: 0.00737142
	LOSS [training: 0.7179635251992131 | validation: 0.36423213282198574]
	TIME [epoch: 9.12 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4694521289541512		[learning rate: 0.0073369]
	Learning Rate: 0.00733686
	LOSS [training: 0.4694521289541512 | validation: 0.29641670087900684]
	TIME [epoch: 9.1 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31401177105718914		[learning rate: 0.0073025]
	Learning Rate: 0.00730246
	LOSS [training: 0.31401177105718914 | validation: 0.529880472684841]
	TIME [epoch: 9.1 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38617699174633585		[learning rate: 0.0072682]
	Learning Rate: 0.00726823
	LOSS [training: 0.38617699174633585 | validation: 0.4112055146346388]
	TIME [epoch: 9.1 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41115501482267963		[learning rate: 0.0072342]
	Learning Rate: 0.00723415
	LOSS [training: 0.41115501482267963 | validation: 0.5556169073601918]
	TIME [epoch: 9.1 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4972172219134599		[learning rate: 0.0072002]
	Learning Rate: 0.00720024
	LOSS [training: 0.4972172219134599 | validation: 1.8644697030326263]
	TIME [epoch: 9.12 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6181248273093705		[learning rate: 0.0071665]
	Learning Rate: 0.00716648
	LOSS [training: 0.6181248273093705 | validation: 0.20779873143397304]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_81.pth
	Model improved!!!
EPOCH 82/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25200572959734874		[learning rate: 0.0071329]
	Learning Rate: 0.00713289
	LOSS [training: 0.25200572959734874 | validation: 0.46150749234328103]
	TIME [epoch: 9.1 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30967309702922646		[learning rate: 0.0070994]
	Learning Rate: 0.00709945
	LOSS [training: 0.30967309702922646 | validation: 0.4416844221764638]
	TIME [epoch: 9.1 sec]
EPOCH 84/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31406305952194874		[learning rate: 0.0070662]
	Learning Rate: 0.00706616
	LOSS [training: 0.31406305952194874 | validation: 0.5644556861682487]
	TIME [epoch: 9.12 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3166681766222253		[learning rate: 0.007033]
	Learning Rate: 0.00703304
	LOSS [training: 0.3166681766222253 | validation: 0.22007696997922127]
	TIME [epoch: 9.1 sec]
EPOCH 86/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45651723268288064		[learning rate: 0.0070001]
	Learning Rate: 0.00700006
	LOSS [training: 0.45651723268288064 | validation: 0.4577267314298574]
	TIME [epoch: 9.09 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3471561992305		[learning rate: 0.0069672]
	Learning Rate: 0.00696725
	LOSS [training: 0.3471561992305 | validation: 0.42011645557110344]
	TIME [epoch: 9.09 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38509937640375663		[learning rate: 0.0069346]
	Learning Rate: 0.00693458
	LOSS [training: 0.38509937640375663 | validation: 0.17367031546847606]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_88.pth
	Model improved!!!
EPOCH 89/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6430137396241257		[learning rate: 0.0069021]
	Learning Rate: 0.00690207
	LOSS [training: 0.6430137396241257 | validation: 0.7378529069662985]
	TIME [epoch: 9.14 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30772836391295655		[learning rate: 0.0068697]
	Learning Rate: 0.00686972
	LOSS [training: 0.30772836391295655 | validation: 0.15460967963050837]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_90.pth
	Model improved!!!
EPOCH 91/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2488908408679491		[learning rate: 0.0068375]
	Learning Rate: 0.00683751
	LOSS [training: 0.2488908408679491 | validation: 0.15364004102981224]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_91.pth
	Model improved!!!
EPOCH 92/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3864721989336769		[learning rate: 0.0068055]
	Learning Rate: 0.00680545
	LOSS [training: 0.3864721989336769 | validation: 0.3535212396957867]
	TIME [epoch: 9.11 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27984751138055924		[learning rate: 0.0067735]
	Learning Rate: 0.00677355
	LOSS [training: 0.27984751138055924 | validation: 0.2902790238450027]
	TIME [epoch: 9.13 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/10] avg loss: 0.342870679076631		[learning rate: 0.0067418]
	Learning Rate: 0.00674179
	LOSS [training: 0.342870679076631 | validation: 0.22624439502513488]
	TIME [epoch: 9.11 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30916976827516834		[learning rate: 0.0067102]
	Learning Rate: 0.00671019
	LOSS [training: 0.30916976827516834 | validation: 0.4945910631534393]
	TIME [epoch: 9.11 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27787626067774807		[learning rate: 0.0066787]
	Learning Rate: 0.00667873
	LOSS [training: 0.27787626067774807 | validation: 0.4063046754038364]
	TIME [epoch: 9.1 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3102971421091488		[learning rate: 0.0066474]
	Learning Rate: 0.00664742
	LOSS [training: 0.3102971421091488 | validation: 0.2348947323872423]
	TIME [epoch: 9.11 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26675539219747163		[learning rate: 0.0066163]
	Learning Rate: 0.00661625
	LOSS [training: 0.26675539219747163 | validation: 0.3450520749094398]
	TIME [epoch: 9.13 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2535187904683366		[learning rate: 0.0065852]
	Learning Rate: 0.00658524
	LOSS [training: 0.2535187904683366 | validation: 0.3293573726598841]
	TIME [epoch: 9.1 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32766350153369206		[learning rate: 0.0065544]
	Learning Rate: 0.00655436
	LOSS [training: 0.32766350153369206 | validation: 0.33104547974253407]
	TIME [epoch: 9.1 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3507085372908089		[learning rate: 0.0065236]
	Learning Rate: 0.00652364
	LOSS [training: 0.3507085372908089 | validation: 0.32706463842112066]
	TIME [epoch: 9.1 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/10] avg loss: 0.273332081378968		[learning rate: 0.0064931]
	Learning Rate: 0.00649305
	LOSS [training: 0.273332081378968 | validation: 0.34936169952151463]
	TIME [epoch: 9.11 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3254865112779436		[learning rate: 0.0064626]
	Learning Rate: 0.00646261
	LOSS [training: 0.3254865112779436 | validation: 0.33126705665304423]
	TIME [epoch: 9.11 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2852471518606768		[learning rate: 0.0064323]
	Learning Rate: 0.00643232
	LOSS [training: 0.2852471518606768 | validation: 0.29451508187359976]
	TIME [epoch: 9.1 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31687640712726306		[learning rate: 0.0064022]
	Learning Rate: 0.00640216
	LOSS [training: 0.31687640712726306 | validation: 0.30575861400466603]
	TIME [epoch: 9.1 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47438405584012794		[learning rate: 0.0063721]
	Learning Rate: 0.00637215
	LOSS [training: 0.47438405584012794 | validation: 0.29532775075589596]
	TIME [epoch: 9.12 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5271409340427832		[learning rate: 0.0063423]
	Learning Rate: 0.00634227
	LOSS [training: 0.5271409340427832 | validation: 1.1913525397465188]
	TIME [epoch: 9.14 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5357241557480484		[learning rate: 0.0063125]
	Learning Rate: 0.00631254
	LOSS [training: 0.5357241557480484 | validation: 0.6979170982292547]
	TIME [epoch: 9.12 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41251212368161233		[learning rate: 0.0062829]
	Learning Rate: 0.00628295
	LOSS [training: 0.41251212368161233 | validation: 0.20994675858866996]
	TIME [epoch: 9.11 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23792830389325909		[learning rate: 0.0062535]
	Learning Rate: 0.00625349
	LOSS [training: 0.23792830389325909 | validation: 0.24231544797277826]
	TIME [epoch: 9.11 sec]
EPOCH 111/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2351020590141372		[learning rate: 0.0062242]
	Learning Rate: 0.00622417
	LOSS [training: 0.2351020590141372 | validation: 0.2753154448296324]
	TIME [epoch: 9.1 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24381231733335484		[learning rate: 0.006195]
	Learning Rate: 0.00619499
	LOSS [training: 0.24381231733335484 | validation: 0.20266061582005568]
	TIME [epoch: 9.14 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3539464918970375		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 0.3539464918970375 | validation: 0.25140130954099776]
	TIME [epoch: 9.11 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31442358507113644		[learning rate: 0.006137]
	Learning Rate: 0.00613704
	LOSS [training: 0.31442358507113644 | validation: 0.19078251974522742]
	TIME [epoch: 9.09 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2373127247337313		[learning rate: 0.0061083]
	Learning Rate: 0.00610827
	LOSS [training: 0.2373127247337313 | validation: 0.1993267462205348]
	TIME [epoch: 9.09 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/10] avg loss: 0.230813723255606		[learning rate: 0.0060796]
	Learning Rate: 0.00607964
	LOSS [training: 0.230813723255606 | validation: 0.16157276846563745]
	TIME [epoch: 9.11 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2727914880552546		[learning rate: 0.0060511]
	Learning Rate: 0.00605113
	LOSS [training: 0.2727914880552546 | validation: 0.25383548396638733]
	TIME [epoch: 9.1 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23584714338675056		[learning rate: 0.0060228]
	Learning Rate: 0.00602276
	LOSS [training: 0.23584714338675056 | validation: 0.24434111834134817]
	TIME [epoch: 9.1 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2756385416943087		[learning rate: 0.0059945]
	Learning Rate: 0.00599453
	LOSS [training: 0.2756385416943087 | validation: 0.2225224902507701]
	TIME [epoch: 9.1 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38941749181231217		[learning rate: 0.0059664]
	Learning Rate: 0.00596643
	LOSS [training: 0.38941749181231217 | validation: 0.27097900458305424]
	TIME [epoch: 9.1 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28866591703247535		[learning rate: 0.0059385]
	Learning Rate: 0.00593845
	LOSS [training: 0.28866591703247535 | validation: 0.17756210692113839]
	TIME [epoch: 9.12 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23606086327616996		[learning rate: 0.0059106]
	Learning Rate: 0.00591061
	LOSS [training: 0.23606086327616996 | validation: 0.12251784334221542]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_122.pth
	Model improved!!!
EPOCH 123/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23111860667641088		[learning rate: 0.0058829]
	Learning Rate: 0.0058829
	LOSS [training: 0.23111860667641088 | validation: 0.9865100835146129]
	TIME [epoch: 9.1 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3872200801666549		[learning rate: 0.0058553]
	Learning Rate: 0.00585532
	LOSS [training: 0.3872200801666549 | validation: 0.20875338305733881]
	TIME [epoch: 9.1 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24532057662897605		[learning rate: 0.0058279]
	Learning Rate: 0.00582787
	LOSS [training: 0.24532057662897605 | validation: 0.20439188855544052]
	TIME [epoch: 9.12 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32764920116520674		[learning rate: 0.0058006]
	Learning Rate: 0.00580055
	LOSS [training: 0.32764920116520674 | validation: 0.23083900381475003]
	TIME [epoch: 9.1 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34554517782991606		[learning rate: 0.0057734]
	Learning Rate: 0.00577336
	LOSS [training: 0.34554517782991606 | validation: 0.25360026475351294]
	TIME [epoch: 9.1 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25570614350466725		[learning rate: 0.0057463]
	Learning Rate: 0.00574629
	LOSS [training: 0.25570614350466725 | validation: 0.20313122754468077]
	TIME [epoch: 9.09 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21311125696253433		[learning rate: 0.0057194]
	Learning Rate: 0.00571935
	LOSS [training: 0.21311125696253433 | validation: 0.13347183550307407]
	TIME [epoch: 9.09 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25480877238744853		[learning rate: 0.0056925]
	Learning Rate: 0.00569254
	LOSS [training: 0.25480877238744853 | validation: 0.3078579597723884]
	TIME [epoch: 9.21 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26934453298045513		[learning rate: 0.0056659]
	Learning Rate: 0.00566585
	LOSS [training: 0.26934453298045513 | validation: 0.24817613406788597]
	TIME [epoch: 9.11 sec]
EPOCH 132/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20113996143391275		[learning rate: 0.0056393]
	Learning Rate: 0.00563929
	LOSS [training: 0.20113996143391275 | validation: 0.46055182546965445]
	TIME [epoch: 9.1 sec]
EPOCH 133/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25671482920013633		[learning rate: 0.0056129]
	Learning Rate: 0.00561285
	LOSS [training: 0.25671482920013633 | validation: 0.22812279015122788]
	TIME [epoch: 9.1 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2673038728485093		[learning rate: 0.0055865]
	Learning Rate: 0.00558654
	LOSS [training: 0.2673038728485093 | validation: 0.35737668925423427]
	TIME [epoch: 9.11 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26000344811123177		[learning rate: 0.0055603]
	Learning Rate: 0.00556035
	LOSS [training: 0.26000344811123177 | validation: 0.3400791047544858]
	TIME [epoch: 9.11 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24630544792857112		[learning rate: 0.0055343]
	Learning Rate: 0.00553428
	LOSS [training: 0.24630544792857112 | validation: 0.15095658153531377]
	TIME [epoch: 9.09 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2276265782209513		[learning rate: 0.0055083]
	Learning Rate: 0.00550834
	LOSS [training: 0.2276265782209513 | validation: 0.3466020929445667]
	TIME [epoch: 9.1 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22648885582465242		[learning rate: 0.0054825]
	Learning Rate: 0.00548251
	LOSS [training: 0.22648885582465242 | validation: 0.15926787124972114]
	TIME [epoch: 9.1 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5281566970658682		[learning rate: 0.0054568]
	Learning Rate: 0.00545681
	LOSS [training: 0.5281566970658682 | validation: 0.6488810230284553]
	TIME [epoch: 9.12 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39326083558236563		[learning rate: 0.0054312]
	Learning Rate: 0.00543123
	LOSS [training: 0.39326083558236563 | validation: 0.26015985217103255]
	TIME [epoch: 9.1 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2344459336217135		[learning rate: 0.0054058]
	Learning Rate: 0.00540576
	LOSS [training: 0.2344459336217135 | validation: 0.40537892677869314]
	TIME [epoch: 9.1 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22756022109814303		[learning rate: 0.0053804]
	Learning Rate: 0.00538042
	LOSS [training: 0.22756022109814303 | validation: 0.25705385318501534]
	TIME [epoch: 9.09 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2124507417341992		[learning rate: 0.0053552]
	Learning Rate: 0.0053552
	LOSS [training: 0.2124507417341992 | validation: 0.42690585358434396]
	TIME [epoch: 9.1 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27727320325320465		[learning rate: 0.0053301]
	Learning Rate: 0.00533009
	LOSS [training: 0.27727320325320465 | validation: 0.37184929452724347]
	TIME [epoch: 9.12 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23764569629694265		[learning rate: 0.0053051]
	Learning Rate: 0.0053051
	LOSS [training: 0.23764569629694265 | validation: 0.6766657083975625]
	TIME [epoch: 9.09 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29511993063828124		[learning rate: 0.0052802]
	Learning Rate: 0.00528023
	LOSS [training: 0.29511993063828124 | validation: 0.16637818166620105]
	TIME [epoch: 9.1 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23471588116559886		[learning rate: 0.0052555]
	Learning Rate: 0.00525548
	LOSS [training: 0.23471588116559886 | validation: 0.2867961025990965]
	TIME [epoch: 9.09 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28039936723600645		[learning rate: 0.0052308]
	Learning Rate: 0.00523084
	LOSS [training: 0.28039936723600645 | validation: 0.7400390698670105]
	TIME [epoch: 9.11 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5135044409592082		[learning rate: 0.0052063]
	Learning Rate: 0.00520632
	LOSS [training: 0.5135044409592082 | validation: 0.2182205189107914]
	TIME [epoch: 9.1 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18667132800838826		[learning rate: 0.0051819]
	Learning Rate: 0.00518191
	LOSS [training: 0.18667132800838826 | validation: 0.21336134180744976]
	TIME [epoch: 9.09 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/10] avg loss: 0.274540451771446		[learning rate: 0.0051576]
	Learning Rate: 0.00515762
	LOSS [training: 0.274540451771446 | validation: 0.14341798989914606]
	TIME [epoch: 9.09 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2293342888095725		[learning rate: 0.0051334]
	Learning Rate: 0.00513344
	LOSS [training: 0.2293342888095725 | validation: 0.25702395133673506]
	TIME [epoch: 9.09 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24707267568658006		[learning rate: 0.0051094]
	Learning Rate: 0.00510937
	LOSS [training: 0.24707267568658006 | validation: 0.40287961046573206]
	TIME [epoch: 9.11 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33195359082680925		[learning rate: 0.0050854]
	Learning Rate: 0.00508542
	LOSS [training: 0.33195359082680925 | validation: 0.2912045824984235]
	TIME [epoch: 9.09 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6406236217577443		[learning rate: 0.0050616]
	Learning Rate: 0.00506158
	LOSS [training: 0.6406236217577443 | validation: 0.22697488892632584]
	TIME [epoch: 9.09 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2208065617067974		[learning rate: 0.0050378]
	Learning Rate: 0.00503785
	LOSS [training: 0.2208065617067974 | validation: 0.23511377908587097]
	TIME [epoch: 9.09 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25452728232381683		[learning rate: 0.0050142]
	Learning Rate: 0.00501423
	LOSS [training: 0.25452728232381683 | validation: 0.15801805844963845]
	TIME [epoch: 9.11 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2136084141726106		[learning rate: 0.0049907]
	Learning Rate: 0.00499072
	LOSS [training: 0.2136084141726106 | validation: 0.15672929755990966]
	TIME [epoch: 9.09 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16152326494996383		[learning rate: 0.0049673]
	Learning Rate: 0.00496732
	LOSS [training: 0.16152326494996383 | validation: 0.2214934657197351]
	TIME [epoch: 9.09 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19332853194064034		[learning rate: 0.004944]
	Learning Rate: 0.00494404
	LOSS [training: 0.19332853194064034 | validation: 0.23716838038391252]
	TIME [epoch: 9.09 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25643277163331407		[learning rate: 0.0049209]
	Learning Rate: 0.00492086
	LOSS [training: 0.25643277163331407 | validation: 0.3180567935260591]
	TIME [epoch: 9.09 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4168006510974117		[learning rate: 0.0048978]
	Learning Rate: 0.00489779
	LOSS [training: 0.4168006510974117 | validation: 0.2719128419025044]
	TIME [epoch: 9.11 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24199382545481715		[learning rate: 0.0048748]
	Learning Rate: 0.00487483
	LOSS [training: 0.24199382545481715 | validation: 0.18044981573134847]
	TIME [epoch: 9.09 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19401147534448143		[learning rate: 0.004852]
	Learning Rate: 0.00485197
	LOSS [training: 0.19401147534448143 | validation: 0.5292526002075848]
	TIME [epoch: 9.09 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35123133552751046		[learning rate: 0.0048292]
	Learning Rate: 0.00482923
	LOSS [training: 0.35123133552751046 | validation: 0.2145549543873555]
	TIME [epoch: 9.09 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19081844177211582		[learning rate: 0.0048066]
	Learning Rate: 0.00480659
	LOSS [training: 0.19081844177211582 | validation: 0.22898846024910818]
	TIME [epoch: 9.09 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14580211216617894		[learning rate: 0.0047841]
	Learning Rate: 0.00478405
	LOSS [training: 0.14580211216617894 | validation: 0.17411174597440737]
	TIME [epoch: 9.11 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/10] avg loss: 0.198641598212331		[learning rate: 0.0047616]
	Learning Rate: 0.00476162
	LOSS [training: 0.198641598212331 | validation: 0.1271764137977161]
	TIME [epoch: 9.09 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2274154202755362		[learning rate: 0.0047393]
	Learning Rate: 0.0047393
	LOSS [training: 0.2274154202755362 | validation: 0.3201293861963971]
	TIME [epoch: 9.09 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2385392320904141		[learning rate: 0.0047171]
	Learning Rate: 0.00471708
	LOSS [training: 0.2385392320904141 | validation: 0.14715102388822135]
	TIME [epoch: 9.09 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1729273997784219		[learning rate: 0.004695]
	Learning Rate: 0.00469497
	LOSS [training: 0.1729273997784219 | validation: 0.10993239739719161]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_171.pth
	Model improved!!!
EPOCH 172/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12365282322889534		[learning rate: 0.004673]
	Learning Rate: 0.00467296
	LOSS [training: 0.12365282322889534 | validation: 0.1137658799423884]
	TIME [epoch: 9.1 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19746650379279926		[learning rate: 0.0046511]
	Learning Rate: 0.00465105
	LOSS [training: 0.19746650379279926 | validation: 0.2979273344092066]
	TIME [epoch: 9.09 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3505276140607085		[learning rate: 0.0046292]
	Learning Rate: 0.00462925
	LOSS [training: 0.3505276140607085 | validation: 0.5944800828714853]
	TIME [epoch: 9.09 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4062265308779186		[learning rate: 0.0046075]
	Learning Rate: 0.00460754
	LOSS [training: 0.4062265308779186 | validation: 0.3093989582609965]
	TIME [epoch: 9.09 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23121981300124567		[learning rate: 0.0045859]
	Learning Rate: 0.00458594
	LOSS [training: 0.23121981300124567 | validation: 0.3919025016734375]
	TIME [epoch: 9.11 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3732668641172446		[learning rate: 0.0045644]
	Learning Rate: 0.00456444
	LOSS [training: 0.3732668641172446 | validation: 0.30773756999954427]
	TIME [epoch: 9.08 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20726937788482896		[learning rate: 0.004543]
	Learning Rate: 0.00454304
	LOSS [training: 0.20726937788482896 | validation: 0.12568314983666143]
	TIME [epoch: 9.08 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16431543790287978		[learning rate: 0.0045217]
	Learning Rate: 0.00452175
	LOSS [training: 0.16431543790287978 | validation: 0.09874207539648688]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_179.pth
	Model improved!!!
EPOCH 180/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13645651441014287		[learning rate: 0.0045005]
	Learning Rate: 0.00450055
	LOSS [training: 0.13645651441014287 | validation: 0.17958093680022116]
	TIME [epoch: 9.11 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1460187214137643		[learning rate: 0.0044794]
	Learning Rate: 0.00447945
	LOSS [training: 0.1460187214137643 | validation: 0.25346883825921074]
	TIME [epoch: 9.1 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13864119192617458		[learning rate: 0.0044584]
	Learning Rate: 0.00445845
	LOSS [training: 0.13864119192617458 | validation: 0.08167187140691515]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_182.pth
	Model improved!!!
EPOCH 183/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17689480674077568		[learning rate: 0.0044375]
	Learning Rate: 0.00443755
	LOSS [training: 0.17689480674077568 | validation: 0.12438810405190445]
	TIME [epoch: 9.09 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17812970527793043		[learning rate: 0.0044167]
	Learning Rate: 0.00441674
	LOSS [training: 0.17812970527793043 | validation: 0.20753118070489684]
	TIME [epoch: 9.09 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1661981239011615		[learning rate: 0.004396]
	Learning Rate: 0.00439604
	LOSS [training: 0.1661981239011615 | validation: 0.3642289007238615]
	TIME [epoch: 9.11 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18792283535447557		[learning rate: 0.0043754]
	Learning Rate: 0.00437543
	LOSS [training: 0.18792283535447557 | validation: 0.22607243760902335]
	TIME [epoch: 9.08 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16046475151676667		[learning rate: 0.0043549]
	Learning Rate: 0.00435491
	LOSS [training: 0.16046475151676667 | validation: 0.3021283717593285]
	TIME [epoch: 9.09 sec]
EPOCH 188/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16252512766533403		[learning rate: 0.0043345]
	Learning Rate: 0.0043345
	LOSS [training: 0.16252512766533403 | validation: 0.13036809428743215]
	TIME [epoch: 9.09 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16096138370889396		[learning rate: 0.0043142]
	Learning Rate: 0.00431418
	LOSS [training: 0.16096138370889396 | validation: 0.2467269452556139]
	TIME [epoch: 9.11 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14338120456448594		[learning rate: 0.004294]
	Learning Rate: 0.00429395
	LOSS [training: 0.14338120456448594 | validation: 0.7795191170151878]
	TIME [epoch: 9.09 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34329427820040764		[learning rate: 0.0042738]
	Learning Rate: 0.00427382
	LOSS [training: 0.34329427820040764 | validation: 0.33956750236904715]
	TIME [epoch: 9.08 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16918892002482694		[learning rate: 0.0042538]
	Learning Rate: 0.00425378
	LOSS [training: 0.16918892002482694 | validation: 0.17501518538921368]
	TIME [epoch: 9.09 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11418895874057226		[learning rate: 0.0042338]
	Learning Rate: 0.00423384
	LOSS [training: 0.11418895874057226 | validation: 0.10568514836758264]
	TIME [epoch: 9.08 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13808683359253865		[learning rate: 0.004214]
	Learning Rate: 0.00421399
	LOSS [training: 0.13808683359253865 | validation: 0.12087018866280938]
	TIME [epoch: 9.11 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11172080257007186		[learning rate: 0.0041942]
	Learning Rate: 0.00419424
	LOSS [training: 0.11172080257007186 | validation: 0.10660662663041823]
	TIME [epoch: 9.1 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0896526965286719		[learning rate: 0.0041746]
	Learning Rate: 0.00417457
	LOSS [training: 0.0896526965286719 | validation: 0.15008558712559658]
	TIME [epoch: 9.09 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14823805897395975		[learning rate: 0.004155]
	Learning Rate: 0.004155
	LOSS [training: 0.14823805897395975 | validation: 0.20070237736592378]
	TIME [epoch: 9.09 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21443578516174192		[learning rate: 0.0041355]
	Learning Rate: 0.00413552
	LOSS [training: 0.21443578516174192 | validation: 0.1439222906676332]
	TIME [epoch: 9.1 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1478525929598447		[learning rate: 0.0041161]
	Learning Rate: 0.00411614
	LOSS [training: 0.1478525929598447 | validation: 0.10710527997496044]
	TIME [epoch: 9.1 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1745731913257634		[learning rate: 0.0040968]
	Learning Rate: 0.00409684
	LOSS [training: 0.1745731913257634 | validation: 0.16852876844018494]
	TIME [epoch: 9.09 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2301067254002656		[learning rate: 0.0040776]
	Learning Rate: 0.00407763
	LOSS [training: 0.2301067254002656 | validation: 0.22502110423513005]
	TIME [epoch: 9.09 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1697306157502064		[learning rate: 0.0040585]
	Learning Rate: 0.00405852
	LOSS [training: 0.1697306157502064 | validation: 0.24735004347693165]
	TIME [epoch: 9.09 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19922921026879076		[learning rate: 0.0040395]
	Learning Rate: 0.00403949
	LOSS [training: 0.19922921026879076 | validation: 0.22580720274579055]
	TIME [epoch: 9.11 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1466229624960837		[learning rate: 0.0040206]
	Learning Rate: 0.00402055
	LOSS [training: 0.1466229624960837 | validation: 0.3830187064933494]
	TIME [epoch: 9.09 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16737746991365582		[learning rate: 0.0040017]
	Learning Rate: 0.0040017
	LOSS [training: 0.16737746991365582 | validation: 0.17583253137309485]
	TIME [epoch: 9.1 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18603158597767283		[learning rate: 0.0039829]
	Learning Rate: 0.00398294
	LOSS [training: 0.18603158597767283 | validation: 0.19176222169394486]
	TIME [epoch: 9.09 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21856596877975898		[learning rate: 0.0039643]
	Learning Rate: 0.00396427
	LOSS [training: 0.21856596877975898 | validation: 0.5301484571750126]
	TIME [epoch: 9.09 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3470724507471695		[learning rate: 0.0039457]
	Learning Rate: 0.00394569
	LOSS [training: 0.3470724507471695 | validation: 0.16636817432278708]
	TIME [epoch: 9.12 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27251460824421553		[learning rate: 0.0039272]
	Learning Rate: 0.00392719
	LOSS [training: 0.27251460824421553 | validation: 0.27512121242690096]
	TIME [epoch: 9.09 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14059073863191543		[learning rate: 0.0039088]
	Learning Rate: 0.00390878
	LOSS [training: 0.14059073863191543 | validation: 0.19860384741480175]
	TIME [epoch: 9.1 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19236065571528352		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.19236065571528352 | validation: 0.14157813676274805]
	TIME [epoch: 9.09 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28780154478689746		[learning rate: 0.0038722]
	Learning Rate: 0.00387221
	LOSS [training: 0.28780154478689746 | validation: 0.24561761680998515]
	TIME [epoch: 9.11 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23084376593187575		[learning rate: 0.0038541]
	Learning Rate: 0.00385406
	LOSS [training: 0.23084376593187575 | validation: 0.19503662616413583]
	TIME [epoch: 9.1 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15860483006495604		[learning rate: 0.003836]
	Learning Rate: 0.00383599
	LOSS [training: 0.15860483006495604 | validation: 0.4533240196753088]
	TIME [epoch: 9.09 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19885147345317694		[learning rate: 0.003818]
	Learning Rate: 0.00381801
	LOSS [training: 0.19885147345317694 | validation: 0.18182428401410458]
	TIME [epoch: 9.09 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20427642732780496		[learning rate: 0.0038001]
	Learning Rate: 0.00380011
	LOSS [training: 0.20427642732780496 | validation: 0.17744559938616813]
	TIME [epoch: 9.09 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21924360387636183		[learning rate: 0.0037823]
	Learning Rate: 0.00378229
	LOSS [training: 0.21924360387636183 | validation: 0.16393438734526727]
	TIME [epoch: 9.11 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2134187771128296		[learning rate: 0.0037646]
	Learning Rate: 0.00376456
	LOSS [training: 0.2134187771128296 | validation: 0.17460938503308843]
	TIME [epoch: 9.09 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16794807565819286		[learning rate: 0.0037469]
	Learning Rate: 0.00374691
	LOSS [training: 0.16794807565819286 | validation: 0.16728459866622591]
	TIME [epoch: 9.1 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1573652077436855		[learning rate: 0.0037293]
	Learning Rate: 0.00372935
	LOSS [training: 0.1573652077436855 | validation: 0.12446148958486788]
	TIME [epoch: 9.09 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20588740732043637		[learning rate: 0.0037119]
	Learning Rate: 0.00371186
	LOSS [training: 0.20588740732043637 | validation: 0.13460600408185872]
	TIME [epoch: 9.1 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1761497136171128		[learning rate: 0.0036945]
	Learning Rate: 0.00369446
	LOSS [training: 0.1761497136171128 | validation: 0.22234130025617593]
	TIME [epoch: 9.1 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17008373237325106		[learning rate: 0.0036771]
	Learning Rate: 0.00367714
	LOSS [training: 0.17008373237325106 | validation: 0.18357234283035506]
	TIME [epoch: 9.09 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17947599546639273		[learning rate: 0.0036599]
	Learning Rate: 0.0036599
	LOSS [training: 0.17947599546639273 | validation: 0.14888475900803527]
	TIME [epoch: 9.09 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12179456522482687		[learning rate: 0.0036427]
	Learning Rate: 0.00364274
	LOSS [training: 0.12179456522482687 | validation: 0.09012420939796009]
	TIME [epoch: 9.09 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12871522246058645		[learning rate: 0.0036257]
	Learning Rate: 0.00362567
	LOSS [training: 0.12871522246058645 | validation: 0.5353693650949344]
	TIME [epoch: 9.11 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25440629104074985		[learning rate: 0.0036087]
	Learning Rate: 0.00360867
	LOSS [training: 0.25440629104074985 | validation: 0.10557333006144681]
	TIME [epoch: 9.09 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13181749351123948		[learning rate: 0.0035918]
	Learning Rate: 0.00359175
	LOSS [training: 0.13181749351123948 | validation: 0.11599282876257494]
	TIME [epoch: 9.09 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13436322210343904		[learning rate: 0.0035749]
	Learning Rate: 0.00357491
	LOSS [training: 0.13436322210343904 | validation: 0.09189856506285632]
	TIME [epoch: 9.09 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10214492697857946		[learning rate: 0.0035582]
	Learning Rate: 0.00355815
	LOSS [training: 0.10214492697857946 | validation: 0.10742314069041636]
	TIME [epoch: 9.08 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11118465119181509		[learning rate: 0.0035415]
	Learning Rate: 0.00354147
	LOSS [training: 0.11118465119181509 | validation: 0.11309008702466561]
	TIME [epoch: 9.11 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1321096981159721		[learning rate: 0.0035249]
	Learning Rate: 0.00352487
	LOSS [training: 0.1321096981159721 | validation: 0.11408902868010454]
	TIME [epoch: 9.09 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17142445744667353		[learning rate: 0.0035083]
	Learning Rate: 0.00350834
	LOSS [training: 0.17142445744667353 | validation: 0.2431424166504806]
	TIME [epoch: 9.09 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2683153947357729		[learning rate: 0.0034919]
	Learning Rate: 0.0034919
	LOSS [training: 0.2683153947357729 | validation: 0.22927105281748733]
	TIME [epoch: 9.09 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17497237068328583		[learning rate: 0.0034755]
	Learning Rate: 0.00347552
	LOSS [training: 0.17497237068328583 | validation: 0.11985280971882219]
	TIME [epoch: 9.11 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18618301746170432		[learning rate: 0.0034592]
	Learning Rate: 0.00345923
	LOSS [training: 0.18618301746170432 | validation: 0.1253501747031338]
	TIME [epoch: 9.09 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1188893702031125		[learning rate: 0.003443]
	Learning Rate: 0.00344301
	LOSS [training: 0.1188893702031125 | validation: 0.10515314319764921]
	TIME [epoch: 9.09 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15119726680476625		[learning rate: 0.0034269]
	Learning Rate: 0.00342687
	LOSS [training: 0.15119726680476625 | validation: 0.4844331962058064]
	TIME [epoch: 9.09 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17291330778490668		[learning rate: 0.0034108]
	Learning Rate: 0.00341081
	LOSS [training: 0.17291330778490668 | validation: 0.2568146956012798]
	TIME [epoch: 9.09 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17672638447579378		[learning rate: 0.0033948]
	Learning Rate: 0.00339482
	LOSS [training: 0.17672638447579378 | validation: 0.13025767793915954]
	TIME [epoch: 9.11 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18837243110350627		[learning rate: 0.0033789]
	Learning Rate: 0.0033789
	LOSS [training: 0.18837243110350627 | validation: 0.16480924706266223]
	TIME [epoch: 9.1 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16157677290537906		[learning rate: 0.0033631]
	Learning Rate: 0.00336306
	LOSS [training: 0.16157677290537906 | validation: 0.19917777054383495]
	TIME [epoch: 9.1 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14630950134780332		[learning rate: 0.0033473]
	Learning Rate: 0.00334729
	LOSS [training: 0.14630950134780332 | validation: 0.09903467903392402]
	TIME [epoch: 9.1 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13924315511454388		[learning rate: 0.0033316]
	Learning Rate: 0.0033316
	LOSS [training: 0.13924315511454388 | validation: 0.16384563288676107]
	TIME [epoch: 9.11 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07551475588384651		[learning rate: 0.003316]
	Learning Rate: 0.00331598
	LOSS [training: 0.07551475588384651 | validation: 0.04820003171050166]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_245.pth
	Model improved!!!
EPOCH 246/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11227012631272926		[learning rate: 0.0033004]
	Learning Rate: 0.00330044
	LOSS [training: 0.11227012631272926 | validation: 0.17579293881590066]
	TIME [epoch: 9.09 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14063805510666158		[learning rate: 0.003285]
	Learning Rate: 0.00328496
	LOSS [training: 0.14063805510666158 | validation: 0.26143748476161477]
	TIME [epoch: 9.09 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10598359029282212		[learning rate: 0.0032696]
	Learning Rate: 0.00326956
	LOSS [training: 0.10598359029282212 | validation: 0.09485831740907111]
	TIME [epoch: 9.09 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0813677474962338		[learning rate: 0.0032542]
	Learning Rate: 0.00325424
	LOSS [training: 0.0813677474962338 | validation: 0.07275598684494526]
	TIME [epoch: 9.12 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16808421087045902		[learning rate: 0.003239]
	Learning Rate: 0.00323898
	LOSS [training: 0.16808421087045902 | validation: 0.09159599946602667]
	TIME [epoch: 9.1 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12045627187416652		[learning rate: 0.0032238]
	Learning Rate: 0.00322379
	LOSS [training: 0.12045627187416652 | validation: 0.1774134268731109]
	TIME [epoch: 9.09 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10535059690924675		[learning rate: 0.0032087]
	Learning Rate: 0.00320868
	LOSS [training: 0.10535059690924675 | validation: 0.10675898863765991]
	TIME [epoch: 9.09 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10864434593145691		[learning rate: 0.0031936]
	Learning Rate: 0.00319364
	LOSS [training: 0.10864434593145691 | validation: 0.09862069529415418]
	TIME [epoch: 9.11 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08998840567650317		[learning rate: 0.0031787]
	Learning Rate: 0.00317867
	LOSS [training: 0.08998840567650317 | validation: 0.11070767202617889]
	TIME [epoch: 9.11 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08577666702695544		[learning rate: 0.0031638]
	Learning Rate: 0.00316376
	LOSS [training: 0.08577666702695544 | validation: 0.07937859740860449]
	TIME [epoch: 9.09 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15605040604558942		[learning rate: 0.0031489]
	Learning Rate: 0.00314893
	LOSS [training: 0.15605040604558942 | validation: 0.11424978133291508]
	TIME [epoch: 9.09 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10714791681439968		[learning rate: 0.0031342]
	Learning Rate: 0.00313417
	LOSS [training: 0.10714791681439968 | validation: 0.16550697639294182]
	TIME [epoch: 9.09 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1353794395277847		[learning rate: 0.0031195]
	Learning Rate: 0.00311948
	LOSS [training: 0.1353794395277847 | validation: 0.11504719494025775]
	TIME [epoch: 9.11 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11121777495732288		[learning rate: 0.0031049]
	Learning Rate: 0.00310485
	LOSS [training: 0.11121777495732288 | validation: 0.07773201167976482]
	TIME [epoch: 9.1 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21851754626730885		[learning rate: 0.0030903]
	Learning Rate: 0.0030903
	LOSS [training: 0.21851754626730885 | validation: 0.10374332386962445]
	TIME [epoch: 9.09 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1202919995411981		[learning rate: 0.0030758]
	Learning Rate: 0.00307581
	LOSS [training: 0.1202919995411981 | validation: 0.35807279668808434]
	TIME [epoch: 9.09 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27274009980026415		[learning rate: 0.0030614]
	Learning Rate: 0.00306139
	LOSS [training: 0.27274009980026415 | validation: 0.22068943289127324]
	TIME [epoch: 9.1 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18407547554109555		[learning rate: 0.003047]
	Learning Rate: 0.00304704
	LOSS [training: 0.18407547554109555 | validation: 0.3629444064641032]
	TIME [epoch: 9.12 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24608778730075076		[learning rate: 0.0030328]
	Learning Rate: 0.00303275
	LOSS [training: 0.24608778730075076 | validation: 0.11973011470015851]
	TIME [epoch: 9.09 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12188154453168283		[learning rate: 0.0030185]
	Learning Rate: 0.00301853
	LOSS [training: 0.12188154453168283 | validation: 0.11941170379427496]
	TIME [epoch: 9.09 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1290595584873107		[learning rate: 0.0030044]
	Learning Rate: 0.00300438
	LOSS [training: 0.1290595584873107 | validation: 0.7569340848563517]
	TIME [epoch: 9.1 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23785752583503209		[learning rate: 0.0029903]
	Learning Rate: 0.0029903
	LOSS [training: 0.23785752583503209 | validation: 0.10217580586479996]
	TIME [epoch: 9.1 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16988871864583194		[learning rate: 0.0029763]
	Learning Rate: 0.00297628
	LOSS [training: 0.16988871864583194 | validation: 0.13018114879019488]
	TIME [epoch: 9.1 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10385956481803668		[learning rate: 0.0029623]
	Learning Rate: 0.00296232
	LOSS [training: 0.10385956481803668 | validation: 0.1929223010950123]
	TIME [epoch: 9.09 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14362847504030193		[learning rate: 0.0029484]
	Learning Rate: 0.00294844
	LOSS [training: 0.14362847504030193 | validation: 0.08540712385254327]
	TIME [epoch: 9.09 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09351072336662711		[learning rate: 0.0029346]
	Learning Rate: 0.00293461
	LOSS [training: 0.09351072336662711 | validation: 0.04633978050527655]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_271.pth
	Model improved!!!
EPOCH 272/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08642117552255521		[learning rate: 0.0029209]
	Learning Rate: 0.00292086
	LOSS [training: 0.08642117552255521 | validation: 0.07236023250795137]
	TIME [epoch: 9.11 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1250652726067919		[learning rate: 0.0029072]
	Learning Rate: 0.00290716
	LOSS [training: 0.1250652726067919 | validation: 0.08808009893928598]
	TIME [epoch: 9.08 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08933330171635354		[learning rate: 0.0028935]
	Learning Rate: 0.00289353
	LOSS [training: 0.08933330171635354 | validation: 0.24898191959377278]
	TIME [epoch: 9.09 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24000029846312682		[learning rate: 0.00288]
	Learning Rate: 0.00287997
	LOSS [training: 0.24000029846312682 | validation: 0.08740092663482862]
	TIME [epoch: 9.08 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14565241721226635		[learning rate: 0.0028665]
	Learning Rate: 0.00286647
	LOSS [training: 0.14565241721226635 | validation: 0.3038277698586026]
	TIME [epoch: 9.1 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17767003293051323		[learning rate: 0.002853]
	Learning Rate: 0.00285303
	LOSS [training: 0.17767003293051323 | validation: 0.0773053742042621]
	TIME [epoch: 9.09 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11536306615826011		[learning rate: 0.0028397]
	Learning Rate: 0.00283965
	LOSS [training: 0.11536306615826011 | validation: 0.3066676438158514]
	TIME [epoch: 9.09 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2715150193829015		[learning rate: 0.0028263]
	Learning Rate: 0.00282634
	LOSS [training: 0.2715150193829015 | validation: 0.19442814203518893]
	TIME [epoch: 9.09 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20163220243951221		[learning rate: 0.0028131]
	Learning Rate: 0.00281309
	LOSS [training: 0.20163220243951221 | validation: 0.21619126510833842]
	TIME [epoch: 9.09 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12022314257743183		[learning rate: 0.0027999]
	Learning Rate: 0.0027999
	LOSS [training: 0.12022314257743183 | validation: 0.06165820124351211]
	TIME [epoch: 9.11 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13619723259599223		[learning rate: 0.0027868]
	Learning Rate: 0.00278678
	LOSS [training: 0.13619723259599223 | validation: 0.3979794003805496]
	TIME [epoch: 9.09 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25845976820580563		[learning rate: 0.0027737]
	Learning Rate: 0.00277371
	LOSS [training: 0.25845976820580563 | validation: 0.18492921869831552]
	TIME [epoch: 9.08 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14222635498778016		[learning rate: 0.0027607]
	Learning Rate: 0.00276071
	LOSS [training: 0.14222635498778016 | validation: 0.07467521000491441]
	TIME [epoch: 9.08 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07713829766800567		[learning rate: 0.0027478]
	Learning Rate: 0.00274776
	LOSS [training: 0.07713829766800567 | validation: 0.06442792665609436]
	TIME [epoch: 9.09 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05414008390768902		[learning rate: 0.0027349]
	Learning Rate: 0.00273488
	LOSS [training: 0.05414008390768902 | validation: 0.09261669410542492]
	TIME [epoch: 9.11 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/10] avg loss: 0.059097599176832404		[learning rate: 0.0027221]
	Learning Rate: 0.00272206
	LOSS [training: 0.059097599176832404 | validation: 0.05338629103299132]
	TIME [epoch: 9.08 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07319973867746153		[learning rate: 0.0027093]
	Learning Rate: 0.0027093
	LOSS [training: 0.07319973867746153 | validation: 0.069091143182794]
	TIME [epoch: 9.08 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09136073925292265		[learning rate: 0.0026966]
	Learning Rate: 0.0026966
	LOSS [training: 0.09136073925292265 | validation: 0.4515316936043364]
	TIME [epoch: 9.1 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17524106918104568		[learning rate: 0.002684]
	Learning Rate: 0.00268396
	LOSS [training: 0.17524106918104568 | validation: 0.2621259121453532]
	TIME [epoch: 9.12 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08451784453343256		[learning rate: 0.0026714]
	Learning Rate: 0.00267137
	LOSS [training: 0.08451784453343256 | validation: 0.05404589422888967]
	TIME [epoch: 9.09 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09583408115698351		[learning rate: 0.0026589]
	Learning Rate: 0.00265885
	LOSS [training: 0.09583408115698351 | validation: 0.10244044235931343]
	TIME [epoch: 9.1 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05714473362172471		[learning rate: 0.0026464]
	Learning Rate: 0.00264639
	LOSS [training: 0.05714473362172471 | validation: 0.10614884570917758]
	TIME [epoch: 9.09 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0697929644407523		[learning rate: 0.002634]
	Learning Rate: 0.00263398
	LOSS [training: 0.0697929644407523 | validation: 0.02381996705012821]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_294.pth
	Model improved!!!
EPOCH 295/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07729148773538838		[learning rate: 0.0026216]
	Learning Rate: 0.00262163
	LOSS [training: 0.07729148773538838 | validation: 0.1011057655133353]
	TIME [epoch: 9.11 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10813283334339978		[learning rate: 0.0026093]
	Learning Rate: 0.00260934
	LOSS [training: 0.10813283334339978 | validation: 0.10892212276230259]
	TIME [epoch: 9.08 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13577549473843728		[learning rate: 0.0025971]
	Learning Rate: 0.00259711
	LOSS [training: 0.13577549473843728 | validation: 0.18976502976589626]
	TIME [epoch: 9.07 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10435310965701372		[learning rate: 0.0025849]
	Learning Rate: 0.00258493
	LOSS [training: 0.10435310965701372 | validation: 0.08834514990332959]
	TIME [epoch: 9.07 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08320370886467349		[learning rate: 0.0025728]
	Learning Rate: 0.00257281
	LOSS [training: 0.08320370886467349 | validation: 0.23531027000849586]
	TIME [epoch: 9.1 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12762071761186192		[learning rate: 0.0025608]
	Learning Rate: 0.00256075
	LOSS [training: 0.12762071761186192 | validation: 0.1397928368700141]
	TIME [epoch: 9.09 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1091353466631508		[learning rate: 0.0025487]
	Learning Rate: 0.00254875
	LOSS [training: 0.1091353466631508 | validation: 0.24586886110543718]
	TIME [epoch: 9.08 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09284074982670601		[learning rate: 0.0025368]
	Learning Rate: 0.0025368
	LOSS [training: 0.09284074982670601 | validation: 0.0996892296563843]
	TIME [epoch: 9.09 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/10] avg loss: 0.143455327186		[learning rate: 0.0025249]
	Learning Rate: 0.0025249
	LOSS [training: 0.143455327186 | validation: 0.07455213618713658]
	TIME [epoch: 9.08 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09769671212533133		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.09769671212533133 | validation: 0.21389046903382972]
	TIME [epoch: 9.1 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08020766327220148		[learning rate: 0.0025013]
	Learning Rate: 0.00250129
	LOSS [training: 0.08020766327220148 | validation: 0.05935614601171112]
	TIME [epoch: 9.09 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10665271959706246		[learning rate: 0.0024896]
	Learning Rate: 0.00248956
	LOSS [training: 0.10665271959706246 | validation: 0.06416806673047543]
	TIME [epoch: 9.09 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06784978622213934		[learning rate: 0.0024779]
	Learning Rate: 0.00247789
	LOSS [training: 0.06784978622213934 | validation: 0.06332266849882284]
	TIME [epoch: 9.09 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04486644818199535		[learning rate: 0.0024663]
	Learning Rate: 0.00246627
	LOSS [training: 0.04486644818199535 | validation: 0.0534500149176112]
	TIME [epoch: 9.11 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05983408963369154		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.05983408963369154 | validation: 0.0681598675841872]
	TIME [epoch: 9.09 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06416920201726631		[learning rate: 0.0024432]
	Learning Rate: 0.0024432
	LOSS [training: 0.06416920201726631 | validation: 0.039355668029657294]
	TIME [epoch: 9.1 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06513769523216198		[learning rate: 0.0024317]
	Learning Rate: 0.00243175
	LOSS [training: 0.06513769523216198 | validation: 0.09470609716053743]
	TIME [epoch: 9.09 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07349342026124164		[learning rate: 0.0024203]
	Learning Rate: 0.00242035
	LOSS [training: 0.07349342026124164 | validation: 0.058438201710476624]
	TIME [epoch: 9.1 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05893462751826415		[learning rate: 0.002409]
	Learning Rate: 0.002409
	LOSS [training: 0.05893462751826415 | validation: 0.1341695302741865]
	TIME [epoch: 9.11 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07706680132119907		[learning rate: 0.0023977]
	Learning Rate: 0.00239771
	LOSS [training: 0.07706680132119907 | validation: 0.07667323104172141]
	TIME [epoch: 9.1 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10036367760190346		[learning rate: 0.0023865]
	Learning Rate: 0.00238647
	LOSS [training: 0.10036367760190346 | validation: 0.051154274392578754]
	TIME [epoch: 9.1 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/10] avg loss: 0.047999961780318304		[learning rate: 0.0023753]
	Learning Rate: 0.00237528
	LOSS [training: 0.047999961780318304 | validation: 0.08398077790964392]
	TIME [epoch: 9.09 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08864960183765273		[learning rate: 0.0023641]
	Learning Rate: 0.00236414
	LOSS [training: 0.08864960183765273 | validation: 0.10866129295691462]
	TIME [epoch: 9.1 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05864332633393212		[learning rate: 0.0023531]
	Learning Rate: 0.00235306
	LOSS [training: 0.05864332633393212 | validation: 0.08854324864063119]
	TIME [epoch: 9.1 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09630486576119272		[learning rate: 0.002342]
	Learning Rate: 0.00234203
	LOSS [training: 0.09630486576119272 | validation: 0.061228196540269494]
	TIME [epoch: 9.09 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/10] avg loss: 0.050234622666912435		[learning rate: 0.002331]
	Learning Rate: 0.00233105
	LOSS [training: 0.050234622666912435 | validation: 0.026673788442294538]
	TIME [epoch: 9.09 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0696738326475963		[learning rate: 0.0023201]
	Learning Rate: 0.00232012
	LOSS [training: 0.0696738326475963 | validation: 0.0552115395336352]
	TIME [epoch: 9.1 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04592453357450801		[learning rate: 0.0023092]
	Learning Rate: 0.00230924
	LOSS [training: 0.04592453357450801 | validation: 0.06143571439287153]
	TIME [epoch: 9.11 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/10] avg loss: 0.058841291995095565		[learning rate: 0.0022984]
	Learning Rate: 0.00229842
	LOSS [training: 0.058841291995095565 | validation: 0.09201930566469835]
	TIME [epoch: 9.08 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06004319605101349		[learning rate: 0.0022876]
	Learning Rate: 0.00228764
	LOSS [training: 0.06004319605101349 | validation: 0.07136244203545172]
	TIME [epoch: 9.1 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0833232398201959		[learning rate: 0.0022769]
	Learning Rate: 0.00227692
	LOSS [training: 0.0833232398201959 | validation: 0.09263318619502528]
	TIME [epoch: 9.09 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05403297002844361		[learning rate: 0.0022662]
	Learning Rate: 0.00226624
	LOSS [training: 0.05403297002844361 | validation: 0.09570244697877126]
	TIME [epoch: 9.09 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08630933386564181		[learning rate: 0.0022556]
	Learning Rate: 0.00225562
	LOSS [training: 0.08630933386564181 | validation: 0.15644828988807177]
	TIME [epoch: 9.11 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06869747560831763		[learning rate: 0.002245]
	Learning Rate: 0.00224504
	LOSS [training: 0.06869747560831763 | validation: 0.03782132010495201]
	TIME [epoch: 9.09 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04147582948272088		[learning rate: 0.0022345]
	Learning Rate: 0.00223452
	LOSS [training: 0.04147582948272088 | validation: 0.07979115089924733]
	TIME [epoch: 9.09 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05827981286884355		[learning rate: 0.002224]
	Learning Rate: 0.00222404
	LOSS [training: 0.05827981286884355 | validation: 0.10842619184514088]
	TIME [epoch: 9.09 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07258839426354896		[learning rate: 0.0022136]
	Learning Rate: 0.00221361
	LOSS [training: 0.07258839426354896 | validation: 0.041950655242419296]
	TIME [epoch: 9.1 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0819425401595133		[learning rate: 0.0022032]
	Learning Rate: 0.00220324
	LOSS [training: 0.0819425401595133 | validation: 0.04724377507634389]
	TIME [epoch: 9.09 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/10] avg loss: 0.055126822227995864		[learning rate: 0.0021929]
	Learning Rate: 0.00219291
	LOSS [training: 0.055126822227995864 | validation: 0.09577366894378671]
	TIME [epoch: 9.08 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10723712786719033		[learning rate: 0.0021826]
	Learning Rate: 0.00218263
	LOSS [training: 0.10723712786719033 | validation: 0.12174730441708984]
	TIME [epoch: 9.08 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10789063523791191		[learning rate: 0.0021724]
	Learning Rate: 0.00217239
	LOSS [training: 0.10789063523791191 | validation: 0.1294350262449316]
	TIME [epoch: 9.09 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08633774606862514		[learning rate: 0.0021622]
	Learning Rate: 0.00216221
	LOSS [training: 0.08633774606862514 | validation: 0.15856575252195648]
	TIME [epoch: 9.1 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2557646590342116		[learning rate: 0.0021521]
	Learning Rate: 0.00215207
	LOSS [training: 0.2557646590342116 | validation: 0.10154924042682226]
	TIME [epoch: 9.08 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08363987875705395		[learning rate: 0.002142]
	Learning Rate: 0.00214198
	LOSS [training: 0.08363987875705395 | validation: 0.07746062078076299]
	TIME [epoch: 9.07 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/10] avg loss: 0.056928163876498274		[learning rate: 0.0021319]
	Learning Rate: 0.00213194
	LOSS [training: 0.056928163876498274 | validation: 0.039558717229115505]
	TIME [epoch: 9.07 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1581699531684103		[learning rate: 0.0021219]
	Learning Rate: 0.00212195
	LOSS [training: 0.1581699531684103 | validation: 0.1653725904683651]
	TIME [epoch: 9.08 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11177305371146282		[learning rate: 0.002112]
	Learning Rate: 0.002112
	LOSS [training: 0.11177305371146282 | validation: 0.05876056250327376]
	TIME [epoch: 9.09 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0871509474112132		[learning rate: 0.0021021]
	Learning Rate: 0.0021021
	LOSS [training: 0.0871509474112132 | validation: 0.138074514133107]
	TIME [epoch: 9.07 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08512059754060819		[learning rate: 0.0020922]
	Learning Rate: 0.00209224
	LOSS [training: 0.08512059754060819 | validation: 0.0796270025443831]
	TIME [epoch: 9.07 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06878281137989309		[learning rate: 0.0020824]
	Learning Rate: 0.00208243
	LOSS [training: 0.06878281137989309 | validation: 0.11777636303977104]
	TIME [epoch: 9.07 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07449350268467125		[learning rate: 0.0020727]
	Learning Rate: 0.00207267
	LOSS [training: 0.07449350268467125 | validation: 0.07481907403105581]
	TIME [epoch: 9.1 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07890003828240189		[learning rate: 0.002063]
	Learning Rate: 0.00206295
	LOSS [training: 0.07890003828240189 | validation: 0.11124835825387937]
	TIME [epoch: 9.08 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07032049947713623		[learning rate: 0.0020533]
	Learning Rate: 0.00205328
	LOSS [training: 0.07032049947713623 | validation: 0.07442954311299299]
	TIME [epoch: 9.07 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08626811204359036		[learning rate: 0.0020437]
	Learning Rate: 0.00204366
	LOSS [training: 0.08626811204359036 | validation: 0.07798336134219135]
	TIME [epoch: 9.07 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05688723999019437		[learning rate: 0.0020341]
	Learning Rate: 0.00203408
	LOSS [training: 0.05688723999019437 | validation: 0.055980568028450764]
	TIME [epoch: 9.07 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0698403191790965		[learning rate: 0.0020245]
	Learning Rate: 0.00202454
	LOSS [training: 0.0698403191790965 | validation: 0.06779130849915917]
	TIME [epoch: 9.1 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07680933436554771		[learning rate: 0.002015]
	Learning Rate: 0.00201505
	LOSS [training: 0.07680933436554771 | validation: 0.11109283868736639]
	TIME [epoch: 9.07 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08198662397097782		[learning rate: 0.0020056]
	Learning Rate: 0.0020056
	LOSS [training: 0.08198662397097782 | validation: 0.08671127871717348]
	TIME [epoch: 9.08 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11960653144276492		[learning rate: 0.0019962]
	Learning Rate: 0.0019962
	LOSS [training: 0.11960653144276492 | validation: 0.13574492024161602]
	TIME [epoch: 9.07 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08524864242778592		[learning rate: 0.0019868]
	Learning Rate: 0.00198684
	LOSS [training: 0.08524864242778592 | validation: 0.09582216389467295]
	TIME [epoch: 9.09 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07787708311497056		[learning rate: 0.0019775]
	Learning Rate: 0.00197753
	LOSS [training: 0.07787708311497056 | validation: 0.17729280016355756]
	TIME [epoch: 9.08 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09649712268846497		[learning rate: 0.0019683]
	Learning Rate: 0.00196826
	LOSS [training: 0.09649712268846497 | validation: 0.0843589498526496]
	TIME [epoch: 9.08 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06725319234467103		[learning rate: 0.001959]
	Learning Rate: 0.00195903
	LOSS [training: 0.06725319234467103 | validation: 0.11190943541497073]
	TIME [epoch: 9.08 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11296479316579391		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.11296479316579391 | validation: 0.1408354460598275]
	TIME [epoch: 9.07 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35681726497410005		[learning rate: 0.0019407]
	Learning Rate: 0.0019407
	LOSS [training: 0.35681726497410005 | validation: 0.27263421354561423]
	TIME [epoch: 9.1 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21098039425550286		[learning rate: 0.0019316]
	Learning Rate: 0.00193161
	LOSS [training: 0.21098039425550286 | validation: 0.35674066108077884]
	TIME [epoch: 9.09 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1608154825272308		[learning rate: 0.0019225]
	Learning Rate: 0.00192255
	LOSS [training: 0.1608154825272308 | validation: 0.10318455872210991]
	TIME [epoch: 9.08 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10468333299413764		[learning rate: 0.0019135]
	Learning Rate: 0.00191354
	LOSS [training: 0.10468333299413764 | validation: 0.09355740484409221]
	TIME [epoch: 9.09 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10656960648141012		[learning rate: 0.0019046]
	Learning Rate: 0.00190457
	LOSS [training: 0.10656960648141012 | validation: 0.11590710418645209]
	TIME [epoch: 9.1 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08843734342507449		[learning rate: 0.0018956]
	Learning Rate: 0.00189564
	LOSS [training: 0.08843734342507449 | validation: 0.18376436407443308]
	TIME [epoch: 9.08 sec]
EPOCH 365/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12393612723178882		[learning rate: 0.0018867]
	Learning Rate: 0.00188675
	LOSS [training: 0.12393612723178882 | validation: 0.1357629067155546]
	TIME [epoch: 9.08 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08463957256242403		[learning rate: 0.0018779]
	Learning Rate: 0.0018779
	LOSS [training: 0.08463957256242403 | validation: 0.09944926835185627]
	TIME [epoch: 9.08 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10266871041671419		[learning rate: 0.0018691]
	Learning Rate: 0.0018691
	LOSS [training: 0.10266871041671419 | validation: 0.09852070909625865]
	TIME [epoch: 9.08 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06830032381694626		[learning rate: 0.0018603]
	Learning Rate: 0.00186034
	LOSS [training: 0.06830032381694626 | validation: 0.08793345236853453]
	TIME [epoch: 9.1 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12220961718592424		[learning rate: 0.0018516]
	Learning Rate: 0.00185162
	LOSS [training: 0.12220961718592424 | validation: 0.19046186047261893]
	TIME [epoch: 9.08 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11822219560756805		[learning rate: 0.0018429]
	Learning Rate: 0.00184294
	LOSS [training: 0.11822219560756805 | validation: 0.09000624295154538]
	TIME [epoch: 9.07 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09084861717082038		[learning rate: 0.0018343]
	Learning Rate: 0.0018343
	LOSS [training: 0.09084861717082038 | validation: 0.13427950093172059]
	TIME [epoch: 9.07 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2141506513597379		[learning rate: 0.0018257]
	Learning Rate: 0.0018257
	LOSS [training: 0.2141506513597379 | validation: 0.2631192618153345]
	TIME [epoch: 9.08 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11405369021457809		[learning rate: 0.0018171]
	Learning Rate: 0.00181714
	LOSS [training: 0.11405369021457809 | validation: 0.08854493396533103]
	TIME [epoch: 9.09 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06545909313615669		[learning rate: 0.0018086]
	Learning Rate: 0.00180862
	LOSS [training: 0.06545909313615669 | validation: 0.11775613733722548]
	TIME [epoch: 9.09 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1003392025745832		[learning rate: 0.0018001]
	Learning Rate: 0.00180014
	LOSS [training: 0.1003392025745832 | validation: 0.06741617021213284]
	TIME [epoch: 9.07 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07937117901510939		[learning rate: 0.0017917]
	Learning Rate: 0.0017917
	LOSS [training: 0.07937117901510939 | validation: 0.0808908996430221]
	TIME [epoch: 9.07 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07534891135343746		[learning rate: 0.0017833]
	Learning Rate: 0.0017833
	LOSS [training: 0.07534891135343746 | validation: 0.07636973201555872]
	TIME [epoch: 9.1 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08782050295067588		[learning rate: 0.0017749]
	Learning Rate: 0.00177494
	LOSS [training: 0.08782050295067588 | validation: 0.07353777306977377]
	TIME [epoch: 9.09 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08335240172872063		[learning rate: 0.0017666]
	Learning Rate: 0.00176662
	LOSS [training: 0.08335240172872063 | validation: 0.043961579562668135]
	TIME [epoch: 9.08 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07042054751672469		[learning rate: 0.0017583]
	Learning Rate: 0.00175834
	LOSS [training: 0.07042054751672469 | validation: 0.06611724042766458]
	TIME [epoch: 9.08 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07360850059570594		[learning rate: 0.0017501]
	Learning Rate: 0.00175009
	LOSS [training: 0.07360850059570594 | validation: 0.14359466878648458]
	TIME [epoch: 9.08 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1147493077207109		[learning rate: 0.0017419]
	Learning Rate: 0.00174189
	LOSS [training: 0.1147493077207109 | validation: 0.10151291396154583]
	TIME [epoch: 9.1 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1251202830700052		[learning rate: 0.0017337]
	Learning Rate: 0.00173372
	LOSS [training: 0.1251202830700052 | validation: 0.1404218657084381]
	TIME [epoch: 9.08 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0904922457347188		[learning rate: 0.0017256]
	Learning Rate: 0.00172559
	LOSS [training: 0.0904922457347188 | validation: 0.06311744769805394]
	TIME [epoch: 9.08 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08816660332285753		[learning rate: 0.0017175]
	Learning Rate: 0.0017175
	LOSS [training: 0.08816660332285753 | validation: 0.05233637279272524]
	TIME [epoch: 9.08 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/10] avg loss: 0.051384043919432666		[learning rate: 0.0017095]
	Learning Rate: 0.00170945
	LOSS [training: 0.051384043919432666 | validation: 0.06995594075175338]
	TIME [epoch: 9.1 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05206966502939173		[learning rate: 0.0017014]
	Learning Rate: 0.00170144
	LOSS [training: 0.05206966502939173 | validation: 0.09832948051691426]
	TIME [epoch: 9.07 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06561006785330026		[learning rate: 0.0016935]
	Learning Rate: 0.00169346
	LOSS [training: 0.06561006785330026 | validation: 0.12134019477349403]
	TIME [epoch: 9.08 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0891903053770988		[learning rate: 0.0016855]
	Learning Rate: 0.00168552
	LOSS [training: 0.0891903053770988 | validation: 0.06626395499494873]
	TIME [epoch: 9.09 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07833761581334282		[learning rate: 0.0016776]
	Learning Rate: 0.00167762
	LOSS [training: 0.07833761581334282 | validation: 0.05909269255753613]
	TIME [epoch: 9.08 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06204330813962709		[learning rate: 0.0016698]
	Learning Rate: 0.00166976
	LOSS [training: 0.06204330813962709 | validation: 0.07267609294085291]
	TIME [epoch: 9.1 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/10] avg loss: 0.057214742693899104		[learning rate: 0.0016619]
	Learning Rate: 0.00166193
	LOSS [training: 0.057214742693899104 | validation: 0.08551559839790793]
	TIME [epoch: 9.09 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04940550995230531		[learning rate: 0.0016541]
	Learning Rate: 0.00165414
	LOSS [training: 0.04940550995230531 | validation: 0.03875323795935755]
	TIME [epoch: 9.09 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/10] avg loss: 0.051776517782642785		[learning rate: 0.0016464]
	Learning Rate: 0.00164638
	LOSS [training: 0.051776517782642785 | validation: 0.059732214187786584]
	TIME [epoch: 9.08 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/10] avg loss: 0.030579261929672953		[learning rate: 0.0016387]
	Learning Rate: 0.00163866
	LOSS [training: 0.030579261929672953 | validation: 0.02535947400291782]
	TIME [epoch: 9.09 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/10] avg loss: 0.035564414948163606		[learning rate: 0.001631]
	Learning Rate: 0.00163098
	LOSS [training: 0.035564414948163606 | validation: 0.07054634264797897]
	TIME [epoch: 9.1 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06152661540251316		[learning rate: 0.0016233]
	Learning Rate: 0.00162333
	LOSS [training: 0.06152661540251316 | validation: 0.10196790009987619]
	TIME [epoch: 9.09 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/10] avg loss: 0.049078379768500054		[learning rate: 0.0016157]
	Learning Rate: 0.00161572
	LOSS [training: 0.049078379768500054 | validation: 0.03845045929496388]
	TIME [epoch: 9.08 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04078075158111335		[learning rate: 0.0016081]
	Learning Rate: 0.00160815
	LOSS [training: 0.04078075158111335 | validation: 0.10202927034351539]
	TIME [epoch: 9.08 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0820868342199957		[learning rate: 0.0016006]
	Learning Rate: 0.00160061
	LOSS [training: 0.0820868342199957 | validation: 0.16641425664301424]
	TIME [epoch: 9.11 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06048979836926709		[learning rate: 0.0015931]
	Learning Rate: 0.00159311
	LOSS [training: 0.06048979836926709 | validation: 0.12028356874600903]
	TIME [epoch: 9.09 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05355272515604424		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.05355272515604424 | validation: 0.02532810211960259]
	TIME [epoch: 9.09 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05635314428587781		[learning rate: 0.0015782]
	Learning Rate: 0.0015782
	LOSS [training: 0.05635314428587781 | validation: 0.03477988512029268]
	TIME [epoch: 9.09 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06689770502345488		[learning rate: 0.0015708]
	Learning Rate: 0.00157081
	LOSS [training: 0.06689770502345488 | validation: 0.17051732215107396]
	TIME [epoch: 9.09 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08935850499949106		[learning rate: 0.0015634]
	Learning Rate: 0.00156344
	LOSS [training: 0.08935850499949106 | validation: 0.047561075712755016]
	TIME [epoch: 9.1 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10085584532321372		[learning rate: 0.0015561]
	Learning Rate: 0.00155611
	LOSS [training: 0.10085584532321372 | validation: 0.048153167667057545]
	TIME [epoch: 9.09 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05173680913715395		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.05173680913715395 | validation: 0.08784208469267701]
	TIME [epoch: 9.08 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0549778802774778		[learning rate: 0.0015416]
	Learning Rate: 0.00154156
	LOSS [training: 0.0549778802774778 | validation: 0.06489197569615754]
	TIME [epoch: 9.08 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05814895682658751		[learning rate: 0.0015343]
	Learning Rate: 0.00153433
	LOSS [training: 0.05814895682658751 | validation: 0.07958420964641594]
	TIME [epoch: 9.1 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06466684745184267		[learning rate: 0.0015271]
	Learning Rate: 0.00152714
	LOSS [training: 0.06466684745184267 | validation: 0.06952596259928781]
	TIME [epoch: 9.09 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06501866374649004		[learning rate: 0.00152]
	Learning Rate: 0.00151998
	LOSS [training: 0.06501866374649004 | validation: 0.06742022935261574]
	TIME [epoch: 9.09 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05336835416449576		[learning rate: 0.0015129]
	Learning Rate: 0.00151285
	LOSS [training: 0.05336835416449576 | validation: 0.04472653839697556]
	TIME [epoch: 9.08 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03821616022452892		[learning rate: 0.0015058]
	Learning Rate: 0.00150576
	LOSS [training: 0.03821616022452892 | validation: 0.05233534306646072]
	TIME [epoch: 9.09 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06092199209051705		[learning rate: 0.0014987]
	Learning Rate: 0.0014987
	LOSS [training: 0.06092199209051705 | validation: 0.05293218436013333]
	TIME [epoch: 9.11 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0633891273815102		[learning rate: 0.0014917]
	Learning Rate: 0.00149167
	LOSS [training: 0.0633891273815102 | validation: 0.11072582502584921]
	TIME [epoch: 9.09 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/10] avg loss: 0.047391570337624034		[learning rate: 0.0014847]
	Learning Rate: 0.00148468
	LOSS [training: 0.047391570337624034 | validation: 0.05697020975235584]
	TIME [epoch: 9.09 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/10] avg loss: 0.054615042311364215		[learning rate: 0.0014777]
	Learning Rate: 0.00147772
	LOSS [training: 0.054615042311364215 | validation: 0.08954352497312427]
	TIME [epoch: 9.08 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06996333289219966		[learning rate: 0.0014708]
	Learning Rate: 0.00147079
	LOSS [training: 0.06996333289219966 | validation: 0.07365769526993134]
	TIME [epoch: 9.11 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04065764072460716		[learning rate: 0.0014639]
	Learning Rate: 0.0014639
	LOSS [training: 0.04065764072460716 | validation: 0.05077557563971374]
	TIME [epoch: 9.09 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/10] avg loss: 0.035028425080185006		[learning rate: 0.001457]
	Learning Rate: 0.00145703
	LOSS [training: 0.035028425080185006 | validation: 0.035810547001813645]
	TIME [epoch: 9.09 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/10] avg loss: 0.039441530705463586		[learning rate: 0.0014502]
	Learning Rate: 0.0014502
	LOSS [training: 0.039441530705463586 | validation: 0.046454537918148325]
	TIME [epoch: 9.09 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/10] avg loss: 0.060038844494022914		[learning rate: 0.0014434]
	Learning Rate: 0.0014434
	LOSS [training: 0.060038844494022914 | validation: 0.09108388886134233]
	TIME [epoch: 9.09 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/10] avg loss: 0.047972799310940485		[learning rate: 0.0014366]
	Learning Rate: 0.00143664
	LOSS [training: 0.047972799310940485 | validation: 0.06124752147800723]
	TIME [epoch: 9.1 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04679727137880021		[learning rate: 0.0014299]
	Learning Rate: 0.0014299
	LOSS [training: 0.04679727137880021 | validation: 0.06219576103655462]
	TIME [epoch: 9.09 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10935843817539101		[learning rate: 0.0014232]
	Learning Rate: 0.0014232
	LOSS [training: 0.10935843817539101 | validation: 0.24165131799106931]
	TIME [epoch: 9.09 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11934115481476364		[learning rate: 0.0014165]
	Learning Rate: 0.00141653
	LOSS [training: 0.11934115481476364 | validation: 0.09863491436153621]
	TIME [epoch: 9.09 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09057360337893214		[learning rate: 0.0014099]
	Learning Rate: 0.00140989
	LOSS [training: 0.09057360337893214 | validation: 0.07569154219531965]
	TIME [epoch: 9.09 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08252036016440614		[learning rate: 0.0014033]
	Learning Rate: 0.00140328
	LOSS [training: 0.08252036016440614 | validation: 0.08850334092446163]
	TIME [epoch: 9.11 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09071712140507973		[learning rate: 0.0013967]
	Learning Rate: 0.0013967
	LOSS [training: 0.09071712140507973 | validation: 0.11899422141873649]
	TIME [epoch: 9.08 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08316939200890074		[learning rate: 0.0013901]
	Learning Rate: 0.00139015
	LOSS [training: 0.08316939200890074 | validation: 0.0596894034281438]
	TIME [epoch: 9.08 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/10] avg loss: 0.058633720344864824		[learning rate: 0.0013836]
	Learning Rate: 0.00138363
	LOSS [training: 0.058633720344864824 | validation: 0.08746604689469456]
	TIME [epoch: 9.08 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05577851353651055		[learning rate: 0.0013771]
	Learning Rate: 0.00137714
	LOSS [training: 0.05577851353651055 | validation: 0.04167018233052405]
	TIME [epoch: 9.11 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07843927754490368		[learning rate: 0.0013707]
	Learning Rate: 0.00137069
	LOSS [training: 0.07843927754490368 | validation: 0.02819914254847417]
	TIME [epoch: 9.09 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05081358583334335		[learning rate: 0.0013643]
	Learning Rate: 0.00136426
	LOSS [training: 0.05081358583334335 | validation: 0.03681940982739884]
	TIME [epoch: 9.08 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08002067856159048		[learning rate: 0.0013579]
	Learning Rate: 0.00135787
	LOSS [training: 0.08002067856159048 | validation: 0.055876554695492284]
	TIME [epoch: 9.08 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03684260553200317		[learning rate: 0.0013515]
	Learning Rate: 0.0013515
	LOSS [training: 0.03684260553200317 | validation: 0.03922907926416805]
	TIME [epoch: 9.08 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0927074456017349		[learning rate: 0.0013452]
	Learning Rate: 0.00134516
	LOSS [training: 0.0927074456017349 | validation: 0.030071317928709616]
	TIME [epoch: 9.11 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03267504646274432		[learning rate: 0.0013389]
	Learning Rate: 0.00133886
	LOSS [training: 0.03267504646274432 | validation: 0.05095934723153269]
	TIME [epoch: 9.09 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/10] avg loss: 0.043300425860159135		[learning rate: 0.0013326]
	Learning Rate: 0.00133258
	LOSS [training: 0.043300425860159135 | validation: 0.057294405017353285]
	TIME [epoch: 9.08 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04467196870546196		[learning rate: 0.0013263]
	Learning Rate: 0.00132633
	LOSS [training: 0.04467196870546196 | validation: 0.04728076167869414]
	TIME [epoch: 9.09 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/10] avg loss: 0.022753586889194467		[learning rate: 0.0013201]
	Learning Rate: 0.00132012
	LOSS [training: 0.022753586889194467 | validation: 0.07030123680982134]
	TIME [epoch: 9.1 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06376147448727523		[learning rate: 0.0013139]
	Learning Rate: 0.00131393
	LOSS [training: 0.06376147448727523 | validation: 0.021186307337835462]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_442.pth
	Model improved!!!
EPOCH 443/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03558999450419565		[learning rate: 0.0013078]
	Learning Rate: 0.00130777
	LOSS [training: 0.03558999450419565 | validation: 0.0522198585725826]
	TIME [epoch: 9.09 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0559612891208265		[learning rate: 0.0013016]
	Learning Rate: 0.00130164
	LOSS [training: 0.0559612891208265 | validation: 0.06547230401496124]
	TIME [epoch: 9.08 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/10] avg loss: 0.051257990669382934		[learning rate: 0.0012955]
	Learning Rate: 0.00129553
	LOSS [training: 0.051257990669382934 | validation: 0.03738632661219328]
	TIME [epoch: 9.08 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0446353076192319		[learning rate: 0.0012895]
	Learning Rate: 0.00128946
	LOSS [training: 0.0446353076192319 | validation: 0.04916034166239479]
	TIME [epoch: 9.1 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08909219502214305		[learning rate: 0.0012834]
	Learning Rate: 0.00128342
	LOSS [training: 0.08909219502214305 | validation: 0.24958390721855522]
	TIME [epoch: 9.09 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08405547753446371		[learning rate: 0.0012774]
	Learning Rate: 0.0012774
	LOSS [training: 0.08405547753446371 | validation: 0.0411975991058907]
	TIME [epoch: 9.15 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03449591300258813		[learning rate: 0.0012714]
	Learning Rate: 0.00127141
	LOSS [training: 0.03449591300258813 | validation: 0.06701921943052176]
	TIME [epoch: 9.08 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05342951888271229		[learning rate: 0.0012654]
	Learning Rate: 0.00126545
	LOSS [training: 0.05342951888271229 | validation: 0.08102124514161022]
	TIME [epoch: 9.11 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04655658098875174		[learning rate: 0.0012595]
	Learning Rate: 0.00125952
	LOSS [training: 0.04655658098875174 | validation: 0.05192512453009271]
	TIME [epoch: 9.08 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07614179626421942		[learning rate: 0.0012536]
	Learning Rate: 0.00125361
	LOSS [training: 0.07614179626421942 | validation: 0.12595895764316142]
	TIME [epoch: 9.08 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10898548190442733		[learning rate: 0.0012477]
	Learning Rate: 0.00124774
	LOSS [training: 0.10898548190442733 | validation: 0.19053175390091642]
	TIME [epoch: 9.08 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14168448844600376		[learning rate: 0.0012419]
	Learning Rate: 0.00124189
	LOSS [training: 0.14168448844600376 | validation: 0.08188556405970446]
	TIME [epoch: 9.08 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06678049594677972		[learning rate: 0.0012361]
	Learning Rate: 0.00123606
	LOSS [training: 0.06678049594677972 | validation: 0.12844451332683576]
	TIME [epoch: 9.1 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06904296165456357		[learning rate: 0.0012303]
	Learning Rate: 0.00123027
	LOSS [training: 0.06904296165456357 | validation: 0.06164504639541035]
	TIME [epoch: 9.09 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05013022044373907		[learning rate: 0.0012245]
	Learning Rate: 0.0012245
	LOSS [training: 0.05013022044373907 | validation: 0.04460634243530803]
	TIME [epoch: 9.08 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03902150158221478		[learning rate: 0.0012188]
	Learning Rate: 0.00121876
	LOSS [training: 0.03902150158221478 | validation: 0.0509950193933357]
	TIME [epoch: 9.08 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06005667412597676		[learning rate: 0.001213]
	Learning Rate: 0.00121305
	LOSS [training: 0.06005667412597676 | validation: 0.05030952817458242]
	TIME [epoch: 9.08 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05637113364699703		[learning rate: 0.0012074]
	Learning Rate: 0.00120736
	LOSS [training: 0.05637113364699703 | validation: 0.05474120299928077]
	TIME [epoch: 9.11 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0762043517271148		[learning rate: 0.0012017]
	Learning Rate: 0.0012017
	LOSS [training: 0.0762043517271148 | validation: 0.05075928016341016]
	TIME [epoch: 9.07 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/10] avg loss: 0.027724517969023244		[learning rate: 0.0011961]
	Learning Rate: 0.00119607
	LOSS [training: 0.027724517969023244 | validation: 0.04818710655259549]
	TIME [epoch: 9.08 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/10] avg loss: 0.058906416949192096		[learning rate: 0.0011905]
	Learning Rate: 0.00119046
	LOSS [training: 0.058906416949192096 | validation: 0.041248674093261564]
	TIME [epoch: 9.08 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/10] avg loss: 0.028551246426244965		[learning rate: 0.0011849]
	Learning Rate: 0.00118488
	LOSS [training: 0.028551246426244965 | validation: 0.05583768194920827]
	TIME [epoch: 9.11 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04531047016661182		[learning rate: 0.0011793]
	Learning Rate: 0.00117932
	LOSS [training: 0.04531047016661182 | validation: 0.05380039651486035]
	TIME [epoch: 9.08 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/10] avg loss: 0.040261726731611276		[learning rate: 0.0011738]
	Learning Rate: 0.00117379
	LOSS [training: 0.040261726731611276 | validation: 0.039399576846906335]
	TIME [epoch: 9.08 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/10] avg loss: 0.040688185919591176		[learning rate: 0.0011683]
	Learning Rate: 0.00116829
	LOSS [training: 0.040688185919591176 | validation: 0.07776148189843271]
	TIME [epoch: 9.09 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06824622880818346		[learning rate: 0.0011628]
	Learning Rate: 0.00116281
	LOSS [training: 0.06824622880818346 | validation: 0.11279200165535726]
	TIME [epoch: 9.08 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08472848150939657		[learning rate: 0.0011574]
	Learning Rate: 0.00115736
	LOSS [training: 0.08472848150939657 | validation: 0.1048444047849201]
	TIME [epoch: 9.11 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10185988197597765		[learning rate: 0.0011519]
	Learning Rate: 0.00115194
	LOSS [training: 0.10185988197597765 | validation: 0.07765811456805807]
	TIME [epoch: 9.08 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/10] avg loss: 0.059053636818828546		[learning rate: 0.0011465]
	Learning Rate: 0.00114654
	LOSS [training: 0.059053636818828546 | validation: 0.0876867182904622]
	TIME [epoch: 9.08 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09345095164324578		[learning rate: 0.0011412]
	Learning Rate: 0.00114116
	LOSS [training: 0.09345095164324578 | validation: 0.13203257097090387]
	TIME [epoch: 9.08 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09229587047226168		[learning rate: 0.0011358]
	Learning Rate: 0.00113581
	LOSS [training: 0.09229587047226168 | validation: 0.054938234998731614]
	TIME [epoch: 9.1 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04773256180016007		[learning rate: 0.0011305]
	Learning Rate: 0.00113049
	LOSS [training: 0.04773256180016007 | validation: 0.06835518428213846]
	TIME [epoch: 9.09 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06133457456355758		[learning rate: 0.0011252]
	Learning Rate: 0.00112519
	LOSS [training: 0.06133457456355758 | validation: 0.07139367372299181]
	TIME [epoch: 9.08 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03690951018472873		[learning rate: 0.0011199]
	Learning Rate: 0.00111991
	LOSS [training: 0.03690951018472873 | validation: 0.06998843695122156]
	TIME [epoch: 9.08 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04629268279542391		[learning rate: 0.0011147]
	Learning Rate: 0.00111466
	LOSS [training: 0.04629268279542391 | validation: 0.11381673196066798]
	TIME [epoch: 9.08 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04983426976980939		[learning rate: 0.0011094]
	Learning Rate: 0.00110944
	LOSS [training: 0.04983426976980939 | validation: 0.028611277762582495]
	TIME [epoch: 9.1 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03646293309387339		[learning rate: 0.0011042]
	Learning Rate: 0.00110423
	LOSS [training: 0.03646293309387339 | validation: 0.029183581237333056]
	TIME [epoch: 9.09 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/10] avg loss: 0.045762741314844375		[learning rate: 0.0010991]
	Learning Rate: 0.00109906
	LOSS [training: 0.045762741314844375 | validation: 0.08009397592609786]
	TIME [epoch: 9.08 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05038281828869214		[learning rate: 0.0010939]
	Learning Rate: 0.0010939
	LOSS [training: 0.05038281828869214 | validation: 0.0594894325931005]
	TIME [epoch: 9.08 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04264117750614728		[learning rate: 0.0010888]
	Learning Rate: 0.00108878
	LOSS [training: 0.04264117750614728 | validation: 0.05389615557687942]
	TIME [epoch: 9.09 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03681090317682129		[learning rate: 0.0010837]
	Learning Rate: 0.00108367
	LOSS [training: 0.03681090317682129 | validation: 0.08737376675209765]
	TIME [epoch: 9.1 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06357748941459523		[learning rate: 0.0010786]
	Learning Rate: 0.00107859
	LOSS [training: 0.06357748941459523 | validation: 0.06906559596284516]
	TIME [epoch: 9.09 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04566909029652021		[learning rate: 0.0010735]
	Learning Rate: 0.00107354
	LOSS [training: 0.04566909029652021 | validation: 0.04211309237352698]
	TIME [epoch: 9.09 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03980089998274358		[learning rate: 0.0010685]
	Learning Rate: 0.0010685
	LOSS [training: 0.03980089998274358 | validation: 0.042214021511534826]
	TIME [epoch: 9.08 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04056075148891948		[learning rate: 0.0010635]
	Learning Rate: 0.00106349
	LOSS [training: 0.04056075148891948 | validation: 0.03829397948066483]
	TIME [epoch: 9.11 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/10] avg loss: 0.039616012871749866		[learning rate: 0.0010585]
	Learning Rate: 0.00105851
	LOSS [training: 0.039616012871749866 | validation: 0.08225988227757866]
	TIME [epoch: 9.09 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08603975858299551		[learning rate: 0.0010535]
	Learning Rate: 0.00105354
	LOSS [training: 0.08603975858299551 | validation: 0.05492305561261031]
	TIME [epoch: 9.08 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04525491309522		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.04525491309522 | validation: 0.06777181804429082]
	TIME [epoch: 9.08 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/10] avg loss: 0.049052600359926354		[learning rate: 0.0010437]
	Learning Rate: 0.00104369
	LOSS [training: 0.049052600359926354 | validation: 0.05678674655887246]
	TIME [epoch: 9.08 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03590872778503234		[learning rate: 0.0010388]
	Learning Rate: 0.0010388
	LOSS [training: 0.03590872778503234 | validation: 0.09583886590389598]
	TIME [epoch: 9.11 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/10] avg loss: 0.041678097420492104		[learning rate: 0.0010339]
	Learning Rate: 0.00103393
	LOSS [training: 0.041678097420492104 | validation: 0.035154604044711164]
	TIME [epoch: 9.08 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03073891934793066		[learning rate: 0.0010291]
	Learning Rate: 0.00102908
	LOSS [training: 0.03073891934793066 | validation: 0.052695826747701416]
	TIME [epoch: 9.09 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04489729118021141		[learning rate: 0.0010243]
	Learning Rate: 0.00102426
	LOSS [training: 0.04489729118021141 | validation: 0.1336012247282431]
	TIME [epoch: 9.08 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04739666629578894		[learning rate: 0.0010195]
	Learning Rate: 0.00101945
	LOSS [training: 0.04739666629578894 | validation: 0.042630000706607926]
	TIME [epoch: 9.1 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/10] avg loss: 0.027882418453065588		[learning rate: 0.0010147]
	Learning Rate: 0.00101467
	LOSS [training: 0.027882418453065588 | validation: 0.039115714946700395]
	TIME [epoch: 9.09 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/10] avg loss: 0.020285686233648636		[learning rate: 0.0010099]
	Learning Rate: 0.00100992
	LOSS [training: 0.020285686233648636 | validation: 0.011948914119454607]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240214_183210/states/model_tr_study4_498.pth
	Model improved!!!
EPOCH 499/500:
	Training over batches...
		[batch 10/10] avg loss: 0.039875580220468186		[learning rate: 0.0010052]
	Learning Rate: 0.00100518
	LOSS [training: 0.039875580220468186 | validation: 0.054707603861205115]
	TIME [epoch: 9.09 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/10] avg loss: 0.060625081919450194		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.060625081919450194 | validation: 0.07260743777380987]
	TIME [epoch: 9.1 sec]
Finished training in 4607.772 seconds.
