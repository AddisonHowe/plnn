Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r1', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2177464555

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.207668032666657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.207668032666657 | validation: 8.607263015908055]
	TIME [epoch: 48.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.713342169428264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.713342169428264 | validation: 6.688573743357329]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.892288319056578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.892288319056578 | validation: 6.337126943750878]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.3846178745690345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3846178745690345 | validation: 5.460776086917214]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.475462223206791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.475462223206791 | validation: 4.014415571995788]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.09304241364998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.09304241364998 | validation: 4.24524316746311]
	TIME [epoch: 9.1 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.236592556952649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.236592556952649 | validation: 3.8761478287478104]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.651673939476569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.651673939476569 | validation: 3.306193346484709]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.229232064060139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.229232064060139 | validation: 2.8851625173899005]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9783422360680802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9783422360680802 | validation: 2.6784666526365917]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.493168673730235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.493168673730235 | validation: 3.569340512587227]
	TIME [epoch: 9.12 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7646801314684843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7646801314684843 | validation: 2.4238385916199334]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.484890164859904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.484890164859904 | validation: 2.1980356366109826]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2308016652105804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2308016652105804 | validation: 4.023557362429014]
	TIME [epoch: 9.1 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2443430551109715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2443430551109715 | validation: 2.0441717762138927]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8148067284597311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8148067284597311 | validation: 3.0528319229748258]
	TIME [epoch: 9.11 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.848213200159222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.848213200159222 | validation: 1.3210454574975312]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5783936140011403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5783936140011403 | validation: 1.6402843695545348]
	TIME [epoch: 9.1 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3630950680585159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3630950680585159 | validation: 0.8791687624223521]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0663778174180403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0663778174180403 | validation: 1.9849310371242561]
	TIME [epoch: 9.13 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.106858378112236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.106858378112236 | validation: 0.8094880327073464]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4803942595813886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4803942595813886 | validation: 0.6364296030023014]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.079169680158781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.079169680158781 | validation: 0.7488103547733392]
	TIME [epoch: 9.08 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9047380332682305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9047380332682305 | validation: 0.43994860492092713]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8226285631385771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8226285631385771 | validation: 0.6299316720372115]
	TIME [epoch: 9.12 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.669332191346377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.669332191346377 | validation: 0.7164227914807]
	TIME [epoch: 9.09 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.730330818636918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.730330818636918 | validation: 1.5253071368871551]
	TIME [epoch: 9.1 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7573029629548447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7573029629548447 | validation: 0.7106705021264696]
	TIME [epoch: 9.09 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6046343527729656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6046343527729656 | validation: 0.6805590633847496]
	TIME [epoch: 9.11 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8025911322700985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8025911322700985 | validation: 0.6909637317664796]
	TIME [epoch: 9.1 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6574712835407633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6574712835407633 | validation: 1.0948846504562475]
	TIME [epoch: 9.09 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7747458543337107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7747458543337107 | validation: 0.5886359805843437]
	TIME [epoch: 9.09 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6564665223982302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6564665223982302 | validation: 0.5300002912459214]
	TIME [epoch: 9.09 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5950418463869062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5950418463869062 | validation: 0.6335695989386116]
	TIME [epoch: 9.11 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5207632954714191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5207632954714191 | validation: 0.6895128409372471]
	TIME [epoch: 9.09 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5488469409370218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5488469409370218 | validation: 0.7466033265367886]
	TIME [epoch: 9.09 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5903577424963873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5903577424963873 | validation: 0.7256419158834158]
	TIME [epoch: 9.1 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5870329590347991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5870329590347991 | validation: 0.44544894439461513]
	TIME [epoch: 9.1 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6974469107560328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6974469107560328 | validation: 0.4248124227235549]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4733829033721492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4733829033721492 | validation: 0.42271900924181527]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7037680251761591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7037680251761591 | validation: 0.7034184961626793]
	TIME [epoch: 9.09 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6284322505299128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6284322505299128 | validation: 0.6240930542430947]
	TIME [epoch: 9.08 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5024330889997143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5024330889997143 | validation: 0.5535486726649844]
	TIME [epoch: 9.11 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6824695513317698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6824695513317698 | validation: 0.36870466658437384]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.437657131358261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.437657131358261 | validation: 0.6540992614811318]
	TIME [epoch: 9.08 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6084089145153082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6084089145153082 | validation: 0.43978398870936203]
	TIME [epoch: 9.08 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5727028709703093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5727028709703093 | validation: 0.37423576609050535]
	TIME [epoch: 9.09 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.14319345199664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.14319345199664 | validation: 3.7950692857154955]
	TIME [epoch: 9.08 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.604447986517306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.604447986517306 | validation: 3.4539630094310754]
	TIME [epoch: 9.08 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1897569222942286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1897569222942286 | validation: 3.003736172656617]
	TIME [epoch: 9.09 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2627948738931747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2627948738931747 | validation: 1.1735627811267695]
	TIME [epoch: 9.09 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3840644462100142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3840644462100142 | validation: 1.372657454885486]
	TIME [epoch: 9.1 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1416967179243336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1416967179243336 | validation: 0.8640718028780237]
	TIME [epoch: 9.1 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0412102897218207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0412102897218207 | validation: 0.7812222629362618]
	TIME [epoch: 9.08 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9331415724847734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9331415724847734 | validation: 0.8147804358345108]
	TIME [epoch: 9.09 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7895146214196396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7895146214196396 | validation: 1.3548370797314613]
	TIME [epoch: 9.1 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7855385379946185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7855385379946185 | validation: 0.6541089735561083]
	TIME [epoch: 9.1 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0005774722878815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0005774722878815 | validation: 0.9631791682738676]
	TIME [epoch: 9.09 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0353430726118489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0353430726118489 | validation: 0.4776029252098378]
	TIME [epoch: 9.08 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.975111537200205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.975111537200205 | validation: 1.8833625931349829]
	TIME [epoch: 9.08 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8825313289813227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8825313289813227 | validation: 0.5543001550774951]
	TIME [epoch: 9.11 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6067787863844011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6067787863844011 | validation: 0.5053624993962794]
	TIME [epoch: 9.09 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5295756916159481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5295756916159481 | validation: 0.42823258771403794]
	TIME [epoch: 9.09 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.456223398639623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.456223398639623 | validation: 0.42451623534985394]
	TIME [epoch: 9.09 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5048190704656914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5048190704656914 | validation: 0.958049078158979]
	TIME [epoch: 9.08 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6657632219044913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6657632219044913 | validation: 0.3581089015541846]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4802841834186852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4802841834186852 | validation: 0.35470188595632396]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4089317216054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4089317216054 | validation: 0.4768438010398719]
	TIME [epoch: 9.09 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6142016808662392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6142016808662392 | validation: 0.5171022784886629]
	TIME [epoch: 9.08 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6113712690543978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6113712690543978 | validation: 0.47664526081253805]
	TIME [epoch: 9.11 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4592058137729819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4592058137729819 | validation: 0.3532395534930475]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32482428243173667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32482428243173667 | validation: 0.4047052276938902]
	TIME [epoch: 9.08 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35986489339319966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35986489339319966 | validation: 1.2337343432982086]
	TIME [epoch: 9.08 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4724232374829166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4724232374829166 | validation: 0.2820309859711866]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3760878069179398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3760878069179398 | validation: 0.3315309695113202]
	TIME [epoch: 9.1 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4136778635846081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4136778635846081 | validation: 0.48145737933285754]
	TIME [epoch: 9.1 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4668743786068005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4668743786068005 | validation: 0.5923321363393372]
	TIME [epoch: 9.09 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44603132657403277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44603132657403277 | validation: 0.5078599520910854]
	TIME [epoch: 9.08 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4237135808854597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4237135808854597 | validation: 0.27963913883564295]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3707021666892849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3707021666892849 | validation: 0.3622850919377122]
	TIME [epoch: 9.08 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40017501120065085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40017501120065085 | validation: 0.29993401225085226]
	TIME [epoch: 9.07 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32034080690672917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32034080690672917 | validation: 0.2914247132999729]
	TIME [epoch: 9.07 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.667708534296702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.667708534296702 | validation: 0.24664462402880755]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3765739252293528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3765739252293528 | validation: 0.3037332738383619]
	TIME [epoch: 9.11 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3325310978101357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3325310978101357 | validation: 0.34554790293219906]
	TIME [epoch: 9.09 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3943693733015586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3943693733015586 | validation: 0.307517639950319]
	TIME [epoch: 9.1 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4259039427700288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4259039427700288 | validation: 0.304203643499545]
	TIME [epoch: 9.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36416039064594635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36416039064594635 | validation: 0.2894102038119678]
	TIME [epoch: 9.11 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35519499983501585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35519499983501585 | validation: 0.29253677235490755]
	TIME [epoch: 9.11 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34780560329730087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34780560329730087 | validation: 0.2801467658431561]
	TIME [epoch: 9.1 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4227010247836745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4227010247836745 | validation: 0.24772337285089485]
	TIME [epoch: 9.1 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3101893927830695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3101893927830695 | validation: 0.22855720969569074]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31060991303309804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31060991303309804 | validation: 1.6326731432679913]
	TIME [epoch: 9.11 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5222193510527737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5222193510527737 | validation: 2.2712997823715906]
	TIME [epoch: 9.1 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6696209917095746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6696209917095746 | validation: 2.126580853268595]
	TIME [epoch: 9.1 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7390179443308338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7390179443308338 | validation: 0.9715873320490236]
	TIME [epoch: 9.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6117279728891144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6117279728891144 | validation: 0.3985929206702873]
	TIME [epoch: 9.11 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4620234400402524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4620234400402524 | validation: 0.6081295881128714]
	TIME [epoch: 9.1 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7255154963545365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7255154963545365 | validation: 0.4559250924226457]
	TIME [epoch: 9.1 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6830820524469783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6830820524469783 | validation: 0.5116963408809966]
	TIME [epoch: 9.1 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5176095421436799		[learning rate: 0.0099782]
	Learning Rate: 0.00997821
	LOSS [training: 0.5176095421436799 | validation: 0.5297085876843903]
	TIME [epoch: 9.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6548233864656624		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 0.6548233864656624 | validation: 0.37843276965929773]
	TIME [epoch: 9.13 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3595038774231318		[learning rate: 0.00993]
	Learning Rate: 0.00992996
	LOSS [training: 0.3595038774231318 | validation: 0.3794674987072516]
	TIME [epoch: 9.1 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3779271826754501		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 0.3779271826754501 | validation: 0.289852917120854]
	TIME [epoch: 9.1 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37628811583556787		[learning rate: 0.0098819]
	Learning Rate: 0.00988194
	LOSS [training: 0.37628811583556787 | validation: 0.35058421528023187]
	TIME [epoch: 9.09 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37571364332704216		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 0.37571364332704216 | validation: 0.31418604900778746]
	TIME [epoch: 9.1 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6116417451717455		[learning rate: 0.0098341]
	Learning Rate: 0.00983415
	LOSS [training: 0.6116417451717455 | validation: 0.5781104816628373]
	TIME [epoch: 9.09 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4597806673815937		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 0.4597806673815937 | validation: 0.3925579070124424]
	TIME [epoch: 9.09 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3832677324123752		[learning rate: 0.0097866]
	Learning Rate: 0.00978659
	LOSS [training: 0.3832677324123752 | validation: 0.4275350650394336]
	TIME [epoch: 9.1 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31258608602559107		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 0.31258608602559107 | validation: 0.3238035879666803]
	TIME [epoch: 9.09 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36390472258246664		[learning rate: 0.0097393]
	Learning Rate: 0.00973927
	LOSS [training: 0.36390472258246664 | validation: 0.3476393399249677]
	TIME [epoch: 9.11 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34363934932616347		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 0.34363934932616347 | validation: 0.3783180097412834]
	TIME [epoch: 9.1 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39315254344899225		[learning rate: 0.0096922]
	Learning Rate: 0.00969217
	LOSS [training: 0.39315254344899225 | validation: 0.32355587169588074]
	TIME [epoch: 9.1 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33934549749762993		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 0.33934549749762993 | validation: 0.2278148146631273]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32515354950484776		[learning rate: 0.0096453]
	Learning Rate: 0.0096453
	LOSS [training: 0.32515354950484776 | validation: 0.20757330700148605]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3552126936095984		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 0.3552126936095984 | validation: 0.2422654125178691]
	TIME [epoch: 9.1 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43976412196091996		[learning rate: 0.0095987]
	Learning Rate: 0.00959866
	LOSS [training: 0.43976412196091996 | validation: 0.26518343939107014]
	TIME [epoch: 9.1 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42635179517900285		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 0.42635179517900285 | validation: 1.1365691447238353]
	TIME [epoch: 9.09 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6627233449945565		[learning rate: 0.0095522]
	Learning Rate: 0.00955224
	LOSS [training: 0.6627233449945565 | validation: 2.683815419183459]
	TIME [epoch: 9.08 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4175692718676374		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 1.4175692718676374 | validation: 0.7295960841544917]
	TIME [epoch: 9.11 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5393252484508126		[learning rate: 0.009506]
	Learning Rate: 0.00950605
	LOSS [training: 0.5393252484508126 | validation: 0.401390372964165]
	TIME [epoch: 9.09 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5681536396742419		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 0.5681536396742419 | validation: 0.26679641793400566]
	TIME [epoch: 9.09 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2993136984911971		[learning rate: 0.0094601]
	Learning Rate: 0.00946008
	LOSS [training: 0.2993136984911971 | validation: 0.32532356106887617]
	TIME [epoch: 9.09 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22975988821875465		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 0.22975988821875465 | validation: 0.24758950393556]
	TIME [epoch: 9.08 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23674852418027936		[learning rate: 0.0094143]
	Learning Rate: 0.00941433
	LOSS [training: 0.23674852418027936 | validation: 0.3358908652324463]
	TIME [epoch: 9.1 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2711155891309754		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 0.2711155891309754 | validation: 0.33634688702653853]
	TIME [epoch: 9.08 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39468818245593296		[learning rate: 0.0093688]
	Learning Rate: 0.00936881
	LOSS [training: 0.39468818245593296 | validation: 0.2749259302032376]
	TIME [epoch: 9.08 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22219038387488416		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 0.22219038387488416 | validation: 0.1860381396554321]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.295720070037519		[learning rate: 0.0093235]
	Learning Rate: 0.0093235
	LOSS [training: 0.295720070037519 | validation: 0.5359555786699188]
	TIME [epoch: 9.1 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6329758266680843		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 2.6329758266680843 | validation: 2.703938855649047]
	TIME [epoch: 9.09 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8555821284944793		[learning rate: 0.0092784]
	Learning Rate: 0.00927841
	LOSS [training: 0.8555821284944793 | validation: 0.2803557154686609]
	TIME [epoch: 9.09 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24285283071309577		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 0.24285283071309577 | validation: 0.6069854757842348]
	TIME [epoch: 9.09 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33438654365773235		[learning rate: 0.0092335]
	Learning Rate: 0.00923354
	LOSS [training: 0.33438654365773235 | validation: 0.21565829255401037]
	TIME [epoch: 9.09 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24901357474913502		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 0.24901357474913502 | validation: 0.22486632355319974]
	TIME [epoch: 9.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2589186895052922		[learning rate: 0.0091889]
	Learning Rate: 0.00918889
	LOSS [training: 0.2589186895052922 | validation: 0.24187534604747862]
	TIME [epoch: 9.09 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24132838641790197		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 0.24132838641790197 | validation: 0.4549121823451525]
	TIME [epoch: 9.09 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30880244397790124		[learning rate: 0.0091445]
	Learning Rate: 0.00914446
	LOSS [training: 0.30880244397790124 | validation: 0.22676568247517137]
	TIME [epoch: 9.09 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26942037107013805		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 0.26942037107013805 | validation: 0.17857754132425496]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2840603210617447		[learning rate: 0.0091002]
	Learning Rate: 0.00910024
	LOSS [training: 0.2840603210617447 | validation: 0.2526351202828784]
	TIME [epoch: 9.08 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2989560313902434		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.2989560313902434 | validation: 0.2538573690912965]
	TIME [epoch: 9.08 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2864886717149381		[learning rate: 0.0090562]
	Learning Rate: 0.00905623
	LOSS [training: 0.2864886717149381 | validation: 0.34583820309882163]
	TIME [epoch: 9.09 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27605807043253733		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 0.27605807043253733 | validation: 0.43734644694780234]
	TIME [epoch: 9.09 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26951735652717357		[learning rate: 0.0090124]
	Learning Rate: 0.00901243
	LOSS [training: 0.26951735652717357 | validation: 1.0517803038286528]
	TIME [epoch: 9.1 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6732860176287724		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 0.6732860176287724 | validation: 0.46906355149521484]
	TIME [epoch: 9.09 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3604950964169801		[learning rate: 0.0089689]
	Learning Rate: 0.00896885
	LOSS [training: 0.3604950964169801 | validation: 0.1336755514768029]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2691702741805165		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 0.2691702741805165 | validation: 0.22370625446668133]
	TIME [epoch: 9.08 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2964684726070106		[learning rate: 0.0089255]
	Learning Rate: 0.00892548
	LOSS [training: 0.2964684726070106 | validation: 0.25990022887377395]
	TIME [epoch: 9.1 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2596317470909287		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 0.2596317470909287 | validation: 0.19084473831988893]
	TIME [epoch: 9.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22097718515921438		[learning rate: 0.0088823]
	Learning Rate: 0.00888232
	LOSS [training: 0.22097718515921438 | validation: 0.322332041593678]
	TIME [epoch: 9.09 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31300744280781945		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 0.31300744280781945 | validation: 0.23613865831552577]
	TIME [epoch: 9.09 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25621708295169016		[learning rate: 0.0088394]
	Learning Rate: 0.00883936
	LOSS [training: 0.25621708295169016 | validation: 0.34907280580590694]
	TIME [epoch: 9.09 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22182061082217697		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 0.22182061082217697 | validation: 0.15089290985990403]
	TIME [epoch: 9.09 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20107954289665475		[learning rate: 0.0087966]
	Learning Rate: 0.00879662
	LOSS [training: 0.20107954289665475 | validation: 0.5367574488566882]
	TIME [epoch: 9.07 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6559542576148261		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 0.6559542576148261 | validation: 3.118287470116284]
	TIME [epoch: 9.08 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8994433419529295		[learning rate: 0.0087541]
	Learning Rate: 0.00875408
	LOSS [training: 0.8994433419529295 | validation: 0.705757792373127]
	TIME [epoch: 9.08 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6792399965740263		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 0.6792399965740263 | validation: 0.3201093356481991]
	TIME [epoch: 9.1 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31085112792671316		[learning rate: 0.0087117]
	Learning Rate: 0.00871175
	LOSS [training: 0.31085112792671316 | validation: 0.18292515029806913]
	TIME [epoch: 9.08 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3082015868625673		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 0.3082015868625673 | validation: 0.178820955359893]
	TIME [epoch: 9.08 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25163480796512266		[learning rate: 0.0086696]
	Learning Rate: 0.00866962
	LOSS [training: 0.25163480796512266 | validation: 0.4840283430734451]
	TIME [epoch: 9.08 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.350787564698311		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.350787564698311 | validation: 0.9073539763404839]
	TIME [epoch: 9.07 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3130500443831428		[learning rate: 0.0086277]
	Learning Rate: 0.00862769
	LOSS [training: 1.3130500443831428 | validation: 0.5221690613644374]
	TIME [epoch: 9.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3332109321344633		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.3332109321344633 | validation: 0.6733238383849143]
	TIME [epoch: 9.08 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9751640080636991		[learning rate: 0.008586]
	Learning Rate: 0.00858597
	LOSS [training: 0.9751640080636991 | validation: 0.30451584049936]
	TIME [epoch: 9.08 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2746396538228807		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 0.2746396538228807 | validation: 0.17468951541729827]
	TIME [epoch: 9.08 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2570547407221998		[learning rate: 0.0085445]
	Learning Rate: 0.00854445
	LOSS [training: 0.2570547407221998 | validation: 0.13247878285208664]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4009978541249108		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 0.4009978541249108 | validation: 0.28331737927179096]
	TIME [epoch: 9.09 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.713020190055145		[learning rate: 0.0085031]
	Learning Rate: 0.00850313
	LOSS [training: 0.713020190055145 | validation: 0.4084303574896546]
	TIME [epoch: 9.09 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3069557740741903		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.3069557740741903 | validation: 0.2908091948950154]
	TIME [epoch: 9.09 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23118528049556203		[learning rate: 0.008462]
	Learning Rate: 0.00846201
	LOSS [training: 0.23118528049556203 | validation: 0.18626312901778325]
	TIME [epoch: 9.09 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28526438048675173		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 0.28526438048675173 | validation: 0.20618015194003636]
	TIME [epoch: 9.1 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23798002715358982		[learning rate: 0.0084211]
	Learning Rate: 0.00842109
	LOSS [training: 0.23798002715358982 | validation: 0.6610084477325038]
	TIME [epoch: 9.08 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29997138319508804		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 0.29997138319508804 | validation: 0.15883563197583606]
	TIME [epoch: 9.07 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2180667484839498		[learning rate: 0.0083804]
	Learning Rate: 0.00838037
	LOSS [training: 0.2180667484839498 | validation: 0.4138252854968886]
	TIME [epoch: 9.08 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5059321166989428		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 0.5059321166989428 | validation: 1.187117724370889]
	TIME [epoch: 9.08 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5073949126297296		[learning rate: 0.0083398]
	Learning Rate: 0.00833984
	LOSS [training: 0.5073949126297296 | validation: 0.19904130496745404]
	TIME [epoch: 9.1 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3365503523831017		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.3365503523831017 | validation: 0.3147851110361486]
	TIME [epoch: 9.08 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2216850872341337		[learning rate: 0.0082995]
	Learning Rate: 0.00829951
	LOSS [training: 0.2216850872341337 | validation: 0.20519799019226526]
	TIME [epoch: 9.08 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18444633419706075		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.18444633419706075 | validation: 0.20701581972522742]
	TIME [epoch: 9.08 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21876618022686353		[learning rate: 0.0082594]
	Learning Rate: 0.00825938
	LOSS [training: 0.21876618022686353 | validation: 0.2567791534511858]
	TIME [epoch: 9.1 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21590702397603842		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.21590702397603842 | validation: 0.2633949157121853]
	TIME [epoch: 9.09 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23153642412465342		[learning rate: 0.0082194]
	Learning Rate: 0.00821944
	LOSS [training: 0.23153642412465342 | validation: 0.2049157701524389]
	TIME [epoch: 9.09 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20770739982010084		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.20770739982010084 | validation: 0.3209444111468338]
	TIME [epoch: 9.09 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2135317638190412		[learning rate: 0.0081797]
	Learning Rate: 0.00817969
	LOSS [training: 0.2135317638190412 | validation: 0.23397459397256815]
	TIME [epoch: 9.08 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25454436603525743		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.25454436603525743 | validation: 0.29252098611896127]
	TIME [epoch: 9.11 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23327689736387908		[learning rate: 0.0081401]
	Learning Rate: 0.00814013
	LOSS [training: 0.23327689736387908 | validation: 0.3772956472250818]
	TIME [epoch: 9.09 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2618325541027883		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.2618325541027883 | validation: 0.2861496520291098]
	TIME [epoch: 9.09 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28378225277096186		[learning rate: 0.0081008]
	Learning Rate: 0.00810077
	LOSS [training: 0.28378225277096186 | validation: 0.20957139316665813]
	TIME [epoch: 9.08 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18274436971448813		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.18274436971448813 | validation: 0.14984290953430188]
	TIME [epoch: 9.1 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3697395573780283		[learning rate: 0.0080616]
	Learning Rate: 0.0080616
	LOSS [training: 0.3697395573780283 | validation: 0.716082103169813]
	TIME [epoch: 9.09 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45190620649273916		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.45190620649273916 | validation: 0.16407584124347713]
	TIME [epoch: 9.09 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2079478090836861		[learning rate: 0.0080226]
	Learning Rate: 0.00802261
	LOSS [training: 0.2079478090836861 | validation: 0.25877684767749354]
	TIME [epoch: 9.09 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21626838480420202		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.21626838480420202 | validation: 0.21172999758730132]
	TIME [epoch: 9.08 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23125076149783136		[learning rate: 0.0079838]
	Learning Rate: 0.00798382
	LOSS [training: 0.23125076149783136 | validation: 0.2286640821076899]
	TIME [epoch: 9.11 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22120470399275433		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.22120470399275433 | validation: 0.22375778761996074]
	TIME [epoch: 9.1 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2189214853481521		[learning rate: 0.0079452]
	Learning Rate: 0.00794521
	LOSS [training: 0.2189214853481521 | validation: 0.23231720668811795]
	TIME [epoch: 9.09 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20512121310944392		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.20512121310944392 | validation: 0.6116195112412501]
	TIME [epoch: 9.09 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5905592757243425		[learning rate: 0.0079068]
	Learning Rate: 0.00790679
	LOSS [training: 0.5905592757243425 | validation: 0.9273351031232051]
	TIME [epoch: 9.09 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4686644764413449		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.4686644764413449 | validation: 0.1857446738814992]
	TIME [epoch: 9.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5745604813658759		[learning rate: 0.0078685]
	Learning Rate: 0.00786855
	LOSS [training: 0.5745604813658759 | validation: 0.943933831827853]
	TIME [epoch: 9.09 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.378786378451984		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.378786378451984 | validation: 0.33783134971713447]
	TIME [epoch: 9.09 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21222091836297582		[learning rate: 0.0078305]
	Learning Rate: 0.0078305
	LOSS [training: 0.21222091836297582 | validation: 0.18893984464563912]
	TIME [epoch: 9.09 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1797026155033359		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.1797026155033359 | validation: 0.1258852949816488]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20421661643068173		[learning rate: 0.0077926]
	Learning Rate: 0.00779263
	LOSS [training: 0.20421661643068173 | validation: 0.21706243620376697]
	TIME [epoch: 9.09 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19374888908877957		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.19374888908877957 | validation: 0.20588097979617853]
	TIME [epoch: 9.08 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1939397631564669		[learning rate: 0.0077549]
	Learning Rate: 0.00775495
	LOSS [training: 0.1939397631564669 | validation: 0.2743633067225629]
	TIME [epoch: 9.08 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30637906444239527		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.30637906444239527 | validation: 0.30563160616864093]
	TIME [epoch: 9.09 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.358681758267305		[learning rate: 0.0077174]
	Learning Rate: 0.00771745
	LOSS [training: 0.358681758267305 | validation: 1.836274518094203]
	TIME [epoch: 9.11 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6420208603604972		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.6420208603604972 | validation: 0.29930391002812845]
	TIME [epoch: 9.09 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19191308682180164		[learning rate: 0.0076801]
	Learning Rate: 0.00768013
	LOSS [training: 0.19191308682180164 | validation: 0.27192024377464225]
	TIME [epoch: 9.09 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25381160590267215		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.25381160590267215 | validation: 0.20389705636271835]
	TIME [epoch: 9.08 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18865112657817157		[learning rate: 0.007643]
	Learning Rate: 0.00764299
	LOSS [training: 0.18865112657817157 | validation: 0.1366360190959441]
	TIME [epoch: 9.1 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22573574556078366		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.22573574556078366 | validation: 0.15982286386710118]
	TIME [epoch: 9.08 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23207697899903706		[learning rate: 0.007606]
	Learning Rate: 0.00760603
	LOSS [training: 0.23207697899903706 | validation: 0.27408187661222416]
	TIME [epoch: 9.08 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24492127054479954		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.24492127054479954 | validation: 0.17651349440973096]
	TIME [epoch: 9.08 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19988471845060798		[learning rate: 0.0075692]
	Learning Rate: 0.00756925
	LOSS [training: 0.19988471845060798 | validation: 0.1764368965149571]
	TIME [epoch: 9.08 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16742247020655732		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.16742247020655732 | validation: 0.31814926612035954]
	TIME [epoch: 9.09 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2160064714619548		[learning rate: 0.0075326]
	Learning Rate: 0.00753264
	LOSS [training: 0.2160064714619548 | validation: 0.22891653225523256]
	TIME [epoch: 9.08 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2044985932509032		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.2044985932509032 | validation: 0.3564452147847429]
	TIME [epoch: 9.07 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22436037178774654		[learning rate: 0.0074962]
	Learning Rate: 0.00749622
	LOSS [training: 0.22436037178774654 | validation: 0.33438973916672277]
	TIME [epoch: 9.08 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24411276536158008		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.24411276536158008 | validation: 0.13569580237931658]
	TIME [epoch: 9.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17093983731678866		[learning rate: 0.00746]
	Learning Rate: 0.00745997
	LOSS [training: 0.17093983731678866 | validation: 0.263122910665615]
	TIME [epoch: 9.09 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20766812561770123		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.20766812561770123 | validation: 0.15733927650257884]
	TIME [epoch: 9.09 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20647864135063126		[learning rate: 0.0074239]
	Learning Rate: 0.00742389
	LOSS [training: 0.20647864135063126 | validation: 0.1492556348047353]
	TIME [epoch: 9.08 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13088002822967196		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.13088002822967196 | validation: 0.13470932673904884]
	TIME [epoch: 9.08 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15656115070474735		[learning rate: 0.007388]
	Learning Rate: 0.00738799
	LOSS [training: 0.15656115070474735 | validation: 0.22400856028837424]
	TIME [epoch: 9.1 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1829054085036191		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.1829054085036191 | validation: 0.25098379514801766]
	TIME [epoch: 9.07 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23900160948403912		[learning rate: 0.0073523]
	Learning Rate: 0.00735226
	LOSS [training: 0.23900160948403912 | validation: 0.29847590273974856]
	TIME [epoch: 9.08 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44483746446162886		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.44483746446162886 | validation: 0.2714686750490226]
	TIME [epoch: 9.07 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18130806711223568		[learning rate: 0.0073167]
	Learning Rate: 0.00731671
	LOSS [training: 0.18130806711223568 | validation: 0.2343610822321292]
	TIME [epoch: 9.09 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1823899039209113		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.1823899039209113 | validation: 0.14371756009307612]
	TIME [epoch: 9.09 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28188446435343983		[learning rate: 0.0072813]
	Learning Rate: 0.00728133
	LOSS [training: 0.28188446435343983 | validation: 0.1488524037535316]
	TIME [epoch: 9.08 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17708216720498265		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.17708216720498265 | validation: 0.17710188095127805]
	TIME [epoch: 9.08 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1760220970541633		[learning rate: 0.0072461]
	Learning Rate: 0.00724612
	LOSS [training: 0.1760220970541633 | validation: 0.21945346742831745]
	TIME [epoch: 9.09 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23747046549608136		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.23747046549608136 | validation: 0.20646288499828283]
	TIME [epoch: 9.11 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29311921052623513		[learning rate: 0.0072111]
	Learning Rate: 0.00721107
	LOSS [training: 0.29311921052623513 | validation: 0.15909039568994882]
	TIME [epoch: 9.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15649224719521102		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.15649224719521102 | validation: 0.26754329099638696]
	TIME [epoch: 9.09 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3220262546256555		[learning rate: 0.0071762]
	Learning Rate: 0.0071762
	LOSS [training: 0.3220262546256555 | validation: 0.47609200184185724]
	TIME [epoch: 9.08 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19992468844164474		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.19992468844164474 | validation: 0.11652497260122915]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14824762620961537		[learning rate: 0.0071415]
	Learning Rate: 0.0071415
	LOSS [training: 0.14824762620961537 | validation: 0.23953582089051706]
	TIME [epoch: 9.11 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18622336933031378		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.18622336933031378 | validation: 0.5053329295535034]
	TIME [epoch: 9.1 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4739877614249218		[learning rate: 0.007107]
	Learning Rate: 0.00710696
	LOSS [training: 0.4739877614249218 | validation: 0.21410088462879995]
	TIME [epoch: 9.09 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.283350405003087		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.283350405003087 | validation: 0.19271155368542797]
	TIME [epoch: 9.09 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13374420562678324		[learning rate: 0.0070726]
	Learning Rate: 0.0070726
	LOSS [training: 0.13374420562678324 | validation: 0.28874776868110674]
	TIME [epoch: 9.12 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20829660136609465		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.20829660136609465 | validation: 0.19898910668623723]
	TIME [epoch: 9.1 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18254132162855796		[learning rate: 0.0070384]
	Learning Rate: 0.0070384
	LOSS [training: 0.18254132162855796 | validation: 0.27777181580235755]
	TIME [epoch: 9.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21665757426017024		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.21665757426017024 | validation: 0.20408259994817024]
	TIME [epoch: 9.1 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16188548029093341		[learning rate: 0.0070044]
	Learning Rate: 0.00700436
	LOSS [training: 0.16188548029093341 | validation: 0.14690589941937826]
	TIME [epoch: 9.1 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20540219422586975		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.20540219422586975 | validation: 0.09113443963223009]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15901715491882196		[learning rate: 0.0069705]
	Learning Rate: 0.00697049
	LOSS [training: 0.15901715491882196 | validation: 0.1341716652789682]
	TIME [epoch: 9.1 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14926006425418517		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.14926006425418517 | validation: 0.2428654689209984]
	TIME [epoch: 9.1 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16922238772032472		[learning rate: 0.0069368]
	Learning Rate: 0.00693678
	LOSS [training: 0.16922238772032472 | validation: 0.20728305666485908]
	TIME [epoch: 9.09 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23800101390117107		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.23800101390117107 | validation: 0.130708662885251]
	TIME [epoch: 9.12 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17267681649366567		[learning rate: 0.0069032]
	Learning Rate: 0.00690323
	LOSS [training: 0.17267681649366567 | validation: 0.39649145994145496]
	TIME [epoch: 9.1 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24209976900035973		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.24209976900035973 | validation: 0.15052614242564916]
	TIME [epoch: 9.1 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18460904901353034		[learning rate: 0.0068699]
	Learning Rate: 0.00686985
	LOSS [training: 0.18460904901353034 | validation: 0.16004671314699592]
	TIME [epoch: 9.1 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1690298965382692		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.1690298965382692 | validation: 0.22267643535227488]
	TIME [epoch: 9.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20128551929446217		[learning rate: 0.0068366]
	Learning Rate: 0.00683663
	LOSS [training: 0.20128551929446217 | validation: 0.1927837241823143]
	TIME [epoch: 9.11 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.185939712675263		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.185939712675263 | validation: 0.16560547412179288]
	TIME [epoch: 9.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21250790073396253		[learning rate: 0.0068036]
	Learning Rate: 0.00680357
	LOSS [training: 0.21250790073396253 | validation: 0.2072643247339875]
	TIME [epoch: 9.09 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20299522986211466		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.20299522986211466 | validation: 0.13400598640303404]
	TIME [epoch: 9.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23982413473966457		[learning rate: 0.0067707]
	Learning Rate: 0.00677067
	LOSS [training: 0.23982413473966457 | validation: 0.22357667397441058]
	TIME [epoch: 9.11 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20447488825401008		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.20447488825401008 | validation: 0.15052065431144965]
	TIME [epoch: 9.1 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18226611429332873		[learning rate: 0.0067379]
	Learning Rate: 0.00673793
	LOSS [training: 0.18226611429332873 | validation: 0.14178541927176758]
	TIME [epoch: 9.1 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15428095634327443		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.15428095634327443 | validation: 0.09353733190000485]
	TIME [epoch: 9.09 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12681026581848742		[learning rate: 0.0067053]
	Learning Rate: 0.00670534
	LOSS [training: 0.12681026581848742 | validation: 0.22277996089683538]
	TIME [epoch: 9.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1528928970813737		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.1528928970813737 | validation: 0.23841331851643602]
	TIME [epoch: 9.11 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42336207082600563		[learning rate: 0.0066729]
	Learning Rate: 0.00667292
	LOSS [training: 0.42336207082600563 | validation: 0.20535579441271634]
	TIME [epoch: 9.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1511184448716072		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.1511184448716072 | validation: 0.08230473580325182]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21071622907381876		[learning rate: 0.0066406]
	Learning Rate: 0.00664065
	LOSS [training: 0.21071622907381876 | validation: 0.21795574372878784]
	TIME [epoch: 9.09 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13693474804440026		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.13693474804440026 | validation: 0.123889204692652]
	TIME [epoch: 9.11 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2483347425289028		[learning rate: 0.0066085]
	Learning Rate: 0.00660854
	LOSS [training: 0.2483347425289028 | validation: 0.09110519304705261]
	TIME [epoch: 9.09 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17199753924577016		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.17199753924577016 | validation: 0.09718251454971]
	TIME [epoch: 9.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.096659227894799		[learning rate: 0.0065766]
	Learning Rate: 0.00657658
	LOSS [training: 0.096659227894799 | validation: 0.16972734555249386]
	TIME [epoch: 9.11 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14353908955263933		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.14353908955263933 | validation: 0.11031678190067137]
	TIME [epoch: 9.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16719295240773233		[learning rate: 0.0065448]
	Learning Rate: 0.00654477
	LOSS [training: 0.16719295240773233 | validation: 0.10314688436831637]
	TIME [epoch: 9.12 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1504495244393751		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.1504495244393751 | validation: 0.10420644804752557]
	TIME [epoch: 9.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16518195370624564		[learning rate: 0.0065131]
	Learning Rate: 0.00651313
	LOSS [training: 0.16518195370624564 | validation: 0.15750538362873434]
	TIME [epoch: 9.09 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15165720251707737		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.15165720251707737 | validation: 0.1280862575497519]
	TIME [epoch: 9.09 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11629194845117533		[learning rate: 0.0064816]
	Learning Rate: 0.00648163
	LOSS [training: 0.11629194845117533 | validation: 0.16583493825194062]
	TIME [epoch: 9.11 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12834988442911038		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.12834988442911038 | validation: 0.14885556438177466]
	TIME [epoch: 9.11 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22354783585385313		[learning rate: 0.0064503]
	Learning Rate: 0.00645029
	LOSS [training: 0.22354783585385313 | validation: 0.5034609516981857]
	TIME [epoch: 9.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2329986487629538		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.2329986487629538 | validation: 0.14375592852825825]
	TIME [epoch: 9.09 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13925664710693242		[learning rate: 0.0064191]
	Learning Rate: 0.00641909
	LOSS [training: 0.13925664710693242 | validation: 0.1227498133605568]
	TIME [epoch: 9.09 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31567771929780697		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.31567771929780697 | validation: 0.1402545756190937]
	TIME [epoch: 9.11 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2649163499607304		[learning rate: 0.0063881]
	Learning Rate: 0.00638805
	LOSS [training: 0.2649163499607304 | validation: 0.09076177328949589]
	TIME [epoch: 9.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10432962089305912		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.10432962089305912 | validation: 0.16119014859167619]
	TIME [epoch: 9.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1654708881970909		[learning rate: 0.0063572]
	Learning Rate: 0.00635716
	LOSS [training: 0.1654708881970909 | validation: 0.17132984825767225]
	TIME [epoch: 9.1 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15728962349810482		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.15728962349810482 | validation: 0.11389534402481727]
	TIME [epoch: 9.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15257267654299753		[learning rate: 0.0063264]
	Learning Rate: 0.00632642
	LOSS [training: 0.15257267654299753 | validation: 0.20169848740278057]
	TIME [epoch: 9.12 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19725887639243628		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.19725887639243628 | validation: 0.15698496001704154]
	TIME [epoch: 9.09 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19286993262021818		[learning rate: 0.0062958]
	Learning Rate: 0.00629582
	LOSS [training: 0.19286993262021818 | validation: 0.3199546875448389]
	TIME [epoch: 9.09 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35207235360089983		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.35207235360089983 | validation: 0.18098971892466859]
	TIME [epoch: 9.09 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3304796594024541		[learning rate: 0.0062654]
	Learning Rate: 0.00626538
	LOSS [training: 0.3304796594024541 | validation: 0.7093652517035185]
	TIME [epoch: 9.12 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5335803620731319		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.5335803620731319 | validation: 0.271505764708857]
	TIME [epoch: 9.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.342658842495571		[learning rate: 0.0062351]
	Learning Rate: 0.00623508
	LOSS [training: 0.342658842495571 | validation: 0.2564796802313031]
	TIME [epoch: 9.09 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2982091634240577		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.2982091634240577 | validation: 0.25848864839701086]
	TIME [epoch: 9.1 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19951448103640107		[learning rate: 0.0062049]
	Learning Rate: 0.00620493
	LOSS [training: 0.19951448103640107 | validation: 0.12886448757483115]
	TIME [epoch: 9.09 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12225101631853694		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.12225101631853694 | validation: 0.169064508029034]
	TIME [epoch: 9.11 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1387077429774733		[learning rate: 0.0061749]
	Learning Rate: 0.00617492
	LOSS [training: 0.1387077429774733 | validation: 0.28780650392353446]
	TIME [epoch: 9.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17053987742121637		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.17053987742121637 | validation: 0.1533515462355154]
	TIME [epoch: 9.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20279418064913676		[learning rate: 0.0061451]
	Learning Rate: 0.00614506
	LOSS [training: 0.20279418064913676 | validation: 0.1666108731821247]
	TIME [epoch: 9.1 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13470955867116788		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.13470955867116788 | validation: 0.10652821288624645]
	TIME [epoch: 9.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16801603254679223		[learning rate: 0.0061153]
	Learning Rate: 0.00611535
	LOSS [training: 0.16801603254679223 | validation: 0.084186451214706]
	TIME [epoch: 9.09 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13613846206276875		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.13613846206276875 | validation: 0.10767671444505553]
	TIME [epoch: 9.09 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1411450212732833		[learning rate: 0.0060858]
	Learning Rate: 0.00608577
	LOSS [training: 0.1411450212732833 | validation: 0.34134865180466833]
	TIME [epoch: 9.08 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15367146447016403		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.15367146447016403 | validation: 0.09608447091979311]
	TIME [epoch: 9.09 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2596331867340578		[learning rate: 0.0060563]
	Learning Rate: 0.00605634
	LOSS [training: 0.2596331867340578 | validation: 0.1805537994204119]
	TIME [epoch: 9.11 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3098963268870877		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.3098963268870877 | validation: 0.3825984098662177]
	TIME [epoch: 9.09 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19412541081310497		[learning rate: 0.0060271]
	Learning Rate: 0.00602706
	LOSS [training: 0.19412541081310497 | validation: 0.16690874462149774]
	TIME [epoch: 9.09 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17553739360916548		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.17553739360916548 | validation: 0.24525675569645358]
	TIME [epoch: 9.08 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3622735347543384		[learning rate: 0.0059979]
	Learning Rate: 0.00599791
	LOSS [training: 0.3622735347543384 | validation: 0.3507385079895381]
	TIME [epoch: 9.1 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1917357116746986		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.1917357116746986 | validation: 0.10353578118597992]
	TIME [epoch: 9.11 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1307032971404708		[learning rate: 0.0059689]
	Learning Rate: 0.00596891
	LOSS [training: 0.1307032971404708 | validation: 0.19916910852467606]
	TIME [epoch: 9.1 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13300907528444178		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.13300907528444178 | validation: 0.10729759864514052]
	TIME [epoch: 9.1 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12459331005564205		[learning rate: 0.00594]
	Learning Rate: 0.00594004
	LOSS [training: 0.12459331005564205 | validation: 0.10917680993687223]
	TIME [epoch: 9.08 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31619794973155396		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.31619794973155396 | validation: 0.16410394903319603]
	TIME [epoch: 9.11 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13760851333572854		[learning rate: 0.0059113]
	Learning Rate: 0.00591132
	LOSS [training: 0.13760851333572854 | validation: 0.17574535348100923]
	TIME [epoch: 9.09 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28284577348941664		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.28284577348941664 | validation: 0.43104185945833573]
	TIME [epoch: 9.08 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21468742383190348		[learning rate: 0.0058827]
	Learning Rate: 0.00588273
	LOSS [training: 0.21468742383190348 | validation: 0.2403284536105069]
	TIME [epoch: 9.09 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.182115222739732		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.182115222739732 | validation: 0.1363222748324873]
	TIME [epoch: 9.08 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21458005420104986		[learning rate: 0.0058543]
	Learning Rate: 0.00585428
	LOSS [training: 0.21458005420104986 | validation: 0.1593704487480966]
	TIME [epoch: 9.11 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2813960948971307		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.2813960948971307 | validation: 1.2935534615097815]
	TIME [epoch: 9.09 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5927431612826446		[learning rate: 0.005826]
	Learning Rate: 0.00582597
	LOSS [training: 0.5927431612826446 | validation: 0.24886149453131862]
	TIME [epoch: 9.08 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20826931509979962		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.20826931509979962 | validation: 0.23232741396157963]
	TIME [epoch: 9.09 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2060323961540656		[learning rate: 0.0057978]
	Learning Rate: 0.0057978
	LOSS [training: 0.2060323961540656 | validation: 0.24951818767189848]
	TIME [epoch: 9.11 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42288650280118933		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.42288650280118933 | validation: 0.3837927075988883]
	TIME [epoch: 9.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2389940985822288		[learning rate: 0.0057698]
	Learning Rate: 0.00576976
	LOSS [training: 0.2389940985822288 | validation: 0.17175906612960568]
	TIME [epoch: 9.09 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1386434977764925		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.1386434977764925 | validation: 0.1441378244914707]
	TIME [epoch: 9.09 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11805403925566438		[learning rate: 0.0057419]
	Learning Rate: 0.00574186
	LOSS [training: 0.11805403925566438 | validation: 0.20456392244381588]
	TIME [epoch: 9.09 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18140491955481683		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.18140491955481683 | validation: 0.13211679368133072]
	TIME [epoch: 9.1 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21045375986723164		[learning rate: 0.0057141]
	Learning Rate: 0.00571409
	LOSS [training: 0.21045375986723164 | validation: 0.1623299501500335]
	TIME [epoch: 9.09 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18802212908293245		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.18802212908293245 | validation: 0.2040296202203838]
	TIME [epoch: 9.09 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2174536792329941		[learning rate: 0.0056865]
	Learning Rate: 0.00568646
	LOSS [training: 0.2174536792329941 | validation: 0.35650869461795176]
	TIME [epoch: 9.08 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19688412735013366		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.19688412735013366 | validation: 0.1525243729110478]
	TIME [epoch: 9.11 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15856791233481118		[learning rate: 0.005659]
	Learning Rate: 0.00565896
	LOSS [training: 0.15856791233481118 | validation: 0.16678329131129155]
	TIME [epoch: 9.08 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17594293405062694		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.17594293405062694 | validation: 0.23712565665804947]
	TIME [epoch: 9.09 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16959295148135373		[learning rate: 0.0056316]
	Learning Rate: 0.0056316
	LOSS [training: 0.16959295148135373 | validation: 0.37849890912502093]
	TIME [epoch: 9.09 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3597937906844844		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.3597937906844844 | validation: 0.27937731465190946]
	TIME [epoch: 9.08 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16249001307677804		[learning rate: 0.0056044]
	Learning Rate: 0.00560436
	LOSS [training: 0.16249001307677804 | validation: 0.10860233764533764]
	TIME [epoch: 9.11 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12410931520269428		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.12410931520269428 | validation: 0.1375993343050369]
	TIME [epoch: 9.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1801099339648129		[learning rate: 0.0055773]
	Learning Rate: 0.00557726
	LOSS [training: 0.1801099339648129 | validation: 0.13687870793188017]
	TIME [epoch: 9.09 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12559716424054143		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.12559716424054143 | validation: 0.31586557128046466]
	TIME [epoch: 9.09 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20558493125112415		[learning rate: 0.0055503]
	Learning Rate: 0.00555029
	LOSS [training: 0.20558493125112415 | validation: 0.1724233724902403]
	TIME [epoch: 9.1 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14087623646332365		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.14087623646332365 | validation: 0.18004344282870435]
	TIME [epoch: 9.1 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1697335507243606		[learning rate: 0.0055235]
	Learning Rate: 0.00552345
	LOSS [training: 0.1697335507243606 | validation: 0.1257846633009886]
	TIME [epoch: 9.09 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1212307684668571		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.1212307684668571 | validation: 0.12118278028747609]
	TIME [epoch: 9.09 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10889104025706202		[learning rate: 0.0054967]
	Learning Rate: 0.00549674
	LOSS [training: 0.10889104025706202 | validation: 0.1123592630550005]
	TIME [epoch: 9.08 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20075213339193657		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.20075213339193657 | validation: 0.1805370104774006]
	TIME [epoch: 9.1 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1466554162215363		[learning rate: 0.0054702]
	Learning Rate: 0.00547016
	LOSS [training: 0.1466554162215363 | validation: 0.15920265399171007]
	TIME [epoch: 9.09 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1833122106990131		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.1833122106990131 | validation: 0.11984745660018713]
	TIME [epoch: 9.09 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11831237735838565		[learning rate: 0.0054437]
	Learning Rate: 0.00544371
	LOSS [training: 0.11831237735838565 | validation: 0.1155047430797089]
	TIME [epoch: 9.09 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10902563331018755		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.10902563331018755 | validation: 0.11217819470350117]
	TIME [epoch: 9.1 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11642478149476891		[learning rate: 0.0054174]
	Learning Rate: 0.00541738
	LOSS [training: 0.11642478149476891 | validation: 0.13082505328979271]
	TIME [epoch: 9.11 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1497956075029178		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.1497956075029178 | validation: 0.12904937604708297]
	TIME [epoch: 9.09 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15541624378723568		[learning rate: 0.0053912]
	Learning Rate: 0.00539118
	LOSS [training: 0.15541624378723568 | validation: 0.1327492163423736]
	TIME [epoch: 9.09 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.573746557214189		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.573746557214189 | validation: 0.4903627378172793]
	TIME [epoch: 9.09 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3723557762275548		[learning rate: 0.0053651]
	Learning Rate: 0.00536511
	LOSS [training: 0.3723557762275548 | validation: 0.1679707704335908]
	TIME [epoch: 9.11 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15349829047773958		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.15349829047773958 | validation: 0.19444139838724422]
	TIME [epoch: 9.09 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15086818127193974		[learning rate: 0.0053392]
	Learning Rate: 0.00533917
	LOSS [training: 0.15086818127193974 | validation: 0.1333636945497204]
	TIME [epoch: 9.09 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11082451590365186		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.11082451590365186 | validation: 0.19014459087594016]
	TIME [epoch: 9.09 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1259561841644118		[learning rate: 0.0053133]
	Learning Rate: 0.00531335
	LOSS [training: 0.1259561841644118 | validation: 0.22410205513479947]
	TIME [epoch: 9.09 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12812672201922332		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.12812672201922332 | validation: 0.16102092913081784]
	TIME [epoch: 9.11 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13343051744564663		[learning rate: 0.0052877]
	Learning Rate: 0.00528766
	LOSS [training: 0.13343051744564663 | validation: 0.13081305569673723]
	TIME [epoch: 9.09 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14602514364426025		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.14602514364426025 | validation: 0.1637723995466256]
	TIME [epoch: 9.09 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3214312555568535		[learning rate: 0.0052621]
	Learning Rate: 0.00526209
	LOSS [training: 0.3214312555568535 | validation: 1.3541813907208136]
	TIME [epoch: 9.09 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3326903289670797		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.3326903289670797 | validation: 0.1370011901971286]
	TIME [epoch: 9.11 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29839028731396		[learning rate: 0.0052366]
	Learning Rate: 0.00523664
	LOSS [training: 0.29839028731396 | validation: 0.26009150656954577]
	TIME [epoch: 9.1 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1637465429379869		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.1637465429379869 | validation: 0.13395202267966805]
	TIME [epoch: 9.09 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12839498507021246		[learning rate: 0.0052113]
	Learning Rate: 0.00521132
	LOSS [training: 0.12839498507021246 | validation: 0.1825545380055943]
	TIME [epoch: 9.09 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15426379179186672		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.15426379179186672 | validation: 0.13331064334783496]
	TIME [epoch: 9.09 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1377062435013801		[learning rate: 0.0051861]
	Learning Rate: 0.00518611
	LOSS [training: 0.1377062435013801 | validation: 0.136722568543924]
	TIME [epoch: 9.11 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24539722652518262		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.24539722652518262 | validation: 0.14478385689047113]
	TIME [epoch: 9.09 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556597803582784		[learning rate: 0.005161]
	Learning Rate: 0.00516104
	LOSS [training: 0.2556597803582784 | validation: 0.32557153583713094]
	TIME [epoch: 9.09 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3500711287617059		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.3500711287617059 | validation: 0.231824387650678]
	TIME [epoch: 9.08 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19076276698055694		[learning rate: 0.0051361]
	Learning Rate: 0.00513608
	LOSS [training: 0.19076276698055694 | validation: 0.19860623273473044]
	TIME [epoch: 9.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1953720771219861		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.1953720771219861 | validation: 0.1370164062927392]
	TIME [epoch: 9.09 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20971981811287183		[learning rate: 0.0051112]
	Learning Rate: 0.00511124
	LOSS [training: 0.20971981811287183 | validation: 0.26199311620451915]
	TIME [epoch: 9.09 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15826591448547156		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.15826591448547156 | validation: 0.07723814926746805]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12593940456856428		[learning rate: 0.0050865]
	Learning Rate: 0.00508652
	LOSS [training: 0.12593940456856428 | validation: 0.12068107589627766]
	TIME [epoch: 9.09 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1375904308031509		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.1375904308031509 | validation: 0.124307411141894]
	TIME [epoch: 9.11 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10923498105121136		[learning rate: 0.0050619]
	Learning Rate: 0.00506193
	LOSS [training: 0.10923498105121136 | validation: 0.07344985551924824]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11539686763951859		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.11539686763951859 | validation: 0.06941784456989508]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13854312761881463		[learning rate: 0.0050374]
	Learning Rate: 0.00503745
	LOSS [training: 0.13854312761881463 | validation: 0.38009037140852087]
	TIME [epoch: 9.09 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27570186702032584		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.27570186702032584 | validation: 0.2052647484540766]
	TIME [epoch: 9.1 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23908543914908345		[learning rate: 0.0050131]
	Learning Rate: 0.00501309
	LOSS [training: 0.23908543914908345 | validation: 0.09193791428399847]
	TIME [epoch: 9.1 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13370946805166262		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.13370946805166262 | validation: 0.16440118923657016]
	TIME [epoch: 9.09 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08738066999879385		[learning rate: 0.0049888]
	Learning Rate: 0.00498884
	LOSS [training: 0.08738066999879385 | validation: 0.2184210797004053]
	TIME [epoch: 9.08 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1252451194187537		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.1252451194187537 | validation: 0.12241716448841064]
	TIME [epoch: 9.09 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1622467706763529		[learning rate: 0.0049647]
	Learning Rate: 0.00496472
	LOSS [training: 0.1622467706763529 | validation: 0.3326555885627853]
	TIME [epoch: 9.11 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1860761923152599		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.1860761923152599 | validation: 0.12144600060418184]
	TIME [epoch: 9.09 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11394058275942365		[learning rate: 0.0049407]
	Learning Rate: 0.00494071
	LOSS [training: 0.11394058275942365 | validation: 0.11175524444675877]
	TIME [epoch: 9.08 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11059668423582336		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.11059668423582336 | validation: 0.18295862623836606]
	TIME [epoch: 9.09 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14042194956969006		[learning rate: 0.0049168]
	Learning Rate: 0.00491682
	LOSS [training: 0.14042194956969006 | validation: 0.15915473073502595]
	TIME [epoch: 9.1 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2036953044768044		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.2036953044768044 | validation: 0.10833177013583692]
	TIME [epoch: 9.11 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10472443070124862		[learning rate: 0.004893]
	Learning Rate: 0.00489304
	LOSS [training: 0.10472443070124862 | validation: 0.131346162251668]
	TIME [epoch: 9.09 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24674650113818944		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.24674650113818944 | validation: 0.23169530418457027]
	TIME [epoch: 9.09 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11321468241899746		[learning rate: 0.0048694]
	Learning Rate: 0.00486938
	LOSS [training: 0.11321468241899746 | validation: 0.19112472105688944]
	TIME [epoch: 9.09 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14309920657955577		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.14309920657955577 | validation: 0.13978222295174614]
	TIME [epoch: 9.11 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13499328015655995		[learning rate: 0.0048458]
	Learning Rate: 0.00484583
	LOSS [training: 0.13499328015655995 | validation: 0.14941355373426485]
	TIME [epoch: 9.1 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13285939122551135		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.13285939122551135 | validation: 0.12882938319204923]
	TIME [epoch: 9.09 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13922264628813208		[learning rate: 0.0048224]
	Learning Rate: 0.0048224
	LOSS [training: 0.13922264628813208 | validation: 0.1505882891644041]
	TIME [epoch: 9.09 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30901847610238237		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.30901847610238237 | validation: 0.13549606187727775]
	TIME [epoch: 9.08 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.249766766055206		[learning rate: 0.0047991]
	Learning Rate: 0.00479908
	LOSS [training: 0.249766766055206 | validation: 0.13337065838651155]
	TIME [epoch: 9.11 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1188413532937778		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.1188413532937778 | validation: 0.14938057972733348]
	TIME [epoch: 9.09 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11423516231749624		[learning rate: 0.0047759]
	Learning Rate: 0.00477587
	LOSS [training: 0.11423516231749624 | validation: 0.12735728976771446]
	TIME [epoch: 9.09 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13026594403483488		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.13026594403483488 | validation: 0.25256421416201935]
	TIME [epoch: 9.09 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11723359339664237		[learning rate: 0.0047528]
	Learning Rate: 0.00475278
	LOSS [training: 0.11723359339664237 | validation: 0.2460016043048942]
	TIME [epoch: 9.12 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13438262275003737		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.13438262275003737 | validation: 0.09138680772990175]
	TIME [epoch: 9.1 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1003674007277883		[learning rate: 0.0047298]
	Learning Rate: 0.00472979
	LOSS [training: 0.1003674007277883 | validation: 0.07500225174663422]
	TIME [epoch: 9.08 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12957841800610378		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.12957841800610378 | validation: 0.15079388347147898]
	TIME [epoch: 9.08 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11616346521711592		[learning rate: 0.0047069]
	Learning Rate: 0.00470692
	LOSS [training: 0.11616346521711592 | validation: 0.19062503150117294]
	TIME [epoch: 9.09 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12281560936804407		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.12281560936804407 | validation: 0.07520371472487246]
	TIME [epoch: 9.1 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13022660135431055		[learning rate: 0.0046842]
	Learning Rate: 0.00468416
	LOSS [training: 0.13022660135431055 | validation: 0.09171232442338517]
	TIME [epoch: 9.08 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1435511453028109		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.1435511453028109 | validation: 0.1088767750688108]
	TIME [epoch: 9.09 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10168216244578517		[learning rate: 0.0046615]
	Learning Rate: 0.00466151
	LOSS [training: 0.10168216244578517 | validation: 0.08847643049832296]
	TIME [epoch: 9.08 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08262562326517622		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.08262562326517622 | validation: 0.16729939345013833]
	TIME [epoch: 9.1 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12529067451782944		[learning rate: 0.004639]
	Learning Rate: 0.00463896
	LOSS [training: 0.12529067451782944 | validation: 0.09440432557012093]
	TIME [epoch: 9.09 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11365786794630642		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.11365786794630642 | validation: 0.09865392228447564]
	TIME [epoch: 9.1 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1595329955909571		[learning rate: 0.0046165]
	Learning Rate: 0.00461653
	LOSS [training: 0.1595329955909571 | validation: 0.16031802154820166]
	TIME [epoch: 9.09 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21273350906796318		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.21273350906796318 | validation: 0.08239081412556229]
	TIME [epoch: 9.08 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15358837418315813		[learning rate: 0.0045942]
	Learning Rate: 0.00459421
	LOSS [training: 0.15358837418315813 | validation: 0.47118886288788675]
	TIME [epoch: 9.11 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13454615500683248		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.13454615500683248 | validation: 0.13966062306238947]
	TIME [epoch: 9.09 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13921901501043915		[learning rate: 0.004572]
	Learning Rate: 0.00457199
	LOSS [training: 0.13921901501043915 | validation: 0.06763513212429334]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_423.pth
	Model improved!!!
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13673993651747882		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.13673993651747882 | validation: 0.2224198515973641]
	TIME [epoch: 9.09 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4021774016950702		[learning rate: 0.0045499]
	Learning Rate: 0.00454988
	LOSS [training: 0.4021774016950702 | validation: 0.16981487159558295]
	TIME [epoch: 9.09 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1432223556070137		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.1432223556070137 | validation: 0.19792343400669732]
	TIME [epoch: 9.09 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22976391474724406		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.22976391474724406 | validation: 0.17290237259182373]
	TIME [epoch: 9.08 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5431452376849988		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.5431452376849988 | validation: 0.4415537564647489]
	TIME [epoch: 9.07 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.290465327377883		[learning rate: 0.004506]
	Learning Rate: 0.00450598
	LOSS [training: 0.290465327377883 | validation: 0.2672093870218678]
	TIME [epoch: 9.08 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11935970281644037		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.11935970281644037 | validation: 0.08680255787167629]
	TIME [epoch: 9.1 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11038699030767704		[learning rate: 0.0044842]
	Learning Rate: 0.00448419
	LOSS [training: 0.11038699030767704 | validation: 0.15317663928836509]
	TIME [epoch: 9.09 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1279842032015098		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.1279842032015098 | validation: 0.1693009820016805]
	TIME [epoch: 9.08 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2554157504100955		[learning rate: 0.0044625]
	Learning Rate: 0.00446251
	LOSS [training: 0.2554157504100955 | validation: 0.1704883023949879]
	TIME [epoch: 9.08 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13565867302108056		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.13565867302108056 | validation: 0.15439391086529194]
	TIME [epoch: 9.08 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1564901421189669		[learning rate: 0.0044409]
	Learning Rate: 0.00444093
	LOSS [training: 0.1564901421189669 | validation: 0.09226645305887415]
	TIME [epoch: 9.1 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18759962607243447		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.18759962607243447 | validation: 0.1029512216380368]
	TIME [epoch: 9.08 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11736154623280229		[learning rate: 0.0044195]
	Learning Rate: 0.00441945
	LOSS [training: 0.11736154623280229 | validation: 0.10654329962228784]
	TIME [epoch: 9.08 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18533451935077894		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.18533451935077894 | validation: 0.3050662394214057]
	TIME [epoch: 9.07 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19779424259096687		[learning rate: 0.0043981]
	Learning Rate: 0.00439808
	LOSS [training: 0.19779424259096687 | validation: 0.09895150128074395]
	TIME [epoch: 9.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13058039489100076		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.13058039489100076 | validation: 0.08496023737293171]
	TIME [epoch: 9.08 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1281342723923752		[learning rate: 0.0043768]
	Learning Rate: 0.00437681
	LOSS [training: 0.1281342723923752 | validation: 0.13079735939536846]
	TIME [epoch: 9.07 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12334084938055176		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.12334084938055176 | validation: 0.19095986794430247]
	TIME [epoch: 9.08 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14845636619398794		[learning rate: 0.0043556]
	Learning Rate: 0.00435565
	LOSS [training: 0.14845636619398794 | validation: 0.13402932616629806]
	TIME [epoch: 9.08 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1521228738282681		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.1521228738282681 | validation: 0.1956989590092421]
	TIME [epoch: 9.11 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1345086890349742		[learning rate: 0.0043346]
	Learning Rate: 0.00433458
	LOSS [training: 0.1345086890349742 | validation: 0.13247130731572515]
	TIME [epoch: 9.08 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14355059168820894		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.14355059168820894 | validation: 0.22048484963474774]
	TIME [epoch: 9.08 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17832162306435118		[learning rate: 0.0043136]
	Learning Rate: 0.00431362
	LOSS [training: 0.17832162306435118 | validation: 0.12146473902867547]
	TIME [epoch: 9.08 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12903887503194414		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.12903887503194414 | validation: 0.09862274116243443]
	TIME [epoch: 9.09 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1382829367532275		[learning rate: 0.0042928]
	Learning Rate: 0.00429276
	LOSS [training: 0.1382829367532275 | validation: 0.17210320107403107]
	TIME [epoch: 9.09 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16216822280465407		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.16216822280465407 | validation: 0.13309694948439638]
	TIME [epoch: 9.09 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.142730512149368		[learning rate: 0.004272]
	Learning Rate: 0.004272
	LOSS [training: 0.142730512149368 | validation: 0.155737413393383]
	TIME [epoch: 9.08 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19267688759329932		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.19267688759329932 | validation: 0.1284136897803248]
	TIME [epoch: 9.08 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12525868729787876		[learning rate: 0.0042513]
	Learning Rate: 0.00425134
	LOSS [training: 0.12525868729787876 | validation: 0.19848690043805123]
	TIME [epoch: 9.1 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2551362734030464		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.2551362734030464 | validation: 0.2662666674667586]
	TIME [epoch: 9.08 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20272128428461547		[learning rate: 0.0042308]
	Learning Rate: 0.00423079
	LOSS [training: 0.20272128428461547 | validation: 0.10334170638769355]
	TIME [epoch: 9.08 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1434928545379634		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.1434928545379634 | validation: 0.17170503358728958]
	TIME [epoch: 9.08 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12703173536333137		[learning rate: 0.0042103]
	Learning Rate: 0.00421033
	LOSS [training: 0.12703173536333137 | validation: 0.09048477405181833]
	TIME [epoch: 9.09 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13105513252249468		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.13105513252249468 | validation: 0.11568486979931297]
	TIME [epoch: 9.09 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1122700583944634		[learning rate: 0.00419]
	Learning Rate: 0.00418997
	LOSS [training: 0.1122700583944634 | validation: 0.11350017586235578]
	TIME [epoch: 9.09 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17078513365328366		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.17078513365328366 | validation: 0.13880504618448503]
	TIME [epoch: 9.07 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13396449175217667		[learning rate: 0.0041697]
	Learning Rate: 0.0041697
	LOSS [training: 0.13396449175217667 | validation: 0.12808373991577254]
	TIME [epoch: 9.09 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14245654156462462		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.14245654156462462 | validation: 0.19301889028408517]
	TIME [epoch: 9.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2030041728717861		[learning rate: 0.0041495]
	Learning Rate: 0.00414954
	LOSS [training: 0.2030041728717861 | validation: 0.12927002888586953]
	TIME [epoch: 9.09 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15318639367338596		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.15318639367338596 | validation: 0.10962211560414738]
	TIME [epoch: 9.08 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14113595950158506		[learning rate: 0.0041295]
	Learning Rate: 0.00412947
	LOSS [training: 0.14113595950158506 | validation: 0.14787389542688534]
	TIME [epoch: 9.08 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12310153533396033		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.12310153533396033 | validation: 0.11452990040856825]
	TIME [epoch: 9.07 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12593018495075475		[learning rate: 0.0041095]
	Learning Rate: 0.0041095
	LOSS [training: 0.12593018495075475 | validation: 0.11769237782116762]
	TIME [epoch: 9.11 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11699313594199437		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.11699313594199437 | validation: 0.11201486696190545]
	TIME [epoch: 9.08 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11136131533408626		[learning rate: 0.0040896]
	Learning Rate: 0.00408963
	LOSS [training: 0.11136131533408626 | validation: 0.11863252550813849]
	TIME [epoch: 9.09 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2051274597586708		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.2051274597586708 | validation: 0.22751104431878175]
	TIME [epoch: 9.09 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2040601560630111		[learning rate: 0.0040699]
	Learning Rate: 0.00406985
	LOSS [training: 0.2040601560630111 | validation: 0.218096838826274]
	TIME [epoch: 9.12 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8601859757987974		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.8601859757987974 | validation: 1.180428461956112]
	TIME [epoch: 9.09 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5510305990331733		[learning rate: 0.0040502]
	Learning Rate: 0.00405017
	LOSS [training: 0.5510305990331733 | validation: 0.5808932438527622]
	TIME [epoch: 9.08 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2661757914085221		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.2661757914085221 | validation: 0.15310678678643286]
	TIME [epoch: 9.08 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5936729918922368		[learning rate: 0.0040306]
	Learning Rate: 0.00403059
	LOSS [training: 0.5936729918922368 | validation: 1.0471630047345288]
	TIME [epoch: 9.08 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.474331298321621		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.474331298321621 | validation: 0.3637820834342065]
	TIME [epoch: 9.11 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26953697343689326		[learning rate: 0.0040111]
	Learning Rate: 0.0040111
	LOSS [training: 0.26953697343689326 | validation: 0.3418833674531342]
	TIME [epoch: 9.09 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3356786561481596		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.3356786561481596 | validation: 0.15293763215758305]
	TIME [epoch: 9.08 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37376723877358337		[learning rate: 0.0039917]
	Learning Rate: 0.0039917
	LOSS [training: 0.37376723877358337 | validation: 0.507797022967554]
	TIME [epoch: 9.08 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34620402724766663		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.34620402724766663 | validation: 0.5223440689686888]
	TIME [epoch: 9.11 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4280480580386657		[learning rate: 0.0039724]
	Learning Rate: 0.0039724
	LOSS [training: 0.4280480580386657 | validation: 0.7912008995690949]
	TIME [epoch: 9.09 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4853259510694281		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.4853259510694281 | validation: 0.44291492189928655]
	TIME [epoch: 9.09 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25732126188920984		[learning rate: 0.0039532]
	Learning Rate: 0.00395319
	LOSS [training: 0.25732126188920984 | validation: 0.20949095588819777]
	TIME [epoch: 9.08 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20759075137211463		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.20759075137211463 | validation: 0.16796858562663716]
	TIME [epoch: 9.09 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17206473599580513		[learning rate: 0.0039341]
	Learning Rate: 0.00393407
	LOSS [training: 0.17206473599580513 | validation: 0.28279301303483245]
	TIME [epoch: 9.12 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23359260102578144		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.23359260102578144 | validation: 0.35097135529508167]
	TIME [epoch: 9.09 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34083880542325923		[learning rate: 0.003915]
	Learning Rate: 0.00391505
	LOSS [training: 0.34083880542325923 | validation: 0.21796031268640248]
	TIME [epoch: 9.08 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3096161076053171		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.3096161076053171 | validation: 0.18977333520439932]
	TIME [epoch: 9.08 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1513153090836067		[learning rate: 0.0038961]
	Learning Rate: 0.00389611
	LOSS [training: 0.1513153090836067 | validation: 0.22806499796486104]
	TIME [epoch: 9.09 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24756560043862877		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.24756560043862877 | validation: 0.22050431780407342]
	TIME [epoch: 9.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12173114972743906		[learning rate: 0.0038773]
	Learning Rate: 0.00387727
	LOSS [training: 0.12173114972743906 | validation: 0.08369065761542635]
	TIME [epoch: 9.09 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11302734888918312		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.11302734888918312 | validation: 0.11595327992566776]
	TIME [epoch: 9.09 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08005946687397325		[learning rate: 0.0038585]
	Learning Rate: 0.00385852
	LOSS [training: 0.08005946687397325 | validation: 0.1713034856849524]
	TIME [epoch: 9.08 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11595674765035394		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.11595674765035394 | validation: 0.06068263928525242]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09547758055592354		[learning rate: 0.0038399]
	Learning Rate: 0.00383986
	LOSS [training: 0.09547758055592354 | validation: 0.15771838184425538]
	TIME [epoch: 9.09 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17130718073383072		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.17130718073383072 | validation: 0.3083880076115604]
	TIME [epoch: 9.07 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18065562451760728		[learning rate: 0.0038213]
	Learning Rate: 0.00382129
	LOSS [training: 0.18065562451760728 | validation: 0.13541706348408714]
	TIME [epoch: 9.09 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11253661648895696		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.11253661648895696 | validation: 0.16135301221524237]
	TIME [epoch: 9.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15460647248422338		[learning rate: 0.0038028]
	Learning Rate: 0.00380282
	LOSS [training: 0.15460647248422338 | validation: 0.1832571414798699]
	TIME [epoch: 9.09 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13306838927802106		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.13306838927802106 | validation: 0.13477784959931222]
	TIME [epoch: 9.08 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08475229196887787		[learning rate: 0.0037844]
	Learning Rate: 0.00378443
	LOSS [training: 0.08475229196887787 | validation: 0.06996129588987529]
	TIME [epoch: 9.08 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16929545744608093		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.16929545744608093 | validation: 0.21924088255624868]
	TIME [epoch: 9.07 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26954772412566463		[learning rate: 0.0037661]
	Learning Rate: 0.00376613
	LOSS [training: 0.26954772412566463 | validation: 0.4189151799181091]
	TIME [epoch: 9.1 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4241246927531601		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.4241246927531601 | validation: 0.28721829238569097]
	TIME [epoch: 9.09 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40650219803700216		[learning rate: 0.0037479]
	Learning Rate: 0.00374791
	LOSS [training: 0.40650219803700216 | validation: 0.5331468714209654]
	TIME [epoch: 9.08 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23158874153449163		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.23158874153449163 | validation: 0.17084445643190735]
	TIME [epoch: 9.08 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12209937376288674		[learning rate: 0.0037298]
	Learning Rate: 0.00372979
	LOSS [training: 0.12209937376288674 | validation: 0.13423981172144406]
	TIME [epoch: 9.08 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14289182733887346		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.14289182733887346 | validation: 0.18545362845139313]
	TIME [epoch: 9.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11509923738887282		[learning rate: 0.0037118]
	Learning Rate: 0.00371175
	LOSS [training: 0.11509923738887282 | validation: 0.09753006102810155]
	TIME [epoch: 9.08 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2231990509942638		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.2231990509942638 | validation: 0.5918409031283091]
	TIME [epoch: 9.09 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24327747440247646		[learning rate: 0.0036938]
	Learning Rate: 0.0036938
	LOSS [training: 0.24327747440247646 | validation: 0.1106418208054975]
	TIME [epoch: 9.08 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2326925144327574		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.2326925144327574 | validation: 0.22525677224202362]
	TIME [epoch: 9.1 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20317368328174074		[learning rate: 0.0036759]
	Learning Rate: 0.00367594
	LOSS [training: 0.20317368328174074 | validation: 0.1088696432605446]
	TIME [epoch: 9.09 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1675821536190553		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.1675821536190553 | validation: 0.2613529541379304]
	TIME [epoch: 9.08 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2266784783329478		[learning rate: 0.0036582]
	Learning Rate: 0.00365816
	LOSS [training: 0.2266784783329478 | validation: 0.23709189582357082]
	TIME [epoch: 9.08 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19363631653402294		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.19363631653402294 | validation: 0.2022422051953408]
	TIME [epoch: 9.08 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21007038515084014		[learning rate: 0.0036405]
	Learning Rate: 0.00364047
	LOSS [training: 0.21007038515084014 | validation: 0.2399062694735916]
	TIME [epoch: 9.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1573758813398693		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.1573758813398693 | validation: 0.36708585520310844]
	TIME [epoch: 9.09 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15177412111472394		[learning rate: 0.0036229]
	Learning Rate: 0.00362287
	LOSS [training: 0.15177412111472394 | validation: 0.18638673380279647]
	TIME [epoch: 9.08 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11554686233391169		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.11554686233391169 | validation: 0.09411280933535757]
	TIME [epoch: 9.08 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0768526295475456		[learning rate: 0.0036053]
	Learning Rate: 0.00360535
	LOSS [training: 0.0768526295475456 | validation: 0.08928295519998419]
	TIME [epoch: 9.09 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10979317352337523		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.10979317352337523 | validation: 0.23838780424920303]
	TIME [epoch: 9.08 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2253802083768217		[learning rate: 0.0035879]
	Learning Rate: 0.00358791
	LOSS [training: 0.2253802083768217 | validation: 0.1217733161039205]
	TIME [epoch: 9.09 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10779074694570197		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.10779074694570197 | validation: 0.13144107581419334]
	TIME [epoch: 9.08 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16342747705463348		[learning rate: 0.0035706]
	Learning Rate: 0.00357056
	LOSS [training: 0.16342747705463348 | validation: 0.30033683014595225]
	TIME [epoch: 9.1 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14141492828608543		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.14141492828608543 | validation: 0.15412466024240695]
	TIME [epoch: 9.1 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14124821811457486		[learning rate: 0.0035533]
	Learning Rate: 0.0035533
	LOSS [training: 0.14124821811457486 | validation: 0.13132674955032425]
	TIME [epoch: 9.09 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08494535796979988		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.08494535796979988 | validation: 0.10898552572125031]
	TIME [epoch: 9.08 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07479300882669679		[learning rate: 0.0035361]
	Learning Rate: 0.00353611
	LOSS [training: 0.07479300882669679 | validation: 0.0835980572204762]
	TIME [epoch: 9.08 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08720636751967786		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.08720636751967786 | validation: 0.11489937411496913]
	TIME [epoch: 9.1 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09195665568254503		[learning rate: 0.003519]
	Learning Rate: 0.00351901
	LOSS [training: 0.09195665568254503 | validation: 0.1303531780447892]
	TIME [epoch: 9.11 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09084167422867433		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.09084167422867433 | validation: 0.1071748237149655]
	TIME [epoch: 9.07 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.136426170088887		[learning rate: 0.003502]
	Learning Rate: 0.003502
	LOSS [training: 0.136426170088887 | validation: 0.20842889193086236]
	TIME [epoch: 9.08 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11109541291509857		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.11109541291509857 | validation: 0.10158252454169864]
	TIME [epoch: 9.09 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13860945002896036		[learning rate: 0.0034851]
	Learning Rate: 0.00348506
	LOSS [training: 0.13860945002896036 | validation: 0.13117394561553525]
	TIME [epoch: 9.12 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.164211956204317		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.164211956204317 | validation: 0.3366830430587334]
	TIME [epoch: 9.1 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2744151141609744		[learning rate: 0.0034682]
	Learning Rate: 0.00346821
	LOSS [training: 0.2744151141609744 | validation: 0.1743982447559401]
	TIME [epoch: 9.09 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2564784879715471		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.2564784879715471 | validation: 0.25309590993512554]
	TIME [epoch: 9.09 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5965538186326058		[learning rate: 0.0034514]
	Learning Rate: 0.00345144
	LOSS [training: 0.5965538186326058 | validation: 0.6761998785501466]
	TIME [epoch: 9.09 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31893238251252226		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.31893238251252226 | validation: 0.2243661830941447]
	TIME [epoch: 9.11 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23331779541046563		[learning rate: 0.0034347]
	Learning Rate: 0.00343475
	LOSS [training: 0.23331779541046563 | validation: 0.09254131275103616]
	TIME [epoch: 9.09 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07106314658788318		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.07106314658788318 | validation: 0.18542314525885675]
	TIME [epoch: 9.08 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18189281648070812		[learning rate: 0.0034181]
	Learning Rate: 0.00341814
	LOSS [training: 0.18189281648070812 | validation: 0.12511847398168024]
	TIME [epoch: 9.09 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16558810343175476		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.16558810343175476 | validation: 0.15560627073010905]
	TIME [epoch: 9.11 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1336096305344761		[learning rate: 0.0034016]
	Learning Rate: 0.00340161
	LOSS [training: 0.1336096305344761 | validation: 0.11956375143430999]
	TIME [epoch: 9.09 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1013165430717253		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.1013165430717253 | validation: 0.0746756369659651]
	TIME [epoch: 9.09 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12740806998558837		[learning rate: 0.0033852]
	Learning Rate: 0.00338516
	LOSS [training: 0.12740806998558837 | validation: 0.09328755664589916]
	TIME [epoch: 9.08 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10226558775352332		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.10226558775352332 | validation: 0.10013012496456844]
	TIME [epoch: 9.09 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07707110170294709		[learning rate: 0.0033688]
	Learning Rate: 0.00336879
	LOSS [training: 0.07707110170294709 | validation: 0.18366498419575153]
	TIME [epoch: 9.11 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11088768499842298		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.11088768499842298 | validation: 0.14162399604695106]
	TIME [epoch: 9.1 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09742411855861915		[learning rate: 0.0033525]
	Learning Rate: 0.0033525
	LOSS [training: 0.09742411855861915 | validation: 0.0699812177497679]
	TIME [epoch: 9.1 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05085386534256188		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.05085386534256188 | validation: 0.11445686056092405]
	TIME [epoch: 9.09 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09054636261605493		[learning rate: 0.0033363]
	Learning Rate: 0.00333629
	LOSS [training: 0.09054636261605493 | validation: 0.08139486721425163]
	TIME [epoch: 9.1 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11462035064893854		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.11462035064893854 | validation: 0.08241281880779919]
	TIME [epoch: 9.09 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0948345725751594		[learning rate: 0.0033202]
	Learning Rate: 0.00332015
	LOSS [training: 0.0948345725751594 | validation: 0.14596203570927802]
	TIME [epoch: 9.08 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3594040430142257		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.3594040430142257 | validation: 0.28875530596611143]
	TIME [epoch: 9.09 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15830106614599343		[learning rate: 0.0033041]
	Learning Rate: 0.0033041
	LOSS [training: 0.15830106614599343 | validation: 0.0836985869991097]
	TIME [epoch: 9.09 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06890197221223289		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.06890197221223289 | validation: 0.08786895020471597]
	TIME [epoch: 9.12 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11564228567109971		[learning rate: 0.0032881]
	Learning Rate: 0.00328812
	LOSS [training: 0.11564228567109971 | validation: 0.10300879523615045]
	TIME [epoch: 9.09 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29401241731815564		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.29401241731815564 | validation: 0.5655075228796005]
	TIME [epoch: 9.08 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2113476731007331		[learning rate: 0.0032722]
	Learning Rate: 0.00327222
	LOSS [training: 0.2113476731007331 | validation: 0.10715400666322951]
	TIME [epoch: 9.09 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09973653122406034		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.09973653122406034 | validation: 0.11716691600236209]
	TIME [epoch: 9.1 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11230480717524653		[learning rate: 0.0032564]
	Learning Rate: 0.00325639
	LOSS [training: 0.11230480717524653 | validation: 0.11147553101005475]
	TIME [epoch: 9.1 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13660791012048165		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.13660791012048165 | validation: 0.11503875021301725]
	TIME [epoch: 9.1 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09961103009095332		[learning rate: 0.0032406]
	Learning Rate: 0.00324065
	LOSS [training: 0.09961103009095332 | validation: 0.11870510109482413]
	TIME [epoch: 9.08 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08044766716178967		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.08044766716178967 | validation: 0.04841028776779565]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_566.pth
	Model improved!!!
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09149156903290798		[learning rate: 0.003225]
	Learning Rate: 0.00322497
	LOSS [training: 0.09149156903290798 | validation: 0.17436756603906955]
	TIME [epoch: 9.1 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10881764061614221		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.10881764061614221 | validation: 0.07092736807878222]
	TIME [epoch: 9.09 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07153579250031043		[learning rate: 0.0032094]
	Learning Rate: 0.00320938
	LOSS [training: 0.07153579250031043 | validation: 0.04700603760975848]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_569.pth
	Model improved!!!
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06190120764884531		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.06190120764884531 | validation: 0.06056713083539052]
	TIME [epoch: 9.09 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07820947449131667		[learning rate: 0.0031939]
	Learning Rate: 0.00319386
	LOSS [training: 0.07820947449131667 | validation: 0.17148249002770716]
	TIME [epoch: 9.11 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10359072938558614		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.10359072938558614 | validation: 0.07010503537224338]
	TIME [epoch: 9.1 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09571969180853404		[learning rate: 0.0031784]
	Learning Rate: 0.00317841
	LOSS [training: 0.09571969180853404 | validation: 0.11427634806808812]
	TIME [epoch: 9.09 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07725153086558659		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.07725153086558659 | validation: 0.09298507487584134]
	TIME [epoch: 9.09 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09713611822786303		[learning rate: 0.003163]
	Learning Rate: 0.00316304
	LOSS [training: 0.09713611822786303 | validation: 0.12031680945052695]
	TIME [epoch: 9.09 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10478962693385126		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.10478962693385126 | validation: 0.06088830135394105]
	TIME [epoch: 9.11 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14100754624345052		[learning rate: 0.0031477]
	Learning Rate: 0.00314775
	LOSS [training: 0.14100754624345052 | validation: 0.1482351505163311]
	TIME [epoch: 9.1 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17830703141954754		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.17830703141954754 | validation: 0.0710305511834009]
	TIME [epoch: 9.08 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10292566928724786		[learning rate: 0.0031325]
	Learning Rate: 0.00313253
	LOSS [training: 0.10292566928724786 | validation: 0.07950800185702948]
	TIME [epoch: 9.09 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07180482020633445		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.07180482020633445 | validation: 0.10180436660585512]
	TIME [epoch: 9.09 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10335671237971249		[learning rate: 0.0031174]
	Learning Rate: 0.00311738
	LOSS [training: 0.10335671237971249 | validation: 0.06499281186759519]
	TIME [epoch: 9.11 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07671973819069522		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.07671973819069522 | validation: 0.07838123228122307]
	TIME [epoch: 9.09 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09218678295547458		[learning rate: 0.0031023]
	Learning Rate: 0.0031023
	LOSS [training: 0.09218678295547458 | validation: 0.0666401567665464]
	TIME [epoch: 9.1 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10539538157929915		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.10539538157929915 | validation: 0.10323318276267646]
	TIME [epoch: 9.09 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10590702998067322		[learning rate: 0.0030873]
	Learning Rate: 0.0030873
	LOSS [training: 0.10590702998067322 | validation: 0.15037493848074204]
	TIME [epoch: 9.11 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14337479752395368		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.14337479752395368 | validation: 0.14857801476259008]
	TIME [epoch: 9.11 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11360741071382092		[learning rate: 0.0030724]
	Learning Rate: 0.00307237
	LOSS [training: 0.11360741071382092 | validation: 0.08642089535684414]
	TIME [epoch: 9.09 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10733681740955003		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.10733681740955003 | validation: 0.12583702367529975]
	TIME [epoch: 9.1 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15901189907492902		[learning rate: 0.0030575]
	Learning Rate: 0.00305751
	LOSS [training: 0.15901189907492902 | validation: 0.0951421989474206]
	TIME [epoch: 9.1 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10849816353204216		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.10849816353204216 | validation: 0.0934319731080886]
	TIME [epoch: 9.12 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08618152602023413		[learning rate: 0.0030427]
	Learning Rate: 0.00304273
	LOSS [training: 0.08618152602023413 | validation: 0.167150941861218]
	TIME [epoch: 9.1 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11657351425809681		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.11657351425809681 | validation: 0.14586991722048598]
	TIME [epoch: 9.09 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09363545434594094		[learning rate: 0.003028]
	Learning Rate: 0.00302801
	LOSS [training: 0.09363545434594094 | validation: 0.11357166673147492]
	TIME [epoch: 9.09 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1078196903684691		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.1078196903684691 | validation: 0.09575875330227307]
	TIME [epoch: 9.11 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09015015486203479		[learning rate: 0.0030134]
	Learning Rate: 0.00301337
	LOSS [training: 0.09015015486203479 | validation: 0.10033867969287831]
	TIME [epoch: 9.09 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08142565462178547		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.08142565462178547 | validation: 0.1402356176812293]
	TIME [epoch: 9.09 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09751833674905855		[learning rate: 0.0029988]
	Learning Rate: 0.0029988
	LOSS [training: 0.09751833674905855 | validation: 0.071068897431126]
	TIME [epoch: 9.1 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09244506024707913		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.09244506024707913 | validation: 0.12172156655958247]
	TIME [epoch: 9.09 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12031145959560963		[learning rate: 0.0029843]
	Learning Rate: 0.0029843
	LOSS [training: 0.12031145959560963 | validation: 0.09127012937340229]
	TIME [epoch: 9.11 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12506554207395343		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.12506554207395343 | validation: 0.4012599428652712]
	TIME [epoch: 9.1 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1801957789571523		[learning rate: 0.0029699]
	Learning Rate: 0.00296987
	LOSS [training: 0.1801957789571523 | validation: 0.12290263245141198]
	TIME [epoch: 9.09 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15176201535477296		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.15176201535477296 | validation: 0.38815594013029475]
	TIME [epoch: 9.1 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18608867700315035		[learning rate: 0.0029555]
	Learning Rate: 0.0029555
	LOSS [training: 0.18608867700315035 | validation: 0.14152942709092273]
	TIME [epoch: 9.11 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0880494786171468		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.0880494786171468 | validation: 0.06796088733625213]
	TIME [epoch: 9.11 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07583672512293065		[learning rate: 0.0029412]
	Learning Rate: 0.00294121
	LOSS [training: 0.07583672512293065 | validation: 0.06664702002049783]
	TIME [epoch: 9.09 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06851853637824343		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.06851853637824343 | validation: 0.07284282399096893]
	TIME [epoch: 9.09 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09509579217559289		[learning rate: 0.002927]
	Learning Rate: 0.00292699
	LOSS [training: 0.09509579217559289 | validation: 0.10281378606065403]
	TIME [epoch: 9.09 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08221723074171086		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.08221723074171086 | validation: 0.055093612558020845]
	TIME [epoch: 9.11 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07500956059074702		[learning rate: 0.0029128]
	Learning Rate: 0.00291283
	LOSS [training: 0.07500956059074702 | validation: 0.1006955732652482]
	TIME [epoch: 9.09 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08624035804151813		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.08624035804151813 | validation: 0.10263979390204686]
	TIME [epoch: 9.09 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09792253684089516		[learning rate: 0.0028987]
	Learning Rate: 0.00289875
	LOSS [training: 0.09792253684089516 | validation: 0.09714866870774762]
	TIME [epoch: 9.08 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09388308328910235		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.09388308328910235 | validation: 0.12060857941442742]
	TIME [epoch: 9.09 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06167403998104533		[learning rate: 0.0028847]
	Learning Rate: 0.00288473
	LOSS [training: 0.06167403998104533 | validation: 0.047988191399980465]
	TIME [epoch: 9.11 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07544900871735795		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.07544900871735795 | validation: 0.061468605004418475]
	TIME [epoch: 9.09 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04828659586535504		[learning rate: 0.0028708]
	Learning Rate: 0.00287078
	LOSS [training: 0.04828659586535504 | validation: 0.09619810743725497]
	TIME [epoch: 9.1 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12674075305961802		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.12674075305961802 | validation: 0.11520087927114744]
	TIME [epoch: 9.1 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17487248454461965		[learning rate: 0.0028569]
	Learning Rate: 0.0028569
	LOSS [training: 0.17487248454461965 | validation: 0.27908748710647396]
	TIME [epoch: 9.12 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19665778493798877		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.19665778493798877 | validation: 0.0821939797958255]
	TIME [epoch: 9.1 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10331147448415734		[learning rate: 0.0028431]
	Learning Rate: 0.00284308
	LOSS [training: 0.10331147448415734 | validation: 0.11524670189324746]
	TIME [epoch: 9.09 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06819479243860739		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.06819479243860739 | validation: 0.09811954683862542]
	TIME [epoch: 9.09 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0907310147749111		[learning rate: 0.0028293]
	Learning Rate: 0.00282933
	LOSS [training: 0.0907310147749111 | validation: 0.05395654560959363]
	TIME [epoch: 9.09 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06511866010138692		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.06511866010138692 | validation: 0.0738681113890419]
	TIME [epoch: 9.11 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04974244772089015		[learning rate: 0.0028157]
	Learning Rate: 0.00281565
	LOSS [training: 0.04974244772089015 | validation: 0.05740260791573888]
	TIME [epoch: 9.1 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0587139126917389		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.0587139126917389 | validation: 0.07329811186493801]
	TIME [epoch: 9.08 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09461220629401337		[learning rate: 0.002802]
	Learning Rate: 0.00280204
	LOSS [training: 0.09461220629401337 | validation: 0.12751518708722714]
	TIME [epoch: 9.09 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09592491905085401		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.09592491905085401 | validation: 0.08084905180420315]
	TIME [epoch: 9.1 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1071567970969464		[learning rate: 0.0027885]
	Learning Rate: 0.00278849
	LOSS [training: 0.1071567970969464 | validation: 0.1013296106013594]
	TIME [epoch: 9.09 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1512874209280164		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.1512874209280164 | validation: 0.08589360164777465]
	TIME [epoch: 9.09 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13530577483679984		[learning rate: 0.002775]
	Learning Rate: 0.002775
	LOSS [training: 0.13530577483679984 | validation: 0.30423945746462544]
	TIME [epoch: 9.09 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6144466572712108		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.6144466572712108 | validation: 0.9446740204896987]
	TIME [epoch: 9.1 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6004103949701767		[learning rate: 0.0027616]
	Learning Rate: 0.00276158
	LOSS [training: 0.6004103949701767 | validation: 0.24880507638505478]
	TIME [epoch: 9.11 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16474821998815378		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.16474821998815378 | validation: 0.10411534651435923]
	TIME [epoch: 9.1 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.102852569714276		[learning rate: 0.0027482]
	Learning Rate: 0.00274823
	LOSS [training: 0.102852569714276 | validation: 0.13553293378947417]
	TIME [epoch: 9.09 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1949350435557196		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.1949350435557196 | validation: 0.1244565072863329]
	TIME [epoch: 9.09 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13519106847731874		[learning rate: 0.0027349]
	Learning Rate: 0.00273494
	LOSS [training: 0.13519106847731874 | validation: 0.14158175793320707]
	TIME [epoch: 9.1 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10296319973048466		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.10296319973048466 | validation: 0.05640918731504473]
	TIME [epoch: 9.09 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07641387619778331		[learning rate: 0.0027217]
	Learning Rate: 0.00272171
	LOSS [training: 0.07641387619778331 | validation: 0.16056338201434858]
	TIME [epoch: 9.09 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17171806432305275		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.17171806432305275 | validation: 0.2929789876445712]
	TIME [epoch: 9.09 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21904031951142908		[learning rate: 0.0027086]
	Learning Rate: 0.00270855
	LOSS [training: 0.21904031951142908 | validation: 0.23703719854705266]
	TIME [epoch: 9.09 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12900980977963367		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.12900980977963367 | validation: 0.10332098660913763]
	TIME [epoch: 9.11 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08272588546630397		[learning rate: 0.0026955]
	Learning Rate: 0.00269545
	LOSS [training: 0.08272588546630397 | validation: 0.11372842120567594]
	TIME [epoch: 9.1 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07316795784997054		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.07316795784997054 | validation: 0.0782836929209563]
	TIME [epoch: 9.09 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0940650473661209		[learning rate: 0.0026824]
	Learning Rate: 0.00268242
	LOSS [training: 0.0940650473661209 | validation: 0.1520037016339376]
	TIME [epoch: 9.09 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07467114334095411		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.07467114334095411 | validation: 0.08600051494987611]
	TIME [epoch: 9.1 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0859673569405683		[learning rate: 0.0026694]
	Learning Rate: 0.00266945
	LOSS [training: 0.0859673569405683 | validation: 0.11414878114497325]
	TIME [epoch: 9.1 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07634484923310704		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.07634484923310704 | validation: 0.07248240048227796]
	TIME [epoch: 9.09 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08941183292846823		[learning rate: 0.0026565]
	Learning Rate: 0.00265654
	LOSS [training: 0.08941183292846823 | validation: 0.056875473907320194]
	TIME [epoch: 9.09 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0779716360596335		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.0779716360596335 | validation: 0.037315246270208824]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_648.pth
	Model improved!!!
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05268774204001325		[learning rate: 0.0026437]
	Learning Rate: 0.00264369
	LOSS [training: 0.05268774204001325 | validation: 0.10068784939889217]
	TIME [epoch: 9.1 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07630105797721122		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.07630105797721122 | validation: 0.0776617946357768]
	TIME [epoch: 9.09 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06132713313681124		[learning rate: 0.0026309]
	Learning Rate: 0.00263091
	LOSS [training: 0.06132713313681124 | validation: 0.06463707084874301]
	TIME [epoch: 9.08 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04495771983301649		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.04495771983301649 | validation: 0.05274996023779321]
	TIME [epoch: 9.08 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0496091712018937		[learning rate: 0.0026182]
	Learning Rate: 0.00261818
	LOSS [training: 0.0496091712018937 | validation: 0.06712549535606839]
	TIME [epoch: 9.08 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06360062818620511		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.06360062818620511 | validation: 0.07257856519791836]
	TIME [epoch: 9.1 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05643546147638737		[learning rate: 0.0026055]
	Learning Rate: 0.00260552
	LOSS [training: 0.05643546147638737 | validation: 0.08563134388748074]
	TIME [epoch: 9.09 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045835558893119334		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.045835558893119334 | validation: 0.07465882807446994]
	TIME [epoch: 9.09 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07104892967750716		[learning rate: 0.0025929]
	Learning Rate: 0.00259292
	LOSS [training: 0.07104892967750716 | validation: 0.07785565746166032]
	TIME [epoch: 9.08 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0777730497033707		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.0777730497033707 | validation: 0.08908776100221044]
	TIME [epoch: 9.11 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07348496870277736		[learning rate: 0.0025804]
	Learning Rate: 0.00258038
	LOSS [training: 0.07348496870277736 | validation: 0.08282973649097894]
	TIME [epoch: 9.08 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05312313544792617		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.05312313544792617 | validation: 0.06303731626176902]
	TIME [epoch: 9.09 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04965621241145333		[learning rate: 0.0025679]
	Learning Rate: 0.0025679
	LOSS [training: 0.04965621241145333 | validation: 0.0636804177708816]
	TIME [epoch: 9.09 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06139162725379889		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.06139162725379889 | validation: 0.06458439881152311]
	TIME [epoch: 9.08 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07205686519114775		[learning rate: 0.0025555]
	Learning Rate: 0.00255549
	LOSS [training: 0.07205686519114775 | validation: 0.0907989091153309]
	TIME [epoch: 9.11 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0863421943059152		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.0863421943059152 | validation: 0.1689633494054641]
	TIME [epoch: 9.08 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11157538553608437		[learning rate: 0.0025431]
	Learning Rate: 0.00254313
	LOSS [training: 0.11157538553608437 | validation: 0.10986168899321494]
	TIME [epoch: 9.08 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11365418646614493		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.11365418646614493 | validation: 0.1243233035849658]
	TIME [epoch: 9.09 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08701412526210428		[learning rate: 0.0025308]
	Learning Rate: 0.00253083
	LOSS [training: 0.08701412526210428 | validation: 0.10414766682527554]
	TIME [epoch: 9.1 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08634923804372185		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.08634923804372185 | validation: 0.11182966491230609]
	TIME [epoch: 9.11 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06777489377889727		[learning rate: 0.0025186]
	Learning Rate: 0.00251859
	LOSS [training: 0.06777489377889727 | validation: 0.05265133980915536]
	TIME [epoch: 9.1 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05430659719343578		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.05430659719343578 | validation: 0.06562755638671255]
	TIME [epoch: 9.09 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053925317923044794		[learning rate: 0.0025064]
	Learning Rate: 0.00250641
	LOSS [training: 0.053925317923044794 | validation: 0.07157521530589706]
	TIME [epoch: 9.08 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04932726378858936		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.04932726378858936 | validation: 0.11150730705745962]
	TIME [epoch: 9.1 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07540446029225711		[learning rate: 0.0024943]
	Learning Rate: 0.00249429
	LOSS [training: 0.07540446029225711 | validation: 0.05313592761304764]
	TIME [epoch: 9.09 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06267172357543255		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.06267172357543255 | validation: 0.0932094734570088]
	TIME [epoch: 9.09 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050908398694446966		[learning rate: 0.0024822]
	Learning Rate: 0.00248223
	LOSS [training: 0.050908398694446966 | validation: 0.04694503700534139]
	TIME [epoch: 9.09 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05918012074025316		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.05918012074025316 | validation: 0.06125325439893255]
	TIME [epoch: 9.1 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06842440329175765		[learning rate: 0.0024702]
	Learning Rate: 0.00247023
	LOSS [training: 0.06842440329175765 | validation: 0.11339888215108401]
	TIME [epoch: 9.1 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12716573409331802		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.12716573409331802 | validation: 0.07209399612229477]
	TIME [epoch: 9.09 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07064537262260791		[learning rate: 0.0024583]
	Learning Rate: 0.00245828
	LOSS [training: 0.07064537262260791 | validation: 0.047272202018213014]
	TIME [epoch: 9.09 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07043595323835752		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.07043595323835752 | validation: 0.059314830706048934]
	TIME [epoch: 9.08 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08195599093715808		[learning rate: 0.0024464]
	Learning Rate: 0.00244639
	LOSS [training: 0.08195599093715808 | validation: 0.1530527573960594]
	TIME [epoch: 9.12 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09189212636573006		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.09189212636573006 | validation: 0.09574339156729023]
	TIME [epoch: 9.1 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10237617018674598		[learning rate: 0.0024346]
	Learning Rate: 0.00243456
	LOSS [training: 0.10237617018674598 | validation: 0.07754609697876164]
	TIME [epoch: 9.09 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06767295898524828		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.06767295898524828 | validation: 0.058485809748988364]
	TIME [epoch: 9.09 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09392290250743993		[learning rate: 0.0024228]
	Learning Rate: 0.00242279
	LOSS [training: 0.09392290250743993 | validation: 0.12210543532786153]
	TIME [epoch: 9.09 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11306146036672131		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.11306146036672131 | validation: 0.2632357216567831]
	TIME [epoch: 9.11 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3224966999072229		[learning rate: 0.0024111]
	Learning Rate: 0.00241107
	LOSS [training: 0.3224966999072229 | validation: 0.11843143455446964]
	TIME [epoch: 9.09 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11071237257768127		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.11071237257768127 | validation: 0.11321808055867438]
	TIME [epoch: 9.1 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1752179270114997		[learning rate: 0.0023994]
	Learning Rate: 0.00239941
	LOSS [training: 0.1752179270114997 | validation: 0.07539313917813564]
	TIME [epoch: 9.09 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10734704473763852		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.10734704473763852 | validation: 0.08475166644702964]
	TIME [epoch: 9.11 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1504521059318774		[learning rate: 0.0023878]
	Learning Rate: 0.00238781
	LOSS [training: 0.1504521059318774 | validation: 0.4766242595882347]
	TIME [epoch: 9.1 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2811471344481985		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.2811471344481985 | validation: 0.16238194688102697]
	TIME [epoch: 9.09 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20066572307201622		[learning rate: 0.0023763]
	Learning Rate: 0.00237626
	LOSS [training: 0.20066572307201622 | validation: 0.253938621591265]
	TIME [epoch: 9.09 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21452926706340722		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.21452926706340722 | validation: 0.16565850342097727]
	TIME [epoch: 9.09 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14492924899652543		[learning rate: 0.0023648]
	Learning Rate: 0.00236477
	LOSS [training: 0.14492924899652543 | validation: 0.15006979953874164]
	TIME [epoch: 9.11 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12381530738403798		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.12381530738403798 | validation: 0.10038837360161904]
	TIME [epoch: 9.09 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11504000375391348		[learning rate: 0.0023533]
	Learning Rate: 0.00235334
	LOSS [training: 0.11504000375391348 | validation: 0.26484032602622193]
	TIME [epoch: 9.08 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4573616747106707		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.4573616747106707 | validation: 0.43486496360268434]
	TIME [epoch: 9.09 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22769124377987354		[learning rate: 0.002342]
	Learning Rate: 0.00234196
	LOSS [training: 0.22769124377987354 | validation: 0.10342333433517092]
	TIME [epoch: 9.1 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13239195132951456		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.13239195132951456 | validation: 0.1529128135755859]
	TIME [epoch: 9.09 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3248434812421753		[learning rate: 0.0023306]
	Learning Rate: 0.00233063
	LOSS [training: 0.3248434812421753 | validation: 0.5009990758204617]
	TIME [epoch: 9.09 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.356747948140708		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.356747948140708 | validation: 0.20626528942137312]
	TIME [epoch: 9.09 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27796198340524014		[learning rate: 0.0023194]
	Learning Rate: 0.00231936
	LOSS [training: 0.27796198340524014 | validation: 0.25258268512234633]
	TIME [epoch: 9.09 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15013517813550026		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.15013517813550026 | validation: 0.1134028065121512]
	TIME [epoch: 9.11 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08007395881188013		[learning rate: 0.0023081]
	Learning Rate: 0.00230815
	LOSS [training: 0.08007395881188013 | validation: 0.07584213506212795]
	TIME [epoch: 9.09 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06905427262633382		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.06905427262633382 | validation: 0.055792776653727325]
	TIME [epoch: 9.09 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08370545756022008		[learning rate: 0.002297]
	Learning Rate: 0.00229698
	LOSS [training: 0.08370545756022008 | validation: 0.06501037130813894]
	TIME [epoch: 9.09 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06776308804413769		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.06776308804413769 | validation: 0.10301246641628448]
	TIME [epoch: 9.12 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06401417070382624		[learning rate: 0.0022859]
	Learning Rate: 0.00228588
	LOSS [training: 0.06401417070382624 | validation: 0.06779808506755264]
	TIME [epoch: 9.1 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0605876491478863		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.0605876491478863 | validation: 0.06586207664670377]
	TIME [epoch: 9.09 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06901518808326487		[learning rate: 0.0022748]
	Learning Rate: 0.00227482
	LOSS [training: 0.06901518808326487 | validation: 0.09459116204968332]
	TIME [epoch: 9.08 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06617825747114206		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.06617825747114206 | validation: 0.070056619475492]
	TIME [epoch: 9.09 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05906332540016377		[learning rate: 0.0022638]
	Learning Rate: 0.00226382
	LOSS [training: 0.05906332540016377 | validation: 0.09759691657716005]
	TIME [epoch: 9.11 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07722816428629779		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.07722816428629779 | validation: 0.061839935050841253]
	TIME [epoch: 9.09 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07993369262385808		[learning rate: 0.0022529]
	Learning Rate: 0.00225287
	LOSS [training: 0.07993369262385808 | validation: 0.09556812207902134]
	TIME [epoch: 9.09 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06693466478729887		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.06693466478729887 | validation: 0.03059116384208669]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_716.pth
	Model improved!!!
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0598264756002159		[learning rate: 0.002242]
	Learning Rate: 0.00224198
	LOSS [training: 0.0598264756002159 | validation: 0.05308741198442265]
	TIME [epoch: 9.1 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045493866836737874		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.045493866836737874 | validation: 0.06310942788055232]
	TIME [epoch: 9.09 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04326832723842207		[learning rate: 0.0022311]
	Learning Rate: 0.00223114
	LOSS [training: 0.04326832723842207 | validation: 0.05433572613187766]
	TIME [epoch: 9.09 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06091866130476431		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.06091866130476431 | validation: 0.04137097846648767]
	TIME [epoch: 9.09 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07650194274092344		[learning rate: 0.0022203]
	Learning Rate: 0.00222035
	LOSS [training: 0.07650194274092344 | validation: 0.08042147199917585]
	TIME [epoch: 9.08 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06453156397159213		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.06453156397159213 | validation: 0.04333879068168829]
	TIME [epoch: 9.11 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04670835730308369		[learning rate: 0.0022096]
	Learning Rate: 0.00220961
	LOSS [training: 0.04670835730308369 | validation: 0.049064848240932525]
	TIME [epoch: 9.08 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04445170519134492		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.04445170519134492 | validation: 0.06602002855964212]
	TIME [epoch: 9.08 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08917509119108871		[learning rate: 0.0021989]
	Learning Rate: 0.00219893
	LOSS [training: 0.08917509119108871 | validation: 0.09964718503649012]
	TIME [epoch: 9.08 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08274420254385428		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.08274420254385428 | validation: 0.08714210920566608]
	TIME [epoch: 9.08 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0713411384101865		[learning rate: 0.0021883]
	Learning Rate: 0.00218829
	LOSS [training: 0.0713411384101865 | validation: 0.1019465737471413]
	TIME [epoch: 9.1 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18996407186172232		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.18996407186172232 | validation: 0.2750804637341512]
	TIME [epoch: 9.08 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11890983654242923		[learning rate: 0.0021777]
	Learning Rate: 0.00217771
	LOSS [training: 0.11890983654242923 | validation: 0.09081554391092014]
	TIME [epoch: 9.08 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07633452261225088		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.07633452261225088 | validation: 0.15454934746717272]
	TIME [epoch: 9.08 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08345504970111126		[learning rate: 0.0021672]
	Learning Rate: 0.00216718
	LOSS [training: 0.08345504970111126 | validation: 0.09802699693823932]
	TIME [epoch: 9.1 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11372099325180525		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.11372099325180525 | validation: 0.10579139038232524]
	TIME [epoch: 9.09 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10187561792547253		[learning rate: 0.0021567]
	Learning Rate: 0.0021567
	LOSS [training: 0.10187561792547253 | validation: 0.15213864812420153]
	TIME [epoch: 9.09 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13037416009853672		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.13037416009853672 | validation: 0.14003110922085893]
	TIME [epoch: 9.09 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07517831877450307		[learning rate: 0.0021463]
	Learning Rate: 0.00214627
	LOSS [training: 0.07517831877450307 | validation: 0.07533409304417625]
	TIME [epoch: 9.09 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10591446663643292		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.10591446663643292 | validation: 0.19192813823755359]
	TIME [epoch: 9.1 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22212873227647933		[learning rate: 0.0021359]
	Learning Rate: 0.00213589
	LOSS [training: 0.22212873227647933 | validation: 0.12207613247899497]
	TIME [epoch: 9.09 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08569112239885951		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.08569112239885951 | validation: 0.06840173214718367]
	TIME [epoch: 9.08 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09376449730466026		[learning rate: 0.0021256]
	Learning Rate: 0.00212556
	LOSS [training: 0.09376449730466026 | validation: 0.0976850453176733]
	TIME [epoch: 9.09 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09496096791425243		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.09496096791425243 | validation: 0.11917042126344499]
	TIME [epoch: 9.1 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07521840503932646		[learning rate: 0.0021153]
	Learning Rate: 0.00211528
	LOSS [training: 0.07521840503932646 | validation: 0.06405510841082203]
	TIME [epoch: 9.09 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04699651967589813		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.04699651967589813 | validation: 0.032215600111592455]
	TIME [epoch: 9.09 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03171812159848166		[learning rate: 0.0021051]
	Learning Rate: 0.00210505
	LOSS [training: 0.03171812159848166 | validation: 0.07928354775355809]
	TIME [epoch: 9.08 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1161245496640118		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.1161245496640118 | validation: 0.27177283851094125]
	TIME [epoch: 9.07 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3128230340384697		[learning rate: 0.0020949]
	Learning Rate: 0.00209487
	LOSS [training: 0.3128230340384697 | validation: 0.27484614834059207]
	TIME [epoch: 9.1 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2022629334472578		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.2022629334472578 | validation: 0.14297967246374474]
	TIME [epoch: 9.08 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1764719403949632		[learning rate: 0.0020847]
	Learning Rate: 0.00208474
	LOSS [training: 0.1764719403949632 | validation: 0.1592728682570088]
	TIME [epoch: 9.09 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12998933524624823		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.12998933524624823 | validation: 0.17629597640048864]
	TIME [epoch: 9.09 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08933361111326169		[learning rate: 0.0020747]
	Learning Rate: 0.00207466
	LOSS [training: 0.08933361111326169 | validation: 0.07916824214351169]
	TIME [epoch: 9.11 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05427905536836377		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.05427905536836377 | validation: 0.11384477993798256]
	TIME [epoch: 9.09 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10051301619670942		[learning rate: 0.0020646]
	Learning Rate: 0.00206463
	LOSS [training: 0.10051301619670942 | validation: 0.2994284550195231]
	TIME [epoch: 9.08 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2641576733115018		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.2641576733115018 | validation: 0.1637535756406647]
	TIME [epoch: 9.08 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08723739382299686		[learning rate: 0.0020546]
	Learning Rate: 0.00205465
	LOSS [training: 0.08723739382299686 | validation: 0.07183932778721308]
	TIME [epoch: 9.08 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06489213711750108		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.06489213711750108 | validation: 0.03746341636194182]
	TIME [epoch: 9.1 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03500831423464735		[learning rate: 0.0020447]
	Learning Rate: 0.00204471
	LOSS [training: 0.03500831423464735 | validation: 0.04091815926639695]
	TIME [epoch: 9.09 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06105444860572097		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.06105444860572097 | validation: 0.049030381476184035]
	TIME [epoch: 9.08 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022143477489871853		[learning rate: 0.0020348]
	Learning Rate: 0.00203482
	LOSS [training: 0.022143477489871853 | validation: 0.0254386026276004]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_757.pth
	Model improved!!!
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07374168711746618		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.07374168711746618 | validation: 0.08753950067307661]
	TIME [epoch: 9.1 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030522332977102294		[learning rate: 0.002025]
	Learning Rate: 0.00202498
	LOSS [training: 0.030522332977102294 | validation: 0.06281136959050225]
	TIME [epoch: 9.09 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07746750514890396		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.07746750514890396 | validation: 0.07882068318924434]
	TIME [epoch: 9.09 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10871191855348968		[learning rate: 0.0020152]
	Learning Rate: 0.00201519
	LOSS [training: 0.10871191855348968 | validation: 0.13218844096642196]
	TIME [epoch: 9.08 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07796467733890257		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.07796467733890257 | validation: 0.08118447783819975]
	TIME [epoch: 9.08 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06204074089097901		[learning rate: 0.0020054]
	Learning Rate: 0.00200544
	LOSS [training: 0.06204074089097901 | validation: 0.09794256912181576]
	TIME [epoch: 9.09 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10817703821087021		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.10817703821087021 | validation: 0.08872215312465322]
	TIME [epoch: 9.08 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07052117301029229		[learning rate: 0.0019957]
	Learning Rate: 0.00199575
	LOSS [training: 0.07052117301029229 | validation: 0.11661603558834799]
	TIME [epoch: 9.08 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09343441211708967		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.09343441211708967 | validation: 0.06728741863733056]
	TIME [epoch: 9.08 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055786427441404364		[learning rate: 0.0019861]
	Learning Rate: 0.00198609
	LOSS [training: 0.055786427441404364 | validation: 0.07922763963343563]
	TIME [epoch: 9.08 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05852009730910625		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.05852009730910625 | validation: 0.04836580725532834]
	TIME [epoch: 9.1 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06163103593744525		[learning rate: 0.0019765]
	Learning Rate: 0.00197649
	LOSS [training: 0.06163103593744525 | validation: 0.06856677733198976]
	TIME [epoch: 9.08 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0540518679871481		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.0540518679871481 | validation: 0.09507638627025411]
	TIME [epoch: 9.08 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054650187573622444		[learning rate: 0.0019669]
	Learning Rate: 0.00196693
	LOSS [training: 0.054650187573622444 | validation: 0.10013243005904324]
	TIME [epoch: 9.08 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05984658056989671		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.05984658056989671 | validation: 0.05515605557552015]
	TIME [epoch: 9.1 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0800612992186027		[learning rate: 0.0019574]
	Learning Rate: 0.00195742
	LOSS [training: 0.0800612992186027 | validation: 0.15573030118025522]
	TIME [epoch: 9.1 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08577386491747761		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.08577386491747761 | validation: 0.16519280826989763]
	TIME [epoch: 9.08 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11329251179559245		[learning rate: 0.001948]
	Learning Rate: 0.00194796
	LOSS [training: 0.11329251179559245 | validation: 0.12989886439743417]
	TIME [epoch: 9.08 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07426879583603384		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.07426879583603384 | validation: 0.08440998301561253]
	TIME [epoch: 9.08 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08593033653387303		[learning rate: 0.0019385]
	Learning Rate: 0.00193854
	LOSS [training: 0.08593033653387303 | validation: 0.06907930881606865]
	TIME [epoch: 9.1 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06404777252287017		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.06404777252287017 | validation: 0.0705757529540334]
	TIME [epoch: 9.09 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04667555878250034		[learning rate: 0.0019292]
	Learning Rate: 0.00192916
	LOSS [training: 0.04667555878250034 | validation: 0.07413855616507418]
	TIME [epoch: 9.08 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04475077446950959		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.04475077446950959 | validation: 0.07526077366552449]
	TIME [epoch: 9.08 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05154192025026416		[learning rate: 0.0019198]
	Learning Rate: 0.00191983
	LOSS [training: 0.05154192025026416 | validation: 0.04506323880309854]
	TIME [epoch: 9.1 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04677442440323241		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.04677442440323241 | validation: 0.059222164619411474]
	TIME [epoch: 9.08 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043716189274625235		[learning rate: 0.0019105]
	Learning Rate: 0.00191055
	LOSS [training: 0.043716189274625235 | validation: 0.07449789867680015]
	TIME [epoch: 9.08 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10378607980421195		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.10378607980421195 | validation: 0.04770359600356239]
	TIME [epoch: 9.08 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060487511037478146		[learning rate: 0.0019013]
	Learning Rate: 0.00190131
	LOSS [training: 0.060487511037478146 | validation: 0.07431486721073748]
	TIME [epoch: 9.08 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06418573994203977		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.06418573994203977 | validation: 0.04261912273853055]
	TIME [epoch: 9.11 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039071567635390284		[learning rate: 0.0018921]
	Learning Rate: 0.00189211
	LOSS [training: 0.039071567635390284 | validation: 0.043645115493651646]
	TIME [epoch: 9.09 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05992188256775359		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.05992188256775359 | validation: 0.09057072470936421]
	TIME [epoch: 9.09 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07007215900625316		[learning rate: 0.001883]
	Learning Rate: 0.00188296
	LOSS [training: 0.07007215900625316 | validation: 0.10452880623086694]
	TIME [epoch: 9.08 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08862011636964615		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.08862011636964615 | validation: 0.10951656219082101]
	TIME [epoch: 9.09 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06402658164440145		[learning rate: 0.0018739]
	Learning Rate: 0.00187386
	LOSS [training: 0.06402658164440145 | validation: 0.07885175606789216]
	TIME [epoch: 9.09 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04868015917435466		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.04868015917435466 | validation: 0.04994079821603672]
	TIME [epoch: 9.07 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03680535574059615		[learning rate: 0.0018648]
	Learning Rate: 0.0018648
	LOSS [training: 0.03680535574059615 | validation: 0.032115738005476804]
	TIME [epoch: 9.08 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04097402767806295		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.04097402767806295 | validation: 0.0931669521258339]
	TIME [epoch: 9.08 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13162603349632554		[learning rate: 0.0018558]
	Learning Rate: 0.00185578
	LOSS [training: 0.13162603349632554 | validation: 0.11161957826248833]
	TIME [epoch: 9.11 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07349867296538798		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.07349867296538798 | validation: 0.057623754230097884]
	TIME [epoch: 9.09 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03896281188147524		[learning rate: 0.0018468]
	Learning Rate: 0.0018468
	LOSS [training: 0.03896281188147524 | validation: 0.06837729638372778]
	TIME [epoch: 9.08 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08860122473491512		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.08860122473491512 | validation: 0.044642129709087125]
	TIME [epoch: 9.08 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030751066971095514		[learning rate: 0.0018379]
	Learning Rate: 0.00183787
	LOSS [training: 0.030751066971095514 | validation: 0.046753465361034856]
	TIME [epoch: 9.09 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051704846790894744		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.051704846790894744 | validation: 0.05796954618342581]
	TIME [epoch: 9.1 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0646505018993914		[learning rate: 0.001829]
	Learning Rate: 0.00182899
	LOSS [training: 0.0646505018993914 | validation: 0.06372230658672978]
	TIME [epoch: 9.09 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11109166153285792		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.11109166153285792 | validation: 0.1374677307987789]
	TIME [epoch: 9.08 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07359954925553139		[learning rate: 0.0018201]
	Learning Rate: 0.00182014
	LOSS [training: 0.07359954925553139 | validation: 0.04830540747926333]
	TIME [epoch: 9.08 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06436114860087819		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.06436114860087819 | validation: 0.05822815061182933]
	TIME [epoch: 9.1 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0436849380915888		[learning rate: 0.0018113]
	Learning Rate: 0.00181134
	LOSS [training: 0.0436849380915888 | validation: 0.03718651071096819]
	TIME [epoch: 9.08 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03591085104714365		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.03591085104714365 | validation: 0.04715057463247259]
	TIME [epoch: 9.08 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06613393593160308		[learning rate: 0.0018026]
	Learning Rate: 0.00180258
	LOSS [training: 0.06613393593160308 | validation: 0.052037453160388464]
	TIME [epoch: 9.08 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04449073535410825		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.04449073535410825 | validation: 0.03425638188710387]
	TIME [epoch: 9.08 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02885890962038546		[learning rate: 0.0017939]
	Learning Rate: 0.00179386
	LOSS [training: 0.02885890962038546 | validation: 0.037571976991471745]
	TIME [epoch: 9.09 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08940483492360572		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.08940483492360572 | validation: 0.10105677112534325]
	TIME [epoch: 9.08 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16561734217364918		[learning rate: 0.0017852]
	Learning Rate: 0.00178519
	LOSS [training: 0.16561734217364918 | validation: 0.15332942580593995]
	TIME [epoch: 9.08 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0798878230930891		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.0798878230930891 | validation: 0.07143957490691008]
	TIME [epoch: 9.08 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034804706181518666		[learning rate: 0.0017766]
	Learning Rate: 0.00177656
	LOSS [training: 0.034804706181518666 | validation: 0.08025217335481816]
	TIME [epoch: 9.11 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07898851892183915		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.07898851892183915 | validation: 0.05547601115699931]
	TIME [epoch: 9.09 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07094795200362268		[learning rate: 0.001768]
	Learning Rate: 0.00176797
	LOSS [training: 0.07094795200362268 | validation: 0.03991220415317734]
	TIME [epoch: 9.08 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03971497176506009		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.03971497176506009 | validation: 0.07300319046110251]
	TIME [epoch: 9.08 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0499158832010454		[learning rate: 0.0017594]
	Learning Rate: 0.00175942
	LOSS [training: 0.0499158832010454 | validation: 0.0421021991253695]
	TIME [epoch: 9.08 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05223364916166151		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.05223364916166151 | validation: 0.0856700996926305]
	TIME [epoch: 9.1 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06079940905757893		[learning rate: 0.0017509]
	Learning Rate: 0.00175091
	LOSS [training: 0.06079940905757893 | validation: 0.026217506876084894]
	TIME [epoch: 9.08 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06601069783707043		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.06601069783707043 | validation: 0.04704861066155583]
	TIME [epoch: 9.08 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03923256636140979		[learning rate: 0.0017424]
	Learning Rate: 0.00174244
	LOSS [training: 0.03923256636140979 | validation: 0.05662378824404653]
	TIME [epoch: 9.08 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08033442197218442		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.08033442197218442 | validation: 0.10651020776178675]
	TIME [epoch: 9.09 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07059320634499464		[learning rate: 0.001734]
	Learning Rate: 0.00173401
	LOSS [training: 0.07059320634499464 | validation: 0.04341939482316329]
	TIME [epoch: 9.08 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03465740819517222		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.03465740819517222 | validation: 0.02892539396960215]
	TIME [epoch: 9.09 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043706713609538414		[learning rate: 0.0017256]
	Learning Rate: 0.00172563
	LOSS [training: 0.043706713609538414 | validation: 0.03004565431479062]
	TIME [epoch: 9.08 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02593647567543652		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.02593647567543652 | validation: 0.0342954438250152]
	TIME [epoch: 9.09 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06194886683167955		[learning rate: 0.0017173]
	Learning Rate: 0.00171728
	LOSS [training: 0.06194886683167955 | validation: 0.07146745121096745]
	TIME [epoch: 9.11 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052929979972535735		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.052929979972535735 | validation: 0.05708054223372519]
	TIME [epoch: 9.08 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04977484521363833		[learning rate: 0.001709]
	Learning Rate: 0.00170898
	LOSS [training: 0.04977484521363833 | validation: 0.08850054472331831]
	TIME [epoch: 9.08 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06410139808372228		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.06410139808372228 | validation: 0.07400800358704984]
	TIME [epoch: 9.08 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050626464099176136		[learning rate: 0.0017007]
	Learning Rate: 0.00170072
	LOSS [training: 0.050626464099176136 | validation: 0.05830627800933204]
	TIME [epoch: 9.08 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05360557919234288		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.05360557919234288 | validation: 0.05421921703440713]
	TIME [epoch: 9.09 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02827621288663672		[learning rate: 0.0016925]
	Learning Rate: 0.00169249
	LOSS [training: 0.02827621288663672 | validation: 0.02837301098843093]
	TIME [epoch: 9.08 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03548978826379102		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.03548978826379102 | validation: 0.05101071719416368]
	TIME [epoch: 9.08 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058568537451028205		[learning rate: 0.0016843]
	Learning Rate: 0.00168431
	LOSS [training: 0.058568537451028205 | validation: 0.11570330278731741]
	TIME [epoch: 9.08 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05764873696344226		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.05764873696344226 | validation: 0.04739922385435387]
	TIME [epoch: 9.1 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03659084072133641		[learning rate: 0.0016762]
	Learning Rate: 0.00167616
	LOSS [training: 0.03659084072133641 | validation: 0.03441620383363403]
	TIME [epoch: 9.08 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03621208761814356		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.03621208761814356 | validation: 0.06506096576521704]
	TIME [epoch: 9.07 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047925049873438194		[learning rate: 0.0016681]
	Learning Rate: 0.00166806
	LOSS [training: 0.047925049873438194 | validation: 0.038471514765664155]
	TIME [epoch: 9.08 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02812422728175635		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.02812422728175635 | validation: 0.02401288020959875]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_840.pth
	Model improved!!!
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02733482578739142		[learning rate: 0.00166]
	Learning Rate: 0.00165999
	LOSS [training: 0.02733482578739142 | validation: 0.06550670019176362]
	TIME [epoch: 9.1 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027800965433554738		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.027800965433554738 | validation: 0.11684008492376252]
	TIME [epoch: 9.08 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06973825839175878		[learning rate: 0.001652]
	Learning Rate: 0.00165196
	LOSS [training: 0.06973825839175878 | validation: 0.04757511082613146]
	TIME [epoch: 9.07 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058694549175583956		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.058694549175583956 | validation: 0.055798207238211106]
	TIME [epoch: 9.07 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04344807597305757		[learning rate: 0.001644]
	Learning Rate: 0.00164397
	LOSS [training: 0.04344807597305757 | validation: 0.055862482773051565]
	TIME [epoch: 9.09 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040879484341359205		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.040879484341359205 | validation: 0.03911957257322858]
	TIME [epoch: 9.11 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028778803153020817		[learning rate: 0.001636]
	Learning Rate: 0.00163602
	LOSS [training: 0.028778803153020817 | validation: 0.034855589743366805]
	TIME [epoch: 9.08 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033437324715850925		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.033437324715850925 | validation: 0.040318583714022395]
	TIME [epoch: 9.13 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03827494533185597		[learning rate: 0.0016281]
	Learning Rate: 0.00162811
	LOSS [training: 0.03827494533185597 | validation: 0.04663511366711582]
	TIME [epoch: 9.09 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018312297984090592		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.018312297984090592 | validation: 0.01483585445674298]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_850.pth
	Model improved!!!
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05671494715244085		[learning rate: 0.0016202]
	Learning Rate: 0.00162024
	LOSS [training: 0.05671494715244085 | validation: 0.09011897496734944]
	TIME [epoch: 9.08 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07087977239178604		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.07087977239178604 | validation: 0.09337973994261198]
	TIME [epoch: 9.08 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06524436193930025		[learning rate: 0.0016124]
	Learning Rate: 0.0016124
	LOSS [training: 0.06524436193930025 | validation: 0.06609731925532505]
	TIME [epoch: 9.08 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046971556946384316		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.046971556946384316 | validation: 0.05466466406304644]
	TIME [epoch: 9.09 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05117264045951544		[learning rate: 0.0016046]
	Learning Rate: 0.00160461
	LOSS [training: 0.05117264045951544 | validation: 0.05847381438163009]
	TIME [epoch: 9.08 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04315230496971441		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.04315230496971441 | validation: 0.021731787267904513]
	TIME [epoch: 9.07 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044364228028342154		[learning rate: 0.0015968]
	Learning Rate: 0.00159685
	LOSS [training: 0.044364228028342154 | validation: 0.028706359273061755]
	TIME [epoch: 9.07 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03578077465682992		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.03578077465682992 | validation: 0.046978177931498506]
	TIME [epoch: 9.08 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03293229449461905		[learning rate: 0.0015891]
	Learning Rate: 0.00158912
	LOSS [training: 0.03293229449461905 | validation: 0.047395092000174756]
	TIME [epoch: 9.09 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041881998498251756		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.041881998498251756 | validation: 0.049437778981524294]
	TIME [epoch: 9.08 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04272511503209602		[learning rate: 0.0015814]
	Learning Rate: 0.00158144
	LOSS [training: 0.04272511503209602 | validation: 0.043796758370223274]
	TIME [epoch: 9.07 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02933246768928578		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.02933246768928578 | validation: 0.041499723946961845]
	TIME [epoch: 9.08 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03500439132959943		[learning rate: 0.0015738]
	Learning Rate: 0.00157379
	LOSS [training: 0.03500439132959943 | validation: 0.03112907423601914]
	TIME [epoch: 9.08 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03847843094439345		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.03847843094439345 | validation: 0.0438409528703855]
	TIME [epoch: 9.09 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030674887409433516		[learning rate: 0.0015662]
	Learning Rate: 0.00156618
	LOSS [training: 0.030674887409433516 | validation: 0.03596320255994301]
	TIME [epoch: 9.1 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037922953840801445		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.037922953840801445 | validation: 0.04289294063495696]
	TIME [epoch: 9.09 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031484095325041074		[learning rate: 0.0015586]
	Learning Rate: 0.00155861
	LOSS [training: 0.031484095325041074 | validation: 0.04355605300107318]
	TIME [epoch: 9.08 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037276840646456186		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.037276840646456186 | validation: 0.030466168658185484]
	TIME [epoch: 9.09 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028261462698110383		[learning rate: 0.0015511]
	Learning Rate: 0.00155107
	LOSS [training: 0.028261462698110383 | validation: 0.02766092999464137]
	TIME [epoch: 9.08 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039427047484535974		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.039427047484535974 | validation: 0.035430138480597624]
	TIME [epoch: 9.08 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048490205587969765		[learning rate: 0.0015436]
	Learning Rate: 0.00154357
	LOSS [training: 0.048490205587969765 | validation: 0.06704760798354717]
	TIME [epoch: 9.09 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047889458844977584		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.047889458844977584 | validation: 0.035377185704546864]
	TIME [epoch: 9.09 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05465599279697782		[learning rate: 0.0015361]
	Learning Rate: 0.00153611
	LOSS [training: 0.05465599279697782 | validation: 0.08674418186442848]
	TIME [epoch: 9.1 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06819738865972136		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.06819738865972136 | validation: 0.045665359794331326]
	TIME [epoch: 9.08 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04649747351179973		[learning rate: 0.0015287]
	Learning Rate: 0.00152868
	LOSS [training: 0.04649747351179973 | validation: 0.017715062846614886]
	TIME [epoch: 9.09 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024458586804695464		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.024458586804695464 | validation: 0.04841031138871919]
	TIME [epoch: 9.07 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022640917134482037		[learning rate: 0.0015213]
	Learning Rate: 0.00152128
	LOSS [training: 0.022640917134482037 | validation: 0.037296957048814375]
	TIME [epoch: 9.1 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030256430322650064		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.030256430322650064 | validation: 0.035313091535011644]
	TIME [epoch: 9.09 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021010075934609695		[learning rate: 0.0015139]
	Learning Rate: 0.00151393
	LOSS [training: 0.021010075934609695 | validation: 0.018075396802809705]
	TIME [epoch: 9.08 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022041326271955822		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.022041326271955822 | validation: 0.0649041612545355]
	TIME [epoch: 9.09 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02943744502239139		[learning rate: 0.0015066]
	Learning Rate: 0.00150661
	LOSS [training: 0.02943744502239139 | validation: 0.038607274121388924]
	TIME [epoch: 9.07 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03407120099561245		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.03407120099561245 | validation: 0.02909811099115748]
	TIME [epoch: 9.1 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02314573079526148		[learning rate: 0.0014993]
	Learning Rate: 0.00149932
	LOSS [training: 0.02314573079526148 | validation: 0.007000079642979497]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_883.pth
	Model improved!!!
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015933810488445884		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.015933810488445884 | validation: 0.019676391346035688]
	TIME [epoch: 9.08 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022819881307056852		[learning rate: 0.0014921]
	Learning Rate: 0.00149207
	LOSS [training: 0.022819881307056852 | validation: 0.01537136361194206]
	TIME [epoch: 9.08 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023697440108275958		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.023697440108275958 | validation: 0.022451585221523275]
	TIME [epoch: 9.1 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028341464868148026		[learning rate: 0.0014849]
	Learning Rate: 0.00148486
	LOSS [training: 0.028341464868148026 | validation: 0.0278729771378428]
	TIME [epoch: 9.09 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0490907141248337		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.0490907141248337 | validation: 0.03672362911107116]
	TIME [epoch: 9.08 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05630087409027327		[learning rate: 0.0014777]
	Learning Rate: 0.00147768
	LOSS [training: 0.05630087409027327 | validation: 0.08423146997627914]
	TIME [epoch: 9.08 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05936940516788995		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.05936940516788995 | validation: 0.07415594763685529]
	TIME [epoch: 9.09 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05286391474387543		[learning rate: 0.0014705]
	Learning Rate: 0.00147053
	LOSS [training: 0.05286391474387543 | validation: 0.05242781399512271]
	TIME [epoch: 9.11 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03076368932432818		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.03076368932432818 | validation: 0.043734730804998186]
	TIME [epoch: 9.09 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04026202979636153		[learning rate: 0.0014634]
	Learning Rate: 0.00146342
	LOSS [training: 0.04026202979636153 | validation: 0.026488781145799493]
	TIME [epoch: 9.09 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035158085390303136		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.035158085390303136 | validation: 0.05147974080358906]
	TIME [epoch: 9.08 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06307055051565519		[learning rate: 0.0014563]
	Learning Rate: 0.00145634
	LOSS [training: 0.06307055051565519 | validation: 0.07971583740273097]
	TIME [epoch: 9.09 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049273485876987336		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.049273485876987336 | validation: 0.03545924293129336]
	TIME [epoch: 9.08 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04918745109318076		[learning rate: 0.0014493]
	Learning Rate: 0.0014493
	LOSS [training: 0.04918745109318076 | validation: 0.04555816616951548]
	TIME [epoch: 9.08 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03897586523957321		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.03897586523957321 | validation: 0.06392433991173455]
	TIME [epoch: 9.08 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05671183663749886		[learning rate: 0.0014423]
	Learning Rate: 0.00144229
	LOSS [training: 0.05671183663749886 | validation: 0.056348047223784566]
	TIME [epoch: 9.08 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04306605121504627		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.04306605121504627 | validation: 0.05099777153042192]
	TIME [epoch: 9.1 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031607592339075494		[learning rate: 0.0014353]
	Learning Rate: 0.00143532
	LOSS [training: 0.031607592339075494 | validation: 0.04722147773993434]
	TIME [epoch: 9.08 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05250839909401903		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.05250839909401903 | validation: 0.07746537823174361]
	TIME [epoch: 9.08 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05321361192479214		[learning rate: 0.0014284]
	Learning Rate: 0.00142837
	LOSS [training: 0.05321361192479214 | validation: 0.0203166427248321]
	TIME [epoch: 9.08 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02179018737855769		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.02179018737855769 | validation: 0.043677361471468834]
	TIME [epoch: 9.1 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03806899210221991		[learning rate: 0.0014215]
	Learning Rate: 0.00142147
	LOSS [training: 0.03806899210221991 | validation: 0.05353770913719656]
	TIME [epoch: 9.1 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04278127215676768		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.04278127215676768 | validation: 0.026687601907669042]
	TIME [epoch: 9.08 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029118229784727633		[learning rate: 0.0014146]
	Learning Rate: 0.00141459
	LOSS [training: 0.029118229784727633 | validation: 0.027865890264778724]
	TIME [epoch: 9.08 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02888485338750086		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.02888485338750086 | validation: 0.02409755238547834]
	TIME [epoch: 9.08 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031710751546463925		[learning rate: 0.0014078]
	Learning Rate: 0.00140775
	LOSS [training: 0.031710751546463925 | validation: 0.02606680801123787]
	TIME [epoch: 9.1 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023810336381076727		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.023810336381076727 | validation: 0.028572007534169448]
	TIME [epoch: 9.08 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035820401522168456		[learning rate: 0.0014009]
	Learning Rate: 0.00140094
	LOSS [training: 0.035820401522168456 | validation: 0.046303327125878355]
	TIME [epoch: 9.09 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04609822458130973		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.04609822458130973 | validation: 0.06235779409651684]
	TIME [epoch: 9.09 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04437440546825379		[learning rate: 0.0013942]
	Learning Rate: 0.00139417
	LOSS [training: 0.04437440546825379 | validation: 0.04711400827030486]
	TIME [epoch: 9.08 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04314088503053588		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.04314088503053588 | validation: 0.044610978092335]
	TIME [epoch: 9.1 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051526024603532325		[learning rate: 0.0013874]
	Learning Rate: 0.00138743
	LOSS [training: 0.051526024603532325 | validation: 0.08103959700161217]
	TIME [epoch: 9.08 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08219255416033919		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.08219255416033919 | validation: 0.1089767194009946]
	TIME [epoch: 9.08 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07302948466161811		[learning rate: 0.0013807]
	Learning Rate: 0.00138072
	LOSS [training: 0.07302948466161811 | validation: 0.08591628026021311]
	TIME [epoch: 9.07 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07324479673343082		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.07324479673343082 | validation: 0.060621449350655776]
	TIME [epoch: 9.1 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05063378864196524		[learning rate: 0.001374]
	Learning Rate: 0.00137404
	LOSS [training: 0.05063378864196524 | validation: 0.056632472983442234]
	TIME [epoch: 9.09 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03625592803261244		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.03625592803261244 | validation: 0.08086560774653496]
	TIME [epoch: 9.08 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05614140728570503		[learning rate: 0.0013674]
	Learning Rate: 0.0013674
	LOSS [training: 0.05614140728570503 | validation: 0.04334874495651546]
	TIME [epoch: 9.08 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0403941748065718		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.0403941748065718 | validation: 0.05125074125906487]
	TIME [epoch: 9.08 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03672068568278998		[learning rate: 0.0013608]
	Learning Rate: 0.00136078
	LOSS [training: 0.03672068568278998 | validation: 0.06117058819121812]
	TIME [epoch: 9.09 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033380752555116806		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.033380752555116806 | validation: 0.029194000892026475]
	TIME [epoch: 9.08 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02662572837065642		[learning rate: 0.0013542]
	Learning Rate: 0.0013542
	LOSS [training: 0.02662572837065642 | validation: 0.019271308112641144]
	TIME [epoch: 9.08 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028186075515737968		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.028186075515737968 | validation: 0.02719482832315146]
	TIME [epoch: 9.08 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015308725321763228		[learning rate: 0.0013477]
	Learning Rate: 0.00134766
	LOSS [training: 0.015308725321763228 | validation: 0.022016074685303144]
	TIME [epoch: 9.09 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01934863691843575		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.01934863691843575 | validation: 0.021869405130011933]
	TIME [epoch: 9.09 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016246247586468986		[learning rate: 0.0013411]
	Learning Rate: 0.00134114
	LOSS [training: 0.016246247586468986 | validation: 0.03772634137142605]
	TIME [epoch: 9.07 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022564514538563434		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.022564514538563434 | validation: 0.02321136419187879]
	TIME [epoch: 9.08 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030254218427304923		[learning rate: 0.0013347]
	Learning Rate: 0.00133465
	LOSS [training: 0.030254218427304923 | validation: 0.03982901783226252]
	TIME [epoch: 9.09 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03820944951667859		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.03820944951667859 | validation: 0.03611767964413551]
	TIME [epoch: 9.1 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02251079814954184		[learning rate: 0.0013282]
	Learning Rate: 0.0013282
	LOSS [training: 0.02251079814954184 | validation: 0.018928720572483904]
	TIME [epoch: 9.09 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01996117833841505		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.01996117833841505 | validation: 0.055810321834698695]
	TIME [epoch: 9.08 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02270047366426794		[learning rate: 0.0013218]
	Learning Rate: 0.00132178
	LOSS [training: 0.02270047366426794 | validation: 0.01423291515627114]
	TIME [epoch: 9.07 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015332538113871808		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.015332538113871808 | validation: 0.0225679705927831]
	TIME [epoch: 9.1 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030891536825014543		[learning rate: 0.0013154]
	Learning Rate: 0.00131538
	LOSS [training: 0.030891536825014543 | validation: 0.04885513166166358]
	TIME [epoch: 9.08 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03300289957487068		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.03300289957487068 | validation: 0.050154282968619596]
	TIME [epoch: 9.08 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023848764909540722		[learning rate: 0.001309]
	Learning Rate: 0.00130902
	LOSS [training: 0.023848764909540722 | validation: 0.030631235780548452]
	TIME [epoch: 9.09 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028612056360997267		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.028612056360997267 | validation: 0.07060876481454485]
	TIME [epoch: 9.07 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052749187369175055		[learning rate: 0.0013027]
	Learning Rate: 0.00130269
	LOSS [training: 0.052749187369175055 | validation: 0.025610027139779938]
	TIME [epoch: 9.1 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015013896779895342		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.015013896779895342 | validation: 0.023916974322174128]
	TIME [epoch: 9.08 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024489918632010766		[learning rate: 0.0012964]
	Learning Rate: 0.00129639
	LOSS [training: 0.024489918632010766 | validation: 0.06769774046407219]
	TIME [epoch: 9.09 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0549717304727278		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.0549717304727278 | validation: 0.0915017856002909]
	TIME [epoch: 9.08 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05511720700768682		[learning rate: 0.0012901]
	Learning Rate: 0.00129012
	LOSS [training: 0.05511720700768682 | validation: 0.04097813002403278]
	TIME [epoch: 9.08 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03216713260939774		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.03216713260939774 | validation: 0.029331379101195498]
	TIME [epoch: 9.1 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029110840021399197		[learning rate: 0.0012839]
	Learning Rate: 0.00128389
	LOSS [training: 0.029110840021399197 | validation: 0.04066533572092997]
	TIME [epoch: 9.08 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018218474716611276		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.018218474716611276 | validation: 0.029362928398292375]
	TIME [epoch: 9.07 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026903682934958883		[learning rate: 0.0012777]
	Learning Rate: 0.00127768
	LOSS [training: 0.026903682934958883 | validation: 0.030503259739318687]
	TIME [epoch: 9.07 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028120709625663837		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.028120709625663837 | validation: 0.025755185316562373]
	TIME [epoch: 9.09 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02617941319454316		[learning rate: 0.0012715]
	Learning Rate: 0.0012715
	LOSS [training: 0.02617941319454316 | validation: 0.02469409324389793]
	TIME [epoch: 9.08 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018180985934845798		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.018180985934845798 | validation: 0.028021953612755755]
	TIME [epoch: 9.07 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024766538066691973		[learning rate: 0.0012653]
	Learning Rate: 0.00126535
	LOSS [training: 0.024766538066691973 | validation: 0.03890205969231213]
	TIME [epoch: 9.08 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038623453373524595		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.038623453373524595 | validation: 0.05868802210584073]
	TIME [epoch: 9.07 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02706777369960407		[learning rate: 0.0012592]
	Learning Rate: 0.00125923
	LOSS [training: 0.02706777369960407 | validation: 0.04580298018898572]
	TIME [epoch: 9.09 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024852512312447443		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.024852512312447443 | validation: 0.05165762744100147]
	TIME [epoch: 9.07 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03945014950459592		[learning rate: 0.0012531]
	Learning Rate: 0.00125314
	LOSS [training: 0.03945014950459592 | validation: 0.07432346177271826]
	TIME [epoch: 9.08 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06299802859045187		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.06299802859045187 | validation: 0.07843055465803961]
	TIME [epoch: 9.08 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060692916052694834		[learning rate: 0.0012471]
	Learning Rate: 0.00124708
	LOSS [training: 0.060692916052694834 | validation: 0.06688206093787384]
	TIME [epoch: 9.09 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05057130804642425		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.05057130804642425 | validation: 0.08031398471205527]
	TIME [epoch: 9.07 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07119672233665479		[learning rate: 0.0012411]
	Learning Rate: 0.00124105
	LOSS [training: 0.07119672233665479 | validation: 0.14073560843112734]
	TIME [epoch: 9.08 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09613185725075094		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.09613185725075094 | validation: 0.07787012807982494]
	TIME [epoch: 9.07 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05797073485340657		[learning rate: 0.001235]
	Learning Rate: 0.00123505
	LOSS [training: 0.05797073485340657 | validation: 0.08280670574783457]
	TIME [epoch: 9.07 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07945947448340351		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.07945947448340351 | validation: 0.09305738752612083]
	TIME [epoch: 9.09 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05595832401210009		[learning rate: 0.0012291]
	Learning Rate: 0.00122908
	LOSS [training: 0.05595832401210009 | validation: 0.06855460407724884]
	TIME [epoch: 9.08 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059414653715894813		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.059414653715894813 | validation: 0.05458547026438016]
	TIME [epoch: 9.08 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05889207162453537		[learning rate: 0.0012231]
	Learning Rate: 0.00122313
	LOSS [training: 0.05889207162453537 | validation: 0.07044254195453949]
	TIME [epoch: 9.09 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0623043755529756		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.0623043755529756 | validation: 0.05721650265885363]
	TIME [epoch: 9.08 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0534215997472914		[learning rate: 0.0012172]
	Learning Rate: 0.00121722
	LOSS [training: 0.0534215997472914 | validation: 0.043565820209280126]
	TIME [epoch: 9.09 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03786572324896905		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.03786572324896905 | validation: 0.04360191718995001]
	TIME [epoch: 9.08 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02425689233077952		[learning rate: 0.0012113]
	Learning Rate: 0.00121133
	LOSS [training: 0.02425689233077952 | validation: 0.033584596649597544]
	TIME [epoch: 9.08 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01663506831886418		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.01663506831886418 | validation: 0.013641253372352356]
	TIME [epoch: 9.06 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023415029744762526		[learning rate: 0.0012055]
	Learning Rate: 0.00120547
	LOSS [training: 0.023415029744762526 | validation: 0.04027748414460829]
	TIME [epoch: 9.09 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028737444956645024		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.028737444956645024 | validation: 0.04883152646727357]
	TIME [epoch: 9.08 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0303849055669416		[learning rate: 0.0011996]
	Learning Rate: 0.00119964
	LOSS [training: 0.0303849055669416 | validation: 0.03379216999096979]
	TIME [epoch: 9.07 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03648021822190452		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.03648021822190452 | validation: 0.05262163480850832]
	TIME [epoch: 9.08 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03828303466316939		[learning rate: 0.0011938]
	Learning Rate: 0.00119384
	LOSS [training: 0.03828303466316939 | validation: 0.031191703804167116]
	TIME [epoch: 9.08 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031793242673831955		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.031793242673831955 | validation: 0.022362592918078267]
	TIME [epoch: 9.09 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04350949899632078		[learning rate: 0.0011881]
	Learning Rate: 0.00118807
	LOSS [training: 0.04350949899632078 | validation: 0.05044081740479971]
	TIME [epoch: 9.07 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03469076620835028		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.03469076620835028 | validation: 0.045892757915631965]
	TIME [epoch: 9.08 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03733048235757129		[learning rate: 0.0011823]
	Learning Rate: 0.00118232
	LOSS [training: 0.03733048235757129 | validation: 0.03298391788632528]
	TIME [epoch: 9.08 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0330991185693935		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.0330991185693935 | validation: 0.039264631320614654]
	TIME [epoch: 9.1 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037259527398000127		[learning rate: 0.0011766]
	Learning Rate: 0.00117661
	LOSS [training: 0.037259527398000127 | validation: 0.04817429162136923]
	TIME [epoch: 9.09 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03618431639346913		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.03618431639346913 | validation: 0.08242661919987804]
	TIME [epoch: 9.09 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08158094996917001		[learning rate: 0.0011709]
	Learning Rate: 0.00117092
	LOSS [training: 0.08158094996917001 | validation: 0.0611373780533477]
	TIME [epoch: 9.08 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06242631888483341		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.06242631888483341 | validation: 0.07399411919146373]
	TIME [epoch: 9.08 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08229818057365726		[learning rate: 0.0011653]
	Learning Rate: 0.00116526
	LOSS [training: 0.08229818057365726 | validation: 0.07425883717427956]
	TIME [epoch: 9.1 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052282695309397456		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.052282695309397456 | validation: 0.06782511994570917]
	TIME [epoch: 9.08 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05678900756126735		[learning rate: 0.0011596]
	Learning Rate: 0.00115962
	LOSS [training: 0.05678900756126735 | validation: 0.07705707907359588]
	TIME [epoch: 9.08 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06606226817547142		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.06606226817547142 | validation: 0.05733736803165926]
	TIME [epoch: 9.07 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042301539570060824		[learning rate: 0.001154]
	Learning Rate: 0.00115401
	LOSS [training: 0.042301539570060824 | validation: 0.07315489193349811]
	TIME [epoch: 9.09 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06249959758097059		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.06249959758097059 | validation: 0.07869904555686989]
	TIME [epoch: 9.09 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05316158017686658		[learning rate: 0.0011484]
	Learning Rate: 0.00114843
	LOSS [training: 0.05316158017686658 | validation: 0.06870704864943321]
	TIME [epoch: 9.08 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049887488147209495		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.049887488147209495 | validation: 0.06507371389547772]
	TIME [epoch: 9.08 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04872444499221017		[learning rate: 0.0011429]
	Learning Rate: 0.00114288
	LOSS [training: 0.04872444499221017 | validation: 0.08567978710579657]
	TIME [epoch: 9.08 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04545894387291092		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.04545894387291092 | validation: 0.07169167974870069]
	TIME [epoch: 9.11 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04927019793540798		[learning rate: 0.0011374]
	Learning Rate: 0.00113735
	LOSS [training: 0.04927019793540798 | validation: 0.053145741992096124]
	TIME [epoch: 9.1 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05083411081085728		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.05083411081085728 | validation: 0.062375546440809296]
	TIME [epoch: 9.09 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03857572160637699		[learning rate: 0.0011319]
	Learning Rate: 0.00113185
	LOSS [training: 0.03857572160637699 | validation: 0.034851286858913366]
	TIME [epoch: 9.1 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04627026765666151		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.04627026765666151 | validation: 0.03870515011358526]
	TIME [epoch: 9.09 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03380697424467925		[learning rate: 0.0011264]
	Learning Rate: 0.00112638
	LOSS [training: 0.03380697424467925 | validation: 0.03476618003309094]
	TIME [epoch: 9.09 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02846828763217372		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.02846828763217372 | validation: 0.02924565149116983]
	TIME [epoch: 9.08 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025795141373331155		[learning rate: 0.0011209]
	Learning Rate: 0.00112093
	LOSS [training: 0.025795141373331155 | validation: 0.03168693746521174]
	TIME [epoch: 9.08 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031590702901708304		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.031590702901708304 | validation: 0.04064308746776914]
	TIME [epoch: 9.08 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03847562258187978		[learning rate: 0.0011155]
	Learning Rate: 0.00111551
	LOSS [training: 0.03847562258187978 | validation: 0.033027219607813976]
	TIME [epoch: 9.11 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027714483665655508		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.027714483665655508 | validation: 0.034518742721197176]
	TIME [epoch: 9.09 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025404785406601453		[learning rate: 0.0011101]
	Learning Rate: 0.00111012
	LOSS [training: 0.025404785406601453 | validation: 0.04591580032767922]
	TIME [epoch: 9.07 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03662313880143135		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.03662313880143135 | validation: 0.03452122379619364]
	TIME [epoch: 9.08 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025518057810963873		[learning rate: 0.0011047]
	Learning Rate: 0.00110475
	LOSS [training: 0.025518057810963873 | validation: 0.035470067699043956]
	TIME [epoch: 9.08 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024901075298205306		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.024901075298205306 | validation: 0.06295280730896752]
	TIME [epoch: 9.12 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0330394534478987		[learning rate: 0.0010994]
	Learning Rate: 0.00109941
	LOSS [training: 0.0330394534478987 | validation: 0.023247978635752054]
	TIME [epoch: 9.09 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02590563211238476		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.02590563211238476 | validation: 0.034918343457228045]
	TIME [epoch: 9.09 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03276539593864276		[learning rate: 0.0010941]
	Learning Rate: 0.00109409
	LOSS [training: 0.03276539593864276 | validation: 0.043198570385789656]
	TIME [epoch: 9.08 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0347812513879538		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.0347812513879538 | validation: 0.04074838706870532]
	TIME [epoch: 9.09 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029730866109320582		[learning rate: 0.0010888]
	Learning Rate: 0.0010888
	LOSS [training: 0.029730866109320582 | validation: 0.04748771030975878]
	TIME [epoch: 9.08 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020901583190693067		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.020901583190693067 | validation: 0.0459040816188942]
	TIME [epoch: 9.07 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03090905364618516		[learning rate: 0.0010835]
	Learning Rate: 0.00108353
	LOSS [training: 0.03090905364618516 | validation: 0.044604861256995254]
	TIME [epoch: 9.09 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05139136245217254		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.05139136245217254 | validation: 0.05968445838618883]
	TIME [epoch: 9.09 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026703349005288413		[learning rate: 0.0010783]
	Learning Rate: 0.00107829
	LOSS [training: 0.026703349005288413 | validation: 0.02669402128482052]
	TIME [epoch: 9.1 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03498879645135185		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.03498879645135185 | validation: 0.05470242854206705]
	TIME [epoch: 9.08 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029951440217431402		[learning rate: 0.0010731]
	Learning Rate: 0.00107308
	LOSS [training: 0.029951440217431402 | validation: 0.050869822935750306]
	TIME [epoch: 9.08 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052024512623663255		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.052024512623663255 | validation: 0.08888993896175804]
	TIME [epoch: 9.09 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0479071178202966		[learning rate: 0.0010679]
	Learning Rate: 0.00106789
	LOSS [training: 0.0479071178202966 | validation: 0.05002892150926951]
	TIME [epoch: 9.11 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013484541561556101		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.013484541561556101 | validation: 0.02337593212292223]
	TIME [epoch: 9.1 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02877400606454341		[learning rate: 0.0010627]
	Learning Rate: 0.00106273
	LOSS [training: 0.02877400606454341 | validation: 0.028951476361099043]
	TIME [epoch: 9.09 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028455902089518294		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.028455902089518294 | validation: 0.02978782801680266]
	TIME [epoch: 9.09 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030252005741245213		[learning rate: 0.0010576]
	Learning Rate: 0.00105759
	LOSS [training: 0.030252005741245213 | validation: 0.04467859064737105]
	TIME [epoch: 9.08 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029697060500449884		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.029697060500449884 | validation: 0.008522102079019885]
	TIME [epoch: 9.1 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020975307566194184		[learning rate: 0.0010525]
	Learning Rate: 0.00105247
	LOSS [training: 0.020975307566194184 | validation: 0.03167318340976449]
	TIME [epoch: 9.09 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026566771959128897		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.026566771959128897 | validation: 0.035753758146981826]
	TIME [epoch: 9.09 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027533888067683792		[learning rate: 0.0010474]
	Learning Rate: 0.00104738
	LOSS [training: 0.027533888067683792 | validation: 0.04590241633742589]
	TIME [epoch: 9.09 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06716837926936056		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.06716837926936056 | validation: 0.05386317682120082]
	TIME [epoch: 9.1 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042341327696244116		[learning rate: 0.0010423]
	Learning Rate: 0.00104232
	LOSS [training: 0.042341327696244116 | validation: 0.035126742355559196]
	TIME [epoch: 9.09 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01779591710105561		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.01779591710105561 | validation: 0.03983499020664715]
	TIME [epoch: 9.08 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030556411936363416		[learning rate: 0.0010373]
	Learning Rate: 0.00103728
	LOSS [training: 0.030556411936363416 | validation: 0.04810802413955442]
	TIME [epoch: 9.08 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05364555659420113		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.05364555659420113 | validation: 0.06864287328866697]
	TIME [epoch: 9.09 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027442450482228636		[learning rate: 0.0010323]
	Learning Rate: 0.00103226
	LOSS [training: 0.027442450482228636 | validation: 0.018323748050827558]
	TIME [epoch: 9.11 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020730160006349325		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.020730160006349325 | validation: 0.05106810832714957]
	TIME [epoch: 9.09 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036293100725761106		[learning rate: 0.0010273]
	Learning Rate: 0.00102727
	LOSS [training: 0.036293100725761106 | validation: 0.04130139847205787]
	TIME [epoch: 9.07 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021562984227893628		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.021562984227893628 | validation: 0.01673379435101268]
	TIME [epoch: 9.06 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02023439612807623		[learning rate: 0.0010223]
	Learning Rate: 0.0010223
	LOSS [training: 0.02023439612807623 | validation: 0.028664993798199524]
	TIME [epoch: 9.07 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030839161028191387		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.030839161028191387 | validation: 0.06369864883919281]
	TIME [epoch: 9.08 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03198271097130197		[learning rate: 0.0010174]
	Learning Rate: 0.00101736
	LOSS [training: 0.03198271097130197 | validation: 0.013989320183147802]
	TIME [epoch: 9.07 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023234485144426137		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.023234485144426137 | validation: 0.03279789558839517]
	TIME [epoch: 9.06 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010710993923559384		[learning rate: 0.0010124]
	Learning Rate: 0.00101244
	LOSS [training: 0.010710993923559384 | validation: 0.022455838447917775]
	TIME [epoch: 9.06 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016903782402264415		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.016903782402264415 | validation: 0.02676132826651032]
	TIME [epoch: 9.07 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015714831994854992		[learning rate: 0.0010075]
	Learning Rate: 0.00100754
	LOSS [training: 0.015714831994854992 | validation: 0.05430472802433574]
	TIME [epoch: 9.07 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05013051879016284		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.05013051879016284 | validation: 0.03297992003079475]
	TIME [epoch: 9.07 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022928330961666955		[learning rate: 0.0010027]
	Learning Rate: 0.00100267
	LOSS [training: 0.022928330961666955 | validation: 0.0298784952997899]
	TIME [epoch: 9.07 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03186831799585017		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.03186831799585017 | validation: 0.01827818418766483]
	TIME [epoch: 9.08 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029268635357173067		[learning rate: 0.00099782]
	Learning Rate: 0.000997821
	LOSS [training: 0.029268635357173067 | validation: 0.06349050940466683]
	TIME [epoch: 9.09 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02400511328468813		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.02400511328468813 | validation: 0.013893584148881115]
	TIME [epoch: 9.06 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02104252713839887		[learning rate: 0.000993]
	Learning Rate: 0.000992996
	LOSS [training: 0.02104252713839887 | validation: 0.025983546171886293]
	TIME [epoch: 9.06 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014454804870613569		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.014454804870613569 | validation: 0.019155017031609614]
	TIME [epoch: 9.06 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01679464388817064		[learning rate: 0.00098819]
	Learning Rate: 0.000988194
	LOSS [training: 0.01679464388817064 | validation: 0.05076723164063854]
	TIME [epoch: 9.08 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03536321883778078		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.03536321883778078 | validation: 0.03315879925953045]
	TIME [epoch: 9.07 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03158174768424455		[learning rate: 0.00098341]
	Learning Rate: 0.000983415
	LOSS [training: 0.03158174768424455 | validation: 0.024788821234208627]
	TIME [epoch: 9.06 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027407131681994313		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.027407131681994313 | validation: 0.03272999417017815]
	TIME [epoch: 9.06 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030215534793479604		[learning rate: 0.00097866]
	Learning Rate: 0.000978659
	LOSS [training: 0.030215534793479604 | validation: 0.037879477429410925]
	TIME [epoch: 9.07 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03222396039822123		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 0.03222396039822123 | validation: 0.05179752393199133]
	TIME [epoch: 9.08 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03380416804505261		[learning rate: 0.00097393]
	Learning Rate: 0.000973927
	LOSS [training: 0.03380416804505261 | validation: 0.032951726496406014]
	TIME [epoch: 9.07 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027944913562929247		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.027944913562929247 | validation: 0.05601852291272029]
	TIME [epoch: 9.08 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032022965004023074		[learning rate: 0.00096922]
	Learning Rate: 0.000969217
	LOSS [training: 0.032022965004023074 | validation: 0.03835844860497829]
	TIME [epoch: 9.08 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038232126447207616		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.038232126447207616 | validation: 0.04205208462997191]
	TIME [epoch: 9.1 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0439420482018652		[learning rate: 0.00096453]
	Learning Rate: 0.00096453
	LOSS [training: 0.0439420482018652 | validation: 0.04925827563249105]
	TIME [epoch: 9.08 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034043516280303374		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.034043516280303374 | validation: 0.02985447534281659]
	TIME [epoch: 9.07 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020778256079306823		[learning rate: 0.00095987]
	Learning Rate: 0.000959866
	LOSS [training: 0.020778256079306823 | validation: 0.009565238734169472]
	TIME [epoch: 9.07 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019122443148522968		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.019122443148522968 | validation: 0.02487405374073858]
	TIME [epoch: 9.08 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017672268957854682		[learning rate: 0.00095522]
	Learning Rate: 0.000955224
	LOSS [training: 0.017672268957854682 | validation: 0.03982131128615496]
	TIME [epoch: 9.09 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01842717992889068		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.01842717992889068 | validation: 0.030588705627272058]
	TIME [epoch: 9.07 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0236750420338404		[learning rate: 0.0009506]
	Learning Rate: 0.000950605
	LOSS [training: 0.0236750420338404 | validation: 0.02683665820552565]
	TIME [epoch: 9.08 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042879774718748674		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.042879774718748674 | validation: 0.04547067889571697]
	TIME [epoch: 9.07 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02562677912617033		[learning rate: 0.00094601]
	Learning Rate: 0.000946008
	LOSS [training: 0.02562677912617033 | validation: 0.014346105093977282]
	TIME [epoch: 9.07 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021497161447661863		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.021497161447661863 | validation: 0.050463724817474714]
	TIME [epoch: 9.08 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026074183518015975		[learning rate: 0.00094143]
	Learning Rate: 0.000941433
	LOSS [training: 0.026074183518015975 | validation: 0.03142717307929374]
	TIME [epoch: 9.07 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0318610798560315		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.0318610798560315 | validation: 0.03717837257622293]
	TIME [epoch: 9.08 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03054392242257729		[learning rate: 0.00093688]
	Learning Rate: 0.00093688
	LOSS [training: 0.03054392242257729 | validation: 0.04558320044488935]
	TIME [epoch: 9.07 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027594362980012353		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.027594362980012353 | validation: 0.02808036629775472]
	TIME [epoch: 9.09 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027543599222178628		[learning rate: 0.00093235]
	Learning Rate: 0.00093235
	LOSS [training: 0.027543599222178628 | validation: 0.02329234625894727]
	TIME [epoch: 9.08 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014973452884448745		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.014973452884448745 | validation: 0.018451250344669434]
	TIME [epoch: 9.06 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03888978488640817		[learning rate: 0.00092784]
	Learning Rate: 0.000927841
	LOSS [training: 0.03888978488640817 | validation: 0.033316613299387544]
	TIME [epoch: 9.07 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03145902123960821		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.03145902123960821 | validation: 0.04129110979701586]
	TIME [epoch: 9.07 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028272433804213994		[learning rate: 0.00092335]
	Learning Rate: 0.000923354
	LOSS [training: 0.028272433804213994 | validation: 0.02635101919199983]
	TIME [epoch: 9.09 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019541391915242283		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.019541391915242283 | validation: 0.021587182035344425]
	TIME [epoch: 9.08 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01500262960970434		[learning rate: 0.00091889]
	Learning Rate: 0.000918889
	LOSS [training: 0.01500262960970434 | validation: 0.022029222764070485]
	TIME [epoch: 9.06 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013107373129804738		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.013107373129804738 | validation: 0.047699259371421096]
	TIME [epoch: 9.07 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036373913970484215		[learning rate: 0.00091445]
	Learning Rate: 0.000914446
	LOSS [training: 0.036373913970484215 | validation: 0.03141364925827831]
	TIME [epoch: 9.09 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014287015034147602		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.014287015034147602 | validation: 0.009634655191058925]
	TIME [epoch: 9.08 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017703511265198528		[learning rate: 0.00091002]
	Learning Rate: 0.000910024
	LOSS [training: 0.017703511265198528 | validation: 0.040980010868279265]
	TIME [epoch: 9.07 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018773035006930724		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.018773035006930724 | validation: 0.022307755164719216]
	TIME [epoch: 9.07 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025857486075523885		[learning rate: 0.00090562]
	Learning Rate: 0.000905623
	LOSS [training: 0.025857486075523885 | validation: 0.03559934132841401]
	TIME [epoch: 9.07 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04611667704762984		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.04611667704762984 | validation: 0.060177785826686356]
	TIME [epoch: 9.08 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029534377749219364		[learning rate: 0.00090124]
	Learning Rate: 0.000901243
	LOSS [training: 0.029534377749219364 | validation: 0.04534079527666095]
	TIME [epoch: 9.07 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02584704242984843		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.02584704242984843 | validation: 0.030744083961083694]
	TIME [epoch: 9.06 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020859540328203738		[learning rate: 0.00089689]
	Learning Rate: 0.000896885
	LOSS [training: 0.020859540328203738 | validation: 0.023202621851930533]
	TIME [epoch: 9.06 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023188684262567354		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.023188684262567354 | validation: 0.03508919776550268]
	TIME [epoch: 9.08 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019276519414569662		[learning rate: 0.00089255]
	Learning Rate: 0.000892548
	LOSS [training: 0.019276519414569662 | validation: 0.028834265257836444]
	TIME [epoch: 9.07 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0303064301390382		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.0303064301390382 | validation: 0.04520020990208242]
	TIME [epoch: 9.06 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023469038116585773		[learning rate: 0.00088823]
	Learning Rate: 0.000888232
	LOSS [training: 0.023469038116585773 | validation: 0.02191094952894923]
	TIME [epoch: 9.07 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02015179735707079		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.02015179735707079 | validation: 0.03193324664394258]
	TIME [epoch: 9.07 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01760630131387338		[learning rate: 0.00088394]
	Learning Rate: 0.000883936
	LOSS [training: 0.01760630131387338 | validation: 0.025063076252038796]
	TIME [epoch: 9.09 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020524290829140937		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.020524290829140937 | validation: 0.03892078490538635]
	TIME [epoch: 9.08 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030443143824346063		[learning rate: 0.00087966]
	Learning Rate: 0.000879662
	LOSS [training: 0.030443143824346063 | validation: 0.04861154407827755]
	TIME [epoch: 9.07 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03157629600396762		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.03157629600396762 | validation: 0.039801978450697745]
	TIME [epoch: 9.08 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015167641742967045		[learning rate: 0.00087541]
	Learning Rate: 0.000875408
	LOSS [training: 0.015167641742967045 | validation: 0.04084597572754235]
	TIME [epoch: 9.08 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033712593504177865		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.033712593504177865 | validation: 0.028722019533146]
	TIME [epoch: 9.08 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026173733791963732		[learning rate: 0.00087117]
	Learning Rate: 0.000871175
	LOSS [training: 0.026173733791963732 | validation: 0.034624045709625725]
	TIME [epoch: 9.07 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036377499386108555		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.036377499386108555 | validation: 0.03874740410365255]
	TIME [epoch: 9.06 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03691255385052215		[learning rate: 0.00086696]
	Learning Rate: 0.000866962
	LOSS [training: 0.03691255385052215 | validation: 0.06809244638156522]
	TIME [epoch: 9.07 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031904199045278955		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.031904199045278955 | validation: 0.029521914619374708]
	TIME [epoch: 9.09 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024553435100343805		[learning rate: 0.00086277]
	Learning Rate: 0.000862769
	LOSS [training: 0.024553435100343805 | validation: 0.03654503750698523]
	TIME [epoch: 9.07 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04394910998314536		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.04394910998314536 | validation: 0.043836922018238106]
	TIME [epoch: 9.08 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03980605618604274		[learning rate: 0.0008586]
	Learning Rate: 0.000858597
	LOSS [training: 0.03980605618604274 | validation: 0.04118531130843266]
	TIME [epoch: 9.07 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03031331870236139		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.03031331870236139 | validation: 0.03513820477207697]
	TIME [epoch: 9.07 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032305093056921655		[learning rate: 0.00085445]
	Learning Rate: 0.000854445
	LOSS [training: 0.032305093056921655 | validation: 0.04249885304123237]
	TIME [epoch: 9.09 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025845992892069118		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.025845992892069118 | validation: 0.023427547352419573]
	TIME [epoch: 9.07 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009325433821665277		[learning rate: 0.00085031]
	Learning Rate: 0.000850313
	LOSS [training: 0.009325433821665277 | validation: 0.01585668008946805]
	TIME [epoch: 9.07 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006284389023747512		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.006284389023747512 | validation: 0.02781098880445845]
	TIME [epoch: 9.07 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022083812561000855		[learning rate: 0.0008462]
	Learning Rate: 0.000846201
	LOSS [training: 0.022083812561000855 | validation: 0.062239150272412516]
	TIME [epoch: 9.08 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02914209247152254		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.02914209247152254 | validation: 0.029070966960043763]
	TIME [epoch: 9.07 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016876692896835646		[learning rate: 0.00084211]
	Learning Rate: 0.000842109
	LOSS [training: 0.016876692896835646 | validation: 0.040390110489386094]
	TIME [epoch: 9.06 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0378524461090868		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.0378524461090868 | validation: 0.08029292799607624]
	TIME [epoch: 9.07 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06146354572251604		[learning rate: 0.00083804]
	Learning Rate: 0.000838037
	LOSS [training: 0.06146354572251604 | validation: 0.053982533731361845]
	TIME [epoch: 9.07 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03273499506866194		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.03273499506866194 | validation: 0.026021903901690437]
	TIME [epoch: 9.09 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01708741876870793		[learning rate: 0.00083398]
	Learning Rate: 0.000833984
	LOSS [training: 0.01708741876870793 | validation: 0.036600996981504236]
	TIME [epoch: 9.08 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019226116810937957		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.019226116810937957 | validation: 0.0255486594594145]
	TIME [epoch: 9.07 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012170880801745396		[learning rate: 0.00082995]
	Learning Rate: 0.000829951
	LOSS [training: 0.012170880801745396 | validation: 0.017529741630312616]
	TIME [epoch: 9.07 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012668642987270334		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.012668642987270334 | validation: 0.028606638041779993]
	TIME [epoch: 9.09 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027027294123345657		[learning rate: 0.00082594]
	Learning Rate: 0.000825938
	LOSS [training: 0.027027294123345657 | validation: 0.02406145453818382]
	TIME [epoch: 9.09 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013485050591369957		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.013485050591369957 | validation: 0.018618471263414333]
	TIME [epoch: 9.09 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010752352223238334		[learning rate: 0.00082194]
	Learning Rate: 0.000821944
	LOSS [training: 0.010752352223238334 | validation: 0.015224940527001837]
	TIME [epoch: 9.08 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010842205332405418		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.010842205332405418 | validation: 0.01362566737460268]
	TIME [epoch: 9.07 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00796738918080582		[learning rate: 0.00081797]
	Learning Rate: 0.000817969
	LOSS [training: 0.00796738918080582 | validation: 0.02881242025084963]
	TIME [epoch: 9.1 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05744675235444706		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.05744675235444706 | validation: 0.09086459440015993]
	TIME [epoch: 9.07 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039171338901672		[learning rate: 0.00081401]
	Learning Rate: 0.000814014
	LOSS [training: 0.039171338901672 | validation: 0.03370880796468546]
	TIME [epoch: 9.07 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02370940666081891		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.02370940666081891 | validation: 0.038873819967458034]
	TIME [epoch: 9.07 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01807095905318453		[learning rate: 0.00081008]
	Learning Rate: 0.000810077
	LOSS [training: 0.01807095905318453 | validation: 0.0349662920030825]
	TIME [epoch: 9.09 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030235460455636843		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.030235460455636843 | validation: 0.06480005787492651]
	TIME [epoch: 9.08 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037917509831570946		[learning rate: 0.00080616]
	Learning Rate: 0.00080616
	LOSS [training: 0.037917509831570946 | validation: 0.057762600491473956]
	TIME [epoch: 9.08 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03296591392237181		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.03296591392237181 | validation: 0.039043898908745864]
	TIME [epoch: 9.08 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06520931202043082		[learning rate: 0.00080226]
	Learning Rate: 0.000802261
	LOSS [training: 0.06520931202043082 | validation: 0.18636788035222623]
	TIME [epoch: 9.08 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11215423272317197		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.11215423272317197 | validation: 0.1363206324014199]
	TIME [epoch: 9.1 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11377318721092648		[learning rate: 0.00079838]
	Learning Rate: 0.000798382
	LOSS [training: 0.11377318721092648 | validation: 0.12164715362111364]
	TIME [epoch: 9.09 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10986164482001279		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.10986164482001279 | validation: 0.1167154056815013]
	TIME [epoch: 9.08 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12969559714285342		[learning rate: 0.00079452]
	Learning Rate: 0.000794521
	LOSS [training: 0.12969559714285342 | validation: 0.10929082558611045]
	TIME [epoch: 9.07 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08895233275740182		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.08895233275740182 | validation: 0.08765145816714151]
	TIME [epoch: 9.07 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062027543662034425		[learning rate: 0.00079068]
	Learning Rate: 0.000790679
	LOSS [training: 0.062027543662034425 | validation: 0.0849600263094997]
	TIME [epoch: 9.09 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059025221401668326		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.059025221401668326 | validation: 0.06064930815244633]
	TIME [epoch: 9.08 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032293448014527236		[learning rate: 0.00078686]
	Learning Rate: 0.000786855
	LOSS [training: 0.032293448014527236 | validation: 0.037163500087447475]
	TIME [epoch: 9.06 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01755226255271955		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.01755226255271955 | validation: 0.03040772578908939]
	TIME [epoch: 9.08 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03180268060786129		[learning rate: 0.00078305]
	Learning Rate: 0.00078305
	LOSS [training: 0.03180268060786129 | validation: 0.04289632850376343]
	TIME [epoch: 9.09 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0404577170172579		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.0404577170172579 | validation: 0.05866531957680916]
	TIME [epoch: 9.07 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04391334669056605		[learning rate: 0.00077926]
	Learning Rate: 0.000779263
	LOSS [training: 0.04391334669056605 | validation: 0.034566077300489134]
	TIME [epoch: 9.07 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021804057373394053		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.021804057373394053 | validation: 0.030327189660585965]
	TIME [epoch: 9.07 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018402991758293952		[learning rate: 0.00077549]
	Learning Rate: 0.000775495
	LOSS [training: 0.018402991758293952 | validation: 0.02972224895984983]
	TIME [epoch: 9.08 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024267575157441865		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.024267575157441865 | validation: 0.03097451878757184]
	TIME [epoch: 9.1 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03571557183601086		[learning rate: 0.00077174]
	Learning Rate: 0.000771745
	LOSS [training: 0.03571557183601086 | validation: 0.03895800663811094]
	TIME [epoch: 9.08 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02182130319166494		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.02182130319166494 | validation: 0.02433976096643487]
	TIME [epoch: 9.07 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012793508471287043		[learning rate: 0.00076801]
	Learning Rate: 0.000768013
	LOSS [training: 0.012793508471287043 | validation: 0.012754658992631843]
	TIME [epoch: 9.07 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012826096348215136		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.012826096348215136 | validation: 0.025332660592208588]
	TIME [epoch: 9.09 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020051113477307918		[learning rate: 0.0007643]
	Learning Rate: 0.000764299
	LOSS [training: 0.020051113477307918 | validation: 0.024203744746679752]
	TIME [epoch: 9.08 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014169951085056023		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.014169951085056023 | validation: 0.024232351665243953]
	TIME [epoch: 9.08 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021246781210585503		[learning rate: 0.0007606]
	Learning Rate: 0.000760603
	LOSS [training: 0.021246781210585503 | validation: 0.0355713748894067]
	TIME [epoch: 9.08 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029546840710458166		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.029546840710458166 | validation: 0.056777254994855364]
	TIME [epoch: 9.07 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03763255907181785		[learning rate: 0.00075692]
	Learning Rate: 0.000756925
	LOSS [training: 0.03763255907181785 | validation: 0.032326882152226254]
	TIME [epoch: 9.09 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012923323089361652		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.012923323089361652 | validation: 0.02213623247124971]
	TIME [epoch: 9.08 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006260926557752055		[learning rate: 0.00075326]
	Learning Rate: 0.000753264
	LOSS [training: 0.006260926557752055 | validation: 0.032025104449073256]
	TIME [epoch: 9.08 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0106069247193159		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.0106069247193159 | validation: 0.03085488020935138]
	TIME [epoch: 9.09 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028989469438291483		[learning rate: 0.00074962]
	Learning Rate: 0.000749622
	LOSS [training: 0.028989469438291483 | validation: 0.0201036823070909]
	TIME [epoch: 9.09 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01949323848751326		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.01949323848751326 | validation: 0.031618311884168956]
	TIME [epoch: 9.09 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018431815540697206		[learning rate: 0.000746]
	Learning Rate: 0.000745997
	LOSS [training: 0.018431815540697206 | validation: 0.009995389655001671]
	TIME [epoch: 9.08 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011522943060164425		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.011522943060164425 | validation: 0.014163884486763903]
	TIME [epoch: 9.07 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01651173076941101		[learning rate: 0.00074239]
	Learning Rate: 0.000742389
	LOSS [training: 0.01651173076941101 | validation: 0.025273024587982085]
	TIME [epoch: 9.07 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021526887886251594		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.021526887886251594 | validation: 0.005319803947538568]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_1174.pth
	Model improved!!!
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011206412813219557		[learning rate: 0.0007388]
	Learning Rate: 0.000738799
	LOSS [training: 0.011206412813219557 | validation: 0.014541833000213084]
	TIME [epoch: 9.07 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008678753727919772		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.008678753727919772 | validation: 0.015521699438316904]
	TIME [epoch: 9.07 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019391189173528018		[learning rate: 0.00073523]
	Learning Rate: 0.000735226
	LOSS [training: 0.019391189173528018 | validation: 0.017805553523539124]
	TIME [epoch: 9.07 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023099187131216718		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.023099187131216718 | validation: 0.01503011342232365]
	TIME [epoch: 9.07 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013046320472567745		[learning rate: 0.00073167]
	Learning Rate: 0.000731671
	LOSS [training: 0.013046320472567745 | validation: 0.02880521985636765]
	TIME [epoch: 9.09 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01980590365774474		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.01980590365774474 | validation: 0.025417795317452686]
	TIME [epoch: 9.06 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02267775425473123		[learning rate: 0.00072813]
	Learning Rate: 0.000728133
	LOSS [training: 0.02267775425473123 | validation: 0.03251560299288751]
	TIME [epoch: 9.07 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006641022634710452		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.006641022634710452 | validation: 0.016877403171261594]
	TIME [epoch: 9.07 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007724872338121876		[learning rate: 0.00072461]
	Learning Rate: 0.000724612
	LOSS [training: 0.007724872338121876 | validation: 0.009122471253410296]
	TIME [epoch: 9.09 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019800786277015408		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.019800786277015408 | validation: 0.017461154826772497]
	TIME [epoch: 9.07 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010447554636256965		[learning rate: 0.00072111]
	Learning Rate: 0.000721107
	LOSS [training: 0.010447554636256965 | validation: 0.027967294985020034]
	TIME [epoch: 9.07 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01668106312841794		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.01668106312841794 | validation: 0.02630604301627835]
	TIME [epoch: 9.07 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028959698274523216		[learning rate: 0.00071762]
	Learning Rate: 0.00071762
	LOSS [training: 0.028959698274523216 | validation: 0.027830206641766837]
	TIME [epoch: 9.06 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02859279003551373		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.02859279003551373 | validation: 0.017880855164783084]
	TIME [epoch: 9.08 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020212464113715023		[learning rate: 0.00071415]
	Learning Rate: 0.00071415
	LOSS [training: 0.020212464113715023 | validation: 0.012511983518790458]
	TIME [epoch: 9.07 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011673364910260817		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.011673364910260817 | validation: 0.015606252218750574]
	TIME [epoch: 9.07 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014850040232591627		[learning rate: 0.0007107]
	Learning Rate: 0.000710697
	LOSS [training: 0.014850040232591627 | validation: 0.01844226891862244]
	TIME [epoch: 9.07 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01224383552277387		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.01224383552277387 | validation: 0.029726623238976214]
	TIME [epoch: 9.08 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01483514799937741		[learning rate: 0.00070726]
	Learning Rate: 0.00070726
	LOSS [training: 0.01483514799937741 | validation: 0.02957590563662224]
	TIME [epoch: 9.07 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018158933332315358		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.018158933332315358 | validation: 0.02133345102006301]
	TIME [epoch: 9.07 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01670916078968898		[learning rate: 0.00070384]
	Learning Rate: 0.00070384
	LOSS [training: 0.01670916078968898 | validation: 0.02632703678039009]
	TIME [epoch: 9.07 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013669176650190795		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.013669176650190795 | validation: 0.03734966537758205]
	TIME [epoch: 9.08 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03714428707921593		[learning rate: 0.00070044]
	Learning Rate: 0.000700436
	LOSS [training: 0.03714428707921593 | validation: 0.03480705781226877]
	TIME [epoch: 9.09 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03278736911387971		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.03278736911387971 | validation: 0.0371037638203745]
	TIME [epoch: 9.07 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01778060629001111		[learning rate: 0.00069705]
	Learning Rate: 0.000697049
	LOSS [training: 0.01778060629001111 | validation: 0.020733773323794447]
	TIME [epoch: 9.06 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01607731101472621		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.01607731101472621 | validation: 0.0299785544913155]
	TIME [epoch: 9.06 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025379375948930288		[learning rate: 0.00069368]
	Learning Rate: 0.000693678
	LOSS [training: 0.025379375948930288 | validation: 0.04830808285362709]
	TIME [epoch: 9.08 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03378752553663239		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.03378752553663239 | validation: 0.03371708643020338]
	TIME [epoch: 9.08 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024988242314568747		[learning rate: 0.00069032]
	Learning Rate: 0.000690324
	LOSS [training: 0.024988242314568747 | validation: 0.026635697521142542]
	TIME [epoch: 9.06 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020478867145695977		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.020478867145695977 | validation: 0.023824176768789385]
	TIME [epoch: 9.06 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011732737517716908		[learning rate: 0.00068699]
	Learning Rate: 0.000686985
	LOSS [training: 0.011732737517716908 | validation: 0.017079561654409575]
	TIME [epoch: 9.06 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010472701169047544		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.010472701169047544 | validation: 0.018593804525449866]
	TIME [epoch: 9.08 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018303870366147286		[learning rate: 0.00068366]
	Learning Rate: 0.000683663
	LOSS [training: 0.018303870366147286 | validation: 0.02541167624701347]
	TIME [epoch: 9.06 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015107283268270284		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.015107283268270284 | validation: 0.025174550499210014]
	TIME [epoch: 9.07 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01847350598000131		[learning rate: 0.00068036]
	Learning Rate: 0.000680357
	LOSS [training: 0.01847350598000131 | validation: 0.01551626053931921]
	TIME [epoch: 9.07 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01266080783174102		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.01266080783174102 | validation: 0.01289704919111606]
	TIME [epoch: 9.07 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017426563543741092		[learning rate: 0.00067707]
	Learning Rate: 0.000677067
	LOSS [training: 0.0017426563543741092 | validation: 0.005231404458186114]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_1211.pth
	Model improved!!!
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003303899673286125		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.003303899673286125 | validation: 0.015516148222530493]
	TIME [epoch: 9.08 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006639564693982825		[learning rate: 0.00067379]
	Learning Rate: 0.000673793
	LOSS [training: 0.006639564693982825 | validation: 0.012937447015308355]
	TIME [epoch: 9.07 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005876991797138438		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.005876991797138438 | validation: 0.014789384349425973]
	TIME [epoch: 9.08 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013215280384725903		[learning rate: 0.00067053]
	Learning Rate: 0.000670534
	LOSS [training: 0.013215280384725903 | validation: 0.008938621735301546]
	TIME [epoch: 9.1 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0066784883895055075		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.0066784883895055075 | validation: 0.016996104760792205]
	TIME [epoch: 9.09 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005014438251628422		[learning rate: 0.00066729]
	Learning Rate: 0.000667292
	LOSS [training: 0.005014438251628422 | validation: 0.017748441728342612]
	TIME [epoch: 9.08 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003955347946999986		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.003955347946999986 | validation: 0.016809622243516495]
	TIME [epoch: 9.07 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005664164667283736		[learning rate: 0.00066406]
	Learning Rate: 0.000664065
	LOSS [training: 0.005664164667283736 | validation: 0.01887406581368458]
	TIME [epoch: 9.07 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010406899096921433		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.010406899096921433 | validation: 0.006356412018249991]
	TIME [epoch: 9.1 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0011393698808695462		[learning rate: 0.00066085]
	Learning Rate: 0.000660854
	LOSS [training: 0.0011393698808695462 | validation: 0.012106537705150903]
	TIME [epoch: 9.08 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014584629400557148		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.014584629400557148 | validation: 0.020754889582148054]
	TIME [epoch: 9.08 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009226520959960838		[learning rate: 0.00065766]
	Learning Rate: 0.000657658
	LOSS [training: 0.009226520959960838 | validation: 0.014194289439166528]
	TIME [epoch: 9.08 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006039694706758957		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.006039694706758957 | validation: 0.01762042477021861]
	TIME [epoch: 9.1 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02571488149486757		[learning rate: 0.00065448]
	Learning Rate: 0.000654478
	LOSS [training: 0.02571488149486757 | validation: 0.045401515760830805]
	TIME [epoch: 9.08 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029612723302674292		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.029612723302674292 | validation: 0.025614752198324056]
	TIME [epoch: 9.07 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038513251149624714		[learning rate: 0.00065131]
	Learning Rate: 0.000651313
	LOSS [training: 0.038513251149624714 | validation: 0.04399346660562417]
	TIME [epoch: 9.07 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03728783444756327		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.03728783444756327 | validation: 0.035582513797316806]
	TIME [epoch: 9.07 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026088098764352592		[learning rate: 0.00064816]
	Learning Rate: 0.000648163
	LOSS [training: 0.026088098764352592 | validation: 0.013359407398209172]
	TIME [epoch: 9.09 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013175461423501964		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.013175461423501964 | validation: 0.021340647744592704]
	TIME [epoch: 9.08 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009767977210376075		[learning rate: 0.00064503]
	Learning Rate: 0.000645029
	LOSS [training: 0.009767977210376075 | validation: 0.011412311739461842]
	TIME [epoch: 9.08 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012184231254534451		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.012184231254534451 | validation: 0.01201159614885754]
	TIME [epoch: 9.08 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010870827316979647		[learning rate: 0.00064191]
	Learning Rate: 0.000641909
	LOSS [training: 0.010870827316979647 | validation: 0.01343723356716242]
	TIME [epoch: 9.1 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02433818893695329		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.02433818893695329 | validation: 0.025983717659503653]
	TIME [epoch: 9.09 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015443895532227811		[learning rate: 0.00063881]
	Learning Rate: 0.000638805
	LOSS [training: 0.015443895532227811 | validation: 0.01695825240407811]
	TIME [epoch: 9.08 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01925432623470563		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.01925432623470563 | validation: 0.0238814294232622]
	TIME [epoch: 9.08 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04156876786128348		[learning rate: 0.00063572]
	Learning Rate: 0.000635716
	LOSS [training: 0.04156876786128348 | validation: 0.058108757354669305]
	TIME [epoch: 9.08 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027303463428754143		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.027303463428754143 | validation: 0.01185538759848117]
	TIME [epoch: 9.09 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009349195425039408		[learning rate: 0.00063264]
	Learning Rate: 0.000632642
	LOSS [training: 0.009349195425039408 | validation: 0.026690163658618673]
	TIME [epoch: 9.08 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008599448896384993		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.008599448896384993 | validation: 0.010976491604683822]
	TIME [epoch: 9.07 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009260225923011303		[learning rate: 0.00062958]
	Learning Rate: 0.000629582
	LOSS [training: -0.0009260225923011303 | validation: 0.012270908290917381]
	TIME [epoch: 9.07 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009714814776652236		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.009714814776652236 | validation: 0.02470997340080002]
	TIME [epoch: 9.09 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010624921110245192		[learning rate: 0.00062654]
	Learning Rate: 0.000626538
	LOSS [training: 0.010624921110245192 | validation: 0.008872664672396682]
	TIME [epoch: 9.09 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0026891220752227663		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.0026891220752227663 | validation: 0.01177030659705753]
	TIME [epoch: 9.08 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013809015903745031		[learning rate: 0.00062351]
	Learning Rate: 0.000623508
	LOSS [training: 0.013809015903745031 | validation: 0.03163820425751715]
	TIME [epoch: 9.08 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006987224307080854		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.006987224307080854 | validation: 0.015173101830315058]
	TIME [epoch: 9.08 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012964503776632875		[learning rate: 0.00062049]
	Learning Rate: 0.000620493
	LOSS [training: 0.012964503776632875 | validation: 0.0109656175368258]
	TIME [epoch: 9.1 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016786129012138724		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.016786129012138724 | validation: 0.0336126124589782]
	TIME [epoch: 9.08 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029474146973754816		[learning rate: 0.00061749]
	Learning Rate: 0.000617492
	LOSS [training: 0.029474146973754816 | validation: 0.024500096381611616]
	TIME [epoch: 9.09 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03402808790717752		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.03402808790717752 | validation: 0.04346038116308313]
	TIME [epoch: 9.08 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021260157739280878		[learning rate: 0.00061451]
	Learning Rate: 0.000614506
	LOSS [training: 0.021260157739280878 | validation: 0.04371939753209874]
	TIME [epoch: 9.08 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028385537761877556		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: 0.028385537761877556 | validation: 0.027983709906243527]
	TIME [epoch: 9.1 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021307474746160165		[learning rate: 0.00061153]
	Learning Rate: 0.000611535
	LOSS [training: 0.021307474746160165 | validation: 0.019509858928548444]
	TIME [epoch: 9.08 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008984181611455342		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.008984181611455342 | validation: 0.016029427241636408]
	TIME [epoch: 9.08 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006913805238415949		[learning rate: 0.00060858]
	Learning Rate: 0.000608577
	LOSS [training: 0.006913805238415949 | validation: 0.023250096808781633]
	TIME [epoch: 9.08 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018748480757363843		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.018748480757363843 | validation: 0.028373027598484486]
	TIME [epoch: 9.09 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015676330613848936		[learning rate: 0.00060563]
	Learning Rate: 0.000605634
	LOSS [training: 0.015676330613848936 | validation: 0.015615527830926467]
	TIME [epoch: 9.08 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014078053716267988		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.014078053716267988 | validation: 0.018910133822089087]
	TIME [epoch: 9.08 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016000243061383423		[learning rate: 0.00060271]
	Learning Rate: 0.000602706
	LOSS [training: 0.016000243061383423 | validation: 0.022313443712122148]
	TIME [epoch: 9.08 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013605146114465758		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.013605146114465758 | validation: 0.01454598492573036]
	TIME [epoch: 9.09 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013417361002368549		[learning rate: 0.00059979]
	Learning Rate: 0.000599791
	LOSS [training: 0.013417361002368549 | validation: 0.025165488515426958]
	TIME [epoch: 9.11 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020555827862569532		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.020555827862569532 | validation: 0.044586329982350514]
	TIME [epoch: 9.09 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044269462654539224		[learning rate: 0.00059689]
	Learning Rate: 0.000596891
	LOSS [training: 0.044269462654539224 | validation: 0.044522563603270254]
	TIME [epoch: 9.08 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028195974204622932		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.028195974204622932 | validation: 0.04320034906772443]
	TIME [epoch: 9.08 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03667457530073713		[learning rate: 0.000594]
	Learning Rate: 0.000594004
	LOSS [training: 0.03667457530073713 | validation: 0.0553891163630415]
	TIME [epoch: 9.1 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034865328930577824		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.034865328930577824 | validation: 0.04388917867396209]
	TIME [epoch: 9.08 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04293992295138188		[learning rate: 0.00059113]
	Learning Rate: 0.000591132
	LOSS [training: 0.04293992295138188 | validation: 0.08819370571958308]
	TIME [epoch: 9.09 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0703813305570735		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.0703813305570735 | validation: 0.0879843164559784]
	TIME [epoch: 9.08 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07516958318457942		[learning rate: 0.00058827]
	Learning Rate: 0.000588273
	LOSS [training: 0.07516958318457942 | validation: 0.10061321345977858]
	TIME [epoch: 9.09 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06542646096401634		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.06542646096401634 | validation: 0.04274713441277116]
	TIME [epoch: 9.1 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036572920706962955		[learning rate: 0.00058543]
	Learning Rate: 0.000585428
	LOSS [training: 0.036572920706962955 | validation: 0.035069758320497184]
	TIME [epoch: 9.08 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040965778026182176		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.040965778026182176 | validation: 0.06046443690251706]
	TIME [epoch: 9.08 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03175311029710877		[learning rate: 0.0005826]
	Learning Rate: 0.000582597
	LOSS [training: 0.03175311029710877 | validation: 0.039240742046265854]
	TIME [epoch: 9.08 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04325471298023226		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.04325471298023226 | validation: 0.07220621161549498]
	TIME [epoch: 9.1 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09182891549424722		[learning rate: 0.00057978]
	Learning Rate: 0.00057978
	LOSS [training: 0.09182891549424722 | validation: 0.09798283052021466]
	TIME [epoch: 9.1 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0977514567616681		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.0977514567616681 | validation: 0.08351693037201272]
	TIME [epoch: 9.08 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08179413787904982		[learning rate: 0.00057698]
	Learning Rate: 0.000576976
	LOSS [training: 0.08179413787904982 | validation: 0.04519357498094998]
	TIME [epoch: 9.08 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0563646202307293		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.0563646202307293 | validation: 0.06503127576213714]
	TIME [epoch: 9.08 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06172819943724435		[learning rate: 0.00057419]
	Learning Rate: 0.000574186
	LOSS [training: 0.06172819943724435 | validation: 0.08805784572004628]
	TIME [epoch: 9.1 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05452122225789091		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.05452122225789091 | validation: 0.04768388334158341]
	TIME [epoch: 9.09 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07327502658979901		[learning rate: 0.00057141]
	Learning Rate: 0.000571409
	LOSS [training: 0.07327502658979901 | validation: 0.10288965764134178]
	TIME [epoch: 9.09 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06731796311496506		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.06731796311496506 | validation: 0.06877617290903039]
	TIME [epoch: 9.08 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0439183875377951		[learning rate: 0.00056865]
	Learning Rate: 0.000568646
	LOSS [training: 0.0439183875377951 | validation: 0.040074067886603684]
	TIME [epoch: 9.1 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03215808127346988		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.03215808127346988 | validation: 0.057053592234570655]
	TIME [epoch: 9.1 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06080197265755207		[learning rate: 0.0005659]
	Learning Rate: 0.000565896
	LOSS [training: 0.06080197265755207 | validation: 0.085332649086854]
	TIME [epoch: 9.08 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07666370299769765		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.07666370299769765 | validation: 0.09262007304020792]
	TIME [epoch: 9.09 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07719477345376365		[learning rate: 0.00056316]
	Learning Rate: 0.00056316
	LOSS [training: 0.07719477345376365 | validation: 0.09117504229954818]
	TIME [epoch: 9.08 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060682812338145466		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.060682812338145466 | validation: 0.055110163536173803]
	TIME [epoch: 9.12 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03841276067951743		[learning rate: 0.00056044]
	Learning Rate: 0.000560436
	LOSS [training: 0.03841276067951743 | validation: 0.03976584450129367]
	TIME [epoch: 9.09 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02926283173811662		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.02926283173811662 | validation: 0.02546952692403205]
	TIME [epoch: 9.09 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01885434289017671		[learning rate: 0.00055773]
	Learning Rate: 0.000557726
	LOSS [training: 0.01885434289017671 | validation: 0.021269041017319624]
	TIME [epoch: 9.08 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02022877773305525		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.02022877773305525 | validation: 0.025803547047006083]
	TIME [epoch: 9.09 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016067881320915408		[learning rate: 0.00055503]
	Learning Rate: 0.000555029
	LOSS [training: 0.016067881320915408 | validation: 0.0286690030781696]
	TIME [epoch: 9.11 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022055938652535148		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.022055938652535148 | validation: 0.013851983737982]
	TIME [epoch: 9.08 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010579089238174738		[learning rate: 0.00055235]
	Learning Rate: 0.000552345
	LOSS [training: 0.010579089238174738 | validation: 0.04495530581507012]
	TIME [epoch: 9.09 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047613904397363155		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.047613904397363155 | validation: 0.08550591364459262]
	TIME [epoch: 9.08 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05224841701563222		[learning rate: 0.00054967]
	Learning Rate: 0.000549674
	LOSS [training: 0.05224841701563222 | validation: 0.05092656622755245]
	TIME [epoch: 9.1 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03342641394812306		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.03342641394812306 | validation: 0.046631934120637285]
	TIME [epoch: 9.09 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03293451041158561		[learning rate: 0.00054702]
	Learning Rate: 0.000547016
	LOSS [training: 0.03293451041158561 | validation: 0.02878068756479521]
	TIME [epoch: 9.08 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03015097204770616		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.03015097204770616 | validation: 0.034003269035681315]
	TIME [epoch: 9.09 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032900936441670296		[learning rate: 0.00054437]
	Learning Rate: 0.000544371
	LOSS [training: 0.032900936441670296 | validation: 0.04532571339309654]
	TIME [epoch: 9.09 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017772397129631513		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.017772397129631513 | validation: 0.024157497067026468]
	TIME [epoch: 9.1 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02035411287072721		[learning rate: 0.00054174]
	Learning Rate: 0.000541738
	LOSS [training: 0.02035411287072721 | validation: 0.050122880532434425]
	TIME [epoch: 9.09 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03475714829923899		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.03475714829923899 | validation: 0.047588941643636695]
	TIME [epoch: 9.08 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0413723674784301		[learning rate: 0.00053912]
	Learning Rate: 0.000539118
	LOSS [training: 0.0413723674784301 | validation: 0.04183408899065691]
	TIME [epoch: 9.08 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03715643565810668		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.03715643565810668 | validation: 0.04269158892833325]
	TIME [epoch: 9.1 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04032383172521138		[learning rate: 0.00053651]
	Learning Rate: 0.000536511
	LOSS [training: 0.04032383172521138 | validation: 0.07193667725347302]
	TIME [epoch: 9.08 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06609701498754675		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.06609701498754675 | validation: 0.08498769930290095]
	TIME [epoch: 9.08 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05486060599204039		[learning rate: 0.00053392]
	Learning Rate: 0.000533917
	LOSS [training: 0.05486060599204039 | validation: 0.05878297690138004]
	TIME [epoch: 9.08 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06188344979927316		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.06188344979927316 | validation: 0.08205312718875624]
	TIME [epoch: 9.08 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0392452321549376		[learning rate: 0.00053134]
	Learning Rate: 0.000531335
	LOSS [training: 0.0392452321549376 | validation: 0.034864360904103206]
	TIME [epoch: 9.1 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021831162635306482		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.021831162635306482 | validation: 0.022868683854226923]
	TIME [epoch: 9.09 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016399440293805627		[learning rate: 0.00052877]
	Learning Rate: 0.000528766
	LOSS [training: 0.016399440293805627 | validation: 0.018549202953231116]
	TIME [epoch: 9.09 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015080792502410414		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.015080792502410414 | validation: 0.029974570498331764]
	TIME [epoch: 9.08 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02919022275778594		[learning rate: 0.00052621]
	Learning Rate: 0.000526208
	LOSS [training: 0.02919022275778594 | validation: 0.042128107208433574]
	TIME [epoch: 9.1 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01979990317649511		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.01979990317649511 | validation: 0.027051130409280144]
	TIME [epoch: 9.09 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020028905758023956		[learning rate: 0.00052366]
	Learning Rate: 0.000523664
	LOSS [training: 0.020028905758023956 | validation: 0.019936399266375835]
	TIME [epoch: 9.08 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024772101297008325		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.024772101297008325 | validation: 0.03536284530372133]
	TIME [epoch: 9.08 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02310438590911442		[learning rate: 0.00052113]
	Learning Rate: 0.000521132
	LOSS [training: 0.02310438590911442 | validation: 0.02952260887997272]
	TIME [epoch: 9.08 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028868613999034815		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.028868613999034815 | validation: 0.053247764308693685]
	TIME [epoch: 9.1 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036815415043567785		[learning rate: 0.00051861]
	Learning Rate: 0.000518611
	LOSS [training: 0.036815415043567785 | validation: 0.033540321828325476]
	TIME [epoch: 9.08 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018522670521731743		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.018522670521731743 | validation: 0.018647848370543417]
	TIME [epoch: 9.08 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01610185599913979		[learning rate: 0.0005161]
	Learning Rate: 0.000516104
	LOSS [training: 0.01610185599913979 | validation: 0.02363068451280277]
	TIME [epoch: 9.08 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013379714178746088		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.013379714178746088 | validation: 0.025175958754458674]
	TIME [epoch: 9.08 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015385168342890606		[learning rate: 0.00051361]
	Learning Rate: 0.000513608
	LOSS [training: 0.015385168342890606 | validation: 0.015546029473834098]
	TIME [epoch: 9.1 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0074855661202088124		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.0074855661202088124 | validation: 0.006813479109982338]
	TIME [epoch: 9.08 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008496579670294872		[learning rate: 0.00051112]
	Learning Rate: 0.000511124
	LOSS [training: 0.008496579670294872 | validation: 0.00848011776125375]
	TIME [epoch: 9.08 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006332806969214866		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.006332806969214866 | validation: 0.011755334992173782]
	TIME [epoch: 9.08 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008753275561796127		[learning rate: 0.00050865]
	Learning Rate: 0.000508652
	LOSS [training: 0.008753275561796127 | validation: 0.014104822008682363]
	TIME [epoch: 9.1 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009975465870672835		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.009975465870672835 | validation: 0.013004911951671779]
	TIME [epoch: 9.07 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01351365055930782		[learning rate: 0.00050619]
	Learning Rate: 0.000506193
	LOSS [training: 0.01351365055930782 | validation: 0.011572357636981962]
	TIME [epoch: 9.08 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013090617448906		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.013090617448906 | validation: 0.016743620095881435]
	TIME [epoch: 9.08 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01089919865401929		[learning rate: 0.00050374]
	Learning Rate: 0.000503745
	LOSS [training: 0.01089919865401929 | validation: 0.00865832520152639]
	TIME [epoch: 9.08 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005137169134332056		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.005137169134332056 | validation: 0.020670742278864083]
	TIME [epoch: 9.1 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0036677594541925677		[learning rate: 0.00050131]
	Learning Rate: 0.000501309
	LOSS [training: 0.0036677594541925677 | validation: 0.012432133352151861]
	TIME [epoch: 9.08 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008462431663597569		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: 0.008462431663597569 | validation: 0.011671750131806422]
	TIME [epoch: 9.07 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005748708452010844		[learning rate: 0.00049888]
	Learning Rate: 0.000498885
	LOSS [training: 0.005748708452010844 | validation: -0.00048237862475644547]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_1337.pth
	Model improved!!!
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00618094526561294		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.00618094526561294 | validation: 0.007641122478330364]
	TIME [epoch: 9.09 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007698512742384908		[learning rate: 0.00049647]
	Learning Rate: 0.000496472
	LOSS [training: 0.007698512742384908 | validation: 0.018076715396522745]
	TIME [epoch: 9.08 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01996586411497885		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.01996586411497885 | validation: 0.024563718954887202]
	TIME [epoch: 9.06 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01653678254422442		[learning rate: 0.00049407]
	Learning Rate: 0.000494071
	LOSS [training: 0.01653678254422442 | validation: 0.028985671889918463]
	TIME [epoch: 9.07 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01957887960465523		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.01957887960465523 | validation: 0.02451870544498448]
	TIME [epoch: 9.06 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007044783995859757		[learning rate: 0.00049168]
	Learning Rate: 0.000491682
	LOSS [training: 0.007044783995859757 | validation: 0.013430795065977193]
	TIME [epoch: 9.09 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011915953684624097		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.011915953684624097 | validation: 0.011429943125741228]
	TIME [epoch: 9.07 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01139809705581558		[learning rate: 0.0004893]
	Learning Rate: 0.000489304
	LOSS [training: 0.01139809705581558 | validation: 0.01055911091287074]
	TIME [epoch: 9.06 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0011301820747469484		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.0011301820747469484 | validation: 0.013526308411909771]
	TIME [epoch: 9.07 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007390620971945564		[learning rate: 0.00048694]
	Learning Rate: 0.000486938
	LOSS [training: 0.007390620971945564 | validation: 0.020979666887238055]
	TIME [epoch: 9.09 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015132890232933276		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.015132890232933276 | validation: 0.018093538014037715]
	TIME [epoch: 9.06 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017285402554278868		[learning rate: 0.00048458]
	Learning Rate: 0.000484583
	LOSS [training: 0.017285402554278868 | validation: 0.0523103828506323]
	TIME [epoch: 9.07 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03440408405429368		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.03440408405429368 | validation: 0.04624438344650021]
	TIME [epoch: 9.06 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029169059838571803		[learning rate: 0.00048224]
	Learning Rate: 0.00048224
	LOSS [training: 0.029169059838571803 | validation: 0.03267919082930054]
	TIME [epoch: 9.07 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021174035392293556		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.021174035392293556 | validation: 0.020196763706224544]
	TIME [epoch: 9.09 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015111348116390417		[learning rate: 0.00047991]
	Learning Rate: 0.000479908
	LOSS [training: 0.015111348116390417 | validation: 0.01739479053658931]
	TIME [epoch: 9.08 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006539407772293194		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: 0.006539407772293194 | validation: 0.017095441328404553]
	TIME [epoch: 9.07 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00861780211231906		[learning rate: 0.00047759]
	Learning Rate: 0.000477587
	LOSS [training: 0.00861780211231906 | validation: 0.018791135463864073]
	TIME [epoch: 9.06 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00594731308581913		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.00594731308581913 | validation: 0.02432627610002103]
	TIME [epoch: 9.08 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0046229294271524		[learning rate: 0.00047528]
	Learning Rate: 0.000475278
	LOSS [training: 0.0046229294271524 | validation: 0.011305050790044999]
	TIME [epoch: 9.07 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015240493858102572		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.015240493858102572 | validation: 0.023484192101825833]
	TIME [epoch: 9.06 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016073833046117033		[learning rate: 0.00047298]
	Learning Rate: 0.000472979
	LOSS [training: 0.016073833046117033 | validation: 0.014347468517984754]
	TIME [epoch: 9.07 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003263286032296142		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.003263286032296142 | validation: 0.021723098814298868]
	TIME [epoch: 9.06 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005080600949714608		[learning rate: 0.00047069]
	Learning Rate: 0.000470692
	LOSS [training: 0.005080600949714608 | validation: 0.012378038945234317]
	TIME [epoch: 9.09 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004201032351062617		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: 0.004201032351062617 | validation: 0.00701274577496749]
	TIME [epoch: 9.07 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004832186393659796		[learning rate: 0.00046842]
	Learning Rate: 0.000468416
	LOSS [training: 0.004832186393659796 | validation: 0.014047770530148058]
	TIME [epoch: 9.07 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006175401671511167		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: 0.006175401671511167 | validation: 0.01636172114351409]
	TIME [epoch: 9.07 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010533022571790998		[learning rate: 0.00046615]
	Learning Rate: 0.000466151
	LOSS [training: 0.010533022571790998 | validation: 0.003761410460795665]
	TIME [epoch: 9.08 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004832354803126953		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 0.004832354803126953 | validation: 0.007730159017563921]
	TIME [epoch: 9.1 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014985571978435666		[learning rate: 0.0004639]
	Learning Rate: 0.000463896
	LOSS [training: 0.0014985571978435666 | validation: 0.012967950525389516]
	TIME [epoch: 9.07 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004275179807239811		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: 0.004275179807239811 | validation: 0.014407102818768659]
	TIME [epoch: 9.07 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01113760968147914		[learning rate: 0.00046165]
	Learning Rate: 0.000461653
	LOSS [training: 0.01113760968147914 | validation: 0.02118399887726378]
	TIME [epoch: 9.06 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010733408891857577		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.010733408891857577 | validation: 0.021359614276497074]
	TIME [epoch: 9.08 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00983985297576078		[learning rate: 0.00045942]
	Learning Rate: 0.000459421
	LOSS [training: 0.00983985297576078 | validation: 0.023567995203019464]
	TIME [epoch: 9.07 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005493293150745003		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.005493293150745003 | validation: 0.022041311974940934]
	TIME [epoch: 9.07 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008930789056064594		[learning rate: 0.0004572]
	Learning Rate: 0.000457199
	LOSS [training: 0.008930789056064594 | validation: 0.015927627246424318]
	TIME [epoch: 9.07 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007283321104886237		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.007283321104886237 | validation: 0.014926784127900834]
	TIME [epoch: 9.07 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0023083247266565917		[learning rate: 0.00045499]
	Learning Rate: 0.000454988
	LOSS [training: 0.0023083247266565917 | validation: 0.015338297856901167]
	TIME [epoch: 9.08 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007627497731604116		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: -0.0007627497731604116 | validation: 0.0144542380776603]
	TIME [epoch: 9.07 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.000811541297107274		[learning rate: 0.00045279]
	Learning Rate: 0.000452788
	LOSS [training: -0.000811541297107274 | validation: 0.007660949418146599]
	TIME [epoch: 9.07 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0025595790085069904		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.0025595790085069904 | validation: 0.0030763981722044067]
	TIME [epoch: 9.07 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015379467079612436		[learning rate: 0.0004506]
	Learning Rate: 0.000450598
	LOSS [training: 0.0015379467079612436 | validation: -0.001305629215188062]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_1379.pth
	Model improved!!!
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0014134061665002104		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: -0.0014134061665002104 | validation: 0.006927812301260739]
	TIME [epoch: 9.07 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004058927382487471		[learning rate: 0.00044842]
	Learning Rate: 0.000448419
	LOSS [training: 0.004058927382487471 | validation: 0.01184027543912636]
	TIME [epoch: 9.07 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008005705488033072		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.008005705488033072 | validation: 0.007242678188108556]
	TIME [epoch: 9.07 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005492035516188235		[learning rate: 0.00044625]
	Learning Rate: 0.000446251
	LOSS [training: 0.005492035516188235 | validation: 0.0051850344255983975]
	TIME [epoch: 9.06 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003154329902227112		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.003154329902227112 | validation: 0.008559825550573667]
	TIME [epoch: 9.08 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019397698798811244		[learning rate: 0.00044409]
	Learning Rate: 0.000444093
	LOSS [training: 0.0019397698798811244 | validation: 0.014181511707309535]
	TIME [epoch: 9.07 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00015660986221288954		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: -0.00015660986221288954 | validation: 0.004246978568712851]
	TIME [epoch: 9.07 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017592425186575042		[learning rate: 0.00044195]
	Learning Rate: 0.000441945
	LOSS [training: 0.0017592425186575042 | validation: 0.013608130060400762]
	TIME [epoch: 9.07 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005365442417556277		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.005365442417556277 | validation: 0.012728593712575587]
	TIME [epoch: 9.08 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005057585403128707		[learning rate: 0.00043981]
	Learning Rate: 0.000439808
	LOSS [training: 0.005057585403128707 | validation: 0.017954350252690897]
	TIME [epoch: 9.08 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0039231962333543405		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.0039231962333543405 | validation: 0.015178959413768605]
	TIME [epoch: 9.07 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00308066937719465		[learning rate: 0.00043768]
	Learning Rate: 0.000437681
	LOSS [training: 0.00308066937719465 | validation: 0.00981443125813896]
	TIME [epoch: 9.07 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0014143911482568283		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: -0.0014143911482568283 | validation: 0.013094062019604202]
	TIME [epoch: 9.08 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009855640531598818		[learning rate: 0.00043556]
	Learning Rate: 0.000435565
	LOSS [training: 0.0009855640531598818 | validation: -0.010567204396879868]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_1393.pth
	Model improved!!!
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0001484225095337733		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: -0.0001484225095337733 | validation: 0.007353959175512495]
	TIME [epoch: 9.07 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005203831593690952		[learning rate: 0.00043346]
	Learning Rate: 0.000433458
	LOSS [training: 0.005203831593690952 | validation: 0.015710939958765442]
	TIME [epoch: 9.1 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005348166339412952		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.005348166339412952 | validation: 0.010368029529859095]
	TIME [epoch: 9.06 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005670254022464155		[learning rate: 0.00043136]
	Learning Rate: 0.000431362
	LOSS [training: 0.005670254022464155 | validation: 0.012890825112587535]
	TIME [epoch: 9.08 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009861876064175344		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.009861876064175344 | validation: 0.016369839298188738]
	TIME [epoch: 9.08 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0036463355472626637		[learning rate: 0.00042928]
	Learning Rate: 0.000429276
	LOSS [training: 0.0036463355472626637 | validation: 0.012133798204521633]
	TIME [epoch: 9.06 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005171623328697132		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: 0.005171623328697132 | validation: 0.0036788279984578433]
	TIME [epoch: 9.07 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009436034899291897		[learning rate: 0.0004272]
	Learning Rate: 0.0004272
	LOSS [training: 0.009436034899291897 | validation: 0.008098339375827473]
	TIME [epoch: 9.05 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005696104849073026		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.005696104849073026 | validation: 0.023345126113861463]
	TIME [epoch: 9.08 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011252639734962063		[learning rate: 0.00042513]
	Learning Rate: 0.000425134
	LOSS [training: 0.011252639734962063 | validation: 0.016271726770125786]
	TIME [epoch: 9.06 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006341286556649381		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: 0.006341286556649381 | validation: 0.004238463966431192]
	TIME [epoch: 9.06 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002749141664057522		[learning rate: 0.00042308]
	Learning Rate: 0.000423079
	LOSS [training: 0.002749141664057522 | validation: 0.013243171229746307]
	TIME [epoch: 9.08 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010821825609153088		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.010821825609153088 | validation: -0.0009831269976038532]
	TIME [epoch: 9.07 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003509751504863765		[learning rate: 0.00042103]
	Learning Rate: 0.000421033
	LOSS [training: 0.003509751504863765 | validation: 0.011573460331433593]
	TIME [epoch: 9.09 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007702357249539038		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: -0.0007702357249539038 | validation: 0.020990879599285937]
	TIME [epoch: 9.07 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003586577501559637		[learning rate: 0.000419]
	Learning Rate: 0.000418997
	LOSS [training: 0.003586577501559637 | validation: -0.0011762870307068783]
	TIME [epoch: 9.06 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005804675782239395		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.005804675782239395 | validation: 0.005875289452418342]
	TIME [epoch: 9.07 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005696100458071789		[learning rate: 0.00041697]
	Learning Rate: 0.00041697
	LOSS [training: 0.005696100458071789 | validation: 0.013903328343347059]
	TIME [epoch: 9.09 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008442238017214216		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.008442238017214216 | validation: 0.0011383028225539285]
	TIME [epoch: 9.06 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01154445153385807		[learning rate: 0.00041495]
	Learning Rate: 0.000414954
	LOSS [training: 0.01154445153385807 | validation: 0.01547782286275785]
	TIME [epoch: 9.07 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007440669875204679		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.007440669875204679 | validation: 0.007732541670936083]
	TIME [epoch: 9.07 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004464030554518689		[learning rate: 0.00041295]
	Learning Rate: 0.000412947
	LOSS [training: -0.004464030554518689 | validation: 0.011994210663405213]
	TIME [epoch: 9.06 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005782960108562218		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.005782960108562218 | validation: 0.010807490309214612]
	TIME [epoch: 9.09 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009000274877513764		[learning rate: 0.00041095]
	Learning Rate: 0.00041095
	LOSS [training: 0.009000274877513764 | validation: 0.023255342013908747]
	TIME [epoch: 9.07 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013110541228366995		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.013110541228366995 | validation: 0.013561208772802362]
	TIME [epoch: 9.07 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010326726703864518		[learning rate: 0.00040896]
	Learning Rate: 0.000408963
	LOSS [training: 0.010326726703864518 | validation: 0.021144938932115623]
	TIME [epoch: 9.07 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00925832876768803		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.00925832876768803 | validation: 0.021805290896899754]
	TIME [epoch: 9.09 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01543317619914622		[learning rate: 0.00040699]
	Learning Rate: 0.000406986
	LOSS [training: 0.01543317619914622 | validation: 0.023282021158233628]
	TIME [epoch: 9.07 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014223957697276277		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.014223957697276277 | validation: 0.022611661485505904]
	TIME [epoch: 9.07 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02871829622304726		[learning rate: 0.00040502]
	Learning Rate: 0.000405017
	LOSS [training: 0.02871829622304726 | validation: 0.03710642606442177]
	TIME [epoch: 9.06 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04745490296383202		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.04745490296383202 | validation: 0.07117054332924812]
	TIME [epoch: 9.07 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05323880826110929		[learning rate: 0.00040306]
	Learning Rate: 0.000403059
	LOSS [training: 0.05323880826110929 | validation: 0.05106076260227292]
	TIME [epoch: 9.09 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03381322572503862		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.03381322572503862 | validation: 0.04351298713346806]
	TIME [epoch: 9.07 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029292763452535016		[learning rate: 0.00040111]
	Learning Rate: 0.00040111
	LOSS [training: 0.029292763452535016 | validation: 0.028413692493833957]
	TIME [epoch: 9.07 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013677819892608519		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.013677819892608519 | validation: 0.021065304182920026]
	TIME [epoch: 9.06 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015509543807990748		[learning rate: 0.00039917]
	Learning Rate: 0.00039917
	LOSS [training: 0.015509543807990748 | validation: 0.013587796280817174]
	TIME [epoch: 9.08 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010293226107740038		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.010293226107740038 | validation: 0.01856497659610728]
	TIME [epoch: 9.07 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005096815436313203		[learning rate: 0.00039724]
	Learning Rate: 0.00039724
	LOSS [training: 0.005096815436313203 | validation: 0.01797662534574961]
	TIME [epoch: 9.08 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0030560674382072		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.0030560674382072 | validation: 0.020612802421581637]
	TIME [epoch: 9.07 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006796912702658987		[learning rate: 0.00039532]
	Learning Rate: 0.000395319
	LOSS [training: 0.006796912702658987 | validation: 0.012343209312722196]
	TIME [epoch: 9.07 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006624696693331376		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.006624696693331376 | validation: 0.0009375634573915022]
	TIME [epoch: 9.08 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007307171216210393		[learning rate: 0.00039341]
	Learning Rate: 0.000393407
	LOSS [training: 0.007307171216210393 | validation: 0.006692313843533899]
	TIME [epoch: 9.07 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00461995048582709		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.00461995048582709 | validation: 0.006304478142158596]
	TIME [epoch: 9.07 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006739986949480968		[learning rate: 0.0003915]
	Learning Rate: 0.000391505
	LOSS [training: 0.006739986949480968 | validation: 0.010600608156271401]
	TIME [epoch: 9.07 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0049258997401255555		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.0049258997401255555 | validation: 0.020019792311479406]
	TIME [epoch: 9.07 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018604934353111717		[learning rate: 0.00038961]
	Learning Rate: 0.000389611
	LOSS [training: 0.018604934353111717 | validation: 0.02532229342085527]
	TIME [epoch: 9.09 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013383367874731118		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.013383367874731118 | validation: 0.018061038940263917]
	TIME [epoch: 9.07 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004865878523156135		[learning rate: 0.00038773]
	Learning Rate: 0.000387727
	LOSS [training: 0.004865878523156135 | validation: 0.01630521054910343]
	TIME [epoch: 9.07 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.704795774135867e-05		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 7.704795774135867e-05 | validation: 0.0038613448933272378]
	TIME [epoch: 9.06 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006013910540960293		[learning rate: 0.00038585]
	Learning Rate: 0.000385852
	LOSS [training: 0.0006013910540960293 | validation: 0.019258584038695153]
	TIME [epoch: 9.09 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006474318909520584		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.006474318909520584 | validation: 0.011900237083217316]
	TIME [epoch: 9.07 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005652844735040942		[learning rate: 0.00038399]
	Learning Rate: 0.000383986
	LOSS [training: 0.005652844735040942 | validation: 0.01192444755155025]
	TIME [epoch: 9.07 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010568013736683925		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.010568013736683925 | validation: 0.014023834295166328]
	TIME [epoch: 9.09 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004951695260724495		[learning rate: 0.00038213]
	Learning Rate: 0.000382129
	LOSS [training: 0.004951695260724495 | validation: 0.013148681777471716]
	TIME [epoch: 9.07 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00601352809423164		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.00601352809423164 | validation: 0.023209734537893323]
	TIME [epoch: 9.09 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006007721891531631		[learning rate: 0.00038028]
	Learning Rate: 0.000380282
	LOSS [training: 0.006007721891531631 | validation: 0.013821261305184802]
	TIME [epoch: 9.07 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00547860231195699		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.00547860231195699 | validation: 0.024260219398984168]
	TIME [epoch: 9.07 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007151400447187953		[learning rate: 0.00037844]
	Learning Rate: 0.000378443
	LOSS [training: 0.007151400447187953 | validation: 0.020545505641825702]
	TIME [epoch: 9.07 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010096380850058092		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.010096380850058092 | validation: 0.019504701080422928]
	TIME [epoch: 9.08 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01222949564487		[learning rate: 0.00037661]
	Learning Rate: 0.000376612
	LOSS [training: 0.01222949564487 | validation: 0.010142283420880464]
	TIME [epoch: 9.07 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004603573048940293		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: 0.004603573048940293 | validation: 0.0338629129053513]
	TIME [epoch: 9.06 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01727364133316215		[learning rate: 0.00037479]
	Learning Rate: 0.000374791
	LOSS [training: 0.01727364133316215 | validation: 0.024365418900616456]
	TIME [epoch: 9.07 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012656451261148196		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.012656451261148196 | validation: 0.01519459617213462]
	TIME [epoch: 9.07 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011898593223862578		[learning rate: 0.00037298]
	Learning Rate: 0.000372979
	LOSS [training: 0.011898593223862578 | validation: 0.01480810124958197]
	TIME [epoch: 9.08 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004708191326586466		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.004708191326586466 | validation: 0.012719911270350496]
	TIME [epoch: 9.08 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00031983307614462636		[learning rate: 0.00037118]
	Learning Rate: 0.000371175
	LOSS [training: 0.00031983307614462636 | validation: -0.004664302107538844]
	TIME [epoch: 9.07 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002386599708927903		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.002386599708927903 | validation: 0.0050295058160475335]
	TIME [epoch: 9.07 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004689782486418354		[learning rate: 0.00036938]
	Learning Rate: 0.00036938
	LOSS [training: -0.004689782486418354 | validation: 0.008093242229195385]
	TIME [epoch: 9.07 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010505976594212148		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.0010505976594212148 | validation: 0.004716448826772059]
	TIME [epoch: 9.07 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003912901695576792		[learning rate: 0.00036759]
	Learning Rate: 0.000367594
	LOSS [training: 0.003912901695576792 | validation: -0.003764004389736783]
	TIME [epoch: 9.06 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003132601769682491		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: -0.003132601769682491 | validation: 0.002611059098704129]
	TIME [epoch: 9.06 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00019123232091501752		[learning rate: 0.00036582]
	Learning Rate: 0.000365816
	LOSS [training: 0.00019123232091501752 | validation: 0.004011761211650544]
	TIME [epoch: 9.06 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003987722881707087		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.003987722881707087 | validation: 0.005291107213251881]
	TIME [epoch: 9.08 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004219728526909126		[learning rate: 0.00036405]
	Learning Rate: 0.000364047
	LOSS [training: 0.004219728526909126 | validation: 0.006121130964445824]
	TIME [epoch: 9.07 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007239172857667303		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.007239172857667303 | validation: 0.009080818848838896]
	TIME [epoch: 9.06 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004030406993819771		[learning rate: 0.00036229]
	Learning Rate: 0.000362287
	LOSS [training: 0.004030406993819771 | validation: 0.01171311800583258]
	TIME [epoch: 9.07 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009641709705226811		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: 0.009641709705226811 | validation: 0.013343271853156985]
	TIME [epoch: 9.06 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004173911286765702		[learning rate: 0.00036053]
	Learning Rate: 0.000360535
	LOSS [training: 0.004173911286765702 | validation: 0.012381846345868811]
	TIME [epoch: 9.1 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008077453807813448		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.008077453807813448 | validation: 0.01695319411891288]
	TIME [epoch: 9.07 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009578217288790263		[learning rate: 0.00035879]
	Learning Rate: 0.000358791
	LOSS [training: 0.009578217288790263 | validation: 0.01578677646458769]
	TIME [epoch: 9.08 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016413891834094192		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.0016413891834094192 | validation: 0.006846355128065056]
	TIME [epoch: 9.07 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0032220595707500737		[learning rate: 0.00035706]
	Learning Rate: 0.000357056
	LOSS [training: -0.0032220595707500737 | validation: 0.01672475082640614]
	TIME [epoch: 9.08 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007194412114325463		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.007194412114325463 | validation: 0.012413706978481603]
	TIME [epoch: 9.07 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013594167010255611		[learning rate: 0.00035533]
	Learning Rate: 0.00035533
	LOSS [training: 0.013594167010255611 | validation: 0.029783294208022844]
	TIME [epoch: 9.07 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013069485405957749		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.013069485405957749 | validation: 0.027879419423894422]
	TIME [epoch: 9.06 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01744770521990397		[learning rate: 0.00035361]
	Learning Rate: 0.000353611
	LOSS [training: 0.01744770521990397 | validation: 0.025655839027718008]
	TIME [epoch: 9.07 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016210554297990492		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: 0.016210554297990492 | validation: 0.020824665172854855]
	TIME [epoch: 9.08 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013947667888775314		[learning rate: 0.0003519]
	Learning Rate: 0.000351901
	LOSS [training: 0.013947667888775314 | validation: 0.01901307006772094]
	TIME [epoch: 9.07 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01190364798972803		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: 0.01190364798972803 | validation: 0.016318031099118932]
	TIME [epoch: 9.07 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006270792363836498		[learning rate: 0.0003502]
	Learning Rate: 0.0003502
	LOSS [training: 0.006270792363836498 | validation: 0.0029795352303065856]
	TIME [epoch: 9.06 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012623978740550799		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.012623978740550799 | validation: 8.103812414404776e-05]
	TIME [epoch: 9.09 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007138416003008724		[learning rate: 0.00034851]
	Learning Rate: 0.000348506
	LOSS [training: 0.007138416003008724 | validation: 0.0105302038518779]
	TIME [epoch: 9.07 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0055818390960533405		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.0055818390960533405 | validation: 0.018403233508856386]
	TIME [epoch: 9.07 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005375599919457095		[learning rate: 0.00034682]
	Learning Rate: 0.000346821
	LOSS [training: 0.005375599919457095 | validation: 0.013383005440352157]
	TIME [epoch: 9.06 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00443038458985461		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: 0.00443038458985461 | validation: 0.021211422990467493]
	TIME [epoch: 9.06 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0052770969097229534		[learning rate: 0.00034514]
	Learning Rate: 0.000345144
	LOSS [training: 0.0052770969097229534 | validation: 0.011286418251986528]
	TIME [epoch: 9.07 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0072723951345677355		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: 0.0072723951345677355 | validation: 0.009236916327578563]
	TIME [epoch: 9.06 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010448498106354122		[learning rate: 0.00034347]
	Learning Rate: 0.000343475
	LOSS [training: 0.010448498106354122 | validation: 0.016060163671070438]
	TIME [epoch: 9.07 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006023651321072765		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.006023651321072765 | validation: 0.006372396970488197]
	TIME [epoch: 9.06 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012300357783967018		[learning rate: 0.00034181]
	Learning Rate: 0.000341814
	LOSS [training: 0.012300357783967018 | validation: 0.012882110809056957]
	TIME [epoch: 9.08 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006118966468641619		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.006118966468641619 | validation: 0.01618363263444757]
	TIME [epoch: 9.08 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004572861923400681		[learning rate: 0.00034016]
	Learning Rate: 0.000340161
	LOSS [training: 0.004572861923400681 | validation: 0.008479723096169404]
	TIME [epoch: 9.06 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009590990732254414		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: -0.0009590990732254414 | validation: 0.002013044601358502]
	TIME [epoch: 9.06 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0037835228516066416		[learning rate: 0.00033852]
	Learning Rate: 0.000338516
	LOSS [training: -0.0037835228516066416 | validation: 0.0042717505651023455]
	TIME [epoch: 9.07 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005973505450599229		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.005973505450599229 | validation: 0.008004522077223172]
	TIME [epoch: 9.09 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004138746236881087		[learning rate: 0.00033688]
	Learning Rate: 0.000336879
	LOSS [training: 0.004138746236881087 | validation: 0.0038790734929848307]
	TIME [epoch: 9.07 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006779011870709386		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.006779011870709386 | validation: 0.009330629497816545]
	TIME [epoch: 9.06 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008091837771591886		[learning rate: 0.00033525]
	Learning Rate: 0.00033525
	LOSS [training: 0.0008091837771591886 | validation: 0.010487501196438844]
	TIME [epoch: 9.06 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00015484554101637154		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: -0.00015484554101637154 | validation: 0.014966129621221642]
	TIME [epoch: 9.06 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009486520278958338		[learning rate: 0.00033363]
	Learning Rate: 0.000333629
	LOSS [training: 0.0009486520278958338 | validation: 0.015924237552592178]
	TIME [epoch: 9.08 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014071549712935053		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.0014071549712935053 | validation: 0.011853218686749517]
	TIME [epoch: 9.07 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003990979184752097		[learning rate: 0.00033202]
	Learning Rate: 0.000332015
	LOSS [training: 0.003990979184752097 | validation: 0.0021797087803605954]
	TIME [epoch: 9.08 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00480661403702934		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.00480661403702934 | validation: 0.0008622285326739271]
	TIME [epoch: 9.06 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.000329824715963831		[learning rate: 0.00033041]
	Learning Rate: 0.00033041
	LOSS [training: -0.000329824715963831 | validation: 0.01170995501389141]
	TIME [epoch: 9.09 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018436696670540089		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: 0.0018436696670540089 | validation: 0.0062824403609953025]
	TIME [epoch: 9.06 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: -2.153743888034694e-05		[learning rate: 0.00032881]
	Learning Rate: 0.000328812
	LOSS [training: -2.153743888034694e-05 | validation: 0.0037011852442123717]
	TIME [epoch: 9.06 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009825435245132204		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: -0.0009825435245132204 | validation: 0.008503694379973035]
	TIME [epoch: 9.07 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0004292161632689452		[learning rate: 0.00032722]
	Learning Rate: 0.000327222
	LOSS [training: 0.0004292161632689452 | validation: 0.019455812931324253]
	TIME [epoch: 9.06 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0035605317767370267		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.0035605317767370267 | validation: 0.011475814287581387]
	TIME [epoch: 9.09 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0039299120220635635		[learning rate: 0.00032564]
	Learning Rate: 0.000325639
	LOSS [training: -0.0039299120220635635 | validation: -0.001128584358430103]
	TIME [epoch: 9.06 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0038558433558209043		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: -0.0038558433558209043 | validation: 0.01285008444809269]
	TIME [epoch: 9.06 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002164376571270666		[learning rate: 0.00032406]
	Learning Rate: 0.000324065
	LOSS [training: -0.002164376571270666 | validation: 0.00045612641067700635]
	TIME [epoch: 9.06 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007123543991941986		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: -0.0007123543991941986 | validation: 0.009614073926367974]
	TIME [epoch: 9.09 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019248087197481333		[learning rate: 0.0003225]
	Learning Rate: 0.000322497
	LOSS [training: 0.0019248087197481333 | validation: 0.011597300347510405]
	TIME [epoch: 9.07 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0016832220741305824		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: -0.0016832220741305824 | validation: -0.002545187830710522]
	TIME [epoch: 9.06 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00015714366581635262		[learning rate: 0.00032094]
	Learning Rate: 0.000320938
	LOSS [training: -0.00015714366581635262 | validation: 0.0016535550492439923]
	TIME [epoch: 9.06 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0052505086823272425		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: -0.0052505086823272425 | validation: 0.002755786032096834]
	TIME [epoch: 9.07 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0022011088392610576		[learning rate: 0.00031939]
	Learning Rate: 0.000319386
	LOSS [training: -0.0022011088392610576 | validation: 0.00781551520460828]
	TIME [epoch: 9.09 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005587779738109676		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.005587779738109676 | validation: -0.0002115897018736745]
	TIME [epoch: 9.06 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00017030191399939072		[learning rate: 0.00031784]
	Learning Rate: 0.000317841
	LOSS [training: -0.00017030191399939072 | validation: 0.003427145127840576]
	TIME [epoch: 9.07 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019976098119746056		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.0019976098119746056 | validation: 0.0037942847172561223]
	TIME [epoch: 9.07 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005452056523925752		[learning rate: 0.0003163]
	Learning Rate: 0.000316304
	LOSS [training: 0.005452056523925752 | validation: 0.012217251701918272]
	TIME [epoch: 9.09 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004744491917875631		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.004744491917875631 | validation: 0.007701081036892538]
	TIME [epoch: 9.08 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00021509731639133208		[learning rate: 0.00031477]
	Learning Rate: 0.000314775
	LOSS [training: 0.00021509731639133208 | validation: 0.009998954920637067]
	TIME [epoch: 9.07 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008044471553266767		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.008044471553266767 | validation: 0.01810907352190285]
	TIME [epoch: 9.06 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012311110003143668		[learning rate: 0.00031325]
	Learning Rate: 0.000313253
	LOSS [training: 0.012311110003143668 | validation: 0.01879253051562818]
	TIME [epoch: 9.06 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0038289165340229274		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.0038289165340229274 | validation: 0.011002581452064343]
	TIME [epoch: 9.09 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00012819295598723106		[learning rate: 0.00031174]
	Learning Rate: 0.000311738
	LOSS [training: 0.00012819295598723106 | validation: 0.010218883546594698]
	TIME [epoch: 9.06 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005200802781994871		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: 0.005200802781994871 | validation: 0.007497019400527605]
	TIME [epoch: 9.07 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0059841536316965795		[learning rate: 0.00031023]
	Learning Rate: 0.00031023
	LOSS [training: 0.0059841536316965795 | validation: 0.01218382507406718]
	TIME [epoch: 9.07 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017820336125308825		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: -0.0017820336125308825 | validation: 0.012896763435512625]
	TIME [epoch: 9.07 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0004818477768867808		[learning rate: 0.00030873]
	Learning Rate: 0.00030873
	LOSS [training: 0.0004818477768867808 | validation: 0.0019222136592949824]
	TIME [epoch: 9.09 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002030190163409832		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.002030190163409832 | validation: 0.0029574015455989065]
	TIME [epoch: 9.06 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0025136477697147094		[learning rate: 0.00030724]
	Learning Rate: 0.000307237
	LOSS [training: -0.0025136477697147094 | validation: 0.008936387237037765]
	TIME [epoch: 9.07 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002575170800038218		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: 0.002575170800038218 | validation: -0.002629829066801959]
	TIME [epoch: 9.07 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006517669169313786		[learning rate: 0.00030575]
	Learning Rate: 0.000305751
	LOSS [training: 0.006517669169313786 | validation: 0.00836064934274446]
	TIME [epoch: 9.09 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006072710972033058		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: 0.006072710972033058 | validation: 0.012341632724261246]
	TIME [epoch: 9.07 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00803589435115827		[learning rate: 0.00030427]
	Learning Rate: 0.000304273
	LOSS [training: 0.00803589435115827 | validation: 0.016142934646972203]
	TIME [epoch: 9.06 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005208507329834484		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.005208507329834484 | validation: 0.00046737243904774865]
	TIME [epoch: 9.07 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0011486418767916995		[learning rate: 0.0003028]
	Learning Rate: 0.000302801
	LOSS [training: 0.0011486418767916995 | validation: 0.01736384325169392]
	TIME [epoch: 9.07 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006712659132097072		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: -0.0006712659132097072 | validation: 0.004605866784857432]
	TIME [epoch: 9.09 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005732418616583139		[learning rate: 0.00030134]
	Learning Rate: 0.000301337
	LOSS [training: 0.0005732418616583139 | validation: 0.004690100655733263]
	TIME [epoch: 9.07 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003884417594366853		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.003884417594366853 | validation: 0.009026318663677958]
	TIME [epoch: 9.06 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00443331144340974		[learning rate: 0.00029988]
	Learning Rate: 0.00029988
	LOSS [training: 0.00443331144340974 | validation: -0.0048612789191146005]
	TIME [epoch: 9.07 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0077968824145592626		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: 0.0077968824145592626 | validation: 0.007300320611104027]
	TIME [epoch: 9.09 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0037177044551566355		[learning rate: 0.00029843]
	Learning Rate: 0.00029843
	LOSS [training: 0.0037177044551566355 | validation: 0.006565528735118947]
	TIME [epoch: 9.07 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00035447103114002185		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: 0.00035447103114002185 | validation: 0.00231475009156221]
	TIME [epoch: 9.08 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00074976014334519		[learning rate: 0.00029699]
	Learning Rate: 0.000296987
	LOSS [training: 0.00074976014334519 | validation: 0.008942730668245519]
	TIME [epoch: 9.07 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017418464704856453		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.0017418464704856453 | validation: 0.002152000036384201]
	TIME [epoch: 9.08 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009952665243527252		[learning rate: 0.00029555]
	Learning Rate: 0.00029555
	LOSS [training: -0.0009952665243527252 | validation: 0.006106175061670838]
	TIME [epoch: 9.09 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001452341587738082		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: 0.001452341587738082 | validation: 0.007926473525599434]
	TIME [epoch: 9.07 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0031958944888075226		[learning rate: 0.00029412]
	Learning Rate: 0.000294121
	LOSS [training: 0.0031958944888075226 | validation: 0.0054335690241849015]
	TIME [epoch: 9.07 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006286106610260616		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: -0.0006286106610260616 | validation: 0.005081391789131264]
	TIME [epoch: 9.06 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0025531409688150848		[learning rate: 0.0002927]
	Learning Rate: 0.000292699
	LOSS [training: 0.0025531409688150848 | validation: 0.01798493104037724]
	TIME [epoch: 9.08 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004555469008812224		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: 0.004555469008812224 | validation: 0.006519974669096835]
	TIME [epoch: 9.08 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006626344939209		[learning rate: 0.00029128]
	Learning Rate: 0.000291283
	LOSS [training: 0.0006626344939209 | validation: 0.002039529147070945]
	TIME [epoch: 9.07 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021465993098264188		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: 0.0021465993098264188 | validation: 0.006945259442185862]
	TIME [epoch: 9.07 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00011291171237999796		[learning rate: 0.00028987]
	Learning Rate: 0.000289875
	LOSS [training: -0.00011291171237999796 | validation: 0.0040395721830842266]
	TIME [epoch: 9.06 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: -4.213877020260732e-05		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: -4.213877020260732e-05 | validation: 0.010880581778831182]
	TIME [epoch: 9.09 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003711466124161533		[learning rate: 0.00028847]
	Learning Rate: 0.000288473
	LOSS [training: 0.003711466124161533 | validation: -0.0011153447670702744]
	TIME [epoch: 9.08 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015672046762474328		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: 0.0015672046762474328 | validation: 0.01269553231972026]
	TIME [epoch: 9.08 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008254783920205793		[learning rate: 0.00028708]
	Learning Rate: 0.000287078
	LOSS [training: 0.008254783920205793 | validation: 0.017972903551363377]
	TIME [epoch: 9.08 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009316593256937516		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: 0.009316593256937516 | validation: 0.01389052094979825]
	TIME [epoch: 9.07 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008529464816257562		[learning rate: 0.00028569]
	Learning Rate: 0.00028569
	LOSS [training: 0.0008529464816257562 | validation: 0.00963950478277652]
	TIME [epoch: 9.09 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005157111074998487		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: 0.005157111074998487 | validation: 0.012392267812791978]
	TIME [epoch: 9.07 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002782233679068993		[learning rate: 0.00028431]
	Learning Rate: 0.000284308
	LOSS [training: 0.002782233679068993 | validation: 0.011371866163003234]
	TIME [epoch: 9.07 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005771780368284969		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: 0.005771780368284969 | validation: 0.01287727852997703]
	TIME [epoch: 9.07 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011046005182790551		[learning rate: 0.00028293]
	Learning Rate: 0.000282933
	LOSS [training: 0.011046005182790551 | validation: 0.014686011306493635]
	TIME [epoch: 9.08 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008963213555619527		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.008963213555619527 | validation: 0.013567747775810827]
	TIME [epoch: 9.07 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002369684479920787		[learning rate: 0.00028157]
	Learning Rate: 0.000281565
	LOSS [training: 0.002369684479920787 | validation: 0.009465378985854356]
	TIME [epoch: 9.07 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0004405345857662838		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: 0.0004405345857662838 | validation: -0.0014522030270067942]
	TIME [epoch: 9.07 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0015598129615875254		[learning rate: 0.0002802]
	Learning Rate: 0.000280204
	LOSS [training: -0.0015598129615875254 | validation: 0.014252794302807348]
	TIME [epoch: 9.07 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006785846562184612		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: -0.0006785846562184612 | validation: 0.0016915212944260895]
	TIME [epoch: 9.1 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00816835862709844		[learning rate: 0.00027885]
	Learning Rate: 0.000278849
	LOSS [training: 0.00816835862709844 | validation: 0.01821841758676205]
	TIME [epoch: 9.08 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021617172834593884		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: 0.0021617172834593884 | validation: 0.008116824279083964]
	TIME [epoch: 9.08 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004953717480137743		[learning rate: 0.0002775]
	Learning Rate: 0.0002775
	LOSS [training: 0.004953717480137743 | validation: 0.014234358951788664]
	TIME [epoch: 9.07 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0041798298668468984		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: 0.0041798298668468984 | validation: 0.008519782512781614]
	TIME [epoch: 9.09 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0028881203340280623		[learning rate: 0.00027616]
	Learning Rate: 0.000276158
	LOSS [training: 0.0028881203340280623 | validation: 0.00762610547326301]
	TIME [epoch: 9.07 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0064365733166343725		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: -0.0064365733166343725 | validation: -0.0020851433180497786]
	TIME [epoch: 9.06 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0007007836355144108		[learning rate: 0.00027482]
	Learning Rate: 0.000274823
	LOSS [training: 0.0007007836355144108 | validation: 0.0124696110628825]
	TIME [epoch: 9.07 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010053692950657586		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: 0.0010053692950657586 | validation: 0.0014486186739956523]
	TIME [epoch: 9.06 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016729850742717872		[learning rate: 0.00027349]
	Learning Rate: 0.000273494
	LOSS [training: 0.0016729850742717872 | validation: 0.013681802309641479]
	TIME [epoch: 9.09 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0052679586896384		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: -0.0052679586896384 | validation: 0.001122578165496662]
	TIME [epoch: 9.07 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0010822734574681438		[learning rate: 0.00027217]
	Learning Rate: 0.000272171
	LOSS [training: -0.0010822734574681438 | validation: 0.004579204294881676]
	TIME [epoch: 9.07 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5525791191362816e-06		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 1.5525791191362816e-06 | validation: 0.0023042573450518036]
	TIME [epoch: 9.06 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0011922198698219818		[learning rate: 0.00027086]
	Learning Rate: 0.000270855
	LOSS [training: -0.0011922198698219818 | validation: -0.00801311865456082]
	TIME [epoch: 9.09 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006302580649475014		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: -0.0006302580649475014 | validation: 0.007524396310775207]
	TIME [epoch: 9.09 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003708776787975396		[learning rate: 0.00026955]
	Learning Rate: 0.000269545
	LOSS [training: -0.003708776787975396 | validation: 0.0030832065169464945]
	TIME [epoch: 9.08 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0023960177649806893		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: -0.0023960177649806893 | validation: 0.007178653366323971]
	TIME [epoch: 9.07 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0037550576814275086		[learning rate: 0.00026824]
	Learning Rate: 0.000268242
	LOSS [training: -0.0037550576814275086 | validation: 0.008294174064143825]
	TIME [epoch: 9.07 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00244085677853506		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: -0.00244085677853506 | validation: -0.004888108418013233]
	TIME [epoch: 9.08 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017291423612550232		[learning rate: 0.00026694]
	Learning Rate: 0.000266945
	LOSS [training: -0.0017291423612550232 | validation: 0.008635496310868143]
	TIME [epoch: 9.07 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002588006781684248		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.002588006781684248 | validation: 0.003080577246146569]
	TIME [epoch: 9.07 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016978685650142892		[learning rate: 0.00026565]
	Learning Rate: 0.000265654
	LOSS [training: 0.0016978685650142892 | validation: 0.003534404432744319]
	TIME [epoch: 9.06 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002829453731036349		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.002829453731036349 | validation: 0.017631969828778363]
	TIME [epoch: 9.07 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003564982662862303		[learning rate: 0.00026437]
	Learning Rate: 0.000264369
	LOSS [training: 0.003564982662862303 | validation: 0.009545521141045323]
	TIME [epoch: 9.08 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.000498793794636858		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: 0.000498793794636858 | validation: 0.005603329390637871]
	TIME [epoch: 9.13 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029434983776822376		[learning rate: 0.00026309]
	Learning Rate: 0.000263091
	LOSS [training: 0.0029434983776822376 | validation: 0.008343035720579478]
	TIME [epoch: 9.07 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002257099606496847		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: 0.002257099606496847 | validation: 0.0002946004752223954]
	TIME [epoch: 9.07 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0056474874685126745		[learning rate: 0.00026182]
	Learning Rate: 0.000261818
	LOSS [training: 0.0056474874685126745 | validation: 0.0023676902596125498]
	TIME [epoch: 9.09 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.000904812670514313		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: 0.000904812670514313 | validation: 0.008220648314090525]
	TIME [epoch: 9.08 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006357813662689544		[learning rate: 0.00026055]
	Learning Rate: 0.000260552
	LOSS [training: -0.0006357813662689544 | validation: 0.010378061825190917]
	TIME [epoch: 9.07 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0037507928572262316		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: -0.0037507928572262316 | validation: 0.007650492619908417]
	TIME [epoch: 9.07 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008459846493469597		[learning rate: 0.00025929]
	Learning Rate: 0.000259292
	LOSS [training: 0.0008459846493469597 | validation: 0.0034440944705539894]
	TIME [epoch: 9.07 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0026319247106669254		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.0026319247106669254 | validation: 0.009501806015643693]
	TIME [epoch: 9.08 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004845856308463467		[learning rate: 0.00025804]
	Learning Rate: 0.000258038
	LOSS [training: -0.004845856308463467 | validation: 0.0016101896957190485]
	TIME [epoch: 9.07 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003174288067522596		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: -0.003174288067522596 | validation: 0.0028052159762493143]
	TIME [epoch: 9.06 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003590166044398818		[learning rate: 0.00025679]
	Learning Rate: 0.00025679
	LOSS [training: -0.003590166044398818 | validation: 0.0028778592122967756]
	TIME [epoch: 9.07 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00047614316641180567		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: -0.00047614316641180567 | validation: -0.0064538805275796765]
	TIME [epoch: 9.08 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003990730775465798		[learning rate: 0.00025555]
	Learning Rate: 0.000255549
	LOSS [training: -0.003990730775465798 | validation: 0.00641661642596914]
	TIME [epoch: 9.07 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005447600149233766		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: -0.0005447600149233766 | validation: 0.012694727786026233]
	TIME [epoch: 9.06 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001072218241640854		[learning rate: 0.00025431]
	Learning Rate: 0.000254313
	LOSS [training: -0.001072218241640854 | validation: 0.008810367752106913]
	TIME [epoch: 9.07 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004648349145249956		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: -0.004648349145249956 | validation: 0.0043168573937527625]
	TIME [epoch: 9.07 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009722637930784615		[learning rate: 0.00025308]
	Learning Rate: 0.000253083
	LOSS [training: -0.0009722637930784615 | validation: 0.010300124778468445]
	TIME [epoch: 9.09 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0027459659957840108		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: 0.0027459659957840108 | validation: 0.021274295797016136]
	TIME [epoch: 9.08 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0028521047479163177		[learning rate: 0.00025186]
	Learning Rate: 0.000251859
	LOSS [training: 0.0028521047479163177 | validation: 0.011730532969709703]
	TIME [epoch: 9.08 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005698758178159814		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.005698758178159814 | validation: 0.01036304757739031]
	TIME [epoch: 9.07 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008286081390592624		[learning rate: 0.00025064]
	Learning Rate: 0.000250641
	LOSS [training: 0.0008286081390592624 | validation: 0.004712998301715525]
	TIME [epoch: 9.08 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0027994944624655637		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: 0.0027994944624655637 | validation: 0.005276003976029603]
	TIME [epoch: 9.07 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00019684958450832488		[learning rate: 0.00024943]
	Learning Rate: 0.000249429
	LOSS [training: -0.00019684958450832488 | validation: 0.0030047379878547246]
	TIME [epoch: 9.06 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0007826887726134428		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: 0.0007826887726134428 | validation: 0.0001724724586168189]
	TIME [epoch: 9.07 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0026939594612098382		[learning rate: 0.00024822]
	Learning Rate: 0.000248223
	LOSS [training: 0.0026939594612098382 | validation: 0.006746810928848458]
	TIME [epoch: 9.07 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0041966289588817		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: -0.0041966289588817 | validation: -0.003847402983941731]
	TIME [epoch: 9.09 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.000908091949122807		[learning rate: 0.00024702]
	Learning Rate: 0.000247023
	LOSS [training: -0.000908091949122807 | validation: 0.002726066737611469]
	TIME [epoch: 9.08 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005356517969344956		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: 0.005356517969344956 | validation: 0.006323035446858189]
	TIME [epoch: 9.08 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004561216322717729		[learning rate: 0.00024583]
	Learning Rate: 0.000245828
	LOSS [training: 0.004561216322717729 | validation: 0.015798368459433314]
	TIME [epoch: 9.08 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029740142269019747		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.0029740142269019747 | validation: 0.0033525356237438437]
	TIME [epoch: 9.09 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021698262515460844		[learning rate: 0.00024464]
	Learning Rate: 0.000244639
	LOSS [training: 0.0021698262515460844 | validation: 0.00818261802239138]
	TIME [epoch: 9.09 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006514648801620264		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.006514648801620264 | validation: 0.014341910715370963]
	TIME [epoch: 9.06 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007360744761161516		[learning rate: 0.00024346]
	Learning Rate: 0.000243456
	LOSS [training: 0.007360744761161516 | validation: 0.005747119745201384]
	TIME [epoch: 9.07 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012524212047449588		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.012524212047449588 | validation: 0.0025445470402512675]
	TIME [epoch: 9.07 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004560677638151915		[learning rate: 0.00024228]
	Learning Rate: 0.000242279
	LOSS [training: 0.004560677638151915 | validation: 0.01456791945551408]
	TIME [epoch: 9.09 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004956058317250623		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: 0.004956058317250623 | validation: 0.014446713364968888]
	TIME [epoch: 9.07 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007889125227053106		[learning rate: 0.00024111]
	Learning Rate: 0.000241107
	LOSS [training: 0.007889125227053106 | validation: 0.01722878540227915]
	TIME [epoch: 9.07 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0028275204059014835		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: 0.0028275204059014835 | validation: -0.0017031072289362373]
	TIME [epoch: 9.07 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005064127392202711		[learning rate: 0.00023994]
	Learning Rate: 0.000239941
	LOSS [training: 0.0005064127392202711 | validation: 0.008629227359255014]
	TIME [epoch: 9.07 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001175268292387856		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: 0.001175268292387856 | validation: 0.013784743879657894]
	TIME [epoch: 9.08 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003706442517639512		[learning rate: 0.00023878]
	Learning Rate: 0.000238781
	LOSS [training: 0.003706442517639512 | validation: 0.013865074470076705]
	TIME [epoch: 9.07 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007121109949608774		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: 0.007121109949608774 | validation: -0.003993782564241044]
	TIME [epoch: 9.08 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0038126937920008445		[learning rate: 0.00023763]
	Learning Rate: 0.000237626
	LOSS [training: 0.0038126937920008445 | validation: 0.0016229187174341456]
	TIME [epoch: 9.07 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0015755324696885772		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: -0.0015755324696885772 | validation: 0.009795796071509166]
	TIME [epoch: 9.09 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005035114551538206		[learning rate: 0.00023648]
	Learning Rate: 0.000236477
	LOSS [training: -0.005035114551538206 | validation: 0.005649317492884537]
	TIME [epoch: 9.07 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0020578042970804972		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.0020578042970804972 | validation: 0.00481230778452394]
	TIME [epoch: 9.06 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016258003731820924		[learning rate: 0.00023533]
	Learning Rate: 0.000235334
	LOSS [training: 0.0016258003731820924 | validation: 0.007106856557754212]
	TIME [epoch: 9.07 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001227330035576884		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.001227330035576884 | validation: -0.0014644792888977216]
	TIME [epoch: 9.06 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0018042039882279382		[learning rate: 0.0002342]
	Learning Rate: 0.000234196
	LOSS [training: -0.0018042039882279382 | validation: 0.0035195215227566716]
	TIME [epoch: 9.09 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0019108392122259312		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: -0.0019108392122259312 | validation: 0.007449366393889772]
	TIME [epoch: 9.07 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00472211413944164		[learning rate: 0.00023306]
	Learning Rate: 0.000233063
	LOSS [training: 0.00472211413944164 | validation: -0.0065846656546999]
	TIME [epoch: 9.07 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002614533961159384		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: -0.002614533961159384 | validation: -0.009752941892804474]
	TIME [epoch: 9.07 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004374039388319018		[learning rate: 0.00023194]
	Learning Rate: 0.000231936
	LOSS [training: -0.004374039388319018 | validation: 0.000558714621445634]
	TIME [epoch: 9.08 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004550916033932834		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: -0.004550916033932834 | validation: 0.007683112632576751]
	TIME [epoch: 9.07 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002724647322423563		[learning rate: 0.00023081]
	Learning Rate: 0.000230814
	LOSS [training: -0.002724647322423563 | validation: 0.004297268453345036]
	TIME [epoch: 9.08 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009950654627042207		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: -0.0009950654627042207 | validation: 0.002914408926093261]
	TIME [epoch: 9.08 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002999632886920753		[learning rate: 0.0002297]
	Learning Rate: 0.000229698
	LOSS [training: -0.002999632886920753 | validation: 0.005011621583692569]
	TIME [epoch: 9.08 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00616620459785672		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: -0.00616620459785672 | validation: 0.0003904732632702073]
	TIME [epoch: 9.09 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003961623602504733		[learning rate: 0.00022859]
	Learning Rate: 0.000228588
	LOSS [training: -0.003961623602504733 | validation: 0.0013258149180308465]
	TIME [epoch: 9.07 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0035969283523760625		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: -0.0035969283523760625 | validation: -0.008026509016451215]
	TIME [epoch: 9.07 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004872606504918283		[learning rate: 0.00022748]
	Learning Rate: 0.000227482
	LOSS [training: -0.004872606504918283 | validation: 0.000817717296307187]
	TIME [epoch: 9.06 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004366575042262321		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: -0.004366575042262321 | validation: 0.0035193415523735814]
	TIME [epoch: 9.08 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004383670761910364		[learning rate: 0.00022638]
	Learning Rate: 0.000226382
	LOSS [training: -0.004383670761910364 | validation: 0.007383363609347661]
	TIME [epoch: 9.08 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0035519847352921455		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: -0.0035519847352921455 | validation: 0.004131358787978013]
	TIME [epoch: 9.07 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0020267663200769907		[learning rate: 0.00022529]
	Learning Rate: 0.000225287
	LOSS [training: -0.0020267663200769907 | validation: 0.004846756560303572]
	TIME [epoch: 9.07 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0015681924450254077		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: -0.0015681924450254077 | validation: 0.00813767583960603]
	TIME [epoch: 9.06 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005337358754315609		[learning rate: 0.0002242]
	Learning Rate: 0.000224198
	LOSS [training: -0.005337358754315609 | validation: 0.006202603871139915]
	TIME [epoch: 9.08 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0048860451805273295		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: -0.0048860451805273295 | validation: 0.0067707930406216065]
	TIME [epoch: 9.08 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003473212239210327		[learning rate: 0.00022311]
	Learning Rate: 0.000223114
	LOSS [training: -0.003473212239210327 | validation: 0.01162144765377238]
	TIME [epoch: 9.08 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0025476471280379354		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: -0.0025476471280379354 | validation: 0.0024590257726546487]
	TIME [epoch: 9.08 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0024969777601122093		[learning rate: 0.00022203]
	Learning Rate: 0.000222035
	LOSS [training: -0.0024969777601122093 | validation: 0.00043136839498504956]
	TIME [epoch: 9.07 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009196572231826558		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.0009196572231826558 | validation: 0.017161356951801158]
	TIME [epoch: 9.09 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002234839916194521		[learning rate: 0.00022096]
	Learning Rate: 0.000220961
	LOSS [training: -0.002234839916194521 | validation: 0.004546453402075923]
	TIME [epoch: 9.06 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0022831778509166093		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: -0.0022831778509166093 | validation: -0.002785105521933384]
	TIME [epoch: 9.07 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013393644832219382		[learning rate: 0.00021989]
	Learning Rate: 0.000219893
	LOSS [training: -0.0013393644832219382 | validation: -0.00107485910008392]
	TIME [epoch: 9.06 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0034665012079416746		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: -0.0034665012079416746 | validation: 0.00014431193323733186]
	TIME [epoch: 9.08 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005580659286117651		[learning rate: 0.00021883]
	Learning Rate: 0.000218829
	LOSS [training: -0.005580659286117651 | validation: 0.0018090482091918632]
	TIME [epoch: 9.07 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010727517074268947		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: 0.0010727517074268947 | validation: 0.006775043763159973]
	TIME [epoch: 9.07 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009947364601476847		[learning rate: 0.00021777]
	Learning Rate: 0.000217771
	LOSS [training: -0.0009947364601476847 | validation: 0.015430779552067012]
	TIME [epoch: 9.06 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0011935582531460661		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: 0.0011935582531460661 | validation: 0.005207504880700994]
	TIME [epoch: 9.07 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004106471111395262		[learning rate: 0.00021672]
	Learning Rate: 0.000216718
	LOSS [training: -0.004106471111395262 | validation: 0.003574988611514013]
	TIME [epoch: 9.09 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001775078951922561		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: -0.001775078951922561 | validation: 0.003446589125016095]
	TIME [epoch: 9.08 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001232268380441092		[learning rate: 0.00021567]
	Learning Rate: 0.00021567
	LOSS [training: 0.001232268380441092 | validation: 0.00901477021833887]
	TIME [epoch: 9.07 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005170660025336797		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: 0.0005170660025336797 | validation: -0.002164112789984649]
	TIME [epoch: 9.07 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005860370148004478		[learning rate: 0.00021463]
	Learning Rate: 0.000214627
	LOSS [training: 0.0005860370148004478 | validation: 0.006302735602241191]
	TIME [epoch: 9.08 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003914290679230157		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: 0.003914290679230157 | validation: 0.010717784371996214]
	TIME [epoch: 9.07 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006754781043513217		[learning rate: 0.00021359]
	Learning Rate: 0.000213589
	LOSS [training: 0.006754781043513217 | validation: 0.013214553673055556]
	TIME [epoch: 9.07 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021265966669128107		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.0021265966669128107 | validation: 0.006701221910237027]
	TIME [epoch: 9.07 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00325404146050264		[learning rate: 0.00021256]
	Learning Rate: 0.000212556
	LOSS [training: 0.00325404146050264 | validation: 0.010309663652583501]
	TIME [epoch: 9.06 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021869080831550345		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.0021869080831550345 | validation: 0.007549147170247692]
	TIME [epoch: 9.09 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008308861697307243		[learning rate: 0.00021153]
	Learning Rate: 0.000211528
	LOSS [training: 0.0008308861697307243 | validation: 0.006859221032508064]
	TIME [epoch: 9.07 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006022472834868845		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.006022472834868845 | validation: 0.011454871548675125]
	TIME [epoch: 9.06 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009859228660670844		[learning rate: 0.00021051]
	Learning Rate: 0.000210505
	LOSS [training: 0.009859228660670844 | validation: 0.010191939901991576]
	TIME [epoch: 9.06 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0078232041778367		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.0078232041778367 | validation: 0.0021695467112771254]
	TIME [epoch: 9.09 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007911976038377288		[learning rate: 0.00020949]
	Learning Rate: 0.000209487
	LOSS [training: -0.0007911976038377288 | validation: 0.012590472562659535]
	TIME [epoch: 9.09 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001618008119320712		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.001618008119320712 | validation: 0.0074857028214007325]
	TIME [epoch: 9.07 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6611663593875133e-05		[learning rate: 0.00020847]
	Learning Rate: 0.000208474
	LOSS [training: 1.6611663593875133e-05 | validation: 0.004915290697944854]
	TIME [epoch: 9.07 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0036159830744581984		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.0036159830744581984 | validation: 0.012243102414846472]
	TIME [epoch: 9.06 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00042004972126528895		[learning rate: 0.00020747]
	Learning Rate: 0.000207466
	LOSS [training: -0.00042004972126528895 | validation: 0.009468906699795339]
	TIME [epoch: 9.08 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0007682356000114696		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: 0.0007682356000114696 | validation: 0.00977557919593284]
	TIME [epoch: 9.08 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0025996501867057726		[learning rate: 0.00020646]
	Learning Rate: 0.000206463
	LOSS [training: 0.0025996501867057726 | validation: 0.009029222090619583]
	TIME [epoch: 9.06 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005274879703582432		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.0005274879703582432 | validation: 0.008395428684547407]
	TIME [epoch: 9.07 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015838721148938556		[learning rate: 0.00020546]
	Learning Rate: 0.000205465
	LOSS [training: 0.0015838721148938556 | validation: 0.010714850695206545]
	TIME [epoch: 9.07 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005617941008803901		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.0005617941008803901 | validation: 0.017064509599388628]
	TIME [epoch: 9.09 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006102628408688312		[learning rate: 0.00020447]
	Learning Rate: 0.000204471
	LOSS [training: 0.006102628408688312 | validation: 0.011991727026668939]
	TIME [epoch: 9.07 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003504495299060109		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: 0.003504495299060109 | validation: 0.00702987115499086]
	TIME [epoch: 9.07 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017874178738176733		[learning rate: 0.00020348]
	Learning Rate: 0.000203482
	LOSS [training: -0.0017874178738176733 | validation: 0.01000524578797192]
	TIME [epoch: 9.07 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018777327173933964		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: 0.0018777327173933964 | validation: 0.0006087201374882717]
	TIME [epoch: 9.09 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005844945235980045		[learning rate: 0.0002025]
	Learning Rate: 0.000202498
	LOSS [training: 0.005844945235980045 | validation: 0.009561864249773002]
	TIME [epoch: 9.07 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0023472957072257117		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.0023472957072257117 | validation: -0.0003318245550667465]
	TIME [epoch: 9.07 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003928097234710235		[learning rate: 0.00020152]
	Learning Rate: 0.000201519
	LOSS [training: 0.003928097234710235 | validation: 0.006065638691431348]
	TIME [epoch: 9.07 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0067699118655224185		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.0067699118655224185 | validation: 0.01659773097919091]
	TIME [epoch: 9.07 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01009551985385781		[learning rate: 0.00020054]
	Learning Rate: 0.000200544
	LOSS [training: 0.01009551985385781 | validation: 0.017233874857544917]
	TIME [epoch: 9.09 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0011823154650418143		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.0011823154650418143 | validation: 0.014409950080821599]
	TIME [epoch: 9.07 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0021735811100101147		[learning rate: 0.00019957]
	Learning Rate: 0.000199575
	LOSS [training: -0.0021735811100101147 | validation: 0.012117889103694688]
	TIME [epoch: 9.07 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00012449608200117075		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: -0.00012449608200117075 | validation: 0.003555077832810457]
	TIME [epoch: 9.07 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0001768286216985963		[learning rate: 0.00019861]
	Learning Rate: 0.000198609
	LOSS [training: -0.0001768286216985963 | validation: 0.005129307907503378]
	TIME [epoch: 9.08 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001461392345478257		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: -0.001461392345478257 | validation: -4.271797729260172e-05]
	TIME [epoch: 9.07 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00011593852619572447		[learning rate: 0.00019765]
	Learning Rate: 0.000197649
	LOSS [training: -0.00011593852619572447 | validation: -0.0014057571458859536]
	TIME [epoch: 9.06 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001083657595471502		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: -0.001083657595471502 | validation: -7.65493042042476e-05]
	TIME [epoch: 9.06 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00025572143117332945		[learning rate: 0.00019669]
	Learning Rate: 0.000196693
	LOSS [training: -0.00025572143117332945 | validation: -0.0006864912849792882]
	TIME [epoch: 9.07 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00040759588536594843		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: -0.00040759588536594843 | validation: 0.005671092331432259]
	TIME [epoch: 9.1 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029349393380166955		[learning rate: 0.00019574]
	Learning Rate: 0.000195742
	LOSS [training: 0.0029349393380166955 | validation: 0.00857492699139765]
	TIME [epoch: 9.08 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007666494617268495		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: -0.0007666494617268495 | validation: -0.0032089479351302954]
	TIME [epoch: 9.06 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001622486181876098		[learning rate: 0.0001948]
	Learning Rate: 0.000194796
	LOSS [training: -0.001622486181876098 | validation: 0.00147410393948989]
	TIME [epoch: 9.06 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: -3.436285247093891e-05		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: -3.436285247093891e-05 | validation: 0.006164524114123737]
	TIME [epoch: 9.08 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0031028809511947208		[learning rate: 0.00019385]
	Learning Rate: 0.000193853
	LOSS [training: -0.0031028809511947208 | validation: 0.004353613424920919]
	TIME [epoch: 9.07 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0028858176876871812		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: -0.0028858176876871812 | validation: 0.0025513996394622546]
	TIME [epoch: 9.07 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00048626795430009383		[learning rate: 0.00019292]
	Learning Rate: 0.000192916
	LOSS [training: -0.00048626795430009383 | validation: 0.0044536840398865275]
	TIME [epoch: 9.06 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010310448107858131		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: 0.0010310448107858131 | validation: 0.007849022466890553]
	TIME [epoch: 9.06 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0016134884593488		[learning rate: 0.00019198]
	Learning Rate: 0.000191983
	LOSS [training: -0.0016134884593488 | validation: 0.01004297857394151]
	TIME [epoch: 9.09 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002185872625717254		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: -0.002185872625717254 | validation: 0.0021601498297810365]
	TIME [epoch: 9.06 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0001568846174700239		[learning rate: 0.00019105]
	Learning Rate: 0.000191055
	LOSS [training: 0.0001568846174700239 | validation: 0.0073278170220776335]
	TIME [epoch: 9.06 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00014156124962940703		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: 0.00014156124962940703 | validation: 0.008151708870746259]
	TIME [epoch: 9.06 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0034410115674188583		[learning rate: 0.00019013]
	Learning Rate: 0.000190131
	LOSS [training: -0.0034410115674188583 | validation: -0.00512790521299853]
	TIME [epoch: 9.07 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.007493707078594372		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: -0.007493707078594372 | validation: 0.005040791250657576]
	TIME [epoch: 9.1 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003727812383210229		[learning rate: 0.00018921]
	Learning Rate: 0.000189211
	LOSS [training: -0.003727812383210229 | validation: 0.010625363777421935]
	TIME [epoch: 9.07 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0018620568549288015		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: -0.0018620568549288015 | validation: 0.008986803245007531]
	TIME [epoch: 9.07 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013815560588043767		[learning rate: 0.0001883]
	Learning Rate: 0.000188296
	LOSS [training: -0.0013815560588043767 | validation: -0.0027297778310355226]
	TIME [epoch: 9.06 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0024365982443642215		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: -0.0024365982443642215 | validation: 0.008486172613744769]
	TIME [epoch: 9.08 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0025998609059766516		[learning rate: 0.00018739]
	Learning Rate: 0.000187386
	LOSS [training: -0.0025998609059766516 | validation: 0.008583826854925713]
	TIME [epoch: 9.07 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005549430630625888		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: -0.005549430630625888 | validation: 0.0019714663989194724]
	TIME [epoch: 9.07 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0051999172258305896		[learning rate: 0.00018648]
	Learning Rate: 0.00018648
	LOSS [training: -0.0051999172258305896 | validation: 0.005917607500707847]
	TIME [epoch: 9.07 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006855864973627258		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: -0.0006855864973627258 | validation: 0.0032894562281699726]
	TIME [epoch: 9.06 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004720851590263314		[learning rate: 0.00018558]
	Learning Rate: 0.000185578
	LOSS [training: -0.004720851590263314 | validation: 0.00524148580226243]
	TIME [epoch: 9.09 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0023663881362122816		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: -0.0023663881362122816 | validation: -0.0015647432438847548]
	TIME [epoch: 9.07 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003180628281157477		[learning rate: 0.00018468]
	Learning Rate: 0.00018468
	LOSS [training: -0.003180628281157477 | validation: 0.0014490515629186401]
	TIME [epoch: 9.07 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0024720726264710045		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: -0.0024720726264710045 | validation: 0.004866597924479026]
	TIME [epoch: 9.07 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003601248352260772		[learning rate: 0.00018379]
	Learning Rate: 0.000183787
	LOSS [training: -0.003601248352260772 | validation: -0.0008500487075312644]
	TIME [epoch: 9.08 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003307511712066976		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: -0.003307511712066976 | validation: -0.004363895195952275]
	TIME [epoch: 9.07 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002891486496963061		[learning rate: 0.0001829]
	Learning Rate: 0.000182899
	LOSS [training: -0.002891486496963061 | validation: 0.0032484165264804942]
	TIME [epoch: 9.07 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00259270205003963		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: -0.00259270205003963 | validation: -0.0019769013500711185]
	TIME [epoch: 9.07 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00563296204094051		[learning rate: 0.00018201]
	Learning Rate: 0.000182014
	LOSS [training: -0.00563296204094051 | validation: -0.001990561639776545]
	TIME [epoch: 9.07 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0048218549351166885		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: -0.0048218549351166885 | validation: -0.0034389655803723058]
	TIME [epoch: 9.09 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004899261359581882		[learning rate: 0.00018113]
	Learning Rate: 0.000181134
	LOSS [training: -0.0004899261359581882 | validation: 0.008201977634202986]
	TIME [epoch: 9.08 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.008443080815972313		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: -0.008443080815972313 | validation: 0.0003364688184398051]
	TIME [epoch: 9.07 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0022763095715616706		[learning rate: 0.00018026]
	Learning Rate: 0.000180258
	LOSS [training: -0.0022763095715616706 | validation: -0.002920774216410715]
	TIME [epoch: 9.07 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006275582069555942		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: -0.006275582069555942 | validation: 0.002539850196942697]
	TIME [epoch: 9.08 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004509243307842572		[learning rate: 0.00017939]
	Learning Rate: 0.000179386
	LOSS [training: -0.004509243307842572 | validation: 0.007515547053157045]
	TIME [epoch: 9.07 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00398666631956409		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: -0.00398666631956409 | validation: 0.006607283395864767]
	TIME [epoch: 9.07 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00645389813964725		[learning rate: 0.00017852]
	Learning Rate: 0.000178519
	LOSS [training: -0.00645389813964725 | validation: 0.0013832291105147798]
	TIME [epoch: 9.07 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017388657135927125		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: -0.0017388657135927125 | validation: 0.0025873619481630904]
	TIME [epoch: 9.08 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001391487975378199		[learning rate: 0.00017766]
	Learning Rate: 0.000177656
	LOSS [training: -0.001391487975378199 | validation: 0.010478497936943111]
	TIME [epoch: 9.09 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006087881525811991		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: 0.0006087881525811991 | validation: 0.006782770713876541]
	TIME [epoch: 9.07 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00013033139582045066		[learning rate: 0.0001768]
	Learning Rate: 0.000176797
	LOSS [training: 0.00013033139582045066 | validation: 0.0019260658713234496]
	TIME [epoch: 9.06 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004011978068601114		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: -0.004011978068601114 | validation: -0.0017543243948904498]
	TIME [epoch: 9.06 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003226191018452983		[learning rate: 0.00017594]
	Learning Rate: 0.000175942
	LOSS [training: -0.003226191018452983 | validation: 0.0005473010296664749]
	TIME [epoch: 9.08 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0029985313990342913		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: -0.0029985313990342913 | validation: 0.005380135456012166]
	TIME [epoch: 9.08 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004046117241237086		[learning rate: 0.00017509]
	Learning Rate: 0.000175091
	LOSS [training: -0.004046117241237086 | validation: 0.001692935305355881]
	TIME [epoch: 9.07 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0031516467203784385		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: -0.0031516467203784385 | validation: 0.0019556182467017425]
	TIME [epoch: 9.07 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001548197902628443		[learning rate: 0.00017424]
	Learning Rate: 0.000174244
	LOSS [training: -0.001548197902628443 | validation: -0.0033632335538483753]
	TIME [epoch: 9.07 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0024007694283563856		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: 0.0024007694283563856 | validation: 0.0044405802812015685]
	TIME [epoch: 9.09 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0030179850096703625		[learning rate: 0.0001734]
	Learning Rate: 0.000173401
	LOSS [training: 0.0030179850096703625 | validation: 0.008374238555524884]
	TIME [epoch: 9.07 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005180831838915735		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.005180831838915735 | validation: 0.013489465438644141]
	TIME [epoch: 9.08 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004332886278486643		[learning rate: 0.00017256]
	Learning Rate: 0.000172563
	LOSS [training: 0.004332886278486643 | validation: 0.00635238152384596]
	TIME [epoch: 9.07 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007791605734000837		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: 0.007791605734000837 | validation: 0.010194280365077331]
	TIME [epoch: 9.07 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: -7.047668863719593e-05		[learning rate: 0.00017173]
	Learning Rate: 0.000171728
	LOSS [training: -7.047668863719593e-05 | validation: 0.011053466337386988]
	TIME [epoch: 9.09 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0031193913030674154		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: -0.0031193913030674154 | validation: 0.00518695481078985]
	TIME [epoch: 9.07 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002453510501792441		[learning rate: 0.0001709]
	Learning Rate: 0.000170898
	LOSS [training: 0.002453510501792441 | validation: 0.005830538938495079]
	TIME [epoch: 9.06 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003935030765707654		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.003935030765707654 | validation: 0.008822684746416504]
	TIME [epoch: 9.06 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00010834556127799276		[learning rate: 0.00017007]
	Learning Rate: 0.000170072
	LOSS [training: 0.00010834556127799276 | validation: 0.005491682126457405]
	TIME [epoch: 9.09 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003032118505255481		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: -0.003032118505255481 | validation: 0.006494259563428151]
	TIME [epoch: 9.07 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013049265502874843		[learning rate: 0.00016925]
	Learning Rate: 0.000169249
	LOSS [training: -0.0013049265502874843 | validation: 0.0009919168955257543]
	TIME [epoch: 9.07 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006076485131672777		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: -0.0006076485131672777 | validation: 0.007357610968196624]
	TIME [epoch: 9.07 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0020334319522180982		[learning rate: 0.00016843]
	Learning Rate: 0.000168431
	LOSS [training: -0.0020334319522180982 | validation: 0.015643119405107743]
	TIME [epoch: 9.07 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005359058384558073		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.0005359058384558073 | validation: 0.009710930448213487]
	TIME [epoch: 9.09 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00030994230008844266		[learning rate: 0.00016762]
	Learning Rate: 0.000167616
	LOSS [training: 0.00030994230008844266 | validation: 0.007748767344771589]
	TIME [epoch: 9.08 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006239049375382528		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.006239049375382528 | validation: 0.005924057657340792]
	TIME [epoch: 9.08 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003514488603330724		[learning rate: 0.00016681]
	Learning Rate: 0.000166806
	LOSS [training: 0.003514488603330724 | validation: 0.010375717819441778]
	TIME [epoch: 9.08 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010223715836444563		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: 0.0010223715836444563 | validation: 0.005503772355461978]
	TIME [epoch: 9.09 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016481130290337044		[learning rate: 0.000166]
	Learning Rate: 0.000165999
	LOSS [training: 0.0016481130290337044 | validation: 0.0014013542971949334]
	TIME [epoch: 9.07 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0035726496651824315		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: 0.0035726496651824315 | validation: 0.016519777378267902]
	TIME [epoch: 9.07 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005880509964074752		[learning rate: 0.0001652]
	Learning Rate: 0.000165196
	LOSS [training: 0.005880509964074752 | validation: 0.017870591431197347]
	TIME [epoch: 9.07 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00037819127240313195		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: 0.00037819127240313195 | validation: 0.013554601036474198]
	TIME [epoch: 9.08 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029766559225322237		[learning rate: 0.0001644]
	Learning Rate: 0.000164397
	LOSS [training: 0.0029766559225322237 | validation: 0.013916854252751645]
	TIME [epoch: 9.09 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007510754715142771		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: -0.0007510754715142771 | validation: 0.013899327690762193]
	TIME [epoch: 9.07 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015085214871236445		[learning rate: 0.0001636]
	Learning Rate: 0.000163602
	LOSS [training: 0.0015085214871236445 | validation: 0.011384217099670238]
	TIME [epoch: 9.07 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001566539812488164		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: 0.001566539812488164 | validation: -0.0019649391177145974]
	TIME [epoch: 9.06 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002392422232066895		[learning rate: 0.00016281]
	Learning Rate: 0.000162811
	LOSS [training: 0.002392422232066895 | validation: 0.0020242712787073573]
	TIME [epoch: 9.08 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005274688427869538		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: 0.0005274688427869538 | validation: 0.004164687575256255]
	TIME [epoch: 9.09 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004163406762197894		[learning rate: 0.00016202]
	Learning Rate: 0.000162024
	LOSS [training: 0.004163406762197894 | validation: 0.009759719216458209]
	TIME [epoch: 9.07 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.538496459634115e-05		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: 8.538496459634115e-05 | validation: 0.003229358011951353]
	TIME [epoch: 9.07 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00038781736724264514		[learning rate: 0.00016124]
	Learning Rate: 0.00016124
	LOSS [training: -0.00038781736724264514 | validation: 0.009622921785615331]
	TIME [epoch: 9.06 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0011086344314750265		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: 0.0011086344314750265 | validation: 0.01334936624823337]
	TIME [epoch: 9.09 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015675641165741633		[learning rate: 0.00016046]
	Learning Rate: 0.000160461
	LOSS [training: 0.0015675641165741633 | validation: 0.009477882285579216]
	TIME [epoch: 9.07 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004032686735493373		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: 0.004032686735493373 | validation: 0.00794156185085656]
	TIME [epoch: 9.07 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008162559281296486		[learning rate: 0.00015968]
	Learning Rate: 0.000159685
	LOSS [training: 0.008162559281296486 | validation: 0.004333913318328989]
	TIME [epoch: 9.07 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007924063853104063		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.007924063853104063 | validation: 0.009687059247472056]
	TIME [epoch: 9.07 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007303490466915948		[learning rate: 0.00015891]
	Learning Rate: 0.000158912
	LOSS [training: 0.007303490466915948 | validation: 0.024187421516483697]
	TIME [epoch: 9.1 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012480581710355768		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: 0.012480581710355768 | validation: 0.034654850425119385]
	TIME [epoch: 9.07 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012365226659206167		[learning rate: 0.00015814]
	Learning Rate: 0.000158144
	LOSS [training: 0.012365226659206167 | validation: 0.016691884350493826]
	TIME [epoch: 9.07 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009751473421868894		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: 0.009751473421868894 | validation: 0.009562595247433605]
	TIME [epoch: 9.07 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007700683239849203		[learning rate: 0.00015738]
	Learning Rate: 0.000157379
	LOSS [training: 0.007700683239849203 | validation: 0.013304291643165394]
	TIME [epoch: 9.1 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004827662276604802		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.004827662276604802 | validation: 0.014889353639454098]
	TIME [epoch: 9.07 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005176040356119215		[learning rate: 0.00015662]
	Learning Rate: 0.000156618
	LOSS [training: 0.005176040356119215 | validation: -0.0004145669367616739]
	TIME [epoch: 9.07 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004270981977363764		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: 0.004270981977363764 | validation: 0.012504451571140223]
	TIME [epoch: 9.06 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003174785724043533		[learning rate: 0.00015586]
	Learning Rate: 0.000155861
	LOSS [training: 0.003174785724043533 | validation: 0.00501357698486205]
	TIME [epoch: 9.07 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0035144750501604734		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: 0.0035144750501604734 | validation: 0.011509099278590085]
	TIME [epoch: 9.08 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004363107858215411		[learning rate: 0.00015511]
	Learning Rate: 0.000155107
	LOSS [training: 0.004363107858215411 | validation: 0.008354768125251617]
	TIME [epoch: 9.07 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00021154555849295392		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.00021154555849295392 | validation: 0.0019060693741593689]
	TIME [epoch: 9.07 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029385316116974035		[learning rate: 0.00015436]
	Learning Rate: 0.000154357
	LOSS [training: 0.0029385316116974035 | validation: 0.007879948006775871]
	TIME [epoch: 9.06 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004106766743447365		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.004106766743447365 | validation: 0.0071662694500019075]
	TIME [epoch: 9.09 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.000756519305665681		[learning rate: 0.00015361]
	Learning Rate: 0.000153611
	LOSS [training: -0.000756519305665681 | validation: 0.004972560612270655]
	TIME [epoch: 9.07 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003147763068086235		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: 0.003147763068086235 | validation: 0.013500494790226367]
	TIME [epoch: 9.07 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0044453574059633485		[learning rate: 0.00015287]
	Learning Rate: 0.000152868
	LOSS [training: 0.0044453574059633485 | validation: 0.006314756446356339]
	TIME [epoch: 9.07 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002053824799741681		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: 0.002053824799741681 | validation: 0.006428933041684769]
	TIME [epoch: 9.07 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021425467896085478		[learning rate: 0.00015213]
	Learning Rate: 0.000152128
	LOSS [training: 0.0021425467896085478 | validation: 0.011483663661934566]
	TIME [epoch: 9.1 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003458357313024547		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: -0.003458357313024547 | validation: 0.010286975014732892]
	TIME [epoch: 9.08 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00045545908909396535		[learning rate: 0.00015139]
	Learning Rate: 0.000151393
	LOSS [training: 0.00045545908909396535 | validation: 0.00884722460381144]
	TIME [epoch: 9.08 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001843586223287676		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: 0.001843586223287676 | validation: 0.003637444314500254]
	TIME [epoch: 9.07 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00044878835645767863		[learning rate: 0.00015066]
	Learning Rate: 0.000150661
	LOSS [training: 0.00044878835645767863 | validation: 0.012699922972843378]
	TIME [epoch: 9.07 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0025687974249582954		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: 0.0025687974249582954 | validation: 0.00816957357778272]
	TIME [epoch: 9.07 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001876321333031469		[learning rate: 0.00014993]
	Learning Rate: 0.000149932
	LOSS [training: 0.001876321333031469 | validation: 0.006950104508067753]
	TIME [epoch: 9.07 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00041639235411163164		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: 0.00041639235411163164 | validation: 0.015306254626578746]
	TIME [epoch: 9.07 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009676706303592001		[learning rate: 0.00014921]
	Learning Rate: 0.000149207
	LOSS [training: 0.0009676706303592001 | validation: 0.005991446565545052]
	TIME [epoch: 9.07 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029154036468817834		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: 0.0029154036468817834 | validation: 0.0129539568652653]
	TIME [epoch: 9.09 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016546496198045172		[learning rate: 0.00014849]
	Learning Rate: 0.000148486
	LOSS [training: 0.0016546496198045172 | validation: 0.009890323901625956]
	TIME [epoch: 9.07 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015959045607897037		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: 0.0015959045607897037 | validation: 0.004168371156793634]
	TIME [epoch: 9.07 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005728608581770504		[learning rate: 0.00014777]
	Learning Rate: 0.000147768
	LOSS [training: 0.005728608581770504 | validation: 0.014856108185082113]
	TIME [epoch: 9.07 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0001442300247455966		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.0001442300247455966 | validation: 0.01023849860009952]
	TIME [epoch: 9.07 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0041537574289760735		[learning rate: 0.00014705]
	Learning Rate: 0.000147053
	LOSS [training: 0.0041537574289760735 | validation: 0.007219602568424924]
	TIME [epoch: 9.1 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004480478374720977		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: 0.004480478374720977 | validation: 0.009272806792175601]
	TIME [epoch: 9.07 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0028698247483647217		[learning rate: 0.00014634]
	Learning Rate: 0.000146342
	LOSS [training: 0.0028698247483647217 | validation: -0.0018086690072356005]
	TIME [epoch: 9.06 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0030718009627707897		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.0030718009627707897 | validation: 0.01310579271014796]
	TIME [epoch: 9.07 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0038917069499600923		[learning rate: 0.00014563]
	Learning Rate: 0.000145634
	LOSS [training: 0.0038917069499600923 | validation: 0.012963172644433064]
	TIME [epoch: 9.09 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005274655408406513		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.005274655408406513 | validation: 0.013871290050913091]
	TIME [epoch: 9.07 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00498998348966929		[learning rate: 0.00014493]
	Learning Rate: 0.00014493
	LOSS [training: 0.00498998348966929 | validation: 0.0021417008588203996]
	TIME [epoch: 9.06 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003969371060761155		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: 0.003969371060761155 | validation: 0.006982595465526634]
	TIME [epoch: 9.07 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004168301508040019		[learning rate: 0.00014423]
	Learning Rate: 0.000144229
	LOSS [training: -0.0004168301508040019 | validation: 0.001132640051453483]
	TIME [epoch: 9.07 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00474567503160013		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.00474567503160013 | validation: 0.003808943600529739]
	TIME [epoch: 9.09 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0025925516127997964		[learning rate: 0.00014353]
	Learning Rate: 0.000143532
	LOSS [training: -0.0025925516127997964 | validation: 0.0029702226356409013]
	TIME [epoch: 9.06 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009971352345033674		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.0009971352345033674 | validation: 0.003314220465619626]
	TIME [epoch: 9.07 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003001754374469887		[learning rate: 0.00014284]
	Learning Rate: 0.000142837
	LOSS [training: -0.003001754374469887 | validation: 0.002634361446188279]
	TIME [epoch: 9.08 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0027645090321719258		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.0027645090321719258 | validation: 0.0032073626659553374]
	TIME [epoch: 9.1 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002033231899167446		[learning rate: 0.00014215]
	Learning Rate: 0.000142147
	LOSS [training: -0.002033231899167446 | validation: 0.016112083946542524]
	TIME [epoch: 9.08 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0035651506718330297		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: 0.0035651506718330297 | validation: 0.008532197484230324]
	TIME [epoch: 9.07 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00039022525488509286		[learning rate: 0.00014146]
	Learning Rate: 0.000141459
	LOSS [training: 0.00039022525488509286 | validation: 0.010257449834812738]
	TIME [epoch: 9.06 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00479154901927568		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: 0.00479154901927568 | validation: 0.007641600276830926]
	TIME [epoch: 9.07 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.000851916249780791		[learning rate: 0.00014078]
	Learning Rate: 0.000140775
	LOSS [training: 0.000851916249780791 | validation: 0.004065318364974572]
	TIME [epoch: 9.09 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0004558174289521296		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: 0.0004558174289521296 | validation: 0.00726941626691911]
	TIME [epoch: 9.07 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003444783351147427		[learning rate: 0.00014009]
	Learning Rate: 0.000140094
	LOSS [training: 0.003444783351147427 | validation: 0.01294930966738683]
	TIME [epoch: 9.07 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004922730916784114		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: -0.0004922730916784114 | validation: 0.003766738980315107]
	TIME [epoch: 9.07 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009918181849930157		[learning rate: 0.00013942]
	Learning Rate: 0.000139417
	LOSS [training: 0.0009918181849930157 | validation: 0.00825602247493594]
	TIME [epoch: 9.11 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00417058254936283		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: -0.00417058254936283 | validation: 0.0005361149193033826]
	TIME [epoch: 9.06 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021255721344974774		[learning rate: 0.00013874]
	Learning Rate: 0.000138743
	LOSS [training: 0.0021255721344974774 | validation: 0.006867124132292408]
	TIME [epoch: 9.06 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004284252655403926		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: -0.004284252655403926 | validation: 0.00883085120991485]
	TIME [epoch: 9.07 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017402225821345277		[learning rate: 0.00013807]
	Learning Rate: 0.000138072
	LOSS [training: -0.0017402225821345277 | validation: 0.00510821577023574]
	TIME [epoch: 9.07 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0031146250869719177		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: 0.0031146250869719177 | validation: 0.011021603486103307]
	TIME [epoch: 9.09 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006295831984818992		[learning rate: 0.0001374]
	Learning Rate: 0.000137404
	LOSS [training: 0.006295831984818992 | validation: 0.00854335647652532]
	TIME [epoch: 9.07 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009141617079740406		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: 0.009141617079740406 | validation: 0.012173849775404096]
	TIME [epoch: 9.07 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010130220422125993		[learning rate: 0.00013674]
	Learning Rate: 0.00013674
	LOSS [training: 0.010130220422125993 | validation: 0.009379619501623292]
	TIME [epoch: 9.07 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006290293565537522		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: 0.006290293565537522 | validation: 0.006551591529230192]
	TIME [epoch: 9.08 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004412951520997263		[learning rate: 0.00013608]
	Learning Rate: 0.000136078
	LOSS [training: 0.004412951520997263 | validation: 0.008932927691727323]
	TIME [epoch: 9.08 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004128334780889703		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: 0.004128334780889703 | validation: 0.009199817962371208]
	TIME [epoch: 9.07 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003370428303167636		[learning rate: 0.00013542]
	Learning Rate: 0.00013542
	LOSS [training: 0.003370428303167636 | validation: 0.011125029861285963]
	TIME [epoch: 9.06 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0007880320135579492		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: 0.0007880320135579492 | validation: 0.002415346267143621]
	TIME [epoch: 9.07 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008196469140009122		[learning rate: 0.00013477]
	Learning Rate: 0.000134766
	LOSS [training: 0.0008196469140009122 | validation: 0.0013667172735683502]
	TIME [epoch: 9.08 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017794218884049384		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: 0.0017794218884049384 | validation: 0.003676304753837187]
	TIME [epoch: 9.07 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004828847432964634		[learning rate: 0.00013411]
	Learning Rate: 0.000134114
	LOSS [training: -0.0004828847432964634 | validation: 0.012328448907218629]
	TIME [epoch: 9.07 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0025181814797688544		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: 0.0025181814797688544 | validation: 0.00441050848255747]
	TIME [epoch: 9.07 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003080965090968575		[learning rate: 0.00013347]
	Learning Rate: 0.000133465
	LOSS [training: 0.003080965090968575 | validation: 0.005819906832112718]
	TIME [epoch: 9.07 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0024972269537460864		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.0024972269537460864 | validation: -0.0003145924590282462]
	TIME [epoch: 9.08 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00015755277159940794		[learning rate: 0.00013282]
	Learning Rate: 0.00013282
	LOSS [training: 0.00015755277159940794 | validation: 0.007687531469448809]
	TIME [epoch: 9.07 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001526730241686382		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: -0.001526730241686382 | validation: 0.008250446822278565]
	TIME [epoch: 9.07 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002396705271813399		[learning rate: 0.00013218]
	Learning Rate: 0.000132178
	LOSS [training: -0.002396705271813399 | validation: 0.0033881415497022003]
	TIME [epoch: 9.06 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002568144751546053		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: -0.002568144751546053 | validation: 0.00426722337886638]
	TIME [epoch: 9.08 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005754599816162104		[learning rate: 0.00013154]
	Learning Rate: 0.000131538
	LOSS [training: 0.0005754599816162104 | validation: 0.0020007175659126956]
	TIME [epoch: 9.06 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004453564369352763		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: -0.004453564369352763 | validation: 0.013896206207384567]
	TIME [epoch: 9.07 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009728145243244508		[learning rate: 0.0001309]
	Learning Rate: 0.000130902
	LOSS [training: -0.0009728145243244508 | validation: -0.0034573322318846795]
	TIME [epoch: 9.07 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0036611570867473636		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: -0.0036611570867473636 | validation: 0.007705124697380673]
	TIME [epoch: 9.06 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004475016204545331		[learning rate: 0.00013027]
	Learning Rate: 0.000130269
	LOSS [training: -0.004475016204545331 | validation: 0.0058754737382059625]
	TIME [epoch: 9.09 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007649915467401378		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: -0.0007649915467401378 | validation: 0.0017465470000090704]
	TIME [epoch: 9.07 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0008011127425428942		[learning rate: 0.00012964]
	Learning Rate: 0.000129639
	LOSS [training: -0.0008011127425428942 | validation: -0.0019850656816357407]
	TIME [epoch: 9.06 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0033748466719480895		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: 0.0033748466719480895 | validation: 0.0016902977075376302]
	TIME [epoch: 9.07 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005562010401394137		[learning rate: 0.00012901]
	Learning Rate: 0.000129012
	LOSS [training: 0.005562010401394137 | validation: 0.0037819680417453087]
	TIME [epoch: 9.08 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015784308101147576		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.0015784308101147576 | validation: -0.0002650835583813246]
	TIME [epoch: 9.07 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013988877757502697		[learning rate: 0.00012839]
	Learning Rate: 0.000128389
	LOSS [training: -0.0013988877757502697 | validation: 0.0014554576723323658]
	TIME [epoch: 9.06 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0033753598471003413		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: -0.0033753598471003413 | validation: 0.002667745081066897]
	TIME [epoch: 9.07 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.007580986338913317		[learning rate: 0.00012777]
	Learning Rate: 0.000127768
	LOSS [training: -0.007580986338913317 | validation: -0.003958644071403682]
	TIME [epoch: 9.06 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0068344024459858045		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: -0.0068344024459858045 | validation: 0.002206640094281561]
	TIME [epoch: 9.08 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003718706299093249		[learning rate: 0.00012715]
	Learning Rate: 0.00012715
	LOSS [training: -0.003718706299093249 | validation: -0.002111814262101706]
	TIME [epoch: 9.07 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0018257807479547573		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: -0.0018257807479547573 | validation: 0.00800756259352594]
	TIME [epoch: 9.06 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0018869872461838918		[learning rate: 0.00012653]
	Learning Rate: 0.000126535
	LOSS [training: -0.0018869872461838918 | validation: -9.825899870267128e-05]
	TIME [epoch: 9.06 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0028444339985087977		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: -0.0028444339985087977 | validation: -0.011104205492496674]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240219_183142/states/model_tr_study4_1904.pth
	Model improved!!!
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0033162103339672323		[learning rate: 0.00012592]
	Learning Rate: 0.000125923
	LOSS [training: -0.0033162103339672323 | validation: 0.002298896724952296]
	TIME [epoch: 9.08 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0026317464796637964		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: 0.0026317464796637964 | validation: 0.004273044963328613]
	TIME [epoch: 9.07 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00016987286061399934		[learning rate: 0.00012531]
	Learning Rate: 0.000125314
	LOSS [training: 0.00016987286061399934 | validation: 0.011336768447674997]
	TIME [epoch: 9.07 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00028949633737523054		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: -0.00028949633737523054 | validation: 0.013703383759506476]
	TIME [epoch: 9.06 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0014323010549939683		[learning rate: 0.00012471]
	Learning Rate: 0.000124708
	LOSS [training: -0.0014323010549939683 | validation: 0.00904503685900887]
	TIME [epoch: 9.09 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0014022980456551506		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: -0.0014022980456551506 | validation: -0.002918620645755665]
	TIME [epoch: 9.06 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0012980978363799178		[learning rate: 0.00012411]
	Learning Rate: 0.000124105
	LOSS [training: 0.0012980978363799178 | validation: 0.015776165791286947]
	TIME [epoch: 9.07 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001509607983176601		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.001509607983176601 | validation: 0.007681521902695736]
	TIME [epoch: 9.06 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0001234811458443139		[learning rate: 0.0001235]
	Learning Rate: 0.000123505
	LOSS [training: -0.0001234811458443139 | validation: -0.0010900631140847534]
	TIME [epoch: 9.07 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0011075839845233327		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: -0.0011075839845233327 | validation: 0.0013282118091974917]
	TIME [epoch: 9.09 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002244588703266673		[learning rate: 0.00012291]
	Learning Rate: 0.000122908
	LOSS [training: -0.002244588703266673 | validation: 0.006445252448875028]
	TIME [epoch: 9.07 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0007060357225151515		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: 0.0007060357225151515 | validation: -0.002556102059587323]
	TIME [epoch: 9.07 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003114763730418653		[learning rate: 0.00012231]
	Learning Rate: 0.000122313
	LOSS [training: -0.003114763730418653 | validation: -0.0018576203746591968]
	TIME [epoch: 9.06 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0019509575304282449		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: -0.0019509575304282449 | validation: 0.004390900660973423]
	TIME [epoch: 9.09 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002094268178572881		[learning rate: 0.00012172]
	Learning Rate: 0.000121722
	LOSS [training: -0.002094268178572881 | validation: 0.0034180584627231435]
	TIME [epoch: 9.08 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0026512307831180783		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: -0.0026512307831180783 | validation: 0.007937139351336091]
	TIME [epoch: 9.08 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018415436923251375		[learning rate: 0.00012113]
	Learning Rate: 0.000121133
	LOSS [training: 0.0018415436923251375 | validation: -0.001343571434160662]
	TIME [epoch: 9.07 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0036044526604055403		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: -0.0036044526604055403 | validation: 0.004029995370726666]
	TIME [epoch: 9.07 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0025157701882251443		[learning rate: 0.00012055]
	Learning Rate: 0.000120547
	LOSS [training: -0.0025157701882251443 | validation: 0.0070344589393279795]
	TIME [epoch: 9.08 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002371600155312766		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: -0.002371600155312766 | validation: 0.004866051637981452]
	TIME [epoch: 9.06 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006163515812053684		[learning rate: 0.00011996]
	Learning Rate: 0.000119964
	LOSS [training: -0.006163515812053684 | validation: 0.006229430175230435]
	TIME [epoch: 9.07 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0008779352425732367		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: -0.0008779352425732367 | validation: 0.0019492266103968328]
	TIME [epoch: 9.06 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005841271161495729		[learning rate: 0.00011938]
	Learning Rate: 0.000119384
	LOSS [training: -0.005841271161495729 | validation: 0.00619174060415871]
	TIME [epoch: 9.09 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001322363250506066		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: -0.001322363250506066 | validation: 0.01171490847826635]
	TIME [epoch: 9.07 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0027796207426699195		[learning rate: 0.00011881]
	Learning Rate: 0.000118807
	LOSS [training: -0.0027796207426699195 | validation: 0.01113382171532952]
	TIME [epoch: 9.07 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004042609758318428		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: -0.004042609758318428 | validation: 0.0004595028083259579]
	TIME [epoch: 9.06 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0029779239719400358		[learning rate: 0.00011823]
	Learning Rate: 0.000118232
	LOSS [training: -0.0029779239719400358 | validation: 0.00549082442000353]
	TIME [epoch: 9.07 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0027767170596345015		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: -0.0027767170596345015 | validation: -0.0011109783796537348]
	TIME [epoch: 9.09 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0037790935878898035		[learning rate: 0.00011766]
	Learning Rate: 0.000117661
	LOSS [training: -0.0037790935878898035 | validation: 0.011054702347578845]
	TIME [epoch: 9.08 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005177641184550264		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: -0.0005177641184550264 | validation: 0.009360771745645702]
	TIME [epoch: 9.08 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: -9.165782032025116e-05		[learning rate: 0.00011709]
	Learning Rate: 0.000117092
	LOSS [training: -9.165782032025116e-05 | validation: 0.008309027539442081]
	TIME [epoch: 9.07 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004119786033372474		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: -0.004119786033372474 | validation: -0.0011415630579087047]
	TIME [epoch: 9.08 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006130492217954533		[learning rate: 0.00011653]
	Learning Rate: 0.000116526
	LOSS [training: -0.006130492217954533 | validation: -0.0030479416896291908]
	TIME [epoch: 9.08 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003856978857043375		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: -0.003856978857043375 | validation: -0.003777745054875215]
	TIME [epoch: 9.07 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.007280902978959632		[learning rate: 0.00011596]
	Learning Rate: 0.000115962
	LOSS [training: -0.007280902978959632 | validation: 0.008394846187584171]
	TIME [epoch: 9.07 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0016561829697772402		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: -0.0016561829697772402 | validation: 0.004169709514443019]
	TIME [epoch: 9.07 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005571346206464306		[learning rate: 0.0001154]
	Learning Rate: 0.000115401
	LOSS [training: -0.005571346206464306 | validation: 0.004798415030818078]
	TIME [epoch: 9.09 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0038257430805862793		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: -0.0038257430805862793 | validation: 0.005126490038541436]
	TIME [epoch: 9.07 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0022048819321750838		[learning rate: 0.00011484]
	Learning Rate: 0.000114843
	LOSS [training: -0.0022048819321750838 | validation: 0.014060820401031474]
	TIME [epoch: 9.07 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004981753405630447		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: -0.004981753405630447 | validation: -0.0020841560767639383]
	TIME [epoch: 9.07 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.007395866629865698		[learning rate: 0.00011429]
	Learning Rate: 0.000114288
	LOSS [training: -0.007395866629865698 | validation: 0.0030924787455546164]
	TIME [epoch: 9.09 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001597902349160894		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: -0.001597902349160894 | validation: -0.0034588065593920943]
	TIME [epoch: 9.09 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00340719573968217		[learning rate: 0.00011374]
	Learning Rate: 0.000113735
	LOSS [training: -0.00340719573968217 | validation: 0.003049239979171049]
	TIME [epoch: 9.07 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004120306182454148		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: -0.004120306182454148 | validation: -0.005201212143461895]
	TIME [epoch: 9.07 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017434052713542058		[learning rate: 0.00011319]
	Learning Rate: 0.000113185
	LOSS [training: -0.0017434052713542058 | validation: -0.00027694556629237043]
	TIME [epoch: 9.07 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013141495908135777		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: -0.0013141495908135777 | validation: -0.002844260562022341]
	TIME [epoch: 9.09 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006480830689495451		[learning rate: 0.00011264]
	Learning Rate: 0.000112638
	LOSS [training: -0.006480830689495451 | validation: -0.0008269592408949491]
	TIME [epoch: 9.07 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.007713741123159238		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: -0.007713741123159238 | validation: -0.007078954761782259]
	TIME [epoch: 9.07 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005083318493461218		[learning rate: 0.00011209]
	Learning Rate: 0.000112093
	LOSS [training: -0.005083318493461218 | validation: -0.00147726093946014]
	TIME [epoch: 9.06 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003438485991757968		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: -0.003438485991757968 | validation: -0.002862675845164533]
	TIME [epoch: 9.07 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.007753438648987833		[learning rate: 0.00011155]
	Learning Rate: 0.000111551
	LOSS [training: -0.007753438648987833 | validation: 0.0034281014235000096]
	TIME [epoch: 9.09 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0015986004584704488		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: -0.0015986004584704488 | validation: 0.0004044745578708558]
	TIME [epoch: 9.07 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0030493086489771807		[learning rate: 0.00011101]
	Learning Rate: 0.000111012
	LOSS [training: -0.0030493086489771807 | validation: 0.012298560044943653]
	TIME [epoch: 9.07 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00047971458072786267		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: 0.00047971458072786267 | validation: -0.001899912377356574]
	TIME [epoch: 9.08 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006973177561322168		[learning rate: 0.00011047]
	Learning Rate: 0.000110475
	LOSS [training: -0.006973177561322168 | validation: 0.004693256918176771]
	TIME [epoch: 9.08 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0010947805564907151		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: -0.0010947805564907151 | validation: -0.009128615864987286]
	TIME [epoch: 9.08 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003915180586839899		[learning rate: 0.00010994]
	Learning Rate: 0.000109941
	LOSS [training: -0.003915180586839899 | validation: 0.004469340870350428]
	TIME [epoch: 9.07 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005265257037487497		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: -0.005265257037487497 | validation: 0.002331235531076832]
	TIME [epoch: 9.07 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0035889120439767676		[learning rate: 0.00010941]
	Learning Rate: 0.000109409
	LOSS [training: -0.0035889120439767676 | validation: 0.005259151652145718]
	TIME [epoch: 9.08 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004831739352774983		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: -0.004831739352774983 | validation: -0.004286833156110517]
	TIME [epoch: 9.09 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0036182710852401675		[learning rate: 0.00010888]
	Learning Rate: 0.00010888
	LOSS [training: -0.0036182710852401675 | validation: 0.007110327603342731]
	TIME [epoch: 9.07 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003179213380648585		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: -0.003179213380648585 | validation: 0.003860349814312149]
	TIME [epoch: 9.07 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005454954152314834		[learning rate: 0.00010835]
	Learning Rate: 0.000108353
	LOSS [training: -0.005454954152314834 | validation: 0.008922722890485223]
	TIME [epoch: 9.06 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0011505663307388322		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: -0.0011505663307388322 | validation: 0.006918489415825727]
	TIME [epoch: 9.09 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00459412248227598		[learning rate: 0.00010783]
	Learning Rate: 0.000107829
	LOSS [training: -0.00459412248227598 | validation: 0.001000193974394366]
	TIME [epoch: 9.06 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00163468387473738		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: -0.00163468387473738 | validation: -0.00382795180786241]
	TIME [epoch: 9.07 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004987163963553437		[learning rate: 0.00010731]
	Learning Rate: 0.000107308
	LOSS [training: -0.004987163963553437 | validation: -0.006029062543777249]
	TIME [epoch: 9.07 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003913604052091117		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: -0.003913604052091117 | validation: -0.00364214053041391]
	TIME [epoch: 9.07 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002594529347784594		[learning rate: 0.00010679]
	Learning Rate: 0.000106789
	LOSS [training: -0.002594529347784594 | validation: 0.00463219272921521]
	TIME [epoch: 9.09 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002788191987801721		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: -0.002788191987801721 | validation: -0.001548543947041599]
	TIME [epoch: 9.06 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0002776491250133352		[learning rate: 0.00010627]
	Learning Rate: 0.000106273
	LOSS [training: -0.0002776491250133352 | validation: 0.010830521041577088]
	TIME [epoch: 9.06 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001586830511332225		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: -0.001586830511332225 | validation: 0.009773888979661534]
	TIME [epoch: 9.06 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014311178601947145		[learning rate: 0.00010576]
	Learning Rate: 0.000105759
	LOSS [training: 0.0014311178601947145 | validation: 0.004793364334980916]
	TIME [epoch: 9.07 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00024627849321229344		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: -0.00024627849321229344 | validation: 0.010213848154977731]
	TIME [epoch: 9.08 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004210875305318771		[learning rate: 0.00010525]
	Learning Rate: 0.000105247
	LOSS [training: 0.004210875305318771 | validation: 0.012231665972689893]
	TIME [epoch: 9.06 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004077014834982325		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.004077014834982325 | validation: 0.010245694309518603]
	TIME [epoch: 9.06 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002202829914558822		[learning rate: 0.00010474]
	Learning Rate: 0.000104738
	LOSS [training: 0.002202829914558822 | validation: 0.0016208342097481308]
	TIME [epoch: 9.06 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00106979873040415		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.00106979873040415 | validation: 0.0030779905667363775]
	TIME [epoch: 9.08 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003711470241048761		[learning rate: 0.00010423]
	Learning Rate: 0.000104232
	LOSS [training: -0.003711470241048761 | validation: 0.006874764085037373]
	TIME [epoch: 9.07 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002930567253287545		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: -0.002930567253287545 | validation: 0.01078154914029454]
	TIME [epoch: 9.08 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003230015642615791		[learning rate: 0.00010373]
	Learning Rate: 0.000103728
	LOSS [training: 0.003230015642615791 | validation: 0.009372503810470697]
	TIME [epoch: 9.08 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004241546132870056		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: 0.004241546132870056 | validation: 0.009776132434412017]
	TIME [epoch: 9.08 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0022222810933644538		[learning rate: 0.00010323]
	Learning Rate: 0.000103226
	LOSS [training: 0.0022222810933644538 | validation: 0.010469745754663305]
	TIME [epoch: 9.09 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005032193237254208		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: 0.005032193237254208 | validation: 0.010605684992412476]
	TIME [epoch: 9.07 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005579668126325264		[learning rate: 0.00010273]
	Learning Rate: 0.000102727
	LOSS [training: 0.005579668126325264 | validation: 0.007762459398892791]
	TIME [epoch: 9.06 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00021650546814501096		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: -0.00021650546814501096 | validation: 0.0024383445396267186]
	TIME [epoch: 9.07 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001675733458758199		[learning rate: 0.00010223]
	Learning Rate: 0.00010223
	LOSS [training: -0.001675733458758199 | validation: 0.00735756666609462]
	TIME [epoch: 9.08 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0016541647689610056		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: -0.0016541647689610056 | validation: 0.002583339554548792]
	TIME [epoch: 9.08 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004457149620976579		[learning rate: 0.00010174]
	Learning Rate: 0.000101736
	LOSS [training: -0.0004457149620976579 | validation: -0.0034343192096058977]
	TIME [epoch: 9.07 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004479730026156403		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: -0.004479730026156403 | validation: 0.00569735288511744]
	TIME [epoch: 9.07 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001023878806245715		[learning rate: 0.00010124]
	Learning Rate: 0.000101244
	LOSS [training: 0.001023878806245715 | validation: 0.008527985628619568]
	TIME [epoch: 9.06 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012326271818255711		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: -0.0012326271818255711 | validation: 0.0063978720248656406]
	TIME [epoch: 9.06 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0018672604393560777		[learning rate: 0.00010075]
	Learning Rate: 0.000100754
	LOSS [training: -0.0018672604393560777 | validation: -0.0036194844155522828]
	TIME [epoch: 9.02 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005925456955121572		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.0005925456955121572 | validation: 0.0046625461096628665]
	TIME [epoch: 9.07 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002191743956227427		[learning rate: 0.00010027]
	Learning Rate: 0.000100267
	LOSS [training: -0.002191743956227427 | validation: 0.013537295023971167]
	TIME [epoch: 9.04 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004533723701254762		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.004533723701254762 | validation: -0.0018907892127466583]
	TIME [epoch: 9.05 sec]
Finished training in 18284.035 seconds.
