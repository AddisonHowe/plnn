Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r1', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=500, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 890546738

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.89688777343325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.89688777343325 | validation: 7.8799623879421965]
	TIME [epoch: 48.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.919188415237825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.919188415237825 | validation: 7.183863666019175]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.315094373883734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.315094373883734 | validation: 4.385375606780075]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.597927331602232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.597927331602232 | validation: 4.44263779355165]
	TIME [epoch: 9.2 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.127032659443051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.127032659443051 | validation: 3.725329705364241]
	TIME [epoch: 9.19 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.021174205071956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.021174205071956 | validation: 3.6573726529725095]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.90149531960609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.90149531960609 | validation: 3.3556008862308717]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7240904958626735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7240904958626735 | validation: 3.4664524363880225]
	TIME [epoch: 9.23 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.514358552159051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.514358552159051 | validation: 3.46590874280673]
	TIME [epoch: 9.22 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2656727328459865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2656727328459865 | validation: 3.485873639662379]
	TIME [epoch: 9.23 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2244271954718924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2244271954718924 | validation: 2.826831683396035]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2472870676564844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2472870676564844 | validation: 3.124497962262406]
	TIME [epoch: 9.22 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1530251889425926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1530251889425926 | validation: 2.817491183728139]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8655050629297314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8655050629297314 | validation: 2.4934030634533366]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4488687445622555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4488687445622555 | validation: 2.1939137893228784]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3255500567940426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3255500567940426 | validation: 2.911966254993201]
	TIME [epoch: 9.21 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.226245107913628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.226245107913628 | validation: 2.031077189126978]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8378859005960422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8378859005960422 | validation: 1.5810482095986638]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5998903216033553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5998903216033553 | validation: 1.0159199881821879]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2945453626608692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2945453626608692 | validation: 0.8683959616441874]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0851198781495324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0851198781495324 | validation: 1.5026825985549217]
	TIME [epoch: 9.21 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3878883314103017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3878883314103017 | validation: 1.9427851551680346]
	TIME [epoch: 9.22 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1543439070215047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1543439070215047 | validation: 0.7462454467191153]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8046569064368482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8046569064368482 | validation: 0.7850766346558713]
	TIME [epoch: 9.19 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9187124629697634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9187124629697634 | validation: 1.6318475114160336]
	TIME [epoch: 9.2 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9255624187364495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9255624187364495 | validation: 0.5633750820127585]
	TIME [epoch: 9.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.7650107491195355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7650107491195355 | validation: 4.414579231532784]
	TIME [epoch: 9.21 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.985076608663658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.985076608663658 | validation: 1.8967768177951547]
	TIME [epoch: 9.21 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0210290466528547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0210290466528547 | validation: 0.9102947657530736]
	TIME [epoch: 9.2 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7947236956819662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7947236956819662 | validation: 0.6932573529574859]
	TIME [epoch: 9.2 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8402568859431476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8402568859431476 | validation: 0.47235483423071534]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6908906254000231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6908906254000231 | validation: 0.5767034860738827]
	TIME [epoch: 9.23 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6182859864740634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6182859864740634 | validation: 0.48041284040039134]
	TIME [epoch: 9.2 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6552801877290724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6552801877290724 | validation: 1.0398689309944045]
	TIME [epoch: 9.22 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4795580134858937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4795580134858937 | validation: 0.6617637305156049]
	TIME [epoch: 9.21 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9594563966370124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9594563966370124 | validation: 0.8921611062155852]
	TIME [epoch: 9.21 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7744844910332465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7744844910332465 | validation: 0.5686767913400284]
	TIME [epoch: 9.24 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5972550107988631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5972550107988631 | validation: 0.5421860161544805]
	TIME [epoch: 9.21 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1619429522721418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1619429522721418 | validation: 1.120088362210018]
	TIME [epoch: 9.22 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6778271897400406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6778271897400406 | validation: 0.6607476645116159]
	TIME [epoch: 9.22 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.789679412518764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.789679412518764 | validation: 0.5032119367903496]
	TIME [epoch: 9.23 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6455526799822191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6455526799822191 | validation: 0.4975329691943925]
	TIME [epoch: 9.22 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5712568420636668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5712568420636668 | validation: 0.43999453577978664]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.17095328380023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.17095328380023 | validation: 1.0574096640589867]
	TIME [epoch: 9.22 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8996526127783324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8996526127783324 | validation: 0.4771258879567386]
	TIME [epoch: 9.22 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.533281377630294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.533281377630294 | validation: 0.729516259514705]
	TIME [epoch: 9.22 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5745590142141022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5745590142141022 | validation: 0.43798788031343217]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5391500811291011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5391500811291011 | validation: 0.4648860985800308]
	TIME [epoch: 9.2 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9098546759473999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9098546759473999 | validation: 0.6315141845303658]
	TIME [epoch: 9.21 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.58493412557551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.58493412557551 | validation: 1.133868153173345]
	TIME [epoch: 9.22 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6480797429560293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6480797429560293 | validation: 2.244895334982211]
	TIME [epoch: 9.22 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3089871231788384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3089871231788384 | validation: 0.6549618505090942]
	TIME [epoch: 9.21 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6170274148866268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6170274148866268 | validation: 0.8922504698414425]
	TIME [epoch: 9.21 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6058072067656245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6058072067656245 | validation: 0.5707964149017096]
	TIME [epoch: 9.2 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7315544311344452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7315544311344452 | validation: 3.966808287060222]
	TIME [epoch: 9.18 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.291375012154577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.291375012154577 | validation: 3.3286616518143988]
	TIME [epoch: 9.21 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3505010489089884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3505010489089884 | validation: 1.3072103947259905]
	TIME [epoch: 9.2 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8756944751605502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8756944751605502 | validation: 0.494277667065531]
	TIME [epoch: 9.2 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6254878852362751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6254878852362751 | validation: 0.48973342853220025]
	TIME [epoch: 9.2 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49766516883666423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49766516883666423 | validation: 1.0856010405854835]
	TIME [epoch: 9.2 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6020124910141955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6020124910141955 | validation: 0.38468670793371257]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42603034510958515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42603034510958515 | validation: 0.5529647471633216]
	TIME [epoch: 9.2 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5957557328352582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5957557328352582 | validation: 0.3889880426213207]
	TIME [epoch: 9.19 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38408795051896605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38408795051896605 | validation: 0.5066159967135752]
	TIME [epoch: 9.18 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6686238366355524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6686238366355524 | validation: 0.6829432441647761]
	TIME [epoch: 9.2 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5338728310211017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5338728310211017 | validation: 0.46485046396384755]
	TIME [epoch: 9.24 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5148867732267659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5148867732267659 | validation: 0.4823852585115984]
	TIME [epoch: 9.21 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5324207127553406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5324207127553406 | validation: 0.7784462803229626]
	TIME [epoch: 9.22 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6409305789165249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6409305789165249 | validation: 0.4028887140621924]
	TIME [epoch: 9.22 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3638513217252163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3638513217252163 | validation: 0.4050799958846302]
	TIME [epoch: 9.2 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.703901553347027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.703901553347027 | validation: 0.559380190477795]
	TIME [epoch: 9.22 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5581627453437937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5581627453437937 | validation: 0.7763500605215534]
	TIME [epoch: 9.2 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45317182052100236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45317182052100236 | validation: 0.33695115294582323]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6002351003093156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6002351003093156 | validation: 0.6064433071004771]
	TIME [epoch: 9.2 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5474225485608751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5474225485608751 | validation: 0.5561103100105975]
	TIME [epoch: 9.2 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48760429168667657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48760429168667657 | validation: 0.38851530929100603]
	TIME [epoch: 9.22 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6477418625240073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6477418625240073 | validation: 0.729683088945452]
	TIME [epoch: 9.21 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6237743102911575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6237743102911575 | validation: 0.3686202086317987]
	TIME [epoch: 9.21 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43844289276129167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43844289276129167 | validation: 0.4502073238603402]
	TIME [epoch: 9.21 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42528830822465197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42528830822465197 | validation: 0.613134966249455]
	TIME [epoch: 9.21 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5652817294618695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5652817294618695 | validation: 0.5434921850191422]
	TIME [epoch: 9.22 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.441605016814394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.441605016814394 | validation: 0.3164761934026796]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4885424036809004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4885424036809004 | validation: 0.6784640999367637]
	TIME [epoch: 9.21 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4126985671281827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4126985671281827 | validation: 0.4601491400703268]
	TIME [epoch: 9.21 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5529099215012602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5529099215012602 | validation: 0.6138694169517134]
	TIME [epoch: 9.22 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4191078237832285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4191078237832285 | validation: 0.5638482654507395]
	TIME [epoch: 9.24 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45633723724379766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45633723724379766 | validation: 1.5934143098740057]
	TIME [epoch: 9.23 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6567509138049672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6567509138049672 | validation: 0.4374481670787046]
	TIME [epoch: 9.22 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41014131380295105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41014131380295105 | validation: 0.33965663112527983]
	TIME [epoch: 9.23 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34365864779400607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34365864779400607 | validation: 0.5580715143731598]
	TIME [epoch: 9.22 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42108788236133543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42108788236133543 | validation: 0.2838108770450307]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35730409669239055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35730409669239055 | validation: 0.4052389761288405]
	TIME [epoch: 9.2 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43460179053843334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43460179053843334 | validation: 0.3411013086727394]
	TIME [epoch: 9.2 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3277068372446148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3277068372446148 | validation: 0.4679018356627529]
	TIME [epoch: 9.22 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4667709766689744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4667709766689744 | validation: 0.3659871605516666]
	TIME [epoch: 9.21 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6881756741242705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6881756741242705 | validation: 0.4127660582939604]
	TIME [epoch: 9.23 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44362055604086753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44362055604086753 | validation: 0.2120055870224163]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33901700846209004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33901700846209004 | validation: 0.4031814005027111]
	TIME [epoch: 9.21 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3608846520223493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3608846520223493 | validation: 0.239073229528739]
	TIME [epoch: 9.22 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5046105398336616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5046105398336616 | validation: 0.2926827517183903]
	TIME [epoch: 9.22 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41605827488895625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41605827488895625 | validation: 0.3324277730696612]
	TIME [epoch: 9.24 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3496822727502246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3496822727502246 | validation: 0.2558646115949281]
	TIME [epoch: 9.21 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3954881685586524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3954881685586524 | validation: 0.2724160019433677]
	TIME [epoch: 9.22 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3539194939710417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3539194939710417 | validation: 0.35687295005708]
	TIME [epoch: 9.22 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37304715457630033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37304715457630033 | validation: 0.4705258903176602]
	TIME [epoch: 9.22 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.560214146522166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.560214146522166 | validation: 0.4070222118924801]
	TIME [epoch: 9.23 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4139448165768659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4139448165768659 | validation: 0.4633815680235407]
	TIME [epoch: 9.2 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3677294983476552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3677294983476552 | validation: 0.3471847086706089]
	TIME [epoch: 9.21 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3655545498994615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3655545498994615 | validation: 0.2505464973199035]
	TIME [epoch: 9.23 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39462300170889936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39462300170889936 | validation: 0.5074483109617458]
	TIME [epoch: 9.24 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34580072598662315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34580072598662315 | validation: 0.3132558110805871]
	TIME [epoch: 9.23 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33687059518496953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33687059518496953 | validation: 0.38588030046330196]
	TIME [epoch: 9.23 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44646189422522314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44646189422522314 | validation: 0.46905568768704]
	TIME [epoch: 9.24 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39575623980833824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39575623980833824 | validation: 0.2576539893359069]
	TIME [epoch: 9.23 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.362776657466718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.362776657466718 | validation: 0.34982445217186303]
	TIME [epoch: 9.26 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32590443453409906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32590443453409906 | validation: 0.35003759153502434]
	TIME [epoch: 9.23 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40720377400271196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40720377400271196 | validation: 0.2722112503778771]
	TIME [epoch: 9.23 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32977179880152097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32977179880152097 | validation: 0.37249842394935606]
	TIME [epoch: 9.23 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35183261974355307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35183261974355307 | validation: 0.4551002480754577]
	TIME [epoch: 9.24 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33958241038511083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33958241038511083 | validation: 0.707633172990892]
	TIME [epoch: 9.24 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38411845781759724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38411845781759724 | validation: 0.35818671593489715]
	TIME [epoch: 9.23 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3902552866314313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3902552866314313 | validation: 1.0831046676430076]
	TIME [epoch: 9.24 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3993552242492194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3993552242492194 | validation: 0.4433599037714672]
	TIME [epoch: 9.24 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33331605246944357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33331605246944357 | validation: 0.4512804863920715]
	TIME [epoch: 9.23 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3296284308191456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3296284308191456 | validation: 0.31675401321572016]
	TIME [epoch: 9.25 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34493922366759955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34493922366759955 | validation: 0.425391218838278]
	TIME [epoch: 9.24 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3254425234554452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3254425234554452 | validation: 0.4844714627714186]
	TIME [epoch: 9.24 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.340659349704333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.340659349704333 | validation: 0.2419163449990966]
	TIME [epoch: 9.24 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3388567367224469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3388567367224469 | validation: 0.3082000599653226]
	TIME [epoch: 9.23 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3138387632165281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3138387632165281 | validation: 0.33996978612188145]
	TIME [epoch: 9.25 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2769310132273807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2769310132273807 | validation: 0.2804622195320129]
	TIME [epoch: 9.23 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2954644647821293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2954644647821293 | validation: 0.310257534691896]
	TIME [epoch: 9.24 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36840543747318366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36840543747318366 | validation: 0.3732563249394402]
	TIME [epoch: 9.24 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34787195934398374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34787195934398374 | validation: 0.2719792516318925]
	TIME [epoch: 9.24 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2502556854110156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2502556854110156 | validation: 0.3400150861736211]
	TIME [epoch: 9.25 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29840152524175256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29840152524175256 | validation: 0.33951029578733705]
	TIME [epoch: 9.24 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42358054619157803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42358054619157803 | validation: 0.308925699825765]
	TIME [epoch: 9.24 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27474628036555543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27474628036555543 | validation: 0.23499584721036823]
	TIME [epoch: 9.24 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28291325898781206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28291325898781206 | validation: 0.42095540880885257]
	TIME [epoch: 9.23 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2993783097203499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2993783097203499 | validation: 0.6293117473280005]
	TIME [epoch: 9.25 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40553915506111604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40553915506111604 | validation: 0.2578960144562845]
	TIME [epoch: 9.24 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9644638433550323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9644638433550323 | validation: 1.2298191121691384]
	TIME [epoch: 9.24 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.643562072126276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.643562072126276 | validation: 0.4626629487618988]
	TIME [epoch: 9.24 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3112734270219333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3112734270219333 | validation: 0.28881795818224965]
	TIME [epoch: 9.24 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2587535907738588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2587535907738588 | validation: 0.24011076833959435]
	TIME [epoch: 9.25 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3210993933685099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3210993933685099 | validation: 0.26183211124361494]
	TIME [epoch: 9.24 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2944102043417069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2944102043417069 | validation: 0.21409678962943363]
	TIME [epoch: 9.24 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26059415425589255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26059415425589255 | validation: 0.2188717187286527]
	TIME [epoch: 9.23 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36729124661014395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36729124661014395 | validation: 0.36184808149639613]
	TIME [epoch: 9.24 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2890063280945263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2890063280945263 | validation: 0.23662702457816376]
	TIME [epoch: 9.26 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2569610954235051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2569610954235051 | validation: 0.21066132128349818]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6523198293157667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6523198293157667 | validation: 0.6966125307386856]
	TIME [epoch: 9.23 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.536293843226533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.536293843226533 | validation: 0.2564572157938927]
	TIME [epoch: 9.21 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26176446338911397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26176446338911397 | validation: 0.2646146945420531]
	TIME [epoch: 9.23 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2783289745662731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2783289745662731 | validation: 0.23956137157014362]
	TIME [epoch: 9.24 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24555822993385798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24555822993385798 | validation: 0.4063600869959646]
	TIME [epoch: 9.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3017780321418714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3017780321418714 | validation: 0.2687194187132408]
	TIME [epoch: 9.22 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4800329744116916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4800329744116916 | validation: 2.556584878324878]
	TIME [epoch: 9.23 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8320138780103934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8320138780103934 | validation: 0.20538390637570902]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22593438034922464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22593438034922464 | validation: 0.30149693682270107]
	TIME [epoch: 9.24 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30005861547205565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30005861547205565 | validation: 0.5043261575746435]
	TIME [epoch: 9.22 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3336654496815563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3336654496815563 | validation: 0.5048117758093356]
	TIME [epoch: 9.22 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29198084162726434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29198084162726434 | validation: 0.39834478221647646]
	TIME [epoch: 9.23 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32608332263232376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32608332263232376 | validation: 0.26575254953124483]
	TIME [epoch: 9.24 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2686089281355829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2686089281355829 | validation: 0.5638493929832119]
	TIME [epoch: 9.24 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.290790574924244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.290790574924244 | validation: 0.2122365795509883]
	TIME [epoch: 9.22 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3252652930120246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3252652930120246 | validation: 0.2400716500716169]
	TIME [epoch: 9.24 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2289256878745573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2289256878745573 | validation: 0.42449284605923754]
	TIME [epoch: 9.22 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26246669336441625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26246669336441625 | validation: 0.24275895753450044]
	TIME [epoch: 9.26 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.333712849121922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.333712849121922 | validation: 0.22576927102217365]
	TIME [epoch: 9.22 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5099967853245604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5099967853245604 | validation: 0.20505096948620605]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2551273061597481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2551273061597481 | validation: 0.21874888857330527]
	TIME [epoch: 9.23 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22917564645120217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22917564645120217 | validation: 0.2782517660116465]
	TIME [epoch: 9.23 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26116353274139736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26116353274139736 | validation: 0.1951008898088612]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27516910890452456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27516910890452456 | validation: 0.2623155194521491]
	TIME [epoch: 9.22 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27576138547858137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27576138547858137 | validation: 0.3554998966796769]
	TIME [epoch: 9.22 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29626317929534335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29626317929534335 | validation: 0.1704895707698691]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.255391412728844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.255391412728844 | validation: 0.17220369353127318]
	TIME [epoch: 9.23 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26927508184253063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26927508184253063 | validation: 0.203898140171151]
	TIME [epoch: 9.25 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24982498117408639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24982498117408639 | validation: 0.3189293543878192]
	TIME [epoch: 9.23 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.264723725509722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.264723725509722 | validation: 0.21193111920045524]
	TIME [epoch: 9.23 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30297417896856144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30297417896856144 | validation: 0.2521459042580135]
	TIME [epoch: 9.23 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27157843078960264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27157843078960264 | validation: 0.1820662027365702]
	TIME [epoch: 9.23 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2956987729662656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2956987729662656 | validation: 0.22116161297264464]
	TIME [epoch: 9.25 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24697590241765321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24697590241765321 | validation: 0.29538564748182616]
	TIME [epoch: 9.23 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24855655803001347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24855655803001347 | validation: 0.2405444427483593]
	TIME [epoch: 9.23 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43826542226847093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43826542226847093 | validation: 0.35751555634424304]
	TIME [epoch: 9.23 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24305811874372685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24305811874372685 | validation: 0.36568666090486057]
	TIME [epoch: 9.23 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2561277673044529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2561277673044529 | validation: 0.2572724040651294]
	TIME [epoch: 9.25 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24223348909050216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24223348909050216 | validation: 0.3487935009155607]
	TIME [epoch: 9.23 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39694930550142493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39694930550142493 | validation: 0.27761865379960626]
	TIME [epoch: 9.24 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2390009333178244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2390009333178244 | validation: 0.19390146950790677]
	TIME [epoch: 9.24 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2696228216442204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2696228216442204 | validation: 0.24903361796498402]
	TIME [epoch: 9.22 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26799944364845624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26799944364845624 | validation: 0.19935682703005292]
	TIME [epoch: 9.25 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.237365929972579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.237365929972579 | validation: 0.17931364647776704]
	TIME [epoch: 9.23 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5859306496742935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5859306496742935 | validation: 0.48730303944478565]
	TIME [epoch: 9.23 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7763894863947441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7763894863947441 | validation: 0.43510456908505]
	TIME [epoch: 9.24 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9549865559824322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9549865559824322 | validation: 0.3384505255386089]
	TIME [epoch: 9.23 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3767597544775762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3767597544775762 | validation: 0.23585940620562107]
	TIME [epoch: 9.25 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40303441924533046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40303441924533046 | validation: 0.6919860388938138]
	TIME [epoch: 9.24 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5224905872121466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5224905872121466 | validation: 0.31853276317750473]
	TIME [epoch: 9.22 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3024363303642766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3024363303642766 | validation: 0.36223874244960674]
	TIME [epoch: 9.23 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3914175532657674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3914175532657674 | validation: 0.4161904811739494]
	TIME [epoch: 9.22 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6490510880785804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6490510880785804 | validation: 0.7424147472954978]
	TIME [epoch: 9.26 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.374630823098502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.374630823098502 | validation: 0.31902243594767066]
	TIME [epoch: 9.24 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2786465761911043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2786465761911043 | validation: 0.15303971337808359]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2040521114158061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2040521114158061 | validation: 0.32599750514404174]
	TIME [epoch: 9.25 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.131966739203571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.131966739203571 | validation: 0.48265929254982476]
	TIME [epoch: 9.24 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5426790620851035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5426790620851035 | validation: 0.2906203099322077]
	TIME [epoch: 9.26 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29211932089190884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29211932089190884 | validation: 0.46807159078250554]
	TIME [epoch: 9.23 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4607236944841587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4607236944841587 | validation: 0.3366433016644883]
	TIME [epoch: 9.24 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28840950267288934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28840950267288934 | validation: 0.624739666200802]
	TIME [epoch: 9.24 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3574543201488571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3574543201488571 | validation: 0.4493298429839325]
	TIME [epoch: 9.24 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49024595202540794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49024595202540794 | validation: 0.41860909865506996]
	TIME [epoch: 9.25 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4093571179728803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4093571179728803 | validation: 0.2711131994373511]
	TIME [epoch: 9.24 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2813628930073995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2813628930073995 | validation: 0.16087257080993284]
	TIME [epoch: 9.24 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29672028955096713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29672028955096713 | validation: 0.23650744876544344]
	TIME [epoch: 9.23 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20778759930853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20778759930853 | validation: 0.1698038887976101]
	TIME [epoch: 9.25 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.163255652477831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.163255652477831 | validation: 0.16477564733053415]
	TIME [epoch: 9.25 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17521488165539004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17521488165539004 | validation: 0.36257532034855056]
	TIME [epoch: 9.23 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4881449715049043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4881449715049043 | validation: 0.6507563086725705]
	TIME [epoch: 9.23 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4083792603857807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4083792603857807 | validation: 0.33045905734140124]
	TIME [epoch: 9.24 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2502983880773289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2502983880773289 | validation: 0.19305002932751247]
	TIME [epoch: 9.25 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2671058706632351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2671058706632351 | validation: 0.3069282631644554]
	TIME [epoch: 9.24 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3361850930756883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3361850930756883 | validation: 0.36922018519388444]
	TIME [epoch: 9.23 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2995614071913133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2995614071913133 | validation: 0.5431563168269257]
	TIME [epoch: 9.23 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5249574073970789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5249574073970789 | validation: 0.24234301507793174]
	TIME [epoch: 9.24 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23394527190647313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23394527190647313 | validation: 0.23117525442494585]
	TIME [epoch: 9.25 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2815721049122287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2815721049122287 | validation: 0.26446867605482266]
	TIME [epoch: 9.24 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3425700040154178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3425700040154178 | validation: 0.40641594371625384]
	TIME [epoch: 9.24 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25934826338095857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25934826338095857 | validation: 0.2887540810453122]
	TIME [epoch: 9.24 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23288491946471077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23288491946471077 | validation: 0.3227085718356261]
	TIME [epoch: 9.24 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4528404842333951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4528404842333951 | validation: 0.46564448423716187]
	TIME [epoch: 9.25 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28254879988371867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28254879988371867 | validation: 0.2053456984553942]
	TIME [epoch: 9.24 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18827534012285424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18827534012285424 | validation: 0.4644558735472106]
	TIME [epoch: 9.24 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5171197905417139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5171197905417139 | validation: 0.9308799357646638]
	TIME [epoch: 9.24 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7809076988097055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7809076988097055 | validation: 0.2662930217305832]
	TIME [epoch: 9.23 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3946183742549502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3946183742549502 | validation: 0.5037768374998172]
	TIME [epoch: 9.26 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3193776685881214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3193776685881214 | validation: 0.26979346979710717]
	TIME [epoch: 9.24 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34639670025179503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34639670025179503 | validation: 0.3126404957564461]
	TIME [epoch: 9.23 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2557033036540489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2557033036540489 | validation: 0.2404909803025878]
	TIME [epoch: 9.23 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29285467789728103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29285467789728103 | validation: 0.20805163487781536]
	TIME [epoch: 9.24 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2787882509992645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2787882509992645 | validation: 0.18149701734428736]
	TIME [epoch: 9.26 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23548656907144827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23548656907144827 | validation: 0.27512193008927477]
	TIME [epoch: 9.24 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24734417026926964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24734417026926964 | validation: 1.6920730930846797]
	TIME [epoch: 9.24 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39633408939843473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39633408939843473 | validation: 0.1918283235540928]
	TIME [epoch: 9.24 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2513497614454048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2513497614454048 | validation: 0.2214943457881806]
	TIME [epoch: 9.24 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26075452739290444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26075452739290444 | validation: 0.33290244282636083]
	TIME [epoch: 9.26 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24415137636784415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24415137636784415 | validation: 0.17072844358548517]
	TIME [epoch: 9.24 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25517779700607257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25517779700607257 | validation: 0.3516179469556998]
	TIME [epoch: 9.25 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2619495251277145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2619495251277145 | validation: 0.18830989509607032]
	TIME [epoch: 9.24 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23087143764149837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23087143764149837 | validation: 0.2696693660437224]
	TIME [epoch: 9.24 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2957545266055583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2957545266055583 | validation: 0.1660771831512468]
	TIME [epoch: 9.26 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23732543129379108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23732543129379108 | validation: 0.4587879574822341]
	TIME [epoch: 9.24 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29466150844332073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29466150844332073 | validation: 0.2733156150977519]
	TIME [epoch: 9.24 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2880049164760164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2880049164760164 | validation: 0.22593223997650633]
	TIME [epoch: 9.23 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2606219749137043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2606219749137043 | validation: 0.26782286586895554]
	TIME [epoch: 9.24 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29059092409582304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29059092409582304 | validation: 0.3582053476175417]
	TIME [epoch: 9.26 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24105464228452736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24105464228452736 | validation: 0.5141708900331585]
	TIME [epoch: 9.25 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2827963909974518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2827963909974518 | validation: 0.17902148910576748]
	TIME [epoch: 9.23 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.250290991909971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.250290991909971 | validation: 0.14238140450902226]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2121462000056244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2121462000056244 | validation: 0.22908530016715248]
	TIME [epoch: 9.24 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3736928526897677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3736928526897677 | validation: 0.5536490185675336]
	TIME [epoch: 9.26 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1824684234237186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1824684234237186 | validation: 0.3098133718909921]
	TIME [epoch: 9.24 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2681925683675029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2681925683675029 | validation: 0.24685368098006422]
	TIME [epoch: 9.24 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29523578559125846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29523578559125846 | validation: 0.1404718491002011]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24320401144863904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24320401144863904 | validation: 0.18404247376765992]
	TIME [epoch: 9.25 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7900274689107021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7900274689107021 | validation: 1.789107062775233]
	TIME [epoch: 9.25 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5261209869695749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5261209869695749 | validation: 0.24497150161408154]
	TIME [epoch: 9.24 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2704578240559373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2704578240559373 | validation: 0.1851791163444041]
	TIME [epoch: 9.23 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24146120591956466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24146120591956466 | validation: 0.16334176193038977]
	TIME [epoch: 9.24 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2501806880810682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2501806880810682 | validation: 0.347153374368953]
	TIME [epoch: 9.24 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23142270456793673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23142270456793673 | validation: 0.278893742912278]
	TIME [epoch: 9.25 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31198692802837413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31198692802837413 | validation: 0.41541129026416024]
	TIME [epoch: 9.23 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.492745477945459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.492745477945459 | validation: 0.3012524476379336]
	TIME [epoch: 9.24 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22417974781129493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22417974781129493 | validation: 0.2289747557767657]
	TIME [epoch: 9.23 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2504541419685499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2504541419685499 | validation: 0.1883561163843131]
	TIME [epoch: 9.25 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2072232636208149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2072232636208149 | validation: 0.22834496935908596]
	TIME [epoch: 9.24 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3386073739481759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3386073739481759 | validation: 0.6259989549210823]
	TIME [epoch: 9.24 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2512320738806054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2512320738806054 | validation: 0.2963253686225463]
	TIME [epoch: 9.23 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28914075793127686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28914075793127686 | validation: 0.182787557880307]
	TIME [epoch: 9.24 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.227108926989468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.227108926989468 | validation: 0.20974500644053107]
	TIME [epoch: 9.25 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30020696101344563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30020696101344563 | validation: 0.4775414518909181]
	TIME [epoch: 9.24 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3436759703220771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3436759703220771 | validation: 0.3670312568868551]
	TIME [epoch: 9.24 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31439102299413435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31439102299413435 | validation: 0.2610134341902373]
	TIME [epoch: 9.24 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24987299491211273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24987299491211273 | validation: 0.2642051614373944]
	TIME [epoch: 9.23 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26717041851521467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26717041851521467 | validation: 0.1624428248038113]
	TIME [epoch: 9.26 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24168989016020737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24168989016020737 | validation: 0.251451805253995]
	TIME [epoch: 9.24 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26164642527723875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26164642527723875 | validation: 0.2743624344664476]
	TIME [epoch: 9.23 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2513736437842292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2513736437842292 | validation: 0.40093521169271873]
	TIME [epoch: 9.19 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29012771301594564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29012771301594564 | validation: 0.34140788483536955]
	TIME [epoch: 9.18 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4125832806799991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4125832806799991 | validation: 0.19602915813097027]
	TIME [epoch: 9.26 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3240447294881687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3240447294881687 | validation: 0.22169895301523795]
	TIME [epoch: 9.24 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.250750051268934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.250750051268934 | validation: 0.25789892331440784]
	TIME [epoch: 9.24 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32358273105940827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32358273105940827 | validation: 0.18732090499777132]
	TIME [epoch: 9.24 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2137985853202466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2137985853202466 | validation: 0.23563332625380673]
	TIME [epoch: 9.23 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25329093327432567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25329093327432567 | validation: 0.3366214625404]
	TIME [epoch: 9.25 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23836990801422897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23836990801422897 | validation: 0.1939504434923563]
	TIME [epoch: 9.21 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21803303745158273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21803303745158273 | validation: 0.28890428244479516]
	TIME [epoch: 9.23 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29008248908419426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29008248908419426 | validation: 0.62414416255042]
	TIME [epoch: 9.24 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2858141042362431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2858141042362431 | validation: 0.1726678809103829]
	TIME [epoch: 9.21 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24342408973624785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24342408973624785 | validation: 0.195055194735422]
	TIME [epoch: 9.25 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20195097882818844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20195097882818844 | validation: 0.2406216964623868]
	TIME [epoch: 9.24 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2484379872965083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2484379872965083 | validation: 0.30363277480172024]
	TIME [epoch: 9.24 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22499030511645218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22499030511645218 | validation: 0.21457653510609315]
	TIME [epoch: 9.24 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24536195320881693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24536195320881693 | validation: 0.1865894944819742]
	TIME [epoch: 9.25 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2286598962853299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2286598962853299 | validation: 0.2504539797989068]
	TIME [epoch: 9.26 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23504210612233928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23504210612233928 | validation: 0.2300384812539269]
	TIME [epoch: 9.24 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2443303097578951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2443303097578951 | validation: 0.2004543692509787]
	TIME [epoch: 9.24 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2741606350035979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2741606350035979 | validation: 0.1682122822402251]
	TIME [epoch: 9.24 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25304644883277866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25304644883277866 | validation: 0.37858123663765186]
	TIME [epoch: 9.24 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29642959272287933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29642959272287933 | validation: 0.1892415530155233]
	TIME [epoch: 9.26 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22600192623774423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22600192623774423 | validation: 0.21180257917187661]
	TIME [epoch: 9.24 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24464628066439448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24464628066439448 | validation: 0.20330274546721389]
	TIME [epoch: 9.25 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2568030306152086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2568030306152086 | validation: 0.6033257923818821]
	TIME [epoch: 9.24 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2160634797025134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2160634797025134 | validation: 0.3205673916092928]
	TIME [epoch: 9.24 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1584974738327078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1584974738327078 | validation: 0.3534058494643647]
	TIME [epoch: 9.27 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49010643913570195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49010643913570195 | validation: 0.4926787797717143]
	TIME [epoch: 9.25 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.629415408670523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.629415408670523 | validation: 0.2875115243579028]
	TIME [epoch: 9.24 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3928790759765778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3928790759765778 | validation: 0.3311742052897051]
	TIME [epoch: 9.25 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31908257924778793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31908257924778793 | validation: 0.17511369802905036]
	TIME [epoch: 9.25 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24158269747168237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24158269747168237 | validation: 0.40394271978959595]
	TIME [epoch: 9.28 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27331364400564945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27331364400564945 | validation: 0.16450118368063693]
	TIME [epoch: 9.25 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24264790865527502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24264790865527502 | validation: 0.16606847447632855]
	TIME [epoch: 9.24 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30382744966500275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30382744966500275 | validation: 0.23419628430367792]
	TIME [epoch: 9.25 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2038452161629664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2038452161629664 | validation: 0.17092727935559154]
	TIME [epoch: 9.24 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25718365966578255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25718365966578255 | validation: 0.15175314503478005]
	TIME [epoch: 9.27 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2552531738530645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2552531738530645 | validation: 0.17828971475276045]
	TIME [epoch: 9.23 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.191645262593406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.191645262593406 | validation: 0.18378974334064183]
	TIME [epoch: 9.24 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2208886518390706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2208886518390706 | validation: 0.16089529026194038]
	TIME [epoch: 9.24 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2601509547657098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2601509547657098 | validation: 0.15123394014173536]
	TIME [epoch: 9.25 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21156347957066252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21156347957066252 | validation: 0.2023518183282373]
	TIME [epoch: 9.26 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4378329826642978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4378329826642978 | validation: 0.40158526107168846]
	TIME [epoch: 9.25 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8781327669221562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8781327669221562 | validation: 0.565995259467318]
	TIME [epoch: 9.25 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9004729913612157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9004729913612157 | validation: 0.4807162332646343]
	TIME [epoch: 9.25 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5188049789830956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5188049789830956 | validation: 0.1960137378996416]
	TIME [epoch: 9.26 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36812164727778524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36812164727778524 | validation: 0.2680386753534076]
	TIME [epoch: 9.26 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2977338477865271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2977338477865271 | validation: 0.18863112205960525]
	TIME [epoch: 9.25 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22435110889837726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22435110889837726 | validation: 0.1733214455213016]
	TIME [epoch: 9.25 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19633749779945944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19633749779945944 | validation: 0.27848353963515576]
	TIME [epoch: 9.24 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2053067416472829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2053067416472829 | validation: 0.20550221523243803]
	TIME [epoch: 9.27 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16808079167747883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16808079167747883 | validation: 0.15814718902863117]
	TIME [epoch: 9.25 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22246570669558535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22246570669558535 | validation: 0.19894428844249362]
	TIME [epoch: 9.25 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3601003403814825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3601003403814825 | validation: 0.18770990256750383]
	TIME [epoch: 9.24 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21019759824475187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21019759824475187 | validation: 0.21277779778521877]
	TIME [epoch: 9.24 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.252620078464532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.252620078464532 | validation: 0.26821632754314595]
	TIME [epoch: 9.26 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4176869575731958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4176869575731958 | validation: 0.3366618223230068]
	TIME [epoch: 9.25 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3352745015387203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3352745015387203 | validation: 0.23310247198633668]
	TIME [epoch: 9.24 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.363617032414624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.363617032414624 | validation: 0.33103769975045205]
	TIME [epoch: 9.25 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3155591241237313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3155591241237313 | validation: 0.4680464217516944]
	TIME [epoch: 9.25 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9194424175160105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9194424175160105 | validation: 0.5318920342260431]
	TIME [epoch: 9.27 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6209043895056473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6209043895056473 | validation: 0.4706600233032773]
	TIME [epoch: 9.25 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5443044082350624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5443044082350624 | validation: 3.2730934768236937]
	TIME [epoch: 9.24 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8530563138858576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8530563138858576 | validation: 0.5087326402161847]
	TIME [epoch: 9.25 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18284000569053754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18284000569053754 | validation: 0.28867416968700615]
	TIME [epoch: 9.24 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1892545188534772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1892545188534772 | validation: 0.21707129912771334]
	TIME [epoch: 9.27 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32732172363174383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32732172363174383 | validation: 0.32265241774551207]
	TIME [epoch: 9.25 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5042646922297733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5042646922297733 | validation: 0.46874548114012615]
	TIME [epoch: 9.25 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32541720974240795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32541720974240795 | validation: 0.368128601598677]
	TIME [epoch: 9.25 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23698162896199598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23698162896199598 | validation: 0.11593950356514118]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4322649107451692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4322649107451692 | validation: 0.3161725325124033]
	TIME [epoch: 9.26 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22692057538776864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22692057538776864 | validation: 0.1862246527820181]
	TIME [epoch: 9.25 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20858159684102984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20858159684102984 | validation: 0.3512642299262404]
	TIME [epoch: 9.25 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2750663594269899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2750663594269899 | validation: 0.3124016181391203]
	TIME [epoch: 9.24 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35642048863498166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35642048863498166 | validation: 0.4316323550461259]
	TIME [epoch: 9.25 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6429478905610456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6429478905610456 | validation: 0.6813698639274279]
	TIME [epoch: 9.27 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5252135773206212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5252135773206212 | validation: 0.4821131621758887]
	TIME [epoch: 9.25 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5963022924742221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5963022924742221 | validation: 0.24192707220700588]
	TIME [epoch: 9.24 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3310443359449248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3310443359449248 | validation: 0.2864307227802996]
	TIME [epoch: 9.24 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3539578668336104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3539578668336104 | validation: 0.29491218571506456]
	TIME [epoch: 9.25 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21514712325628035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21514712325628035 | validation: 0.18717701890790944]
	TIME [epoch: 9.26 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20868992727929872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20868992727929872 | validation: 0.09234616542866499]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_372.pth
	Model improved!!!
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4441107616899818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4441107616899818 | validation: 0.23304208097247883]
	TIME [epoch: 9.24 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41933640310636433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41933640310636433 | validation: 0.26685693440628355]
	TIME [epoch: 9.24 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33120899478888854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33120899478888854 | validation: 0.30604362195546914]
	TIME [epoch: 9.24 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3685987850892765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3685987850892765 | validation: 0.3944524011526285]
	TIME [epoch: 9.26 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2300418314928324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2300418314928324 | validation: 0.2051784835068141]
	TIME [epoch: 9.92 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24058370603288134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24058370603288134 | validation: 0.5029925285165813]
	TIME [epoch: 9.24 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2961653086450559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2961653086450559 | validation: 0.13669152487410416]
	TIME [epoch: 9.24 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46011107284492747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46011107284492747 | validation: 1.5474251294654724]
	TIME [epoch: 9.25 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4440088295227519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4440088295227519 | validation: 0.34540620243079845]
	TIME [epoch: 9.26 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2547422659832588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2547422659832588 | validation: 0.15425517400139643]
	TIME [epoch: 9.23 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26521553801991377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26521553801991377 | validation: 0.1658292231707024]
	TIME [epoch: 9.23 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23952177188067547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23952177188067547 | validation: 0.305678859674656]
	TIME [epoch: 9.25 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3020149544308319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3020149544308319 | validation: 0.25996568689263083]
	TIME [epoch: 9.26 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49675259481073175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49675259481073175 | validation: 1.1397310523105872]
	TIME [epoch: 9.26 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5342722423985968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5342722423985968 | validation: 0.2168446272817457]
	TIME [epoch: 9.24 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34822457758129544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34822457758129544 | validation: 0.14647061172421788]
	TIME [epoch: 9.25 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2269392894075788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2269392894075788 | validation: 0.2623395854645693]
	TIME [epoch: 9.24 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37771477540891824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37771477540891824 | validation: 0.3715735938115497]
	TIME [epoch: 9.26 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31865698923327573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31865698923327573 | validation: 0.2862455057859896]
	TIME [epoch: 9.25 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21864696833827776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21864696833827776 | validation: 0.22486374952741903]
	TIME [epoch: 9.25 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2645876897613956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2645876897613956 | validation: 0.5117982262028561]
	TIME [epoch: 9.24 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3019518078941338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3019518078941338 | validation: 0.1560045151287544]
	TIME [epoch: 9.24 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.313764880454631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.313764880454631 | validation: 0.9759834918101149]
	TIME [epoch: 9.27 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41950339508625467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41950339508625467 | validation: 0.2423706585790002]
	TIME [epoch: 9.25 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18571007106458165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18571007106458165 | validation: 0.1785174236361901]
	TIME [epoch: 9.25 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23209497420265093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23209497420265093 | validation: 0.22637816794330867]
	TIME [epoch: 9.25 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2927767319163125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2927767319163125 | validation: 0.28342712730426434]
	TIME [epoch: 9.25 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28208374989436413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28208374989436413 | validation: 0.37101344127317004]
	TIME [epoch: 9.27 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32898551235485496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32898551235485496 | validation: 0.2516699064989205]
	TIME [epoch: 9.25 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28893614612752533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28893614612752533 | validation: 0.8092879818456589]
	TIME [epoch: 9.24 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3460994059020136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3460994059020136 | validation: 0.35289444677120174]
	TIME [epoch: 9.25 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6366138495862413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6366138495862413 | validation: 0.30778762807838966]
	TIME [epoch: 9.25 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4335798857113148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4335798857113148 | validation: 0.4403582886288419]
	TIME [epoch: 9.27 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37635014437297865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37635014437297865 | validation: 0.22949015549668345]
	TIME [epoch: 9.25 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22892785588123393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22892785588123393 | validation: 0.24929417649881064]
	TIME [epoch: 9.25 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20223803380744987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20223803380744987 | validation: 0.15773173888290662]
	TIME [epoch: 9.25 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27770097281736755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27770097281736755 | validation: 0.1383020683479815]
	TIME [epoch: 9.25 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22177360458825796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22177360458825796 | validation: 0.14286180378039548]
	TIME [epoch: 9.26 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26650981052170664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26650981052170664 | validation: 0.14378428715134184]
	TIME [epoch: 9.25 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1731237498051093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1731237498051093 | validation: 0.22272708040136757]
	TIME [epoch: 9.26 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1834341277262816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1834341277262816 | validation: 0.30615668291087283]
	TIME [epoch: 9.24 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22298650411551427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22298650411551427 | validation: 0.19888698193582932]
	TIME [epoch: 9.24 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33364816762721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33364816762721 | validation: 0.15341741237090753]
	TIME [epoch: 9.27 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20066680337245807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20066680337245807 | validation: 0.24987183005204783]
	TIME [epoch: 9.24 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2598621391926225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2598621391926225 | validation: 0.31856448437934826]
	TIME [epoch: 9.24 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24011331043428186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24011331043428186 | validation: 0.25860289308440104]
	TIME [epoch: 9.24 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2569571969217416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2569571969217416 | validation: 0.32486738070131815]
	TIME [epoch: 9.24 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2803522735010099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2803522735010099 | validation: 0.18722228903660754]
	TIME [epoch: 9.26 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25816823354987284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25816823354987284 | validation: 0.21161999568998688]
	TIME [epoch: 9.25 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21756675240581025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21756675240581025 | validation: 0.23316704208381117]
	TIME [epoch: 9.25 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2484837457804298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2484837457804298 | validation: 0.25771988892220365]
	TIME [epoch: 9.24 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25879368863428887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25879368863428887 | validation: 0.29656991182997194]
	TIME [epoch: 9.25 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20772665656094325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20772665656094325 | validation: 0.15541663539776224]
	TIME [epoch: 9.27 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33017231370986055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33017231370986055 | validation: 0.27405617555914386]
	TIME [epoch: 9.24 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22604901375846756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22604901375846756 | validation: 1.4692930946083873]
	TIME [epoch: 9.25 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9647772760379315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9647772760379315 | validation: 2.132123826586114]
	TIME [epoch: 9.25 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45230162584780276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45230162584780276 | validation: 0.18514869692958352]
	TIME [epoch: 9.24 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2179118280707834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2179118280707834 | validation: 0.18537940086250942]
	TIME [epoch: 9.26 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2747596988259592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2747596988259592 | validation: 0.2275825087157789]
	TIME [epoch: 9.24 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24785615732205796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24785615732205796 | validation: 0.24487438664636654]
	TIME [epoch: 9.25 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24648547112117963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24648547112117963 | validation: 0.3017953206667647]
	TIME [epoch: 9.24 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25458012109429484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25458012109429484 | validation: 0.18230758942896397]
	TIME [epoch: 9.24 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2527628579548412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2527628579548412 | validation: 0.2273295974307662]
	TIME [epoch: 9.26 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1949653737330874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1949653737330874 | validation: 0.20757998472384834]
	TIME [epoch: 9.24 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26623531161678976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26623531161678976 | validation: 0.19326621322111037]
	TIME [epoch: 9.25 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1965863486804236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1965863486804236 | validation: 0.5063192945561729]
	TIME [epoch: 9.25 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32752334134251015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32752334134251015 | validation: 0.20105021894823497]
	TIME [epoch: 9.25 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41167690657122413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41167690657122413 | validation: 0.2752649792193822]
	TIME [epoch: 9.26 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25716576883350856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25716576883350856 | validation: 0.16992815095316213]
	TIME [epoch: 9.25 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.272966764994497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.272966764994497 | validation: 0.2970967703655802]
	TIME [epoch: 9.24 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.29343602154784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.29343602154784 | validation: 3.3019579806424346]
	TIME [epoch: 9.25 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7980682638202423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7980682638202423 | validation: 0.4461770243976327]
	TIME [epoch: 9.25 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4978161215133675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4978161215133675 | validation: 0.24689596722219886]
	TIME [epoch: 9.25 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3321245133811447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3321245133811447 | validation: 0.2657247214730687]
	TIME [epoch: 9.24 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2687542076486485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2687542076486485 | validation: 0.3126592565029692]
	TIME [epoch: 9.24 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24677334753420915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24677334753420915 | validation: 0.32865013207925586]
	TIME [epoch: 9.24 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22843757585216062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22843757585216062 | validation: 0.16665989737947368]
	TIME [epoch: 9.26 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2616015248455248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2616015248455248 | validation: 0.7833641339958421]
	TIME [epoch: 9.25 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9076932029707747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9076932029707747 | validation: 0.9242036014933348]
	TIME [epoch: 9.25 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5902746249026128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5902746249026128 | validation: 0.41119379062603223]
	TIME [epoch: 9.25 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17661716564002963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17661716564002963 | validation: 0.18114358267823105]
	TIME [epoch: 9.23 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23057062288289892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23057062288289892 | validation: 0.2824840345508265]
	TIME [epoch: 9.27 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2523774161314306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2523774161314306 | validation: 0.2699642820773518]
	TIME [epoch: 9.25 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22248429311489706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22248429311489706 | validation: 0.1505931191522078]
	TIME [epoch: 9.24 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21291275580217697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21291275580217697 | validation: 0.35476071875245063]
	TIME [epoch: 9.24 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26324585937919853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26324585937919853 | validation: 0.15943835037717136]
	TIME [epoch: 9.24 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.226237150268775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.226237150268775 | validation: 0.23906815301952644]
	TIME [epoch: 9.27 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21255113472834236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21255113472834236 | validation: 0.19995319375470452]
	TIME [epoch: 9.25 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2149849781202103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2149849781202103 | validation: 0.18201725364131174]
	TIME [epoch: 9.25 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22990670635553875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22990670635553875 | validation: 0.3717245910489678]
	TIME [epoch: 9.24 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26657585454608923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26657585454608923 | validation: 0.15105163643656835]
	TIME [epoch: 9.25 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20426494388311595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20426494388311595 | validation: 0.24106304359877762]
	TIME [epoch: 9.27 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20771833004141063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20771833004141063 | validation: 0.200349178569857]
	TIME [epoch: 9.25 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1847033702193929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1847033702193929 | validation: 0.18924788199100437]
	TIME [epoch: 9.24 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2355507221019873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2355507221019873 | validation: 0.2000220966359417]
	TIME [epoch: 9.24 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2523470112388654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2523470112388654 | validation: 0.1893823148117128]
	TIME [epoch: 9.24 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3679420918468848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3679420918468848 | validation: 0.27028600079072695]
	TIME [epoch: 9.27 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3256273802870904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3256273802870904 | validation: 0.1786516838155236]
	TIME [epoch: 9.25 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24511747014612456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24511747014612456 | validation: 0.14475402710825896]
	TIME [epoch: 9.25 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2279253379987245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2279253379987245 | validation: 0.3026547110680924]
	TIME [epoch: 9.24 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7209849678355253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7209849678355253 | validation: 0.5339928928130541]
	TIME [epoch: 9.25 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2791709900575113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2791709900575113 | validation: 0.1249478086746238]
	TIME [epoch: 9.26 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18707014411354164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18707014411354164 | validation: 0.2825274194490167]
	TIME [epoch: 9.25 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18239253075497103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18239253075497103 | validation: 0.2528364874863674]
	TIME [epoch: 9.24 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2311481482295506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2311481482295506 | validation: 0.23169247186619787]
	TIME [epoch: 9.25 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22655257222631336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22655257222631336 | validation: 0.5458188329287988]
	TIME [epoch: 9.25 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2603441753380411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2603441753380411 | validation: 0.28345830889387946]
	TIME [epoch: 9.27 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22606503643966516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22606503643966516 | validation: 0.3181795396578967]
	TIME [epoch: 9.24 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5354084454672177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5354084454672177 | validation: 0.5819402620511572]
	TIME [epoch: 9.25 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26451510896549446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26451510896549446 | validation: 0.30757426441011976]
	TIME [epoch: 9.25 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18840159711929477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18840159711929477 | validation: 0.1317817132237793]
	TIME [epoch: 9.25 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17956854310453632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17956854310453632 | validation: 0.21883139855828887]
	TIME [epoch: 9.27 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5013562890812462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5013562890812462 | validation: 0.5722284648204978]
	TIME [epoch: 9.25 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6581231848100553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6581231848100553 | validation: 0.3463817877974821]
	TIME [epoch: 9.25 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4132269792665893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4132269792665893 | validation: 0.4356101737889465]
	TIME [epoch: 9.25 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2803438101861763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2803438101861763 | validation: 0.15110241475084688]
	TIME [epoch: 9.25 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23677739344677157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23677739344677157 | validation: 0.26632631539272533]
	TIME [epoch: 9.27 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47189806611403623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47189806611403623 | validation: 0.6148131329929947]
	TIME [epoch: 9.24 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25433018249277095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25433018249277095 | validation: 0.30636165240348456]
	TIME [epoch: 9.25 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22168945657576952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22168945657576952 | validation: 0.13466547149624078]
	TIME [epoch: 9.25 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32059617671542906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32059617671542906 | validation: 0.22695279862936368]
	TIME [epoch: 9.25 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3517018002562753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3517018002562753 | validation: 0.24296357362531512]
	TIME [epoch: 9.26 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18558009437671005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18558009437671005 | validation: 0.1394379771861308]
	TIME [epoch: 9.25 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20616080922156757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20616080922156757 | validation: 0.2560607597736093]
	TIME [epoch: 9.25 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19869118262148358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19869118262148358 | validation: 0.24257819788591517]
	TIME [epoch: 9.24 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2455032471177022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2455032471177022 | validation: 0.16431568473849367]
	TIME [epoch: 9.26 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2508596632526049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2508596632526049 | validation: 0.2745541528196927]
	TIME [epoch: 9.25 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20583139253581323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20583139253581323 | validation: 0.16852202138131603]
	TIME [epoch: 9.25 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21352909907447568		[learning rate: 0.0099724]
	Learning Rate: 0.00997241
	LOSS [training: 0.21352909907447568 | validation: 0.41571647741653905]
	TIME [epoch: 9.25 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2111530360679763		[learning rate: 0.0099418]
	Learning Rate: 0.00994184
	LOSS [training: 0.2111530360679763 | validation: 0.19188300964462715]
	TIME [epoch: 9.25 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25203684115885155		[learning rate: 0.0099114]
	Learning Rate: 0.00991136
	LOSS [training: 0.25203684115885155 | validation: 0.1380465584480964]
	TIME [epoch: 9.26 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33002078683298114		[learning rate: 0.009881]
	Learning Rate: 0.00988098
	LOSS [training: 0.33002078683298114 | validation: 0.191125762721774]
	TIME [epoch: 9.25 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2394720930971177		[learning rate: 0.0098507]
	Learning Rate: 0.00985069
	LOSS [training: 0.2394720930971177 | validation: 0.20425846949989862]
	TIME [epoch: 9.24 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17491398381040812		[learning rate: 0.0098205]
	Learning Rate: 0.00982049
	LOSS [training: 0.17491398381040812 | validation: 0.2644932500216175]
	TIME [epoch: 9.25 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23334112552800002		[learning rate: 0.0097904]
	Learning Rate: 0.00979039
	LOSS [training: 0.23334112552800002 | validation: 0.1913855478642396]
	TIME [epoch: 9.24 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18311174359027024		[learning rate: 0.0097604]
	Learning Rate: 0.00976038
	LOSS [training: 0.18311174359027024 | validation: 0.15270573009543958]
	TIME [epoch: 9.26 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18003053354925896		[learning rate: 0.0097305]
	Learning Rate: 0.00973046
	LOSS [training: 0.18003053354925896 | validation: 0.2511612975319971]
	TIME [epoch: 9.25 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23236605937501958		[learning rate: 0.0097006]
	Learning Rate: 0.00970063
	LOSS [training: 0.23236605937501958 | validation: 0.19890889368186243]
	TIME [epoch: 9.25 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21865090911812093		[learning rate: 0.0096709]
	Learning Rate: 0.00967089
	LOSS [training: 0.21865090911812093 | validation: 0.14588405013458583]
	TIME [epoch: 9.25 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1988658649834014		[learning rate: 0.0096412]
	Learning Rate: 0.00964125
	LOSS [training: 0.1988658649834014 | validation: 0.15653780186450333]
	TIME [epoch: 9.24 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1601288154549515		[learning rate: 0.0096117]
	Learning Rate: 0.0096117
	LOSS [training: 0.1601288154549515 | validation: 0.14111212256828282]
	TIME [epoch: 9.26 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18118871586854712		[learning rate: 0.0095822]
	Learning Rate: 0.00958223
	LOSS [training: 0.18118871586854712 | validation: 0.2360881186793573]
	TIME [epoch: 9.24 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28315969432584026		[learning rate: 0.0095529]
	Learning Rate: 0.00955286
	LOSS [training: 0.28315969432584026 | validation: 0.17915984007191238]
	TIME [epoch: 9.24 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35942509786190757		[learning rate: 0.0095236]
	Learning Rate: 0.00952357
	LOSS [training: 0.35942509786190757 | validation: 0.33704183847395]
	TIME [epoch: 9.24 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.250387145565939		[learning rate: 0.0094944]
	Learning Rate: 0.00949438
	LOSS [training: 0.250387145565939 | validation: 0.13844041412822075]
	TIME [epoch: 9.24 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2257649873898034		[learning rate: 0.0094653]
	Learning Rate: 0.00946528
	LOSS [training: 0.2257649873898034 | validation: 0.48558666801956696]
	TIME [epoch: 9.26 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34819498698518936		[learning rate: 0.0094363]
	Learning Rate: 0.00943626
	LOSS [training: 0.34819498698518936 | validation: 0.48627339109939877]
	TIME [epoch: 9.24 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28329199344155065		[learning rate: 0.0094073]
	Learning Rate: 0.00940734
	LOSS [training: 0.28329199344155065 | validation: 0.2939763874325144]
	TIME [epoch: 9.24 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3353084003700604		[learning rate: 0.0093785]
	Learning Rate: 0.0093785
	LOSS [training: 0.3353084003700604 | validation: 0.6311369515350774]
	TIME [epoch: 9.25 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29056284216273015		[learning rate: 0.0093497]
	Learning Rate: 0.00934975
	LOSS [training: 0.29056284216273015 | validation: 0.27717599540006965]
	TIME [epoch: 9.25 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18368178462359938		[learning rate: 0.0093211]
	Learning Rate: 0.00932109
	LOSS [training: 0.18368178462359938 | validation: 0.16293191183093247]
	TIME [epoch: 9.26 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6400528043770198		[learning rate: 0.0092925]
	Learning Rate: 0.00929252
	LOSS [training: 0.6400528043770198 | validation: 0.33380932404901476]
	TIME [epoch: 9.24 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4030353524180118		[learning rate: 0.009264]
	Learning Rate: 0.00926403
	LOSS [training: 0.4030353524180118 | validation: 0.2553024314413268]
	TIME [epoch: 9.24 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22173661331721592		[learning rate: 0.0092356]
	Learning Rate: 0.00923563
	LOSS [training: 0.22173661331721592 | validation: 0.24984996015200994]
	TIME [epoch: 9.24 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27989755789417853		[learning rate: 0.0092073]
	Learning Rate: 0.00920732
	LOSS [training: 0.27989755789417853 | validation: 0.2661379924019305]
	TIME [epoch: 9.25 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.254419029506178		[learning rate: 0.0091791]
	Learning Rate: 0.0091791
	LOSS [training: 0.254419029506178 | validation: 0.2597946303228533]
	TIME [epoch: 9.26 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23997926578518242		[learning rate: 0.009151]
	Learning Rate: 0.00915096
	LOSS [training: 0.23997926578518242 | validation: 0.16194426660673755]
	TIME [epoch: 9.24 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.179741820732281		[learning rate: 0.0091229]
	Learning Rate: 0.00912291
	LOSS [training: 0.179741820732281 | validation: 0.15543248017644912]
	TIME [epoch: 9.24 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16833549801886197		[learning rate: 0.0090949]
	Learning Rate: 0.00909494
	LOSS [training: 0.16833549801886197 | validation: 0.21868991467434024]
	TIME [epoch: 9.25 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22924845480538933		[learning rate: 0.0090671]
	Learning Rate: 0.00906706
	LOSS [training: 0.22924845480538933 | validation: 0.16422649349722074]
	TIME [epoch: 9.24 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17338222830140532		[learning rate: 0.0090393]
	Learning Rate: 0.00903927
	LOSS [training: 0.17338222830140532 | validation: 0.47043088199566196]
	TIME [epoch: 9.26 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5011858113416318		[learning rate: 0.0090116]
	Learning Rate: 0.00901156
	LOSS [training: 0.5011858113416318 | validation: 0.22300257374833182]
	TIME [epoch: 9.25 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21454924706682504		[learning rate: 0.0089839]
	Learning Rate: 0.00898394
	LOSS [training: 0.21454924706682504 | validation: 0.6678076890858137]
	TIME [epoch: 9.24 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1735223209922023		[learning rate: 0.0089564]
	Learning Rate: 0.0089564
	LOSS [training: 1.1735223209922023 | validation: 3.205946443660652]
	TIME [epoch: 9.25 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9540355772464675		[learning rate: 0.0089289]
	Learning Rate: 0.00892894
	LOSS [training: 0.9540355772464675 | validation: 0.14721250788238005]
	TIME [epoch: 9.24 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18625539852404852		[learning rate: 0.0089016]
	Learning Rate: 0.00890157
	LOSS [training: 0.18625539852404852 | validation: 0.21380092928369743]
	TIME [epoch: 9.27 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1680992949570067		[learning rate: 0.0088743]
	Learning Rate: 0.00887428
	LOSS [training: 0.1680992949570067 | validation: 0.25376738268129784]
	TIME [epoch: 9.24 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22827844835307354		[learning rate: 0.0088471]
	Learning Rate: 0.00884708
	LOSS [training: 0.22827844835307354 | validation: 0.19919102540238337]
	TIME [epoch: 9.24 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2101612305884717		[learning rate: 0.00882]
	Learning Rate: 0.00881996
	LOSS [training: 0.2101612305884717 | validation: 0.14541525991460152]
	TIME [epoch: 9.24 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14038648147714478		[learning rate: 0.0087929]
	Learning Rate: 0.00879292
	LOSS [training: 0.14038648147714478 | validation: 0.1829984404034691]
	TIME [epoch: 9.25 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2813109827387602		[learning rate: 0.008766]
	Learning Rate: 0.00876597
	LOSS [training: 0.2813109827387602 | validation: 0.11616848275973991]
	TIME [epoch: 9.26 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3310422350939222		[learning rate: 0.0087391]
	Learning Rate: 0.0087391
	LOSS [training: 0.3310422350939222 | validation: 1.3647005072538088]
	TIME [epoch: 9.24 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9541290652254226		[learning rate: 0.0087123]
	Learning Rate: 0.00871231
	LOSS [training: 0.9541290652254226 | validation: 0.4116667239495023]
	TIME [epoch: 9.24 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4291736582007112		[learning rate: 0.0086856]
	Learning Rate: 0.0086856
	LOSS [training: 0.4291736582007112 | validation: 0.2777135906391286]
	TIME [epoch: 9.24 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24236719371468435		[learning rate: 0.008659]
	Learning Rate: 0.00865898
	LOSS [training: 0.24236719371468435 | validation: 0.39023039033465434]
	TIME [epoch: 9.25 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24685731140669015		[learning rate: 0.0086324]
	Learning Rate: 0.00863244
	LOSS [training: 0.24685731140669015 | validation: 0.18926159290780195]
	TIME [epoch: 9.25 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21899511486164883		[learning rate: 0.008606]
	Learning Rate: 0.00860597
	LOSS [training: 0.21899511486164883 | validation: 0.23034040218623048]
	TIME [epoch: 9.24 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36269564167901364		[learning rate: 0.0085796]
	Learning Rate: 0.00857959
	LOSS [training: 0.36269564167901364 | validation: 0.3864905249676204]
	TIME [epoch: 9.24 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4524193411788356		[learning rate: 0.0085533]
	Learning Rate: 0.00855329
	LOSS [training: 0.4524193411788356 | validation: 0.4816891782485579]
	TIME [epoch: 9.24 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3685311614302055		[learning rate: 0.0085271]
	Learning Rate: 0.00852707
	LOSS [training: 0.3685311614302055 | validation: 0.2251770417225148]
	TIME [epoch: 9.26 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2076505806609982		[learning rate: 0.0085009]
	Learning Rate: 0.00850093
	LOSS [training: 0.2076505806609982 | validation: 0.27234830613498334]
	TIME [epoch: 9.25 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26620381617993505		[learning rate: 0.0084749]
	Learning Rate: 0.00847488
	LOSS [training: 0.26620381617993505 | validation: 0.2982605406367469]
	TIME [epoch: 9.24 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24450757167674264		[learning rate: 0.0084489]
	Learning Rate: 0.0084489
	LOSS [training: 0.24450757167674264 | validation: 0.1755371696419823]
	TIME [epoch: 9.23 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35888943022638353		[learning rate: 0.008423]
	Learning Rate: 0.008423
	LOSS [training: 0.35888943022638353 | validation: 0.26687425921680064]
	TIME [epoch: 9.24 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2578498508810181		[learning rate: 0.0083972]
	Learning Rate: 0.00839718
	LOSS [training: 0.2578498508810181 | validation: 0.29996619108148964]
	TIME [epoch: 9.25 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4056460807198328		[learning rate: 0.0083714]
	Learning Rate: 0.00837144
	LOSS [training: 0.4056460807198328 | validation: 0.4917744730939816]
	TIME [epoch: 9.25 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39117546242980883		[learning rate: 0.0083458]
	Learning Rate: 0.00834577
	LOSS [training: 0.39117546242980883 | validation: 0.2702250378522076]
	TIME [epoch: 9.24 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2386128591062872		[learning rate: 0.0083202]
	Learning Rate: 0.00832019
	LOSS [training: 0.2386128591062872 | validation: 0.22722972067395808]
	TIME [epoch: 9.24 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1950422806437458		[learning rate: 0.0082947]
	Learning Rate: 0.00829469
	LOSS [training: 0.1950422806437458 | validation: 0.2709790543796232]
	TIME [epoch: 9.24 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2277122599528174		[learning rate: 0.0082693]
	Learning Rate: 0.00826926
	LOSS [training: 0.2277122599528174 | validation: 0.14617147588137275]
	TIME [epoch: 9.26 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19659838806325927		[learning rate: 0.0082439]
	Learning Rate: 0.00824391
	LOSS [training: 0.19659838806325927 | validation: 0.20682715372001667]
	TIME [epoch: 9.25 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19624886547829784		[learning rate: 0.0082186]
	Learning Rate: 0.00821864
	LOSS [training: 0.19624886547829784 | validation: 0.18640453222249545]
	TIME [epoch: 9.25 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24102103852775048		[learning rate: 0.0081934]
	Learning Rate: 0.00819345
	LOSS [training: 0.24102103852775048 | validation: 0.2470828565950145]
	TIME [epoch: 9.24 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21550858212614526		[learning rate: 0.0081683]
	Learning Rate: 0.00816833
	LOSS [training: 0.21550858212614526 | validation: 0.19049697282881675]
	TIME [epoch: 9.24 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16563353765857008		[learning rate: 0.0081433]
	Learning Rate: 0.00814329
	LOSS [training: 0.16563353765857008 | validation: 0.2053162727811834]
	TIME [epoch: 9.26 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18575182053620326		[learning rate: 0.0081183]
	Learning Rate: 0.00811833
	LOSS [training: 0.18575182053620326 | validation: 0.2244573776737101]
	TIME [epoch: 9.25 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17236960502696433		[learning rate: 0.0080934]
	Learning Rate: 0.00809344
	LOSS [training: 0.17236960502696433 | validation: 0.37740908939618206]
	TIME [epoch: 9.24 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21130179828316073		[learning rate: 0.0080686]
	Learning Rate: 0.00806863
	LOSS [training: 0.21130179828316073 | validation: 0.1969570097649656]
	TIME [epoch: 9.24 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18660238631260911		[learning rate: 0.0080439]
	Learning Rate: 0.0080439
	LOSS [training: 0.18660238631260911 | validation: 0.18993411649547237]
	TIME [epoch: 9.24 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2043452588070937		[learning rate: 0.0080192]
	Learning Rate: 0.00801924
	LOSS [training: 0.2043452588070937 | validation: 0.14666658421244505]
	TIME [epoch: 9.26 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21434034437811927		[learning rate: 0.0079947]
	Learning Rate: 0.00799466
	LOSS [training: 0.21434034437811927 | validation: 0.14660465401493333]
	TIME [epoch: 9.25 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14480324302604172		[learning rate: 0.0079702]
	Learning Rate: 0.00797015
	LOSS [training: 0.14480324302604172 | validation: 0.15228176222687795]
	TIME [epoch: 9.25 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25300081215613723		[learning rate: 0.0079457]
	Learning Rate: 0.00794572
	LOSS [training: 0.25300081215613723 | validation: 0.3365746971707866]
	TIME [epoch: 9.24 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21422768627412242		[learning rate: 0.0079214]
	Learning Rate: 0.00792136
	LOSS [training: 0.21422768627412242 | validation: 0.29475324080529014]
	TIME [epoch: 9.24 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3722971827118554		[learning rate: 0.0078971]
	Learning Rate: 0.00789708
	LOSS [training: 0.3722971827118554 | validation: 0.2628774205805672]
	TIME [epoch: 9.26 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26093577697974357		[learning rate: 0.0078729]
	Learning Rate: 0.00787287
	LOSS [training: 0.26093577697974357 | validation: 0.1227246098675181]
	TIME [epoch: 9.24 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15737318665895064		[learning rate: 0.0078487]
	Learning Rate: 0.00784874
	LOSS [training: 0.15737318665895064 | validation: 0.12317945764017903]
	TIME [epoch: 9.24 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1906836401392957		[learning rate: 0.0078247]
	Learning Rate: 0.00782468
	LOSS [training: 0.1906836401392957 | validation: 0.11703388097387868]
	TIME [epoch: 9.24 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17283881746275212		[learning rate: 0.0078007]
	Learning Rate: 0.0078007
	LOSS [training: 0.17283881746275212 | validation: 0.1281008168209291]
	TIME [epoch: 9.24 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14705586008023286		[learning rate: 0.0077768]
	Learning Rate: 0.00777678
	LOSS [training: 0.14705586008023286 | validation: 0.1324187133848546]
	TIME [epoch: 9.26 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13986223500755304		[learning rate: 0.0077529]
	Learning Rate: 0.00775294
	LOSS [training: 0.13986223500755304 | validation: 0.13253756154374385]
	TIME [epoch: 9.24 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1148341776822576		[learning rate: 0.0077292]
	Learning Rate: 0.00772918
	LOSS [training: 0.1148341776822576 | validation: 0.1317966322692338]
	TIME [epoch: 9.25 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1735386872295731		[learning rate: 0.0077055]
	Learning Rate: 0.00770548
	LOSS [training: 0.1735386872295731 | validation: 0.11438697208164829]
	TIME [epoch: 9.24 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19464165940546424		[learning rate: 0.0076819]
	Learning Rate: 0.00768186
	LOSS [training: 0.19464165940546424 | validation: 0.14001664822874096]
	TIME [epoch: 9.23 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3819103706282959		[learning rate: 0.0076583]
	Learning Rate: 0.00765832
	LOSS [training: 0.3819103706282959 | validation: 0.1379059858153271]
	TIME [epoch: 9.26 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20663565092818165		[learning rate: 0.0076348]
	Learning Rate: 0.00763484
	LOSS [training: 0.20663565092818165 | validation: 0.8602857175388798]
	TIME [epoch: 9.24 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1568003937972071		[learning rate: 0.0076114]
	Learning Rate: 0.00761144
	LOSS [training: 1.1568003937972071 | validation: 0.3056964066039272]
	TIME [epoch: 9.24 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19420360878698958		[learning rate: 0.0075881]
	Learning Rate: 0.0075881
	LOSS [training: 0.19420360878698958 | validation: 0.2269197940184668]
	TIME [epoch: 9.24 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1915868043129407		[learning rate: 0.0075648]
	Learning Rate: 0.00756484
	LOSS [training: 0.1915868043129407 | validation: 0.1153226014240544]
	TIME [epoch: 9.24 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.157212332270862		[learning rate: 0.0075417]
	Learning Rate: 0.00754165
	LOSS [training: 0.157212332270862 | validation: 0.11198611367334266]
	TIME [epoch: 9.27 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18636001724347884		[learning rate: 0.0075185]
	Learning Rate: 0.00751854
	LOSS [training: 0.18636001724347884 | validation: 0.12836360554311407]
	TIME [epoch: 9.24 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15325691516711265		[learning rate: 0.0074955]
	Learning Rate: 0.00749549
	LOSS [training: 0.15325691516711265 | validation: 0.16391700490967714]
	TIME [epoch: 9.25 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1965698793541715		[learning rate: 0.0074725]
	Learning Rate: 0.00747251
	LOSS [training: 0.1965698793541715 | validation: 0.15361193054606692]
	TIME [epoch: 9.24 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17034938256914192		[learning rate: 0.0074496]
	Learning Rate: 0.00744961
	LOSS [training: 0.17034938256914192 | validation: 0.3271255479804793]
	TIME [epoch: 9.25 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26853481973205134		[learning rate: 0.0074268]
	Learning Rate: 0.00742677
	LOSS [training: 0.26853481973205134 | validation: 0.29158983887724904]
	TIME [epoch: 9.27 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5005264326484465		[learning rate: 0.007404]
	Learning Rate: 0.007404
	LOSS [training: 0.5005264326484465 | validation: 0.21452584857091622]
	TIME [epoch: 9.24 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23181419759324856		[learning rate: 0.0073813]
	Learning Rate: 0.00738131
	LOSS [training: 0.23181419759324856 | validation: 0.16390350340627272]
	TIME [epoch: 9.24 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18141991075949618		[learning rate: 0.0073587]
	Learning Rate: 0.00735868
	LOSS [training: 0.18141991075949618 | validation: 0.1347850104946945]
	TIME [epoch: 9.25 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20398855783516429		[learning rate: 0.0073361]
	Learning Rate: 0.00733612
	LOSS [training: 0.20398855783516429 | validation: 0.18355617461413298]
	TIME [epoch: 9.25 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15736105148146523		[learning rate: 0.0073136]
	Learning Rate: 0.00731364
	LOSS [training: 0.15736105148146523 | validation: 0.09970056175880115]
	TIME [epoch: 9.26 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.115572746272631		[learning rate: 0.0072912]
	Learning Rate: 0.00729122
	LOSS [training: 0.115572746272631 | validation: 0.1731086892097083]
	TIME [epoch: 9.25 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1607423934075256		[learning rate: 0.0072689]
	Learning Rate: 0.00726887
	LOSS [training: 0.1607423934075256 | validation: 0.18873974969817053]
	TIME [epoch: 9.24 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16999515309393132		[learning rate: 0.0072466]
	Learning Rate: 0.00724658
	LOSS [training: 0.16999515309393132 | validation: 0.1974823631456096]
	TIME [epoch: 9.24 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2266357038192816		[learning rate: 0.0072244]
	Learning Rate: 0.00722437
	LOSS [training: 0.2266357038192816 | validation: 0.1265271461914086]
	TIME [epoch: 9.26 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15734117938644926		[learning rate: 0.0072022]
	Learning Rate: 0.00720222
	LOSS [training: 0.15734117938644926 | validation: 0.0894728036046559]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_607.pth
	Model improved!!!
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14509972284146933		[learning rate: 0.0071801]
	Learning Rate: 0.00718015
	LOSS [training: 0.14509972284146933 | validation: 0.09703566064790765]
	TIME [epoch: 9.24 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1970462584762993		[learning rate: 0.0071581]
	Learning Rate: 0.00715814
	LOSS [training: 0.1970462584762993 | validation: 0.19260532377729533]
	TIME [epoch: 9.25 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2511048866990432		[learning rate: 0.0071362]
	Learning Rate: 0.00713619
	LOSS [training: 0.2511048866990432 | validation: 0.22079487389753433]
	TIME [epoch: 9.24 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23110502511355654		[learning rate: 0.0071143]
	Learning Rate: 0.00711432
	LOSS [training: 0.23110502511355654 | validation: 0.19327455598343948]
	TIME [epoch: 9.25 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18825110152953423		[learning rate: 0.0070925]
	Learning Rate: 0.00709251
	LOSS [training: 0.18825110152953423 | validation: 0.1327379139559648]
	TIME [epoch: 9.24 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20409562583841848		[learning rate: 0.0070708]
	Learning Rate: 0.00707077
	LOSS [training: 0.20409562583841848 | validation: 0.1731304546099316]
	TIME [epoch: 9.23 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21079333467055078		[learning rate: 0.0070491]
	Learning Rate: 0.00704909
	LOSS [training: 0.21079333467055078 | validation: 0.18520198605304788]
	TIME [epoch: 9.24 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14973166799427928		[learning rate: 0.0070275]
	Learning Rate: 0.00702749
	LOSS [training: 0.14973166799427928 | validation: 0.14511317027835197]
	TIME [epoch: 9.24 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1527920589680625		[learning rate: 0.0070059]
	Learning Rate: 0.00700594
	LOSS [training: 0.1527920589680625 | validation: 0.14664345287652958]
	TIME [epoch: 9.26 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17328552122506416		[learning rate: 0.0069845]
	Learning Rate: 0.00698447
	LOSS [training: 0.17328552122506416 | validation: 0.14341501093999534]
	TIME [epoch: 9.25 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14055522157398107		[learning rate: 0.0069631]
	Learning Rate: 0.00696306
	LOSS [training: 0.14055522157398107 | validation: 0.16373355223920794]
	TIME [epoch: 9.24 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21687618505037398		[learning rate: 0.0069417]
	Learning Rate: 0.00694171
	LOSS [training: 0.21687618505037398 | validation: 0.1297297580215046]
	TIME [epoch: 9.24 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17110436935876133		[learning rate: 0.0069204]
	Learning Rate: 0.00692043
	LOSS [training: 0.17110436935876133 | validation: 0.17653386258677595]
	TIME [epoch: 9.24 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1956093181194451		[learning rate: 0.0068992]
	Learning Rate: 0.00689922
	LOSS [training: 0.1956093181194451 | validation: 0.16838408677253314]
	TIME [epoch: 9.25 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2082910706984676		[learning rate: 0.0068781]
	Learning Rate: 0.00687807
	LOSS [training: 0.2082910706984676 | validation: 0.36799047521324063]
	TIME [epoch: 9.24 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21238093891931875		[learning rate: 0.006857]
	Learning Rate: 0.00685699
	LOSS [training: 0.21238093891931875 | validation: 0.21894673061045775]
	TIME [epoch: 9.24 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16972997905947992		[learning rate: 0.006836]
	Learning Rate: 0.00683597
	LOSS [training: 0.16972997905947992 | validation: 0.11016499900261273]
	TIME [epoch: 9.24 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16131011266184495		[learning rate: 0.006815]
	Learning Rate: 0.00681501
	LOSS [training: 0.16131011266184495 | validation: 0.10643155730924952]
	TIME [epoch: 9.24 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1539194159182175		[learning rate: 0.0067941]
	Learning Rate: 0.00679412
	LOSS [training: 0.1539194159182175 | validation: 0.1967869276208183]
	TIME [epoch: 9.26 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4044164503594473		[learning rate: 0.0067733]
	Learning Rate: 0.00677329
	LOSS [training: 0.4044164503594473 | validation: 0.3270860527232725]
	TIME [epoch: 9.24 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39301356772946416		[learning rate: 0.0067525]
	Learning Rate: 0.00675253
	LOSS [training: 0.39301356772946416 | validation: 0.2814311592565356]
	TIME [epoch: 9.24 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3942934674235933		[learning rate: 0.0067318]
	Learning Rate: 0.00673183
	LOSS [training: 0.3942934674235933 | validation: 0.2579727961743954]
	TIME [epoch: 9.24 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23808070367878392		[learning rate: 0.0067112]
	Learning Rate: 0.0067112
	LOSS [training: 0.23808070367878392 | validation: 0.30291180417584546]
	TIME [epoch: 9.24 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24962479435089882		[learning rate: 0.0066906]
	Learning Rate: 0.00669062
	LOSS [training: 0.24962479435089882 | validation: 0.13604765558399584]
	TIME [epoch: 9.26 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20560949327094039		[learning rate: 0.0066701]
	Learning Rate: 0.00667012
	LOSS [training: 0.20560949327094039 | validation: 0.22632899188496292]
	TIME [epoch: 9.24 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21435364661611178		[learning rate: 0.0066497]
	Learning Rate: 0.00664967
	LOSS [training: 0.21435364661611178 | validation: 0.17311061703168829]
	TIME [epoch: 9.24 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20798275347873912		[learning rate: 0.0066293]
	Learning Rate: 0.00662928
	LOSS [training: 0.20798275347873912 | validation: 0.12160585647324261]
	TIME [epoch: 9.24 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13256709952168105		[learning rate: 0.006609]
	Learning Rate: 0.00660896
	LOSS [training: 0.13256709952168105 | validation: 0.11918592757340207]
	TIME [epoch: 9.23 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16791043850207943		[learning rate: 0.0065887]
	Learning Rate: 0.0065887
	LOSS [training: 0.16791043850207943 | validation: 0.20096995085023298]
	TIME [epoch: 9.26 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2392630609690511		[learning rate: 0.0065685]
	Learning Rate: 0.00656851
	LOSS [training: 0.2392630609690511 | validation: 0.17775407260965723]
	TIME [epoch: 9.24 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16909881130687401		[learning rate: 0.0065484]
	Learning Rate: 0.00654837
	LOSS [training: 0.16909881130687401 | validation: 0.20556618170615765]
	TIME [epoch: 9.24 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14995876470038533		[learning rate: 0.0065283]
	Learning Rate: 0.0065283
	LOSS [training: 0.14995876470038533 | validation: 0.15978243104083453]
	TIME [epoch: 9.24 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16820327531540363		[learning rate: 0.0065083]
	Learning Rate: 0.00650829
	LOSS [training: 0.16820327531540363 | validation: 0.1587877339919066]
	TIME [epoch: 9.24 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14063647667900003		[learning rate: 0.0064883]
	Learning Rate: 0.00648834
	LOSS [training: 0.14063647667900003 | validation: 0.14259759547181095]
	TIME [epoch: 9.26 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12966196550987963		[learning rate: 0.0064684]
	Learning Rate: 0.00646845
	LOSS [training: 0.12966196550987963 | validation: 0.15101385764546085]
	TIME [epoch: 9.24 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16126440356629984		[learning rate: 0.0064486]
	Learning Rate: 0.00644862
	LOSS [training: 0.16126440356629984 | validation: 0.14070821271669018]
	TIME [epoch: 9.23 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15864867621179637		[learning rate: 0.0064289]
	Learning Rate: 0.00642885
	LOSS [training: 0.15864867621179637 | validation: 0.11725978003732541]
	TIME [epoch: 9.24 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1405300612050342		[learning rate: 0.0064091]
	Learning Rate: 0.00640914
	LOSS [training: 0.1405300612050342 | validation: 0.2385650772927808]
	TIME [epoch: 9.23 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23738880763683046		[learning rate: 0.0063895]
	Learning Rate: 0.0063895
	LOSS [training: 0.23738880763683046 | validation: 0.13341282990337316]
	TIME [epoch: 9.26 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14590749660532745		[learning rate: 0.0063699]
	Learning Rate: 0.00636991
	LOSS [training: 0.14590749660532745 | validation: 0.1400729207832595]
	TIME [epoch: 9.23 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15846731598978103		[learning rate: 0.0063504]
	Learning Rate: 0.00635038
	LOSS [training: 0.15846731598978103 | validation: 0.1381664735005988]
	TIME [epoch: 9.24 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14347758292365081		[learning rate: 0.0063309]
	Learning Rate: 0.00633092
	LOSS [training: 0.14347758292365081 | validation: 0.14922424081265673]
	TIME [epoch: 9.24 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16999326380312638		[learning rate: 0.0063115]
	Learning Rate: 0.00631151
	LOSS [training: 0.16999326380312638 | validation: 0.15075282808859]
	TIME [epoch: 9.24 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19702091150665943		[learning rate: 0.0062922]
	Learning Rate: 0.00629216
	LOSS [training: 0.19702091150665943 | validation: 0.20786330156838728]
	TIME [epoch: 9.26 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.144764890652839		[learning rate: 0.0062729]
	Learning Rate: 0.00627288
	LOSS [training: 0.144764890652839 | validation: 0.18021912890487268]
	TIME [epoch: 9.24 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22959884512839412		[learning rate: 0.0062536]
	Learning Rate: 0.00625365
	LOSS [training: 0.22959884512839412 | validation: 0.3019511669875072]
	TIME [epoch: 9.24 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15307662874434794		[learning rate: 0.0062345]
	Learning Rate: 0.00623448
	LOSS [training: 0.15307662874434794 | validation: 0.24306187679300983]
	TIME [epoch: 9.23 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14359193515820606		[learning rate: 0.0062154]
	Learning Rate: 0.00621536
	LOSS [training: 0.14359193515820606 | validation: 0.1095361824922959]
	TIME [epoch: 9.25 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09899975431784322		[learning rate: 0.0061963]
	Learning Rate: 0.00619631
	LOSS [training: 0.09899975431784322 | validation: 0.1559192575525319]
	TIME [epoch: 9.25 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15467074066874822		[learning rate: 0.0061773]
	Learning Rate: 0.00617732
	LOSS [training: 0.15467074066874822 | validation: 0.11181504812255548]
	TIME [epoch: 9.24 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09441083817865573		[learning rate: 0.0061584]
	Learning Rate: 0.00615838
	LOSS [training: 0.09441083817865573 | validation: 0.18251242792536645]
	TIME [epoch: 9.25 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12687182148205528		[learning rate: 0.0061395]
	Learning Rate: 0.0061395
	LOSS [training: 0.12687182148205528 | validation: 0.12854025111648634]
	TIME [epoch: 9.24 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14951394138784974		[learning rate: 0.0061207]
	Learning Rate: 0.00612068
	LOSS [training: 0.14951394138784974 | validation: 0.1012527291675879]
	TIME [epoch: 9.25 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10362676402616797		[learning rate: 0.0061019]
	Learning Rate: 0.00610192
	LOSS [training: 0.10362676402616797 | validation: 0.18120537798290137]
	TIME [epoch: 9.25 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13433253784771015		[learning rate: 0.0060832]
	Learning Rate: 0.00608322
	LOSS [training: 0.13433253784771015 | validation: 0.1453512359934636]
	TIME [epoch: 9.24 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1418588103494863		[learning rate: 0.0060646]
	Learning Rate: 0.00606457
	LOSS [training: 0.1418588103494863 | validation: 0.15297231317103957]
	TIME [epoch: 9.24 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16103680985073546		[learning rate: 0.006046]
	Learning Rate: 0.00604598
	LOSS [training: 0.16103680985073546 | validation: 0.22462239223704422]
	TIME [epoch: 9.24 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18367010059855443		[learning rate: 0.0060274]
	Learning Rate: 0.00602745
	LOSS [training: 0.18367010059855443 | validation: 0.12020098686150679]
	TIME [epoch: 9.26 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11792623592303234		[learning rate: 0.006009]
	Learning Rate: 0.00600897
	LOSS [training: 0.11792623592303234 | validation: 0.13777263574418702]
	TIME [epoch: 9.25 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12643465861909226		[learning rate: 0.0059905]
	Learning Rate: 0.00599055
	LOSS [training: 0.12643465861909226 | validation: 0.10861693361123426]
	TIME [epoch: 9.25 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13391251519591615		[learning rate: 0.0059722]
	Learning Rate: 0.00597219
	LOSS [training: 0.13391251519591615 | validation: 0.13493975101700265]
	TIME [epoch: 9.24 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10876573786863084		[learning rate: 0.0059539]
	Learning Rate: 0.00595388
	LOSS [training: 0.10876573786863084 | validation: 0.09255127910800676]
	TIME [epoch: 9.31 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10156137940611867		[learning rate: 0.0059356]
	Learning Rate: 0.00593563
	LOSS [training: 0.10156137940611867 | validation: 0.11899975686592534]
	TIME [epoch: 9.26 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17345594318669305		[learning rate: 0.0059174]
	Learning Rate: 0.00591743
	LOSS [training: 0.17345594318669305 | validation: 0.1714363452731876]
	TIME [epoch: 9.24 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1281921238698518		[learning rate: 0.0058993]
	Learning Rate: 0.00589929
	LOSS [training: 0.1281921238698518 | validation: 0.21221629212237442]
	TIME [epoch: 9.24 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15402356291860025		[learning rate: 0.0058812]
	Learning Rate: 0.00588121
	LOSS [training: 0.15402356291860025 | validation: 0.19575846362051766]
	TIME [epoch: 9.24 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14540185907312236		[learning rate: 0.0058632]
	Learning Rate: 0.00586318
	LOSS [training: 0.14540185907312236 | validation: 0.1349476225291962]
	TIME [epoch: 9.23 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14279906271534898		[learning rate: 0.0058452]
	Learning Rate: 0.00584521
	LOSS [training: 0.14279906271534898 | validation: 0.19151427674741028]
	TIME [epoch: 9.26 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13131540215020376		[learning rate: 0.0058273]
	Learning Rate: 0.00582729
	LOSS [training: 0.13131540215020376 | validation: 0.14060976288991117]
	TIME [epoch: 9.24 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14508944286889144		[learning rate: 0.0058094]
	Learning Rate: 0.00580943
	LOSS [training: 0.14508944286889144 | validation: 0.14206517871607563]
	TIME [epoch: 9.24 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1327709234060684		[learning rate: 0.0057916]
	Learning Rate: 0.00579162
	LOSS [training: 0.1327709234060684 | validation: 0.21941142421394216]
	TIME [epoch: 9.24 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16038667233242945		[learning rate: 0.0057739]
	Learning Rate: 0.00577387
	LOSS [training: 0.16038667233242945 | validation: 0.23822020332219299]
	TIME [epoch: 9.24 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13158593332952728		[learning rate: 0.0057562]
	Learning Rate: 0.00575617
	LOSS [training: 0.13158593332952728 | validation: 0.12994051315132754]
	TIME [epoch: 9.26 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1220997248769011		[learning rate: 0.0057385]
	Learning Rate: 0.00573852
	LOSS [training: 0.1220997248769011 | validation: 0.11531579133022932]
	TIME [epoch: 9.24 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14918857189797008		[learning rate: 0.0057209]
	Learning Rate: 0.00572093
	LOSS [training: 0.14918857189797008 | validation: 0.12257208736135486]
	TIME [epoch: 9.24 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12378341452664791		[learning rate: 0.0057034]
	Learning Rate: 0.00570339
	LOSS [training: 0.12378341452664791 | validation: 0.16253897832610448]
	TIME [epoch: 9.24 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16769008269410177		[learning rate: 0.0056859]
	Learning Rate: 0.00568591
	LOSS [training: 0.16769008269410177 | validation: 0.14119390903722426]
	TIME [epoch: 10.3 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1504415598334174		[learning rate: 0.0056685]
	Learning Rate: 0.00566848
	LOSS [training: 0.1504415598334174 | validation: 0.102997732352548]
	TIME [epoch: 9.26 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1203954839386421		[learning rate: 0.0056511]
	Learning Rate: 0.0056511
	LOSS [training: 0.1203954839386421 | validation: 0.10803175382620506]
	TIME [epoch: 9.24 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16535342388056418		[learning rate: 0.0056338]
	Learning Rate: 0.00563378
	LOSS [training: 0.16535342388056418 | validation: 0.18629401948770039]
	TIME [epoch: 9.24 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19403460990881113		[learning rate: 0.0056165]
	Learning Rate: 0.00561651
	LOSS [training: 0.19403460990881113 | validation: 0.15066731729443966]
	TIME [epoch: 9.24 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16251236837139413		[learning rate: 0.0055993]
	Learning Rate: 0.00559929
	LOSS [training: 0.16251236837139413 | validation: 0.09260625371888509]
	TIME [epoch: 9.24 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.100698719001722		[learning rate: 0.0055821]
	Learning Rate: 0.00558213
	LOSS [training: 0.100698719001722 | validation: 0.0906695334559571]
	TIME [epoch: 9.26 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08537400809730125		[learning rate: 0.005565]
	Learning Rate: 0.00556502
	LOSS [training: 0.08537400809730125 | validation: 0.11641233223748206]
	TIME [epoch: 9.24 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12537994113178513		[learning rate: 0.005548]
	Learning Rate: 0.00554796
	LOSS [training: 0.12537994113178513 | validation: 0.12016034863580119]
	TIME [epoch: 9.24 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12351588187248816		[learning rate: 0.005531]
	Learning Rate: 0.00553095
	LOSS [training: 0.12351588187248816 | validation: 0.1579723010735557]
	TIME [epoch: 9.24 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11137157793132053		[learning rate: 0.005514]
	Learning Rate: 0.005514
	LOSS [training: 0.11137157793132053 | validation: 0.10445269306181125]
	TIME [epoch: 9.24 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17827012191300903		[learning rate: 0.0054971]
	Learning Rate: 0.0054971
	LOSS [training: 0.17827012191300903 | validation: 0.25296711726243476]
	TIME [epoch: 9.25 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16004704698737948		[learning rate: 0.0054802]
	Learning Rate: 0.00548025
	LOSS [training: 0.16004704698737948 | validation: 0.13926162706571704]
	TIME [epoch: 9.24 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1379018508497966		[learning rate: 0.0054634]
	Learning Rate: 0.00546345
	LOSS [training: 0.1379018508497966 | validation: 0.12282823223166349]
	TIME [epoch: 9.23 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16003325127997545		[learning rate: 0.0054467]
	Learning Rate: 0.0054467
	LOSS [training: 0.16003325127997545 | validation: 0.17420488928908173]
	TIME [epoch: 9.24 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18775576612140962		[learning rate: 0.00543]
	Learning Rate: 0.00543
	LOSS [training: 0.18775576612140962 | validation: 0.19216740468635096]
	TIME [epoch: 9.24 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14763637926244835		[learning rate: 0.0054134]
	Learning Rate: 0.00541336
	LOSS [training: 0.14763637926244835 | validation: 0.11641557288184542]
	TIME [epoch: 9.26 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13539039807592818		[learning rate: 0.0053968]
	Learning Rate: 0.00539676
	LOSS [training: 0.13539039807592818 | validation: 0.1554565541409917]
	TIME [epoch: 9.24 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16048650425311808		[learning rate: 0.0053802]
	Learning Rate: 0.00538022
	LOSS [training: 0.16048650425311808 | validation: 0.16426001562839754]
	TIME [epoch: 9.23 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16462538320933742		[learning rate: 0.0053637]
	Learning Rate: 0.00536373
	LOSS [training: 0.16462538320933742 | validation: 0.1730048865841346]
	TIME [epoch: 9.24 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15180304077919338		[learning rate: 0.0053473]
	Learning Rate: 0.00534728
	LOSS [training: 0.15180304077919338 | validation: 0.13142971435908157]
	TIME [epoch: 9.24 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12511821922462474		[learning rate: 0.0053309]
	Learning Rate: 0.00533089
	LOSS [training: 0.12511821922462474 | validation: 0.1517036390158504]
	TIME [epoch: 9.25 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12808484858104494		[learning rate: 0.0053146]
	Learning Rate: 0.00531455
	LOSS [training: 0.12808484858104494 | validation: 0.21433925513823807]
	TIME [epoch: 9.24 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13305081621593523		[learning rate: 0.0052983]
	Learning Rate: 0.00529826
	LOSS [training: 0.13305081621593523 | validation: 0.10567048999910875]
	TIME [epoch: 9.24 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15523146850006497		[learning rate: 0.005282]
	Learning Rate: 0.00528202
	LOSS [training: 0.15523146850006497 | validation: 0.12197223778167615]
	TIME [epoch: 9.24 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15305338880146874		[learning rate: 0.0052658]
	Learning Rate: 0.00526583
	LOSS [training: 0.15305338880146874 | validation: 0.14051670203092453]
	TIME [epoch: 9.24 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11415890146617128		[learning rate: 0.0052497]
	Learning Rate: 0.00524969
	LOSS [training: 0.11415890146617128 | validation: 0.06868518740073379]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_710.pth
	Model improved!!!
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10239347983397935		[learning rate: 0.0052336]
	Learning Rate: 0.00523359
	LOSS [training: 0.10239347983397935 | validation: 0.11511814320993996]
	TIME [epoch: 9.24 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10869162166428299		[learning rate: 0.0052176]
	Learning Rate: 0.00521755
	LOSS [training: 0.10869162166428299 | validation: 0.12613146970178862]
	TIME [epoch: 9.24 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14170938875183187		[learning rate: 0.0052016]
	Learning Rate: 0.00520156
	LOSS [training: 0.14170938875183187 | validation: 0.17813545157731264]
	TIME [epoch: 9.24 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23890865729698813		[learning rate: 0.0051856]
	Learning Rate: 0.00518561
	LOSS [training: 0.23890865729698813 | validation: 0.19020653370974014]
	TIME [epoch: 9.25 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10701284672169394		[learning rate: 0.0051697]
	Learning Rate: 0.00516972
	LOSS [training: 0.10701284672169394 | validation: 0.14111185114972818]
	TIME [epoch: 9.25 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11378441571205093		[learning rate: 0.0051539]
	Learning Rate: 0.00515387
	LOSS [training: 0.11378441571205093 | validation: 0.14575471897684605]
	TIME [epoch: 9.24 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15320188399590853		[learning rate: 0.0051381]
	Learning Rate: 0.00513807
	LOSS [training: 0.15320188399590853 | validation: 0.1222229568640333]
	TIME [epoch: 9.23 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16910760180192153		[learning rate: 0.0051223]
	Learning Rate: 0.00512232
	LOSS [training: 0.16910760180192153 | validation: 0.11682114275985733]
	TIME [epoch: 9.24 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1455352529242121		[learning rate: 0.0051066]
	Learning Rate: 0.00510662
	LOSS [training: 0.1455352529242121 | validation: 0.1421641475666502]
	TIME [epoch: 9.25 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16775160297961783		[learning rate: 0.005091]
	Learning Rate: 0.00509096
	LOSS [training: 0.16775160297961783 | validation: 0.196574958857671]
	TIME [epoch: 9.24 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1523774276356209		[learning rate: 0.0050754]
	Learning Rate: 0.00507536
	LOSS [training: 0.1523774276356209 | validation: 0.15532780015416298]
	TIME [epoch: 9.24 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1475027790349844		[learning rate: 0.0050598]
	Learning Rate: 0.0050598
	LOSS [training: 0.1475027790349844 | validation: 0.12786024954267242]
	TIME [epoch: 9.24 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13686293680925624		[learning rate: 0.0050443]
	Learning Rate: 0.00504429
	LOSS [training: 0.13686293680925624 | validation: 0.15728428225702343]
	TIME [epoch: 9.24 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2042545298389172		[learning rate: 0.0050288]
	Learning Rate: 0.00502883
	LOSS [training: 0.2042545298389172 | validation: 0.19459072113166664]
	TIME [epoch: 9.25 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17153304468064373		[learning rate: 0.0050134]
	Learning Rate: 0.00501341
	LOSS [training: 0.17153304468064373 | validation: 0.12278656078940631]
	TIME [epoch: 9.24 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11513371906753775		[learning rate: 0.004998]
	Learning Rate: 0.00499804
	LOSS [training: 0.11513371906753775 | validation: 0.2180142747647395]
	TIME [epoch: 9.25 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13210472293815217		[learning rate: 0.0049827]
	Learning Rate: 0.00498272
	LOSS [training: 0.13210472293815217 | validation: 0.13119628867833574]
	TIME [epoch: 9.24 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11494850007492137		[learning rate: 0.0049674]
	Learning Rate: 0.00496745
	LOSS [training: 0.11494850007492137 | validation: 0.2091677044625102]
	TIME [epoch: 9.24 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17001592239680824		[learning rate: 0.0049522]
	Learning Rate: 0.00495222
	LOSS [training: 0.17001592239680824 | validation: 0.18064945330286059]
	TIME [epoch: 9.26 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1326288230014974		[learning rate: 0.004937]
	Learning Rate: 0.00493704
	LOSS [training: 0.1326288230014974 | validation: 0.3886864957968681]
	TIME [epoch: 9.25 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1629636454917776		[learning rate: 0.0049219]
	Learning Rate: 0.00492191
	LOSS [training: 0.1629636454917776 | validation: 0.162333883129182]
	TIME [epoch: 9.24 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12151969412282744		[learning rate: 0.0049068]
	Learning Rate: 0.00490682
	LOSS [training: 0.12151969412282744 | validation: 0.09675235868719267]
	TIME [epoch: 9.24 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11753634772833103		[learning rate: 0.0048918]
	Learning Rate: 0.00489178
	LOSS [training: 0.11753634772833103 | validation: 0.10480411993038202]
	TIME [epoch: 9.24 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1613785623531449		[learning rate: 0.0048768]
	Learning Rate: 0.00487678
	LOSS [training: 0.1613785623531449 | validation: 0.16035477320241387]
	TIME [epoch: 9.26 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14465009466667864		[learning rate: 0.0048618]
	Learning Rate: 0.00486183
	LOSS [training: 0.14465009466667864 | validation: 0.10380110755761561]
	TIME [epoch: 9.24 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13006847467223986		[learning rate: 0.0048469]
	Learning Rate: 0.00484693
	LOSS [training: 0.13006847467223986 | validation: 0.1489853898604926]
	TIME [epoch: 9.24 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14980794682019885		[learning rate: 0.0048321]
	Learning Rate: 0.00483207
	LOSS [training: 0.14980794682019885 | validation: 0.11678060692675385]
	TIME [epoch: 9.24 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16199116583259693		[learning rate: 0.0048173]
	Learning Rate: 0.00481726
	LOSS [training: 0.16199116583259693 | validation: 0.20872636647324277]
	TIME [epoch: 9.24 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15591899465286113		[learning rate: 0.0048025]
	Learning Rate: 0.00480249
	LOSS [training: 0.15591899465286113 | validation: 0.12309923154841489]
	TIME [epoch: 9.25 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17068265875735317		[learning rate: 0.0047878]
	Learning Rate: 0.00478777
	LOSS [training: 0.17068265875735317 | validation: 0.18242430605021592]
	TIME [epoch: 9.24 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16127231242053255		[learning rate: 0.0047731]
	Learning Rate: 0.00477309
	LOSS [training: 0.16127231242053255 | validation: 0.19583205272055343]
	TIME [epoch: 9.23 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13648372326781547		[learning rate: 0.0047585]
	Learning Rate: 0.00475846
	LOSS [training: 0.13648372326781547 | validation: 0.1399421975352154]
	TIME [epoch: 9.24 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13193316805900648		[learning rate: 0.0047439]
	Learning Rate: 0.00474388
	LOSS [training: 0.13193316805900648 | validation: 0.325557764989239]
	TIME [epoch: 9.24 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34184720116723477		[learning rate: 0.0047293]
	Learning Rate: 0.00472933
	LOSS [training: 0.34184720116723477 | validation: 0.1666165796947334]
	TIME [epoch: 9.25 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14388247726405629		[learning rate: 0.0047148]
	Learning Rate: 0.00471484
	LOSS [training: 0.14388247726405629 | validation: 0.1306045805722133]
	TIME [epoch: 9.24 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12466932589674748		[learning rate: 0.0047004]
	Learning Rate: 0.00470038
	LOSS [training: 0.12466932589674748 | validation: 0.15710777156531897]
	TIME [epoch: 9.24 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1488197750218097		[learning rate: 0.004686]
	Learning Rate: 0.00468598
	LOSS [training: 0.1488197750218097 | validation: 0.22768976523358775]
	TIME [epoch: 9.24 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16121245767303322		[learning rate: 0.0046716]
	Learning Rate: 0.00467161
	LOSS [training: 0.16121245767303322 | validation: 0.10420177663781412]
	TIME [epoch: 9.23 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.136315553759508		[learning rate: 0.0046573]
	Learning Rate: 0.00465729
	LOSS [training: 0.136315553759508 | validation: 0.12265530417816764]
	TIME [epoch: 9.26 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1562705336640355		[learning rate: 0.004643]
	Learning Rate: 0.00464301
	LOSS [training: 0.1562705336640355 | validation: 0.141461820738635]
	TIME [epoch: 9.24 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14261642316680911		[learning rate: 0.0046288]
	Learning Rate: 0.00462878
	LOSS [training: 0.14261642316680911 | validation: 0.08701885493013442]
	TIME [epoch: 9.23 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1168904465368428		[learning rate: 0.0046146]
	Learning Rate: 0.00461459
	LOSS [training: 0.1168904465368428 | validation: 0.09683920685661179]
	TIME [epoch: 9.24 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12708616792705948		[learning rate: 0.0046004]
	Learning Rate: 0.00460045
	LOSS [training: 0.12708616792705948 | validation: 0.12284652397813706]
	TIME [epoch: 9.23 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1251684630110708		[learning rate: 0.0045863]
	Learning Rate: 0.00458634
	LOSS [training: 0.1251684630110708 | validation: 0.08674013569007291]
	TIME [epoch: 9.25 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09871848056849365		[learning rate: 0.0045723]
	Learning Rate: 0.00457229
	LOSS [training: 0.09871848056849365 | validation: 0.11632364035703671]
	TIME [epoch: 9.23 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09341064884689598		[learning rate: 0.0045583]
	Learning Rate: 0.00455827
	LOSS [training: 0.09341064884689598 | validation: 0.08479433036195594]
	TIME [epoch: 9.23 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1163743191056946		[learning rate: 0.0045443]
	Learning Rate: 0.0045443
	LOSS [training: 0.1163743191056946 | validation: 0.08304603966384735]
	TIME [epoch: 9.24 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12088267014506782		[learning rate: 0.0045304]
	Learning Rate: 0.00453037
	LOSS [training: 0.12088267014506782 | validation: 0.1279832045480105]
	TIME [epoch: 9.23 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15090458824593858		[learning rate: 0.0045165]
	Learning Rate: 0.00451648
	LOSS [training: 0.15090458824593858 | validation: 0.08751604291466908]
	TIME [epoch: 9.25 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10461907571775804		[learning rate: 0.0045026]
	Learning Rate: 0.00450263
	LOSS [training: 0.10461907571775804 | validation: 0.12512415255603004]
	TIME [epoch: 9.24 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19250853893755823		[learning rate: 0.0044888]
	Learning Rate: 0.00448883
	LOSS [training: 0.19250853893755823 | validation: 0.13061942485653655]
	TIME [epoch: 9.24 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12401772985267016		[learning rate: 0.0044751]
	Learning Rate: 0.00447507
	LOSS [training: 0.12401772985267016 | validation: 0.32160164374644395]
	TIME [epoch: 9.23 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15234145214647757		[learning rate: 0.0044614]
	Learning Rate: 0.00446135
	LOSS [training: 0.15234145214647757 | validation: 0.10006657925910888]
	TIME [epoch: 9.23 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27123177104635054		[learning rate: 0.0044477]
	Learning Rate: 0.00444768
	LOSS [training: 0.27123177104635054 | validation: 0.22654120055820892]
	TIME [epoch: 9.25 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16588600272592469		[learning rate: 0.004434]
	Learning Rate: 0.00443404
	LOSS [training: 0.16588600272592469 | validation: 0.12860503018782007]
	TIME [epoch: 9.23 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13328842935179663		[learning rate: 0.0044205]
	Learning Rate: 0.00442045
	LOSS [training: 0.13328842935179663 | validation: 0.08615877522380601]
	TIME [epoch: 9.24 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23845955133557864		[learning rate: 0.0044069]
	Learning Rate: 0.0044069
	LOSS [training: 0.23845955133557864 | validation: 0.4879582123365762]
	TIME [epoch: 9.23 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2541376461370096		[learning rate: 0.0043934]
	Learning Rate: 0.00439339
	LOSS [training: 0.2541376461370096 | validation: 0.16556361166196382]
	TIME [epoch: 9.24 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10809623543612915		[learning rate: 0.0043799]
	Learning Rate: 0.00437992
	LOSS [training: 0.10809623543612915 | validation: 0.20692982557068934]
	TIME [epoch: 9.24 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12780164320217494		[learning rate: 0.0043665]
	Learning Rate: 0.0043665
	LOSS [training: 0.12780164320217494 | validation: 0.13712299478642145]
	TIME [epoch: 9.24 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19672037479907567		[learning rate: 0.0043531]
	Learning Rate: 0.00435311
	LOSS [training: 0.19672037479907567 | validation: 0.09875190684275449]
	TIME [epoch: 9.23 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11144173145908727		[learning rate: 0.0043398]
	Learning Rate: 0.00433977
	LOSS [training: 0.11144173145908727 | validation: 0.10684172595137942]
	TIME [epoch: 9.23 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17386954680180225		[learning rate: 0.0043265]
	Learning Rate: 0.00432647
	LOSS [training: 0.17386954680180225 | validation: 0.7070640727758575]
	TIME [epoch: 9.25 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3546446295284896		[learning rate: 0.0043132]
	Learning Rate: 0.0043132
	LOSS [training: 0.3546446295284896 | validation: 0.11613812627038612]
	TIME [epoch: 9.24 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17168998633158647		[learning rate: 0.0043]
	Learning Rate: 0.00429998
	LOSS [training: 0.17168998633158647 | validation: 0.14911184021059082]
	TIME [epoch: 9.23 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15113495424149415		[learning rate: 0.0042868]
	Learning Rate: 0.0042868
	LOSS [training: 0.15113495424149415 | validation: 0.1483188619672013]
	TIME [epoch: 9.23 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1397121076874054		[learning rate: 0.0042737]
	Learning Rate: 0.00427366
	LOSS [training: 0.1397121076874054 | validation: 0.21742604506235824]
	TIME [epoch: 9.24 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18771049321780736		[learning rate: 0.0042606]
	Learning Rate: 0.00426056
	LOSS [training: 0.18771049321780736 | validation: 0.1860820406452821]
	TIME [epoch: 9.25 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14646488750967707		[learning rate: 0.0042475]
	Learning Rate: 0.0042475
	LOSS [training: 0.14646488750967707 | validation: 0.16466808223700385]
	TIME [epoch: 9.24 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13092784808347172		[learning rate: 0.0042345]
	Learning Rate: 0.00423448
	LOSS [training: 0.13092784808347172 | validation: 0.20340424011528657]
	TIME [epoch: 9.23 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14024132842184406		[learning rate: 0.0042215]
	Learning Rate: 0.0042215
	LOSS [training: 0.14024132842184406 | validation: 0.20029246870165288]
	TIME [epoch: 9.23 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12254134066594469		[learning rate: 0.0042086]
	Learning Rate: 0.00420856
	LOSS [training: 0.12254134066594469 | validation: 0.10958669049830566]
	TIME [epoch: 9.23 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12051331981060309		[learning rate: 0.0041957]
	Learning Rate: 0.00419566
	LOSS [training: 0.12051331981060309 | validation: 0.1738040387710949]
	TIME [epoch: 9.25 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1389481057398063		[learning rate: 0.0041828]
	Learning Rate: 0.0041828
	LOSS [training: 0.1389481057398063 | validation: 0.07699414790621767]
	TIME [epoch: 9.24 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09426802280951393		[learning rate: 0.00417]
	Learning Rate: 0.00416997
	LOSS [training: 0.09426802280951393 | validation: 0.0779743022415801]
	TIME [epoch: 9.23 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07139708809089707		[learning rate: 0.0041572]
	Learning Rate: 0.00415719
	LOSS [training: 0.07139708809089707 | validation: 0.0662670878500907]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_786.pth
	Model improved!!!
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09317656988225269		[learning rate: 0.0041444]
	Learning Rate: 0.00414445
	LOSS [training: 0.09317656988225269 | validation: 0.0669868599398776]
	TIME [epoch: 9.23 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10660175895164961		[learning rate: 0.0041317]
	Learning Rate: 0.00413174
	LOSS [training: 0.10660175895164961 | validation: 0.13088302055567907]
	TIME [epoch: 9.25 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10978686200375873		[learning rate: 0.0041191]
	Learning Rate: 0.00411908
	LOSS [training: 0.10978686200375873 | validation: 0.15228459097455296]
	TIME [epoch: 9.24 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09561754230150951		[learning rate: 0.0041065]
	Learning Rate: 0.00410645
	LOSS [training: 0.09561754230150951 | validation: 0.12969862995361098]
	TIME [epoch: 9.24 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09702378784856665		[learning rate: 0.0040939]
	Learning Rate: 0.00409386
	LOSS [training: 0.09702378784856665 | validation: 0.09243552775652857]
	TIME [epoch: 9.24 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08802390727098602		[learning rate: 0.0040813]
	Learning Rate: 0.00408131
	LOSS [training: 0.08802390727098602 | validation: 0.10442032581758409]
	TIME [epoch: 9.24 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07844111297284363		[learning rate: 0.0040688]
	Learning Rate: 0.0040688
	LOSS [training: 0.07844111297284363 | validation: 0.1739758033397628]
	TIME [epoch: 9.26 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09910201936804551		[learning rate: 0.0040563]
	Learning Rate: 0.00405633
	LOSS [training: 0.09910201936804551 | validation: 0.11423693258945981]
	TIME [epoch: 9.24 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10211188963687035		[learning rate: 0.0040439]
	Learning Rate: 0.0040439
	LOSS [training: 0.10211188963687035 | validation: 0.10895853398697902]
	TIME [epoch: 9.23 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09924087253224731		[learning rate: 0.0040315]
	Learning Rate: 0.0040315
	LOSS [training: 0.09924087253224731 | validation: 0.10535471217173517]
	TIME [epoch: 9.23 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09103291434209848		[learning rate: 0.0040191]
	Learning Rate: 0.00401914
	LOSS [training: 0.09103291434209848 | validation: 0.10484571655556028]
	TIME [epoch: 9.24 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08214644789087301		[learning rate: 0.0040068]
	Learning Rate: 0.00400682
	LOSS [training: 0.08214644789087301 | validation: 0.07199474996343289]
	TIME [epoch: 9.25 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09535168631973491		[learning rate: 0.0039945]
	Learning Rate: 0.00399454
	LOSS [training: 0.09535168631973491 | validation: 0.10547993425993352]
	TIME [epoch: 9.24 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0989275272996372		[learning rate: 0.0039823]
	Learning Rate: 0.00398229
	LOSS [training: 0.0989275272996372 | validation: 0.16946706891555563]
	TIME [epoch: 9.24 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09279714578814299		[learning rate: 0.0039701]
	Learning Rate: 0.00397009
	LOSS [training: 0.09279714578814299 | validation: 0.06679133092344522]
	TIME [epoch: 9.23 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08404296825187353		[learning rate: 0.0039579]
	Learning Rate: 0.00395792
	LOSS [training: 0.08404296825187353 | validation: 0.08579463217188019]
	TIME [epoch: 9.24 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07838793430883968		[learning rate: 0.0039458]
	Learning Rate: 0.00394578
	LOSS [training: 0.07838793430883968 | validation: 0.09918330907468553]
	TIME [epoch: 9.25 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09447185555739493		[learning rate: 0.0039337]
	Learning Rate: 0.00393369
	LOSS [training: 0.09447185555739493 | validation: 0.08114390844574829]
	TIME [epoch: 9.24 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09754611701718599		[learning rate: 0.0039216]
	Learning Rate: 0.00392163
	LOSS [training: 0.09754611701718599 | validation: 0.10010319715381705]
	TIME [epoch: 9.24 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12734124534456573		[learning rate: 0.0039096]
	Learning Rate: 0.00390961
	LOSS [training: 0.12734124534456573 | validation: 0.17682625798079457]
	TIME [epoch: 9.24 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19369190575001596		[learning rate: 0.0038976]
	Learning Rate: 0.00389762
	LOSS [training: 0.19369190575001596 | validation: 0.21267698423669326]
	TIME [epoch: 9.25 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1329702639000873		[learning rate: 0.0038857]
	Learning Rate: 0.00388568
	LOSS [training: 0.1329702639000873 | validation: 0.1529877746353491]
	TIME [epoch: 9.26 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12689638569799172		[learning rate: 0.0038738]
	Learning Rate: 0.00387377
	LOSS [training: 0.12689638569799172 | validation: 0.18847393673082746]
	TIME [epoch: 9.24 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1609392382434559		[learning rate: 0.0038619]
	Learning Rate: 0.00386189
	LOSS [training: 0.1609392382434559 | validation: 0.16599452308910356]
	TIME [epoch: 9.24 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1342419267421191		[learning rate: 0.0038501]
	Learning Rate: 0.00385005
	LOSS [training: 0.1342419267421191 | validation: 0.09723661346673176]
	TIME [epoch: 9.24 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09470786364530406		[learning rate: 0.0038383]
	Learning Rate: 0.00383825
	LOSS [training: 0.09470786364530406 | validation: 0.150026883859927]
	TIME [epoch: 9.24 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1099634864437286		[learning rate: 0.0038265]
	Learning Rate: 0.00382648
	LOSS [training: 0.1099634864437286 | validation: 0.1493339980611748]
	TIME [epoch: 9.26 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09929663869964878		[learning rate: 0.0038148]
	Learning Rate: 0.00381476
	LOSS [training: 0.09929663869964878 | validation: 0.06654867295908067]
	TIME [epoch: 9.24 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07940166010504787		[learning rate: 0.0038031]
	Learning Rate: 0.00380306
	LOSS [training: 0.07940166010504787 | validation: 0.15037048644725207]
	TIME [epoch: 9.24 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16245371215318713		[learning rate: 0.0037914]
	Learning Rate: 0.0037914
	LOSS [training: 0.16245371215318713 | validation: 0.13039953597055692]
	TIME [epoch: 9.24 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08966407176819813		[learning rate: 0.0037798]
	Learning Rate: 0.00377978
	LOSS [training: 0.08966407176819813 | validation: 0.11138091160355212]
	TIME [epoch: 9.25 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11385527617415914		[learning rate: 0.0037682]
	Learning Rate: 0.00376819
	LOSS [training: 0.11385527617415914 | validation: 0.10211576381766249]
	TIME [epoch: 9.26 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08711022723004432		[learning rate: 0.0037566]
	Learning Rate: 0.00375664
	LOSS [training: 0.08711022723004432 | validation: 0.10162677275951665]
	TIME [epoch: 9.23 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06477749343989667		[learning rate: 0.0037451]
	Learning Rate: 0.00374513
	LOSS [training: 0.06477749343989667 | validation: 0.07517909947784367]
	TIME [epoch: 9.24 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08053991203576359		[learning rate: 0.0037336]
	Learning Rate: 0.00373365
	LOSS [training: 0.08053991203576359 | validation: 0.06739048165556155]
	TIME [epoch: 9.24 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09963012815356179		[learning rate: 0.0037222]
	Learning Rate: 0.0037222
	LOSS [training: 0.09963012815356179 | validation: 0.12643615269796674]
	TIME [epoch: 9.25 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12977621523518673		[learning rate: 0.0037108]
	Learning Rate: 0.00371079
	LOSS [training: 0.12977621523518673 | validation: 0.0988379546515977]
	TIME [epoch: 9.25 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0994526617435426		[learning rate: 0.0036994]
	Learning Rate: 0.00369942
	LOSS [training: 0.0994526617435426 | validation: 0.15503946868121393]
	TIME [epoch: 9.24 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11911615618869435		[learning rate: 0.0036881]
	Learning Rate: 0.00368808
	LOSS [training: 0.11911615618869435 | validation: 0.053631624414640394]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_825.pth
	Model improved!!!
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10055251288199965		[learning rate: 0.0036768]
	Learning Rate: 0.00367677
	LOSS [training: 0.10055251288199965 | validation: 0.11008188197836116]
	TIME [epoch: 9.23 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08522634525943994		[learning rate: 0.0036655]
	Learning Rate: 0.0036655
	LOSS [training: 0.08522634525943994 | validation: 0.08683980341465368]
	TIME [epoch: 9.25 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07148938031880679		[learning rate: 0.0036543]
	Learning Rate: 0.00365426
	LOSS [training: 0.07148938031880679 | validation: 0.08671690374874186]
	TIME [epoch: 9.23 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06463831297775188		[learning rate: 0.0036431]
	Learning Rate: 0.00364306
	LOSS [training: 0.06463831297775188 | validation: 0.07828342165581748]
	TIME [epoch: 9.23 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10123635399920057		[learning rate: 0.0036319]
	Learning Rate: 0.0036319
	LOSS [training: 0.10123635399920057 | validation: 0.12047946733078257]
	TIME [epoch: 9.23 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09799866339319559		[learning rate: 0.0036208]
	Learning Rate: 0.00362076
	LOSS [training: 0.09799866339319559 | validation: 0.09447434711512427]
	TIME [epoch: 9.24 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07799931782463308		[learning rate: 0.0036097]
	Learning Rate: 0.00360966
	LOSS [training: 0.07799931782463308 | validation: 0.08820588309894818]
	TIME [epoch: 9.25 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10122035490810737		[learning rate: 0.0035986]
	Learning Rate: 0.0035986
	LOSS [training: 0.10122035490810737 | validation: 0.10707162699899242]
	TIME [epoch: 12.1 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06883579557484204		[learning rate: 0.0035876]
	Learning Rate: 0.00358757
	LOSS [training: 0.06883579557484204 | validation: 0.089905261211919]
	TIME [epoch: 9.23 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12096180695700551		[learning rate: 0.0035766]
	Learning Rate: 0.00357657
	LOSS [training: 0.12096180695700551 | validation: 0.09007610634718065]
	TIME [epoch: 9.24 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10326246337273756		[learning rate: 0.0035656]
	Learning Rate: 0.00356561
	LOSS [training: 0.10326246337273756 | validation: 0.07152956217228719]
	TIME [epoch: 9.23 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09706741357371425		[learning rate: 0.0035547]
	Learning Rate: 0.00355468
	LOSS [training: 0.09706741357371425 | validation: 0.09202771452572228]
	TIME [epoch: 9.25 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11326713820301734		[learning rate: 0.0035438]
	Learning Rate: 0.00354378
	LOSS [training: 0.11326713820301734 | validation: 0.16230018345343472]
	TIME [epoch: 9.24 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10637121223534873		[learning rate: 0.0035329]
	Learning Rate: 0.00353292
	LOSS [training: 0.10637121223534873 | validation: 0.06519644406492431]
	TIME [epoch: 9.23 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08064486063971846		[learning rate: 0.0035221]
	Learning Rate: 0.00352209
	LOSS [training: 0.08064486063971846 | validation: 0.06709905231893573]
	TIME [epoch: 9.24 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08159043028805386		[learning rate: 0.0035113]
	Learning Rate: 0.00351129
	LOSS [training: 0.08159043028805386 | validation: 0.08925486687792097]
	TIME [epoch: 9.24 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0860531538190573		[learning rate: 0.0035005]
	Learning Rate: 0.00350053
	LOSS [training: 0.0860531538190573 | validation: 0.1373133804702035]
	TIME [epoch: 9.26 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09311541249016941		[learning rate: 0.0034898]
	Learning Rate: 0.0034898
	LOSS [training: 0.09311541249016941 | validation: 0.11161137374498269]
	TIME [epoch: 9.24 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08013067246421793		[learning rate: 0.0034791]
	Learning Rate: 0.0034791
	LOSS [training: 0.08013067246421793 | validation: 0.0716551418688673]
	TIME [epoch: 9.23 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10636703120957065		[learning rate: 0.0034684]
	Learning Rate: 0.00346843
	LOSS [training: 0.10636703120957065 | validation: 0.12812312525035058]
	TIME [epoch: 9.23 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08119519072842427		[learning rate: 0.0034578]
	Learning Rate: 0.0034578
	LOSS [training: 0.08119519072842427 | validation: 0.12029313299049305]
	TIME [epoch: 9.23 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10802320916529366		[learning rate: 0.0034472]
	Learning Rate: 0.0034472
	LOSS [training: 0.10802320916529366 | validation: 0.10416552556737846]
	TIME [epoch: 9.25 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09329721446988229		[learning rate: 0.0034366]
	Learning Rate: 0.00343663
	LOSS [training: 0.09329721446988229 | validation: 0.15713294317427162]
	TIME [epoch: 9.23 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15103841459823336		[learning rate: 0.0034261]
	Learning Rate: 0.0034261
	LOSS [training: 0.15103841459823336 | validation: 0.10840583373132545]
	TIME [epoch: 9.24 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11351155088733647		[learning rate: 0.0034156]
	Learning Rate: 0.0034156
	LOSS [training: 0.11351155088733647 | validation: 0.10858253103524212]
	TIME [epoch: 9.24 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10392144017094118		[learning rate: 0.0034051]
	Learning Rate: 0.00340513
	LOSS [training: 0.10392144017094118 | validation: 0.09952704407898852]
	TIME [epoch: 9.24 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10157951914417855		[learning rate: 0.0033947]
	Learning Rate: 0.00339469
	LOSS [training: 0.10157951914417855 | validation: 0.09567490586707691]
	TIME [epoch: 9.25 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14203383513754883		[learning rate: 0.0033843]
	Learning Rate: 0.00338428
	LOSS [training: 0.14203383513754883 | validation: 0.1062536350685262]
	TIME [epoch: 9.23 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11884254892042663		[learning rate: 0.0033739]
	Learning Rate: 0.00337391
	LOSS [training: 0.11884254892042663 | validation: 0.10199125749646863]
	TIME [epoch: 9.23 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10515068309125768		[learning rate: 0.0033636]
	Learning Rate: 0.00336357
	LOSS [training: 0.10515068309125768 | validation: 0.12204152302986127]
	TIME [epoch: 9.24 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12060733068837977		[learning rate: 0.0033533]
	Learning Rate: 0.00335326
	LOSS [training: 0.12060733068837977 | validation: 0.05856981367189097]
	TIME [epoch: 9.24 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19263784119567892		[learning rate: 0.003343]
	Learning Rate: 0.00334298
	LOSS [training: 0.19263784119567892 | validation: 0.3174919824330882]
	TIME [epoch: 9.26 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25014393863794404		[learning rate: 0.0033327]
	Learning Rate: 0.00333273
	LOSS [training: 0.25014393863794404 | validation: 0.1316344982405087]
	TIME [epoch: 9.24 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13997361328189978		[learning rate: 0.0033225]
	Learning Rate: 0.00332251
	LOSS [training: 0.13997361328189978 | validation: 0.2219392060989783]
	TIME [epoch: 9.24 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25264255994866974		[learning rate: 0.0033123]
	Learning Rate: 0.00331233
	LOSS [training: 0.25264255994866974 | validation: 0.22713648946699105]
	TIME [epoch: 9.24 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1293103613930327		[learning rate: 0.0033022]
	Learning Rate: 0.00330217
	LOSS [training: 0.1293103613930327 | validation: 0.08917567385092665]
	TIME [epoch: 9.24 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12768727240439953		[learning rate: 0.0032921]
	Learning Rate: 0.00329205
	LOSS [training: 0.12768727240439953 | validation: 0.17528185205536773]
	TIME [epoch: 9.26 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15382723840561516		[learning rate: 0.003282]
	Learning Rate: 0.00328196
	LOSS [training: 0.15382723840561516 | validation: 0.13829217524401388]
	TIME [epoch: 9.24 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15277370463229828		[learning rate: 0.0032719]
	Learning Rate: 0.0032719
	LOSS [training: 0.15277370463229828 | validation: 0.13347725460689716]
	TIME [epoch: 9.24 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11091999954302678		[learning rate: 0.0032619]
	Learning Rate: 0.00326187
	LOSS [training: 0.11091999954302678 | validation: 0.1424163829920706]
	TIME [epoch: 9.24 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10255193073545721		[learning rate: 0.0032519]
	Learning Rate: 0.00325187
	LOSS [training: 0.10255193073545721 | validation: 0.09392738607037265]
	TIME [epoch: 9.24 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11794995342602665		[learning rate: 0.0032419]
	Learning Rate: 0.0032419
	LOSS [training: 0.11794995342602665 | validation: 0.11245717612410731]
	TIME [epoch: 9.27 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09070280775743264		[learning rate: 0.003232]
	Learning Rate: 0.00323197
	LOSS [training: 0.09070280775743264 | validation: 0.12720447371043525]
	TIME [epoch: 9.24 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16899895117045313		[learning rate: 0.0032221]
	Learning Rate: 0.00322206
	LOSS [training: 0.16899895117045313 | validation: 0.23110995067552792]
	TIME [epoch: 9.24 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3326128735660501		[learning rate: 0.0032122]
	Learning Rate: 0.00321218
	LOSS [training: 0.3326128735660501 | validation: 0.19366314690646597]
	TIME [epoch: 9.24 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1585478064060743		[learning rate: 0.0032023]
	Learning Rate: 0.00320233
	LOSS [training: 0.1585478064060743 | validation: 0.17621902098250916]
	TIME [epoch: 9.24 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17469142478422414		[learning rate: 0.0031925]
	Learning Rate: 0.00319252
	LOSS [training: 0.17469142478422414 | validation: 0.20380578312096548]
	TIME [epoch: 9.26 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16434855140285254		[learning rate: 0.0031827]
	Learning Rate: 0.00318273
	LOSS [training: 0.16434855140285254 | validation: 0.10447356614843242]
	TIME [epoch: 9.24 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12103803273637512		[learning rate: 0.003173]
	Learning Rate: 0.00317297
	LOSS [training: 0.12103803273637512 | validation: 0.12178091502507656]
	TIME [epoch: 9.24 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11361368112239982		[learning rate: 0.0031632]
	Learning Rate: 0.00316325
	LOSS [training: 0.11361368112239982 | validation: 0.11246088397582196]
	TIME [epoch: 9.24 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10005962645563352		[learning rate: 0.0031536]
	Learning Rate: 0.00315355
	LOSS [training: 0.10005962645563352 | validation: 0.08969007326919831]
	TIME [epoch: 9.25 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11609641753869726		[learning rate: 0.0031439]
	Learning Rate: 0.00314389
	LOSS [training: 0.11609641753869726 | validation: 0.09876750752445534]
	TIME [epoch: 9.25 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1149894855213048		[learning rate: 0.0031342]
	Learning Rate: 0.00313425
	LOSS [training: 0.1149894855213048 | validation: 0.0737806804012755]
	TIME [epoch: 9.24 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06784750459465586		[learning rate: 0.0031246]
	Learning Rate: 0.00312464
	LOSS [training: 0.06784750459465586 | validation: 0.14323159405330801]
	TIME [epoch: 9.24 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.074720419056161		[learning rate: 0.0031151]
	Learning Rate: 0.00311506
	LOSS [training: 0.074720419056161 | validation: 0.05920869811407861]
	TIME [epoch: 9.24 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.066153104917933		[learning rate: 0.0031055]
	Learning Rate: 0.00310551
	LOSS [training: 0.066153104917933 | validation: 0.05579583302216348]
	TIME [epoch: 9.26 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08040164106800743		[learning rate: 0.003096]
	Learning Rate: 0.00309599
	LOSS [training: 0.08040164106800743 | validation: 0.0861944448502305]
	TIME [epoch: 9.24 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05606873860751508		[learning rate: 0.0030865]
	Learning Rate: 0.0030865
	LOSS [training: 0.05606873860751508 | validation: 0.05919692296713078]
	TIME [epoch: 9.24 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06517178386224687		[learning rate: 0.003077]
	Learning Rate: 0.00307704
	LOSS [training: 0.06517178386224687 | validation: 0.051933745939320985]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_884.pth
	Model improved!!!
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05667146692055146		[learning rate: 0.0030676]
	Learning Rate: 0.00306761
	LOSS [training: 0.05667146692055146 | validation: 0.0471807964469802]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_885.pth
	Model improved!!!
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06461242927386292		[learning rate: 0.0030582]
	Learning Rate: 0.00305821
	LOSS [training: 0.06461242927386292 | validation: 0.08945723201932695]
	TIME [epoch: 9.25 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0725263682825851		[learning rate: 0.0030488]
	Learning Rate: 0.00304883
	LOSS [training: 0.0725263682825851 | validation: 0.09226060613667009]
	TIME [epoch: 9.25 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12388263709526537		[learning rate: 0.0030395]
	Learning Rate: 0.00303948
	LOSS [training: 0.12388263709526537 | validation: 0.12466332714136563]
	TIME [epoch: 9.24 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08748130547591651		[learning rate: 0.0030302]
	Learning Rate: 0.00303017
	LOSS [training: 0.08748130547591651 | validation: 0.07713786705889433]
	TIME [epoch: 9.24 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08158385130509758		[learning rate: 0.0030209]
	Learning Rate: 0.00302088
	LOSS [training: 0.08158385130509758 | validation: 0.12095468403403156]
	TIME [epoch: 9.24 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08776946765266999		[learning rate: 0.0030116]
	Learning Rate: 0.00301162
	LOSS [training: 0.08776946765266999 | validation: 0.09577786443677197]
	TIME [epoch: 9.26 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09758627710059649		[learning rate: 0.0030024]
	Learning Rate: 0.00300239
	LOSS [training: 0.09758627710059649 | validation: 0.13596076024103282]
	TIME [epoch: 9.25 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08013474831364845		[learning rate: 0.0029932]
	Learning Rate: 0.00299318
	LOSS [training: 0.08013474831364845 | validation: 0.07207053345210931]
	TIME [epoch: 9.24 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10665317911968193		[learning rate: 0.002984]
	Learning Rate: 0.00298401
	LOSS [training: 0.10665317911968193 | validation: 0.16118993230332557]
	TIME [epoch: 9.24 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09602707590457782		[learning rate: 0.0029749]
	Learning Rate: 0.00297486
	LOSS [training: 0.09602707590457782 | validation: 0.10772503841424524]
	TIME [epoch: 9.24 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08161892591402982		[learning rate: 0.0029657]
	Learning Rate: 0.00296574
	LOSS [training: 0.08161892591402982 | validation: 0.1684474186170716]
	TIME [epoch: 9.26 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08584134061173852		[learning rate: 0.0029567]
	Learning Rate: 0.00295665
	LOSS [training: 0.08584134061173852 | validation: 0.09266240446209889]
	TIME [epoch: 9.24 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14354625168132223		[learning rate: 0.0029476]
	Learning Rate: 0.00294759
	LOSS [training: 0.14354625168132223 | validation: 0.17557163749791366]
	TIME [epoch: 9.24 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12593949738499796		[learning rate: 0.0029386]
	Learning Rate: 0.00293855
	LOSS [training: 0.12593949738499796 | validation: 0.08790560440555271]
	TIME [epoch: 9.24 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07513487682534944		[learning rate: 0.0029295]
	Learning Rate: 0.00292954
	LOSS [training: 0.07513487682534944 | validation: 0.09145751718158057]
	TIME [epoch: 9.24 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08298371922802597		[learning rate: 0.0029206]
	Learning Rate: 0.00292056
	LOSS [training: 0.08298371922802597 | validation: 0.09732674605895883]
	TIME [epoch: 9.26 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08586834213455274		[learning rate: 0.0029116]
	Learning Rate: 0.00291161
	LOSS [training: 0.08586834213455274 | validation: 0.09486980092021297]
	TIME [epoch: 9.24 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06899341500321683		[learning rate: 0.0029027]
	Learning Rate: 0.00290269
	LOSS [training: 0.06899341500321683 | validation: 0.08141697402382286]
	TIME [epoch: 9.24 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06255021386947662		[learning rate: 0.0028938]
	Learning Rate: 0.00289379
	LOSS [training: 0.06255021386947662 | validation: 0.040154464125089655]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_904.pth
	Model improved!!!
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05847997841930924		[learning rate: 0.0028849]
	Learning Rate: 0.00288492
	LOSS [training: 0.05847997841930924 | validation: 0.04665330453688872]
	TIME [epoch: 9.24 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0686288869215437		[learning rate: 0.0028761]
	Learning Rate: 0.00287607
	LOSS [training: 0.0686288869215437 | validation: 0.06953823889662811]
	TIME [epoch: 9.26 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057331269239266194		[learning rate: 0.0028673]
	Learning Rate: 0.00286726
	LOSS [training: 0.057331269239266194 | validation: 0.06870422404980675]
	TIME [epoch: 9.24 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06132494422921335		[learning rate: 0.0028585]
	Learning Rate: 0.00285847
	LOSS [training: 0.06132494422921335 | validation: 0.07472564778788016]
	TIME [epoch: 9.24 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06658608250996963		[learning rate: 0.0028497]
	Learning Rate: 0.00284971
	LOSS [training: 0.06658608250996963 | validation: 0.06889825773463013]
	TIME [epoch: 9.24 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07251975863956342		[learning rate: 0.002841]
	Learning Rate: 0.00284097
	LOSS [training: 0.07251975863956342 | validation: 0.05802477594120914]
	TIME [epoch: 9.24 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05608304312610367		[learning rate: 0.0028323]
	Learning Rate: 0.00283226
	LOSS [training: 0.05608304312610367 | validation: 0.04426613938561355]
	TIME [epoch: 9.25 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0667417504364062		[learning rate: 0.0028236]
	Learning Rate: 0.00282358
	LOSS [training: 0.0667417504364062 | validation: 0.06462723110125972]
	TIME [epoch: 9.24 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10262243412739731		[learning rate: 0.0028149]
	Learning Rate: 0.00281492
	LOSS [training: 0.10262243412739731 | validation: 0.0743310443075604]
	TIME [epoch: 9.24 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10017024508604862		[learning rate: 0.0028063]
	Learning Rate: 0.0028063
	LOSS [training: 0.10017024508604862 | validation: 0.11264796591043291]
	TIME [epoch: 9.24 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09144868665252584		[learning rate: 0.0027977]
	Learning Rate: 0.00279769
	LOSS [training: 0.09144868665252584 | validation: 0.04359815122517416]
	TIME [epoch: 9.23 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05788786535270268		[learning rate: 0.0027891]
	Learning Rate: 0.00278912
	LOSS [training: 0.05788786535270268 | validation: 0.05019269304117667]
	TIME [epoch: 9.26 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07440257249036158		[learning rate: 0.0027806]
	Learning Rate: 0.00278057
	LOSS [training: 0.07440257249036158 | validation: 0.060604352994868625]
	TIME [epoch: 9.24 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06828385469182047		[learning rate: 0.002772]
	Learning Rate: 0.00277204
	LOSS [training: 0.06828385469182047 | validation: 0.06819027072134581]
	TIME [epoch: 9.24 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059318608256122576		[learning rate: 0.0027635]
	Learning Rate: 0.00276355
	LOSS [training: 0.059318608256122576 | validation: 0.11147925197256854]
	TIME [epoch: 9.24 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10591617540185345		[learning rate: 0.0027551]
	Learning Rate: 0.00275507
	LOSS [training: 0.10591617540185345 | validation: 0.0489833137427713]
	TIME [epoch: 9.24 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05779595386585511		[learning rate: 0.0027466]
	Learning Rate: 0.00274663
	LOSS [training: 0.05779595386585511 | validation: 0.11486361260430647]
	TIME [epoch: 9.26 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06609979011222894		[learning rate: 0.0027382]
	Learning Rate: 0.00273821
	LOSS [training: 0.06609979011222894 | validation: 0.04397826012174188]
	TIME [epoch: 9.24 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05270333399772777		[learning rate: 0.0027298]
	Learning Rate: 0.00272982
	LOSS [training: 0.05270333399772777 | validation: 0.06504654347804738]
	TIME [epoch: 9.24 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05675737874412275		[learning rate: 0.0027214]
	Learning Rate: 0.00272145
	LOSS [training: 0.05675737874412275 | validation: 0.06061855409498301]
	TIME [epoch: 9.24 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07159001937920202		[learning rate: 0.0027131]
	Learning Rate: 0.00271311
	LOSS [training: 0.07159001937920202 | validation: 0.08891720412695919]
	TIME [epoch: 9.24 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07831011859394385		[learning rate: 0.0027048]
	Learning Rate: 0.00270479
	LOSS [training: 0.07831011859394385 | validation: 0.06899132039740438]
	TIME [epoch: 9.25 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08440900982987617		[learning rate: 0.0026965]
	Learning Rate: 0.0026965
	LOSS [training: 0.08440900982987617 | validation: 0.08908140364520957]
	TIME [epoch: 9.24 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05822350036133036		[learning rate: 0.0026882]
	Learning Rate: 0.00268823
	LOSS [training: 0.05822350036133036 | validation: 0.060722245135954075]
	TIME [epoch: 9.23 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08247023261621628		[learning rate: 0.00268]
	Learning Rate: 0.00267999
	LOSS [training: 0.08247023261621628 | validation: 0.08812543040515221]
	TIME [epoch: 9.23 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0945774643149296		[learning rate: 0.0026718]
	Learning Rate: 0.00267178
	LOSS [training: 0.0945774643149296 | validation: 0.19643558803792854]
	TIME [epoch: 9.26 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11624247662959412		[learning rate: 0.0026636]
	Learning Rate: 0.00266359
	LOSS [training: 0.11624247662959412 | validation: 0.07408856317943867]
	TIME [epoch: 9.24 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.079530967671058		[learning rate: 0.0026554]
	Learning Rate: 0.00265542
	LOSS [training: 0.079530967671058 | validation: 0.07341648910103346]
	TIME [epoch: 9.23 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07279310667901041		[learning rate: 0.0026473]
	Learning Rate: 0.00264728
	LOSS [training: 0.07279310667901041 | validation: 0.09040242363501094]
	TIME [epoch: 9.24 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06515986045690256		[learning rate: 0.0026392]
	Learning Rate: 0.00263917
	LOSS [training: 0.06515986045690256 | validation: 0.09827317000363574]
	TIME [epoch: 9.23 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07622841216098368		[learning rate: 0.0026311]
	Learning Rate: 0.00263108
	LOSS [training: 0.07622841216098368 | validation: 0.06768356404890882]
	TIME [epoch: 9.26 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06996928158053457		[learning rate: 0.002623]
	Learning Rate: 0.00262301
	LOSS [training: 0.06996928158053457 | validation: 0.07988324832450835]
	TIME [epoch: 9.24 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07964733272586139		[learning rate: 0.002615]
	Learning Rate: 0.00261497
	LOSS [training: 0.07964733272586139 | validation: 0.10585276007846113]
	TIME [epoch: 9.23 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08840857571132642		[learning rate: 0.002607]
	Learning Rate: 0.00260695
	LOSS [training: 0.08840857571132642 | validation: 0.11505581522424435]
	TIME [epoch: 9.23 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0784600637404076		[learning rate: 0.002599]
	Learning Rate: 0.00259896
	LOSS [training: 0.0784600637404076 | validation: 0.08988080312682925]
	TIME [epoch: 9.24 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06751710770243086		[learning rate: 0.002591]
	Learning Rate: 0.002591
	LOSS [training: 0.06751710770243086 | validation: 0.05582062091972584]
	TIME [epoch: 9.25 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07769061439627356		[learning rate: 0.0025831]
	Learning Rate: 0.00258305
	LOSS [training: 0.07769061439627356 | validation: 0.06633737698032106]
	TIME [epoch: 9.24 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0851364311219098		[learning rate: 0.0025751]
	Learning Rate: 0.00257513
	LOSS [training: 0.0851364311219098 | validation: 0.08825416522803635]
	TIME [epoch: 9.24 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06285069072059152		[learning rate: 0.0025672]
	Learning Rate: 0.00256724
	LOSS [training: 0.06285069072059152 | validation: 0.07721331416156135]
	TIME [epoch: 9.24 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06339375870448576		[learning rate: 0.0025594]
	Learning Rate: 0.00255937
	LOSS [training: 0.06339375870448576 | validation: 0.10575657167303706]
	TIME [epoch: 9.24 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07966587797327691		[learning rate: 0.0025515]
	Learning Rate: 0.00255153
	LOSS [training: 0.07966587797327691 | validation: 0.07188089144650402]
	TIME [epoch: 9.25 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07060873253141683		[learning rate: 0.0025437]
	Learning Rate: 0.0025437
	LOSS [training: 0.07060873253141683 | validation: 0.13698530522078387]
	TIME [epoch: 9.24 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09986301361621235		[learning rate: 0.0025359]
	Learning Rate: 0.00253591
	LOSS [training: 0.09986301361621235 | validation: 0.06929420973870148]
	TIME [epoch: 9.23 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07073201535991111		[learning rate: 0.0025281]
	Learning Rate: 0.00252813
	LOSS [training: 0.07073201535991111 | validation: 0.07035476531051021]
	TIME [epoch: 9.24 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06968018632972285		[learning rate: 0.0025204]
	Learning Rate: 0.00252038
	LOSS [training: 0.06968018632972285 | validation: 0.08650194994266139]
	TIME [epoch: 9.23 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06914965023238952		[learning rate: 0.0025127]
	Learning Rate: 0.00251266
	LOSS [training: 0.06914965023238952 | validation: 0.07954582080998493]
	TIME [epoch: 9.25 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0695018925122461		[learning rate: 0.002505]
	Learning Rate: 0.00250496
	LOSS [training: 0.0695018925122461 | validation: 0.06468252617564586]
	TIME [epoch: 9.24 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09451799929368125		[learning rate: 0.0024973]
	Learning Rate: 0.00249728
	LOSS [training: 0.09451799929368125 | validation: 0.12707908353132819]
	TIME [epoch: 9.23 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06952546756268307		[learning rate: 0.0024896]
	Learning Rate: 0.00248962
	LOSS [training: 0.06952546756268307 | validation: 0.04905682572535254]
	TIME [epoch: 9.22 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047122341093479916		[learning rate: 0.002482]
	Learning Rate: 0.00248199
	LOSS [training: 0.047122341093479916 | validation: 0.04934097105076197]
	TIME [epoch: 9.24 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04499188071304109		[learning rate: 0.0024744]
	Learning Rate: 0.00247438
	LOSS [training: 0.04499188071304109 | validation: 0.06349156409976085]
	TIME [epoch: 9.26 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058981513247315195		[learning rate: 0.0024668]
	Learning Rate: 0.0024668
	LOSS [training: 0.058981513247315195 | validation: 0.0769771167686657]
	TIME [epoch: 9.24 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0653615980696218		[learning rate: 0.0024592]
	Learning Rate: 0.00245923
	LOSS [training: 0.0653615980696218 | validation: 0.06336468327764375]
	TIME [epoch: 9.24 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05756165795841267		[learning rate: 0.0024517]
	Learning Rate: 0.0024517
	LOSS [training: 0.05756165795841267 | validation: 0.062934419064034]
	TIME [epoch: 9.23 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05422112654477205		[learning rate: 0.0024442]
	Learning Rate: 0.00244418
	LOSS [training: 0.05422112654477205 | validation: 0.05587845772412816]
	TIME [epoch: 9.25 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05630697117237993		[learning rate: 0.0024367]
	Learning Rate: 0.00243669
	LOSS [training: 0.05630697117237993 | validation: 0.05047194944176809]
	TIME [epoch: 9.25 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05715924249522027		[learning rate: 0.0024292]
	Learning Rate: 0.00242922
	LOSS [training: 0.05715924249522027 | validation: 0.06727351951182257]
	TIME [epoch: 9.23 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05789220679734984		[learning rate: 0.0024218]
	Learning Rate: 0.00242177
	LOSS [training: 0.05789220679734984 | validation: 0.06142970349615695]
	TIME [epoch: 9.26 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07380620141365432		[learning rate: 0.0024143]
	Learning Rate: 0.00241435
	LOSS [training: 0.07380620141365432 | validation: 0.1058122535361781]
	TIME [epoch: 9.24 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07656959686740616		[learning rate: 0.0024069]
	Learning Rate: 0.00240695
	LOSS [training: 0.07656959686740616 | validation: 0.08436669213106793]
	TIME [epoch: 9.23 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05956915821278441		[learning rate: 0.0023996]
	Learning Rate: 0.00239957
	LOSS [training: 0.05956915821278441 | validation: 0.09317008974654734]
	TIME [epoch: 9.26 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05636555938698669		[learning rate: 0.0023922]
	Learning Rate: 0.00239221
	LOSS [training: 0.05636555938698669 | validation: 0.07166378947636357]
	TIME [epoch: 9.23 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06133690190974517		[learning rate: 0.0023849]
	Learning Rate: 0.00238488
	LOSS [training: 0.06133690190974517 | validation: 0.07695507920232011]
	TIME [epoch: 9.23 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05767095262812515		[learning rate: 0.0023776]
	Learning Rate: 0.00237757
	LOSS [training: 0.05767095262812515 | validation: 0.14151045032914875]
	TIME [epoch: 9.23 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10786861606563032		[learning rate: 0.0023703]
	Learning Rate: 0.00237028
	LOSS [training: 0.10786861606563032 | validation: 0.06358017873992844]
	TIME [epoch: 9.22 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05967681903177476		[learning rate: 0.002363]
	Learning Rate: 0.00236302
	LOSS [training: 0.05967681903177476 | validation: 0.0678777590178552]
	TIME [epoch: 9.25 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08401048316898199		[learning rate: 0.0023558]
	Learning Rate: 0.00235577
	LOSS [training: 0.08401048316898199 | validation: 0.0858371791174354]
	TIME [epoch: 9.22 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05404228433074717		[learning rate: 0.0023486]
	Learning Rate: 0.00234855
	LOSS [training: 0.05404228433074717 | validation: 0.07871283335279625]
	TIME [epoch: 9.23 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05199677965032364		[learning rate: 0.0023414]
	Learning Rate: 0.00234135
	LOSS [training: 0.05199677965032364 | validation: 0.05854112333223195]
	TIME [epoch: 9.23 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04555685291178358		[learning rate: 0.0023342]
	Learning Rate: 0.00233417
	LOSS [training: 0.04555685291178358 | validation: 0.11247079535133706]
	TIME [epoch: 9.24 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07324618066358102		[learning rate: 0.002327]
	Learning Rate: 0.00232702
	LOSS [training: 0.07324618066358102 | validation: 0.07464049326862186]
	TIME [epoch: 9.26 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0708771805178572		[learning rate: 0.0023199]
	Learning Rate: 0.00231989
	LOSS [training: 0.0708771805178572 | validation: 0.11013349807130304]
	TIME [epoch: 9.24 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08558740588668343		[learning rate: 0.0023128]
	Learning Rate: 0.00231277
	LOSS [training: 0.08558740588668343 | validation: 0.08039756875792792]
	TIME [epoch: 9.24 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05567809267052757		[learning rate: 0.0023057]
	Learning Rate: 0.00230569
	LOSS [training: 0.05567809267052757 | validation: 0.06923229205510714]
	TIME [epoch: 9.24 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06343546608003262		[learning rate: 0.0022986]
	Learning Rate: 0.00229862
	LOSS [training: 0.06343546608003262 | validation: 0.07973531588556146]
	TIME [epoch: 9.25 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1197142785796359		[learning rate: 0.0022916]
	Learning Rate: 0.00229157
	LOSS [training: 0.1197142785796359 | validation: 0.11201677165679391]
	TIME [epoch: 9.25 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0760160938686773		[learning rate: 0.0022845]
	Learning Rate: 0.00228455
	LOSS [training: 0.0760160938686773 | validation: 0.08798103127178124]
	TIME [epoch: 9.23 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07221225776223791		[learning rate: 0.0022775]
	Learning Rate: 0.00227754
	LOSS [training: 0.07221225776223791 | validation: 0.09229297133850496]
	TIME [epoch: 9.24 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05928063316656821		[learning rate: 0.0022706]
	Learning Rate: 0.00227056
	LOSS [training: 0.05928063316656821 | validation: 0.05339764163896148]
	TIME [epoch: 9.24 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05193075775050349		[learning rate: 0.0022636]
	Learning Rate: 0.0022636
	LOSS [training: 0.05193075775050349 | validation: 0.05471937280143347]
	TIME [epoch: 9.25 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039332734221327145		[learning rate: 0.0022567]
	Learning Rate: 0.00225666
	LOSS [training: 0.039332734221327145 | validation: 0.06486361012673345]
	TIME [epoch: 9.24 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058233383519058046		[learning rate: 0.0022497]
	Learning Rate: 0.00224975
	LOSS [training: 0.058233383519058046 | validation: 0.07886081075942136]
	TIME [epoch: 9.23 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06396404366162453		[learning rate: 0.0022428]
	Learning Rate: 0.00224285
	LOSS [training: 0.06396404366162453 | validation: 0.07515891813966677]
	TIME [epoch: 9.23 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05068885714764726		[learning rate: 0.002236]
	Learning Rate: 0.00223597
	LOSS [training: 0.05068885714764726 | validation: 0.06160546014089252]
	TIME [epoch: 9.24 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05479751432853107		[learning rate: 0.0022291]
	Learning Rate: 0.00222912
	LOSS [training: 0.05479751432853107 | validation: 0.05130655586266041]
	TIME [epoch: 9.25 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03784052378679929		[learning rate: 0.0022223]
	Learning Rate: 0.00222229
	LOSS [training: 0.03784052378679929 | validation: 0.06381770887240484]
	TIME [epoch: 9.24 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05043348902249991		[learning rate: 0.0022155]
	Learning Rate: 0.00221547
	LOSS [training: 0.05043348902249991 | validation: 0.07173436834696605]
	TIME [epoch: 9.24 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03984616758467482		[learning rate: 0.0022087]
	Learning Rate: 0.00220868
	LOSS [training: 0.03984616758467482 | validation: 0.05883373435328905]
	TIME [epoch: 9.23 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06260799558963578		[learning rate: 0.0022019]
	Learning Rate: 0.00220191
	LOSS [training: 0.06260799558963578 | validation: 0.1183413884055273]
	TIME [epoch: 9.24 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0719783217055256		[learning rate: 0.0021952]
	Learning Rate: 0.00219516
	LOSS [training: 0.0719783217055256 | validation: 0.046911231596369174]
	TIME [epoch: 9.26 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06311889669344209		[learning rate: 0.0021884]
	Learning Rate: 0.00218843
	LOSS [training: 0.06311889669344209 | validation: 0.07025931851016243]
	TIME [epoch: 9.24 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04381899541553267		[learning rate: 0.0021817]
	Learning Rate: 0.00218173
	LOSS [training: 0.04381899541553267 | validation: 0.0664156682954409]
	TIME [epoch: 9.23 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07392839577064493		[learning rate: 0.002175]
	Learning Rate: 0.00217504
	LOSS [training: 0.07392839577064493 | validation: 0.14755625242717146]
	TIME [epoch: 9.23 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07695670892487147		[learning rate: 0.0021684]
	Learning Rate: 0.00216837
	LOSS [training: 0.07695670892487147 | validation: 0.04544351844290632]
	TIME [epoch: 9.24 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05267142373651314		[learning rate: 0.0021617]
	Learning Rate: 0.00216172
	LOSS [training: 0.05267142373651314 | validation: 0.06268134808849546]
	TIME [epoch: 9.25 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07341967565472897		[learning rate: 0.0021551]
	Learning Rate: 0.0021551
	LOSS [training: 0.07341967565472897 | validation: 0.05257267212919113]
	TIME [epoch: 9.24 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05602654532485283		[learning rate: 0.0021485]
	Learning Rate: 0.00214849
	LOSS [training: 0.05602654532485283 | validation: 0.04155776059232191]
	TIME [epoch: 9.23 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043126811331833166		[learning rate: 0.0021419]
	Learning Rate: 0.0021419
	LOSS [training: 0.043126811331833166 | validation: 0.04904487203184271]
	TIME [epoch: 9.24 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05607209501828593		[learning rate: 0.0021353]
	Learning Rate: 0.00213534
	LOSS [training: 0.05607209501828593 | validation: 0.06672189726831486]
	TIME [epoch: 9.23 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06705392638577708		[learning rate: 0.0021288]
	Learning Rate: 0.00212879
	LOSS [training: 0.06705392638577708 | validation: 0.07621422185935742]
	TIME [epoch: 9.25 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0553463801251771		[learning rate: 0.0021223]
	Learning Rate: 0.00212227
	LOSS [training: 0.0553463801251771 | validation: 0.060644356796543356]
	TIME [epoch: 9.23 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04364838151139032		[learning rate: 0.0021158]
	Learning Rate: 0.00211576
	LOSS [training: 0.04364838151139032 | validation: 0.09036880412124298]
	TIME [epoch: 9.24 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05997287742259638		[learning rate: 0.0021093]
	Learning Rate: 0.00210928
	LOSS [training: 0.05997287742259638 | validation: 0.04866474475811171]
	TIME [epoch: 9.24 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07123543301982013		[learning rate: 0.0021028]
	Learning Rate: 0.00210281
	LOSS [training: 0.07123543301982013 | validation: 0.08336725906838993]
	TIME [epoch: 9.24 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06750331616232626		[learning rate: 0.0020964]
	Learning Rate: 0.00209636
	LOSS [training: 0.06750331616232626 | validation: 0.08160621033015401]
	TIME [epoch: 9.26 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05655617362118907		[learning rate: 0.0020899]
	Learning Rate: 0.00208994
	LOSS [training: 0.05655617362118907 | validation: 0.046841806591616686]
	TIME [epoch: 9.24 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054884305708315886		[learning rate: 0.0020835]
	Learning Rate: 0.00208353
	LOSS [training: 0.054884305708315886 | validation: 0.05607892696360607]
	TIME [epoch: 9.24 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051623143843063414		[learning rate: 0.0020771]
	Learning Rate: 0.00207714
	LOSS [training: 0.051623143843063414 | validation: 0.07825500238368024]
	TIME [epoch: 9.24 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04378263792810883		[learning rate: 0.0020708]
	Learning Rate: 0.00207078
	LOSS [training: 0.04378263792810883 | validation: 0.06667681847548568]
	TIME [epoch: 9.24 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05183702273995883		[learning rate: 0.0020644]
	Learning Rate: 0.00206443
	LOSS [training: 0.05183702273995883 | validation: 0.05093426258261013]
	TIME [epoch: 9.26 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04310268349700879		[learning rate: 0.0020581]
	Learning Rate: 0.0020581
	LOSS [training: 0.04310268349700879 | validation: 0.08623176841696514]
	TIME [epoch: 9.24 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049237836745933294		[learning rate: 0.0020518]
	Learning Rate: 0.00205179
	LOSS [training: 0.049237836745933294 | validation: 0.04297237627711386]
	TIME [epoch: 9.24 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048087920700792944		[learning rate: 0.0020455]
	Learning Rate: 0.0020455
	LOSS [training: 0.048087920700792944 | validation: 0.06772811009477958]
	TIME [epoch: 9.24 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05780438500645052		[learning rate: 0.0020392]
	Learning Rate: 0.00203923
	LOSS [training: 0.05780438500645052 | validation: 0.06521143944326144]
	TIME [epoch: 9.24 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05693049755512386		[learning rate: 0.002033]
	Learning Rate: 0.00203298
	LOSS [training: 0.05693049755512386 | validation: 0.07291289371496823]
	TIME [epoch: 9.26 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06034660373305328		[learning rate: 0.0020267]
	Learning Rate: 0.00202675
	LOSS [training: 0.06034660373305328 | validation: 0.059474265523963565]
	TIME [epoch: 9.24 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053442592913101036		[learning rate: 0.0020205]
	Learning Rate: 0.00202054
	LOSS [training: 0.053442592913101036 | validation: 0.0495565449624088]
	TIME [epoch: 9.24 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05539492602548172		[learning rate: 0.0020143]
	Learning Rate: 0.00201434
	LOSS [training: 0.05539492602548172 | validation: 0.05877534521414106]
	TIME [epoch: 9.24 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054351443364386645		[learning rate: 0.0020082]
	Learning Rate: 0.00200817
	LOSS [training: 0.054351443364386645 | validation: 0.05974306844106654]
	TIME [epoch: 9.24 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04924970302263147		[learning rate: 0.002002]
	Learning Rate: 0.00200201
	LOSS [training: 0.04924970302263147 | validation: 0.048132471113414996]
	TIME [epoch: 9.26 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061463719660320805		[learning rate: 0.0019959]
	Learning Rate: 0.00199587
	LOSS [training: 0.061463719660320805 | validation: 0.06504612266480922]
	TIME [epoch: 9.24 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04532289085705215		[learning rate: 0.0019898]
	Learning Rate: 0.00198976
	LOSS [training: 0.04532289085705215 | validation: 0.03968332319322395]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1026.pth
	Model improved!!!
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047762627520258095		[learning rate: 0.0019837]
	Learning Rate: 0.00198366
	LOSS [training: 0.047762627520258095 | validation: 0.06479105581969502]
	TIME [epoch: 9.23 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05361079628276688		[learning rate: 0.0019776]
	Learning Rate: 0.00197758
	LOSS [training: 0.05361079628276688 | validation: 0.07668864977010945]
	TIME [epoch: 9.22 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05070666370546704		[learning rate: 0.0019715]
	Learning Rate: 0.00197151
	LOSS [training: 0.05070666370546704 | validation: 0.046613374240273786]
	TIME [epoch: 9.25 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05137734297622225		[learning rate: 0.0019655]
	Learning Rate: 0.00196547
	LOSS [training: 0.05137734297622225 | validation: 0.1422645512845233]
	TIME [epoch: 9.23 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07488039122953041		[learning rate: 0.0019594]
	Learning Rate: 0.00195945
	LOSS [training: 0.07488039122953041 | validation: 0.052706883589718256]
	TIME [epoch: 9.23 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06082047051200529		[learning rate: 0.0019534]
	Learning Rate: 0.00195344
	LOSS [training: 0.06082047051200529 | validation: 0.062255969249901066]
	TIME [epoch: 9.23 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0706400386064219		[learning rate: 0.0019475]
	Learning Rate: 0.00194745
	LOSS [training: 0.0706400386064219 | validation: 0.09544862567084905]
	TIME [epoch: 9.24 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06105087236073631		[learning rate: 0.0019415]
	Learning Rate: 0.00194148
	LOSS [training: 0.06105087236073631 | validation: 0.05614156717789111]
	TIME [epoch: 11.6 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05891920961520873		[learning rate: 0.0019355]
	Learning Rate: 0.00193553
	LOSS [training: 0.05891920961520873 | validation: 0.06741223298380214]
	TIME [epoch: 9.24 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055313946479396095		[learning rate: 0.0019296]
	Learning Rate: 0.0019296
	LOSS [training: 0.055313946479396095 | validation: 0.06316635270525608]
	TIME [epoch: 9.24 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05621299855341129		[learning rate: 0.0019237]
	Learning Rate: 0.00192368
	LOSS [training: 0.05621299855341129 | validation: 0.07258420286528959]
	TIME [epoch: 9.24 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05741683871623543		[learning rate: 0.0019178]
	Learning Rate: 0.00191779
	LOSS [training: 0.05741683871623543 | validation: 0.06909513230126418]
	TIME [epoch: 9.25 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047111965696771514		[learning rate: 0.0019119]
	Learning Rate: 0.00191191
	LOSS [training: 0.047111965696771514 | validation: 0.051208700412825714]
	TIME [epoch: 9.24 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06087926992605915		[learning rate: 0.001906]
	Learning Rate: 0.00190605
	LOSS [training: 0.06087926992605915 | validation: 0.06227789278354004]
	TIME [epoch: 9.23 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04990769968910867		[learning rate: 0.0019002]
	Learning Rate: 0.0019002
	LOSS [training: 0.04990769968910867 | validation: 0.05721461317508611]
	TIME [epoch: 9.24 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051419507778325935		[learning rate: 0.0018944]
	Learning Rate: 0.00189438
	LOSS [training: 0.051419507778325935 | validation: 0.10697806112893633]
	TIME [epoch: 9.24 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05255033568793386		[learning rate: 0.0018886]
	Learning Rate: 0.00188857
	LOSS [training: 0.05255033568793386 | validation: 0.03823398061811663]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1043.pth
	Model improved!!!
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04995215038734173		[learning rate: 0.0018828]
	Learning Rate: 0.00188278
	LOSS [training: 0.04995215038734173 | validation: 0.040569035509748816]
	TIME [epoch: 9.23 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03810131921689186		[learning rate: 0.001877]
	Learning Rate: 0.00187701
	LOSS [training: 0.03810131921689186 | validation: 0.032181399737262695]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1045.pth
	Model improved!!!
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03883419053257779		[learning rate: 0.0018713]
	Learning Rate: 0.00187126
	LOSS [training: 0.03883419053257779 | validation: 0.037239107874718]
	TIME [epoch: 9.22 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03500617732808907		[learning rate: 0.0018655]
	Learning Rate: 0.00186552
	LOSS [training: 0.03500617732808907 | validation: 0.04304812554314266]
	TIME [epoch: 9.24 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037490046066054626		[learning rate: 0.0018598]
	Learning Rate: 0.0018598
	LOSS [training: 0.037490046066054626 | validation: 0.04096467739393134]
	TIME [epoch: 9.25 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03715415865341892		[learning rate: 0.0018541]
	Learning Rate: 0.0018541
	LOSS [training: 0.03715415865341892 | validation: 0.07590126207173321]
	TIME [epoch: 9.24 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04496222904661386		[learning rate: 0.0018484]
	Learning Rate: 0.00184842
	LOSS [training: 0.04496222904661386 | validation: 0.0719135057312255]
	TIME [epoch: 9.23 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04114601190023852		[learning rate: 0.0018428]
	Learning Rate: 0.00184275
	LOSS [training: 0.04114601190023852 | validation: 0.045389242011698555]
	TIME [epoch: 9.23 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05095110504716168		[learning rate: 0.0018371]
	Learning Rate: 0.0018371
	LOSS [training: 0.05095110504716168 | validation: 0.0613595839098392]
	TIME [epoch: 9.23 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06708154063728974		[learning rate: 0.0018315]
	Learning Rate: 0.00183147
	LOSS [training: 0.06708154063728974 | validation: 0.05835290642049885]
	TIME [epoch: 9.25 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058883790962785634		[learning rate: 0.0018259]
	Learning Rate: 0.00182586
	LOSS [training: 0.058883790962785634 | validation: 0.06112810004167002]
	TIME [epoch: 9.24 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04225833483255952		[learning rate: 0.0018203]
	Learning Rate: 0.00182026
	LOSS [training: 0.04225833483255952 | validation: 0.040478225007659456]
	TIME [epoch: 9.24 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03684951875878433		[learning rate: 0.0018147]
	Learning Rate: 0.00181468
	LOSS [training: 0.03684951875878433 | validation: 0.0586879330136217]
	TIME [epoch: 9.23 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04427425654623305		[learning rate: 0.0018091]
	Learning Rate: 0.00180912
	LOSS [training: 0.04427425654623305 | validation: 0.03904291977817309]
	TIME [epoch: 9.23 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029020318720932768		[learning rate: 0.0018036]
	Learning Rate: 0.00180357
	LOSS [training: 0.029020318720932768 | validation: 0.04383404327392568]
	TIME [epoch: 9.25 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03071211372348659		[learning rate: 0.001798]
	Learning Rate: 0.00179804
	LOSS [training: 0.03071211372348659 | validation: 0.042571903700852794]
	TIME [epoch: 9.23 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03457339088571384		[learning rate: 0.0017925]
	Learning Rate: 0.00179253
	LOSS [training: 0.03457339088571384 | validation: 0.0534189150335347]
	TIME [epoch: 9.24 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03745814984953994		[learning rate: 0.001787]
	Learning Rate: 0.00178704
	LOSS [training: 0.03745814984953994 | validation: 0.04601867410087345]
	TIME [epoch: 9.24 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028750180442745098		[learning rate: 0.0017816]
	Learning Rate: 0.00178156
	LOSS [training: 0.028750180442745098 | validation: 0.02968429626190454]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1062.pth
	Model improved!!!
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04176501013838724		[learning rate: 0.0017761]
	Learning Rate: 0.0017761
	LOSS [training: 0.04176501013838724 | validation: 0.044884618893483316]
	TIME [epoch: 9.25 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031755100419190094		[learning rate: 0.0017707]
	Learning Rate: 0.00177065
	LOSS [training: 0.031755100419190094 | validation: 0.04070052975089251]
	TIME [epoch: 9.23 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03462251631356358		[learning rate: 0.0017652]
	Learning Rate: 0.00176522
	LOSS [training: 0.03462251631356358 | validation: 0.08938378720690517]
	TIME [epoch: 9.23 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055639005593638435		[learning rate: 0.0017598]
	Learning Rate: 0.00175981
	LOSS [training: 0.055639005593638435 | validation: 0.02935352917883221]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1066.pth
	Model improved!!!
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028211033411252324		[learning rate: 0.0017544]
	Learning Rate: 0.00175442
	LOSS [training: 0.028211033411252324 | validation: 0.0507980556619783]
	TIME [epoch: 9.24 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0435978116273289		[learning rate: 0.001749]
	Learning Rate: 0.00174904
	LOSS [training: 0.0435978116273289 | validation: 0.03438497073711448]
	TIME [epoch: 9.25 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0473574661113695		[learning rate: 0.0017437]
	Learning Rate: 0.00174368
	LOSS [training: 0.0473574661113695 | validation: 0.06568841860148827]
	TIME [epoch: 9.23 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049335352013368715		[learning rate: 0.0017383]
	Learning Rate: 0.00173833
	LOSS [training: 0.049335352013368715 | validation: 0.07310240205983218]
	TIME [epoch: 9.23 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05850946852909047		[learning rate: 0.001733]
	Learning Rate: 0.00173301
	LOSS [training: 0.05850946852909047 | validation: 0.09365462854231169]
	TIME [epoch: 9.23 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07077127908341611		[learning rate: 0.0017277]
	Learning Rate: 0.00172769
	LOSS [training: 0.07077127908341611 | validation: 0.05799102983076268]
	TIME [epoch: 9.23 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04510955613029723		[learning rate: 0.0017224]
	Learning Rate: 0.0017224
	LOSS [training: 0.04510955613029723 | validation: 0.05800544573088749]
	TIME [epoch: 9.25 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05141242597304052		[learning rate: 0.0017171]
	Learning Rate: 0.00171712
	LOSS [training: 0.05141242597304052 | validation: 0.047753747069774505]
	TIME [epoch: 9.23 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04832264299360316		[learning rate: 0.0017119]
	Learning Rate: 0.00171185
	LOSS [training: 0.04832264299360316 | validation: 0.06236859809267998]
	TIME [epoch: 9.23 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05148112255596067		[learning rate: 0.0017066]
	Learning Rate: 0.00170661
	LOSS [training: 0.05148112255596067 | validation: 0.0700060908414718]
	TIME [epoch: 9.22 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05833729273555103		[learning rate: 0.0017014]
	Learning Rate: 0.00170137
	LOSS [training: 0.05833729273555103 | validation: 0.08675756098006379]
	TIME [epoch: 9.23 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06435538985709408		[learning rate: 0.0016962]
	Learning Rate: 0.00169616
	LOSS [training: 0.06435538985709408 | validation: 0.08203033870040369]
	TIME [epoch: 9.25 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059329165203476565		[learning rate: 0.001691]
	Learning Rate: 0.00169096
	LOSS [training: 0.059329165203476565 | validation: 0.0646411975251589]
	TIME [epoch: 9.23 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048875718237414156		[learning rate: 0.0016858]
	Learning Rate: 0.00168578
	LOSS [training: 0.048875718237414156 | validation: 0.07158015078097626]
	TIME [epoch: 9.23 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06018064798087515		[learning rate: 0.0016806]
	Learning Rate: 0.00168061
	LOSS [training: 0.06018064798087515 | validation: 0.08298941404442786]
	TIME [epoch: 9.23 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06000254372236215		[learning rate: 0.0016755]
	Learning Rate: 0.00167546
	LOSS [training: 0.06000254372236215 | validation: 0.08806464915256812]
	TIME [epoch: 9.24 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06683789009976972		[learning rate: 0.0016703]
	Learning Rate: 0.00167032
	LOSS [training: 0.06683789009976972 | validation: 0.07563890151440153]
	TIME [epoch: 9.24 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06905568843875541		[learning rate: 0.0016652]
	Learning Rate: 0.0016652
	LOSS [training: 0.06905568843875541 | validation: 0.07946624082228645]
	TIME [epoch: 9.22 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05678322437517889		[learning rate: 0.0016601]
	Learning Rate: 0.0016601
	LOSS [training: 0.05678322437517889 | validation: 0.06396576461085958]
	TIME [epoch: 9.22 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06528313750964668		[learning rate: 0.001655]
	Learning Rate: 0.00165501
	LOSS [training: 0.06528313750964668 | validation: 0.08277614480619111]
	TIME [epoch: 9.23 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05532968732340067		[learning rate: 0.0016499]
	Learning Rate: 0.00164993
	LOSS [training: 0.05532968732340067 | validation: 0.05090583683323875]
	TIME [epoch: 9.24 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05201660713551567		[learning rate: 0.0016449]
	Learning Rate: 0.00164488
	LOSS [training: 0.05201660713551567 | validation: 0.07351776476185018]
	TIME [epoch: 9.24 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06406527506630286		[learning rate: 0.0016398]
	Learning Rate: 0.00163983
	LOSS [training: 0.06406527506630286 | validation: 0.09365781577764573]
	TIME [epoch: 9.23 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056253780425548475		[learning rate: 0.0016348]
	Learning Rate: 0.00163481
	LOSS [training: 0.056253780425548475 | validation: 0.0749202104350159]
	TIME [epoch: 9.23 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06469539025107707		[learning rate: 0.0016298]
	Learning Rate: 0.0016298
	LOSS [training: 0.06469539025107707 | validation: 0.08883885389219782]
	TIME [epoch: 9.23 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06165829789979711		[learning rate: 0.0016248]
	Learning Rate: 0.0016248
	LOSS [training: 0.06165829789979711 | validation: 0.06579518481726285]
	TIME [epoch: 9.25 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05644369034796097		[learning rate: 0.0016198]
	Learning Rate: 0.00161982
	LOSS [training: 0.05644369034796097 | validation: 0.0800283210183032]
	TIME [epoch: 9.24 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058987839994972334		[learning rate: 0.0016149]
	Learning Rate: 0.00161485
	LOSS [training: 0.058987839994972334 | validation: 0.07091445943245384]
	TIME [epoch: 9.24 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059334473451966074		[learning rate: 0.0016099]
	Learning Rate: 0.0016099
	LOSS [training: 0.059334473451966074 | validation: 0.07607073411233643]
	TIME [epoch: 9.23 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0659655630709905		[learning rate: 0.001605]
	Learning Rate: 0.00160497
	LOSS [training: 0.0659655630709905 | validation: 0.06460009875538637]
	TIME [epoch: 9.23 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05509401411535668		[learning rate: 0.0016]
	Learning Rate: 0.00160005
	LOSS [training: 0.05509401411535668 | validation: 0.05719897966698624]
	TIME [epoch: 9.25 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05434129973218853		[learning rate: 0.0015951]
	Learning Rate: 0.00159514
	LOSS [training: 0.05434129973218853 | validation: 0.0632453995569881]
	TIME [epoch: 9.23 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04797533029994305		[learning rate: 0.0015903]
	Learning Rate: 0.00159025
	LOSS [training: 0.04797533029994305 | validation: 0.05725205483067594]
	TIME [epoch: 9.23 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05420780215132528		[learning rate: 0.0015854]
	Learning Rate: 0.00158538
	LOSS [training: 0.05420780215132528 | validation: 0.04766069707416326]
	TIME [epoch: 9.22 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04262437349559607		[learning rate: 0.0015805]
	Learning Rate: 0.00158052
	LOSS [training: 0.04262437349559607 | validation: 0.05447255985008402]
	TIME [epoch: 9.23 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04776170841826248		[learning rate: 0.0015757]
	Learning Rate: 0.00157568
	LOSS [training: 0.04776170841826248 | validation: 0.053776851483436236]
	TIME [epoch: 9.24 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042958815114271305		[learning rate: 0.0015708]
	Learning Rate: 0.00157084
	LOSS [training: 0.042958815114271305 | validation: 0.04320609486192501]
	TIME [epoch: 9.23 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03985906851938899		[learning rate: 0.001566]
	Learning Rate: 0.00156603
	LOSS [training: 0.03985906851938899 | validation: 0.04831059821388925]
	TIME [epoch: 9.23 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04043622851591917		[learning rate: 0.0015612]
	Learning Rate: 0.00156123
	LOSS [training: 0.04043622851591917 | validation: 0.05718303010065641]
	TIME [epoch: 9.24 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038343164430262235		[learning rate: 0.0015564]
	Learning Rate: 0.00155644
	LOSS [training: 0.038343164430262235 | validation: 0.05708955938096713]
	TIME [epoch: 9.23 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04033113864592169		[learning rate: 0.0015517]
	Learning Rate: 0.00155167
	LOSS [training: 0.04033113864592169 | validation: 0.03679479435551699]
	TIME [epoch: 9.24 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03380014772369002		[learning rate: 0.0015469]
	Learning Rate: 0.00154692
	LOSS [training: 0.03380014772369002 | validation: 0.03245032537116525]
	TIME [epoch: 9.23 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03918087374536897		[learning rate: 0.0015422]
	Learning Rate: 0.00154217
	LOSS [training: 0.03918087374536897 | validation: 0.0490685394983761]
	TIME [epoch: 9.22 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04110350920004293		[learning rate: 0.0015374]
	Learning Rate: 0.00153745
	LOSS [training: 0.04110350920004293 | validation: 0.04216444338706689]
	TIME [epoch: 9.23 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038699734675584595		[learning rate: 0.0015327]
	Learning Rate: 0.00153273
	LOSS [training: 0.038699734675584595 | validation: 0.041239777145295226]
	TIME [epoch: 9.23 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041828098531164065		[learning rate: 0.001528]
	Learning Rate: 0.00152804
	LOSS [training: 0.041828098531164065 | validation: 0.04750849952863062]
	TIME [epoch: 9.24 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04643054527064796		[learning rate: 0.0015234]
	Learning Rate: 0.00152335
	LOSS [training: 0.04643054527064796 | validation: 0.04321379355511843]
	TIME [epoch: 9.23 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045325715185527936		[learning rate: 0.0015187]
	Learning Rate: 0.00151868
	LOSS [training: 0.045325715185527936 | validation: 0.061987623818556215]
	TIME [epoch: 9.23 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05358777697971212		[learning rate: 0.001514]
	Learning Rate: 0.00151403
	LOSS [training: 0.05358777697971212 | validation: 0.03209461251039026]
	TIME [epoch: 9.23 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034472763143771734		[learning rate: 0.0015094]
	Learning Rate: 0.00150938
	LOSS [training: 0.034472763143771734 | validation: 0.0499219742654891]
	TIME [epoch: 9.22 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039739381645432004		[learning rate: 0.0015048]
	Learning Rate: 0.00150476
	LOSS [training: 0.039739381645432004 | validation: 0.03932930908226399]
	TIME [epoch: 9.25 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03693455334996639		[learning rate: 0.0015001]
	Learning Rate: 0.00150015
	LOSS [training: 0.03693455334996639 | validation: 0.057729534653255615]
	TIME [epoch: 9.23 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03940755373414077		[learning rate: 0.0014955]
	Learning Rate: 0.00149555
	LOSS [training: 0.03940755373414077 | validation: 0.04162723502538875]
	TIME [epoch: 9.23 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03114094348985786		[learning rate: 0.001491]
	Learning Rate: 0.00149096
	LOSS [training: 0.03114094348985786 | validation: 0.03450426077424366]
	TIME [epoch: 9.22 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04274290607033208		[learning rate: 0.0014864]
	Learning Rate: 0.00148639
	LOSS [training: 0.04274290607033208 | validation: 0.08132547960011188]
	TIME [epoch: 9.23 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04619349870431448		[learning rate: 0.0014818]
	Learning Rate: 0.00148184
	LOSS [training: 0.04619349870431448 | validation: 0.06867050819753172]
	TIME [epoch: 9.25 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0723126719400495		[learning rate: 0.0014773]
	Learning Rate: 0.00147729
	LOSS [training: 0.0723126719400495 | validation: 0.07165079472790323]
	TIME [epoch: 9.23 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03746223015703207		[learning rate: 0.0014728]
	Learning Rate: 0.00147276
	LOSS [training: 0.03746223015703207 | validation: 0.04372132812182945]
	TIME [epoch: 9.23 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03642609042693155		[learning rate: 0.0014682]
	Learning Rate: 0.00146825
	LOSS [training: 0.03642609042693155 | validation: 0.047574784081220414]
	TIME [epoch: 9.23 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030377096117986623		[learning rate: 0.0014637]
	Learning Rate: 0.00146375
	LOSS [training: 0.030377096117986623 | validation: 0.036928588528539405]
	TIME [epoch: 9.23 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04386231076214337		[learning rate: 0.0014593]
	Learning Rate: 0.00145926
	LOSS [training: 0.04386231076214337 | validation: 0.04853453884987008]
	TIME [epoch: 9.25 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03215240937907515		[learning rate: 0.0014548]
	Learning Rate: 0.00145479
	LOSS [training: 0.03215240937907515 | validation: 0.04097476967031684]
	TIME [epoch: 9.23 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0372317180796275		[learning rate: 0.0014503]
	Learning Rate: 0.00145033
	LOSS [training: 0.0372317180796275 | validation: 0.04094956927771303]
	TIME [epoch: 9.23 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029376589420004446		[learning rate: 0.0014459]
	Learning Rate: 0.00144588
	LOSS [training: 0.029376589420004446 | validation: 0.037890786569377236]
	TIME [epoch: 9.23 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025644583187706717		[learning rate: 0.0014415]
	Learning Rate: 0.00144145
	LOSS [training: 0.025644583187706717 | validation: 0.02961263318944801]
	TIME [epoch: 9.23 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03207523534879776		[learning rate: 0.001437]
	Learning Rate: 0.00143703
	LOSS [training: 0.03207523534879776 | validation: 0.05420395162742658]
	TIME [epoch: 9.25 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0342257687765755		[learning rate: 0.0014326]
	Learning Rate: 0.00143263
	LOSS [training: 0.0342257687765755 | validation: 0.04658486245380715]
	TIME [epoch: 9.23 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03585621730146567		[learning rate: 0.0014282]
	Learning Rate: 0.00142824
	LOSS [training: 0.03585621730146567 | validation: 0.05986517456568578]
	TIME [epoch: 9.23 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054293816055615104		[learning rate: 0.0014239]
	Learning Rate: 0.00142386
	LOSS [training: 0.054293816055615104 | validation: 0.041553213178831205]
	TIME [epoch: 9.23 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03857159136381461		[learning rate: 0.0014195]
	Learning Rate: 0.00141949
	LOSS [training: 0.03857159136381461 | validation: 0.036780396266060264]
	TIME [epoch: 9.23 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032328264697323306		[learning rate: 0.0014151]
	Learning Rate: 0.00141514
	LOSS [training: 0.032328264697323306 | validation: 0.052948688406938275]
	TIME [epoch: 13.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041058920033673216		[learning rate: 0.0014108]
	Learning Rate: 0.0014108
	LOSS [training: 0.041058920033673216 | validation: 0.05289130393283126]
	TIME [epoch: 9.23 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03646458714240279		[learning rate: 0.0014065]
	Learning Rate: 0.00140648
	LOSS [training: 0.03646458714240279 | validation: 0.028284393136721195]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1139.pth
	Model improved!!!
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02840030096609213		[learning rate: 0.0014022]
	Learning Rate: 0.00140217
	LOSS [training: 0.02840030096609213 | validation: 0.05243497021541977]
	TIME [epoch: 9.24 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03589299602248983		[learning rate: 0.0013979]
	Learning Rate: 0.00139787
	LOSS [training: 0.03589299602248983 | validation: 0.0369875862380943]
	TIME [epoch: 9.24 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027997062415925637		[learning rate: 0.0013936]
	Learning Rate: 0.00139358
	LOSS [training: 0.027997062415925637 | validation: 0.04302584848536523]
	TIME [epoch: 9.25 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02548440145200918		[learning rate: 0.0013893]
	Learning Rate: 0.00138931
	LOSS [training: 0.02548440145200918 | validation: 0.029566438238318032]
	TIME [epoch: 9.24 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03124234843184486		[learning rate: 0.0013851]
	Learning Rate: 0.00138505
	LOSS [training: 0.03124234843184486 | validation: 0.030524972697860447]
	TIME [epoch: 9.24 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03477983284030919		[learning rate: 0.0013808]
	Learning Rate: 0.00138081
	LOSS [training: 0.03477983284030919 | validation: 0.03506621411036823]
	TIME [epoch: 9.23 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027620111581323055		[learning rate: 0.0013766]
	Learning Rate: 0.00137658
	LOSS [training: 0.027620111581323055 | validation: 0.0260969677671842]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1146.pth
	Model improved!!!
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017883479439298786		[learning rate: 0.0013724]
	Learning Rate: 0.00137236
	LOSS [training: 0.017883479439298786 | validation: 0.03572997070352051]
	TIME [epoch: 9.23 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021266235940352863		[learning rate: 0.0013681]
	Learning Rate: 0.00136815
	LOSS [training: 0.021266235940352863 | validation: 0.02740176971445018]
	TIME [epoch: 9.23 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020928528353246344		[learning rate: 0.001364]
	Learning Rate: 0.00136395
	LOSS [training: 0.020928528353246344 | validation: 0.03915482599241487]
	TIME [epoch: 9.23 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03931153942876202		[learning rate: 0.0013598]
	Learning Rate: 0.00135977
	LOSS [training: 0.03931153942876202 | validation: 0.06328621109939755]
	TIME [epoch: 9.23 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037643493544919096		[learning rate: 0.0013556]
	Learning Rate: 0.00135561
	LOSS [training: 0.037643493544919096 | validation: 0.0686542056798934]
	TIME [epoch: 9.25 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030971131008912033		[learning rate: 0.0013515]
	Learning Rate: 0.00135145
	LOSS [training: 0.030971131008912033 | validation: 0.025814505939066534]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1152.pth
	Model improved!!!
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03651574443133361		[learning rate: 0.0013473]
	Learning Rate: 0.00134731
	LOSS [training: 0.03651574443133361 | validation: 0.03508928396695479]
	TIME [epoch: 9.23 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034884462540241266		[learning rate: 0.0013432]
	Learning Rate: 0.00134318
	LOSS [training: 0.034884462540241266 | validation: 0.05155816677931861]
	TIME [epoch: 9.24 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05773684731155563		[learning rate: 0.0013391]
	Learning Rate: 0.00133906
	LOSS [training: 0.05773684731155563 | validation: 0.04983958466882597]
	TIME [epoch: 9.23 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028552528766647205		[learning rate: 0.001335]
	Learning Rate: 0.00133496
	LOSS [training: 0.028552528766647205 | validation: 0.04791457496917639]
	TIME [epoch: 10.9 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03867927924616659		[learning rate: 0.0013309]
	Learning Rate: 0.00133086
	LOSS [training: 0.03867927924616659 | validation: 0.048529975100765954]
	TIME [epoch: 9.22 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04819746362120503		[learning rate: 0.0013268]
	Learning Rate: 0.00132678
	LOSS [training: 0.04819746362120503 | validation: 0.10231834425866948]
	TIME [epoch: 9.23 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08340529312842371		[learning rate: 0.0013227]
	Learning Rate: 0.00132272
	LOSS [training: 0.08340529312842371 | validation: 0.10032048447344508]
	TIME [epoch: 12.6 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0754724528190444		[learning rate: 0.0013187]
	Learning Rate: 0.00131866
	LOSS [training: 0.0754724528190444 | validation: 0.12605529614157202]
	TIME [epoch: 9.23 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061044932993873834		[learning rate: 0.0013146]
	Learning Rate: 0.00131462
	LOSS [training: 0.061044932993873834 | validation: 0.04215688661599244]
	TIME [epoch: 9.25 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033365135150779074		[learning rate: 0.0013106]
	Learning Rate: 0.00131059
	LOSS [training: 0.033365135150779074 | validation: 0.030050379137171724]
	TIME [epoch: 9.23 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026533173545819615		[learning rate: 0.0013066]
	Learning Rate: 0.00130657
	LOSS [training: 0.026533173545819615 | validation: 0.035774285967785674]
	TIME [epoch: 9.23 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047648398011613746		[learning rate: 0.0013026]
	Learning Rate: 0.00130257
	LOSS [training: 0.047648398011613746 | validation: 0.10156193293001348]
	TIME [epoch: 9.23 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059456664567621255		[learning rate: 0.0012986]
	Learning Rate: 0.00129857
	LOSS [training: 0.059456664567621255 | validation: 0.034062524870062644]
	TIME [epoch: 10.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03245303003805068		[learning rate: 0.0012946]
	Learning Rate: 0.00129459
	LOSS [training: 0.03245303003805068 | validation: 0.030313608360210475]
	TIME [epoch: 9.25 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0422288042803922		[learning rate: 0.0012906]
	Learning Rate: 0.00129062
	LOSS [training: 0.0422288042803922 | validation: 0.03460518927246414]
	TIME [epoch: 9.24 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032994630185937866		[learning rate: 0.0012867]
	Learning Rate: 0.00128667
	LOSS [training: 0.032994630185937866 | validation: 0.053683121578503176]
	TIME [epoch: 9.22 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03454688676898357		[learning rate: 0.0012827]
	Learning Rate: 0.00128272
	LOSS [training: 0.03454688676898357 | validation: 0.039076411142351636]
	TIME [epoch: 9.22 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03965639519460999		[learning rate: 0.0012788]
	Learning Rate: 0.00127879
	LOSS [training: 0.03965639519460999 | validation: 0.06087824979896929]
	TIME [epoch: 9.23 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044461861602613215		[learning rate: 0.0012749]
	Learning Rate: 0.00127487
	LOSS [training: 0.044461861602613215 | validation: 0.019981863998609906]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1171.pth
	Model improved!!!
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020378721863030684		[learning rate: 0.001271]
	Learning Rate: 0.00127096
	LOSS [training: 0.020378721863030684 | validation: 0.026981662919393683]
	TIME [epoch: 9.36 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020126673709131328		[learning rate: 0.0012671]
	Learning Rate: 0.00126707
	LOSS [training: 0.020126673709131328 | validation: 0.05653011045437792]
	TIME [epoch: 9.25 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0457930322949298		[learning rate: 0.0012632]
	Learning Rate: 0.00126318
	LOSS [training: 0.0457930322949298 | validation: 0.04390457666738135]
	TIME [epoch: 9.24 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02814046046001297		[learning rate: 0.0012593]
	Learning Rate: 0.00125931
	LOSS [training: 0.02814046046001297 | validation: 0.02577911208191163]
	TIME [epoch: 9.23 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01680724908624927		[learning rate: 0.0012555]
	Learning Rate: 0.00125545
	LOSS [training: 0.01680724908624927 | validation: 0.02916760070701975]
	TIME [epoch: 9.26 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024922050985566366		[learning rate: 0.0012516]
	Learning Rate: 0.0012516
	LOSS [training: 0.024922050985566366 | validation: 0.03788268210917275]
	TIME [epoch: 9.24 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03182911259544771		[learning rate: 0.0012478]
	Learning Rate: 0.00124777
	LOSS [training: 0.03182911259544771 | validation: 0.043619577506739046]
	TIME [epoch: 9.24 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025971634747268886		[learning rate: 0.0012439]
	Learning Rate: 0.00124394
	LOSS [training: 0.025971634747268886 | validation: 0.02170401637830269]
	TIME [epoch: 9.24 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018627621305344955		[learning rate: 0.0012401]
	Learning Rate: 0.00124013
	LOSS [training: 0.018627621305344955 | validation: 0.027077104095601955]
	TIME [epoch: 9.23 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02655854605237039		[learning rate: 0.0012363]
	Learning Rate: 0.00123633
	LOSS [training: 0.02655854605237039 | validation: 0.03935939176572343]
	TIME [epoch: 9.26 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026783422284925418		[learning rate: 0.0012325]
	Learning Rate: 0.00123254
	LOSS [training: 0.026783422284925418 | validation: 0.025245522447892382]
	TIME [epoch: 9.23 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02376956213495429		[learning rate: 0.0012288]
	Learning Rate: 0.00122876
	LOSS [training: 0.02376956213495429 | validation: 0.051401009544089396]
	TIME [epoch: 9.24 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046003767468009306		[learning rate: 0.001225]
	Learning Rate: 0.00122499
	LOSS [training: 0.046003767468009306 | validation: 0.0327756859127538]
	TIME [epoch: 9.23 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024178328095180706		[learning rate: 0.0012212]
	Learning Rate: 0.00122124
	LOSS [training: 0.024178328095180706 | validation: 0.030177252294858636]
	TIME [epoch: 9.25 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018493555832092112		[learning rate: 0.0012175]
	Learning Rate: 0.00121749
	LOSS [training: 0.018493555832092112 | validation: 0.020635473502621987]
	TIME [epoch: 9.25 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018187394698840627		[learning rate: 0.0012138]
	Learning Rate: 0.00121376
	LOSS [training: 0.018187394698840627 | validation: 0.016837779059310096]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1187.pth
	Model improved!!!
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019542811092314556		[learning rate: 0.00121]
	Learning Rate: 0.00121004
	LOSS [training: 0.019542811092314556 | validation: 0.02796100106489518]
	TIME [epoch: 9.23 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015021977327303596		[learning rate: 0.0012063]
	Learning Rate: 0.00120633
	LOSS [training: 0.015021977327303596 | validation: 0.033860059736631656]
	TIME [epoch: 9.22 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02226146206195812		[learning rate: 0.0012026]
	Learning Rate: 0.00120263
	LOSS [training: 0.02226146206195812 | validation: 0.05671571825993064]
	TIME [epoch: 9.24 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02868675132512975		[learning rate: 0.0011989]
	Learning Rate: 0.00119895
	LOSS [training: 0.02868675132512975 | validation: 0.024043689843442406]
	TIME [epoch: 9.23 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012018055097247234		[learning rate: 0.0011953]
	Learning Rate: 0.00119527
	LOSS [training: 0.012018055097247234 | validation: 0.0148505462111291]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1192.pth
	Model improved!!!
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013298330145571047		[learning rate: 0.0011916]
	Learning Rate: 0.00119161
	LOSS [training: 0.013298330145571047 | validation: 0.02976852748799271]
	TIME [epoch: 9.23 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02038350816481841		[learning rate: 0.001188]
	Learning Rate: 0.00118795
	LOSS [training: 0.02038350816481841 | validation: 0.05316538454103176]
	TIME [epoch: 9.23 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028742174258432875		[learning rate: 0.0011843]
	Learning Rate: 0.00118431
	LOSS [training: 0.028742174258432875 | validation: 0.04409271127739434]
	TIME [epoch: 9.24 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03329666783295289		[learning rate: 0.0011807]
	Learning Rate: 0.00118068
	LOSS [training: 0.03329666783295289 | validation: 0.05375165282598897]
	TIME [epoch: 9.23 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04075641027252453		[learning rate: 0.0011771]
	Learning Rate: 0.00117706
	LOSS [training: 0.04075641027252453 | validation: 0.0431267163585205]
	TIME [epoch: 9.23 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023267542885861543		[learning rate: 0.0011735]
	Learning Rate: 0.00117346
	LOSS [training: 0.023267542885861543 | validation: 0.032895969969318026]
	TIME [epoch: 9.23 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02193616243141035		[learning rate: 0.0011699]
	Learning Rate: 0.00116986
	LOSS [training: 0.02193616243141035 | validation: 0.0428497434781829]
	TIME [epoch: 9.23 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03620670754806592		[learning rate: 0.0011663]
	Learning Rate: 0.00116627
	LOSS [training: 0.03620670754806592 | validation: 0.049983509440207484]
	TIME [epoch: 9.24 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02569245639121525		[learning rate: 0.0011627]
	Learning Rate: 0.0011627
	LOSS [training: 0.02569245639121525 | validation: 0.03292387782074746]
	TIME [epoch: 9.22 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026941059322209866		[learning rate: 0.0011591]
	Learning Rate: 0.00115913
	LOSS [training: 0.026941059322209866 | validation: 0.060894322505255186]
	TIME [epoch: 9.22 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03603985050981691		[learning rate: 0.0011556]
	Learning Rate: 0.00115558
	LOSS [training: 0.03603985050981691 | validation: 0.05187874607406232]
	TIME [epoch: 9.22 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04789727574329771		[learning rate: 0.001152]
	Learning Rate: 0.00115204
	LOSS [training: 0.04789727574329771 | validation: 0.09318416631210824]
	TIME [epoch: 9.22 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05968498513709064		[learning rate: 0.0011485]
	Learning Rate: 0.00114851
	LOSS [training: 0.05968498513709064 | validation: 0.055319352466904906]
	TIME [epoch: 9.25 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04775584939928152		[learning rate: 0.001145]
	Learning Rate: 0.00114499
	LOSS [training: 0.04775584939928152 | validation: 0.0853245615242777]
	TIME [epoch: 9.23 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06852590310565355		[learning rate: 0.0011415]
	Learning Rate: 0.00114148
	LOSS [training: 0.06852590310565355 | validation: 0.058524449632333]
	TIME [epoch: 9.23 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036788349369124416		[learning rate: 0.001138]
	Learning Rate: 0.00113798
	LOSS [training: 0.036788349369124416 | validation: 0.046154800356484366]
	TIME [epoch: 9.23 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03317468786607784		[learning rate: 0.0011345]
	Learning Rate: 0.00113449
	LOSS [training: 0.03317468786607784 | validation: 0.051722789468213015]
	TIME [epoch: 9.23 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04466120370106018		[learning rate: 0.001131]
	Learning Rate: 0.00113101
	LOSS [training: 0.04466120370106018 | validation: 0.04679999621820548]
	TIME [epoch: 9.25 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03194270321676318		[learning rate: 0.0011275]
	Learning Rate: 0.00112754
	LOSS [training: 0.03194270321676318 | validation: 0.0334591869513505]
	TIME [epoch: 9.23 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027617972007427032		[learning rate: 0.0011241]
	Learning Rate: 0.00112409
	LOSS [training: 0.027617972007427032 | validation: 0.041873181413325744]
	TIME [epoch: 9.23 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02495418352277141		[learning rate: 0.0011206]
	Learning Rate: 0.00112064
	LOSS [training: 0.02495418352277141 | validation: 0.03177845694858054]
	TIME [epoch: 9.23 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030432429957275353		[learning rate: 0.0011172]
	Learning Rate: 0.00111721
	LOSS [training: 0.030432429957275353 | validation: 0.04572176828288626]
	TIME [epoch: 9.23 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017295145667701645		[learning rate: 0.0011138]
	Learning Rate: 0.00111378
	LOSS [training: 0.017295145667701645 | validation: 0.029488275177478665]
	TIME [epoch: 9.25 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016091497229453595		[learning rate: 0.0011104]
	Learning Rate: 0.00111037
	LOSS [training: 0.016091497229453595 | validation: 0.026496905336368046]
	TIME [epoch: 9.23 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022140525675959588		[learning rate: 0.001107]
	Learning Rate: 0.00110696
	LOSS [training: 0.022140525675959588 | validation: 0.029253077027805108]
	TIME [epoch: 9.23 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022060336714080704		[learning rate: 0.0011036]
	Learning Rate: 0.00110357
	LOSS [training: 0.022060336714080704 | validation: 0.012511550131031949]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1218.pth
	Model improved!!!
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017088220989722215		[learning rate: 0.0011002]
	Learning Rate: 0.00110019
	LOSS [training: 0.017088220989722215 | validation: 0.034346389651641586]
	TIME [epoch: 9.22 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024960919814345287		[learning rate: 0.0010968]
	Learning Rate: 0.00109681
	LOSS [training: 0.024960919814345287 | validation: 0.04522333807920672]
	TIME [epoch: 9.25 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026081392849994826		[learning rate: 0.0010935]
	Learning Rate: 0.00109345
	LOSS [training: 0.026081392849994826 | validation: 0.02578724901049395]
	TIME [epoch: 9.22 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020127537058541513		[learning rate: 0.0010901]
	Learning Rate: 0.0010901
	LOSS [training: 0.020127537058541513 | validation: 0.03838412569890405]
	TIME [epoch: 9.23 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026720143421662484		[learning rate: 0.0010868]
	Learning Rate: 0.00108676
	LOSS [training: 0.026720143421662484 | validation: 0.02057303139576912]
	TIME [epoch: 9.23 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02286762395686113		[learning rate: 0.0010834]
	Learning Rate: 0.00108343
	LOSS [training: 0.02286762395686113 | validation: 0.03161389902276246]
	TIME [epoch: 9.23 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030018023132290027		[learning rate: 0.0010801]
	Learning Rate: 0.00108011
	LOSS [training: 0.030018023132290027 | validation: 0.029375407386355204]
	TIME [epoch: 9.24 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02508631110339172		[learning rate: 0.0010768]
	Learning Rate: 0.0010768
	LOSS [training: 0.02508631110339172 | validation: 0.028192817532884627]
	TIME [epoch: 9.23 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027004964871192187		[learning rate: 0.0010735]
	Learning Rate: 0.00107349
	LOSS [training: 0.027004964871192187 | validation: 0.038461201146129456]
	TIME [epoch: 9.22 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029182585240660964		[learning rate: 0.0010702]
	Learning Rate: 0.0010702
	LOSS [training: 0.029182585240660964 | validation: 0.03692970292988551]
	TIME [epoch: 9.23 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024342550378130875		[learning rate: 0.0010669]
	Learning Rate: 0.00106692
	LOSS [training: 0.024342550378130875 | validation: 0.02155101193376168]
	TIME [epoch: 9.22 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02453599808017961		[learning rate: 0.0010637]
	Learning Rate: 0.00106365
	LOSS [training: 0.02453599808017961 | validation: 0.021936750533910386]
	TIME [epoch: 9.25 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023256223104628698		[learning rate: 0.0010604]
	Learning Rate: 0.00106039
	LOSS [training: 0.023256223104628698 | validation: 0.04142207550743583]
	TIME [epoch: 9.23 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03601963757417555		[learning rate: 0.0010571]
	Learning Rate: 0.00105714
	LOSS [training: 0.03601963757417555 | validation: 0.04613210976345785]
	TIME [epoch: 9.23 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03691187432172642		[learning rate: 0.0010539]
	Learning Rate: 0.0010539
	LOSS [training: 0.03691187432172642 | validation: 0.039520183387844895]
	TIME [epoch: 9.23 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034467586616107694		[learning rate: 0.0010507]
	Learning Rate: 0.00105067
	LOSS [training: 0.034467586616107694 | validation: 0.05055343002866415]
	TIME [epoch: 9.23 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03717218366667947		[learning rate: 0.0010475]
	Learning Rate: 0.00104745
	LOSS [training: 0.03717218366667947 | validation: 0.05476197598433015]
	TIME [epoch: 9.25 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050583170661628915		[learning rate: 0.0010442]
	Learning Rate: 0.00104424
	LOSS [training: 0.050583170661628915 | validation: 0.04906958186428058]
	TIME [epoch: 9.22 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03773942644842255		[learning rate: 0.001041]
	Learning Rate: 0.00104104
	LOSS [training: 0.03773942644842255 | validation: 0.03673506971040955]
	TIME [epoch: 9.23 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04602233505797308		[learning rate: 0.0010378]
	Learning Rate: 0.00103785
	LOSS [training: 0.04602233505797308 | validation: 0.07679470066344293]
	TIME [epoch: 9.23 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.097738940724294		[learning rate: 0.0010347]
	Learning Rate: 0.00103467
	LOSS [training: 0.097738940724294 | validation: 0.09148442402530546]
	TIME [epoch: 9.23 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06379823990665619		[learning rate: 0.0010315]
	Learning Rate: 0.00103149
	LOSS [training: 0.06379823990665619 | validation: 0.04377956850233561]
	TIME [epoch: 9.24 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042852557563352635		[learning rate: 0.0010283]
	Learning Rate: 0.00102833
	LOSS [training: 0.042852557563352635 | validation: 0.04884050513856701]
	TIME [epoch: 9.22 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054683343984453146		[learning rate: 0.0010252]
	Learning Rate: 0.00102518
	LOSS [training: 0.054683343984453146 | validation: 0.04809312998010719]
	TIME [epoch: 9.23 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051733957313329026		[learning rate: 0.001022]
	Learning Rate: 0.00102204
	LOSS [training: 0.051733957313329026 | validation: 0.06712530185159554]
	TIME [epoch: 9.22 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05233735895641992		[learning rate: 0.0010189]
	Learning Rate: 0.0010189
	LOSS [training: 0.05233735895641992 | validation: 0.06440591515814147]
	TIME [epoch: 9.24 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06061835027155595		[learning rate: 0.0010158]
	Learning Rate: 0.00101578
	LOSS [training: 0.06061835027155595 | validation: 0.04339081427822128]
	TIME [epoch: 9.23 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04343607186193629		[learning rate: 0.0010127]
	Learning Rate: 0.00101267
	LOSS [training: 0.04343607186193629 | validation: 0.05097627074597945]
	TIME [epoch: 9.23 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06735229168382048		[learning rate: 0.0010096]
	Learning Rate: 0.00100956
	LOSS [training: 0.06735229168382048 | validation: 0.08118630950414787]
	TIME [epoch: 9.23 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08291345407000325		[learning rate: 0.0010065]
	Learning Rate: 0.00100647
	LOSS [training: 0.08291345407000325 | validation: 0.08107487129283199]
	TIME [epoch: 9.22 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07595314272963813		[learning rate: 0.0010034]
	Learning Rate: 0.00100338
	LOSS [training: 0.07595314272963813 | validation: 0.07345712298019494]
	TIME [epoch: 9.25 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06440442725689574		[learning rate: 0.0010003]
	Learning Rate: 0.00100031
	LOSS [training: 0.06440442725689574 | validation: 0.04697740904379776]
	TIME [epoch: 9.23 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04664201511925546		[learning rate: 0.00099724]
	Learning Rate: 0.000997241
	LOSS [training: 0.04664201511925546 | validation: 0.04384554317470239]
	TIME [epoch: 9.23 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04042508282961726		[learning rate: 0.00099418]
	Learning Rate: 0.000994184
	LOSS [training: 0.04042508282961726 | validation: 0.04970445370726355]
	TIME [epoch: 9.22 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05927524012696724		[learning rate: 0.00099114]
	Learning Rate: 0.000991136
	LOSS [training: 0.05927524012696724 | validation: 0.049721620943361564]
	TIME [epoch: 9.23 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038326498006106505		[learning rate: 0.0009881]
	Learning Rate: 0.000988098
	LOSS [training: 0.038326498006106505 | validation: 0.05155716486052885]
	TIME [epoch: 9.24 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02978961786563795		[learning rate: 0.00098507]
	Learning Rate: 0.000985069
	LOSS [training: 0.02978961786563795 | validation: 0.03352626434428065]
	TIME [epoch: 9.23 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027475378865889542		[learning rate: 0.00098205]
	Learning Rate: 0.00098205
	LOSS [training: 0.027475378865889542 | validation: 0.036347905989951676]
	TIME [epoch: 9.23 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027263373823840135		[learning rate: 0.00097904]
	Learning Rate: 0.000979039
	LOSS [training: 0.027263373823840135 | validation: 0.03768647106147872]
	TIME [epoch: 9.23 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028346638770583233		[learning rate: 0.00097604]
	Learning Rate: 0.000976038
	LOSS [training: 0.028346638770583233 | validation: 0.04190474645394039]
	TIME [epoch: 9.23 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023861562003031765		[learning rate: 0.00097305]
	Learning Rate: 0.000973046
	LOSS [training: 0.023861562003031765 | validation: 0.02961111774931123]
	TIME [epoch: 9.26 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03159476312695946		[learning rate: 0.00097006]
	Learning Rate: 0.000970063
	LOSS [training: 0.03159476312695946 | validation: 0.03874299741391489]
	TIME [epoch: 9.23 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038976551214869856		[learning rate: 0.00096709]
	Learning Rate: 0.000967089
	LOSS [training: 0.038976551214869856 | validation: 0.07716870346927257]
	TIME [epoch: 9.24 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04040163283684912		[learning rate: 0.00096412]
	Learning Rate: 0.000964125
	LOSS [training: 0.04040163283684912 | validation: 0.03977221227286171]
	TIME [epoch: 9.23 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032786198936876995		[learning rate: 0.00096117]
	Learning Rate: 0.00096117
	LOSS [training: 0.032786198936876995 | validation: 0.04881047483276392]
	TIME [epoch: 9.24 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024126722608473705		[learning rate: 0.00095822]
	Learning Rate: 0.000958223
	LOSS [training: 0.024126722608473705 | validation: 0.02760983684349086]
	TIME [epoch: 9.25 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02480590808604905		[learning rate: 0.00095529]
	Learning Rate: 0.000955286
	LOSS [training: 0.02480590808604905 | validation: 0.03778839109969853]
	TIME [epoch: 9.23 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03615439009119442		[learning rate: 0.00095236]
	Learning Rate: 0.000952357
	LOSS [training: 0.03615439009119442 | validation: 0.03463997833401214]
	TIME [epoch: 9.23 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0239881579685187		[learning rate: 0.00094944]
	Learning Rate: 0.000949438
	LOSS [training: 0.0239881579685187 | validation: 0.03117633399779321]
	TIME [epoch: 9.23 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027802020904702417		[learning rate: 0.00094653]
	Learning Rate: 0.000946528
	LOSS [training: 0.027802020904702417 | validation: 0.03647217092759794]
	TIME [epoch: 9.23 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021791530807704983		[learning rate: 0.00094363]
	Learning Rate: 0.000943626
	LOSS [training: 0.021791530807704983 | validation: 0.023378931825453714]
	TIME [epoch: 9.25 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023154045478304606		[learning rate: 0.00094073]
	Learning Rate: 0.000940734
	LOSS [training: 0.023154045478304606 | validation: 0.035732342307351644]
	TIME [epoch: 9.24 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029204791221235416		[learning rate: 0.00093785]
	Learning Rate: 0.00093785
	LOSS [training: 0.029204791221235416 | validation: 0.019178524705152696]
	TIME [epoch: 9.23 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01773536537726846		[learning rate: 0.00093497]
	Learning Rate: 0.000934975
	LOSS [training: 0.01773536537726846 | validation: 0.02642194056983995]
	TIME [epoch: 9.24 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017698608352175713		[learning rate: 0.00093211]
	Learning Rate: 0.000932109
	LOSS [training: 0.017698608352175713 | validation: 0.022352071862340894]
	TIME [epoch: 9.23 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01609126323418667		[learning rate: 0.00092925]
	Learning Rate: 0.000929252
	LOSS [training: 0.01609126323418667 | validation: 0.021196805147148872]
	TIME [epoch: 9.25 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017034928095410563		[learning rate: 0.0009264]
	Learning Rate: 0.000926403
	LOSS [training: 0.017034928095410563 | validation: 0.024423937262572137]
	TIME [epoch: 9.24 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02073214940032806		[learning rate: 0.00092356]
	Learning Rate: 0.000923563
	LOSS [training: 0.02073214940032806 | validation: 0.040822885347906866]
	TIME [epoch: 9.22 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01996050667793335		[learning rate: 0.00092073]
	Learning Rate: 0.000920732
	LOSS [training: 0.01996050667793335 | validation: 0.020894753392424657]
	TIME [epoch: 9.24 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011853017432410358		[learning rate: 0.00091791]
	Learning Rate: 0.00091791
	LOSS [training: 0.011853017432410358 | validation: 0.018835508174117544]
	TIME [epoch: 9.23 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013765642001284445		[learning rate: 0.0009151]
	Learning Rate: 0.000915096
	LOSS [training: 0.013765642001284445 | validation: 0.02681824537417115]
	TIME [epoch: 9.25 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02010939053569761		[learning rate: 0.00091229]
	Learning Rate: 0.000912291
	LOSS [training: 0.02010939053569761 | validation: 0.02170342883145853]
	TIME [epoch: 9.24 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016240522485104547		[learning rate: 0.00090949]
	Learning Rate: 0.000909494
	LOSS [training: 0.016240522485104547 | validation: 0.023212768005449174]
	TIME [epoch: 9.24 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015219765508912079		[learning rate: 0.00090671]
	Learning Rate: 0.000906706
	LOSS [training: 0.015219765508912079 | validation: 0.020661146243948554]
	TIME [epoch: 9.24 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013378988811391098		[learning rate: 0.00090393]
	Learning Rate: 0.000903927
	LOSS [training: 0.013378988811391098 | validation: 0.017385486371311765]
	TIME [epoch: 9.24 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020300662948902322		[learning rate: 0.00090116]
	Learning Rate: 0.000901156
	LOSS [training: 0.020300662948902322 | validation: 0.028581791072208703]
	TIME [epoch: 9.26 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01736057065452021		[learning rate: 0.00089839]
	Learning Rate: 0.000898394
	LOSS [training: 0.01736057065452021 | validation: 0.017941606371253443]
	TIME [epoch: 9.23 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015001450512716003		[learning rate: 0.00089564]
	Learning Rate: 0.00089564
	LOSS [training: 0.015001450512716003 | validation: 0.03419083633264117]
	TIME [epoch: 9.23 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02851322999200115		[learning rate: 0.00089289]
	Learning Rate: 0.000892894
	LOSS [training: 0.02851322999200115 | validation: 0.052307879833697064]
	TIME [epoch: 9.23 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05218406796985301		[learning rate: 0.00089016]
	Learning Rate: 0.000890157
	LOSS [training: 0.05218406796985301 | validation: 0.07564850224922917]
	TIME [epoch: 9.23 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08670268266670257		[learning rate: 0.00088743]
	Learning Rate: 0.000887428
	LOSS [training: 0.08670268266670257 | validation: 0.13118468810305328]
	TIME [epoch: 9.26 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18040799838583638		[learning rate: 0.00088471]
	Learning Rate: 0.000884708
	LOSS [training: 0.18040799838583638 | validation: 0.25138501954474335]
	TIME [epoch: 9.23 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19845296306457794		[learning rate: 0.000882]
	Learning Rate: 0.000881996
	LOSS [training: 0.19845296306457794 | validation: 0.21370723909939726]
	TIME [epoch: 9.23 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1855147494628036		[learning rate: 0.00087929]
	Learning Rate: 0.000879292
	LOSS [training: 0.1855147494628036 | validation: 0.14835294952502448]
	TIME [epoch: 9.23 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13289609342675002		[learning rate: 0.0008766]
	Learning Rate: 0.000876597
	LOSS [training: 0.13289609342675002 | validation: 0.12870718971025097]
	TIME [epoch: 9.25 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1120019008120895		[learning rate: 0.00087391]
	Learning Rate: 0.00087391
	LOSS [training: 0.1120019008120895 | validation: 0.10836376319861898]
	TIME [epoch: 9.26 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11013170349677084		[learning rate: 0.00087123]
	Learning Rate: 0.000871231
	LOSS [training: 0.11013170349677084 | validation: 0.15387428582768609]
	TIME [epoch: 9.24 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17740965947300893		[learning rate: 0.00086856]
	Learning Rate: 0.00086856
	LOSS [training: 0.17740965947300893 | validation: 0.1937438394386159]
	TIME [epoch: 9.23 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11865038376433387		[learning rate: 0.0008659]
	Learning Rate: 0.000865898
	LOSS [training: 0.11865038376433387 | validation: 0.1160409211415517]
	TIME [epoch: 9.24 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11358783392910357		[learning rate: 0.00086324]
	Learning Rate: 0.000863243
	LOSS [training: 0.11358783392910357 | validation: 0.11566970071691832]
	TIME [epoch: 9.25 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08741899992690852		[learning rate: 0.0008606]
	Learning Rate: 0.000860597
	LOSS [training: 0.08741899992690852 | validation: 0.08449518678464332]
	TIME [epoch: 9.24 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057183912054599606		[learning rate: 0.00085796]
	Learning Rate: 0.000857959
	LOSS [training: 0.057183912054599606 | validation: 0.052301852888750944]
	TIME [epoch: 9.23 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04226600633000538		[learning rate: 0.00085533]
	Learning Rate: 0.000855329
	LOSS [training: 0.04226600633000538 | validation: 0.0416577620069926]
	TIME [epoch: 9.23 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03538874343622392		[learning rate: 0.00085271]
	Learning Rate: 0.000852707
	LOSS [training: 0.03538874343622392 | validation: 0.04596866140388131]
	TIME [epoch: 9.24 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04502492047199389		[learning rate: 0.00085009]
	Learning Rate: 0.000850093
	LOSS [training: 0.04502492047199389 | validation: 0.03814459149609253]
	TIME [epoch: 9.24 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040100150964033035		[learning rate: 0.00084749]
	Learning Rate: 0.000847488
	LOSS [training: 0.040100150964033035 | validation: 0.043295939608112774]
	TIME [epoch: 9.23 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03691530021856635		[learning rate: 0.00084489]
	Learning Rate: 0.00084489
	LOSS [training: 0.03691530021856635 | validation: 0.03399996037443244]
	TIME [epoch: 9.23 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029563066207980042		[learning rate: 0.0008423]
	Learning Rate: 0.0008423
	LOSS [training: 0.029563066207980042 | validation: 0.034113875557864326]
	TIME [epoch: 9.23 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022887781669776584		[learning rate: 0.00083972]
	Learning Rate: 0.000839718
	LOSS [training: 0.022887781669776584 | validation: 0.023351277318709476]
	TIME [epoch: 9.23 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01565528562354434		[learning rate: 0.00083714]
	Learning Rate: 0.000837144
	LOSS [training: 0.01565528562354434 | validation: 0.022131299099097203]
	TIME [epoch: 9.25 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029353539483950686		[learning rate: 0.00083458]
	Learning Rate: 0.000834578
	LOSS [training: 0.029353539483950686 | validation: 0.01812900292209818]
	TIME [epoch: 9.23 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02074388804072252		[learning rate: 0.00083202]
	Learning Rate: 0.000832019
	LOSS [training: 0.02074388804072252 | validation: 0.020094414675998023]
	TIME [epoch: 9.22 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028385671290170784		[learning rate: 0.00082947]
	Learning Rate: 0.000829469
	LOSS [training: 0.028385671290170784 | validation: 0.032041620782008944]
	TIME [epoch: 9.23 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015399481154083305		[learning rate: 0.00082693]
	Learning Rate: 0.000826926
	LOSS [training: 0.015399481154083305 | validation: 0.0211288647297]
	TIME [epoch: 9.23 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019299299893995384		[learning rate: 0.00082439]
	Learning Rate: 0.000824391
	LOSS [training: 0.019299299893995384 | validation: 0.01646076654308162]
	TIME [epoch: 9.24 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015577578513985457		[learning rate: 0.00082186]
	Learning Rate: 0.000821864
	LOSS [training: 0.015577578513985457 | validation: 0.029732706953196485]
	TIME [epoch: 9.23 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017689663045934896		[learning rate: 0.00081934]
	Learning Rate: 0.000819345
	LOSS [training: 0.017689663045934896 | validation: 0.01786924611550465]
	TIME [epoch: 9.22 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019096190692717296		[learning rate: 0.00081683]
	Learning Rate: 0.000816833
	LOSS [training: 0.019096190692717296 | validation: 0.028080274693030344]
	TIME [epoch: 9.22 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021886726702151187		[learning rate: 0.00081433]
	Learning Rate: 0.000814329
	LOSS [training: 0.021886726702151187 | validation: 0.02511805732495457]
	TIME [epoch: 9.22 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015066355752390542		[learning rate: 0.00081183]
	Learning Rate: 0.000811833
	LOSS [training: 0.015066355752390542 | validation: 0.03347109470607745]
	TIME [epoch: 9.24 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02231724459425421		[learning rate: 0.00080934]
	Learning Rate: 0.000809344
	LOSS [training: 0.02231724459425421 | validation: 0.03157735151005894]
	TIME [epoch: 9.22 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022210578392817773		[learning rate: 0.00080686]
	Learning Rate: 0.000806863
	LOSS [training: 0.022210578392817773 | validation: 0.021667304065605082]
	TIME [epoch: 9.21 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020151921808209444		[learning rate: 0.00080439]
	Learning Rate: 0.00080439
	LOSS [training: 0.020151921808209444 | validation: 0.020020449630787095]
	TIME [epoch: 9.22 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017802934023396312		[learning rate: 0.00080192]
	Learning Rate: 0.000801924
	LOSS [training: 0.017802934023396312 | validation: 0.03199433517897152]
	TIME [epoch: 9.23 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0170379759282839		[learning rate: 0.00079947]
	Learning Rate: 0.000799466
	LOSS [training: 0.0170379759282839 | validation: 0.028121830536337693]
	TIME [epoch: 9.25 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015154261900692387		[learning rate: 0.00079702]
	Learning Rate: 0.000797015
	LOSS [training: 0.015154261900692387 | validation: 0.028057828248095513]
	TIME [epoch: 9.22 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0209663803633554		[learning rate: 0.00079457]
	Learning Rate: 0.000794572
	LOSS [training: 0.0209663803633554 | validation: 0.035379231743622674]
	TIME [epoch: 9.23 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025162816346134396		[learning rate: 0.00079214]
	Learning Rate: 0.000792136
	LOSS [training: 0.025162816346134396 | validation: 0.031046515249324547]
	TIME [epoch: 9.22 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0291768615958543		[learning rate: 0.00078971]
	Learning Rate: 0.000789708
	LOSS [training: 0.0291768615958543 | validation: 0.05314841356261499]
	TIME [epoch: 9.22 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03680976956607393		[learning rate: 0.00078729]
	Learning Rate: 0.000787287
	LOSS [training: 0.03680976956607393 | validation: 0.03288319548224902]
	TIME [epoch: 9.23 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024699657410942707		[learning rate: 0.00078487]
	Learning Rate: 0.000784874
	LOSS [training: 0.024699657410942707 | validation: 0.03733073452051413]
	TIME [epoch: 9.22 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02808475625628986		[learning rate: 0.00078247]
	Learning Rate: 0.000782468
	LOSS [training: 0.02808475625628986 | validation: 0.038764703275170995]
	TIME [epoch: 9.21 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03257500537550823		[learning rate: 0.00078007]
	Learning Rate: 0.00078007
	LOSS [training: 0.03257500537550823 | validation: 0.030704363775109104]
	TIME [epoch: 9.22 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028506335322794257		[learning rate: 0.00077768]
	Learning Rate: 0.000777678
	LOSS [training: 0.028506335322794257 | validation: 0.0407546376594414]
	TIME [epoch: 9.22 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032501827126381236		[learning rate: 0.00077529]
	Learning Rate: 0.000775294
	LOSS [training: 0.032501827126381236 | validation: 0.030854746797515348]
	TIME [epoch: 9.24 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02121501938181962		[learning rate: 0.00077292]
	Learning Rate: 0.000772918
	LOSS [training: 0.02121501938181962 | validation: 0.025032664927832626]
	TIME [epoch: 9.22 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025585779571600083		[learning rate: 0.00077055]
	Learning Rate: 0.000770548
	LOSS [training: 0.025585779571600083 | validation: 0.03161770154056831]
	TIME [epoch: 9.22 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02347448375076871		[learning rate: 0.00076819]
	Learning Rate: 0.000768187
	LOSS [training: 0.02347448375076871 | validation: 0.01783147369167764]
	TIME [epoch: 9.23 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021657145838831365		[learning rate: 0.00076583]
	Learning Rate: 0.000765832
	LOSS [training: 0.021657145838831365 | validation: 0.034389732280031046]
	TIME [epoch: 9.22 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02172312094492413		[learning rate: 0.00076348]
	Learning Rate: 0.000763484
	LOSS [training: 0.02172312094492413 | validation: 0.014615451311321564]
	TIME [epoch: 9.25 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022349441247934067		[learning rate: 0.00076114]
	Learning Rate: 0.000761144
	LOSS [training: 0.022349441247934067 | validation: 0.027156042933114855]
	TIME [epoch: 9.22 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0363140294788318		[learning rate: 0.00075881]
	Learning Rate: 0.00075881
	LOSS [training: 0.0363140294788318 | validation: 0.05499020201791302]
	TIME [epoch: 9.22 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04026748316163952		[learning rate: 0.00075648]
	Learning Rate: 0.000756484
	LOSS [training: 0.04026748316163952 | validation: 0.061752233159851164]
	TIME [epoch: 9.23 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04728525081263959		[learning rate: 0.00075417]
	Learning Rate: 0.000754165
	LOSS [training: 0.04728525081263959 | validation: 0.04088332723702519]
	TIME [epoch: 9.22 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04282305102107732		[learning rate: 0.00075185]
	Learning Rate: 0.000751854
	LOSS [training: 0.04282305102107732 | validation: 0.04618945670407749]
	TIME [epoch: 9.25 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028958474149945346		[learning rate: 0.00074955]
	Learning Rate: 0.000749549
	LOSS [training: 0.028958474149945346 | validation: 0.024875943773649812]
	TIME [epoch: 9.22 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022581169442922912		[learning rate: 0.00074725]
	Learning Rate: 0.000747251
	LOSS [training: 0.022581169442922912 | validation: 0.03356674573764757]
	TIME [epoch: 9.23 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045540406421921184		[learning rate: 0.00074496]
	Learning Rate: 0.000744961
	LOSS [training: 0.045540406421921184 | validation: 0.06017271207007867]
	TIME [epoch: 9.22 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035658346230387494		[learning rate: 0.00074268]
	Learning Rate: 0.000742677
	LOSS [training: 0.035658346230387494 | validation: 0.060779700966227965]
	TIME [epoch: 9.23 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041075538111766244		[learning rate: 0.0007404]
	Learning Rate: 0.0007404
	LOSS [training: 0.041075538111766244 | validation: 0.035568521111427644]
	TIME [epoch: 9.25 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032978742382151614		[learning rate: 0.00073813]
	Learning Rate: 0.000738131
	LOSS [training: 0.032978742382151614 | validation: 0.031066175738380816]
	TIME [epoch: 9.23 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029975773376735643		[learning rate: 0.00073587]
	Learning Rate: 0.000735868
	LOSS [training: 0.029975773376735643 | validation: 0.020888400109257445]
	TIME [epoch: 9.23 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026802904567673785		[learning rate: 0.00073361]
	Learning Rate: 0.000733612
	LOSS [training: 0.026802904567673785 | validation: 0.039312683828135075]
	TIME [epoch: 9.23 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030909812155226684		[learning rate: 0.00073136]
	Learning Rate: 0.000731364
	LOSS [training: 0.030909812155226684 | validation: 0.04741740339586749]
	TIME [epoch: 9.23 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035921448901630466		[learning rate: 0.00072912]
	Learning Rate: 0.000729122
	LOSS [training: 0.035921448901630466 | validation: 0.04529914619359396]
	TIME [epoch: 9.24 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03455627436990205		[learning rate: 0.00072689]
	Learning Rate: 0.000726886
	LOSS [training: 0.03455627436990205 | validation: 0.030683149900393746]
	TIME [epoch: 9.23 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0263344880214399		[learning rate: 0.00072466]
	Learning Rate: 0.000724658
	LOSS [training: 0.0263344880214399 | validation: 0.023043251971024248]
	TIME [epoch: 9.22 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02222859222187492		[learning rate: 0.00072244]
	Learning Rate: 0.000722437
	LOSS [training: 0.02222859222187492 | validation: 0.02959591875766074]
	TIME [epoch: 9.23 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030011308315850305		[learning rate: 0.00072022]
	Learning Rate: 0.000720223
	LOSS [training: 0.030011308315850305 | validation: 0.02730238010157751]
	TIME [epoch: 9.25 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023580651605225204		[learning rate: 0.00071801]
	Learning Rate: 0.000718015
	LOSS [training: 0.023580651605225204 | validation: 0.031567614441408154]
	TIME [epoch: 9.23 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02847884462478937		[learning rate: 0.00071581]
	Learning Rate: 0.000715814
	LOSS [training: 0.02847884462478937 | validation: 0.02565034392893658]
	TIME [epoch: 9.23 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02072410164996268		[learning rate: 0.00071362]
	Learning Rate: 0.000713619
	LOSS [training: 0.02072410164996268 | validation: 0.03303824792051242]
	TIME [epoch: 9.23 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02803651255945857		[learning rate: 0.00071143]
	Learning Rate: 0.000711432
	LOSS [training: 0.02803651255945857 | validation: 0.03367985531572303]
	TIME [epoch: 9.23 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01824642734774007		[learning rate: 0.00070925]
	Learning Rate: 0.000709251
	LOSS [training: 0.01824642734774007 | validation: 0.02942536982828777]
	TIME [epoch: 9.24 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017495943532826665		[learning rate: 0.00070708]
	Learning Rate: 0.000707077
	LOSS [training: 0.017495943532826665 | validation: 0.025113878042740064]
	TIME [epoch: 9.23 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01842890134173524		[learning rate: 0.00070491]
	Learning Rate: 0.00070491
	LOSS [training: 0.01842890134173524 | validation: 0.019106099863617085]
	TIME [epoch: 9.22 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017873701931915037		[learning rate: 0.00070275]
	Learning Rate: 0.000702748
	LOSS [training: 0.017873701931915037 | validation: 0.04767470032194093]
	TIME [epoch: 9.22 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02444347502609755		[learning rate: 0.00070059]
	Learning Rate: 0.000700594
	LOSS [training: 0.02444347502609755 | validation: 0.015953267418004576]
	TIME [epoch: 9.23 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018149588390147107		[learning rate: 0.00069845]
	Learning Rate: 0.000698447
	LOSS [training: 0.018149588390147107 | validation: 0.02155896236491569]
	TIME [epoch: 9.25 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032361214215919754		[learning rate: 0.00069631]
	Learning Rate: 0.000696306
	LOSS [training: 0.032361214215919754 | validation: 0.05359356077202067]
	TIME [epoch: 9.24 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02603535308559126		[learning rate: 0.00069417]
	Learning Rate: 0.000694171
	LOSS [training: 0.02603535308559126 | validation: 0.021223357199702184]
	TIME [epoch: 9.22 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019586404090105154		[learning rate: 0.00069204]
	Learning Rate: 0.000692043
	LOSS [training: 0.019586404090105154 | validation: 0.03373477363900508]
	TIME [epoch: 9.22 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017024629839082234		[learning rate: 0.00068992]
	Learning Rate: 0.000689922
	LOSS [training: 0.017024629839082234 | validation: 0.019405070920174815]
	TIME [epoch: 9.23 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02111520690947346		[learning rate: 0.00068781]
	Learning Rate: 0.000687807
	LOSS [training: 0.02111520690947346 | validation: 0.03174696715815375]
	TIME [epoch: 9.24 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02625042373508677		[learning rate: 0.0006857]
	Learning Rate: 0.000685699
	LOSS [training: 0.02625042373508677 | validation: 0.04586931946428481]
	TIME [epoch: 9.23 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032844439657599714		[learning rate: 0.0006836]
	Learning Rate: 0.000683597
	LOSS [training: 0.032844439657599714 | validation: 0.027964316304441607]
	TIME [epoch: 9.22 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023378758194801157		[learning rate: 0.0006815]
	Learning Rate: 0.000681501
	LOSS [training: 0.023378758194801157 | validation: 0.05219868719304728]
	TIME [epoch: 9.22 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031676164907797635		[learning rate: 0.00067941]
	Learning Rate: 0.000679412
	LOSS [training: 0.031676164907797635 | validation: 0.04087042246328031]
	TIME [epoch: 9.22 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0344279930692277		[learning rate: 0.00067733]
	Learning Rate: 0.000677329
	LOSS [training: 0.0344279930692277 | validation: 0.04068702667765915]
	TIME [epoch: 9.24 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032780962984726436		[learning rate: 0.00067525]
	Learning Rate: 0.000675253
	LOSS [training: 0.032780962984726436 | validation: 0.03536657954946683]
	TIME [epoch: 9.23 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031408058376756906		[learning rate: 0.00067318]
	Learning Rate: 0.000673183
	LOSS [training: 0.031408058376756906 | validation: 0.04021913767800234]
	TIME [epoch: 9.23 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027845236735071256		[learning rate: 0.00067112]
	Learning Rate: 0.00067112
	LOSS [training: 0.027845236735071256 | validation: 0.02406080435002102]
	TIME [epoch: 9.22 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01965916013289114		[learning rate: 0.00066906]
	Learning Rate: 0.000669062
	LOSS [training: 0.01965916013289114 | validation: 0.028410763245110403]
	TIME [epoch: 9.22 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017470939852106366		[learning rate: 0.00066701]
	Learning Rate: 0.000667011
	LOSS [training: 0.017470939852106366 | validation: 0.025416461490985476]
	TIME [epoch: 9.24 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01192027874730858		[learning rate: 0.00066497]
	Learning Rate: 0.000664967
	LOSS [training: 0.01192027874730858 | validation: 0.03170202945679036]
	TIME [epoch: 9.22 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02377630202635376		[learning rate: 0.00066293]
	Learning Rate: 0.000662929
	LOSS [training: 0.02377630202635376 | validation: 0.024043423444956864]
	TIME [epoch: 9.22 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024160369088241464		[learning rate: 0.0006609]
	Learning Rate: 0.000660896
	LOSS [training: 0.024160369088241464 | validation: 0.023555712579301228]
	TIME [epoch: 9.22 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027011636541316265		[learning rate: 0.00065887]
	Learning Rate: 0.00065887
	LOSS [training: 0.027011636541316265 | validation: 0.028179796605120412]
	TIME [epoch: 9.22 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017135825786903702		[learning rate: 0.00065685]
	Learning Rate: 0.000656851
	LOSS [training: 0.017135825786903702 | validation: 0.02656597382234606]
	TIME [epoch: 9.25 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026299296161367752		[learning rate: 0.00065484]
	Learning Rate: 0.000654837
	LOSS [training: 0.026299296161367752 | validation: 0.03576549609516079]
	TIME [epoch: 9.22 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018290819673828552		[learning rate: 0.00065283]
	Learning Rate: 0.00065283
	LOSS [training: 0.018290819673828552 | validation: 0.020919518352012084]
	TIME [epoch: 9.21 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010409107642029068		[learning rate: 0.00065083]
	Learning Rate: 0.000650829
	LOSS [training: 0.010409107642029068 | validation: 0.022226908141545012]
	TIME [epoch: 9.22 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01509166676901558		[learning rate: 0.00064883]
	Learning Rate: 0.000648834
	LOSS [training: 0.01509166676901558 | validation: 0.019283151272124786]
	TIME [epoch: 9.23 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015316107424053097		[learning rate: 0.00064684]
	Learning Rate: 0.000646845
	LOSS [training: 0.015316107424053097 | validation: 0.015010197955880966]
	TIME [epoch: 9.25 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010406859555726566		[learning rate: 0.00064486]
	Learning Rate: 0.000644862
	LOSS [training: 0.010406859555726566 | validation: 0.02295553743378819]
	TIME [epoch: 9.23 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01073373322035412		[learning rate: 0.00064289]
	Learning Rate: 0.000642885
	LOSS [training: 0.01073373322035412 | validation: 0.014490815076667881]
	TIME [epoch: 9.23 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010856262195008771		[learning rate: 0.00064091]
	Learning Rate: 0.000640914
	LOSS [training: 0.010856262195008771 | validation: 0.02046900879512243]
	TIME [epoch: 9.22 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015795948780759954		[learning rate: 0.00063895]
	Learning Rate: 0.00063895
	LOSS [training: 0.015795948780759954 | validation: 0.025796672820896944]
	TIME [epoch: 9.23 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01131415014596614		[learning rate: 0.00063699]
	Learning Rate: 0.000636991
	LOSS [training: 0.01131415014596614 | validation: 0.021980302429996025]
	TIME [epoch: 9.25 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014448867673189925		[learning rate: 0.00063504]
	Learning Rate: 0.000635038
	LOSS [training: 0.014448867673189925 | validation: 0.008308999526925372]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1398.pth
	Model improved!!!
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01118390280843919		[learning rate: 0.00063309]
	Learning Rate: 0.000633092
	LOSS [training: 0.01118390280843919 | validation: 0.02659038398185858]
	TIME [epoch: 9.23 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015849102670820386		[learning rate: 0.00063115]
	Learning Rate: 0.000631151
	LOSS [training: 0.015849102670820386 | validation: 0.029251496734794998]
	TIME [epoch: 9.23 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017407022657896544		[learning rate: 0.00062922]
	Learning Rate: 0.000629216
	LOSS [training: 0.017407022657896544 | validation: 0.02522191029385715]
	TIME [epoch: 9.22 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017466084936757737		[learning rate: 0.00062729]
	Learning Rate: 0.000627287
	LOSS [training: 0.017466084936757737 | validation: 0.02489595802251858]
	TIME [epoch: 9.24 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025080481337300432		[learning rate: 0.00062536]
	Learning Rate: 0.000625365
	LOSS [training: 0.025080481337300432 | validation: 0.03358269379999662]
	TIME [epoch: 9.22 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018439734605564532		[learning rate: 0.00062345]
	Learning Rate: 0.000623448
	LOSS [training: 0.018439734605564532 | validation: 0.01736543622739844]
	TIME [epoch: 9.21 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029197116408040347		[learning rate: 0.00062154]
	Learning Rate: 0.000621537
	LOSS [training: 0.029197116408040347 | validation: 0.023007516661745886]
	TIME [epoch: 9.22 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03644868531519801		[learning rate: 0.00061963]
	Learning Rate: 0.000619631
	LOSS [training: 0.03644868531519801 | validation: 0.0679274361151874]
	TIME [epoch: 9.23 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052192257740802106		[learning rate: 0.00061773]
	Learning Rate: 0.000617732
	LOSS [training: 0.052192257740802106 | validation: 0.031055298836525587]
	TIME [epoch: 9.24 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026733025256511927		[learning rate: 0.00061584]
	Learning Rate: 0.000615838
	LOSS [training: 0.026733025256511927 | validation: 0.028855122968844325]
	TIME [epoch: 9.22 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029875992457240035		[learning rate: 0.00061395]
	Learning Rate: 0.00061395
	LOSS [training: 0.029875992457240035 | validation: 0.03590963545904199]
	TIME [epoch: 9.23 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03006640586280967		[learning rate: 0.00061207]
	Learning Rate: 0.000612068
	LOSS [training: 0.03006640586280967 | validation: 0.05652334286213263]
	TIME [epoch: 9.22 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047161098087565564		[learning rate: 0.00061019]
	Learning Rate: 0.000610192
	LOSS [training: 0.047161098087565564 | validation: 0.051677690779887764]
	TIME [epoch: 9.25 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02846632878900939		[learning rate: 0.00060832]
	Learning Rate: 0.000608322
	LOSS [training: 0.02846632878900939 | validation: 0.027741505939180088]
	TIME [epoch: 9.22 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013835759794831334		[learning rate: 0.00060646]
	Learning Rate: 0.000606457
	LOSS [training: 0.013835759794831334 | validation: 0.01969441650632814]
	TIME [epoch: 9.22 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014648429479959002		[learning rate: 0.0006046]
	Learning Rate: 0.000604598
	LOSS [training: 0.014648429479959002 | validation: 0.0268065632656079]
	TIME [epoch: 9.22 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014354792263989677		[learning rate: 0.00060274]
	Learning Rate: 0.000602745
	LOSS [training: 0.014354792263989677 | validation: 0.017479577242009495]
	TIME [epoch: 9.22 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018827694259802758		[learning rate: 0.0006009]
	Learning Rate: 0.000600897
	LOSS [training: 0.018827694259802758 | validation: 0.022571150990671657]
	TIME [epoch: 9.23 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014398394111096932		[learning rate: 0.00059905]
	Learning Rate: 0.000599055
	LOSS [training: 0.014398394111096932 | validation: 0.0252013279862078]
	TIME [epoch: 9.23 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014229342325462769		[learning rate: 0.00059722]
	Learning Rate: 0.000597219
	LOSS [training: 0.014229342325462769 | validation: 0.024018492650623897]
	TIME [epoch: 9.22 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019354878069955367		[learning rate: 0.00059539]
	Learning Rate: 0.000595388
	LOSS [training: 0.019354878069955367 | validation: 0.01901743371966777]
	TIME [epoch: 9.22 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016787431307345314		[learning rate: 0.00059356]
	Learning Rate: 0.000593563
	LOSS [training: 0.016787431307345314 | validation: 0.02069252759079961]
	TIME [epoch: 9.22 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014292889242745943		[learning rate: 0.00059174]
	Learning Rate: 0.000591743
	LOSS [training: 0.014292889242745943 | validation: 0.032286188512659644]
	TIME [epoch: 9.24 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015701024071455072		[learning rate: 0.00058993]
	Learning Rate: 0.000589929
	LOSS [training: 0.015701024071455072 | validation: 0.01895364047247126]
	TIME [epoch: 9.23 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01271544388313606		[learning rate: 0.00058812]
	Learning Rate: 0.000588121
	LOSS [training: 0.01271544388313606 | validation: 0.02200419871697428]
	TIME [epoch: 9.23 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01865694345802297		[learning rate: 0.00058632]
	Learning Rate: 0.000586318
	LOSS [training: 0.01865694345802297 | validation: 0.0220203330891946]
	TIME [epoch: 9.23 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01763923976732349		[learning rate: 0.00058452]
	Learning Rate: 0.000584521
	LOSS [training: 0.01763923976732349 | validation: 0.017224894975961455]
	TIME [epoch: 9.23 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016903828117576788		[learning rate: 0.00058273]
	Learning Rate: 0.000582729
	LOSS [training: 0.016903828117576788 | validation: 0.014510847324141297]
	TIME [epoch: 9.24 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015482271009720522		[learning rate: 0.00058094]
	Learning Rate: 0.000580943
	LOSS [training: 0.015482271009720522 | validation: 0.011790001531553563]
	TIME [epoch: 9.23 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01234699833075415		[learning rate: 0.00057916]
	Learning Rate: 0.000579162
	LOSS [training: 0.01234699833075415 | validation: 0.020479048160950974]
	TIME [epoch: 9.22 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010191505263464292		[learning rate: 0.00057739]
	Learning Rate: 0.000577386
	LOSS [training: 0.010191505263464292 | validation: 0.023171528255184412]
	TIME [epoch: 9.22 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011773253118474714		[learning rate: 0.00057562]
	Learning Rate: 0.000575616
	LOSS [training: 0.011773253118474714 | validation: 0.015602199697845293]
	TIME [epoch: 9.23 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008315171793107408		[learning rate: 0.00057385]
	Learning Rate: 0.000573852
	LOSS [training: 0.008315171793107408 | validation: 0.023737141412997646]
	TIME [epoch: 9.24 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010761971169584857		[learning rate: 0.00057209]
	Learning Rate: 0.000572093
	LOSS [training: 0.010761971169584857 | validation: 0.02699374543116345]
	TIME [epoch: 9.22 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01810468967611046		[learning rate: 0.00057034]
	Learning Rate: 0.000570339
	LOSS [training: 0.01810468967611046 | validation: 0.005314553251279717]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1433.pth
	Model improved!!!
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013615736897684066		[learning rate: 0.00056859]
	Learning Rate: 0.000568591
	LOSS [training: 0.013615736897684066 | validation: 0.01042842360013665]
	TIME [epoch: 9.22 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009646890969704966		[learning rate: 0.00056685]
	Learning Rate: 0.000566848
	LOSS [training: 0.009646890969704966 | validation: 0.013762341985613984]
	TIME [epoch: 9.22 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011886231247812719		[learning rate: 0.00056511]
	Learning Rate: 0.00056511
	LOSS [training: 0.011886231247812719 | validation: 0.016806531856266592]
	TIME [epoch: 9.23 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01959053622276568		[learning rate: 0.00056338]
	Learning Rate: 0.000563378
	LOSS [training: 0.01959053622276568 | validation: 0.03337224659652595]
	TIME [epoch: 9.22 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022751616769501187		[learning rate: 0.00056165]
	Learning Rate: 0.000561651
	LOSS [training: 0.022751616769501187 | validation: 0.027866856019453063]
	TIME [epoch: 9.21 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021655578804210544		[learning rate: 0.00055993]
	Learning Rate: 0.000559929
	LOSS [training: 0.021655578804210544 | validation: 0.017470653240659814]
	TIME [epoch: 9.22 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01789257948790791		[learning rate: 0.00055821]
	Learning Rate: 0.000558213
	LOSS [training: 0.01789257948790791 | validation: 0.022230664481893727]
	TIME [epoch: 9.21 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0094294883741168		[learning rate: 0.0005565]
	Learning Rate: 0.000556502
	LOSS [training: 0.0094294883741168 | validation: 0.025613563240685734]
	TIME [epoch: 9.24 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012938096428868881		[learning rate: 0.0005548]
	Learning Rate: 0.000554796
	LOSS [training: 0.012938096428868881 | validation: 0.026086370912093045]
	TIME [epoch: 9.23 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012235733919286725		[learning rate: 0.0005531]
	Learning Rate: 0.000553095
	LOSS [training: 0.012235733919286725 | validation: 0.01778172365406753]
	TIME [epoch: 9.23 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013066832721915314		[learning rate: 0.0005514]
	Learning Rate: 0.0005514
	LOSS [training: 0.013066832721915314 | validation: 0.02323318103364367]
	TIME [epoch: 9.22 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016157167831597038		[learning rate: 0.00054971]
	Learning Rate: 0.000549709
	LOSS [training: 0.016157167831597038 | validation: 0.02799576768499794]
	TIME [epoch: 9.22 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01795717755431188		[learning rate: 0.00054802]
	Learning Rate: 0.000548024
	LOSS [training: 0.01795717755431188 | validation: 0.03543506893102161]
	TIME [epoch: 9.24 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024588297307244822		[learning rate: 0.00054634]
	Learning Rate: 0.000546345
	LOSS [training: 0.024588297307244822 | validation: 0.020317287276787152]
	TIME [epoch: 9.22 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019511992815875574		[learning rate: 0.00054467]
	Learning Rate: 0.00054467
	LOSS [training: 0.019511992815875574 | validation: 0.028045647693123746]
	TIME [epoch: 9.21 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01571574009969631		[learning rate: 0.000543]
	Learning Rate: 0.000543
	LOSS [training: 0.01571574009969631 | validation: 0.023020755992499545]
	TIME [epoch: 9.22 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00904560737317397		[learning rate: 0.00054134]
	Learning Rate: 0.000541336
	LOSS [training: 0.00904560737317397 | validation: 0.017784556690749714]
	TIME [epoch: 9.23 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013177496154264825		[learning rate: 0.00053968]
	Learning Rate: 0.000539676
	LOSS [training: 0.013177496154264825 | validation: 0.02322202906077023]
	TIME [epoch: 9.24 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024463633278721534		[learning rate: 0.00053802]
	Learning Rate: 0.000538022
	LOSS [training: 0.024463633278721534 | validation: 0.03513943588314143]
	TIME [epoch: 9.22 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018886099127959736		[learning rate: 0.00053637]
	Learning Rate: 0.000536373
	LOSS [training: 0.018886099127959736 | validation: 0.021464060670573847]
	TIME [epoch: 9.23 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02039902073085345		[learning rate: 0.00053473]
	Learning Rate: 0.000534728
	LOSS [training: 0.02039902073085345 | validation: 0.030848825884514056]
	TIME [epoch: 9.23 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01907289921827043		[learning rate: 0.00053309]
	Learning Rate: 0.000533089
	LOSS [training: 0.01907289921827043 | validation: 0.02207945974354609]
	TIME [epoch: 9.22 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016234472202952502		[learning rate: 0.00053146]
	Learning Rate: 0.000531455
	LOSS [training: 0.016234472202952502 | validation: 0.01873378532373643]
	TIME [epoch: 9.24 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015414947685678814		[learning rate: 0.00052983]
	Learning Rate: 0.000529826
	LOSS [training: 0.015414947685678814 | validation: 0.04359094334789515]
	TIME [epoch: 9.22 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013426712072227088		[learning rate: 0.0005282]
	Learning Rate: 0.000528202
	LOSS [training: 0.013426712072227088 | validation: 0.02487430324377265]
	TIME [epoch: 9.23 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01756992376397794		[learning rate: 0.00052658]
	Learning Rate: 0.000526583
	LOSS [training: 0.01756992376397794 | validation: 0.01664970984515064]
	TIME [epoch: 9.23 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01773072004645296		[learning rate: 0.00052497]
	Learning Rate: 0.000524969
	LOSS [training: 0.01773072004645296 | validation: 0.031510120759469844]
	TIME [epoch: 9.23 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016474470984270517		[learning rate: 0.00052336]
	Learning Rate: 0.000523359
	LOSS [training: 0.016474470984270517 | validation: 0.03509469637153055]
	TIME [epoch: 9.23 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020870588566106303		[learning rate: 0.00052176]
	Learning Rate: 0.000521755
	LOSS [training: 0.020870588566106303 | validation: 0.03097478545656834]
	TIME [epoch: 9.22 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011859340809418408		[learning rate: 0.00052016]
	Learning Rate: 0.000520156
	LOSS [training: 0.011859340809418408 | validation: 0.023681832270036146]
	TIME [epoch: 9.22 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012749136056385344		[learning rate: 0.00051856]
	Learning Rate: 0.000518561
	LOSS [training: 0.012749136056385344 | validation: 0.024805247857681713]
	TIME [epoch: 9.22 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014904940918710132		[learning rate: 0.00051697]
	Learning Rate: 0.000516972
	LOSS [training: 0.014904940918710132 | validation: 0.021043732164411508]
	TIME [epoch: 9.23 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009779804447823637		[learning rate: 0.00051539]
	Learning Rate: 0.000515387
	LOSS [training: 0.009779804447823637 | validation: 0.025046315999472678]
	TIME [epoch: 9.24 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021431971739609416		[learning rate: 0.00051381]
	Learning Rate: 0.000513807
	LOSS [training: 0.021431971739609416 | validation: 0.03570038331637932]
	TIME [epoch: 9.21 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018593514026216347		[learning rate: 0.00051223]
	Learning Rate: 0.000512232
	LOSS [training: 0.018593514026216347 | validation: 0.023851939370660054]
	TIME [epoch: 9.21 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013177837257048982		[learning rate: 0.00051066]
	Learning Rate: 0.000510662
	LOSS [training: 0.013177837257048982 | validation: 0.02640246279242034]
	TIME [epoch: 9.22 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014558585375353938		[learning rate: 0.0005091]
	Learning Rate: 0.000509096
	LOSS [training: 0.014558585375353938 | validation: 0.024338787200628053]
	TIME [epoch: 9.24 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008069252201897066		[learning rate: 0.00050754]
	Learning Rate: 0.000507536
	LOSS [training: 0.008069252201897066 | validation: 0.023233758634668897]
	TIME [epoch: 9.23 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011283927399733055		[learning rate: 0.00050598]
	Learning Rate: 0.00050598
	LOSS [training: 0.011283927399733055 | validation: 0.026102237985900428]
	TIME [epoch: 9.22 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015130286345609797		[learning rate: 0.00050443]
	Learning Rate: 0.000504429
	LOSS [training: 0.015130286345609797 | validation: 0.03273677462350085]
	TIME [epoch: 9.22 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020610932626884085		[learning rate: 0.00050288]
	Learning Rate: 0.000502883
	LOSS [training: 0.020610932626884085 | validation: 0.0429241955739737]
	TIME [epoch: 9.22 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01501661920044764		[learning rate: 0.00050134]
	Learning Rate: 0.000501341
	LOSS [training: 0.01501661920044764 | validation: 0.02024495650963981]
	TIME [epoch: 9.24 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015675295194436424		[learning rate: 0.0004998]
	Learning Rate: 0.000499804
	LOSS [training: 0.015675295194436424 | validation: 0.029144342310908608]
	TIME [epoch: 9.21 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011167242266773146		[learning rate: 0.00049827]
	Learning Rate: 0.000498272
	LOSS [training: 0.011167242266773146 | validation: 0.018176097116135895]
	TIME [epoch: 9.22 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016409811773743836		[learning rate: 0.00049674]
	Learning Rate: 0.000496745
	LOSS [training: 0.016409811773743836 | validation: 0.0281486916100354]
	TIME [epoch: 9.22 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019267577678050686		[learning rate: 0.00049522]
	Learning Rate: 0.000495222
	LOSS [training: 0.019267577678050686 | validation: 0.027745859410710255]
	TIME [epoch: 9.22 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014937863881155644		[learning rate: 0.0004937]
	Learning Rate: 0.000493704
	LOSS [training: 0.014937863881155644 | validation: 0.04122364167598353]
	TIME [epoch: 9.24 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016415297786922835		[learning rate: 0.00049219]
	Learning Rate: 0.000492191
	LOSS [training: 0.016415297786922835 | validation: 0.023162637490983386]
	TIME [epoch: 9.23 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014880928772257366		[learning rate: 0.00049068]
	Learning Rate: 0.000490682
	LOSS [training: 0.014880928772257366 | validation: 0.022381825821614278]
	TIME [epoch: 9.22 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01526650299435397		[learning rate: 0.00048918]
	Learning Rate: 0.000489178
	LOSS [training: 0.01526650299435397 | validation: 0.026885146833598203]
	TIME [epoch: 9.22 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017435929354872294		[learning rate: 0.00048768]
	Learning Rate: 0.000487678
	LOSS [training: 0.017435929354872294 | validation: 0.022745669114455604]
	TIME [epoch: 9.22 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015579858719734213		[learning rate: 0.00048618]
	Learning Rate: 0.000486183
	LOSS [training: 0.015579858719734213 | validation: 0.02697318971714535]
	TIME [epoch: 9.25 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024124578512878962		[learning rate: 0.00048469]
	Learning Rate: 0.000484693
	LOSS [training: 0.024124578512878962 | validation: 0.03728299241050374]
	TIME [epoch: 9.23 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02061225819000709		[learning rate: 0.00048321]
	Learning Rate: 0.000483207
	LOSS [training: 0.02061225819000709 | validation: 0.042729320869127965]
	TIME [epoch: 9.23 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026062592237820943		[learning rate: 0.00048173]
	Learning Rate: 0.000481726
	LOSS [training: 0.026062592237820943 | validation: 0.027694197181337803]
	TIME [epoch: 9.22 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016251364572865665		[learning rate: 0.00048025]
	Learning Rate: 0.000480249
	LOSS [training: 0.016251364572865665 | validation: 0.026366736568897542]
	TIME [epoch: 9.22 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015823197834107055		[learning rate: 0.00047878]
	Learning Rate: 0.000478777
	LOSS [training: 0.015823197834107055 | validation: 0.03948746360184354]
	TIME [epoch: 9.25 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016900128214449535		[learning rate: 0.00047731]
	Learning Rate: 0.000477309
	LOSS [training: 0.016900128214449535 | validation: 0.017653734519676355]
	TIME [epoch: 9.22 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015949697238634104		[learning rate: 0.00047585]
	Learning Rate: 0.000475846
	LOSS [training: 0.015949697238634104 | validation: 0.02585227276836279]
	TIME [epoch: 9.22 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01632252259077716		[learning rate: 0.00047439]
	Learning Rate: 0.000474388
	LOSS [training: 0.01632252259077716 | validation: 0.025830886990432768]
	TIME [epoch: 9.23 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014332315865298432		[learning rate: 0.00047293]
	Learning Rate: 0.000472933
	LOSS [training: 0.014332315865298432 | validation: 0.02287171067010392]
	TIME [epoch: 9.22 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01531539824939573		[learning rate: 0.00047148]
	Learning Rate: 0.000471484
	LOSS [training: 0.01531539824939573 | validation: 0.027623457137839463]
	TIME [epoch: 9.24 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013775801775690152		[learning rate: 0.00047004]
	Learning Rate: 0.000470038
	LOSS [training: 0.013775801775690152 | validation: 0.015388355461896309]
	TIME [epoch: 9.22 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009818454766794054		[learning rate: 0.0004686]
	Learning Rate: 0.000468597
	LOSS [training: 0.009818454766794054 | validation: 0.015573105937206864]
	TIME [epoch: 9.23 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013884502945786702		[learning rate: 0.00046716]
	Learning Rate: 0.000467161
	LOSS [training: 0.013884502945786702 | validation: 0.03601981003896103]
	TIME [epoch: 9.22 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017951033950684675		[learning rate: 0.00046573]
	Learning Rate: 0.000465729
	LOSS [training: 0.017951033950684675 | validation: 0.02132150955598827]
	TIME [epoch: 9.22 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01095230762573191		[learning rate: 0.0004643]
	Learning Rate: 0.000464301
	LOSS [training: 0.01095230762573191 | validation: 0.020039430613130346]
	TIME [epoch: 9.25 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016258276606163434		[learning rate: 0.00046288]
	Learning Rate: 0.000462878
	LOSS [training: 0.016258276606163434 | validation: 0.028378456485892472]
	TIME [epoch: 9.23 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011886607712589214		[learning rate: 0.00046146]
	Learning Rate: 0.000461459
	LOSS [training: 0.011886607712589214 | validation: 0.026956186293426918]
	TIME [epoch: 9.22 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01454256633379516		[learning rate: 0.00046004]
	Learning Rate: 0.000460045
	LOSS [training: 0.01454256633379516 | validation: 0.02207280631217325]
	TIME [epoch: 9.22 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013495894821163363		[learning rate: 0.00045863]
	Learning Rate: 0.000458634
	LOSS [training: 0.013495894821163363 | validation: 0.019820499887710778]
	TIME [epoch: 9.22 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015677644905422648		[learning rate: 0.00045723]
	Learning Rate: 0.000457229
	LOSS [training: 0.015677644905422648 | validation: 0.02756918144041501]
	TIME [epoch: 9.24 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020691855523017503		[learning rate: 0.00045583]
	Learning Rate: 0.000455827
	LOSS [training: 0.020691855523017503 | validation: 0.027730201323249267]
	TIME [epoch: 9.22 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018486762774435866		[learning rate: 0.00045443]
	Learning Rate: 0.00045443
	LOSS [training: 0.018486762774435866 | validation: 0.02537719619521322]
	TIME [epoch: 9.22 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015314255653816205		[learning rate: 0.00045304]
	Learning Rate: 0.000453037
	LOSS [training: 0.015314255653816205 | validation: 0.01721999384346186]
	TIME [epoch: 9.23 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022188521254805867		[learning rate: 0.00045165]
	Learning Rate: 0.000451648
	LOSS [training: 0.022188521254805867 | validation: 0.028209105606878546]
	TIME [epoch: 9.23 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023304192796692998		[learning rate: 0.00045026]
	Learning Rate: 0.000450263
	LOSS [training: 0.023304192796692998 | validation: 0.02074158347131412]
	TIME [epoch: 9.25 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0158541019264363		[learning rate: 0.00044888]
	Learning Rate: 0.000448883
	LOSS [training: 0.0158541019264363 | validation: 0.03232719517497406]
	TIME [epoch: 9.23 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01314165874047259		[learning rate: 0.00044751]
	Learning Rate: 0.000447507
	LOSS [training: 0.01314165874047259 | validation: 0.033202594470898794]
	TIME [epoch: 9.23 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017262672361365226		[learning rate: 0.00044614]
	Learning Rate: 0.000446135
	LOSS [training: 0.017262672361365226 | validation: 0.024969719940813682]
	TIME [epoch: 9.23 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015328812408180941		[learning rate: 0.00044477]
	Learning Rate: 0.000444768
	LOSS [training: 0.015328812408180941 | validation: 0.034472322491960986]
	TIME [epoch: 9.23 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01960728654044135		[learning rate: 0.0004434]
	Learning Rate: 0.000443404
	LOSS [training: 0.01960728654044135 | validation: 0.022212114648706562]
	TIME [epoch: 9.25 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02336033075155107		[learning rate: 0.00044205]
	Learning Rate: 0.000442045
	LOSS [training: 0.02336033075155107 | validation: 0.028627703274316366]
	TIME [epoch: 9.22 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022194617426059795		[learning rate: 0.00044069]
	Learning Rate: 0.00044069
	LOSS [training: 0.022194617426059795 | validation: 0.03345914193175935]
	TIME [epoch: 9.23 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02052446752881907		[learning rate: 0.00043934]
	Learning Rate: 0.000439339
	LOSS [training: 0.02052446752881907 | validation: 0.024261321449229007]
	TIME [epoch: 9.22 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01536298789071323		[learning rate: 0.00043799]
	Learning Rate: 0.000437992
	LOSS [training: 0.01536298789071323 | validation: 0.020507523427811716]
	TIME [epoch: 9.23 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015598996154030157		[learning rate: 0.00043665]
	Learning Rate: 0.00043665
	LOSS [training: 0.015598996154030157 | validation: 0.01457867376321231]
	TIME [epoch: 9.24 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016545832715318155		[learning rate: 0.00043531]
	Learning Rate: 0.000435311
	LOSS [training: 0.016545832715318155 | validation: 0.020069688557676147]
	TIME [epoch: 9.23 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012280015186090636		[learning rate: 0.00043398]
	Learning Rate: 0.000433977
	LOSS [training: 0.012280015186090636 | validation: 0.019976082714727346]
	TIME [epoch: 9.22 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009267080968104944		[learning rate: 0.00043265]
	Learning Rate: 0.000432647
	LOSS [training: 0.009267080968104944 | validation: 0.022655464381055812]
	TIME [epoch: 9.23 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00501469087342306		[learning rate: 0.00043132]
	Learning Rate: 0.00043132
	LOSS [training: 0.00501469087342306 | validation: 0.019127074156937096]
	TIME [epoch: 9.24 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008367283865257		[learning rate: 0.00043]
	Learning Rate: 0.000429998
	LOSS [training: 0.008367283865257 | validation: 0.014366755527588978]
	TIME [epoch: 9.23 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015670102907010687		[learning rate: 0.00042868]
	Learning Rate: 0.00042868
	LOSS [training: 0.015670102907010687 | validation: 0.013125535395007527]
	TIME [epoch: 9.23 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010479611828149844		[learning rate: 0.00042737]
	Learning Rate: 0.000427366
	LOSS [training: 0.010479611828149844 | validation: 0.015448215683537155]
	TIME [epoch: 9.23 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011549212056490702		[learning rate: 0.00042606]
	Learning Rate: 0.000426056
	LOSS [training: 0.011549212056490702 | validation: 0.013462336366302341]
	TIME [epoch: 9.23 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009962316237074708		[learning rate: 0.00042475]
	Learning Rate: 0.00042475
	LOSS [training: 0.009962316237074708 | validation: 0.005755215658441894]
	TIME [epoch: 9.24 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008525583443987223		[learning rate: 0.00042345]
	Learning Rate: 0.000423448
	LOSS [training: 0.008525583443987223 | validation: 0.009413205787775686]
	TIME [epoch: 9.23 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01208690408604285		[learning rate: 0.00042215]
	Learning Rate: 0.00042215
	LOSS [training: 0.01208690408604285 | validation: 0.022656891153951492]
	TIME [epoch: 9.23 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003370183550055782		[learning rate: 0.00042086]
	Learning Rate: 0.000420856
	LOSS [training: 0.003370183550055782 | validation: 0.014466718074220002]
	TIME [epoch: 9.22 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004287209495430442		[learning rate: 0.00041957]
	Learning Rate: 0.000419566
	LOSS [training: 0.004287209495430442 | validation: 0.01969563785760208]
	TIME [epoch: 9.23 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006297429245168526		[learning rate: 0.00041828]
	Learning Rate: 0.00041828
	LOSS [training: 0.006297429245168526 | validation: 0.010101059548727732]
	TIME [epoch: 9.24 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008109726902368108		[learning rate: 0.000417]
	Learning Rate: 0.000416997
	LOSS [training: 0.008109726902368108 | validation: 0.015742758003511714]
	TIME [epoch: 9.23 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006833360698081037		[learning rate: 0.00041572]
	Learning Rate: 0.000415719
	LOSS [training: 0.006833360698081037 | validation: 0.02354409098165401]
	TIME [epoch: 9.23 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012345052005690142		[learning rate: 0.00041444]
	Learning Rate: 0.000414445
	LOSS [training: 0.012345052005690142 | validation: 0.020750081093504645]
	TIME [epoch: 9.23 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00879543286302333		[learning rate: 0.00041317]
	Learning Rate: 0.000413174
	LOSS [training: 0.00879543286302333 | validation: 0.02218852480580348]
	TIME [epoch: 9.24 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012398617430018936		[learning rate: 0.00041191]
	Learning Rate: 0.000411908
	LOSS [training: 0.012398617430018936 | validation: 0.020793911288732744]
	TIME [epoch: 9.24 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009348047832121564		[learning rate: 0.00041065]
	Learning Rate: 0.000410645
	LOSS [training: 0.009348047832121564 | validation: 0.012458360194129756]
	TIME [epoch: 9.23 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0037839565101010714		[learning rate: 0.00040939]
	Learning Rate: 0.000409386
	LOSS [training: 0.0037839565101010714 | validation: 0.010324466606171503]
	TIME [epoch: 9.24 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009277029109839647		[learning rate: 0.00040813]
	Learning Rate: 0.000408131
	LOSS [training: 0.009277029109839647 | validation: 0.015282480717485307]
	TIME [epoch: 9.22 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009802678875546016		[learning rate: 0.00040688]
	Learning Rate: 0.00040688
	LOSS [training: 0.009802678875546016 | validation: 0.023579318571384705]
	TIME [epoch: 9.22 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01397108615034583		[learning rate: 0.00040563]
	Learning Rate: 0.000405633
	LOSS [training: 0.01397108615034583 | validation: 0.010888792270687292]
	TIME [epoch: 9.25 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007906145407741053		[learning rate: 0.00040439]
	Learning Rate: 0.00040439
	LOSS [training: 0.007906145407741053 | validation: 0.01803164906061954]
	TIME [epoch: 9.23 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008976036381219575		[learning rate: 0.00040315]
	Learning Rate: 0.00040315
	LOSS [training: 0.008976036381219575 | validation: 0.021187760534205305]
	TIME [epoch: 9.23 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006525693605520466		[learning rate: 0.00040191]
	Learning Rate: 0.000401914
	LOSS [training: 0.006525693605520466 | validation: 0.008419718933003997]
	TIME [epoch: 9.22 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00563418227287017		[learning rate: 0.00040068]
	Learning Rate: 0.000400682
	LOSS [training: 0.00563418227287017 | validation: 0.017295255818560437]
	TIME [epoch: 9.23 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006593108250374848		[learning rate: 0.00039945]
	Learning Rate: 0.000399454
	LOSS [training: 0.006593108250374848 | validation: 0.02033055877301223]
	TIME [epoch: 9.24 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009020418036513852		[learning rate: 0.00039823]
	Learning Rate: 0.000398229
	LOSS [training: 0.009020418036513852 | validation: 0.01938780357634938]
	TIME [epoch: 9.23 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011304963075215358		[learning rate: 0.00039701]
	Learning Rate: 0.000397009
	LOSS [training: 0.011304963075215358 | validation: 0.009590913736094303]
	TIME [epoch: 9.22 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009005353316985225		[learning rate: 0.00039579]
	Learning Rate: 0.000395792
	LOSS [training: 0.009005353316985225 | validation: 0.013632194032402132]
	TIME [epoch: 9.23 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008089310307967976		[learning rate: 0.00039458]
	Learning Rate: 0.000394578
	LOSS [training: 0.008089310307967976 | validation: 0.01799219770822226]
	TIME [epoch: 9.22 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00806220347699614		[learning rate: 0.00039337]
	Learning Rate: 0.000393369
	LOSS [training: 0.00806220347699614 | validation: 0.01612394581298575]
	TIME [epoch: 9.24 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010262795972093163		[learning rate: 0.00039216]
	Learning Rate: 0.000392163
	LOSS [training: 0.010262795972093163 | validation: 0.0198964544978602]
	TIME [epoch: 9.23 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010441602071948287		[learning rate: 0.00039096]
	Learning Rate: 0.000390961
	LOSS [training: 0.010441602071948287 | validation: 0.016083733208139044]
	TIME [epoch: 9.23 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00402924050217616		[learning rate: 0.00038976]
	Learning Rate: 0.000389762
	LOSS [training: 0.00402924050217616 | validation: 0.0063385667349684085]
	TIME [epoch: 9.23 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010007249476243313		[learning rate: 0.00038857]
	Learning Rate: 0.000388568
	LOSS [training: 0.010007249476243313 | validation: 0.013574348524927844]
	TIME [epoch: 9.23 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01389980449613803		[learning rate: 0.00038738]
	Learning Rate: 0.000387377
	LOSS [training: 0.01389980449613803 | validation: 0.01703765156610683]
	TIME [epoch: 9.25 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012160518736787012		[learning rate: 0.00038619]
	Learning Rate: 0.000386189
	LOSS [training: 0.012160518736787012 | validation: 0.019455766608756753]
	TIME [epoch: 9.23 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013401887335502228		[learning rate: 0.00038501]
	Learning Rate: 0.000385005
	LOSS [training: 0.013401887335502228 | validation: 0.016227010525530126]
	TIME [epoch: 9.22 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014992646021979522		[learning rate: 0.00038382]
	Learning Rate: 0.000383825
	LOSS [training: 0.014992646021979522 | validation: 0.023568751816694572]
	TIME [epoch: 9.23 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013751439057499495		[learning rate: 0.00038265]
	Learning Rate: 0.000382649
	LOSS [training: 0.013751439057499495 | validation: 0.023115442369044836]
	TIME [epoch: 9.22 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011921652723442835		[learning rate: 0.00038148]
	Learning Rate: 0.000381476
	LOSS [training: 0.011921652723442835 | validation: 0.01982917568702566]
	TIME [epoch: 9.25 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00852135530800301		[learning rate: 0.00038031]
	Learning Rate: 0.000380306
	LOSS [training: 0.00852135530800301 | validation: 0.028730526299470302]
	TIME [epoch: 9.22 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00947602461548627		[learning rate: 0.00037914]
	Learning Rate: 0.00037914
	LOSS [training: 0.00947602461548627 | validation: 0.012302384272994448]
	TIME [epoch: 9.24 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003881578669914307		[learning rate: 0.00037798]
	Learning Rate: 0.000377978
	LOSS [training: 0.003881578669914307 | validation: 0.004353712072546249]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1567.pth
	Model improved!!!
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008645952382910263		[learning rate: 0.00037682]
	Learning Rate: 0.000376819
	LOSS [training: 0.008645952382910263 | validation: 0.007860356533650288]
	TIME [epoch: 9.23 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004775312933884109		[learning rate: 0.00037566]
	Learning Rate: 0.000375664
	LOSS [training: 0.004775312933884109 | validation: 0.015014986918162408]
	TIME [epoch: 9.25 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00891647263709689		[learning rate: 0.00037451]
	Learning Rate: 0.000374513
	LOSS [training: 0.00891647263709689 | validation: 0.025446084749295564]
	TIME [epoch: 9.22 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007017598226428804		[learning rate: 0.00037336]
	Learning Rate: 0.000373365
	LOSS [training: 0.007017598226428804 | validation: 0.01774371532738862]
	TIME [epoch: 9.22 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008076807232508454		[learning rate: 0.00037222]
	Learning Rate: 0.00037222
	LOSS [training: 0.008076807232508454 | validation: 0.01321229080166229]
	TIME [epoch: 9.22 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004082843841626692		[learning rate: 0.00037108]
	Learning Rate: 0.000371079
	LOSS [training: 0.004082843841626692 | validation: 0.013104268043356165]
	TIME [epoch: 9.24 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005202107006164215		[learning rate: 0.00036994]
	Learning Rate: 0.000369942
	LOSS [training: 0.005202107006164215 | validation: 0.018173609076572624]
	TIME [epoch: 9.24 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004259188732823424		[learning rate: 0.00036881]
	Learning Rate: 0.000368808
	LOSS [training: 0.004259188732823424 | validation: 0.022874467612206906]
	TIME [epoch: 9.22 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006585673965859182		[learning rate: 0.00036768]
	Learning Rate: 0.000367677
	LOSS [training: 0.006585673965859182 | validation: 0.01045460709180284]
	TIME [epoch: 9.23 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00870722139757168		[learning rate: 0.00036655]
	Learning Rate: 0.00036655
	LOSS [training: 0.00870722139757168 | validation: 0.016063124382578724]
	TIME [epoch: 9.23 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006727231692115317		[learning rate: 0.00036543]
	Learning Rate: 0.000365426
	LOSS [training: 0.006727231692115317 | validation: 0.017777952787145262]
	TIME [epoch: 9.25 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005660503545605422		[learning rate: 0.00036431]
	Learning Rate: 0.000364306
	LOSS [training: 0.005660503545605422 | validation: 0.015892508903529366]
	TIME [epoch: 9.23 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006684583871156925		[learning rate: 0.00036319]
	Learning Rate: 0.00036319
	LOSS [training: 0.006684583871156925 | validation: 0.011674185836635109]
	TIME [epoch: 9.23 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0056180708293935505		[learning rate: 0.00036208]
	Learning Rate: 0.000362076
	LOSS [training: 0.0056180708293935505 | validation: 0.01633022312234641]
	TIME [epoch: 9.23 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007006590621574145		[learning rate: 0.00036097]
	Learning Rate: 0.000360966
	LOSS [training: 0.007006590621574145 | validation: 0.013295768793016235]
	TIME [epoch: 9.23 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009469181586665399		[learning rate: 0.00035986]
	Learning Rate: 0.00035986
	LOSS [training: 0.009469181586665399 | validation: 0.007250937905261478]
	TIME [epoch: 9.24 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007164531290543634		[learning rate: 0.00035876]
	Learning Rate: 0.000358757
	LOSS [training: 0.007164531290543634 | validation: 0.01301446213931386]
	TIME [epoch: 9.23 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0036549683274099353		[learning rate: 0.00035766]
	Learning Rate: 0.000357657
	LOSS [training: 0.0036549683274099353 | validation: 0.01846107923720613]
	TIME [epoch: 9.23 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005194083149064979		[learning rate: 0.00035656]
	Learning Rate: 0.000356561
	LOSS [training: 0.005194083149064979 | validation: 0.019010974456474223]
	TIME [epoch: 9.23 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004622084211175938		[learning rate: 0.00035547]
	Learning Rate: 0.000355468
	LOSS [training: 0.004622084211175938 | validation: 0.008901109677467496]
	TIME [epoch: 9.23 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009029815123452932		[learning rate: 0.00035438]
	Learning Rate: 0.000354378
	LOSS [training: 0.009029815123452932 | validation: 0.01996705995544412]
	TIME [epoch: 9.25 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006964157494210183		[learning rate: 0.00035329]
	Learning Rate: 0.000353292
	LOSS [training: 0.006964157494210183 | validation: 0.012401110027056895]
	TIME [epoch: 9.24 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014558193628524804		[learning rate: 0.00035221]
	Learning Rate: 0.000352209
	LOSS [training: 0.014558193628524804 | validation: 0.02315701797817214]
	TIME [epoch: 9.22 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014670795444876136		[learning rate: 0.00035113]
	Learning Rate: 0.000351129
	LOSS [training: 0.014670795444876136 | validation: 0.027947215591686586]
	TIME [epoch: 9.22 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0337067007739756		[learning rate: 0.00035005]
	Learning Rate: 0.000350053
	LOSS [training: 0.0337067007739756 | validation: 0.048655381952569784]
	TIME [epoch: 9.23 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023826240034824697		[learning rate: 0.00034898]
	Learning Rate: 0.000348979
	LOSS [training: 0.023826240034824697 | validation: 0.024109784701515376]
	TIME [epoch: 9.25 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01456583236390594		[learning rate: 0.00034791]
	Learning Rate: 0.00034791
	LOSS [training: 0.01456583236390594 | validation: 0.012777731236190464]
	TIME [epoch: 9.23 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01263705099150223		[learning rate: 0.00034684]
	Learning Rate: 0.000346843
	LOSS [training: 0.01263705099150223 | validation: 0.02033087588939378]
	TIME [epoch: 9.24 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010828569643579334		[learning rate: 0.00034578]
	Learning Rate: 0.00034578
	LOSS [training: 0.010828569643579334 | validation: 0.017644497646023806]
	TIME [epoch: 9.22 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010608559829610153		[learning rate: 0.00034472]
	Learning Rate: 0.00034472
	LOSS [training: 0.010608559829610153 | validation: 0.014063983834595725]
	TIME [epoch: 9.23 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008214376355960487		[learning rate: 0.00034366]
	Learning Rate: 0.000343663
	LOSS [training: 0.008214376355960487 | validation: 0.013326922096076294]
	TIME [epoch: 9.25 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012355467058856944		[learning rate: 0.00034261]
	Learning Rate: 0.00034261
	LOSS [training: 0.012355467058856944 | validation: 0.02307523761740263]
	TIME [epoch: 9.24 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014537342023045135		[learning rate: 0.00034156]
	Learning Rate: 0.00034156
	LOSS [training: 0.014537342023045135 | validation: 0.019654947855420508]
	TIME [epoch: 9.23 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019962980128541467		[learning rate: 0.00034051]
	Learning Rate: 0.000340513
	LOSS [training: 0.019962980128541467 | validation: 0.035637649410899475]
	TIME [epoch: 9.23 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015895926445463643		[learning rate: 0.00033947]
	Learning Rate: 0.000339469
	LOSS [training: 0.015895926445463643 | validation: 0.025250806356844558]
	TIME [epoch: 9.23 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009583235222445547		[learning rate: 0.00033843]
	Learning Rate: 0.000338428
	LOSS [training: 0.009583235222445547 | validation: 0.012640894614630756]
	TIME [epoch: 9.25 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007186357868690901		[learning rate: 0.00033739]
	Learning Rate: 0.000337391
	LOSS [training: 0.007186357868690901 | validation: 0.019018517288057764]
	TIME [epoch: 9.24 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008915475020503702		[learning rate: 0.00033636]
	Learning Rate: 0.000336357
	LOSS [training: 0.008915475020503702 | validation: 0.02544026572613375]
	TIME [epoch: 9.22 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005786483684125929		[learning rate: 0.00033533]
	Learning Rate: 0.000335326
	LOSS [training: 0.005786483684125929 | validation: 0.01652639128767294]
	TIME [epoch: 9.23 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0086241945248814		[learning rate: 0.0003343]
	Learning Rate: 0.000334298
	LOSS [training: 0.0086241945248814 | validation: 0.02127171969903724]
	TIME [epoch: 9.23 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015658540014506922		[learning rate: 0.00033327]
	Learning Rate: 0.000333273
	LOSS [training: 0.015658540014506922 | validation: 0.015488215288612477]
	TIME [epoch: 9.25 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010475657952457617		[learning rate: 0.00033225]
	Learning Rate: 0.000332251
	LOSS [training: 0.010475657952457617 | validation: 0.011935507741806736]
	TIME [epoch: 9.23 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00743701893023079		[learning rate: 0.00033123]
	Learning Rate: 0.000331233
	LOSS [training: 0.00743701893023079 | validation: 0.018926042048616247]
	TIME [epoch: 9.22 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011753499678235742		[learning rate: 0.00033022]
	Learning Rate: 0.000330217
	LOSS [training: 0.011753499678235742 | validation: 0.021051397063529764]
	TIME [epoch: 9.22 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01044463136050874		[learning rate: 0.00032921]
	Learning Rate: 0.000329205
	LOSS [training: 0.01044463136050874 | validation: 0.026203713237708127]
	TIME [epoch: 9.22 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01251175611652022		[learning rate: 0.0003282]
	Learning Rate: 0.000328196
	LOSS [training: 0.01251175611652022 | validation: 0.019243603296981365]
	TIME [epoch: 9.25 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011356683799967812		[learning rate: 0.00032719]
	Learning Rate: 0.00032719
	LOSS [training: 0.011356683799967812 | validation: 0.015497952265594828]
	TIME [epoch: 9.28 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00822128065606399		[learning rate: 0.00032619]
	Learning Rate: 0.000326187
	LOSS [training: 0.00822128065606399 | validation: 0.024796438858637193]
	TIME [epoch: 9.22 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0046059574298451		[learning rate: 0.00032519]
	Learning Rate: 0.000325187
	LOSS [training: 0.0046059574298451 | validation: 0.01716929739875589]
	TIME [epoch: 9.23 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004475535964574167		[learning rate: 0.00032419]
	Learning Rate: 0.00032419
	LOSS [training: 0.004475535964574167 | validation: 0.023021110187013]
	TIME [epoch: 9.23 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012326962862640373		[learning rate: 0.0003232]
	Learning Rate: 0.000323196
	LOSS [training: 0.012326962862640373 | validation: 0.015716519798687923]
	TIME [epoch: 9.26 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01192934957938746		[learning rate: 0.00032221]
	Learning Rate: 0.000322206
	LOSS [training: 0.01192934957938746 | validation: 0.022270209081145874]
	TIME [epoch: 9.24 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010209375183220942		[learning rate: 0.00032122]
	Learning Rate: 0.000321218
	LOSS [training: 0.010209375183220942 | validation: 0.024235743961870573]
	TIME [epoch: 9.24 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010167000860743337		[learning rate: 0.00032023]
	Learning Rate: 0.000320233
	LOSS [training: 0.010167000860743337 | validation: 0.0172125148997995]
	TIME [epoch: 9.23 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012945014709327083		[learning rate: 0.00031925]
	Learning Rate: 0.000319252
	LOSS [training: 0.012945014709327083 | validation: 0.017499432681362673]
	TIME [epoch: 9.23 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014063843623947428		[learning rate: 0.00031827]
	Learning Rate: 0.000318273
	LOSS [training: 0.014063843623947428 | validation: 0.012957599543829633]
	TIME [epoch: 9.25 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010285012926819447		[learning rate: 0.0003173]
	Learning Rate: 0.000317297
	LOSS [training: 0.010285012926819447 | validation: 0.022295632902347803]
	TIME [epoch: 9.23 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0056977980984759865		[learning rate: 0.00031632]
	Learning Rate: 0.000316325
	LOSS [training: 0.0056977980984759865 | validation: 0.020577528613801493]
	TIME [epoch: 9.23 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008079854596538247		[learning rate: 0.00031536]
	Learning Rate: 0.000315355
	LOSS [training: 0.008079854596538247 | validation: 0.019814000689801145]
	TIME [epoch: 9.23 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0046151729864683895		[learning rate: 0.00031439]
	Learning Rate: 0.000314389
	LOSS [training: 0.0046151729864683895 | validation: 0.010321762323674762]
	TIME [epoch: 9.24 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005385954753170405		[learning rate: 0.00031342]
	Learning Rate: 0.000313425
	LOSS [training: 0.005385954753170405 | validation: 0.02461876072139267]
	TIME [epoch: 9.24 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006699831992379833		[learning rate: 0.00031246]
	Learning Rate: 0.000312464
	LOSS [training: 0.006699831992379833 | validation: 0.006190276823500291]
	TIME [epoch: 9.23 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0071210986176496		[learning rate: 0.00031151]
	Learning Rate: 0.000311506
	LOSS [training: 0.0071210986176496 | validation: 0.013365953124973452]
	TIME [epoch: 9.23 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009019023520701578		[learning rate: 0.00031055]
	Learning Rate: 0.000310551
	LOSS [training: 0.009019023520701578 | validation: 0.01963123956018347]
	TIME [epoch: 9.22 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0064691438167849185		[learning rate: 0.0003096]
	Learning Rate: 0.000309599
	LOSS [training: 0.0064691438167849185 | validation: 0.01497103530905947]
	TIME [epoch: 9.23 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005548747791980716		[learning rate: 0.00030865]
	Learning Rate: 0.00030865
	LOSS [training: 0.005548747791980716 | validation: 0.013942505134160621]
	TIME [epoch: 9.22 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009788257170225904		[learning rate: 0.0003077]
	Learning Rate: 0.000307704
	LOSS [training: 0.009788257170225904 | validation: 0.017232936885925837]
	TIME [epoch: 9.21 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0026699426946857037		[learning rate: 0.00030676]
	Learning Rate: 0.000306761
	LOSS [training: 0.0026699426946857037 | validation: 0.010645287076272235]
	TIME [epoch: 9.23 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006032508673862444		[learning rate: 0.00030582]
	Learning Rate: 0.00030582
	LOSS [training: -0.0006032508673862444 | validation: 0.016745549825128776]
	TIME [epoch: 9.23 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005234841170632904		[learning rate: 0.00030488]
	Learning Rate: 0.000304883
	LOSS [training: 0.005234841170632904 | validation: 0.01728953615286975]
	TIME [epoch: 9.24 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0056138275556358325		[learning rate: 0.00030395]
	Learning Rate: 0.000303948
	LOSS [training: 0.0056138275556358325 | validation: 0.010888342028511622]
	TIME [epoch: 9.23 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015192471410227367		[learning rate: 0.00030302]
	Learning Rate: 0.000303017
	LOSS [training: 0.0015192471410227367 | validation: 0.011990724232374747]
	TIME [epoch: 9.23 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006240408369056802		[learning rate: 0.00030209]
	Learning Rate: 0.000302088
	LOSS [training: 0.006240408369056802 | validation: 0.020069470955219642]
	TIME [epoch: 9.22 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003810684316202669		[learning rate: 0.00030116]
	Learning Rate: 0.000301162
	LOSS [training: 0.003810684316202669 | validation: 0.014923930943645192]
	TIME [epoch: 9.23 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0024089500497655467		[learning rate: 0.00030024]
	Learning Rate: 0.000300239
	LOSS [training: 0.0024089500497655467 | validation: 0.008306395159832284]
	TIME [epoch: 9.25 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0068465398094765175		[learning rate: 0.00029932]
	Learning Rate: 0.000299318
	LOSS [training: 0.0068465398094765175 | validation: 0.008243429406042682]
	TIME [epoch: 9.24 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006910728546075204		[learning rate: 0.0002984]
	Learning Rate: 0.000298401
	LOSS [training: 0.006910728546075204 | validation: 0.01732884339965739]
	TIME [epoch: 9.23 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006179653409817612		[learning rate: 0.00029749]
	Learning Rate: 0.000297486
	LOSS [training: 0.006179653409817612 | validation: 0.0028320715730294674]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1645.pth
	Model improved!!!
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008659803671592655		[learning rate: 0.00029657]
	Learning Rate: 0.000296574
	LOSS [training: 0.008659803671592655 | validation: 0.008091003610984025]
	TIME [epoch: 9.23 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005319803015735409		[learning rate: 0.00029567]
	Learning Rate: 0.000295665
	LOSS [training: 0.005319803015735409 | validation: 0.017813624187410514]
	TIME [epoch: 9.25 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014316525593900628		[learning rate: 0.00029476]
	Learning Rate: 0.000294759
	LOSS [training: 0.014316525593900628 | validation: 0.014474856120733886]
	TIME [epoch: 9.23 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009988271723586527		[learning rate: 0.00029386]
	Learning Rate: 0.000293855
	LOSS [training: 0.009988271723586527 | validation: 0.02413989086753625]
	TIME [epoch: 9.23 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0079886472743001		[learning rate: 0.00029295]
	Learning Rate: 0.000292954
	LOSS [training: 0.0079886472743001 | validation: 0.014076687884946665]
	TIME [epoch: 9.22 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007982486554680885		[learning rate: 0.00029206]
	Learning Rate: 0.000292056
	LOSS [training: 0.007982486554680885 | validation: 0.0219008183260032]
	TIME [epoch: 9.22 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008701059485588292		[learning rate: 0.00029116]
	Learning Rate: 0.000291161
	LOSS [training: 0.008701059485588292 | validation: 0.016371511646642876]
	TIME [epoch: 9.23 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0020523363607624946		[learning rate: 0.00029027]
	Learning Rate: 0.000290269
	LOSS [training: 0.0020523363607624946 | validation: 0.014290064676693335]
	TIME [epoch: 9.22 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0045052792090129285		[learning rate: 0.00028938]
	Learning Rate: 0.000289379
	LOSS [training: 0.0045052792090129285 | validation: 0.018773662397190728]
	TIME [epoch: 9.22 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006660451940084043		[learning rate: 0.00028849]
	Learning Rate: 0.000288492
	LOSS [training: 0.006660451940084043 | validation: 0.007073677440472718]
	TIME [epoch: 9.22 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018751462085427803		[learning rate: 0.00028761]
	Learning Rate: 0.000287607
	LOSS [training: 0.0018751462085427803 | validation: 0.009837740099635882]
	TIME [epoch: 9.22 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0012451542341754243		[learning rate: 0.00028673]
	Learning Rate: 0.000286726
	LOSS [training: 0.0012451542341754243 | validation: 0.009572520576424525]
	TIME [epoch: 9.24 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003165615785343538		[learning rate: 0.00028585]
	Learning Rate: 0.000285847
	LOSS [training: 0.003165615785343538 | validation: 0.01208080805764465]
	TIME [epoch: 9.22 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012103427875609547		[learning rate: 0.00028497]
	Learning Rate: 0.000284971
	LOSS [training: 0.012103427875609547 | validation: 0.022799285997841513]
	TIME [epoch: 9.22 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008127384753145606		[learning rate: 0.0002841]
	Learning Rate: 0.000284097
	LOSS [training: 0.008127384753145606 | validation: 0.024749365414309443]
	TIME [epoch: 9.22 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00418811674573669		[learning rate: 0.00028323]
	Learning Rate: 0.000283226
	LOSS [training: 0.00418811674573669 | validation: 0.028922346778208624]
	TIME [epoch: 9.22 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0049889059923321055		[learning rate: 0.00028236]
	Learning Rate: 0.000282358
	LOSS [training: 0.0049889059923321055 | validation: 0.013288218008566334]
	TIME [epoch: 9.24 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00803165377663122		[learning rate: 0.00028149]
	Learning Rate: 0.000281492
	LOSS [training: 0.00803165377663122 | validation: 0.003751343560402868]
	TIME [epoch: 9.22 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004134942193622425		[learning rate: 0.00028063]
	Learning Rate: 0.000280629
	LOSS [training: 0.004134942193622425 | validation: 0.007739805460567968]
	TIME [epoch: 9.23 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00045891858343008517		[learning rate: 0.00027977]
	Learning Rate: 0.000279769
	LOSS [training: -0.00045891858343008517 | validation: 0.020232544925725623]
	TIME [epoch: 9.22 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007071478562370594		[learning rate: 0.00027891]
	Learning Rate: 0.000278912
	LOSS [training: 0.007071478562370594 | validation: 0.01791048619898538]
	TIME [epoch: 9.22 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0036406818243369123		[learning rate: 0.00027806]
	Learning Rate: 0.000278057
	LOSS [training: 0.0036406818243369123 | validation: 0.008350401993233971]
	TIME [epoch: 9.25 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002957657303047941		[learning rate: 0.0002772]
	Learning Rate: 0.000277204
	LOSS [training: 0.002957657303047941 | validation: 0.011921035946839109]
	TIME [epoch: 9.23 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006775450071750863		[learning rate: 0.00027635]
	Learning Rate: 0.000276355
	LOSS [training: 0.006775450071750863 | validation: 0.018457119464134565]
	TIME [epoch: 9.22 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006193038451003383		[learning rate: 0.00027551]
	Learning Rate: 0.000275507
	LOSS [training: 0.006193038451003383 | validation: 0.014982339156296076]
	TIME [epoch: 9.24 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010668396800556519		[learning rate: 0.00027466]
	Learning Rate: 0.000274663
	LOSS [training: 0.010668396800556519 | validation: 0.011562647183128757]
	TIME [epoch: 9.23 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006430367548285495		[learning rate: 0.00027382]
	Learning Rate: 0.000273821
	LOSS [training: 0.006430367548285495 | validation: 0.005261206864459268]
	TIME [epoch: 9.25 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005174545885993075		[learning rate: 0.00027298]
	Learning Rate: 0.000272982
	LOSS [training: 0.005174545885993075 | validation: 0.022613707864020477]
	TIME [epoch: 9.22 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008849972360978852		[learning rate: 0.00027214]
	Learning Rate: 0.000272145
	LOSS [training: 0.008849972360978852 | validation: 0.01902330130288102]
	TIME [epoch: 9.23 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00823967343882053		[learning rate: 0.00027131]
	Learning Rate: 0.000271311
	LOSS [training: 0.00823967343882053 | validation: 0.016234078789908152]
	TIME [epoch: 9.23 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007610409688137922		[learning rate: 0.00027048]
	Learning Rate: 0.000270479
	LOSS [training: 0.007610409688137922 | validation: 0.006660816332647405]
	TIME [epoch: 9.23 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005454194367630881		[learning rate: 0.00026965]
	Learning Rate: 0.00026965
	LOSS [training: 0.005454194367630881 | validation: 0.019947000324741736]
	TIME [epoch: 9.25 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0027942518698316514		[learning rate: 0.00026882]
	Learning Rate: 0.000268823
	LOSS [training: 0.0027942518698316514 | validation: 0.010586198655733861]
	TIME [epoch: 9.23 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0027932572820862887		[learning rate: 0.000268]
	Learning Rate: 0.000267999
	LOSS [training: 0.0027932572820862887 | validation: 0.02295384368279116]
	TIME [epoch: 9.23 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00452004964811074		[learning rate: 0.00026718]
	Learning Rate: 0.000267178
	LOSS [training: 0.00452004964811074 | validation: 0.008747304163097875]
	TIME [epoch: 9.23 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009079783089648812		[learning rate: 0.00026636]
	Learning Rate: 0.000266359
	LOSS [training: 0.009079783089648812 | validation: 0.0037551808246693626]
	TIME [epoch: 9.24 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005437758693102422		[learning rate: 0.00026554]
	Learning Rate: 0.000265542
	LOSS [training: 0.005437758693102422 | validation: 0.014685814899289627]
	TIME [epoch: 9.24 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004814457921025863		[learning rate: 0.00026473]
	Learning Rate: 0.000264728
	LOSS [training: 0.004814457921025863 | validation: 0.011371975014264658]
	TIME [epoch: 9.23 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00441271475571108		[learning rate: 0.00026392]
	Learning Rate: 0.000263917
	LOSS [training: 0.00441271475571108 | validation: 0.02460305029138101]
	TIME [epoch: 9.22 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004779067446993914		[learning rate: 0.00026311]
	Learning Rate: 0.000263108
	LOSS [training: 0.004779067446993914 | validation: 0.011865549836400166]
	TIME [epoch: 9.23 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029759447927606964		[learning rate: 0.0002623]
	Learning Rate: 0.000262301
	LOSS [training: 0.0029759447927606964 | validation: 0.005272833112785681]
	TIME [epoch: 9.25 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009965546716798373		[learning rate: 0.0002615]
	Learning Rate: 0.000261497
	LOSS [training: 0.009965546716798373 | validation: 0.002235951128678875]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1687.pth
	Model improved!!!
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00411875462459271		[learning rate: 0.0002607]
	Learning Rate: 0.000260695
	LOSS [training: 0.00411875462459271 | validation: 0.015411015160256055]
	TIME [epoch: 9.3 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00639743311944941		[learning rate: 0.0002599]
	Learning Rate: 0.000259896
	LOSS [training: 0.00639743311944941 | validation: 0.0210956489679663]
	TIME [epoch: 9.23 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0030944512595901417		[learning rate: 0.0002591]
	Learning Rate: 0.0002591
	LOSS [training: 0.0030944512595901417 | validation: 0.00561982945342275]
	TIME [epoch: 9.24 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004075838468666954		[learning rate: 0.00025831]
	Learning Rate: 0.000258305
	LOSS [training: 0.004075838468666954 | validation: 0.013591080500123084]
	TIME [epoch: 9.25 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008168311169160853		[learning rate: 0.00025751]
	Learning Rate: 0.000257513
	LOSS [training: 0.008168311169160853 | validation: 0.009044923952234723]
	TIME [epoch: 9.24 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008384920052589603		[learning rate: 0.00025672]
	Learning Rate: 0.000256724
	LOSS [training: 0.008384920052589603 | validation: 0.01370609604378312]
	TIME [epoch: 9.22 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005779369204452543		[learning rate: 0.00025594]
	Learning Rate: 0.000255937
	LOSS [training: 0.005779369204452543 | validation: 0.00554339273153936]
	TIME [epoch: 9.23 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006229930956746828		[learning rate: 0.00025515]
	Learning Rate: 0.000255153
	LOSS [training: 0.006229930956746828 | validation: 0.02145478596254826]
	TIME [epoch: 9.22 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004005122737978885		[learning rate: 0.00025437]
	Learning Rate: 0.00025437
	LOSS [training: 0.004005122737978885 | validation: 0.014163113735953074]
	TIME [epoch: 9.26 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007357676346426046		[learning rate: 0.00025359]
	Learning Rate: 0.000253591
	LOSS [training: 0.007357676346426046 | validation: 0.015554370256576626]
	TIME [epoch: 9.24 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005857557796685122		[learning rate: 0.00025281]
	Learning Rate: 0.000252813
	LOSS [training: 0.005857557796685122 | validation: 0.009454527360400707]
	TIME [epoch: 9.23 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0015220423281721868		[learning rate: 0.00025204]
	Learning Rate: 0.000252038
	LOSS [training: -0.0015220423281721868 | validation: 0.009677100633810396]
	TIME [epoch: 9.23 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0034860514322702894		[learning rate: 0.00025127]
	Learning Rate: 0.000251266
	LOSS [training: 0.0034860514322702894 | validation: 0.01279790902736327]
	TIME [epoch: 9.23 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004524906182913855		[learning rate: 0.0002505]
	Learning Rate: 0.000250496
	LOSS [training: 0.004524906182913855 | validation: 0.01158960448094775]
	TIME [epoch: 9.25 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00555006101525284		[learning rate: 0.00024973]
	Learning Rate: 0.000249728
	LOSS [training: 0.00555006101525284 | validation: 0.016407567931517215]
	TIME [epoch: 9.24 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012533458911662026		[learning rate: 0.00024896]
	Learning Rate: 0.000248962
	LOSS [training: 0.012533458911662026 | validation: 0.01352121232963481]
	TIME [epoch: 9.23 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007880478302261346		[learning rate: 0.0002482]
	Learning Rate: 0.000248199
	LOSS [training: 0.007880478302261346 | validation: 0.006765994452466706]
	TIME [epoch: 9.23 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012308837875709484		[learning rate: 0.00024744]
	Learning Rate: 0.000247438
	LOSS [training: 0.012308837875709484 | validation: 0.021230749751035786]
	TIME [epoch: 9.23 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012874887191952103		[learning rate: 0.00024668]
	Learning Rate: 0.00024668
	LOSS [training: 0.012874887191952103 | validation: 0.019719153298051625]
	TIME [epoch: 9.25 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005036245092045662		[learning rate: 0.00024592]
	Learning Rate: 0.000245923
	LOSS [training: 0.005036245092045662 | validation: 0.012242203434250837]
	TIME [epoch: 9.24 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0030718188381935936		[learning rate: 0.00024517]
	Learning Rate: 0.00024517
	LOSS [training: 0.0030718188381935936 | validation: 0.0015726570552797104]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1708.pth
	Model improved!!!
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007625591354019257		[learning rate: 0.00024442]
	Learning Rate: 0.000244418
	LOSS [training: 0.007625591354019257 | validation: 0.010917150426162776]
	TIME [epoch: 9.23 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007018235171079715		[learning rate: 0.00024367]
	Learning Rate: 0.000243669
	LOSS [training: 0.007018235171079715 | validation: 0.0031182466828226533]
	TIME [epoch: 9.23 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014860355723478203		[learning rate: 0.00024292]
	Learning Rate: 0.000242922
	LOSS [training: 0.0014860355723478203 | validation: 0.008282804778640723]
	TIME [epoch: 9.27 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006265325214423995		[learning rate: 0.00024218]
	Learning Rate: 0.000242177
	LOSS [training: 0.006265325214423995 | validation: 0.016543720287274785]
	TIME [epoch: 9.19 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009648462058970249		[learning rate: 0.00024143]
	Learning Rate: 0.000241435
	LOSS [training: 0.009648462058970249 | validation: 0.013563516689565569]
	TIME [epoch: 9.35 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00655444860206624		[learning rate: 0.00024069]
	Learning Rate: 0.000240695
	LOSS [training: 0.00655444860206624 | validation: 0.009121082652088656]
	TIME [epoch: 9.24 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007298436583175907		[learning rate: 0.00023996]
	Learning Rate: 0.000239957
	LOSS [training: 0.007298436583175907 | validation: 0.012249182164911476]
	TIME [epoch: 9.24 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01064324737518787		[learning rate: 0.00023922]
	Learning Rate: 0.000239221
	LOSS [training: 0.01064324737518787 | validation: 0.010584356057038388]
	TIME [epoch: 9.26 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012903864672123958		[learning rate: 0.00023849]
	Learning Rate: 0.000238488
	LOSS [training: 0.012903864672123958 | validation: 0.013162231326065803]
	TIME [epoch: 9.23 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009052390666194909		[learning rate: 0.00023776]
	Learning Rate: 0.000237757
	LOSS [training: 0.009052390666194909 | validation: 0.003966135423831965]
	TIME [epoch: 9.23 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0059610181966098		[learning rate: 0.00023703]
	Learning Rate: 0.000237028
	LOSS [training: 0.0059610181966098 | validation: 0.006197958570778052]
	TIME [epoch: 9.24 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014384679642245143		[learning rate: 0.0002363]
	Learning Rate: 0.000236302
	LOSS [training: 0.014384679642245143 | validation: 0.01367776142841071]
	TIME [epoch: 9.24 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010052381012760212		[learning rate: 0.00023558]
	Learning Rate: 0.000235577
	LOSS [training: 0.010052381012760212 | validation: 0.012603082697577768]
	TIME [epoch: 9.27 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007366738541527973		[learning rate: 0.00023486]
	Learning Rate: 0.000234855
	LOSS [training: 0.007366738541527973 | validation: 0.022871778255797934]
	TIME [epoch: 9.24 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0080489511806926		[learning rate: 0.00023414]
	Learning Rate: 0.000234135
	LOSS [training: 0.0080489511806926 | validation: 0.005458837706683598]
	TIME [epoch: 9.23 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008956009140934524		[learning rate: 0.00023342]
	Learning Rate: 0.000233417
	LOSS [training: 0.008956009140934524 | validation: -0.00026624809124536734]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1724.pth
	Model improved!!!
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0052291346974574		[learning rate: 0.0002327]
	Learning Rate: 0.000232702
	LOSS [training: 0.0052291346974574 | validation: 0.011055066604127042]
	TIME [epoch: 9.24 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005617027440812908		[learning rate: 0.00023199]
	Learning Rate: 0.000231989
	LOSS [training: 0.005617027440812908 | validation: 0.008037197957052617]
	TIME [epoch: 9.24 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002993884678105824		[learning rate: 0.00023128]
	Learning Rate: 0.000231277
	LOSS [training: 0.002993884678105824 | validation: 0.006072236725007265]
	TIME [epoch: 9.23 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007275964627654724		[learning rate: 0.00023057]
	Learning Rate: 0.000230569
	LOSS [training: 0.007275964627654724 | validation: 0.020005534137317746]
	TIME [epoch: 9.23 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00590444506172937		[learning rate: 0.00022986]
	Learning Rate: 0.000229862
	LOSS [training: 0.00590444506172937 | validation: 0.011106786256369183]
	TIME [epoch: 9.22 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008677176139641212		[learning rate: 0.00022916]
	Learning Rate: 0.000229157
	LOSS [training: 0.008677176139641212 | validation: 0.009096481772158618]
	TIME [epoch: 9.24 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010367253018865148		[learning rate: 0.00022845]
	Learning Rate: 0.000228455
	LOSS [training: 0.0010367253018865148 | validation: 0.01650606088813881]
	TIME [epoch: 9.23 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008962133000353823		[learning rate: 0.00022775]
	Learning Rate: 0.000227754
	LOSS [training: 0.008962133000353823 | validation: 0.01490502242625679]
	TIME [epoch: 9.22 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00880057739588096		[learning rate: 0.00022706]
	Learning Rate: 0.000227056
	LOSS [training: 0.00880057739588096 | validation: 0.021428462555457693]
	TIME [epoch: 9.22 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009505432605876872		[learning rate: 0.00022636]
	Learning Rate: 0.00022636
	LOSS [training: 0.009505432605876872 | validation: 0.012742011701554805]
	TIME [epoch: 9.22 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007538850109260917		[learning rate: 0.00022567]
	Learning Rate: 0.000225666
	LOSS [training: 0.007538850109260917 | validation: 0.006758451795386406]
	TIME [epoch: 9.24 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0114322743721204		[learning rate: 0.00022497]
	Learning Rate: 0.000224974
	LOSS [training: 0.0114322743721204 | validation: 0.010002290725773404]
	TIME [epoch: 9.23 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009987711156156459		[learning rate: 0.00022428]
	Learning Rate: 0.000224285
	LOSS [training: 0.009987711156156459 | validation: 0.014385213708934955]
	TIME [epoch: 9.23 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012360407125245918		[learning rate: 0.0002236]
	Learning Rate: 0.000223597
	LOSS [training: 0.012360407125245918 | validation: 0.0195359305675967]
	TIME [epoch: 9.24 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015606123123354316		[learning rate: 0.00022291]
	Learning Rate: 0.000222912
	LOSS [training: 0.015606123123354316 | validation: 0.014688723687248433]
	TIME [epoch: 9.22 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010966688169767957		[learning rate: 0.00022223]
	Learning Rate: 0.000222229
	LOSS [training: 0.010966688169767957 | validation: 0.012350208718644975]
	TIME [epoch: 9.24 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0089166509785093		[learning rate: 0.00022155]
	Learning Rate: 0.000221547
	LOSS [training: 0.0089166509785093 | validation: 0.009387193618737782]
	TIME [epoch: 9.23 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012023076396374737		[learning rate: 0.00022087]
	Learning Rate: 0.000220868
	LOSS [training: 0.012023076396374737 | validation: 0.006345843553921124]
	TIME [epoch: 9.23 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011627784219077725		[learning rate: 0.00022019]
	Learning Rate: 0.000220191
	LOSS [training: 0.011627784219077725 | validation: 0.015553089152046777]
	TIME [epoch: 9.23 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009022764143004961		[learning rate: 0.00021952]
	Learning Rate: 0.000219516
	LOSS [training: 0.009022764143004961 | validation: 0.012198174691998298]
	TIME [epoch: 9.22 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011046613261390305		[learning rate: 0.00021884]
	Learning Rate: 0.000218843
	LOSS [training: 0.011046613261390305 | validation: 0.014865127641258618]
	TIME [epoch: 9.24 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011796270700891592		[learning rate: 0.00021817]
	Learning Rate: 0.000218172
	LOSS [training: 0.011796270700891592 | validation: 0.014250633132718155]
	TIME [epoch: 9.23 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013587655806272492		[learning rate: 0.0002175]
	Learning Rate: 0.000217504
	LOSS [training: 0.013587655806272492 | validation: 0.018310525355311334]
	TIME [epoch: 9.23 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01154899007510033		[learning rate: 0.00021684]
	Learning Rate: 0.000216837
	LOSS [training: 0.01154899007510033 | validation: 0.019174393918317434]
	TIME [epoch: 9.22 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015525682589508646		[learning rate: 0.00021617]
	Learning Rate: 0.000216172
	LOSS [training: 0.015525682589508646 | validation: 0.012566096144433197]
	TIME [epoch: 9.23 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0157799896454835		[learning rate: 0.00021551]
	Learning Rate: 0.00021551
	LOSS [training: 0.0157799896454835 | validation: 0.019794588618399757]
	TIME [epoch: 9.25 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012208769776983134		[learning rate: 0.00021485]
	Learning Rate: 0.000214849
	LOSS [training: 0.012208769776983134 | validation: 0.012922653995477061]
	TIME [epoch: 9.23 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009950388893263919		[learning rate: 0.00021419]
	Learning Rate: 0.00021419
	LOSS [training: 0.009950388893263919 | validation: 0.01301424644584198]
	TIME [epoch: 9.22 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013981967353454028		[learning rate: 0.00021353]
	Learning Rate: 0.000213534
	LOSS [training: 0.013981967353454028 | validation: 0.018944261472427164]
	TIME [epoch: 9.23 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010988958316454463		[learning rate: 0.00021288]
	Learning Rate: 0.000212879
	LOSS [training: 0.010988958316454463 | validation: 0.016574994373909926]
	TIME [epoch: 9.22 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012156778330455151		[learning rate: 0.00021223]
	Learning Rate: 0.000212227
	LOSS [training: 0.012156778330455151 | validation: 0.007329561196252341]
	TIME [epoch: 9.25 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010295354716651514		[learning rate: 0.00021158]
	Learning Rate: 0.000211576
	LOSS [training: 0.010295354716651514 | validation: 0.017305269798140902]
	TIME [epoch: 9.22 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011888292670099544		[learning rate: 0.00021093]
	Learning Rate: 0.000210928
	LOSS [training: 0.011888292670099544 | validation: 0.013418467793162903]
	TIME [epoch: 9.22 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013955457596398163		[learning rate: 0.00021028]
	Learning Rate: 0.000210281
	LOSS [training: 0.013955457596398163 | validation: 0.007485171542201343]
	TIME [epoch: 9.22 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008823763701830255		[learning rate: 0.00020964]
	Learning Rate: 0.000209636
	LOSS [training: 0.008823763701830255 | validation: 0.015209374707302686]
	TIME [epoch: 9.22 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013743408759240888		[learning rate: 0.00020899]
	Learning Rate: 0.000208994
	LOSS [training: 0.013743408759240888 | validation: 0.011061863131177727]
	TIME [epoch: 9.24 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007795695707198927		[learning rate: 0.00020835]
	Learning Rate: 0.000208353
	LOSS [training: 0.007795695707198927 | validation: 0.018114607335731975]
	TIME [epoch: 9.22 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01396877739160359		[learning rate: 0.00020771]
	Learning Rate: 0.000207714
	LOSS [training: 0.01396877739160359 | validation: 0.016279438821835253]
	TIME [epoch: 9.22 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016111038363812703		[learning rate: 0.00020708]
	Learning Rate: 0.000207078
	LOSS [training: 0.016111038363812703 | validation: 0.016192746247186408]
	TIME [epoch: 9.22 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011448256115664683		[learning rate: 0.00020644]
	Learning Rate: 0.000206443
	LOSS [training: 0.011448256115664683 | validation: 0.011587937104127337]
	TIME [epoch: 9.22 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011569981032882154		[learning rate: 0.00020581]
	Learning Rate: 0.00020581
	LOSS [training: 0.011569981032882154 | validation: 0.01833799045918052]
	TIME [epoch: 9.25 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006244936797050004		[learning rate: 0.00020518]
	Learning Rate: 0.000205179
	LOSS [training: 0.006244936797050004 | validation: 0.011129494645602117]
	TIME [epoch: 9.22 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005487661534726455		[learning rate: 0.00020455]
	Learning Rate: 0.00020455
	LOSS [training: 0.005487661534726455 | validation: 0.015135318548038474]
	TIME [epoch: 9.23 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008776129620234035		[learning rate: 0.00020392]
	Learning Rate: 0.000203923
	LOSS [training: 0.008776129620234035 | validation: 0.003917336766601744]
	TIME [epoch: 9.22 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007014300825204024		[learning rate: 0.0002033]
	Learning Rate: 0.000203298
	LOSS [training: 0.007014300825204024 | validation: 0.01641056882720532]
	TIME [epoch: 9.22 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010998835013871935		[learning rate: 0.00020267]
	Learning Rate: 0.000202675
	LOSS [training: 0.010998835013871935 | validation: 0.004447448866065133]
	TIME [epoch: 9.24 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007305432590180831		[learning rate: 0.00020205]
	Learning Rate: 0.000202054
	LOSS [training: 0.007305432590180831 | validation: 0.010945972801333737]
	TIME [epoch: 9.22 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008216405824810619		[learning rate: 0.00020143]
	Learning Rate: 0.000201434
	LOSS [training: 0.008216405824810619 | validation: 0.010876369736477265]
	TIME [epoch: 9.22 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00801950306804948		[learning rate: 0.00020082]
	Learning Rate: 0.000200817
	LOSS [training: 0.00801950306804948 | validation: 0.005107249967343717]
	TIME [epoch: 9.22 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00822082169286206		[learning rate: 0.0002002]
	Learning Rate: 0.000200201
	LOSS [training: 0.00822082169286206 | validation: 0.012917855573510764]
	TIME [epoch: 9.31 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007693794995791088		[learning rate: 0.00019959]
	Learning Rate: 0.000199588
	LOSS [training: 0.007693794995791088 | validation: 0.011032668494418512]
	TIME [epoch: 9.26 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010448863308992768		[learning rate: 0.00019898]
	Learning Rate: 0.000198976
	LOSS [training: 0.010448863308992768 | validation: 0.0022040659160601768]
	TIME [epoch: 9.23 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008722936404127288		[learning rate: 0.00019837]
	Learning Rate: 0.000198366
	LOSS [training: 0.008722936404127288 | validation: 0.015263424459886933]
	TIME [epoch: 9.24 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011881116939816236		[learning rate: 0.00019776]
	Learning Rate: 0.000197758
	LOSS [training: 0.011881116939816236 | validation: 0.02385739489618602]
	TIME [epoch: 9.22 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004880388153618817		[learning rate: 0.00019715]
	Learning Rate: 0.000197151
	LOSS [training: 0.004880388153618817 | validation: 0.015520741797831483]
	TIME [epoch: 9.22 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010487019518018673		[learning rate: 0.00019655]
	Learning Rate: 0.000196547
	LOSS [training: 0.010487019518018673 | validation: 0.02056951605574967]
	TIME [epoch: 9.24 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013455449989235358		[learning rate: 0.00019594]
	Learning Rate: 0.000195945
	LOSS [training: 0.013455449989235358 | validation: 0.02139191060434013]
	TIME [epoch: 9.24 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01464446075258594		[learning rate: 0.00019534]
	Learning Rate: 0.000195344
	LOSS [training: 0.01464446075258594 | validation: 0.025182597072508223]
	TIME [epoch: 9.22 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01292955487101333		[learning rate: 0.00019475]
	Learning Rate: 0.000194745
	LOSS [training: 0.01292955487101333 | validation: 0.014252505879849733]
	TIME [epoch: 9.23 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009975457784372995		[learning rate: 0.00019415]
	Learning Rate: 0.000194148
	LOSS [training: 0.009975457784372995 | validation: 0.01277805793049527]
	TIME [epoch: 9.24 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0030327326210307076		[learning rate: 0.00019355]
	Learning Rate: 0.000193553
	LOSS [training: 0.0030327326210307076 | validation: 0.01256682704063258]
	TIME [epoch: 9.23 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00908025767436443		[learning rate: 0.00019296]
	Learning Rate: 0.00019296
	LOSS [training: 0.00908025767436443 | validation: 0.0003724773381071872]
	TIME [epoch: 9.22 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010218128254765363		[learning rate: 0.00019237]
	Learning Rate: 0.000192368
	LOSS [training: 0.0010218128254765363 | validation: 0.01288472761292547]
	TIME [epoch: 9.22 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004662751661551613		[learning rate: 0.00019178]
	Learning Rate: 0.000191778
	LOSS [training: 0.004662751661551613 | validation: 0.005447126323832756]
	TIME [epoch: 9.22 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005973337808556437		[learning rate: 0.00019119]
	Learning Rate: 0.000191191
	LOSS [training: 0.005973337808556437 | validation: 0.015468154510074442]
	TIME [epoch: 9.25 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015007439456271713		[learning rate: 0.0001906]
	Learning Rate: 0.000190605
	LOSS [training: 0.0015007439456271713 | validation: 0.012468842687363334]
	TIME [epoch: 9.23 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00536450062731044		[learning rate: 0.00019002]
	Learning Rate: 0.00019002
	LOSS [training: 0.00536450062731044 | validation: 0.0063385626804119185]
	TIME [epoch: 9.22 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014737130417263652		[learning rate: 0.00018944]
	Learning Rate: 0.000189438
	LOSS [training: 0.0014737130417263652 | validation: 0.007593619936141164]
	TIME [epoch: 9.22 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005896952829904578		[learning rate: 0.00018886]
	Learning Rate: 0.000188857
	LOSS [training: 0.005896952829904578 | validation: 0.000791649369183568]
	TIME [epoch: 9.32 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006563812881268903		[learning rate: 0.00018828]
	Learning Rate: 0.000188278
	LOSS [training: 0.006563812881268903 | validation: 0.0058453627432045446]
	TIME [epoch: 9.24 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001549552113524135		[learning rate: 0.0001877]
	Learning Rate: 0.000187701
	LOSS [training: 0.001549552113524135 | validation: 0.013703376452856006]
	TIME [epoch: 9.22 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021534184928402584		[learning rate: 0.00018713]
	Learning Rate: 0.000187126
	LOSS [training: 0.0021534184928402584 | validation: 0.02060288081545161]
	TIME [epoch: 9.22 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019938483835694044		[learning rate: 0.00018655]
	Learning Rate: 0.000186552
	LOSS [training: 0.0019938483835694044 | validation: 0.017673887035549413]
	TIME [epoch: 9.23 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008764440808750544		[learning rate: 0.00018598]
	Learning Rate: 0.00018598
	LOSS [training: 0.008764440808750544 | validation: 0.012146301449824346]
	TIME [epoch: 9.22 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006456980734566945		[learning rate: 0.00018541]
	Learning Rate: 0.00018541
	LOSS [training: 0.006456980734566945 | validation: 0.020880673103213322]
	TIME [epoch: 9.24 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003931581521418296		[learning rate: 0.00018484]
	Learning Rate: 0.000184842
	LOSS [training: 0.003931581521418296 | validation: 0.015782768638388338]
	TIME [epoch: 9.22 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007740888809736267		[learning rate: 0.00018428]
	Learning Rate: 0.000184275
	LOSS [training: 0.007740888809736267 | validation: 0.013994030067635114]
	TIME [epoch: 9.22 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011738189206612073		[learning rate: 0.00018371]
	Learning Rate: 0.00018371
	LOSS [training: 0.011738189206612073 | validation: 0.020091899699570478]
	TIME [epoch: 9.23 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008769550180995006		[learning rate: 0.00018315]
	Learning Rate: 0.000183147
	LOSS [training: 0.008769550180995006 | validation: 0.015617969838564075]
	TIME [epoch: 9.22 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006323800808505019		[learning rate: 0.00018259]
	Learning Rate: 0.000182586
	LOSS [training: 0.006323800808505019 | validation: 0.013132330167383828]
	TIME [epoch: 9.24 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006813398142791809		[learning rate: 0.00018203]
	Learning Rate: 0.000182026
	LOSS [training: 0.006813398142791809 | validation: 0.010279881052452805]
	TIME [epoch: 9.24 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0031505801841952993		[learning rate: 0.00018147]
	Learning Rate: 0.000181468
	LOSS [training: 0.0031505801841952993 | validation: 0.012970820968578576]
	TIME [epoch: 9.23 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0024116464649277186		[learning rate: 0.00018091]
	Learning Rate: 0.000180912
	LOSS [training: 0.0024116464649277186 | validation: 0.008497549012294396]
	TIME [epoch: 9.23 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004581078469904426		[learning rate: 0.00018036]
	Learning Rate: 0.000180357
	LOSS [training: 0.004581078469904426 | validation: 0.008434689201120808]
	TIME [epoch: 9.23 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006190625661086498		[learning rate: 0.0001798]
	Learning Rate: 0.000179804
	LOSS [training: 0.006190625661086498 | validation: 0.011142544442385488]
	TIME [epoch: 9.24 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008813157182525908		[learning rate: 0.00017925]
	Learning Rate: 0.000179253
	LOSS [training: 0.008813157182525908 | validation: 0.015475575551079132]
	TIME [epoch: 9.23 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005934857504002946		[learning rate: 0.0001787]
	Learning Rate: 0.000178704
	LOSS [training: 0.005934857504002946 | validation: 0.009079596055800991]
	TIME [epoch: 9.22 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006115221105572798		[learning rate: 0.00017816]
	Learning Rate: 0.000178156
	LOSS [training: 0.006115221105572798 | validation: 0.015210884452144958]
	TIME [epoch: 9.23 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006574665761996244		[learning rate: 0.00017761]
	Learning Rate: 0.00017761
	LOSS [training: 0.006574665761996244 | validation: 0.012983117268337997]
	TIME [epoch: 9.23 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006467611707943037		[learning rate: 0.00017707]
	Learning Rate: 0.000177065
	LOSS [training: 0.006467611707943037 | validation: 0.012314235590497729]
	TIME [epoch: 9.24 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0062215909102573165		[learning rate: 0.00017652]
	Learning Rate: 0.000176522
	LOSS [training: 0.0062215909102573165 | validation: 0.01796651564851417]
	TIME [epoch: 9.23 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029394236925012803		[learning rate: 0.00017598]
	Learning Rate: 0.000175981
	LOSS [training: 0.0029394236925012803 | validation: 0.00963082691395279]
	TIME [epoch: 9.22 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004536304208629783		[learning rate: 0.00017544]
	Learning Rate: 0.000175442
	LOSS [training: 0.004536304208629783 | validation: 0.012245017532147132]
	TIME [epoch: 9.23 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009723893108058736		[learning rate: 0.0001749]
	Learning Rate: 0.000174904
	LOSS [training: 0.009723893108058736 | validation: 0.009901486930141526]
	TIME [epoch: 9.23 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006813302666914191		[learning rate: 0.00017437]
	Learning Rate: 0.000174368
	LOSS [training: 0.006813302666914191 | validation: 0.017223777747267507]
	TIME [epoch: 9.24 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008506768330942122		[learning rate: 0.00017383]
	Learning Rate: 0.000173833
	LOSS [training: 0.008506768330942122 | validation: 0.019238711870917104]
	TIME [epoch: 9.23 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01209158178275452		[learning rate: 0.0001733]
	Learning Rate: 0.000173301
	LOSS [training: 0.01209158178275452 | validation: 0.014521866259203573]
	TIME [epoch: 9.22 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004318149281039671		[learning rate: 0.00017277]
	Learning Rate: 0.000172769
	LOSS [training: 0.004318149281039671 | validation: 0.012536207766716788]
	TIME [epoch: 9.23 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008722807352066417		[learning rate: 0.00017224]
	Learning Rate: 0.00017224
	LOSS [training: 0.008722807352066417 | validation: 0.013295548071369817]
	TIME [epoch: 9.22 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010444909687858972		[learning rate: 0.00017171]
	Learning Rate: 0.000171712
	LOSS [training: 0.010444909687858972 | validation: 0.015579430922364431]
	TIME [epoch: 9.25 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009628739133338685		[learning rate: 0.00017119]
	Learning Rate: 0.000171185
	LOSS [training: 0.009628739133338685 | validation: 0.01596684479505517]
	TIME [epoch: 9.22 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008222192779945063		[learning rate: 0.00017066]
	Learning Rate: 0.000170661
	LOSS [training: 0.008222192779945063 | validation: 0.015340049531293011]
	TIME [epoch: 9.23 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004699864452306914		[learning rate: 0.00017014]
	Learning Rate: 0.000170137
	LOSS [training: 0.004699864452306914 | validation: 0.015341139410997129]
	TIME [epoch: 9.22 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00839717087237495		[learning rate: 0.00016962]
	Learning Rate: 0.000169616
	LOSS [training: 0.00839717087237495 | validation: 0.005017226621992578]
	TIME [epoch: 9.23 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00883185994276444		[learning rate: 0.0001691]
	Learning Rate: 0.000169096
	LOSS [training: 0.00883185994276444 | validation: 0.009976698891686628]
	TIME [epoch: 9.25 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006078559903916321		[learning rate: 0.00016858]
	Learning Rate: 0.000168578
	LOSS [training: 0.006078559903916321 | validation: 0.01292795644467079]
	TIME [epoch: 9.22 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00624186229267968		[learning rate: 0.00016806]
	Learning Rate: 0.000168061
	LOSS [training: 0.00624186229267968 | validation: 0.0033616463572386677]
	TIME [epoch: 9.22 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005419465110687035		[learning rate: 0.00016755]
	Learning Rate: 0.000167546
	LOSS [training: 0.005419465110687035 | validation: 0.0009407734908770998]
	TIME [epoch: 9.22 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0022854582082660604		[learning rate: 0.00016703]
	Learning Rate: 0.000167032
	LOSS [training: 0.0022854582082660604 | validation: 0.0025069701565132874]
	TIME [epoch: 9.25 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0037446539022065184		[learning rate: 0.00016652]
	Learning Rate: 0.00016652
	LOSS [training: 0.0037446539022065184 | validation: 0.002726647309925765]
	TIME [epoch: 9.24 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007389519377860721		[learning rate: 0.00016601]
	Learning Rate: 0.00016601
	LOSS [training: 0.007389519377860721 | validation: 0.012330991145317483]
	TIME [epoch: 9.22 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0030021488598826213		[learning rate: 0.0001655]
	Learning Rate: 0.000165501
	LOSS [training: 0.0030021488598826213 | validation: 0.009203389136463506]
	TIME [epoch: 9.22 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006766342371530144		[learning rate: 0.00016499]
	Learning Rate: 0.000164993
	LOSS [training: 0.006766342371530144 | validation: 0.018484908417473085]
	TIME [epoch: 9.22 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004508747955689685		[learning rate: 0.00016449]
	Learning Rate: 0.000164488
	LOSS [training: 0.004508747955689685 | validation: 0.013523869056804819]
	TIME [epoch: 9.24 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005350373669429852		[learning rate: 0.00016398]
	Learning Rate: 0.000163983
	LOSS [training: 0.005350373669429852 | validation: 0.013840041479012159]
	TIME [epoch: 9.25 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007238250751580298		[learning rate: 0.00016348]
	Learning Rate: 0.000163481
	LOSS [training: 0.007238250751580298 | validation: 0.005241693433085533]
	TIME [epoch: 9.24 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004378119565445803		[learning rate: 0.00016298]
	Learning Rate: 0.00016298
	LOSS [training: 0.004378119565445803 | validation: 0.0004319779114908091]
	TIME [epoch: 9.23 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006440133558374109		[learning rate: 0.00016248]
	Learning Rate: 0.00016248
	LOSS [training: 0.006440133558374109 | validation: 0.011356830355529018]
	TIME [epoch: 9.22 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001956418633577009		[learning rate: 0.00016198]
	Learning Rate: 0.000161982
	LOSS [training: 0.001956418633577009 | validation: 0.009979254181518833]
	TIME [epoch: 9.25 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018550075529014808		[learning rate: 0.00016149]
	Learning Rate: 0.000161485
	LOSS [training: 0.0018550075529014808 | validation: 0.014149964643186045]
	TIME [epoch: 9.24 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004107013202235295		[learning rate: 0.00016099]
	Learning Rate: 0.00016099
	LOSS [training: 0.004107013202235295 | validation: 0.008045483077172948]
	TIME [epoch: 9.23 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00716170657828826		[learning rate: 0.0001605]
	Learning Rate: 0.000160497
	LOSS [training: 0.00716170657828826 | validation: 0.006251904529693845]
	TIME [epoch: 9.22 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005734227199494481		[learning rate: 0.00016]
	Learning Rate: 0.000160005
	LOSS [training: 0.005734227199494481 | validation: 0.009958755759233077]
	TIME [epoch: 9.23 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005601206926803456		[learning rate: 0.00015951]
	Learning Rate: 0.000159514
	LOSS [training: 0.005601206926803456 | validation: 0.012409270861575405]
	TIME [epoch: 9.24 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011717156283230468		[learning rate: 0.00015903]
	Learning Rate: 0.000159025
	LOSS [training: 0.011717156283230468 | validation: 0.011732416722858744]
	TIME [epoch: 9.23 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007920964640321044		[learning rate: 0.00015854]
	Learning Rate: 0.000158538
	LOSS [training: 0.007920964640321044 | validation: 0.0039276414817027575]
	TIME [epoch: 9.23 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002475967236938298		[learning rate: 0.00015805]
	Learning Rate: 0.000158052
	LOSS [training: 0.002475967236938298 | validation: 0.01335355057942924]
	TIME [epoch: 9.22 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005281437626857731		[learning rate: 0.00015757]
	Learning Rate: 0.000157567
	LOSS [training: 0.005281437626857731 | validation: 0.011852486998722177]
	TIME [epoch: 9.23 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005616740170333973		[learning rate: 0.00015708]
	Learning Rate: 0.000157084
	LOSS [training: 0.005616740170333973 | validation: 0.01011984192478294]
	TIME [epoch: 9.24 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004887600576382107		[learning rate: 0.0001566]
	Learning Rate: 0.000156603
	LOSS [training: 0.004887600576382107 | validation: 0.00805344506344715]
	TIME [epoch: 9.23 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005673130668197314		[learning rate: 0.00015612]
	Learning Rate: 0.000156123
	LOSS [training: 0.005673130668197314 | validation: 0.009110099815162857]
	TIME [epoch: 9.22 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0032700194466883715		[learning rate: 0.00015564]
	Learning Rate: 0.000155644
	LOSS [training: 0.0032700194466883715 | validation: 0.011564595640758856]
	TIME [epoch: 9.22 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009819200035708502		[learning rate: 0.00015517]
	Learning Rate: 0.000155167
	LOSS [training: 0.009819200035708502 | validation: 0.012514999765995485]
	TIME [epoch: 9.23 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005717238733535662		[learning rate: 0.00015469]
	Learning Rate: 0.000154692
	LOSS [training: 0.005717238733535662 | validation: 0.011328500829136102]
	TIME [epoch: 9.25 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0040674747451506675		[learning rate: 0.00015422]
	Learning Rate: 0.000154217
	LOSS [training: 0.0040674747451506675 | validation: 0.012832001632493518]
	TIME [epoch: 9.23 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004480382378115466		[learning rate: 0.00015374]
	Learning Rate: 0.000153745
	LOSS [training: 0.004480382378115466 | validation: 0.014780659010438221]
	TIME [epoch: 9.22 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0033096262217865062		[learning rate: 0.00015327]
	Learning Rate: 0.000153273
	LOSS [training: 0.0033096262217865062 | validation: 0.005236834990563936]
	TIME [epoch: 9.22 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004475180673602247		[learning rate: 0.0001528]
	Learning Rate: 0.000152803
	LOSS [training: 0.004475180673602247 | validation: 0.010312054305856046]
	TIME [epoch: 9.22 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0038087872903079176		[learning rate: 0.00015234]
	Learning Rate: 0.000152335
	LOSS [training: 0.0038087872903079176 | validation: 0.017551808789507378]
	TIME [epoch: 9.24 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0037385397817599362		[learning rate: 0.00015187]
	Learning Rate: 0.000151868
	LOSS [training: 0.0037385397817599362 | validation: 0.013003332376769913]
	TIME [epoch: 9.22 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00482308622324829		[learning rate: 0.0001514]
	Learning Rate: 0.000151403
	LOSS [training: 0.00482308622324829 | validation: 0.00904879838611495]
	TIME [epoch: 9.22 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008864875161116658		[learning rate: 0.00015094]
	Learning Rate: 0.000150938
	LOSS [training: 0.008864875161116658 | validation: 0.003301941843671347]
	TIME [epoch: 9.23 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003009713812929588		[learning rate: 0.00015048]
	Learning Rate: 0.000150476
	LOSS [training: 0.003009713812929588 | validation: 0.012422730438848645]
	TIME [epoch: 9.23 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00552022267079943		[learning rate: 0.00015001]
	Learning Rate: 0.000150015
	LOSS [training: 0.00552022267079943 | validation: 0.010700989437444172]
	TIME [epoch: 9.25 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004953525115114804		[learning rate: 0.00014955]
	Learning Rate: 0.000149555
	LOSS [training: 0.004953525115114804 | validation: 0.008493368218168434]
	TIME [epoch: 9.23 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0024980048170365234		[learning rate: 0.0001491]
	Learning Rate: 0.000149096
	LOSS [training: 0.0024980048170365234 | validation: 0.015406178303134527]
	TIME [epoch: 9.22 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008522821689442977		[learning rate: 0.00014864]
	Learning Rate: 0.000148639
	LOSS [training: 0.008522821689442977 | validation: 0.007851869430630124]
	TIME [epoch: 9.23 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003436336028689766		[learning rate: 0.00014818]
	Learning Rate: 0.000148184
	LOSS [training: 0.003436336028689766 | validation: 0.005129826169328116]
	TIME [epoch: 9.22 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008628377867119837		[learning rate: 0.00014773]
	Learning Rate: 0.000147729
	LOSS [training: 0.008628377867119837 | validation: 0.0067241317244348415]
	TIME [epoch: 9.23 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0028478732368494284		[learning rate: 0.00014728]
	Learning Rate: 0.000147276
	LOSS [training: 0.0028478732368494284 | validation: 0.006803205356585535]
	TIME [epoch: 9.23 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008006034147536924		[learning rate: 0.00014682]
	Learning Rate: 0.000146825
	LOSS [training: 0.008006034147536924 | validation: 0.001407527677504813]
	TIME [epoch: 9.22 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0013611270876469684		[learning rate: 0.00014637]
	Learning Rate: 0.000146375
	LOSS [training: 0.0013611270876469684 | validation: 0.010424568047324372]
	TIME [epoch: 9.22 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004836909862030789		[learning rate: 0.00014593]
	Learning Rate: 0.000145926
	LOSS [training: 0.004836909862030789 | validation: 0.00027525550595151166]
	TIME [epoch: 9.22 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002915201294572555		[learning rate: 0.00014548]
	Learning Rate: 0.000145479
	LOSS [training: 0.002915201294572555 | validation: 0.005363582952953418]
	TIME [epoch: 9.25 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003644301322621353		[learning rate: 0.00014503]
	Learning Rate: 0.000145033
	LOSS [training: 0.003644301322621353 | validation: 0.009091351151932886]
	TIME [epoch: 9.23 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00239537547301717		[learning rate: 0.00014459]
	Learning Rate: 0.000144588
	LOSS [training: 0.00239537547301717 | validation: 0.01242677273526701]
	TIME [epoch: 9.23 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007766216371254538		[learning rate: 0.00014415]
	Learning Rate: 0.000144145
	LOSS [training: 0.007766216371254538 | validation: 0.006766152003597143]
	TIME [epoch: 9.23 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002843238645471928		[learning rate: 0.0001437]
	Learning Rate: 0.000143703
	LOSS [training: 0.002843238645471928 | validation: 0.01142866117091659]
	TIME [epoch: 9.23 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0004941035798358795		[learning rate: 0.00014326]
	Learning Rate: 0.000143263
	LOSS [training: 0.0004941035798358795 | validation: 0.018761280904682317]
	TIME [epoch: 9.24 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004428503055485759		[learning rate: 0.00014282]
	Learning Rate: 0.000142824
	LOSS [training: 0.004428503055485759 | validation: 0.007457705497282434]
	TIME [epoch: 9.22 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003495709421391844		[learning rate: 0.00014239]
	Learning Rate: 0.000142386
	LOSS [training: 0.003495709421391844 | validation: 0.013335854088231696]
	TIME [epoch: 9.22 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003133252819160386		[learning rate: 0.00014195]
	Learning Rate: 0.000141949
	LOSS [training: 0.003133252819160386 | validation: 0.008121693988460582]
	TIME [epoch: 9.23 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0031065629024001713		[learning rate: 0.00014151]
	Learning Rate: 0.000141514
	LOSS [training: 0.0031065629024001713 | validation: -9.227838018130105e-05]
	TIME [epoch: 9.23 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0041572244429831425		[learning rate: 0.00014108]
	Learning Rate: 0.00014108
	LOSS [training: 0.0041572244429831425 | validation: 0.00615599983255147]
	TIME [epoch: 9.24 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7665797055276276e-05		[learning rate: 0.00014065]
	Learning Rate: 0.000140648
	LOSS [training: 2.7665797055276276e-05 | validation: 0.008085989640925353]
	TIME [epoch: 9.22 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003598526013604002		[learning rate: 0.00014022]
	Learning Rate: 0.000140217
	LOSS [training: 0.003598526013604002 | validation: 0.002623875004683046]
	TIME [epoch: 9.23 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.000471201385604555		[learning rate: 0.00013979]
	Learning Rate: 0.000139787
	LOSS [training: -0.000471201385604555 | validation: 0.008777914129128931]
	TIME [epoch: 9.23 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005458397110164714		[learning rate: 0.00013936]
	Learning Rate: 0.000139358
	LOSS [training: 0.005458397110164714 | validation: 0.015455492540334848]
	TIME [epoch: 9.24 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003546275450144698		[learning rate: 0.00013893]
	Learning Rate: 0.000138931
	LOSS [training: 0.003546275450144698 | validation: 0.013433989163641805]
	TIME [epoch: 9.23 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005398079714768017		[learning rate: 0.00013851]
	Learning Rate: 0.000138505
	LOSS [training: 0.005398079714768017 | validation: 0.00662516524402019]
	TIME [epoch: 9.23 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0037008466437260393		[learning rate: 0.00013808]
	Learning Rate: 0.000138081
	LOSS [training: 0.0037008466437260393 | validation: 0.009556213843699708]
	TIME [epoch: 9.22 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0012477860700686428		[learning rate: 0.00013766]
	Learning Rate: 0.000137658
	LOSS [training: 0.0012477860700686428 | validation: 0.013617598895887473]
	TIME [epoch: 9.22 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0034338843678305064		[learning rate: 0.00013724]
	Learning Rate: 0.000137236
	LOSS [training: 0.0034338843678305064 | validation: 0.0059280141324749855]
	TIME [epoch: 9.24 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00333740697249948		[learning rate: 0.00013681]
	Learning Rate: 0.000136815
	LOSS [training: 0.00333740697249948 | validation: 0.006943642661330756]
	TIME [epoch: 9.22 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0022721408706225066		[learning rate: 0.0001364]
	Learning Rate: 0.000136395
	LOSS [training: 0.0022721408706225066 | validation: 0.009618454326934527]
	TIME [epoch: 9.23 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00162114180666395		[learning rate: 0.00013598]
	Learning Rate: 0.000135977
	LOSS [training: 0.00162114180666395 | validation: 0.015889865796767495]
	TIME [epoch: 9.23 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00585053643539636		[learning rate: 0.00013556]
	Learning Rate: 0.000135561
	LOSS [training: 0.00585053643539636 | validation: 0.017960488513476067]
	TIME [epoch: 9.23 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00323926457258177		[learning rate: 0.00013515]
	Learning Rate: 0.000135145
	LOSS [training: 0.00323926457258177 | validation: 0.01011594640437723]
	TIME [epoch: 9.25 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006991059123717099		[learning rate: 0.00013473]
	Learning Rate: 0.000134731
	LOSS [training: -0.0006991059123717099 | validation: 0.008086710051266146]
	TIME [epoch: 9.23 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004987482146680522		[learning rate: 0.00013432]
	Learning Rate: 0.000134318
	LOSS [training: 0.004987482146680522 | validation: 0.007042218068000341]
	TIME [epoch: 9.23 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004462314205242775		[learning rate: 0.00013391]
	Learning Rate: 0.000133906
	LOSS [training: 0.004462314205242775 | validation: 0.014756812300573493]
	TIME [epoch: 9.23 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004922843017727751		[learning rate: 0.0001335]
	Learning Rate: 0.000133496
	LOSS [training: 0.004922843017727751 | validation: 0.0033829080049784166]
	TIME [epoch: 9.23 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0036924979427668653		[learning rate: 0.00013309]
	Learning Rate: 0.000133086
	LOSS [training: 0.0036924979427668653 | validation: 0.0017340436665782806]
	TIME [epoch: 9.24 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0013251143120877461		[learning rate: 0.00013268]
	Learning Rate: 0.000132678
	LOSS [training: 0.0013251143120877461 | validation: 0.0033233818259257057]
	TIME [epoch: 9.23 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014533562758439064		[learning rate: 0.00013227]
	Learning Rate: 0.000132272
	LOSS [training: 0.0014533562758439064 | validation: 0.005274420457980434]
	TIME [epoch: 9.23 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002925860128804673		[learning rate: 0.00013187]
	Learning Rate: 0.000131866
	LOSS [training: 0.002925860128804673 | validation: 0.005437006699622212]
	TIME [epoch: 9.23 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014036487232763032		[learning rate: 0.00013146]
	Learning Rate: 0.000131462
	LOSS [training: 0.0014036487232763032 | validation: 0.010394360537386146]
	TIME [epoch: 9.22 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0028680829134980304		[learning rate: 0.00013106]
	Learning Rate: 0.000131059
	LOSS [training: 0.0028680829134980304 | validation: 0.007480133360683192]
	TIME [epoch: 9.24 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005951550848726607		[learning rate: 0.00013066]
	Learning Rate: 0.000130657
	LOSS [training: 0.005951550848726607 | validation: 0.004674754816375257]
	TIME [epoch: 9.31 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012860583373238764		[learning rate: 0.00013026]
	Learning Rate: 0.000130257
	LOSS [training: -0.0012860583373238764 | validation: 0.013992065964946588]
	TIME [epoch: 9.22 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015902589505034132		[learning rate: 0.00012986]
	Learning Rate: 0.000129857
	LOSS [training: 0.0015902589505034132 | validation: 0.005584650085928395]
	TIME [epoch: 9.21 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00048386691788792675		[learning rate: 0.00012946]
	Learning Rate: 0.000129459
	LOSS [training: 0.00048386691788792675 | validation: 0.0017981315282132012]
	TIME [epoch: 9.22 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: -2.617035498558816e-05		[learning rate: 0.00012906]
	Learning Rate: 0.000129062
	LOSS [training: -2.617035498558816e-05 | validation: 0.002838595575496574]
	TIME [epoch: 9.23 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0012993329894186723		[learning rate: 0.00012867]
	Learning Rate: 0.000128667
	LOSS [training: 0.0012993329894186723 | validation: 0.008959672265923686]
	TIME [epoch: 9.22 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.875982116360529e-06		[learning rate: 0.00012827]
	Learning Rate: 0.000128272
	LOSS [training: 7.875982116360529e-06 | validation: 0.0173092996984214]
	TIME [epoch: 9.21 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0028089686907107046		[learning rate: 0.00012788]
	Learning Rate: 0.000127879
	LOSS [training: 0.0028089686907107046 | validation: -0.0005629887574888433]
	TIME [epoch: 9.22 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1920.pth
	Model improved!!!
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010967802562142513		[learning rate: 0.00012749]
	Learning Rate: 0.000127487
	LOSS [training: 0.0010967802562142513 | validation: 0.007417324392811387]
	TIME [epoch: 9.23 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002299432548247381		[learning rate: 0.0001271]
	Learning Rate: 0.000127096
	LOSS [training: 0.002299432548247381 | validation: 0.00566088078755135]
	TIME [epoch: 9.24 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0028412578296762273		[learning rate: 0.00012671]
	Learning Rate: 0.000126707
	LOSS [training: 0.0028412578296762273 | validation: -9.475603362141532e-05]
	TIME [epoch: 9.21 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004273785540087812		[learning rate: 0.00012632]
	Learning Rate: 0.000126318
	LOSS [training: -0.0004273785540087812 | validation: 0.015168658246682017]
	TIME [epoch: 9.22 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0012256256552267007		[learning rate: 0.00012593]
	Learning Rate: 0.000125931
	LOSS [training: 0.0012256256552267007 | validation: 0.015407090766708563]
	TIME [epoch: 9.22 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005530357125685928		[learning rate: 0.00012555]
	Learning Rate: 0.000125545
	LOSS [training: 0.005530357125685928 | validation: 0.01092940905421925]
	TIME [epoch: 9.22 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.000672867818183294		[learning rate: 0.00012516]
	Learning Rate: 0.00012516
	LOSS [training: -0.000672867818183294 | validation: 0.006559467768145197]
	TIME [epoch: 9.24 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004325453149034873		[learning rate: 0.00012478]
	Learning Rate: 0.000124777
	LOSS [training: 0.004325453149034873 | validation: 0.014159614437441197]
	TIME [epoch: 9.22 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004125965529934065		[learning rate: 0.00012439]
	Learning Rate: 0.000124394
	LOSS [training: 0.004125965529934065 | validation: 0.004740873540882745]
	TIME [epoch: 9.23 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0032190209278765854		[learning rate: 0.00012401]
	Learning Rate: 0.000124013
	LOSS [training: 0.0032190209278765854 | validation: 0.013418174811045635]
	TIME [epoch: 9.24 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005242403295035573		[learning rate: 0.00012363]
	Learning Rate: 0.000123633
	LOSS [training: -0.0005242403295035573 | validation: 0.005309405950248287]
	TIME [epoch: 9.24 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0046601611796276265		[learning rate: 0.00012325]
	Learning Rate: 0.000123254
	LOSS [training: 0.0046601611796276265 | validation: 0.019829272476822292]
	TIME [epoch: 9.26 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.06889826488148e-05		[learning rate: 0.00012288]
	Learning Rate: 0.000122876
	LOSS [training: 9.06889826488148e-05 | validation: 0.004161829087418661]
	TIME [epoch: 9.23 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004402591652451024		[learning rate: 0.0001225]
	Learning Rate: 0.000122499
	LOSS [training: 0.004402591652451024 | validation: 0.0017346865885686054]
	TIME [epoch: 9.22 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004861399819029016		[learning rate: 0.00012212]
	Learning Rate: 0.000122124
	LOSS [training: 0.004861399819029016 | validation: 0.006097271204201005]
	TIME [epoch: 9.24 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0032007500653182335		[learning rate: 0.00012175]
	Learning Rate: 0.000121749
	LOSS [training: 0.0032007500653182335 | validation: 0.006148786048377746]
	TIME [epoch: 9.23 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0041191503012456675		[learning rate: 0.00012138]
	Learning Rate: 0.000121376
	LOSS [training: 0.0041191503012456675 | validation: 0.013021980817780133]
	TIME [epoch: 9.24 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006887738627860934		[learning rate: 0.000121]
	Learning Rate: 0.000121004
	LOSS [training: 0.006887738627860934 | validation: 0.006850508391809284]
	TIME [epoch: 9.23 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004038305341777568		[learning rate: 0.00012063]
	Learning Rate: 0.000120633
	LOSS [training: 0.004038305341777568 | validation: 0.0171443653583128]
	TIME [epoch: 9.23 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0033471533466527467		[learning rate: 0.00012026]
	Learning Rate: 0.000120263
	LOSS [training: 0.0033471533466527467 | validation: 0.014467670241953253]
	TIME [epoch: 9.31 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007392309329166029		[learning rate: 0.00011989]
	Learning Rate: 0.000119895
	LOSS [training: -0.0007392309329166029 | validation: 0.007091309877892726]
	TIME [epoch: 9.25 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006916052266980515		[learning rate: 0.00011953]
	Learning Rate: 0.000119527
	LOSS [training: 0.006916052266980515 | validation: 0.002994237188218519]
	TIME [epoch: 9.24 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0030574030262505198		[learning rate: 0.00011916]
	Learning Rate: 0.000119161
	LOSS [training: 0.0030574030262505198 | validation: 0.008468390548852152]
	TIME [epoch: 9.22 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0033852211054795		[learning rate: 0.0001188]
	Learning Rate: 0.000118795
	LOSS [training: 0.0033852211054795 | validation: 0.005924247282038546]
	TIME [epoch: 9.23 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004546922483369843		[learning rate: 0.00011843]
	Learning Rate: 0.000118431
	LOSS [training: 0.004546922483369843 | validation: 0.006014186794835311]
	TIME [epoch: 9.22 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001925035070537675		[learning rate: 0.00011807]
	Learning Rate: 0.000118068
	LOSS [training: 0.001925035070537675 | validation: 0.01799496505949226]
	TIME [epoch: 9.24 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006832313212296618		[learning rate: 0.00011771]
	Learning Rate: 0.000117706
	LOSS [training: -0.0006832313212296618 | validation: 0.012365585567880201]
	TIME [epoch: 9.23 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0023855026964957533		[learning rate: 0.00011735]
	Learning Rate: 0.000117346
	LOSS [training: 0.0023855026964957533 | validation: 0.005586745517185045]
	TIME [epoch: 9.22 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010357070914837076		[learning rate: 0.00011699]
	Learning Rate: 0.000116986
	LOSS [training: 0.0010357070914837076 | validation: 0.0010128099126614231]
	TIME [epoch: 9.22 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005712697842333409		[learning rate: 0.00011663]
	Learning Rate: 0.000116627
	LOSS [training: 0.0005712697842333409 | validation: 0.011788368081842453]
	TIME [epoch: 9.22 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004263454801639897		[learning rate: 0.00011627]
	Learning Rate: 0.00011627
	LOSS [training: -0.0004263454801639897 | validation: 0.002582878531082876]
	TIME [epoch: 9.24 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017266030481072753		[learning rate: 0.00011591]
	Learning Rate: 0.000115913
	LOSS [training: -0.0017266030481072753 | validation: 0.008108550027996072]
	TIME [epoch: 9.23 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0016778021040101895		[learning rate: 0.00011556]
	Learning Rate: 0.000115558
	LOSS [training: -0.0016778021040101895 | validation: 0.013818144503155525]
	TIME [epoch: 9.23 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014959239167680644		[learning rate: 0.0001152]
	Learning Rate: 0.000115204
	LOSS [training: 0.0014959239167680644 | validation: -0.0009178533707901043]
	TIME [epoch: 9.23 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1954.pth
	Model improved!!!
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029167213698585758		[learning rate: 0.00011485]
	Learning Rate: 0.000114851
	LOSS [training: 0.0029167213698585758 | validation: 0.00860490890468908]
	TIME [epoch: 9.23 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013410966065649874		[learning rate: 0.0001145]
	Learning Rate: 0.000114499
	LOSS [training: -0.0013410966065649874 | validation: 0.011836011603848298]
	TIME [epoch: 9.25 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006585818093261832		[learning rate: 0.00011415]
	Learning Rate: 0.000114148
	LOSS [training: 0.0006585818093261832 | validation: 0.0036784416379237036]
	TIME [epoch: 9.22 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009611141719359425		[learning rate: 0.0001138]
	Learning Rate: 0.000113798
	LOSS [training: 0.0009611141719359425 | validation: 0.0020187487426117684]
	TIME [epoch: 9.22 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00345499449233361		[learning rate: 0.00011345]
	Learning Rate: 0.000113449
	LOSS [training: 0.00345499449233361 | validation: 0.011822437223038502]
	TIME [epoch: 9.22 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003406588336678279		[learning rate: 0.0001131]
	Learning Rate: 0.000113101
	LOSS [training: 0.003406588336678279 | validation: 0.007458958034815483]
	TIME [epoch: 9.22 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0013580793687210696		[learning rate: 0.00011275]
	Learning Rate: 0.000112754
	LOSS [training: 0.0013580793687210696 | validation: 0.015403001999008542]
	TIME [epoch: 9.25 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002292582278905415		[learning rate: 0.00011241]
	Learning Rate: 0.000112409
	LOSS [training: 0.002292582278905415 | validation: 0.014559198348339478]
	TIME [epoch: 9.23 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0003468371931568839		[learning rate: 0.00011206]
	Learning Rate: 0.000112064
	LOSS [training: -0.0003468371931568839 | validation: 0.011647194181143732]
	TIME [epoch: 9.22 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008989940875691393		[learning rate: 0.00011172]
	Learning Rate: 0.000111721
	LOSS [training: 0.0008989940875691393 | validation: 0.0007570213218348575]
	TIME [epoch: 9.23 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006278748194202486		[learning rate: 0.00011138]
	Learning Rate: 0.000111378
	LOSS [training: -0.0006278748194202486 | validation: 0.010153205871139041]
	TIME [epoch: 9.22 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0024031682400481287		[learning rate: 0.00011104]
	Learning Rate: 0.000111037
	LOSS [training: 0.0024031682400481287 | validation: 0.015615852178952016]
	TIME [epoch: 9.24 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0003828399929221804		[learning rate: 0.0001107]
	Learning Rate: 0.000110696
	LOSS [training: -0.0003828399929221804 | validation: 0.003685598261183436]
	TIME [epoch: 9.22 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004227491743554922		[learning rate: 0.00011036]
	Learning Rate: 0.000110357
	LOSS [training: 0.004227491743554922 | validation: 0.005072376924976393]
	TIME [epoch: 9.22 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014960906127117527		[learning rate: 0.00011002]
	Learning Rate: 0.000110019
	LOSS [training: 0.0014960906127117527 | validation: 0.00674516093180689]
	TIME [epoch: 9.23 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004041170350638455		[learning rate: 0.00010968]
	Learning Rate: 0.000109681
	LOSS [training: 0.004041170350638455 | validation: 2.6635214409984618e-05]
	TIME [epoch: 9.22 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0011350326199795271		[learning rate: 0.00010935]
	Learning Rate: 0.000109345
	LOSS [training: 0.0011350326199795271 | validation: 0.011836774324742153]
	TIME [epoch: 9.46 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0007386182670873055		[learning rate: 0.00010901]
	Learning Rate: 0.00010901
	LOSS [training: 0.0007386182670873055 | validation: 0.008581335333325564]
	TIME [epoch: 9.23 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0028577736132019303		[learning rate: 0.00010868]
	Learning Rate: 0.000108676
	LOSS [training: 0.0028577736132019303 | validation: 0.007236968821727576]
	TIME [epoch: 9.23 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003920673295310514		[learning rate: 0.00010834]
	Learning Rate: 0.000108343
	LOSS [training: 0.003920673295310514 | validation: 0.007797972999631591]
	TIME [epoch: 9.23 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0035472638564613577		[learning rate: 0.00010801]
	Learning Rate: 0.000108011
	LOSS [training: 0.0035472638564613577 | validation: 0.023845604066061156]
	TIME [epoch: 9.23 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.000911167225813931		[learning rate: 0.00010768]
	Learning Rate: 0.00010768
	LOSS [training: 0.000911167225813931 | validation: 0.006785653186799185]
	TIME [epoch: 9.25 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004183747361222278		[learning rate: 0.00010735]
	Learning Rate: 0.000107349
	LOSS [training: 0.004183747361222278 | validation: 0.020634899480903704]
	TIME [epoch: 9.23 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003330358890118213		[learning rate: 0.00010702]
	Learning Rate: 0.00010702
	LOSS [training: 0.003330358890118213 | validation: 0.005889575455998338]
	TIME [epoch: 9.23 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0013806021303448312		[learning rate: 0.00010669]
	Learning Rate: 0.000106692
	LOSS [training: 0.0013806021303448312 | validation: 0.0017413487027181773]
	TIME [epoch: 9.23 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0039546036650003075		[learning rate: 0.00010637]
	Learning Rate: 0.000106365
	LOSS [training: 0.0039546036650003075 | validation: 0.005351708050148975]
	TIME [epoch: 9.23 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001328133929427377		[learning rate: 0.00010604]
	Learning Rate: 0.000106039
	LOSS [training: 0.001328133929427377 | validation: -0.0010191373961934373]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1981.pth
	Model improved!!!
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019147970721323422		[learning rate: 0.00010571]
	Learning Rate: 0.000105714
	LOSS [training: 0.0019147970721323422 | validation: 0.004691791727314072]
	TIME [epoch: 9.22 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004020214834029877		[learning rate: 0.00010539]
	Learning Rate: 0.00010539
	LOSS [training: -0.004020214834029877 | validation: 0.0009114181605274422]
	TIME [epoch: 9.23 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009307854677206046		[learning rate: 0.00010507]
	Learning Rate: 0.000105067
	LOSS [training: 0.0009307854677206046 | validation: 0.007874260259027937]
	TIME [epoch: 9.22 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0001972813149138086		[learning rate: 0.00010474]
	Learning Rate: 0.000104745
	LOSS [training: 0.0001972813149138086 | validation: 0.010842478228974186]
	TIME [epoch: 9.23 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00015475071481816497		[learning rate: 0.00010442]
	Learning Rate: 0.000104424
	LOSS [training: 0.00015475071481816497 | validation: 0.003977028800639132]
	TIME [epoch: 9.23 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002392182014940096		[learning rate: 0.0001041]
	Learning Rate: 0.000104104
	LOSS [training: 0.002392182014940096 | validation: 0.012270980084072437]
	TIME [epoch: 9.22 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00012242264406339584		[learning rate: 0.00010378]
	Learning Rate: 0.000103785
	LOSS [training: -0.00012242264406339584 | validation: -0.0015102705874718864]
	TIME [epoch: 9.21 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_023827/states/model_tr_study4_1988.pth
	Model improved!!!
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010225036676381294		[learning rate: 0.00010347]
	Learning Rate: 0.000103467
	LOSS [training: 0.0010225036676381294 | validation: 0.005156740497833746]
	TIME [epoch: 9.23 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0010275071777417371		[learning rate: 0.00010315]
	Learning Rate: 0.000103149
	LOSS [training: -0.0010275071777417371 | validation: 0.0003488900056905352]
	TIME [epoch: 9.25 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0007448117569914203		[learning rate: 0.00010283]
	Learning Rate: 0.000102833
	LOSS [training: 0.0007448117569914203 | validation: 0.014733268002227094]
	TIME [epoch: 9.24 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008206314436213624		[learning rate: 0.00010252]
	Learning Rate: 0.000102518
	LOSS [training: 0.0008206314436213624 | validation: 0.01159593550258737]
	TIME [epoch: 9.23 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008632330430323347		[learning rate: 0.0001022]
	Learning Rate: 0.000102204
	LOSS [training: 0.0008632330430323347 | validation: 0.006813957267270072]
	TIME [epoch: 9.23 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004873654825938727		[learning rate: 0.00010189]
	Learning Rate: 0.00010189
	LOSS [training: 0.004873654825938727 | validation: 0.007258713729682948]
	TIME [epoch: 9.23 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0027377840606619508		[learning rate: 0.00010158]
	Learning Rate: 0.000101578
	LOSS [training: 0.0027377840606619508 | validation: 0.0100798392586582]
	TIME [epoch: 9.25 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0033412576027579285		[learning rate: 0.00010127]
	Learning Rate: 0.000101267
	LOSS [training: 0.0033412576027579285 | validation: 0.011325456987739794]
	TIME [epoch: 9.24 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005988214005949087		[learning rate: 0.00010096]
	Learning Rate: 0.000100956
	LOSS [training: 0.005988214005949087 | validation: 0.006989430015297736]
	TIME [epoch: 9.23 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0025795641782496936		[learning rate: 0.00010065]
	Learning Rate: 0.000100647
	LOSS [training: 0.0025795641782496936 | validation: 0.015256852690981452]
	TIME [epoch: 9.23 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0002472627341849557		[learning rate: 0.00010034]
	Learning Rate: 0.000100338
	LOSS [training: 0.0002472627341849557 | validation: 0.007237571069420397]
	TIME [epoch: 9.23 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0026015599381069947		[learning rate: 0.00010003]
	Learning Rate: 0.000100031
	LOSS [training: 0.0026015599381069947 | validation: 0.011812150255758824]
	TIME [epoch: 9.24 sec]
Finished training in 18782.650 seconds.
