Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r5', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1593410909

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 9.272029181820134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.272029181820134 | validation: 8.547760479279626]
	TIME [epoch: 79.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.44594627265343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.44594627265343 | validation: 8.300104261008928]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.165958901230425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.165958901230425 | validation: 7.682428265684092]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.644395513021704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.644395513021704 | validation: 6.149089593422887]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.894585839370244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.894585839370244 | validation: 5.900668133218641]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.56061406436226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.56061406436226 | validation: 6.684260169262664]
	TIME [epoch: 8.5 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.220474202697307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.220474202697307 | validation: 5.121866568315663]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.026494564777794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.026494564777794 | validation: 6.275080347658728]
	TIME [epoch: 8.52 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.167325676863339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.167325676863339 | validation: 5.095565850955309]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.1005447317940735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1005447317940735 | validation: 5.081907859928888]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.107440038579661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.107440038579661 | validation: 5.503832663089677]
	TIME [epoch: 8.53 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.299084541223653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.299084541223653 | validation: 6.455079520435429]
	TIME [epoch: 8.51 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.413189288994005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.413189288994005 | validation: 6.272796017403801]
	TIME [epoch: 8.5 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.816981746362519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.816981746362519 | validation: 7.9899061394048925]
	TIME [epoch: 8.49 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.051322188979646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.051322188979646 | validation: 4.954949699010006]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.486211817898746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.486211817898746 | validation: 4.752236798298965]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.490457030489132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.490457030489132 | validation: 4.985296585949565]
	TIME [epoch: 8.5 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.539979626786225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.539979626786225 | validation: 4.646865548641682]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.306183004617481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.306183004617481 | validation: 4.7592784285998135]
	TIME [epoch: 8.52 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.450844016416359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.450844016416359 | validation: 4.7039258687588505]
	TIME [epoch: 8.49 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.509189947016026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.509189947016026 | validation: 4.400599847159321]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.153171463042287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.153171463042287 | validation: 4.338904960252723]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.306930015749572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.306930015749572 | validation: 4.499136704790869]
	TIME [epoch: 8.53 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.293176617743132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.293176617743132 | validation: 4.671251497561929]
	TIME [epoch: 8.51 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.112539556337813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.112539556337813 | validation: 5.512077440162999]
	TIME [epoch: 8.51 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.510932254451829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.510932254451829 | validation: 4.375619546066639]
	TIME [epoch: 8.51 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.162150560618096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.162150560618096 | validation: 4.172641544963663]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.0333126155752606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0333126155752606 | validation: 5.653295291266424]
	TIME [epoch: 8.51 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.486250437240448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.486250437240448 | validation: 5.733446185986346]
	TIME [epoch: 8.5 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.101105173159919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.101105173159919 | validation: 3.950976004476341]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.672405803856724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.672405803856724 | validation: 5.14006240074095]
	TIME [epoch: 8.52 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.1386655350846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1386655350846 | validation: 3.801490343986983]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.5424248491962835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5424248491962835 | validation: 4.152489710388994]
	TIME [epoch: 8.51 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.415274275099529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.415274275099529 | validation: 4.442800070284646]
	TIME [epoch: 8.52 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.3616930884999565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3616930884999565 | validation: 3.587299741446051]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.212223388162714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.212223388162714 | validation: 3.9859252817193926]
	TIME [epoch: 8.51 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.355151525540278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.355151525540278 | validation: 4.312430796856132]
	TIME [epoch: 8.5 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.257229751355151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.257229751355151 | validation: 4.038686105467983]
	TIME [epoch: 8.53 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.006278864683444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.006278864683444 | validation: 4.235529244925328]
	TIME [epoch: 8.51 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.9712821815294403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9712821815294403 | validation: 3.236960114830624]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.7201382725421785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7201382725421785 | validation: 6.402400014902888]
	TIME [epoch: 8.51 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.88507731122516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.88507731122516 | validation: 3.693292609498804]
	TIME [epoch: 8.53 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.3790831764586273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3790831764586273 | validation: 3.3120747984654395]
	TIME [epoch: 8.5 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.874841727855043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.874841727855043 | validation: 4.380818396288575]
	TIME [epoch: 8.5 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.3244305559937843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3244305559937843 | validation: 2.288254699275859]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.8943631393904155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8943631393904155 | validation: 2.5750734043990002]
	TIME [epoch: 8.53 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.1336270992783395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1336270992783395 | validation: 3.4927042169228946]
	TIME [epoch: 8.5 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.530595239251389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.530595239251389 | validation: 2.7512473726778497]
	TIME [epoch: 8.49 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.570028132484511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.570028132484511 | validation: 2.952301112121554]
	TIME [epoch: 8.49 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3399069540468864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3399069540468864 | validation: 2.556117481937207]
	TIME [epoch: 8.52 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.1169767241446467		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 3.1169767241446467 | validation: 5.776561975918499]
	TIME [epoch: 8.5 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.5393888679128223		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 3.5393888679128223 | validation: 2.131849933072526]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_52.pth
	Model improved!!!
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.7563044162767185		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 2.7563044162767185 | validation: 3.4368298923324376]
	TIME [epoch: 8.5 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.6689097052181125		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 2.6689097052181125 | validation: 2.3396345528054217]
	TIME [epoch: 8.53 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.4296577940062547		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 2.4296577940062547 | validation: 2.4516339432681526]
	TIME [epoch: 8.5 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.704909070480381		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 2.704909070480381 | validation: 2.4166624996909007]
	TIME [epoch: 8.51 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.7688928542716935		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 2.7688928542716935 | validation: 2.4117356956529523]
	TIME [epoch: 8.52 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.496484274466011		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 2.496484274466011 | validation: 2.9074254691155046]
	TIME [epoch: 8.52 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.7680857006354396		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 2.7680857006354396 | validation: 3.3295415902645775]
	TIME [epoch: 8.51 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.318905850494592		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 2.318905850494592 | validation: 2.7605880236156413]
	TIME [epoch: 8.5 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.6498679226895856		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 2.6498679226895856 | validation: 2.499624070999375]
	TIME [epoch: 8.51 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.2335252937707497		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 2.2335252937707497 | validation: 3.3729466297396016]
	TIME [epoch: 8.51 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3578179178365		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 2.3578179178365 | validation: 1.9034333309234557]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_63.pth
	Model improved!!!
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3091908078848236		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 2.3091908078848236 | validation: 1.806538758787035]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_64.pth
	Model improved!!!
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.3458182756210535		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 2.3458182756210535 | validation: 2.23394945931508]
	TIME [epoch: 8.52 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.098679948219065		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 2.098679948219065 | validation: 1.617788720395228]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_66.pth
	Model improved!!!
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.745066817716784		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 2.745066817716784 | validation: 1.5372831263535374]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_67.pth
	Model improved!!!
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0514738842706164		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 2.0514738842706164 | validation: 1.9435621961037668]
	TIME [epoch: 8.5 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9470283028209683		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 1.9470283028209683 | validation: 2.33291320181457]
	TIME [epoch: 8.51 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.014572367728072		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 2.014572367728072 | validation: 1.7726844570262854]
	TIME [epoch: 8.51 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.05795166891039		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 2.05795166891039 | validation: 2.0189529613717134]
	TIME [epoch: 8.49 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.380676329630697		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 2.380676329630697 | validation: 1.817210359558137]
	TIME [epoch: 8.49 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6491030783102758		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 1.6491030783102758 | validation: 1.7758930608413181]
	TIME [epoch: 8.52 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5988232213747189		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 1.5988232213747189 | validation: 1.3710528373887683]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_74.pth
	Model improved!!!
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5459765952073783		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 1.5459765952073783 | validation: 2.406160427046075]
	TIME [epoch: 8.49 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.1337280448761136		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 2.1337280448761136 | validation: 1.3949322022142514]
	TIME [epoch: 8.49 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5372786666623832		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 1.5372786666623832 | validation: 1.8208000933813833]
	TIME [epoch: 8.52 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.598582663669133		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 1.598582663669133 | validation: 1.8822742928615699]
	TIME [epoch: 8.49 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4598352187003105		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 1.4598352187003105 | validation: 1.454414136519004]
	TIME [epoch: 8.49 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6875234520961395		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 1.6875234520961395 | validation: 1.4207975162043356]
	TIME [epoch: 8.49 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5449414260317809		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 1.5449414260317809 | validation: 1.9368050354691777]
	TIME [epoch: 8.52 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4670803652354434		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 1.4670803652354434 | validation: 2.1096069424307786]
	TIME [epoch: 8.49 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4959057778429226		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 1.4959057778429226 | validation: 1.84137955812372]
	TIME [epoch: 8.49 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4527058329724412		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 1.4527058329724412 | validation: 1.793157578679335]
	TIME [epoch: 8.5 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7999202653775523		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 1.7999202653775523 | validation: 1.2330181598711931]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_85.pth
	Model improved!!!
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.501363897260183		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 1.501363897260183 | validation: 1.4707144357877442]
	TIME [epoch: 8.49 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4604593485063444		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 1.4604593485063444 | validation: 1.3431462244726027]
	TIME [epoch: 8.5 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5474863427917969		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.5474863427917969 | validation: 1.3429140822889496]
	TIME [epoch: 8.5 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5966044697966084		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.5966044697966084 | validation: 2.442247323446005]
	TIME [epoch: 8.51 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4901358853118516		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.4901358853118516 | validation: 1.3529433106633073]
	TIME [epoch: 8.49 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4283694957914261		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 1.4283694957914261 | validation: 2.0466471526131995]
	TIME [epoch: 8.5 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6237133503659529		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 1.6237133503659529 | validation: 1.952973160656029]
	TIME [epoch: 8.5 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4891887103242158		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 1.4891887103242158 | validation: 1.6525123460516034]
	TIME [epoch: 8.51 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.324171090938941		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 1.324171090938941 | validation: 1.3585614987950454]
	TIME [epoch: 8.5 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5306371203286837		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 1.5306371203286837 | validation: 1.4610734702342358]
	TIME [epoch: 8.49 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3074766519592342		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.3074766519592342 | validation: 1.2928707590841169]
	TIME [epoch: 8.52 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4366365553532154		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 1.4366365553532154 | validation: 1.134503713270847]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_97.pth
	Model improved!!!
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4176072513766467		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.4176072513766467 | validation: 1.3054385974139424]
	TIME [epoch: 8.5 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.331928045634663		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.331928045634663 | validation: 1.9710218968964544]
	TIME [epoch: 8.49 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.413291504047596		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.413291504047596 | validation: 1.1880019727236801]
	TIME [epoch: 8.51 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.343426233611086		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.343426233611086 | validation: 1.4375343180486015]
	TIME [epoch: 8.5 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4398233575290127		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.4398233575290127 | validation: 1.8030830970187859]
	TIME [epoch: 8.49 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4123685849865795		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.4123685849865795 | validation: 1.6072263078556643]
	TIME [epoch: 8.49 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3951410911772897		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.3951410911772897 | validation: 1.7617669944069174]
	TIME [epoch: 8.52 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.637222712178497		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 1.637222712178497 | validation: 1.1124286297091346]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_105.pth
	Model improved!!!
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4007485667535111		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 1.4007485667535111 | validation: 1.2462930475428475]
	TIME [epoch: 8.5 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.315209420047192		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 1.315209420047192 | validation: 1.2218057568868228]
	TIME [epoch: 8.49 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.434238140720924		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.434238140720924 | validation: 1.2698890584634903]
	TIME [epoch: 8.52 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3266974286913154		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.3266974286913154 | validation: 1.3018852184713048]
	TIME [epoch: 8.5 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3856906206562845		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.3856906206562845 | validation: 1.2084864614304174]
	TIME [epoch: 8.49 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.236773468579067		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.236773468579067 | validation: 1.5932766380384469]
	TIME [epoch: 8.49 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2390315048056755		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 1.2390315048056755 | validation: 1.3386814234577527]
	TIME [epoch: 8.53 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.354433829588022		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 1.354433829588022 | validation: 1.8055771542086845]
	TIME [epoch: 8.49 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6393261418997749		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 1.6393261418997749 | validation: 1.7297626366813252]
	TIME [epoch: 8.49 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2550981299478767		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.2550981299478767 | validation: 1.7352313970473139]
	TIME [epoch: 8.49 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3590219442555123		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 1.3590219442555123 | validation: 1.0991891814727452]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_116.pth
	Model improved!!!
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4946344571042505		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 1.4946344571042505 | validation: 1.4439222841528996]
	TIME [epoch: 8.5 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2914068069417612		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 1.2914068069417612 | validation: 1.494459620673143]
	TIME [epoch: 8.48 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3622712462225182		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 1.3622712462225182 | validation: 1.2718396707236548]
	TIME [epoch: 8.48 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3172657809107382		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.3172657809107382 | validation: 1.4278615106651098]
	TIME [epoch: 8.51 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3356527548065609		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 1.3356527548065609 | validation: 1.3756607142312882]
	TIME [epoch: 8.48 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.304505130942473		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 1.304505130942473 | validation: 1.4118971261369984]
	TIME [epoch: 8.49 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2565924861734774		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 1.2565924861734774 | validation: 1.2331567233966734]
	TIME [epoch: 8.48 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.293400374595655		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 1.293400374595655 | validation: 1.1361448769253006]
	TIME [epoch: 8.51 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2379845188841494		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 1.2379845188841494 | validation: 2.9549907601892036]
	TIME [epoch: 8.48 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5056822923883058		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 1.5056822923883058 | validation: 1.133797399317672]
	TIME [epoch: 8.48 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2663207767380347		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 1.2663207767380347 | validation: 1.272717451204649]
	TIME [epoch: 8.49 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3056290725484199		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.3056290725484199 | validation: 1.6711295133804]
	TIME [epoch: 8.5 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4643419387263708		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 1.4643419387263708 | validation: 1.3648248310176339]
	TIME [epoch: 8.49 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.278756067550125		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 1.278756067550125 | validation: 1.353975767193369]
	TIME [epoch: 8.5 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.309831605060588		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 1.309831605060588 | validation: 1.1875517594370675]
	TIME [epoch: 8.51 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2567773849570891		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 1.2567773849570891 | validation: 1.2053879884134122]
	TIME [epoch: 8.5 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2208093813450642		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 1.2208093813450642 | validation: 1.1621202984963668]
	TIME [epoch: 8.49 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1310038687011876		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 1.1310038687011876 | validation: 1.1977591682550897]
	TIME [epoch: 8.49 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3047037591424824		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 1.3047037591424824 | validation: 1.6827468866920408]
	TIME [epoch: 8.5 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3758707017016305		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 1.3758707017016305 | validation: 1.1103256797999492]
	TIME [epoch: 8.49 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3099155481636302		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 1.3099155481636302 | validation: 1.2650993495330396]
	TIME [epoch: 8.49 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3124997321261553		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.3124997321261553 | validation: 1.2109744585708941]
	TIME [epoch: 8.49 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2625672062217643		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 1.2625672062217643 | validation: 1.0237150876970886]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_139.pth
	Model improved!!!
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2033732381041782		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 1.2033732381041782 | validation: 1.1622889944078403]
	TIME [epoch: 8.5 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2872846069542299		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 1.2872846069542299 | validation: 1.2688814540180853]
	TIME [epoch: 8.48 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1335592230709919		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 1.1335592230709919 | validation: 1.1093383132189385]
	TIME [epoch: 8.49 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1585923306627965		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 1.1585923306627965 | validation: 1.1255627196102962]
	TIME [epoch: 8.51 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2322779227214962		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 1.2322779227214962 | validation: 1.5343976405566448]
	TIME [epoch: 8.49 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.16816602084988		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 1.16816602084988 | validation: 1.3468434957873923]
	TIME [epoch: 8.49 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1044038861856262		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 1.1044038861856262 | validation: 1.3300282498407134]
	TIME [epoch: 8.48 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2091093596808498		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 1.2091093596808498 | validation: 1.917266159563939]
	TIME [epoch: 8.51 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3454725983988243		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 1.3454725983988243 | validation: 1.4280854391222833]
	TIME [epoch: 8.49 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1532522240034413		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 1.1532522240034413 | validation: 0.9495459952225032]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_149.pth
	Model improved!!!
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3756941189070315		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 1.3756941189070315 | validation: 1.0505457577307895]
	TIME [epoch: 8.5 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2549787145937896		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 1.2549787145937896 | validation: 1.119678976501758]
	TIME [epoch: 8.52 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1662410573646216		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 1.1662410573646216 | validation: 1.019459228461426]
	TIME [epoch: 8.49 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1588041436370653		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 1.1588041436370653 | validation: 1.0498188764828456]
	TIME [epoch: 8.49 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3062027376595335		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 1.3062027376595335 | validation: 1.0683242946647684]
	TIME [epoch: 8.48 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1248395509170954		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 1.1248395509170954 | validation: 1.263029742589316]
	TIME [epoch: 8.5 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0965845972813515		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 1.0965845972813515 | validation: 1.4710947436952142]
	TIME [epoch: 8.49 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.149541350029488		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 1.149541350029488 | validation: 1.3431167248968647]
	TIME [epoch: 8.48 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0382976953215501		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 1.0382976953215501 | validation: 0.9692871991469469]
	TIME [epoch: 8.48 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2143024710748975		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 1.2143024710748975 | validation: 0.9374314461652459]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_159.pth
	Model improved!!!
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0610135878546338		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 1.0610135878546338 | validation: 1.17089837213616]
	TIME [epoch: 8.48 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1695602199856099		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 1.1695602199856099 | validation: 1.6820881415467253]
	TIME [epoch: 8.48 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2791099741612935		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 1.2791099741612935 | validation: 1.1472455049250903]
	TIME [epoch: 8.49 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.148357073606911		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 1.148357073606911 | validation: 1.1439335832050466]
	TIME [epoch: 8.51 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.247444198470164		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 1.247444198470164 | validation: 1.463240368385846]
	TIME [epoch: 8.48 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.207775671568362		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 1.207775671568362 | validation: 1.0358894241679324]
	TIME [epoch: 8.48 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2656089109704012		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 1.2656089109704012 | validation: 1.5623319209435524]
	TIME [epoch: 8.49 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1151088982292334		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 1.1151088982292334 | validation: 1.209501452107472]
	TIME [epoch: 8.5 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.344511098137112		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 1.344511098137112 | validation: 1.1562027927480458]
	TIME [epoch: 8.48 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.089909469143866		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 1.089909469143866 | validation: 1.0785274515751226]
	TIME [epoch: 8.48 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1276363864502266		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 1.1276363864502266 | validation: 1.0158512206014885]
	TIME [epoch: 8.51 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1646325542549822		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 1.1646325542549822 | validation: 0.9902506989298904]
	TIME [epoch: 8.48 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2871505193534487		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 1.2871505193534487 | validation: 1.2535246484795528]
	TIME [epoch: 8.48 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1368766789454736		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 1.1368766789454736 | validation: 1.0674167583104772]
	TIME [epoch: 8.48 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0165616718854107		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 1.0165616718854107 | validation: 1.1941681797967667]
	TIME [epoch: 8.5 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1407137621629884		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 1.1407137621629884 | validation: 0.934305715456466]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_175.pth
	Model improved!!!
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1374629395589122		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 1.1374629395589122 | validation: 1.37049115770205]
	TIME [epoch: 8.48 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1123868083083568		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 1.1123868083083568 | validation: 1.1425252542013797]
	TIME [epoch: 8.48 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.09535443265244		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 1.09535443265244 | validation: 1.6232937771700566]
	TIME [epoch: 8.5 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0307527843036595		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 1.0307527843036595 | validation: 1.034945973694961]
	TIME [epoch: 8.49 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9803081434988199		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.9803081434988199 | validation: 1.4830688792313826]
	TIME [epoch: 8.49 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0494315869261097		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 1.0494315869261097 | validation: 1.2845134903247817]
	TIME [epoch: 8.48 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0835567733424096		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 1.0835567733424096 | validation: 1.0937291501546527]
	TIME [epoch: 8.5 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.078849644209612		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 1.078849644209612 | validation: 1.0538866688479913]
	TIME [epoch: 8.48 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0676201498396984		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 1.0676201498396984 | validation: 1.0743714902542236]
	TIME [epoch: 8.48 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1034458742826283		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 1.1034458742826283 | validation: 1.3691991446869454]
	TIME [epoch: 8.49 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.135505536056933		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 1.135505536056933 | validation: 1.0652747556343245]
	TIME [epoch: 8.51 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1019226907485529		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 1.1019226907485529 | validation: 1.2638674002034673]
	TIME [epoch: 8.49 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0477804434310456		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 1.0477804434310456 | validation: 1.2040006331444177]
	TIME [epoch: 8.49 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5516808645382105		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 1.5516808645382105 | validation: 1.1825787017964504]
	TIME [epoch: 8.48 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.099584204224123		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 1.099584204224123 | validation: 1.1996176803500098]
	TIME [epoch: 8.5 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.112756402246538		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 1.112756402246538 | validation: 1.3755449930553585]
	TIME [epoch: 8.49 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1522251349386397		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 1.1522251349386397 | validation: 1.5124178229795922]
	TIME [epoch: 8.48 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0499154369367525		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 1.0499154369367525 | validation: 1.0447997767451218]
	TIME [epoch: 8.49 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0445628919423222		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 1.0445628919423222 | validation: 0.9144974404226619]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_194.pth
	Model improved!!!
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0319596945421716		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 1.0319596945421716 | validation: 1.0136452353966914]
	TIME [epoch: 8.49 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9288640636018013		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.9288640636018013 | validation: 1.3661408386721843]
	TIME [epoch: 8.48 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0661740639697317		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 1.0661740639697317 | validation: 1.164762550469541]
	TIME [epoch: 8.48 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.036378244670038		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 1.036378244670038 | validation: 1.13585145716555]
	TIME [epoch: 8.5 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0392922865212868		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 1.0392922865212868 | validation: 1.0588696864170186]
	TIME [epoch: 8.48 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1333069687123012		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 1.1333069687123012 | validation: 1.3172953792227293]
	TIME [epoch: 8.47 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.042909533158725		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 1.042909533158725 | validation: 1.084056587936659]
	TIME [epoch: 8.49 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1404647264279473		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 1.1404647264279473 | validation: 0.9267375136178513]
	TIME [epoch: 8.49 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1136031675456468		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 1.1136031675456468 | validation: 1.2920916517604042]
	TIME [epoch: 8.49 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9973617511826637		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.9973617511826637 | validation: 1.2762260566192782]
	TIME [epoch: 8.49 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0579455235204194		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 1.0579455235204194 | validation: 1.3001362727342287]
	TIME [epoch: 8.48 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1160221482869732		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 1.1160221482869732 | validation: 2.067943379765926]
	TIME [epoch: 8.5 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1146218668360572		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 1.1146218668360572 | validation: 0.9701130235195883]
	TIME [epoch: 8.48 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9947642495225878		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.9947642495225878 | validation: 0.8786410484517664]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_208.pth
	Model improved!!!
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9734044733459614		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.9734044733459614 | validation: 0.8710542684756607]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_209.pth
	Model improved!!!
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9583446672370549		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.9583446672370549 | validation: 1.4763775861745478]
	TIME [epoch: 8.49 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0060559526782769		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 1.0060559526782769 | validation: 1.0499378112674627]
	TIME [epoch: 8.48 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.195841206441712		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 1.195841206441712 | validation: 1.752638830539178]
	TIME [epoch: 8.48 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1504555228451825		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 1.1504555228451825 | validation: 1.2982073628983146]
	TIME [epoch: 8.49 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.044314661889072		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 1.044314661889072 | validation: 0.9717164056635197]
	TIME [epoch: 8.48 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9990068424080073		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.9990068424080073 | validation: 0.7667698164898121]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_215.pth
	Model improved!!!
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1337273853017467		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 1.1337273853017467 | validation: 0.9205413956278261]
	TIME [epoch: 8.5 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9703115270314424		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.9703115270314424 | validation: 0.9210423203099406]
	TIME [epoch: 8.52 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0327430237407174		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 1.0327430237407174 | validation: 1.6014228283957634]
	TIME [epoch: 8.5 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0070314039395567		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 1.0070314039395567 | validation: 1.1687798074697646]
	TIME [epoch: 8.5 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9848276092019155		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.9848276092019155 | validation: 0.998191151236542]
	TIME [epoch: 8.49 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8545683045528654		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.8545683045528654 | validation: 1.0688226718698808]
	TIME [epoch: 8.53 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.930706492072004		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.930706492072004 | validation: 1.0728689245256244]
	TIME [epoch: 8.5 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9466979036410953		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.9466979036410953 | validation: 1.0635582267815393]
	TIME [epoch: 8.5 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0102938685589096		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 1.0102938685589096 | validation: 1.6254213009444376]
	TIME [epoch: 8.5 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.181710367920556		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 1.181710367920556 | validation: 1.5472146190403522]
	TIME [epoch: 8.52 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9469932653516999		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.9469932653516999 | validation: 1.3638644063322416]
	TIME [epoch: 8.51 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9213935705365209		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.9213935705365209 | validation: 0.9950444794341007]
	TIME [epoch: 8.49 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9725424062147028		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.9725424062147028 | validation: 0.7700838746444891]
	TIME [epoch: 8.5 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0253743912197042		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 1.0253743912197042 | validation: 0.7279065649152653]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_229.pth
	Model improved!!!
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.01555323594528		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 1.01555323594528 | validation: 1.4726745147744573]
	TIME [epoch: 8.5 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9174430078767634		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.9174430078767634 | validation: 0.9689338772198419]
	TIME [epoch: 8.5 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8717398872877139		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.8717398872877139 | validation: 0.8168337723608037]
	TIME [epoch: 8.5 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.855054389410221		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.855054389410221 | validation: 0.9421749106452391]
	TIME [epoch: 8.52 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9113865504811107		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.9113865504811107 | validation: 0.795723643329153]
	TIME [epoch: 8.5 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9671114523538156		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.9671114523538156 | validation: 0.7063247739540752]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_235.pth
	Model improved!!!
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9186888681004473		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.9186888681004473 | validation: 0.9492708734389075]
	TIME [epoch: 8.5 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.861605979199916		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.861605979199916 | validation: 1.2976626737040038]
	TIME [epoch: 8.51 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8522887806111183		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.8522887806111183 | validation: 0.9757932034418537]
	TIME [epoch: 8.5 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.149839313126756		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 1.149839313126756 | validation: 0.9227132311060591]
	TIME [epoch: 8.5 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8979314659061384		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.8979314659061384 | validation: 0.9406534764100215]
	TIME [epoch: 8.52 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9114219920428628		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.9114219920428628 | validation: 0.7854281247761189]
	TIME [epoch: 8.5 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9998178228511396		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.9998178228511396 | validation: 0.897034226182958]
	TIME [epoch: 8.5 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9160531579388749		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.9160531579388749 | validation: 0.7735974411681142]
	TIME [epoch: 8.5 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8485235136694376		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.8485235136694376 | validation: 0.7315299903635748]
	TIME [epoch: 8.52 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1777097331258461		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 1.1777097331258461 | validation: 0.9688602974883019]
	TIME [epoch: 8.5 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9639815094093945		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.9639815094093945 | validation: 1.1286425262293516]
	TIME [epoch: 8.5 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1123658023993745		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 1.1123658023993745 | validation: 0.6782959523666493]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_247.pth
	Model improved!!!
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9364438918197135		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.9364438918197135 | validation: 1.1411489808249007]
	TIME [epoch: 8.52 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9333295164206692		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.9333295164206692 | validation: 0.8182837476031308]
	TIME [epoch: 8.5 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0258911713845043		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 1.0258911713845043 | validation: 0.8216529438580518]
	TIME [epoch: 8.49 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8985714383988027		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.8985714383988027 | validation: 0.8117809092954427]
	TIME [epoch: 8.49 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8762472208824178		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.8762472208824178 | validation: 0.9714336634954843]
	TIME [epoch: 8.51 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.840388060750014		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.840388060750014 | validation: 0.984739497238458]
	TIME [epoch: 8.5 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9484705107366211		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.9484705107366211 | validation: 1.1062914609998868]
	TIME [epoch: 8.49 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1171315476014378		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 1.1171315476014378 | validation: 0.9337920341155174]
	TIME [epoch: 8.49 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9015917231492141		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.9015917231492141 | validation: 0.8094929600680159]
	TIME [epoch: 8.51 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9105081700859149		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.9105081700859149 | validation: 0.9047667260152398]
	TIME [epoch: 8.5 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8584484352117248		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.8584484352117248 | validation: 1.0532049954751672]
	TIME [epoch: 8.49 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8984941396763988		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.8984941396763988 | validation: 1.07830228486237]
	TIME [epoch: 8.49 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9358361221455815		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.9358361221455815 | validation: 1.0603795713118842]
	TIME [epoch: 8.51 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8952534965439792		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.8952534965439792 | validation: 0.8358568875781982]
	TIME [epoch: 8.49 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9527812904383811		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.9527812904383811 | validation: 1.1923053116917675]
	TIME [epoch: 8.49 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9401498171862634		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.9401498171862634 | validation: 0.9126096425822654]
	TIME [epoch: 8.49 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9476122115607234		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.9476122115607234 | validation: 1.1233913808810891]
	TIME [epoch: 8.52 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0123651961681661		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 1.0123651961681661 | validation: 0.9899134397750738]
	TIME [epoch: 8.49 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9125628630336109		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.9125628630336109 | validation: 0.871044977764088]
	TIME [epoch: 8.49 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.910961807993681		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.910961807993681 | validation: 0.7894869358264642]
	TIME [epoch: 8.52 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.986428343505539		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.986428343505539 | validation: 0.9312358121237971]
	TIME [epoch: 8.53 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8218527890072783		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.8218527890072783 | validation: 1.071437145225505]
	TIME [epoch: 8.5 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9571181910255764		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.9571181910255764 | validation: 1.0439074063575762]
	TIME [epoch: 8.51 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9070134125479707		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.9070134125479707 | validation: 0.8478750487989621]
	TIME [epoch: 8.51 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9245585366392541		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.9245585366392541 | validation: 0.7467064106385188]
	TIME [epoch: 8.52 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7503502547069619		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.7503502547069619 | validation: 0.9118431865612109]
	TIME [epoch: 8.5 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7927604435448836		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.7927604435448836 | validation: 0.9675553706688017]
	TIME [epoch: 8.5 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8715169771082435		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.8715169771082435 | validation: 1.4813897251190284]
	TIME [epoch: 8.5 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9440631883083691		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.9440631883083691 | validation: 1.6016447954683768]
	TIME [epoch: 8.52 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9565586101031137		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.9565586101031137 | validation: 1.038051694888321]
	TIME [epoch: 8.5 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8904497666521536		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.8904497666521536 | validation: 1.8429287877570335]
	TIME [epoch: 8.49 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9830150876736787		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.9830150876736787 | validation: 0.6884062561862125]
	TIME [epoch: 8.51 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7740743033708269		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.7740743033708269 | validation: 0.7282840735769713]
	TIME [epoch: 8.51 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9006603545862009		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.9006603545862009 | validation: 0.6980372019088279]
	TIME [epoch: 8.5 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8437918613998345		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.8437918613998345 | validation: 0.6476002654868177]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_282.pth
	Model improved!!!
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7834918921952821		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.7834918921952821 | validation: 1.4985796037704247]
	TIME [epoch: 8.51 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8826022261149369		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.8826022261149369 | validation: 0.9130015996275402]
	TIME [epoch: 8.49 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8674935366014349		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.8674935366014349 | validation: 0.6718311832834172]
	TIME [epoch: 8.49 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9666188611341076		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.9666188611341076 | validation: 0.6671051475274619]
	TIME [epoch: 8.49 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8950207901966364		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.8950207901966364 | validation: 1.064371979595316]
	TIME [epoch: 8.51 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7638056984968324		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.7638056984968324 | validation: 1.0191594781962277]
	TIME [epoch: 8.49 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9642580742601169		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.9642580742601169 | validation: 1.37266031385253]
	TIME [epoch: 8.48 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0172127991361153		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 1.0172127991361153 | validation: 1.4605374745522464]
	TIME [epoch: 8.49 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8477389641879254		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.8477389641879254 | validation: 0.959378268062693]
	TIME [epoch: 8.51 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8448911738022729		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.8448911738022729 | validation: 0.9810317109444655]
	TIME [epoch: 8.49 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9666835377022723		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.9666835377022723 | validation: 0.8733392580785395]
	TIME [epoch: 8.49 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8102807915843092		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.8102807915843092 | validation: 0.706691648020074]
	TIME [epoch: 8.48 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.865467323436912		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.865467323436912 | validation: 1.2673021868933256]
	TIME [epoch: 8.51 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7522051263736474		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.7522051263736474 | validation: 0.9246303475945652]
	TIME [epoch: 8.49 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7699836668584502		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.7699836668584502 | validation: 1.1465651679402713]
	TIME [epoch: 8.49 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.009536007859897		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 1.009536007859897 | validation: 0.7179745380231295]
	TIME [epoch: 8.48 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9807821177700962		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.9807821177700962 | validation: 0.7944062644208416]
	TIME [epoch: 8.52 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8394605560739583		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.8394605560739583 | validation: 0.6738779784811294]
	TIME [epoch: 8.49 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8117639561002736		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.8117639561002736 | validation: 1.4761126543248173]
	TIME [epoch: 8.49 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8564033534313052		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.8564033534313052 | validation: 0.6599601357594225]
	TIME [epoch: 8.48 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7023382263967201		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.7023382263967201 | validation: 0.6023787902067361]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_303.pth
	Model improved!!!
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8631474890565721		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.8631474890565721 | validation: 1.1416446797374347]
	TIME [epoch: 8.49 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9434254985150778		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.9434254985150778 | validation: 1.2877420029919446]
	TIME [epoch: 8.5 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8317282342363541		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.8317282342363541 | validation: 1.4464411297467166]
	TIME [epoch: 8.5 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9269164915794887		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.9269164915794887 | validation: 1.1674721469203129]
	TIME [epoch: 8.51 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7944512428985597		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.7944512428985597 | validation: 0.6387423454502723]
	TIME [epoch: 8.49 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8540766915786534		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.8540766915786534 | validation: 0.9239797943940921]
	TIME [epoch: 8.49 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9105015151076685		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.9105015151076685 | validation: 0.9887889091105629]
	TIME [epoch: 8.5 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8586494549916683		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.8586494549916683 | validation: 0.9565126844933602]
	TIME [epoch: 8.52 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.837852241183071		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.837852241183071 | validation: 0.6231615949234239]
	TIME [epoch: 8.49 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8090894636766265		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.8090894636766265 | validation: 1.0573103095774061]
	TIME [epoch: 8.5 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8973497941969019		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.8973497941969019 | validation: 1.0589737616432249]
	TIME [epoch: 8.51 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9490551629821986		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.9490551629821986 | validation: 0.830528874781703]
	TIME [epoch: 8.49 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8511422353058619		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.8511422353058619 | validation: 0.8964869664291533]
	TIME [epoch: 8.49 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0177006661747021		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 1.0177006661747021 | validation: 1.2359057469010517]
	TIME [epoch: 8.49 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8415342573672862		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.8415342573672862 | validation: 0.7992695201213323]
	TIME [epoch: 8.52 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7539816498107367		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.7539816498107367 | validation: 0.8594105326255874]
	TIME [epoch: 8.5 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7733730589285488		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.7733730589285488 | validation: 0.688776326149084]
	TIME [epoch: 8.48 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8046624425556255		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.8046624425556255 | validation: 0.8755979578135835]
	TIME [epoch: 8.49 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8162177272293167		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.8162177272293167 | validation: 0.6618759462224267]
	TIME [epoch: 8.52 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8940860252720106		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.8940860252720106 | validation: 0.9516059899986288]
	TIME [epoch: 8.5 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7303383788857422		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.7303383788857422 | validation: 0.8025799496424761]
	TIME [epoch: 8.48 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0804881201775804		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 1.0804881201775804 | validation: 3.0530345613524625]
	TIME [epoch: 8.49 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1848274212105447		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 1.1848274212105447 | validation: 0.9032115393569593]
	TIME [epoch: 8.51 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2068321579472108		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 1.2068321579472108 | validation: 0.637187260944247]
	TIME [epoch: 8.51 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7121398034213794		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.7121398034213794 | validation: 1.0151002892330037]
	TIME [epoch: 8.49 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7800848688375243		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.7800848688375243 | validation: 0.6866439677360667]
	TIME [epoch: 8.49 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7860607387903983		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.7860607387903983 | validation: 1.4719349678587788]
	TIME [epoch: 8.51 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9704229207748885		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.9704229207748885 | validation: 0.9013627794978103]
	TIME [epoch: 8.49 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8899060920998527		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.8899060920998527 | validation: 1.136001886946154]
	TIME [epoch: 8.49 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8392856644632702		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.8392856644632702 | validation: 0.936556940425458]
	TIME [epoch: 8.48 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9116028469014376		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.9116028469014376 | validation: 0.9099806786375827]
	TIME [epoch: 8.51 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8513041441056404		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.8513041441056404 | validation: 1.1975171544888092]
	TIME [epoch: 8.49 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8912431648581581		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.8912431648581581 | validation: 0.8111439512579732]
	TIME [epoch: 8.49 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8670764300126297		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.8670764300126297 | validation: 0.8607459262342341]
	TIME [epoch: 8.49 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7599102178498613		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.7599102178498613 | validation: 0.8499965398240927]
	TIME [epoch: 8.51 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8368605936538793		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.8368605936538793 | validation: 0.7540697293604288]
	TIME [epoch: 8.49 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7318087244763974		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.7318087244763974 | validation: 0.741884335748751]
	TIME [epoch: 8.48 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8674590719143171		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.8674590719143171 | validation: 0.9435962954439667]
	TIME [epoch: 8.49 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8715416932081128		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.8715416932081128 | validation: 0.7697467343803197]
	TIME [epoch: 8.51 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7966274372108885		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.7966274372108885 | validation: 0.837433087797385]
	TIME [epoch: 8.49 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9606943008776654		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.9606943008776654 | validation: 0.8597185346498724]
	TIME [epoch: 8.48 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7727112817053096		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.7727112817053096 | validation: 0.7340191218041772]
	TIME [epoch: 8.49 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8377133019370765		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.8377133019370765 | validation: 0.8057571615210515]
	TIME [epoch: 8.51 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8516599487235312		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.8516599487235312 | validation: 0.8278396900727295]
	TIME [epoch: 8.49 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7738386375951845		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.7738386375951845 | validation: 0.8008975846348207]
	TIME [epoch: 8.49 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7978411039885088		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.7978411039885088 | validation: 0.7134586431489467]
	TIME [epoch: 8.51 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8752308732368117		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.8752308732368117 | validation: 1.2411498163416184]
	TIME [epoch: 8.5 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7866814921024246		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.7866814921024246 | validation: 0.738951132986045]
	TIME [epoch: 8.5 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9962959070757276		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.9962959070757276 | validation: 0.847639815212778]
	TIME [epoch: 8.49 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9570612339396695		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.9570612339396695 | validation: 0.720076570752213]
	TIME [epoch: 8.5 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8967617804988361		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.8967617804988361 | validation: 0.6989912642986351]
	TIME [epoch: 8.51 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8060321219048777		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.8060321219048777 | validation: 0.8959981906000483]
	TIME [epoch: 8.49 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9008862279117646		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.9008862279117646 | validation: 0.8465654401284151]
	TIME [epoch: 8.5 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8656500103332583		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.8656500103332583 | validation: 1.1031763892628452]
	TIME [epoch: 8.51 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7819711473427591		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.7819711473427591 | validation: 1.1148048398270154]
	TIME [epoch: 8.5 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7438190959476323		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.7438190959476323 | validation: 1.1399589496750235]
	TIME [epoch: 8.5 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.88826772192294		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.88826772192294 | validation: 0.7852801848941046]
	TIME [epoch: 8.5 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7854553723265312		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.7854553723265312 | validation: 1.1510384334792798]
	TIME [epoch: 8.51 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8691972158255858		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.8691972158255858 | validation: 3.0357040824731176]
	TIME [epoch: 8.51 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.002316310495428		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 1.002316310495428 | validation: 1.1897185808564386]
	TIME [epoch: 8.5 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.892010384866351		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.892010384866351 | validation: 0.9660389621215761]
	TIME [epoch: 8.49 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.820822019601495		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.820822019601495 | validation: 0.6697822635995814]
	TIME [epoch: 8.51 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7375511284929082		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.7375511284929082 | validation: 0.7121307420492973]
	TIME [epoch: 8.5 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8362450219829809		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.8362450219829809 | validation: 3.7863572306399265]
	TIME [epoch: 8.5 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.228259015368985		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 1.228259015368985 | validation: 0.6866544479709833]
	TIME [epoch: 8.49 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6766988195713024		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.6766988195713024 | validation: 0.8444963935439769]
	TIME [epoch: 8.51 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7044263080061373		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.7044263080061373 | validation: 0.920081850399652]
	TIME [epoch: 8.5 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.717701293113866		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.717701293113866 | validation: 0.8807431763538687]
	TIME [epoch: 8.49 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.684995125125735		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.684995125125735 | validation: 1.7543851969318118]
	TIME [epoch: 8.5 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9931762479578907		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.9931762479578907 | validation: 0.9607657446109588]
	TIME [epoch: 8.51 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8771490210829201		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.8771490210829201 | validation: 1.2296901015610189]
	TIME [epoch: 8.5 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8358177764929227		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.8358177764929227 | validation: 0.7083457205294051]
	TIME [epoch: 8.5 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0554323706971522		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 1.0554323706971522 | validation: 0.8604610180055945]
	TIME [epoch: 8.49 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6917475806947565		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.6917475806947565 | validation: 1.5223415714088047]
	TIME [epoch: 8.52 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8544436467293733		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.8544436467293733 | validation: 0.8713906075341373]
	TIME [epoch: 8.49 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7123873663882032		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.7123873663882032 | validation: 0.6749168092595728]
	TIME [epoch: 8.49 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9298986963206195		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.9298986963206195 | validation: 1.0229905843381906]
	TIME [epoch: 8.5 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7374675650152144		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.7374675650152144 | validation: 0.6698303004383406]
	TIME [epoch: 8.52 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.851408888176407		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.851408888176407 | validation: 0.9654387124060281]
	TIME [epoch: 8.51 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8756518283105746		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.8756518283105746 | validation: 0.6437930430806189]
	TIME [epoch: 8.5 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6342100531632011		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.6342100531632011 | validation: 0.7673555298201743]
	TIME [epoch: 8.5 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7665082872384764		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.7665082872384764 | validation: 0.8639900631187127]
	TIME [epoch: 8.52 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8285111716806555		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.8285111716806555 | validation: 0.6835593734298617]
	TIME [epoch: 8.5 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7134089359182956		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.7134089359182956 | validation: 0.7022994334704329]
	TIME [epoch: 8.49 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8734465473376556		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.8734465473376556 | validation: 0.9212380209856685]
	TIME [epoch: 8.49 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8447510418025008		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.8447510418025008 | validation: 0.6914851339636738]
	TIME [epoch: 8.51 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6834709109651712		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.6834709109651712 | validation: 0.8388078018332554]
	TIME [epoch: 8.49 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7836026634359143		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.7836026634359143 | validation: 1.246648571184996]
	TIME [epoch: 8.49 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7508065876692993		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.7508065876692993 | validation: 0.7049593052411254]
	TIME [epoch: 8.5 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6504574820442358		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.6504574820442358 | validation: 0.7642802398794615]
	TIME [epoch: 8.51 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0031973322009111		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 1.0031973322009111 | validation: 1.140409991070866]
	TIME [epoch: 8.49 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9166620596785966		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.9166620596785966 | validation: 0.7159115025766529]
	TIME [epoch: 8.49 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7551463777351862		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.7551463777351862 | validation: 0.8458545108699802]
	TIME [epoch: 8.51 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7441717745531855		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.7441717745531855 | validation: 1.1261443743227482]
	TIME [epoch: 8.5 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7158658727943411		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.7158658727943411 | validation: 0.6794667097592859]
	TIME [epoch: 8.49 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9432413627988249		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.9432413627988249 | validation: 0.8878204791677072]
	TIME [epoch: 8.5 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9262273149985486		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.9262273149985486 | validation: 1.1715569827726173]
	TIME [epoch: 8.51 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8286750385379122		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.8286750385379122 | validation: 0.6041960893697356]
	TIME [epoch: 8.51 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6996050906347049		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.6996050906347049 | validation: 0.6296407489144171]
	TIME [epoch: 8.5 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8689196012497163		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.8689196012497163 | validation: 1.0299092687072366]
	TIME [epoch: 8.5 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8789624217876078		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.8789624217876078 | validation: 0.7005251278761929]
	TIME [epoch: 8.52 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7036649202459287		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.7036649202459287 | validation: 1.1669972199572822]
	TIME [epoch: 8.49 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8196296866263332		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.8196296866263332 | validation: 0.7378827474316965]
	TIME [epoch: 8.49 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7315186426106518		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.7315186426106518 | validation: 0.7475396209341805]
	TIME [epoch: 8.48 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7666489711967148		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.7666489711967148 | validation: 0.7422583615450087]
	TIME [epoch: 8.51 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7162924200747612		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.7162924200747612 | validation: 1.0458330177786936]
	TIME [epoch: 8.49 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6960135581501808		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.6960135581501808 | validation: 0.6813016215912409]
	TIME [epoch: 8.49 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6330927241232395		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.6330927241232395 | validation: 1.1852535887604632]
	TIME [epoch: 8.48 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6599767369422207		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.6599767369422207 | validation: 0.833543562393079]
	TIME [epoch: 8.51 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7555863753708298		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.7555863753708298 | validation: 1.607487762187748]
	TIME [epoch: 8.49 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8138042914438189		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.8138042914438189 | validation: 0.6929730521479743]
	TIME [epoch: 8.49 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7068510114966811		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.7068510114966811 | validation: 0.633964855710068]
	TIME [epoch: 8.49 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6899249519434159		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.6899249519434159 | validation: 0.65681574946165]
	TIME [epoch: 8.5 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7546971075349033		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.7546971075349033 | validation: 0.7428413099966737]
	TIME [epoch: 8.49 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8194698273418639		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.8194698273418639 | validation: 0.8445020657438214]
	TIME [epoch: 8.5 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6913614144706982		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.6913614144706982 | validation: 0.6836206833775436]
	TIME [epoch: 8.48 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6460773381808822		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.6460773381808822 | validation: 0.6484602358333265]
	TIME [epoch: 8.51 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6470521901938457		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.6470521901938457 | validation: 0.8412712979327617]
	TIME [epoch: 8.49 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6795274958392673		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.6795274958392673 | validation: 0.8243923532937503]
	TIME [epoch: 8.49 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7213603885216925		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.7213603885216925 | validation: 1.0757200002563294]
	TIME [epoch: 8.49 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6379769978153732		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.6379769978153732 | validation: 0.9614403978276078]
	TIME [epoch: 8.51 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8835995344424719		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.8835995344424719 | validation: 0.5757481100794959]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_425.pth
	Model improved!!!
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7695832966862483		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.7695832966862483 | validation: 0.5937441160051071]
	TIME [epoch: 8.5 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7362804647280374		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.7362804647280374 | validation: 0.8872051623852828]
	TIME [epoch: 8.5 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.650571602370906		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.650571602370906 | validation: 0.6238929519366814]
	TIME [epoch: 8.51 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7476755326385762		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.7476755326385762 | validation: 0.6322755997861014]
	TIME [epoch: 8.5 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6597643078304667		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.6597643078304667 | validation: 0.7765803920976408]
	TIME [epoch: 8.48 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6244931312847288		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.6244931312847288 | validation: 0.6229797125484513]
	TIME [epoch: 8.51 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7692586503944205		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.7692586503944205 | validation: 0.6654505164190383]
	TIME [epoch: 8.51 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.656566593865442		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.656566593865442 | validation: 0.5550100953235219]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_433.pth
	Model improved!!!
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7969458989561362		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.7969458989561362 | validation: 0.8444706768910334]
	TIME [epoch: 8.49 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6379735160319209		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.6379735160319209 | validation: 2.9120938904462683]
	TIME [epoch: 8.51 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8846469319180722		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.8846469319180722 | validation: 0.6870565295143195]
	TIME [epoch: 8.49 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6885050455339395		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.6885050455339395 | validation: 0.6344021192409836]
	TIME [epoch: 8.49 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7204419486521573		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.7204419486521573 | validation: 0.801232843742697]
	TIME [epoch: 8.49 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.62468461276644		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.62468461276644 | validation: 0.9335066922091306]
	TIME [epoch: 8.51 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6726303000080902		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.6726303000080902 | validation: 0.6942424362881028]
	TIME [epoch: 8.5 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5735485040614212		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.5735485040614212 | validation: 1.0203442462318397]
	TIME [epoch: 8.49 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7418741592094328		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.7418741592094328 | validation: 0.6444756741472037]
	TIME [epoch: 8.49 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6579111914319906		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.6579111914319906 | validation: 0.8602817713167422]
	TIME [epoch: 8.51 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7627181338917913		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.7627181338917913 | validation: 0.6808265512160209]
	TIME [epoch: 8.5 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7051232655796058		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.7051232655796058 | validation: 0.6960391072767058]
	TIME [epoch: 8.48 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6749355178963179		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.6749355178963179 | validation: 0.7318198854638422]
	TIME [epoch: 8.49 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8138320004156349		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.8138320004156349 | validation: 0.6202950167407146]
	TIME [epoch: 8.51 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8063150618902686		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.8063150618902686 | validation: 0.6992946528086301]
	TIME [epoch: 8.5 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8025863779932394		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.8025863779932394 | validation: 0.7049177792188708]
	TIME [epoch: 8.48 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2922619688424568		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 1.2922619688424568 | validation: 1.9964808864408057]
	TIME [epoch: 8.48 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8584953152291517		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.8584953152291517 | validation: 0.8056226283510177]
	TIME [epoch: 8.51 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6667055638013759		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.6667055638013759 | validation: 0.6702116676980978]
	TIME [epoch: 8.49 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7754130239680304		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.7754130239680304 | validation: 0.6303104246880584]
	TIME [epoch: 8.49 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6806319769422297		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.6806319769422297 | validation: 0.6138791231774625]
	TIME [epoch: 8.49 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6428673609149932		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.6428673609149932 | validation: 0.6693419432361709]
	TIME [epoch: 8.51 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5599811874416649		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.5599811874416649 | validation: 0.7643426345708819]
	TIME [epoch: 8.48 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5556758954054454		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.5556758954054454 | validation: 0.7308515970770464]
	TIME [epoch: 8.49 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7476591594354165		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.7476591594354165 | validation: 0.6855695366031962]
	TIME [epoch: 8.48 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6354824146924397		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.6354824146924397 | validation: 0.7471782514357614]
	TIME [epoch: 8.51 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5747919882800312		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.5747919882800312 | validation: 3.264685300267578]
	TIME [epoch: 8.49 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.257609646074613		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 1.257609646074613 | validation: 0.6138577365467306]
	TIME [epoch: 8.49 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6014427690404036		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.6014427690404036 | validation: 0.7016453497177325]
	TIME [epoch: 8.49 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7239814449887694		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.7239814449887694 | validation: 0.621270916584888]
	TIME [epoch: 8.52 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.191427449783163		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 1.191427449783163 | validation: 3.348925837076251]
	TIME [epoch: 8.49 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8884927087462995		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 1.8884927087462995 | validation: 1.4236440989835684]
	TIME [epoch: 8.5 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7087990240746859		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.7087990240746859 | validation: 0.525648530245258]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_466.pth
	Model improved!!!
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6205657308683967		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.6205657308683967 | validation: 0.8446583859996283]
	TIME [epoch: 8.51 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.607460975323861		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.607460975323861 | validation: 0.5809847542696529]
	TIME [epoch: 8.48 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6520564583976219		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.6520564583976219 | validation: 0.8685577540000806]
	TIME [epoch: 8.48 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6122922699105402		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.6122922699105402 | validation: 0.7001250856222598]
	TIME [epoch: 8.5 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6600467513799425		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.6600467513799425 | validation: 1.6509370521550226]
	TIME [epoch: 8.49 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6921474121564636		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.6921474121564636 | validation: 0.7692768972308991]
	TIME [epoch: 8.49 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5856045448305233		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.5856045448305233 | validation: 0.5256764515221148]
	TIME [epoch: 8.47 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2380556186989495		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 1.2380556186989495 | validation: 0.5441506718487144]
	TIME [epoch: 8.51 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0162316535839344		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 1.0162316535839344 | validation: 0.5373444399581431]
	TIME [epoch: 8.5 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7685635072986502		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.7685635072986502 | validation: 0.8493945217872718]
	TIME [epoch: 8.49 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6223631007481718		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.6223631007481718 | validation: 0.6125728349240553]
	TIME [epoch: 8.49 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5979538329284172		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.5979538329284172 | validation: 1.0110279825477937]
	TIME [epoch: 8.51 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5856415182017147		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.5856415182017147 | validation: 0.6319972237240691]
	TIME [epoch: 8.49 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.752000466807182		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.752000466807182 | validation: 0.6941599232861471]
	TIME [epoch: 8.48 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6474987857609815		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.6474987857609815 | validation: 0.7484923214998718]
	TIME [epoch: 8.48 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6972427958541806		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.6972427958541806 | validation: 0.637062704599075]
	TIME [epoch: 8.51 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5531127140300385		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.5531127140300385 | validation: 0.5168702200110444]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_483.pth
	Model improved!!!
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7405478153969934		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.7405478153969934 | validation: 0.8338818937061732]
	TIME [epoch: 8.5 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.562084452729916		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.562084452729916 | validation: 0.5358878015701161]
	TIME [epoch: 8.48 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7021337398376202		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.7021337398376202 | validation: 0.7498226853851175]
	TIME [epoch: 8.51 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6488725508399515		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.6488725508399515 | validation: 0.8314827850754609]
	TIME [epoch: 8.5 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6629639277608722		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.6629639277608722 | validation: 0.8598213442137536]
	TIME [epoch: 8.48 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6370699476606525		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.6370699476606525 | validation: 0.7219535503099981]
	TIME [epoch: 8.5 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7457589248049981		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.7457589248049981 | validation: 0.5520323563583899]
	TIME [epoch: 8.51 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5605570717598067		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.5605570717598067 | validation: 0.6314031740460893]
	TIME [epoch: 8.49 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6188647780117449		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.6188647780117449 | validation: 0.5506470341576692]
	TIME [epoch: 8.48 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6018570263013483		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.6018570263013483 | validation: 0.5842731089964762]
	TIME [epoch: 8.49 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6071054286589473		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.6071054286589473 | validation: 0.5936623898247391]
	TIME [epoch: 8.51 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.639244395742574		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.639244395742574 | validation: 0.5925848532321258]
	TIME [epoch: 8.48 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.615934781733465		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.615934781733465 | validation: 0.6743664849592008]
	TIME [epoch: 8.48 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6845414022278135		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.6845414022278135 | validation: 0.5724283763096774]
	TIME [epoch: 8.48 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5304937500729782		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.5304937500729782 | validation: 0.5305740137844358]
	TIME [epoch: 8.51 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5569046795366346		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.5569046795366346 | validation: 0.5602175005920036]
	TIME [epoch: 8.49 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.680612017734222		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.680612017734222 | validation: 0.7821043731541799]
	TIME [epoch: 8.49 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5955437130234127		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.5955437130234127 | validation: 0.5786179683897413]
	TIME [epoch: 8.48 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5383695713482526		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.5383695713482526 | validation: 0.66284155869704]
	TIME [epoch: 8.51 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2207874359787179		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 1.2207874359787179 | validation: 0.6916562368624453]
	TIME [epoch: 8.48 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8206385562718399		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.8206385562718399 | validation: 0.7267929028293749]
	TIME [epoch: 8.48 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5981278127536298		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.5981278127536298 | validation: 0.5135603001247426]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_505.pth
	Model improved!!!
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8725921653020252		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.8725921653020252 | validation: 0.6798736919755894]
	TIME [epoch: 8.5 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5777007193498527		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.5777007193498527 | validation: 1.187002258727247]
	TIME [epoch: 8.48 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6362116632275094		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.6362116632275094 | validation: 0.6693284235794632]
	TIME [epoch: 8.48 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5742930516407216		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.5742930516407216 | validation: 0.4992882517748648]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_509.pth
	Model improved!!!
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5292577067989729		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.5292577067989729 | validation: 0.960860628150707]
	TIME [epoch: 8.49 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6297525746916575		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.6297525746916575 | validation: 0.493835164501914]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_511.pth
	Model improved!!!
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7459797253482867		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.7459797253482867 | validation: 0.7073434003314807]
	TIME [epoch: 8.49 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6419670633658207		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.6419670633658207 | validation: 0.5196411280059793]
	TIME [epoch: 8.49 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5936516811319438		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.5936516811319438 | validation: 0.5129760636550226]
	TIME [epoch: 8.48 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5220178939329522		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.5220178939329522 | validation: 0.5320775194579814]
	TIME [epoch: 8.48 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6332796761823046		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.6332796761823046 | validation: 0.48522472266498506]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_516.pth
	Model improved!!!
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5810966424264583		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.5810966424264583 | validation: 0.6155165395481161]
	TIME [epoch: 8.52 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5596151257090314		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.5596151257090314 | validation: 0.5298003052066431]
	TIME [epoch: 8.49 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5941330412449359		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.5941330412449359 | validation: 0.5543216395665287]
	TIME [epoch: 8.5 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5499278288120717		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.5499278288120717 | validation: 1.0071126283062313]
	TIME [epoch: 8.49 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8656280862822534		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.8656280862822534 | validation: 3.2684285383122416]
	TIME [epoch: 8.52 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8386682394005792		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.8386682394005792 | validation: 0.6966770652035348]
	TIME [epoch: 8.5 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.556175912414897		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.556175912414897 | validation: 0.5072543918094368]
	TIME [epoch: 8.48 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.560160102415128		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.560160102415128 | validation: 0.7459187462116326]
	TIME [epoch: 8.47 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.604364120635739		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.604364120635739 | validation: 0.5705124833325812]
	TIME [epoch: 8.51 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5185488081976567		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.5185488081976567 | validation: 0.48282364675652906]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_526.pth
	Model improved!!!
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6014420705271194		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.6014420705271194 | validation: 1.3491193408986963]
	TIME [epoch: 8.5 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.647522291101212		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.647522291101212 | validation: 0.6181989701594163]
	TIME [epoch: 8.5 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5680826240974735		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.5680826240974735 | validation: 0.4740377785654144]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_529.pth
	Model improved!!!
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5858683332996008		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.5858683332996008 | validation: 0.4865404089569635]
	TIME [epoch: 8.48 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5761882230991766		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.5761882230991766 | validation: 0.47142760238321674]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_531.pth
	Model improved!!!
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5240629635178913		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.5240629635178913 | validation: 0.4790977600959223]
	TIME [epoch: 8.49 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6086006850030116		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.6086006850030116 | validation: 0.44250936553013753]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_533.pth
	Model improved!!!
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6139475166400233		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.6139475166400233 | validation: 0.4374477669574921]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_534.pth
	Model improved!!!
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.604672644508931		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.604672644508931 | validation: 0.46518935289349955]
	TIME [epoch: 8.49 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5565417107662132		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.5565417107662132 | validation: 0.49959676400628356]
	TIME [epoch: 8.5 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5989598366143182		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.5989598366143182 | validation: 0.7768387977772725]
	TIME [epoch: 8.5 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0405519016586342		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 1.0405519016586342 | validation: 0.8591240584775435]
	TIME [epoch: 8.49 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.755753556041651		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.755753556041651 | validation: 1.1791076606639814]
	TIME [epoch: 8.48 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6283323077912117		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.6283323077912117 | validation: 1.237821006009857]
	TIME [epoch: 8.5 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1807973109582424		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 1.1807973109582424 | validation: 0.47459522235579144]
	TIME [epoch: 8.5 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5335451450765195		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.5335451450765195 | validation: 0.8403624377398502]
	TIME [epoch: 8.48 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5187859389786389		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.5187859389786389 | validation: 0.4861990245008504]
	TIME [epoch: 8.49 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5605854477198658		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.5605854477198658 | validation: 0.5035936082505692]
	TIME [epoch: 8.5 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5076358933986294		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.5076358933986294 | validation: 0.9147768669032317]
	TIME [epoch: 8.49 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5123477225138049		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.5123477225138049 | validation: 0.5834257035755792]
	TIME [epoch: 8.49 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5946176572580696		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.5946176572580696 | validation: 0.705498973477237]
	TIME [epoch: 8.49 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.942671667940601		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.942671667940601 | validation: 1.566261426025159]
	TIME [epoch: 8.51 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7447977749928121		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.7447977749928121 | validation: 0.42581544138879435]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_549.pth
	Model improved!!!
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45941914625354735		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.45941914625354735 | validation: 0.5723073894240202]
	TIME [epoch: 8.5 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46300268947704437		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.46300268947704437 | validation: 0.7975355192035083]
	TIME [epoch: 8.48 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9274171195938203		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.9274171195938203 | validation: 0.8000268512047899]
	TIME [epoch: 8.51 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5537019042106128		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.5537019042106128 | validation: 0.7558426405146352]
	TIME [epoch: 8.49 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6495639419418815		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.6495639419418815 | validation: 0.5140844903425865]
	TIME [epoch: 8.48 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5601332271589283		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.5601332271589283 | validation: 0.53921402653338]
	TIME [epoch: 8.5 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6369595057598557		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.6369595057598557 | validation: 0.46253324221338077]
	TIME [epoch: 8.5 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5188836510647545		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.5188836510647545 | validation: 0.42771515798757354]
	TIME [epoch: 8.48 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6225503183539082		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.6225503183539082 | validation: 1.3423098396501545]
	TIME [epoch: 8.49 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6483633234945934		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.6483633234945934 | validation: 0.48459945727186204]
	TIME [epoch: 8.5 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48778209512841525		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.48778209512841525 | validation: 0.5510361664191934]
	TIME [epoch: 8.52 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47159839926265895		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.47159839926265895 | validation: 0.4921927137076445]
	TIME [epoch: 8.5 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5286689897863605		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.5286689897863605 | validation: 0.6867329663470165]
	TIME [epoch: 8.49 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5041079117959069		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.5041079117959069 | validation: 0.47967620604158767]
	TIME [epoch: 8.48 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4744172976330302		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.4744172976330302 | validation: 0.43187330860046447]
	TIME [epoch: 8.52 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48921899513727524		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.48921899513727524 | validation: 0.628263617629676]
	TIME [epoch: 8.48 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6120609630946415		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.6120609630946415 | validation: 0.3823878317677716]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_566.pth
	Model improved!!!
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6965495390962093		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.6965495390962093 | validation: 0.5604130506506813]
	TIME [epoch: 8.5 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4668198607116002		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.4668198607116002 | validation: 0.43209489475486107]
	TIME [epoch: 8.5 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.541082128975862		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.541082128975862 | validation: 0.5377721560164265]
	TIME [epoch: 8.49 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5463561200203981		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.5463561200203981 | validation: 0.6343857790726077]
	TIME [epoch: 8.49 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5436273026494564		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.5436273026494564 | validation: 0.9568922274982838]
	TIME [epoch: 8.49 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6084698612818032		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.6084698612818032 | validation: 0.657169925431569]
	TIME [epoch: 8.5 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49392227660760213		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.49392227660760213 | validation: 0.6714093220481957]
	TIME [epoch: 8.48 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5125294638787821		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.5125294638787821 | validation: 0.4090035012923299]
	TIME [epoch: 8.48 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5901347336107194		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.5901347336107194 | validation: 2.025956334957384]
	TIME [epoch: 8.51 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6747280655952919		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.6747280655952919 | validation: 0.5345224056062217]
	TIME [epoch: 8.48 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45217422294074205		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.45217422294074205 | validation: 0.7357127891231363]
	TIME [epoch: 8.48 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5430364778206943		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.5430364778206943 | validation: 0.7602567228425361]
	TIME [epoch: 8.47 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5247974415206522		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.5247974415206522 | validation: 0.5320320062502478]
	TIME [epoch: 8.5 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43366940174695384		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.43366940174695384 | validation: 0.5329428316013385]
	TIME [epoch: 8.5 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8322030872761106		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.8322030872761106 | validation: 0.44937415357500776]
	TIME [epoch: 8.49 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5047493399628783		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.5047493399628783 | validation: 0.5173997505015343]
	TIME [epoch: 8.47 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0506503843637747		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 1.0506503843637747 | validation: 0.4464668528979244]
	TIME [epoch: 8.51 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4859558119572015		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.4859558119572015 | validation: 0.6985258888155009]
	TIME [epoch: 8.49 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5034239910846756		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.5034239910846756 | validation: 0.4042030181812514]
	TIME [epoch: 8.49 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44923578467692443		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.44923578467692443 | validation: 1.7689489659400994]
	TIME [epoch: 8.49 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7033184461617216		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.7033184461617216 | validation: 0.4493314774525201]
	TIME [epoch: 8.51 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5117670003324103		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.5117670003324103 | validation: 0.5650750782018543]
	TIME [epoch: 8.49 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5000549961770449		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.5000549961770449 | validation: 0.7622983306102428]
	TIME [epoch: 8.49 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4658726175821819		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.4658726175821819 | validation: 0.5256076093768647]
	TIME [epoch: 8.48 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5188930665499961		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.5188930665499961 | validation: 1.0529101729330452]
	TIME [epoch: 8.52 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5493552432380161		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.5493552432380161 | validation: 0.6338516926118904]
	TIME [epoch: 8.49 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5344233625865031		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.5344233625865031 | validation: 0.7374880478051946]
	TIME [epoch: 8.48 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49617303866187895		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.49617303866187895 | validation: 0.4668456006040009]
	TIME [epoch: 8.49 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6322514939218014		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.6322514939218014 | validation: 0.43446450968110556]
	TIME [epoch: 8.52 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47842891876569216		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.47842891876569216 | validation: 0.5678036118026847]
	TIME [epoch: 8.49 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4864098654840892		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.4864098654840892 | validation: 0.45701639738125244]
	TIME [epoch: 8.48 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4783366080682665		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.4783366080682665 | validation: 0.5594326243577965]
	TIME [epoch: 8.49 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4636538133883509		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.4636538133883509 | validation: 0.45614676158512946]
	TIME [epoch: 8.52 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5032459796282017		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.5032459796282017 | validation: 0.45155086969315167]
	TIME [epoch: 8.49 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47449993730232326		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.47449993730232326 | validation: 0.4245896999489502]
	TIME [epoch: 8.5 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5021684687529243		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.5021684687529243 | validation: 0.48947555794335085]
	TIME [epoch: 8.5 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4916556104455392		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.4916556104455392 | validation: 0.4992174386875404]
	TIME [epoch: 8.51 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5059181820149589		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.5059181820149589 | validation: 0.6495940648139652]
	TIME [epoch: 8.47 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4810135694612628		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.4810135694612628 | validation: 0.4343178285485864]
	TIME [epoch: 8.49 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45345283190889624		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.45345283190889624 | validation: 0.4482861013066538]
	TIME [epoch: 8.48 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48976354560141677		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.48976354560141677 | validation: 0.37140862962596255]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_607.pth
	Model improved!!!
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6475935627499895		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.6475935627499895 | validation: 0.5404452651508881]
	TIME [epoch: 8.49 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4792518430799058		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.4792518430799058 | validation: 0.8816482647020977]
	TIME [epoch: 8.49 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5616777020109499		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.5616777020109499 | validation: 0.5523588926664]
	TIME [epoch: 8.5 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46895377278903255		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.46895377278903255 | validation: 0.6444769401953108]
	TIME [epoch: 8.5 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4877112757470646		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.4877112757470646 | validation: 0.5718488703353457]
	TIME [epoch: 8.49 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4638032758657055		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.4638032758657055 | validation: 0.538064843921378]
	TIME [epoch: 8.49 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48207683446424454		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.48207683446424454 | validation: 0.3769649847882501]
	TIME [epoch: 8.5 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4717833619934838		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.4717833619934838 | validation: 0.44038873338606555]
	TIME [epoch: 8.49 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48851065942764926		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.48851065942764926 | validation: 0.46347868458906527]
	TIME [epoch: 8.48 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5498530233563046		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.5498530233563046 | validation: 0.36137238589020465]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_617.pth
	Model improved!!!
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43759454408677784		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.43759454408677784 | validation: 0.46676097098906744]
	TIME [epoch: 8.51 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44391284178804485		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.44391284178804485 | validation: 1.0688835245450825]
	TIME [epoch: 8.5 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49228745182941464		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.49228745182941464 | validation: 0.7298272865364757]
	TIME [epoch: 8.49 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8205162647313152		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.8205162647313152 | validation: 0.5270142674258644]
	TIME [epoch: 8.49 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41010722128080584		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.41010722128080584 | validation: 0.88222000974579]
	TIME [epoch: 8.51 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4838200804227647		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.4838200804227647 | validation: 0.7825008806243455]
	TIME [epoch: 8.49 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5125911081448346		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.5125911081448346 | validation: 0.4552568157402573]
	TIME [epoch: 8.49 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4840520536237093		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.4840520536237093 | validation: 0.4274499602172536]
	TIME [epoch: 8.49 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4677144982208463		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.4677144982208463 | validation: 0.46142164979899625]
	TIME [epoch: 8.52 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44407782056042666		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.44407782056042666 | validation: 0.442075823693312]
	TIME [epoch: 8.49 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45876445144148337		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.45876445144148337 | validation: 0.37290371762239016]
	TIME [epoch: 8.49 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4610090856652248		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.4610090856652248 | validation: 0.436932350955454]
	TIME [epoch: 8.49 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5498631372006764		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.5498631372006764 | validation: 0.3943902891140335]
	TIME [epoch: 8.51 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4318578219346486		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.4318578219346486 | validation: 0.5862047473309544]
	TIME [epoch: 8.49 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44483699126310255		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.44483699126310255 | validation: 0.37938452958417207]
	TIME [epoch: 8.49 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47664348521902633		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.47664348521902633 | validation: 0.4529683729662793]
	TIME [epoch: 8.49 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9483618672503983		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.9483618672503983 | validation: 0.5325424716885829]
	TIME [epoch: 8.51 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4759248762898178		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.4759248762898178 | validation: 0.389610444560768]
	TIME [epoch: 8.49 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4696299072555809		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.4696299072555809 | validation: 0.48009932253613863]
	TIME [epoch: 8.49 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49872227115847834		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.49872227115847834 | validation: 0.39484032393933144]
	TIME [epoch: 8.49 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4718496336840543		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.4718496336840543 | validation: 0.4123929045518863]
	TIME [epoch: 8.52 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4579390504444598		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.4579390504444598 | validation: 0.38664036335006724]
	TIME [epoch: 8.49 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41176537078685077		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.41176537078685077 | validation: 0.4227414453161856]
	TIME [epoch: 8.49 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5616115831725805		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.5616115831725805 | validation: 0.39015371716179137]
	TIME [epoch: 8.49 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.794581462942564		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.794581462942564 | validation: 0.9138620574156223]
	TIME [epoch: 8.52 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1850633410415283		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 1.1850633410415283 | validation: 2.095783370086287]
	TIME [epoch: 8.5 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2483344953173774		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 1.2483344953173774 | validation: 1.3259136369182483]
	TIME [epoch: 8.49 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8105884645834023		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.8105884645834023 | validation: 0.8273245689202976]
	TIME [epoch: 8.5 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8681065394584973		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.8681065394584973 | validation: 0.5945441790216444]
	TIME [epoch: 8.5 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6935199997087398		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.6935199997087398 | validation: 0.4656778820278029]
	TIME [epoch: 8.49 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.600971470979137		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.600971470979137 | validation: 0.3846633642170179]
	TIME [epoch: 8.49 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44435508887157515		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.44435508887157515 | validation: 0.5388732982728215]
	TIME [epoch: 8.5 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8037699076074795		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.8037699076074795 | validation: 0.452483502126149]
	TIME [epoch: 8.5 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42320285499839105		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.42320285499839105 | validation: 0.6578297718559796]
	TIME [epoch: 8.49 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6127286855604568		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.6127286855604568 | validation: 0.9379063501122271]
	TIME [epoch: 8.49 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8927427370450186		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.8927427370450186 | validation: 1.814807851229101]
	TIME [epoch: 8.51 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6291281111660034		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.6291281111660034 | validation: 0.512327282481238]
	TIME [epoch: 8.5 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4547180925275652		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.4547180925275652 | validation: 0.4645763555831259]
	TIME [epoch: 8.49 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41991493311538575		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.41991493311538575 | validation: 0.39802864747329436]
	TIME [epoch: 8.49 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36974097725072086		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.36974097725072086 | validation: 0.5004495450277135]
	TIME [epoch: 8.5 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4185705537457089		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.4185705537457089 | validation: 0.3601476960903692]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_658.pth
	Model improved!!!
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41830765313029294		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.41830765313029294 | validation: 0.36447261776445217]
	TIME [epoch: 8.5 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5174575025445752		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.5174575025445752 | validation: 0.41027717858601814]
	TIME [epoch: 8.49 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45685990891665573		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.45685990891665573 | validation: 0.3984859571911864]
	TIME [epoch: 8.51 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4258604598772343		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.4258604598772343 | validation: 0.44816107523204074]
	TIME [epoch: 8.49 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4443722501086943		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.4443722501086943 | validation: 0.5434072086763672]
	TIME [epoch: 8.48 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39103820165728315		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.39103820165728315 | validation: 0.5173490331317304]
	TIME [epoch: 8.49 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5647475392693864		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.5647475392693864 | validation: 0.4033418128893999]
	TIME [epoch: 8.51 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4315797075069618		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.4315797075069618 | validation: 0.34011953940401396]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_666.pth
	Model improved!!!
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35482299782655347		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.35482299782655347 | validation: 0.41162896609872446]
	TIME [epoch: 8.5 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40896679816366976		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.40896679816366976 | validation: 0.5661863384306114]
	TIME [epoch: 8.49 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46111076276883034		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.46111076276883034 | validation: 0.455579594906667]
	TIME [epoch: 8.52 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5323141225606578		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.5323141225606578 | validation: 0.4268327146170582]
	TIME [epoch: 8.5 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5097365588020504		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.5097365588020504 | validation: 0.3799720533472333]
	TIME [epoch: 8.48 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3985087894790804		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.3985087894790804 | validation: 0.4074859112675049]
	TIME [epoch: 8.48 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8110305632986936		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.8110305632986936 | validation: 0.8223374196494426]
	TIME [epoch: 8.51 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4700161052283175		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.4700161052283175 | validation: 0.49775320363211284]
	TIME [epoch: 8.48 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3878443831473524		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.3878443831473524 | validation: 0.3303014833621637]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_675.pth
	Model improved!!!
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39490439888612394		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.39490439888612394 | validation: 0.36082893268173083]
	TIME [epoch: 8.51 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42383326047160963		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.42383326047160963 | validation: 0.4391569380971897]
	TIME [epoch: 8.53 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4245059424215887		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.4245059424215887 | validation: 0.36624268356820755]
	TIME [epoch: 8.51 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46218242987051195		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.46218242987051195 | validation: 0.354846457175516]
	TIME [epoch: 8.51 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47947569819817837		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.47947569819817837 | validation: 0.5624171447505536]
	TIME [epoch: 8.53 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5222427305078705		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.5222427305078705 | validation: 0.37740497808562845]
	TIME [epoch: 8.53 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6857154961981602		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.6857154961981602 | validation: 0.37590020229697485]
	TIME [epoch: 8.51 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3690431811775069		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.3690431811775069 | validation: 0.760637889786465]
	TIME [epoch: 8.51 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4066750886942677		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.4066750886942677 | validation: 0.3424174268628064]
	TIME [epoch: 8.53 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40922646991508216		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.40922646991508216 | validation: 0.46771234865809935]
	TIME [epoch: 8.52 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.408812546362988		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.408812546362988 | validation: 0.35751323438745075]
	TIME [epoch: 8.5 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3656311536886926		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.3656311536886926 | validation: 0.8448226167716899]
	TIME [epoch: 8.52 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5101120975836566		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.5101120975836566 | validation: 0.3656627065214739]
	TIME [epoch: 8.53 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5288884877909376		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.5288884877909376 | validation: 0.34778814734623414]
	TIME [epoch: 8.51 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5515685591229568		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.5515685591229568 | validation: 0.5444583189784795]
	TIME [epoch: 8.51 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5624390347818793		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.5624390347818793 | validation: 0.6302333895273543]
	TIME [epoch: 8.51 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41686103660731605		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.41686103660731605 | validation: 0.982343287684996]
	TIME [epoch: 8.53 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49588977204996904		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.49588977204996904 | validation: 0.3537060182672702]
	TIME [epoch: 8.51 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41139315380363656		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.41139315380363656 | validation: 0.36735165540555725]
	TIME [epoch: 8.5 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3945989038788257		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.3945989038788257 | validation: 0.4580426570256457]
	TIME [epoch: 8.51 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38963252724182557		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.38963252724182557 | validation: 0.35919103530163365]
	TIME [epoch: 8.53 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4054502980186324		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.4054502980186324 | validation: 0.4311363769072133]
	TIME [epoch: 8.58 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6003383080660583		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.6003383080660583 | validation: 0.42268118530648713]
	TIME [epoch: 8.51 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4062852158554334		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.4062852158554334 | validation: 0.8787350738493437]
	TIME [epoch: 8.51 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46441182249703206		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.46441182249703206 | validation: 0.4172856764751197]
	TIME [epoch: 8.53 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39296933355692004		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.39296933355692004 | validation: 0.36220847786838367]
	TIME [epoch: 8.52 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37249644384211833		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.37249644384211833 | validation: 0.3473113423151518]
	TIME [epoch: 8.51 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39467778851919677		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.39467778851919677 | validation: 0.3778143245945208]
	TIME [epoch: 8.51 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3834822414752451		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.3834822414752451 | validation: 0.489574979702718]
	TIME [epoch: 8.54 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5231816967071584		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.5231816967071584 | validation: 0.3488005733171804]
	TIME [epoch: 8.52 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35736430813940934		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.35736430813940934 | validation: 0.42475450571340934]
	TIME [epoch: 8.51 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43351151812948147		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.43351151812948147 | validation: 0.9584709620778682]
	TIME [epoch: 8.52 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46177584274648725		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.46177584274648725 | validation: 0.37238244319225644]
	TIME [epoch: 8.54 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.454033531689206		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.454033531689206 | validation: 0.9896499913335546]
	TIME [epoch: 8.51 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48187376462400666		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.48187376462400666 | validation: 0.34813140672560394]
	TIME [epoch: 8.51 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4809758274686716		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.4809758274686716 | validation: 0.35673618082276704]
	TIME [epoch: 8.51 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3660439434475317		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.3660439434475317 | validation: 0.6801718140935229]
	TIME [epoch: 8.54 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4088712917791181		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.4088712917791181 | validation: 0.7450019160730699]
	TIME [epoch: 8.51 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4212163590597073		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.4212163590597073 | validation: 0.35094371094492977]
	TIME [epoch: 8.51 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39919080593658574		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.39919080593658574 | validation: 0.7357657848473367]
	TIME [epoch: 8.53 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4400510949225563		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.4400510949225563 | validation: 0.49318217944379006]
	TIME [epoch: 8.52 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4546816907397092		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.4546816907397092 | validation: 0.4864950115192705]
	TIME [epoch: 8.51 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4868823974270377		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.4868823974270377 | validation: 0.42293302499872043]
	TIME [epoch: 8.51 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36618385890166905		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.36618385890166905 | validation: 0.4546271683639881]
	TIME [epoch: 8.54 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.560256793743078		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.560256793743078 | validation: 0.525830583999724]
	TIME [epoch: 8.52 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48171714109885483		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.48171714109885483 | validation: 0.3694244869745006]
	TIME [epoch: 8.52 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47086302131586394		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.47086302131586394 | validation: 0.3802889156393693]
	TIME [epoch: 8.51 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45750922629033514		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.45750922629033514 | validation: 0.6426182215493668]
	TIME [epoch: 8.53 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6160208551469414		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.6160208551469414 | validation: 0.3352828268067022]
	TIME [epoch: 8.52 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4434318398700904		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.4434318398700904 | validation: 0.41084181487059346]
	TIME [epoch: 8.52 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36252081941001985		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.36252081941001985 | validation: 0.39174420080252204]
	TIME [epoch: 8.52 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3811639856016225		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.3811639856016225 | validation: 0.355698881167291]
	TIME [epoch: 8.54 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3827136890098156		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.3827136890098156 | validation: 0.3570329208158507]
	TIME [epoch: 8.52 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36532229975853914		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.36532229975853914 | validation: 0.4526860178213249]
	TIME [epoch: 8.51 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.411443298904259		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.411443298904259 | validation: 0.36955194912658396]
	TIME [epoch: 8.51 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3961904389861498		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.3961904389861498 | validation: 0.5561867692724042]
	TIME [epoch: 8.53 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41961493460458765		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.41961493460458765 | validation: 0.3737401444286247]
	TIME [epoch: 8.51 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3683280492163704		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.3683280492163704 | validation: 0.3581679405022349]
	TIME [epoch: 8.51 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39875287639470813		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.39875287639470813 | validation: 0.42485114216335024]
	TIME [epoch: 8.52 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3829310791340407		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.3829310791340407 | validation: 0.4236929968665882]
	TIME [epoch: 8.53 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38118369906066374		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.38118369906066374 | validation: 0.48906263689261165]
	TIME [epoch: 8.52 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4559573106958025		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.4559573106958025 | validation: 0.39024962096779414]
	TIME [epoch: 8.52 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3813527333941835		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.3813527333941835 | validation: 0.4436766902140875]
	TIME [epoch: 8.51 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5334236835208764		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.5334236835208764 | validation: 0.8919246536721682]
	TIME [epoch: 8.54 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48222205321430434		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.48222205321430434 | validation: 0.38591712026692365]
	TIME [epoch: 8.51 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5096703902759827		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.5096703902759827 | validation: 0.9738784559344295]
	TIME [epoch: 8.51 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47753978661011853		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.47753978661011853 | validation: 0.513432299923434]
	TIME [epoch: 8.51 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5836375119618554		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.5836375119618554 | validation: 0.34855436211867563]
	TIME [epoch: 8.54 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43542436317236105		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.43542436317236105 | validation: 0.41677477098455507]
	TIME [epoch: 8.51 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42735981927605327		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.42735981927605327 | validation: 0.38445757081804577]
	TIME [epoch: 8.51 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46359987829166		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.46359987829166 | validation: 0.3804258693753776]
	TIME [epoch: 8.5 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5485834019147143		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.5485834019147143 | validation: 0.3514471665784138]
	TIME [epoch: 8.54 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6296020300659128		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.6296020300659128 | validation: 1.2196100840532893]
	TIME [epoch: 8.51 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5620158310822794		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.5620158310822794 | validation: 0.7530325612120208]
	TIME [epoch: 8.52 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7513322492666681		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.7513322492666681 | validation: 0.3484918544671176]
	TIME [epoch: 8.52 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37482014598738095		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.37482014598738095 | validation: 0.37004790091170847]
	TIME [epoch: 8.53 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4593840084286769		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.4593840084286769 | validation: 1.3465220798785305]
	TIME [epoch: 8.51 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5318429579470998		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.5318429579470998 | validation: 0.3497785992149508]
	TIME [epoch: 8.5 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4255571913964804		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.4255571913964804 | validation: 0.3476333887881312]
	TIME [epoch: 8.54 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3747853746724557		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.3747853746724557 | validation: 0.5173528141278624]
	TIME [epoch: 8.51 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4924571573564938		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.4924571573564938 | validation: 0.3314986368112799]
	TIME [epoch: 8.51 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3671758717305252		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.3671758717305252 | validation: 0.5170294171153358]
	TIME [epoch: 8.51 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38645585143401934		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.38645585143401934 | validation: 0.5239563841156962]
	TIME [epoch: 8.52 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41291603610888783		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.41291603610888783 | validation: 0.3983249129611804]
	TIME [epoch: 8.52 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35860704698445356		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.35860704698445356 | validation: 0.3673111827157886]
	TIME [epoch: 8.5 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39951895604601095		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.39951895604601095 | validation: 0.5969813339659231]
	TIME [epoch: 8.51 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5142000372477371		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.5142000372477371 | validation: 0.3605464564886134]
	TIME [epoch: 8.53 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45049982455967374		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.45049982455967374 | validation: 0.3239116390057053]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_763.pth
	Model improved!!!
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45222745102578055		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.45222745102578055 | validation: 0.40169759420052487]
	TIME [epoch: 8.51 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37475195935719563		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.37475195935719563 | validation: 0.4164163865187941]
	TIME [epoch: 8.51 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5259296660988354		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.5259296660988354 | validation: 0.39568237362012104]
	TIME [epoch: 8.52 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6271822117493607		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.6271822117493607 | validation: 0.32655157222719133]
	TIME [epoch: 8.51 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9571157261262814		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.9571157261262814 | validation: 0.573303156471711]
	TIME [epoch: 8.5 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7463482234382364		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.7463482234382364 | validation: 0.409013883121388]
	TIME [epoch: 8.5 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39444050244597567		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.39444050244597567 | validation: 0.9628895527909228]
	TIME [epoch: 8.53 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4915103924882704		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.4915103924882704 | validation: 0.45193880561769484]
	TIME [epoch: 8.51 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42897342661903026		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.42897342661903026 | validation: 0.6421298942107255]
	TIME [epoch: 8.5 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38871270421799076		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.38871270421799076 | validation: 0.47705622269554077]
	TIME [epoch: 8.5 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4704291106343594		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.4704291106343594 | validation: 0.32721050517669137]
	TIME [epoch: 8.53 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4053806583215113		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.4053806583215113 | validation: 0.7578897364347135]
	TIME [epoch: 8.5 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46003584447675		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.46003584447675 | validation: 0.5380620953901606]
	TIME [epoch: 8.5 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39529678515376776		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.39529678515376776 | validation: 0.32193114866311096]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_777.pth
	Model improved!!!
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3406557889074751		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.3406557889074751 | validation: 0.5767363210233054]
	TIME [epoch: 8.53 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.374554963896958		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.374554963896958 | validation: 0.34508724985371564]
	TIME [epoch: 8.51 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36776128152772636		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.36776128152772636 | validation: 0.3495271002090129]
	TIME [epoch: 8.5 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43648703605058536		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.43648703605058536 | validation: 0.4193501172537068]
	TIME [epoch: 8.52 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39372323545543425		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.39372323545543425 | validation: 0.44188765958674625]
	TIME [epoch: 8.52 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.366568171227801		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.366568171227801 | validation: 0.34273289350033054]
	TIME [epoch: 8.51 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4248970993479406		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.4248970993479406 | validation: 0.5072237514367051]
	TIME [epoch: 8.51 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36176715693311234		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.36176715693311234 | validation: 0.3683414980786921]
	TIME [epoch: 8.52 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33562426233338327		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.33562426233338327 | validation: 0.36671398227042923]
	TIME [epoch: 8.52 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36504975473283496		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.36504975473283496 | validation: 0.4419606839308696]
	TIME [epoch: 8.51 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3425476905066335		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.3425476905066335 | validation: 0.4247450791581952]
	TIME [epoch: 8.51 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41383680591695027		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.41383680591695027 | validation: 0.3734292117802186]
	TIME [epoch: 8.53 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3628948940551285		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.3628948940551285 | validation: 0.3884064305104681]
	TIME [epoch: 8.52 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3496013234913532		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.3496013234913532 | validation: 0.32563003112837974]
	TIME [epoch: 8.51 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3989186503254773		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.3989186503254773 | validation: 0.3449615716158027]
	TIME [epoch: 8.51 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3674068815344546		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.3674068815344546 | validation: 0.35655917332178844]
	TIME [epoch: 8.52 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33031742876129633		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.33031742876129633 | validation: 0.3513892934063134]
	TIME [epoch: 8.51 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38546393358461195		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.38546393358461195 | validation: 0.3963967037074695]
	TIME [epoch: 8.5 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3405503281605976		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.3405503281605976 | validation: 0.34520004798138876]
	TIME [epoch: 8.5 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3621278167913949		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.3621278167913949 | validation: 0.3779502234088059]
	TIME [epoch: 8.52 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4286012696256993		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.4286012696256993 | validation: 0.39908132713726224]
	TIME [epoch: 8.51 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3528263083353448		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.3528263083353448 | validation: 0.33459195904781763]
	TIME [epoch: 8.5 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3567188354993158		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.3567188354993158 | validation: 0.37492404970230964]
	TIME [epoch: 8.5 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3804938546976836		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.3804938546976836 | validation: 0.3743737566430416]
	TIME [epoch: 8.52 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35545919048260466		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.35545919048260466 | validation: 0.35243737815804643]
	TIME [epoch: 8.51 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35267609030890223		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.35267609030890223 | validation: 0.34546757864179345]
	TIME [epoch: 8.5 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4750717895890005		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.4750717895890005 | validation: 0.3410016756052426]
	TIME [epoch: 8.5 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32672532048018144		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.32672532048018144 | validation: 0.3372830297069297]
	TIME [epoch: 8.53 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3710702005357619		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.3710702005357619 | validation: 0.32206258917672737]
	TIME [epoch: 8.51 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3277035014618215		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.3277035014618215 | validation: 0.3550735371935647]
	TIME [epoch: 8.5 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5097535127917149		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.5097535127917149 | validation: 0.6866494699257935]
	TIME [epoch: 8.5 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39322756187444097		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.39322756187444097 | validation: 0.36053696212135944]
	TIME [epoch: 8.53 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33607832942307664		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.33607832942307664 | validation: 0.40816412520942513]
	TIME [epoch: 8.5 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3529752393384418		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.3529752393384418 | validation: 0.34026193841638486]
	TIME [epoch: 8.5 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3239799603578174		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.3239799603578174 | validation: 0.4039162105824999]
	TIME [epoch: 8.5 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3461065990056341		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.3461065990056341 | validation: 0.4865907698515112]
	TIME [epoch: 8.53 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3615293996063181		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.3615293996063181 | validation: 0.36664919852182043]
	TIME [epoch: 8.5 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3659842253808406		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.3659842253808406 | validation: 0.4425064395782665]
	TIME [epoch: 8.5 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3399215141532066		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.3399215141532066 | validation: 0.37443029472041733]
	TIME [epoch: 8.5 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39142074949513794		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.39142074949513794 | validation: 0.4018049172916445]
	TIME [epoch: 8.53 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37980766249745346		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.37980766249745346 | validation: 0.39794556611324133]
	TIME [epoch: 8.5 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35623494087490687		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.35623494087490687 | validation: 0.5181461714335585]
	TIME [epoch: 8.5 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3904492875023052		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.3904492875023052 | validation: 0.31944168549638174]
	TIME [epoch: 8.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_820.pth
	Model improved!!!
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3887967375093567		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.3887967375093567 | validation: 0.38405048280235765]
	TIME [epoch: 8.52 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3621740749542523		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.3621740749542523 | validation: 0.42877074216611666]
	TIME [epoch: 8.5 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34220978375908806		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.34220978375908806 | validation: 0.3339389534043258]
	TIME [epoch: 8.5 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3949823974010617		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.3949823974010617 | validation: 0.3298103909917294]
	TIME [epoch: 8.51 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44605356271936253		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.44605356271936253 | validation: 0.8352614706844765]
	TIME [epoch: 8.5 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5008431616210758		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.5008431616210758 | validation: 0.33286658315760054]
	TIME [epoch: 8.49 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39145246518088495		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.39145246518088495 | validation: 0.394518438292195]
	TIME [epoch: 8.49 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35093667210947854		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.35093667210947854 | validation: 0.3478914707805617]
	TIME [epoch: 8.51 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39417160333501106		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.39417160333501106 | validation: 0.34251563924594675]
	TIME [epoch: 8.51 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37673747553766135		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.37673747553766135 | validation: 0.3344948352005085]
	TIME [epoch: 8.5 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3626128121061993		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.3626128121061993 | validation: 0.32077367356687214]
	TIME [epoch: 8.5 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32416604906867275		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.32416604906867275 | validation: 0.3249912620511832]
	TIME [epoch: 8.52 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32840136969427924		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.32840136969427924 | validation: 0.3390164678383111]
	TIME [epoch: 8.51 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36001032319345694		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.36001032319345694 | validation: 0.8856323667766607]
	TIME [epoch: 8.5 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44858314477267325		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.44858314477267325 | validation: 0.35564524549816867]
	TIME [epoch: 8.5 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4140306876001206		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.4140306876001206 | validation: 0.43078628642813016]
	TIME [epoch: 8.52 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3730283753069756		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.3730283753069756 | validation: 0.714047981557201]
	TIME [epoch: 8.51 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43921940918446367		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.43921940918446367 | validation: 0.3562517371245558]
	TIME [epoch: 8.5 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3359342300334321		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.3359342300334321 | validation: 0.3492859016616191]
	TIME [epoch: 8.5 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34526217742890714		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.34526217742890714 | validation: 0.4116973572924649]
	TIME [epoch: 8.52 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3376998533601629		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.3376998533601629 | validation: 0.3961512818881321]
	TIME [epoch: 8.49 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3581888808174639		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.3581888808174639 | validation: 0.36599057198725776]
	TIME [epoch: 8.49 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35256398679871037		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.35256398679871037 | validation: 0.35625300276167493]
	TIME [epoch: 8.5 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3610838517535671		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.3610838517535671 | validation: 0.3189347467402195]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_844.pth
	Model improved!!!
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3626313525273456		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.3626313525273456 | validation: 0.36925310632172614]
	TIME [epoch: 8.5 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35750200658876724		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.35750200658876724 | validation: 0.3770919893302179]
	TIME [epoch: 8.49 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36856566291037485		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.36856566291037485 | validation: 0.5319945708891856]
	TIME [epoch: 8.49 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35041310403771875		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.35041310403771875 | validation: 0.3361248285950858]
	TIME [epoch: 8.52 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44589931870532135		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.44589931870532135 | validation: 0.32396874768748163]
	TIME [epoch: 8.49 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.445979677170962		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.445979677170962 | validation: 0.35044364266204353]
	TIME [epoch: 8.49 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3856787455391689		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.3856787455391689 | validation: 0.40993718103952725]
	TIME [epoch: 8.49 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3685044350542611		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.3685044350542611 | validation: 0.3320113921291009]
	TIME [epoch: 8.51 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35200618142295526		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.35200618142295526 | validation: 0.3400314884433962]
	TIME [epoch: 8.49 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33432489467295223		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.33432489467295223 | validation: 0.5900620482875579]
	TIME [epoch: 8.5 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3770509592956938		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.3770509592956938 | validation: 0.3598554111894714]
	TIME [epoch: 8.5 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3550912105180434		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.3550912105180434 | validation: 0.3512756966530368]
	TIME [epoch: 8.51 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.367774504867109		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.367774504867109 | validation: 0.3474906309685168]
	TIME [epoch: 8.5 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3331982968367224		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.3331982968367224 | validation: 0.318363801193817]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_858.pth
	Model improved!!!
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.335046354993413		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.335046354993413 | validation: 0.4674647055628459]
	TIME [epoch: 8.51 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3500774317968714		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.3500774317968714 | validation: 0.34850086191225504]
	TIME [epoch: 8.5 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38117254760525854		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.38117254760525854 | validation: 0.34754918854158856]
	TIME [epoch: 8.5 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38169788647065395		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.38169788647065395 | validation: 0.35660629428969093]
	TIME [epoch: 8.49 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3428088303819354		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.3428088303819354 | validation: 0.366843272581333]
	TIME [epoch: 8.5 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32395699731597705		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.32395699731597705 | validation: 0.5506282167077714]
	TIME [epoch: 8.49 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4159181581730474		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.4159181581730474 | validation: 0.3176821043853387]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_865.pth
	Model improved!!!
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35548955693795364		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.35548955693795364 | validation: 0.5380423906428458]
	TIME [epoch: 8.48 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34901221746727357		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.34901221746727357 | validation: 0.3356320302261489]
	TIME [epoch: 8.52 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33844253919267275		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.33844253919267275 | validation: 0.3728352481138051]
	TIME [epoch: 8.49 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34761570163671707		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.34761570163671707 | validation: 0.31556497901837466]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_869.pth
	Model improved!!!
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3664708708832807		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.3664708708832807 | validation: 0.39056834781324495]
	TIME [epoch: 8.49 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3371937798017099		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.3371937798017099 | validation: 0.45705509808065414]
	TIME [epoch: 8.51 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3470482900406368		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.3470482900406368 | validation: 0.42255442628209877]
	TIME [epoch: 8.49 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3284085619185385		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.3284085619185385 | validation: 0.3860097759456146]
	TIME [epoch: 8.49 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35932855232603156		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.35932855232603156 | validation: 0.333896793168038]
	TIME [epoch: 8.49 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3736796498565701		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.3736796498565701 | validation: 0.33615268412826926]
	TIME [epoch: 8.51 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3147192022933662		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.3147192022933662 | validation: 0.4248774311017649]
	TIME [epoch: 8.5 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42495963550425914		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.42495963550425914 | validation: 0.3251469258674288]
	TIME [epoch: 8.49 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3208122347522441		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.3208122347522441 | validation: 0.48574239667751395]
	TIME [epoch: 8.49 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37918597269422943		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.37918597269422943 | validation: 0.38043512898215304]
	TIME [epoch: 8.51 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3704187201612265		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.3704187201612265 | validation: 0.31978966146498994]
	TIME [epoch: 8.49 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3183496454088911		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.3183496454088911 | validation: 0.47135737739191275]
	TIME [epoch: 8.48 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35796135502984		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.35796135502984 | validation: 0.35520371464995004]
	TIME [epoch: 8.49 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4436256099551117		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.4436256099551117 | validation: 0.34053657148050376]
	TIME [epoch: 8.52 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32982184003801807		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.32982184003801807 | validation: 0.34304228089041555]
	TIME [epoch: 8.49 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33185156555323303		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.33185156555323303 | validation: 0.3359097188397081]
	TIME [epoch: 8.49 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3417489117297583		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.3417489117297583 | validation: 0.32772241271875824]
	TIME [epoch: 8.49 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34585970554586576		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.34585970554586576 | validation: 0.3022109886484496]
	TIME [epoch: 8.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240217_140927/states/model_tr_study4_887.pth
	Model improved!!!
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32063672158077716		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.32063672158077716 | validation: 0.4113408016513437]
	TIME [epoch: 8.49 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3300329262916742		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.3300329262916742 | validation: 0.3306199722631939]
	TIME [epoch: 8.49 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31973086237642795		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.31973086237642795 | validation: 0.32659638008244385]
	TIME [epoch: 8.51 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38798499958466015		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.38798499958466015 | validation: 0.6705483208181559]
	TIME [epoch: 8.5 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4100320305597832		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.4100320305597832 | validation: 0.378828526092593]
	TIME [epoch: 8.49 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3354394224680087		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.3354394224680087 | validation: 0.3409880247610587]
	TIME [epoch: 8.49 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32611708730509237		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.32611708730509237 | validation: 0.35389066966644755]
	TIME [epoch: 8.51 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3122486963729336		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.3122486963729336 | validation: 0.3237197806980885]
	TIME [epoch: 8.5 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35308093040430744		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.35308093040430744 | validation: 0.37288819408504836]
	TIME [epoch: 8.49 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3613284560615672		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.3613284560615672 | validation: 0.3831793826163427]
	TIME [epoch: 8.48 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3379903819984743		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.3379903819984743 | validation: 0.33038532858410763]
	TIME [epoch: 8.5 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3108338800437728		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.3108338800437728 | validation: 0.3428563372845599]
	TIME [epoch: 8.49 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3780058344478917		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.3780058344478917 | validation: 0.39009757767050746]
	TIME [epoch: 8.48 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3917537900193127		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.3917537900193127 | validation: 0.39202672050340037]
	TIME [epoch: 8.48 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36759668145117463		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.36759668145117463 | validation: 0.38735023872437047]
	TIME [epoch: 8.51 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4253147452866573		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.4253147452866573 | validation: 0.6354199943213947]
	TIME [epoch: 8.49 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35854500399428957		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.35854500399428957 | validation: 0.34324988544657203]
	TIME [epoch: 8.49 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36116699589057455		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.36116699589057455 | validation: 0.33183803685342617]
	TIME [epoch: 8.48 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4370958897511069		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.4370958897511069 | validation: 0.3104073456914436]
	TIME [epoch: 8.51 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.349716668992175		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.349716668992175 | validation: 0.49783198441850474]
	TIME [epoch: 8.5 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4557323370155906		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.4557323370155906 | validation: 0.3080792350914999]
	TIME [epoch: 8.49 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47880274751841645		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.47880274751841645 | validation: 0.32873401077241526]
	TIME [epoch: 8.48 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.48051867573744944		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.48051867573744944 | validation: 0.3414006479530698]
	TIME [epoch: 8.51 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35586394792240456		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.35586394792240456 | validation: 0.31520785800543155]
	TIME [epoch: 8.49 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31876570061644643		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.31876570061644643 | validation: 0.38302423161697813]
	TIME [epoch: 8.49 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3306602865994863		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.3306602865994863 | validation: 0.3791523577311656]
	TIME [epoch: 8.49 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33922681014018047		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.33922681014018047 | validation: 0.3292880360651436]
	TIME [epoch: 8.51 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.446587833228259		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.446587833228259 | validation: 0.6755333918472541]
	TIME [epoch: 8.49 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39966282641140816		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.39966282641140816 | validation: 0.44543034985076957]
	TIME [epoch: 8.48 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40070930652506326		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.40070930652506326 | validation: 0.34150114030159784]
	TIME [epoch: 8.49 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3337212532302826		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.3337212532302826 | validation: 0.36187562850118704]
	TIME [epoch: 8.51 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3702881714334028		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.3702881714334028 | validation: 0.3998530665975202]
	TIME [epoch: 8.49 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35755361010116105		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.35755361010116105 | validation: 0.31334279722722935]
	TIME [epoch: 8.48 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3798766490843881		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.3798766490843881 | validation: 0.3340589430599388]
	TIME [epoch: 8.49 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3567274168119633		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.3567274168119633 | validation: 0.5332508813355368]
	TIME [epoch: 8.51 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44370942175163836		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.44370942175163836 | validation: 0.4962090021655534]
	TIME [epoch: 8.49 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45560119686472644		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.45560119686472644 | validation: 0.3344322099861512]
	TIME [epoch: 8.49 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3604358999434655		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.3604358999434655 | validation: 0.3334125100971852]
	TIME [epoch: 8.49 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34909084557268366		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.34909084557268366 | validation: 0.369581667587656]
	TIME [epoch: 8.51 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3821177778034318		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.3821177778034318 | validation: 0.39537221081148594]
	TIME [epoch: 8.48 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36823366773813726		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.36823366773813726 | validation: 0.4355494737086569]
	TIME [epoch: 8.49 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40922115013714677		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.40922115013714677 | validation: 0.41614343092409073]
	TIME [epoch: 8.51 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3410985981191962		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.3410985981191962 | validation: 0.4055247878965712]
	TIME [epoch: 8.5 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45634477567269405		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.45634477567269405 | validation: 0.3299154106535884]
	TIME [epoch: 8.49 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41435657670604786		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.41435657670604786 | validation: 0.3506234850696549]
	TIME [epoch: 8.48 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.328993754336813		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.328993754336813 | validation: 0.35225947841296246]
	TIME [epoch: 8.5 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3880619014031491		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.3880619014031491 | validation: 0.32585430057984827]
	TIME [epoch: 8.49 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34577046273360446		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.34577046273360446 | validation: 0.609530761754278]
	TIME [epoch: 8.49 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3529355680578968		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.3529355680578968 | validation: 0.4005623632478209]
	TIME [epoch: 8.49 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3345426890472005		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.3345426890472005 | validation: 0.33052031436791507]
	TIME [epoch: 8.5 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3081969492605702		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.3081969492605702 | validation: 0.322712834759995]
	TIME [epoch: 8.5 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31461345947661246		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.31461345947661246 | validation: 0.3228626266317236]
	TIME [epoch: 8.48 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3175944438108727		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.3175944438108727 | validation: 0.3619155652944035]
	TIME [epoch: 8.49 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3645908499951968		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.3645908499951968 | validation: 0.529909101929497]
	TIME [epoch: 8.5 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3560152089945838		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.3560152089945838 | validation: 0.3289788021318758]
	TIME [epoch: 8.49 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3468640259660459		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.3468640259660459 | validation: 0.33769255965394535]
	TIME [epoch: 8.48 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3538787038474997		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.3538787038474997 | validation: 0.3317470810956275]
	TIME [epoch: 8.49 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3444454071236404		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.3444454071236404 | validation: 0.3875262028573171]
	TIME [epoch: 8.5 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38785986106867293		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.38785986106867293 | validation: 0.4384529077113637]
	TIME [epoch: 8.49 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37671638541954816		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.37671638541954816 | validation: 0.335807045439378]
	TIME [epoch: 8.48 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3333767897180687		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.3333767897180687 | validation: 0.3871683443199103]
	TIME [epoch: 8.49 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42268438235196104		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.42268438235196104 | validation: 0.34961428413265794]
	TIME [epoch: 8.5 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33237797101793204		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.33237797101793204 | validation: 0.3775018054919726]
	TIME [epoch: 8.48 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36467387846124505		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.36467387846124505 | validation: 0.7745696085338101]
	TIME [epoch: 8.48 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4303491793327514		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.4303491793327514 | validation: 0.3402366284223115]
	TIME [epoch: 8.48 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34547813054482496		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.34547813054482496 | validation: 0.36207604261234133]
	TIME [epoch: 8.51 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41085384253392976		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.41085384253392976 | validation: 0.4972807508584212]
	TIME [epoch: 8.49 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36559918048298123		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.36559918048298123 | validation: 0.3350288230116384]
	TIME [epoch: 8.48 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4144068274308811		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.4144068274308811 | validation: 0.32683324402478703]
	TIME [epoch: 8.49 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47463450226044196		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.47463450226044196 | validation: 0.35415747433719824]
	TIME [epoch: 8.51 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37552239631178075		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.37552239631178075 | validation: 0.41287836691925084]
	TIME [epoch: 8.49 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3876288395779735		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.3876288395779735 | validation: 0.34432270990311953]
	TIME [epoch: 8.49 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3452757632264145		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.3452757632264145 | validation: 0.415525199497381]
	TIME [epoch: 8.5 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.448298898177985		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.448298898177985 | validation: 0.5738879877420544]
	TIME [epoch: 8.52 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4704244969813026		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.4704244969813026 | validation: 0.3424941585758633]
	TIME [epoch: 8.49 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3976338412551102		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.3976338412551102 | validation: 0.36727393916702167]
	TIME [epoch: 8.49 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36868835065376754		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.36868835065376754 | validation: 0.3602452358957797]
	TIME [epoch: 8.49 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3633602962606497		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.3633602962606497 | validation: 0.33658300761291227]
	TIME [epoch: 8.5 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4086384796045312		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.4086384796045312 | validation: 0.3551483620546505]
	TIME [epoch: 8.48 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37710870061756485		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.37710870061756485 | validation: 0.34379507324684233]
	TIME [epoch: 8.49 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38184003039271663		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.38184003039271663 | validation: 0.37353096993573076]
	TIME [epoch: 8.5 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3780147754949034		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.3780147754949034 | validation: 0.5851872557048001]
	TIME [epoch: 8.49 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3914753398878209		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.3914753398878209 | validation: 0.4341399304299822]
	TIME [epoch: 8.48 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3917358112785865		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.3917358112785865 | validation: 0.3769111334432469]
	TIME [epoch: 8.47 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3640034478994128		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.3640034478994128 | validation: 0.33785032101624374]
	TIME [epoch: 8.5 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36420070794977394		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.36420070794977394 | validation: 0.38347807675614964]
	TIME [epoch: 8.49 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3558407350899479		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.3558407350899479 | validation: 0.5623536305199621]
	TIME [epoch: 8.49 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4153101280907353		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.4153101280907353 | validation: 0.33280635470531117]
	TIME [epoch: 8.48 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35834947482350177		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.35834947482350177 | validation: 0.33685071231049]
	TIME [epoch: 8.49 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39049665286011825		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.39049665286011825 | validation: 0.5063478325863738]
	TIME [epoch: 8.48 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3784960160584731		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.3784960160584731 | validation: 0.3486805123724677]
	TIME [epoch: 8.48 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.342237665723575		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.342237665723575 | validation: 0.34438731778329584]
	TIME [epoch: 8.48 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37355335840920945		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.37355335840920945 | validation: 0.3883303540386484]
	TIME [epoch: 8.5 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3464186470770376		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.3464186470770376 | validation: 0.36680562324839844]
	TIME [epoch: 8.49 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3890714322097546		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.3890714322097546 | validation: 0.520190783936756]
	TIME [epoch: 8.48 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6147328312666371		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.6147328312666371 | validation: 0.4113740017952552]
	TIME [epoch: 8.47 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37717833721484045		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.37717833721484045 | validation: 0.34447952423592865]
	TIME [epoch: 8.5 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3936782519378334		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.3936782519378334 | validation: 0.40889359808516534]
	TIME [epoch: 8.48 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3630668768408539		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.3630668768408539 | validation: 0.3408208306400372]
	TIME [epoch: 8.49 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4209240183816231		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.4209240183816231 | validation: 0.3414954934258746]
	TIME [epoch: 8.47 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4798035626335649		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.4798035626335649 | validation: 0.3958676016323713]
	TIME [epoch: 8.49 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40221614953613594		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.40221614953613594 | validation: 0.34375833989548865]
	TIME [epoch: 8.47 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38897831521970866		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.38897831521970866 | validation: 0.39411006413803784]
	TIME [epoch: 8.46 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3378285852195328		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.3378285852195328 | validation: 0.347103579799055]
	TIME [epoch: 8.47 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33129234089867343		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.33129234089867343 | validation: 0.6758937979385291]
	TIME [epoch: 8.49 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5430911655344833		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.5430911655344833 | validation: 0.450103930899291]
	TIME [epoch: 8.47 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34709057037691365		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.34709057037691365 | validation: 0.4637214354624569]
	TIME [epoch: 8.47 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4569238344125151		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.4569238344125151 | validation: 0.4013242656973912]
	TIME [epoch: 8.47 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.36295901335766406		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.36295901335766406 | validation: 0.35386888333811845]
	TIME [epoch: 8.49 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.365110397266764		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.365110397266764 | validation: 0.49751855249080323]
	TIME [epoch: 8.46 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37794405367383477		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.37794405367383477 | validation: 0.44053483914859903]
	TIME [epoch: 8.46 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3457009167285835		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.3457009167285835 | validation: 0.3861832438149923]
	TIME [epoch: 8.46 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3533949750774255		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.3533949750774255 | validation: 0.5900090703641405]
	TIME [epoch: 8.49 sec]
Finished training in 8609.549 seconds.
