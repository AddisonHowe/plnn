Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r3', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 453868828

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.02821664832552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.02821664832552 | validation: 9.391867088650784]
	TIME [epoch: 48.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.512030400963168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.512030400963168 | validation: 6.308917866174709]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.912742844378803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.912742844378803 | validation: 5.226581273729963]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.032508991871985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.032508991871985 | validation: 4.945318719164765]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.380000665308838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.380000665308838 | validation: 5.769805597851273]
	TIME [epoch: 9.1 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.3797462075987434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3797462075987434 | validation: 5.168115705744528]
	TIME [epoch: 9.09 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.493397875778501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.493397875778501 | validation: 6.314254388048046]
	TIME [epoch: 9.11 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.406634928925617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.406634928925617 | validation: 3.598077431615555]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.077387804103026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.077387804103026 | validation: 5.425529306812482]
	TIME [epoch: 9.09 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.622734240610572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.622734240610572 | validation: 3.8745527127533284]
	TIME [epoch: 9.09 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.387230674388632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.387230674388632 | validation: 3.3819346467750564]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.276784300119213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.276784300119213 | validation: 3.1966750926594507]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6114162530022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6114162530022 | validation: 4.0896419870307446]
	TIME [epoch: 9.08 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6080184251046044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6080184251046044 | validation: 3.066161080217844]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6299096145435605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6299096145435605 | validation: 2.939965994870157]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.980979526196874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.980979526196874 | validation: 2.996668014088426]
	TIME [epoch: 9.09 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8933227436700406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8933227436700406 | validation: 2.968637830943789]
	TIME [epoch: 9.08 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.899599898513839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.899599898513839 | validation: 3.0798086002368574]
	TIME [epoch: 9.08 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9254784414102373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9254784414102373 | validation: 2.900783963890475]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9686010979696262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9686010979696262 | validation: 2.941122558903234]
	TIME [epoch: 9.08 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8315903276592294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8315903276592294 | validation: 2.795233120701435]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8143015329180154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8143015329180154 | validation: 2.632890669258953]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.270956690350868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.270956690350868 | validation: 2.299361209969384]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0290894248308655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0290894248308655 | validation: 1.4592277728831258]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.791635085244583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.791635085244583 | validation: 2.052464541905469]
	TIME [epoch: 9.11 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7072532124958961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7072532124958961 | validation: 1.2194440616606692]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2712182093079094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2712182093079094 | validation: 5.547538245225553]
	TIME [epoch: 9.08 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7388100369719421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7388100369719421 | validation: 0.8527370613346161]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9648483396758245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9648483396758245 | validation: 0.6931093094173367]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1595238563095123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1595238563095123 | validation: 0.6208914835944599]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8671176440223356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8671176440223356 | validation: 0.5648675731636481]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.812413073369493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.812413073369493 | validation: 0.9216392457210405]
	TIME [epoch: 9.08 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9182636267701012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9182636267701012 | validation: 0.9386692780450757]
	TIME [epoch: 9.08 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7743965744046857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7743965744046857 | validation: 1.5004618514412082]
	TIME [epoch: 9.11 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8953979599108752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8953979599108752 | validation: 1.2630515968953662]
	TIME [epoch: 9.09 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9573564868129921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9573564868129921 | validation: 0.9054316459411599]
	TIME [epoch: 9.08 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7686546888063251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7686546888063251 | validation: 0.6550792750054836]
	TIME [epoch: 9.08 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9187218052419762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9187218052419762 | validation: 0.8045568242998091]
	TIME [epoch: 9.09 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7793255146931306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7793255146931306 | validation: 0.8583954011179665]
	TIME [epoch: 9.09 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7231710102122769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7231710102122769 | validation: 0.6277334566011831]
	TIME [epoch: 9.08 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7861803833500749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7861803833500749 | validation: 0.5152858620615798]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8562748577335546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8562748577335546 | validation: 1.3241467758324041]
	TIME [epoch: 9.09 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2086785016747301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2086785016747301 | validation: 0.712419554407013]
	TIME [epoch: 9.1 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8576277151255033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8576277151255033 | validation: 0.48147521300367657]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6994014395453605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6994014395453605 | validation: 0.6265033763553436]
	TIME [epoch: 9.09 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8520187521531701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8520187521531701 | validation: 0.6544712941883213]
	TIME [epoch: 9.09 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9509213026716832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9509213026716832 | validation: 0.8021472586276837]
	TIME [epoch: 9.09 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7592575617976294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7592575617976294 | validation: 0.5542768748601357]
	TIME [epoch: 9.1 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8027583131841054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8027583131841054 | validation: 0.8396310196547383]
	TIME [epoch: 9.09 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8586834051074123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8586834051074123 | validation: 1.6357967436905934]
	TIME [epoch: 9.1 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2268105706789354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2268105706789354 | validation: 1.6197684140753437]
	TIME [epoch: 9.09 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8885305949199267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8885305949199267 | validation: 0.8801997989100339]
	TIME [epoch: 9.1 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8787500083825697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8787500083825697 | validation: 0.8808485904754519]
	TIME [epoch: 9.09 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8580771182434802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8580771182434802 | validation: 0.5508641013338782]
	TIME [epoch: 9.08 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6829986066542283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6829986066542283 | validation: 0.5594559781435786]
	TIME [epoch: 9.09 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5756158320630081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5756158320630081 | validation: 0.5801781158201426]
	TIME [epoch: 9.09 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8192512059351751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8192512059351751 | validation: 0.6657556750332935]
	TIME [epoch: 9.11 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.725342797669822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.725342797669822 | validation: 2.616355240975967]
	TIME [epoch: 9.09 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1310820273726754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1310820273726754 | validation: 0.6495546604929954]
	TIME [epoch: 9.08 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6335671598326211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6335671598326211 | validation: 0.7356251140630812]
	TIME [epoch: 9.09 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7680903873660607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7680903873660607 | validation: 0.7223754807112468]
	TIME [epoch: 9.1 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7579908822986379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7579908822986379 | validation: 0.4902467463272387]
	TIME [epoch: 9.1 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9323451100786597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9323451100786597 | validation: 0.7590448950240594]
	TIME [epoch: 9.09 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8274658823844957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8274658823844957 | validation: 0.7135593240660825]
	TIME [epoch: 9.09 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7303731907435628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7303731907435628 | validation: 0.5134717950940755]
	TIME [epoch: 9.09 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8244397272732747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8244397272732747 | validation: 0.6738368908468582]
	TIME [epoch: 9.1 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6431195213279868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6431195213279868 | validation: 0.5237864949419839]
	TIME [epoch: 9.09 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7563824443089524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7563824443089524 | validation: 0.7147949559148234]
	TIME [epoch: 9.09 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7845716839425143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7845716839425143 | validation: 0.6815922372578787]
	TIME [epoch: 9.08 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7279814767796122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7279814767796122 | validation: 0.4682005917061285]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6315929627601279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6315929627601279 | validation: 0.6276734995429543]
	TIME [epoch: 9.1 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8228756763607846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8228756763607846 | validation: 0.5970888500702063]
	TIME [epoch: 9.09 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6164165842437681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6164165842437681 | validation: 0.603707674407113]
	TIME [epoch: 9.09 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5526406304212279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5526406304212279 | validation: 0.6881402861609056]
	TIME [epoch: 9.09 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6515610737573226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6515610737573226 | validation: 0.6741065303907481]
	TIME [epoch: 9.11 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6324362400966204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6324362400966204 | validation: 0.8456548492874538]
	TIME [epoch: 9.1 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7146187308129314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7146187308129314 | validation: 0.5066610769748348]
	TIME [epoch: 9.08 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7869376646286383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7869376646286383 | validation: 1.099741199879912]
	TIME [epoch: 9.08 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6395857774285847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6395857774285847 | validation: 0.5310044918242833]
	TIME [epoch: 9.09 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8095634396114907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8095634396114907 | validation: 0.5449328031542673]
	TIME [epoch: 9.1 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6138961310070604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6138961310070604 | validation: 0.6666365494174386]
	TIME [epoch: 9.07 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5964596197227268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5964596197227268 | validation: 0.4726428577871437]
	TIME [epoch: 9.08 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6344843716466319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6344843716466319 | validation: 0.602172596027648]
	TIME [epoch: 9.08 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6365168217370644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6365168217370644 | validation: 0.5832491353374761]
	TIME [epoch: 9.09 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5504787919075802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5504787919075802 | validation: 0.7158103247618808]
	TIME [epoch: 9.08 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.577957215089166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.577957215089166 | validation: 0.6578593077100073]
	TIME [epoch: 9.08 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6870442350236404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6870442350236404 | validation: 0.5300838473614238]
	TIME [epoch: 9.08 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5947359195257933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5947359195257933 | validation: 0.5893639284408867]
	TIME [epoch: 9.07 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5517596205518831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5517596205518831 | validation: 0.7222616394702798]
	TIME [epoch: 9.1 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6089878064205603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6089878064205603 | validation: 0.5395641180635693]
	TIME [epoch: 9.09 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7523061228922089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7523061228922089 | validation: 0.7359626121757887]
	TIME [epoch: 9.08 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.607012349510201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.607012349510201 | validation: 0.9127479387686208]
	TIME [epoch: 9.08 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8398137311237164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8398137311237164 | validation: 0.571899926672917]
	TIME [epoch: 9.09 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5897114424560821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5897114424560821 | validation: 0.4342054919827068]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5356182373658209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5356182373658209 | validation: 0.524714209599428]
	TIME [epoch: 9.1 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5098486183207954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5098486183207954 | validation: 0.5306758507751754]
	TIME [epoch: 9.09 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48578560221069444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48578560221069444 | validation: 1.079332145618296]
	TIME [epoch: 9.08 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8168689753767465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8168689753767465 | validation: 0.5087459931436294]
	TIME [epoch: 9.11 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4842286938280883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4842286938280883 | validation: 0.5317384607515867]
	TIME [epoch: 9.09 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4889254016532164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4889254016532164 | validation: 0.44983867790247245]
	TIME [epoch: 9.08 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.53319035593337		[learning rate: 0.0099782]
	Learning Rate: 0.00997821
	LOSS [training: 0.53319035593337 | validation: 0.4113769718095581]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5218892008410692		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 0.5218892008410692 | validation: 0.6422726239317946]
	TIME [epoch: 9.1 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5460398679216554		[learning rate: 0.00993]
	Learning Rate: 0.00992996
	LOSS [training: 0.5460398679216554 | validation: 0.44210883649923693]
	TIME [epoch: 9.09 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5296341171649607		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 0.5296341171649607 | validation: 0.8296571524582786]
	TIME [epoch: 9.08 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4791500876763717		[learning rate: 0.0098819]
	Learning Rate: 0.00988194
	LOSS [training: 0.4791500876763717 | validation: 0.4241849649377897]
	TIME [epoch: 9.08 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40837744538951304		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 0.40837744538951304 | validation: 0.4878254130049685]
	TIME [epoch: 9.08 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4198163256624524		[learning rate: 0.0098341]
	Learning Rate: 0.00983415
	LOSS [training: 0.4198163256624524 | validation: 0.9077241087376471]
	TIME [epoch: 9.09 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.562833488383259		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 0.562833488383259 | validation: 0.5907083963167196]
	TIME [epoch: 9.08 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4503058487241788		[learning rate: 0.0097866]
	Learning Rate: 0.00978659
	LOSS [training: 0.4503058487241788 | validation: 0.3778145431094295]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.018249433802831		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 1.018249433802831 | validation: 2.9740989970646456]
	TIME [epoch: 9.08 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2947640122190887		[learning rate: 0.0097393]
	Learning Rate: 0.00973927
	LOSS [training: 1.2947640122190887 | validation: 1.4586562239643948]
	TIME [epoch: 9.09 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7710794490531993		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 0.7710794490531993 | validation: 1.9575124863306517]
	TIME [epoch: 9.09 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7470929646057368		[learning rate: 0.0096922]
	Learning Rate: 0.00969217
	LOSS [training: 0.7470929646057368 | validation: 0.35869580908983933]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3875719667294308		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 0.3875719667294308 | validation: 0.3595027716253788]
	TIME [epoch: 9.08 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33041006186234645		[learning rate: 0.0096453]
	Learning Rate: 0.0096453
	LOSS [training: 0.33041006186234645 | validation: 0.3352595160893991]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40514063698168173		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 0.40514063698168173 | validation: 0.4567658917098022]
	TIME [epoch: 9.07 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5478283734244994		[learning rate: 0.0095987]
	Learning Rate: 0.00959866
	LOSS [training: 0.5478283734244994 | validation: 0.5183154718191118]
	TIME [epoch: 9.06 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6716832836871831		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 0.6716832836871831 | validation: 0.3472431958191212]
	TIME [epoch: 9.06 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34171429059656155		[learning rate: 0.0095522]
	Learning Rate: 0.00955224
	LOSS [training: 0.34171429059656155 | validation: 0.2846663837606781]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37944702872993097		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 0.37944702872993097 | validation: 2.745979750073806]
	TIME [epoch: 9.09 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8731779807582054		[learning rate: 0.009506]
	Learning Rate: 0.00950605
	LOSS [training: 0.8731779807582054 | validation: 0.5137678733327021]
	TIME [epoch: 9.08 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5838253729522476		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 0.5838253729522476 | validation: 0.4823103942508915]
	TIME [epoch: 9.06 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5578336729581862		[learning rate: 0.0094601]
	Learning Rate: 0.00946008
	LOSS [training: 0.5578336729581862 | validation: 0.32977302830412136]
	TIME [epoch: 9.07 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39822598295783157		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 0.39822598295783157 | validation: 0.3547532734159281]
	TIME [epoch: 9.06 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3488700558452958		[learning rate: 0.0094143]
	Learning Rate: 0.00941433
	LOSS [training: 0.3488700558452958 | validation: 0.44238207607502333]
	TIME [epoch: 9.08 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33810688409372297		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 0.33810688409372297 | validation: 0.294842256582999]
	TIME [epoch: 9.06 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3474209269480745		[learning rate: 0.0093688]
	Learning Rate: 0.00936881
	LOSS [training: 0.3474209269480745 | validation: 0.30070130292153074]
	TIME [epoch: 9.06 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2998257229334405		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 0.2998257229334405 | validation: 0.9669136860469003]
	TIME [epoch: 9.06 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6171645389266771		[learning rate: 0.0093235]
	Learning Rate: 0.0093235
	LOSS [training: 0.6171645389266771 | validation: 0.309914707277034]
	TIME [epoch: 9.06 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3356500207091192		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 0.3356500207091192 | validation: 0.44940045458227523]
	TIME [epoch: 9.09 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34852173859632957		[learning rate: 0.0092784]
	Learning Rate: 0.00927841
	LOSS [training: 0.34852173859632957 | validation: 0.3466673349720014]
	TIME [epoch: 9.06 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38190134755169347		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 0.38190134755169347 | validation: 0.3573182430134413]
	TIME [epoch: 9.06 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31088617401403423		[learning rate: 0.0092335]
	Learning Rate: 0.00923354
	LOSS [training: 0.31088617401403423 | validation: 0.3789109638224253]
	TIME [epoch: 9.06 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4113475898490505		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 0.4113475898490505 | validation: 0.38699245680663763]
	TIME [epoch: 9.06 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3451833200945774		[learning rate: 0.0091889]
	Learning Rate: 0.00918889
	LOSS [training: 0.3451833200945774 | validation: 0.4198706944870203]
	TIME [epoch: 9.08 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4184598439652338		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 0.4184598439652338 | validation: 0.4778997658380649]
	TIME [epoch: 9.07 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.839313838790574		[learning rate: 0.0091445]
	Learning Rate: 0.00914446
	LOSS [training: 0.839313838790574 | validation: 0.37116575058390133]
	TIME [epoch: 9.06 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37329981263687695		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 0.37329981263687695 | validation: 0.3940157438679901]
	TIME [epoch: 9.06 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3447809790461306		[learning rate: 0.0091002]
	Learning Rate: 0.00910024
	LOSS [training: 0.3447809790461306 | validation: 0.5620027896849351]
	TIME [epoch: 9.08 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3620241882545305		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.3620241882545305 | validation: 0.29371267931770273]
	TIME [epoch: 9.06 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35481050595672475		[learning rate: 0.0090562]
	Learning Rate: 0.00905623
	LOSS [training: 0.35481050595672475 | validation: 0.5513617760035681]
	TIME [epoch: 9.06 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3485945940258182		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 0.3485945940258182 | validation: 0.31884827273192307]
	TIME [epoch: 9.05 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3026759441875024		[learning rate: 0.0090124]
	Learning Rate: 0.00901243
	LOSS [training: 0.3026759441875024 | validation: 0.39750324498179623]
	TIME [epoch: 9.06 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40652199564032376		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 0.40652199564032376 | validation: 0.255720031071982]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3924480184959988		[learning rate: 0.0089689]
	Learning Rate: 0.00896885
	LOSS [training: 0.3924480184959988 | validation: 0.7478572640647017]
	TIME [epoch: 9.08 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6324844900470035		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 0.6324844900470035 | validation: 0.6966772361657937]
	TIME [epoch: 9.07 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5295610554638617		[learning rate: 0.0089255]
	Learning Rate: 0.00892548
	LOSS [training: 0.5295610554638617 | validation: 0.2713627088208862]
	TIME [epoch: 9.07 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24539014466352554		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 0.24539014466352554 | validation: 0.1933469172523773]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3213892699632745		[learning rate: 0.0088823]
	Learning Rate: 0.00888232
	LOSS [training: 0.3213892699632745 | validation: 0.3191178290444397]
	TIME [epoch: 9.07 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.273364330380259		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 0.273364330380259 | validation: 1.00262149643583]
	TIME [epoch: 9.07 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5753643632530752		[learning rate: 0.0088394]
	Learning Rate: 0.00883936
	LOSS [training: 0.5753643632530752 | validation: 0.28553925599802765]
	TIME [epoch: 9.07 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6763535739430844		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 0.6763535739430844 | validation: 0.4984631827081948]
	TIME [epoch: 9.08 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.485507869008347		[learning rate: 0.0087966]
	Learning Rate: 0.00879662
	LOSS [training: 0.485507869008347 | validation: 0.37100777472256574]
	TIME [epoch: 9.08 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4089837638191048		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 0.4089837638191048 | validation: 0.5489852930999851]
	TIME [epoch: 9.07 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46432507925584954		[learning rate: 0.0087541]
	Learning Rate: 0.00875408
	LOSS [training: 0.46432507925584954 | validation: 0.2914996366392717]
	TIME [epoch: 9.09 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29092766847070073		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 0.29092766847070073 | validation: 0.29183611045688684]
	TIME [epoch: 9.07 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28882108682952745		[learning rate: 0.0087117]
	Learning Rate: 0.00871175
	LOSS [training: 0.28882108682952745 | validation: 0.36039152774163963]
	TIME [epoch: 9.09 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3012375796849619		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 0.3012375796849619 | validation: 0.19888886602002342]
	TIME [epoch: 9.07 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40139716464867714		[learning rate: 0.0086696]
	Learning Rate: 0.00866962
	LOSS [training: 0.40139716464867714 | validation: 0.508484441251251]
	TIME [epoch: 9.07 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.535555400972363		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.535555400972363 | validation: 0.47793002432099196]
	TIME [epoch: 9.07 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5632239815440971		[learning rate: 0.0086277]
	Learning Rate: 0.00862769
	LOSS [training: 0.5632239815440971 | validation: 0.5086851599417417]
	TIME [epoch: 9.07 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.433903495576257		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.433903495576257 | validation: 0.27747171140917437]
	TIME [epoch: 9.09 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24340741187604037		[learning rate: 0.008586]
	Learning Rate: 0.00858597
	LOSS [training: 0.24340741187604037 | validation: 0.2067821722980599]
	TIME [epoch: 9.06 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2882774985788408		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 0.2882774985788408 | validation: 0.35400675869157017]
	TIME [epoch: 9.06 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44628376299535566		[learning rate: 0.0085445]
	Learning Rate: 0.00854445
	LOSS [training: 0.44628376299535566 | validation: 0.2561838608847984]
	TIME [epoch: 9.07 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1971373754998155		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 0.1971373754998155 | validation: 0.15124586510562782]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3163502230782897		[learning rate: 0.0085031]
	Learning Rate: 0.00850313
	LOSS [training: 0.3163502230782897 | validation: 0.2497244075058453]
	TIME [epoch: 9.07 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.298935961774216		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.298935961774216 | validation: 0.2781768480949829]
	TIME [epoch: 9.07 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3062432034295099		[learning rate: 0.008462]
	Learning Rate: 0.00846201
	LOSS [training: 0.3062432034295099 | validation: 0.2817472213837259]
	TIME [epoch: 9.07 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36834253904341663		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 0.36834253904341663 | validation: 0.36175834314354305]
	TIME [epoch: 9.06 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28362553538228263		[learning rate: 0.0084211]
	Learning Rate: 0.00842109
	LOSS [training: 0.28362553538228263 | validation: 0.22630545229731508]
	TIME [epoch: 9.09 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28235407869020496		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 0.28235407869020496 | validation: 0.2671844409186324]
	TIME [epoch: 9.07 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3028927162104558		[learning rate: 0.0083804]
	Learning Rate: 0.00838037
	LOSS [training: 0.3028927162104558 | validation: 0.26907289519587363]
	TIME [epoch: 9.07 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3171909673063049		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 0.3171909673063049 | validation: 0.4101265840496001]
	TIME [epoch: 9.07 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4617698057757077		[learning rate: 0.0083398]
	Learning Rate: 0.00833984
	LOSS [training: 0.4617698057757077 | validation: 0.2668369761036863]
	TIME [epoch: 9.08 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3023498903369625		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.3023498903369625 | validation: 0.257124557089657]
	TIME [epoch: 9.07 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30062023698050555		[learning rate: 0.0082995]
	Learning Rate: 0.00829951
	LOSS [training: 0.30062023698050555 | validation: 0.3019160724193299]
	TIME [epoch: 9.07 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3310100703582255		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.3310100703582255 | validation: 0.35426700186264803]
	TIME [epoch: 9.07 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31356221073429397		[learning rate: 0.0082594]
	Learning Rate: 0.00825938
	LOSS [training: 0.31356221073429397 | validation: 0.3222868974404651]
	TIME [epoch: 9.07 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31176740276426074		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.31176740276426074 | validation: 0.31488036755289206]
	TIME [epoch: 9.09 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3344344051545609		[learning rate: 0.0082194]
	Learning Rate: 0.00821944
	LOSS [training: 0.3344344051545609 | validation: 0.4514431656319745]
	TIME [epoch: 9.07 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3410823826028805		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.3410823826028805 | validation: 0.31336666600117574]
	TIME [epoch: 9.07 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32914387716972365		[learning rate: 0.0081797]
	Learning Rate: 0.00817969
	LOSS [training: 0.32914387716972365 | validation: 0.3242551377087248]
	TIME [epoch: 9.06 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31692407060463623		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.31692407060463623 | validation: 0.3686775007528917]
	TIME [epoch: 9.06 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33003159825312334		[learning rate: 0.0081401]
	Learning Rate: 0.00814013
	LOSS [training: 0.33003159825312334 | validation: 0.29267487015557236]
	TIME [epoch: 9.08 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30496399041489636		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.30496399041489636 | validation: 0.5537160635190239]
	TIME [epoch: 9.06 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31030042542222086		[learning rate: 0.0081008]
	Learning Rate: 0.00810077
	LOSS [training: 0.31030042542222086 | validation: 0.3429003634579006]
	TIME [epoch: 9.07 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6974679042139895		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.6974679042139895 | validation: 0.3664792785789774]
	TIME [epoch: 9.07 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2699944527328849		[learning rate: 0.0080616]
	Learning Rate: 0.0080616
	LOSS [training: 0.2699944527328849 | validation: 0.16723179859345486]
	TIME [epoch: 9.09 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4002375776909396		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.4002375776909396 | validation: 0.5714568315200933]
	TIME [epoch: 9.08 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24478317080591436		[learning rate: 0.0080226]
	Learning Rate: 0.00802261
	LOSS [training: 0.24478317080591436 | validation: 0.16547875041975743]
	TIME [epoch: 9.06 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2541866178819301		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.2541866178819301 | validation: 0.2529882280584572]
	TIME [epoch: 9.07 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3341437590254177		[learning rate: 0.0079838]
	Learning Rate: 0.00798382
	LOSS [training: 0.3341437590254177 | validation: 0.33999309195741534]
	TIME [epoch: 9.07 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27592380725538956		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.27592380725538956 | validation: 0.36400268187466034]
	TIME [epoch: 9.09 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2823977798054949		[learning rate: 0.0079452]
	Learning Rate: 0.00794521
	LOSS [training: 0.2823977798054949 | validation: 0.15624770701056717]
	TIME [epoch: 9.07 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15644894735639586		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.15644894735639586 | validation: 0.30129021346205553]
	TIME [epoch: 9.07 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3072168480798963		[learning rate: 0.0079068]
	Learning Rate: 0.00790679
	LOSS [training: 0.3072168480798963 | validation: 0.2595486042673258]
	TIME [epoch: 9.07 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2828160687646477		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.2828160687646477 | validation: 0.629726852997234]
	TIME [epoch: 9.08 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2997284224255363		[learning rate: 0.0078685]
	Learning Rate: 0.00786855
	LOSS [training: 0.2997284224255363 | validation: 0.23400819122413222]
	TIME [epoch: 9.08 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2635620141940524		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.2635620141940524 | validation: 0.24069406196656573]
	TIME [epoch: 9.06 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2649951530182572		[learning rate: 0.0078305]
	Learning Rate: 0.0078305
	LOSS [training: 0.2649951530182572 | validation: 0.41717046368898236]
	TIME [epoch: 9.06 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26528114883978593		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.26528114883978593 | validation: 0.24580101885153455]
	TIME [epoch: 9.07 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3475015668122683		[learning rate: 0.0077926]
	Learning Rate: 0.00779263
	LOSS [training: 0.3475015668122683 | validation: 0.22383317955021875]
	TIME [epoch: 9.09 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20836979516370255		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.20836979516370255 | validation: 0.252886582441751]
	TIME [epoch: 9.07 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21220882404224345		[learning rate: 0.0077549]
	Learning Rate: 0.00775495
	LOSS [training: 0.21220882404224345 | validation: 0.23203840571812212]
	TIME [epoch: 9.07 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29648795897353775		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.29648795897353775 | validation: 0.26835897770652994]
	TIME [epoch: 9.07 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23843452723500896		[learning rate: 0.0077174]
	Learning Rate: 0.00771745
	LOSS [training: 0.23843452723500896 | validation: 0.35611759147410843]
	TIME [epoch: 9.08 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2090182375409176		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.2090182375409176 | validation: 0.22007352895030838]
	TIME [epoch: 9.07 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3363621029473617		[learning rate: 0.0076801]
	Learning Rate: 0.00768013
	LOSS [training: 0.3363621029473617 | validation: 0.2103187774635288]
	TIME [epoch: 9.08 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27003382245251395		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.27003382245251395 | validation: 0.3699810700206758]
	TIME [epoch: 9.07 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21680545212836852		[learning rate: 0.007643]
	Learning Rate: 0.00764299
	LOSS [training: 0.21680545212836852 | validation: 0.20675361105328405]
	TIME [epoch: 9.08 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8683739607476275		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.8683739607476275 | validation: 0.8403964020260828]
	TIME [epoch: 9.09 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0093586931492466		[learning rate: 0.007606]
	Learning Rate: 0.00760603
	LOSS [training: 1.0093586931492466 | validation: 0.8708678872898332]
	TIME [epoch: 9.07 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3432659903519285		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.3432659903519285 | validation: 0.1568403068152123]
	TIME [epoch: 9.06 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27061703292246764		[learning rate: 0.0075692]
	Learning Rate: 0.00756925
	LOSS [training: 0.27061703292246764 | validation: 0.42064256570470493]
	TIME [epoch: 9.07 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31258855458383195		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.31258855458383195 | validation: 0.19244677140276104]
	TIME [epoch: 9.06 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20585041751932504		[learning rate: 0.0075326]
	Learning Rate: 0.00753264
	LOSS [training: 0.20585041751932504 | validation: 0.2263552263706492]
	TIME [epoch: 9.08 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2043079064168456		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.2043079064168456 | validation: 0.15776659967731357]
	TIME [epoch: 9.06 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16532599607352688		[learning rate: 0.0074962]
	Learning Rate: 0.00749622
	LOSS [training: 0.16532599607352688 | validation: 0.8074253195770498]
	TIME [epoch: 9.05 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30024617759935074		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.30024617759935074 | validation: 0.27196402391739305]
	TIME [epoch: 9.06 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2101845571354189		[learning rate: 0.00746]
	Learning Rate: 0.00745997
	LOSS [training: 0.2101845571354189 | validation: 0.45775219366252573]
	TIME [epoch: 9.07 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20002872407207203		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.20002872407207203 | validation: 0.12733732579306856]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13549784016350394		[learning rate: 0.0074239]
	Learning Rate: 0.00742389
	LOSS [training: 0.13549784016350394 | validation: 0.21096428756383742]
	TIME [epoch: 9.07 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4849360011941924		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.4849360011941924 | validation: 0.2834765408944418]
	TIME [epoch: 9.07 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2185702301292134		[learning rate: 0.007388]
	Learning Rate: 0.00738799
	LOSS [training: 0.2185702301292134 | validation: 0.10408574274388899]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19209218315907844		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.19209218315907844 | validation: 0.18270762254991613]
	TIME [epoch: 9.1 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1918665262539943		[learning rate: 0.0073523]
	Learning Rate: 0.00735226
	LOSS [training: 0.1918665262539943 | validation: 0.19694064901946662]
	TIME [epoch: 9.07 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18892703444352377		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.18892703444352377 | validation: 0.15771909552526114]
	TIME [epoch: 9.08 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1613691015290612		[learning rate: 0.0073167]
	Learning Rate: 0.00731671
	LOSS [training: 0.1613691015290612 | validation: 0.4259983949444537]
	TIME [epoch: 9.08 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22517564991789146		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.22517564991789146 | validation: 0.19994584929749376]
	TIME [epoch: 9.08 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27537577429418486		[learning rate: 0.0072813]
	Learning Rate: 0.00728133
	LOSS [training: 0.27537577429418486 | validation: 0.24261886765989027]
	TIME [epoch: 9.09 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2319025434742453		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.2319025434742453 | validation: 0.16421805945777077]
	TIME [epoch: 9.06 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17474717689153993		[learning rate: 0.0072461]
	Learning Rate: 0.00724612
	LOSS [training: 0.17474717689153993 | validation: 0.12874471637134488]
	TIME [epoch: 9.07 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15898985031146		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.15898985031146 | validation: 0.12190218508387388]
	TIME [epoch: 9.09 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2290942134806667		[learning rate: 0.0072111]
	Learning Rate: 0.00721107
	LOSS [training: 0.2290942134806667 | validation: 0.1854200330403171]
	TIME [epoch: 9.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4511439989528239		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.4511439989528239 | validation: 0.283922130613684]
	TIME [epoch: 9.08 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1713379076106013		[learning rate: 0.0071762]
	Learning Rate: 0.0071762
	LOSS [training: 0.1713379076106013 | validation: 0.12988200717424117]
	TIME [epoch: 9.07 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5102130034982456		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.5102130034982456 | validation: 1.0873500050830935]
	TIME [epoch: 9.07 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5665148050530563		[learning rate: 0.0071415]
	Learning Rate: 0.0071415
	LOSS [training: 0.5665148050530563 | validation: 0.3114843616384759]
	TIME [epoch: 9.09 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3363340428774345		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.3363340428774345 | validation: 0.49658924225071344]
	TIME [epoch: 9.09 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3508085930220048		[learning rate: 0.007107]
	Learning Rate: 0.00710696
	LOSS [training: 0.3508085930220048 | validation: 0.6191417254318505]
	TIME [epoch: 9.08 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29186528641958615		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.29186528641958615 | validation: 0.25954285595795795]
	TIME [epoch: 9.08 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22518294087187787		[learning rate: 0.0070726]
	Learning Rate: 0.0070726
	LOSS [training: 0.22518294087187787 | validation: 1.4953162083570581]
	TIME [epoch: 9.08 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5814749363765566		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.5814749363765566 | validation: 0.16331977784721233]
	TIME [epoch: 9.09 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23919097797638172		[learning rate: 0.0070384]
	Learning Rate: 0.0070384
	LOSS [training: 0.23919097797638172 | validation: 0.38711236890516443]
	TIME [epoch: 9.07 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18722232464935795		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.18722232464935795 | validation: 0.25732853914752335]
	TIME [epoch: 9.09 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23568759635610417		[learning rate: 0.0070044]
	Learning Rate: 0.00700436
	LOSS [training: 0.23568759635610417 | validation: 0.3142627271830097]
	TIME [epoch: 9.07 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2935594761030037		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.2935594761030037 | validation: 0.22411015168283682]
	TIME [epoch: 9.07 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2587065835570924		[learning rate: 0.0069705]
	Learning Rate: 0.00697049
	LOSS [training: 0.2587065835570924 | validation: 0.14154847474806004]
	TIME [epoch: 9.09 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1513166923970612		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.1513166923970612 | validation: 0.16233292507822095]
	TIME [epoch: 9.07 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22464064882426124		[learning rate: 0.0069368]
	Learning Rate: 0.00693678
	LOSS [training: 0.22464064882426124 | validation: 0.2094375708165971]
	TIME [epoch: 9.07 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23466342571735077		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.23466342571735077 | validation: 0.25295700222825124]
	TIME [epoch: 9.08 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2022825261847751		[learning rate: 0.0069032]
	Learning Rate: 0.00690323
	LOSS [training: 0.2022825261847751 | validation: 0.20433896628795617]
	TIME [epoch: 9.09 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21577950823241726		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.21577950823241726 | validation: 0.2956952412532714]
	TIME [epoch: 9.09 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24315382795570847		[learning rate: 0.0068699]
	Learning Rate: 0.00686985
	LOSS [training: 0.24315382795570847 | validation: 0.20038936155886605]
	TIME [epoch: 9.08 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.213523680058533		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.213523680058533 | validation: 0.4058012341465207]
	TIME [epoch: 9.07 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2581029741366674		[learning rate: 0.0068366]
	Learning Rate: 0.00683663
	LOSS [training: 0.2581029741366674 | validation: 0.23405711296179957]
	TIME [epoch: 9.07 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2625428977930536		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.2625428977930536 | validation: 0.24390002934190924]
	TIME [epoch: 9.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2253869556273745		[learning rate: 0.0068036]
	Learning Rate: 0.00680357
	LOSS [training: 0.2253869556273745 | validation: 0.17279346556041258]
	TIME [epoch: 9.08 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4570732572415455		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.4570732572415455 | validation: 1.582794798595788]
	TIME [epoch: 9.07 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3809837756201151		[learning rate: 0.0067707]
	Learning Rate: 0.00677067
	LOSS [training: 0.3809837756201151 | validation: 0.1980426761640146]
	TIME [epoch: 9.08 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18802725059742312		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.18802725059742312 | validation: 0.1300961504666024]
	TIME [epoch: 9.08 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.125639714636322		[learning rate: 0.0067379]
	Learning Rate: 0.00673793
	LOSS [training: 0.125639714636322 | validation: 0.08537512944695513]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16220993975368533		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.16220993975368533 | validation: 0.24845262608751129]
	TIME [epoch: 9.09 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1688478469397224		[learning rate: 0.0067053]
	Learning Rate: 0.00670534
	LOSS [training: 0.1688478469397224 | validation: 0.1133767294785859]
	TIME [epoch: 9.08 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1220923633703634		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.1220923633703634 | validation: 0.19404514518491628]
	TIME [epoch: 9.07 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3277171386814676		[learning rate: 0.0066729]
	Learning Rate: 0.00667292
	LOSS [training: 0.3277171386814676 | validation: 0.2263610131613315]
	TIME [epoch: 9.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18932375827898476		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.18932375827898476 | validation: 0.10715934589071277]
	TIME [epoch: 9.09 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15645536277777175		[learning rate: 0.0066406]
	Learning Rate: 0.00664065
	LOSS [training: 0.15645536277777175 | validation: 0.16019289739794584]
	TIME [epoch: 9.08 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19754443183323814		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.19754443183323814 | validation: 0.3728255325135481]
	TIME [epoch: 9.07 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25887912219848674		[learning rate: 0.0066085]
	Learning Rate: 0.00660854
	LOSS [training: 0.25887912219848674 | validation: 0.1609378407826565]
	TIME [epoch: 9.08 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18793146853008913		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.18793146853008913 | validation: 0.23960146817188005]
	TIME [epoch: 9.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20777591127824707		[learning rate: 0.0065766]
	Learning Rate: 0.00657658
	LOSS [training: 0.20777591127824707 | validation: 0.35812611298821007]
	TIME [epoch: 9.08 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30314108973686527		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.30314108973686527 | validation: 0.141813198235603]
	TIME [epoch: 9.09 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2822492334192197		[learning rate: 0.0065448]
	Learning Rate: 0.00654477
	LOSS [training: 0.2822492334192197 | validation: 0.8873906918134171]
	TIME [epoch: 9.07 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26416423470684114		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.26416423470684114 | validation: 0.15381878320371817]
	TIME [epoch: 9.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18469984900035938		[learning rate: 0.0065131]
	Learning Rate: 0.00651313
	LOSS [training: 0.18469984900035938 | validation: 0.25148230660118565]
	TIME [epoch: 9.07 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18376449510664927		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.18376449510664927 | validation: 0.13066988947132507]
	TIME [epoch: 9.07 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25636806935829515		[learning rate: 0.0064816]
	Learning Rate: 0.00648163
	LOSS [training: 0.25636806935829515 | validation: 0.47042622601040174]
	TIME [epoch: 9.08 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33075683615580037		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.33075683615580037 | validation: 0.2334022665276947]
	TIME [epoch: 9.08 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22725332570636922		[learning rate: 0.0064503]
	Learning Rate: 0.00645029
	LOSS [training: 0.22725332570636922 | validation: 0.2670818013901751]
	TIME [epoch: 9.11 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35320208214842774		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.35320208214842774 | validation: 0.3424494062179999]
	TIME [epoch: 9.07 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26462803940602575		[learning rate: 0.0064191]
	Learning Rate: 0.00641909
	LOSS [training: 0.26462803940602575 | validation: 0.22215235724281285]
	TIME [epoch: 9.07 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17104368575263326		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.17104368575263326 | validation: 0.27833876728572926]
	TIME [epoch: 9.08 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2861974609766361		[learning rate: 0.0063881]
	Learning Rate: 0.00638805
	LOSS [training: 0.2861974609766361 | validation: 0.1960079688671022]
	TIME [epoch: 9.08 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28262487787366847		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.28262487787366847 | validation: 0.24386242667217006]
	TIME [epoch: 9.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2737166701367223		[learning rate: 0.0063572]
	Learning Rate: 0.00635716
	LOSS [training: 0.2737166701367223 | validation: 0.5889276651993538]
	TIME [epoch: 9.09 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26245472814345494		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.26245472814345494 | validation: 0.1534674494252808]
	TIME [epoch: 9.07 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16405300091766362		[learning rate: 0.0063264]
	Learning Rate: 0.00632642
	LOSS [training: 0.16405300091766362 | validation: 0.19455610536738482]
	TIME [epoch: 9.07 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23066508347463488		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.23066508347463488 | validation: 0.19189895775227667]
	TIME [epoch: 9.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2044417863416192		[learning rate: 0.0062958]
	Learning Rate: 0.00629582
	LOSS [training: 0.2044417863416192 | validation: 0.19676603445062518]
	TIME [epoch: 9.08 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2077292479047467		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.2077292479047467 | validation: 0.17777631097349128]
	TIME [epoch: 9.07 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20144618988361027		[learning rate: 0.0062654]
	Learning Rate: 0.00626538
	LOSS [training: 0.20144618988361027 | validation: 0.2401067026240215]
	TIME [epoch: 9.08 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20822115004550054		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.20822115004550054 | validation: 0.17777169610836394]
	TIME [epoch: 9.09 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16280330822630917		[learning rate: 0.0062351]
	Learning Rate: 0.00623508
	LOSS [training: 0.16280330822630917 | validation: 0.19247003628565418]
	TIME [epoch: 9.08 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19573600880850392		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.19573600880850392 | validation: 0.18028880361257016]
	TIME [epoch: 9.08 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20803885442667328		[learning rate: 0.0062049]
	Learning Rate: 0.00620493
	LOSS [training: 0.20803885442667328 | validation: 0.2229352031824025]
	TIME [epoch: 9.07 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2657149566608605		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.2657149566608605 | validation: 0.1843497886183919]
	TIME [epoch: 9.07 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18816049757407116		[learning rate: 0.0061749]
	Learning Rate: 0.00617492
	LOSS [training: 0.18816049757407116 | validation: 0.19028491339057707]
	TIME [epoch: 9.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2397422774187795		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.2397422774187795 | validation: 0.2751810212236854]
	TIME [epoch: 9.09 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2181904635677397		[learning rate: 0.0061451]
	Learning Rate: 0.00614506
	LOSS [training: 0.2181904635677397 | validation: 0.1843382144603281]
	TIME [epoch: 9.08 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21135628491427777		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.21135628491427777 | validation: 0.2286893986829039]
	TIME [epoch: 9.08 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26839405571613917		[learning rate: 0.0061153]
	Learning Rate: 0.00611535
	LOSS [training: 0.26839405571613917 | validation: 0.3569430373379937]
	TIME [epoch: 9.08 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22263743753190615		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.22263743753190615 | validation: 0.21781131697652462]
	TIME [epoch: 9.1 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18036464335585617		[learning rate: 0.0060858]
	Learning Rate: 0.00608577
	LOSS [training: 0.18036464335585617 | validation: 0.16118428420206943]
	TIME [epoch: 9.07 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23565563350665686		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.23565563350665686 | validation: 0.21163603479356052]
	TIME [epoch: 9.08 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23472627053367293		[learning rate: 0.0060563]
	Learning Rate: 0.00605634
	LOSS [training: 0.23472627053367293 | validation: 0.15862931665597638]
	TIME [epoch: 9.08 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2569148787234427		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.2569148787234427 | validation: 0.19120280447138407]
	TIME [epoch: 9.1 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21685785068558597		[learning rate: 0.0060271]
	Learning Rate: 0.00602706
	LOSS [training: 0.21685785068558597 | validation: 0.18633741609927104]
	TIME [epoch: 9.07 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19890371121320397		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.19890371121320397 | validation: 0.38108820909404706]
	TIME [epoch: 9.08 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20391863316042516		[learning rate: 0.0059979]
	Learning Rate: 0.00599791
	LOSS [training: 0.20391863316042516 | validation: 0.1306119491906191]
	TIME [epoch: 9.08 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19570532018631767		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.19570532018631767 | validation: 0.22259931573391334]
	TIME [epoch: 9.09 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1931751671091499		[learning rate: 0.0059689]
	Learning Rate: 0.00596891
	LOSS [training: 0.1931751671091499 | validation: 0.3196697506705284]
	TIME [epoch: 9.11 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2854865681741424		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.2854865681741424 | validation: 0.27858810958850266]
	TIME [epoch: 9.08 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2438878229575973		[learning rate: 0.00594]
	Learning Rate: 0.00594004
	LOSS [training: 0.2438878229575973 | validation: 0.24678539458102453]
	TIME [epoch: 9.08 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21455651183415653		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.21455651183415653 | validation: 0.28313594993607655]
	TIME [epoch: 9.08 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21183305894244295		[learning rate: 0.0059113]
	Learning Rate: 0.00591132
	LOSS [training: 0.21183305894244295 | validation: 0.19844036508364507]
	TIME [epoch: 9.09 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18601153110845386		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.18601153110845386 | validation: 0.1473747788682791]
	TIME [epoch: 9.09 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2173218470064096		[learning rate: 0.0058827]
	Learning Rate: 0.00588273
	LOSS [training: 0.2173218470064096 | validation: 0.6733534930696478]
	TIME [epoch: 9.08 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24264676990115666		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.24264676990115666 | validation: 0.4032158190058125]
	TIME [epoch: 9.09 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23880026729655338		[learning rate: 0.0058543]
	Learning Rate: 0.00585428
	LOSS [training: 0.23880026729655338 | validation: 0.2056956816329631]
	TIME [epoch: 9.08 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2678360647547832		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.2678360647547832 | validation: 0.28436929094229435]
	TIME [epoch: 9.11 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32636825808476766		[learning rate: 0.005826]
	Learning Rate: 0.00582597
	LOSS [training: 0.32636825808476766 | validation: 0.18294015134880648]
	TIME [epoch: 9.08 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19110587814246593		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.19110587814246593 | validation: 0.0960731308195983]
	TIME [epoch: 9.08 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13761022471890091		[learning rate: 0.0057978]
	Learning Rate: 0.0057978
	LOSS [training: 0.13761022471890091 | validation: 0.11999990311134984]
	TIME [epoch: 9.07 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5428818585951475		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.5428818585951475 | validation: 0.5327292717189854]
	TIME [epoch: 9.09 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23556141494935012		[learning rate: 0.0057698]
	Learning Rate: 0.00576976
	LOSS [training: 0.23556141494935012 | validation: 0.096624058067528]
	TIME [epoch: 9.1 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09554164492808095		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.09554164492808095 | validation: 0.10558291506115286]
	TIME [epoch: 9.08 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23444939225004227		[learning rate: 0.0057419]
	Learning Rate: 0.00574186
	LOSS [training: 0.23444939225004227 | validation: 0.543598191257878]
	TIME [epoch: 9.08 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2766075807476699		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.2766075807476699 | validation: 0.19750621621203712]
	TIME [epoch: 9.09 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13404223100518925		[learning rate: 0.0057141]
	Learning Rate: 0.00571409
	LOSS [training: 0.13404223100518925 | validation: 0.17619266824115634]
	TIME [epoch: 9.11 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17554832868263695		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.17554832868263695 | validation: 0.2015576429634317]
	TIME [epoch: 9.09 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2920811070729553		[learning rate: 0.0056865]
	Learning Rate: 0.00568646
	LOSS [training: 0.2920811070729553 | validation: 0.4237352269639407]
	TIME [epoch: 9.08 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39272079286492645		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.39272079286492645 | validation: 0.1886323051378835]
	TIME [epoch: 9.08 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13799395570497738		[learning rate: 0.005659]
	Learning Rate: 0.00565896
	LOSS [training: 0.13799395570497738 | validation: 0.10592446946459158]
	TIME [epoch: 9.08 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1907677299662811		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.1907677299662811 | validation: 0.20277662680397052]
	TIME [epoch: 9.09 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15453926213312208		[learning rate: 0.0056316]
	Learning Rate: 0.0056316
	LOSS [training: 0.15453926213312208 | validation: 0.23276102110956187]
	TIME [epoch: 9.07 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11902720034099627		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.11902720034099627 | validation: 0.08203337962755748]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10231101827598146		[learning rate: 0.0056044]
	Learning Rate: 0.00560436
	LOSS [training: 0.10231101827598146 | validation: 0.7109800559180424]
	TIME [epoch: 9.08 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2767090825240823		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.2767090825240823 | validation: 0.24251938611107837]
	TIME [epoch: 9.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2714559974893832		[learning rate: 0.0055773]
	Learning Rate: 0.00557726
	LOSS [training: 0.2714559974893832 | validation: 0.20740343063460115]
	TIME [epoch: 9.08 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21167215301854103		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.21167215301854103 | validation: 0.10302316983956958]
	TIME [epoch: 9.08 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11012090822935805		[learning rate: 0.0055503]
	Learning Rate: 0.00555029
	LOSS [training: 0.11012090822935805 | validation: 0.13054839019595912]
	TIME [epoch: 9.08 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20793609065583016		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.20793609065583016 | validation: 0.2499926545427472]
	TIME [epoch: 9.07 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18678549842587122		[learning rate: 0.0055235]
	Learning Rate: 0.00552345
	LOSS [training: 0.18678549842587122 | validation: 0.1363340538517377]
	TIME [epoch: 9.1 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10373791872480523		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.10373791872480523 | validation: 0.07307624578112307]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1496654005542665		[learning rate: 0.0054967]
	Learning Rate: 0.00549674
	LOSS [training: 0.1496654005542665 | validation: 0.1905204327454671]
	TIME [epoch: 9.08 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13562846121726801		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.13562846121726801 | validation: 0.12515732411783087]
	TIME [epoch: 9.07 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15045930946594027		[learning rate: 0.0054702]
	Learning Rate: 0.00547016
	LOSS [training: 0.15045930946594027 | validation: 0.21029102339011901]
	TIME [epoch: 9.08 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23643171589396245		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.23643171589396245 | validation: 0.1432181748420526]
	TIME [epoch: 9.09 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2929492846401731		[learning rate: 0.0054437]
	Learning Rate: 0.00544371
	LOSS [training: 0.2929492846401731 | validation: 0.14411606255567352]
	TIME [epoch: 9.08 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10767013785308481		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.10767013785308481 | validation: 0.2002767785994939]
	TIME [epoch: 9.08 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15836068568431366		[learning rate: 0.0054174]
	Learning Rate: 0.00541738
	LOSS [training: 0.15836068568431366 | validation: 0.16130529883899583]
	TIME [epoch: 9.08 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13687995274498918		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.13687995274498918 | validation: 0.1667794254389956]
	TIME [epoch: 9.09 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1252093577864256		[learning rate: 0.0053912]
	Learning Rate: 0.00539118
	LOSS [training: 0.1252093577864256 | validation: 0.19569104926187386]
	TIME [epoch: 9.08 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12945310728038725		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.12945310728038725 | validation: 0.14660504489818954]
	TIME [epoch: 9.07 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15039226707866082		[learning rate: 0.0053651]
	Learning Rate: 0.00536511
	LOSS [training: 0.15039226707866082 | validation: 0.16799610102749618]
	TIME [epoch: 9.08 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15864091460600332		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.15864091460600332 | validation: 0.14798823999393929]
	TIME [epoch: 9.08 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1906171585663166		[learning rate: 0.0053392]
	Learning Rate: 0.00533917
	LOSS [training: 0.1906171585663166 | validation: 0.24248623034719285]
	TIME [epoch: 9.09 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19806437239398697		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.19806437239398697 | validation: 0.20345231102478595]
	TIME [epoch: 9.08 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25028889132795235		[learning rate: 0.0053133]
	Learning Rate: 0.00531335
	LOSS [training: 0.25028889132795235 | validation: 0.1922963164597919]
	TIME [epoch: 9.08 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15676451441062234		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.15676451441062234 | validation: 0.22595258387247585]
	TIME [epoch: 9.08 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3334375404550958		[learning rate: 0.0052877]
	Learning Rate: 0.00528766
	LOSS [training: 0.3334375404550958 | validation: 0.20508535636721595]
	TIME [epoch: 9.09 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15776642446061695		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.15776642446061695 | validation: 0.17466742841609934]
	TIME [epoch: 9.08 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1720737000392462		[learning rate: 0.0052621]
	Learning Rate: 0.00526209
	LOSS [training: 0.1720737000392462 | validation: 0.22958745501596495]
	TIME [epoch: 9.08 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27632160430786473		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.27632160430786473 | validation: 0.36065938226499616]
	TIME [epoch: 9.08 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2296255770960937		[learning rate: 0.0052366]
	Learning Rate: 0.00523664
	LOSS [training: 0.2296255770960937 | validation: 0.17041502407800396]
	TIME [epoch: 9.08 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25520985633081883		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.25520985633081883 | validation: 0.182652192735857]
	TIME [epoch: 9.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18953819287853851		[learning rate: 0.0052113]
	Learning Rate: 0.00521132
	LOSS [training: 0.18953819287853851 | validation: 0.14113466359578256]
	TIME [epoch: 9.07 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14972172075324944		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.14972172075324944 | validation: 0.14346389184092995]
	TIME [epoch: 9.08 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18432707840741527		[learning rate: 0.0051861]
	Learning Rate: 0.00518611
	LOSS [training: 0.18432707840741527 | validation: 0.1309932961311524]
	TIME [epoch: 9.08 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16558045030724808		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.16558045030724808 | validation: 0.15304811544683505]
	TIME [epoch: 9.09 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14781978195821593		[learning rate: 0.005161]
	Learning Rate: 0.00516104
	LOSS [training: 0.14781978195821593 | validation: 0.27583568230524474]
	TIME [epoch: 9.08 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1951998533106008		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.1951998533106008 | validation: 0.13774853779046084]
	TIME [epoch: 9.07 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15356603139174813		[learning rate: 0.0051361]
	Learning Rate: 0.00513608
	LOSS [training: 0.15356603139174813 | validation: 0.18297666553956154]
	TIME [epoch: 9.08 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1590880452316798		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.1590880452316798 | validation: 0.20047531303390032]
	TIME [epoch: 9.08 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1276497836147897		[learning rate: 0.0051112]
	Learning Rate: 0.00511124
	LOSS [training: 0.1276497836147897 | validation: 0.13582218902293253]
	TIME [epoch: 9.09 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1513612004917993		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.1513612004917993 | validation: 0.4338824687154517]
	TIME [epoch: 9.07 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27497570199414356		[learning rate: 0.0050865]
	Learning Rate: 0.00508652
	LOSS [training: 0.27497570199414356 | validation: 0.20747182673776077]
	TIME [epoch: 9.07 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14861099294321706		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.14861099294321706 | validation: 0.07711790022008075]
	TIME [epoch: 9.08 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2157794071195071		[learning rate: 0.0050619]
	Learning Rate: 0.00506193
	LOSS [training: 0.2157794071195071 | validation: 0.09017142542088719]
	TIME [epoch: 9.09 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10430638903029892		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.10430638903029892 | validation: 0.13282753155503096]
	TIME [epoch: 9.09 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14522561874756115		[learning rate: 0.0050374]
	Learning Rate: 0.00503745
	LOSS [training: 0.14522561874756115 | validation: 0.1205469412022903]
	TIME [epoch: 9.07 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13690781818786651		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.13690781818786651 | validation: 0.23487238504816882]
	TIME [epoch: 9.07 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13184139855938984		[learning rate: 0.0050131]
	Learning Rate: 0.00501309
	LOSS [training: 0.13184139855938984 | validation: 0.10462806187130563]
	TIME [epoch: 9.08 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14830146653114887		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.14830146653114887 | validation: 0.15735703938771894]
	TIME [epoch: 9.1 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13520809017517038		[learning rate: 0.0049888]
	Learning Rate: 0.00498884
	LOSS [training: 0.13520809017517038 | validation: 0.11450583501204539]
	TIME [epoch: 9.08 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1383300337264429		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.1383300337264429 | validation: 0.14801486923720233]
	TIME [epoch: 9.08 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.239729932296557		[learning rate: 0.0049647]
	Learning Rate: 0.00496472
	LOSS [training: 0.239729932296557 | validation: 0.14611821566791372]
	TIME [epoch: 9.08 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1136320216996275		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.1136320216996275 | validation: 0.11802950961810571]
	TIME [epoch: 9.09 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14627534484201776		[learning rate: 0.0049407]
	Learning Rate: 0.00494071
	LOSS [training: 0.14627534484201776 | validation: 0.15219763904129174]
	TIME [epoch: 9.09 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15784200031167503		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.15784200031167503 | validation: 0.07316631029536036]
	TIME [epoch: 9.07 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09886657019927421		[learning rate: 0.0049168]
	Learning Rate: 0.00491682
	LOSS [training: 0.09886657019927421 | validation: 0.11442344808890006]
	TIME [epoch: 9.08 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2585725836026272		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.2585725836026272 | validation: 0.27776474168940957]
	TIME [epoch: 9.07 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2248890062151002		[learning rate: 0.004893]
	Learning Rate: 0.00489304
	LOSS [training: 0.2248890062151002 | validation: 0.1990118111716606]
	TIME [epoch: 9.09 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21274263789408238		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.21274263789408238 | validation: 0.12308753305193967]
	TIME [epoch: 9.08 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08734308871109363		[learning rate: 0.0048694]
	Learning Rate: 0.00486938
	LOSS [training: 0.08734308871109363 | validation: 0.05219910748531142]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14183994557481705		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.14183994557481705 | validation: 0.19133575900511865]
	TIME [epoch: 9.08 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11441528265877739		[learning rate: 0.0048458]
	Learning Rate: 0.00484583
	LOSS [training: 0.11441528265877739 | validation: 0.0889311572411431]
	TIME [epoch: 9.08 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08676367536263757		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.08676367536263757 | validation: 0.08930638964627946]
	TIME [epoch: 9.1 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16631342804775223		[learning rate: 0.0048224]
	Learning Rate: 0.0048224
	LOSS [training: 0.16631342804775223 | validation: 0.2143057848322607]
	TIME [epoch: 9.08 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23174237134100362		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.23174237134100362 | validation: 0.7772847948193273]
	TIME [epoch: 9.08 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4187148434534932		[learning rate: 0.0047991]
	Learning Rate: 0.00479908
	LOSS [training: 0.4187148434534932 | validation: 0.091601518043147]
	TIME [epoch: 9.08 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10594736628524867		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.10594736628524867 | validation: 0.137903018785967]
	TIME [epoch: 9.09 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12931997324666403		[learning rate: 0.0047759]
	Learning Rate: 0.00477587
	LOSS [training: 0.12931997324666403 | validation: 0.07677710463440642]
	TIME [epoch: 9.08 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12485928180945882		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.12485928180945882 | validation: 0.1561080214173682]
	TIME [epoch: 9.1 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16384511171428306		[learning rate: 0.0047528]
	Learning Rate: 0.00475278
	LOSS [training: 0.16384511171428306 | validation: 0.09109469664287229]
	TIME [epoch: 9.07 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09730679755026264		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.09730679755026264 | validation: 0.10479272083081258]
	TIME [epoch: 9.08 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10396981600180785		[learning rate: 0.0047298]
	Learning Rate: 0.00472979
	LOSS [training: 0.10396981600180785 | validation: 0.16452621416499058]
	TIME [epoch: 9.1 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12222196716203604		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.12222196716203604 | validation: 0.14708994959545485]
	TIME [epoch: 9.07 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16970449216681122		[learning rate: 0.0047069]
	Learning Rate: 0.00470692
	LOSS [training: 0.16970449216681122 | validation: 0.24768553167687657]
	TIME [epoch: 9.08 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1826018249126199		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.1826018249126199 | validation: 0.13650422863228273]
	TIME [epoch: 9.08 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12963070543166455		[learning rate: 0.0046842]
	Learning Rate: 0.00468416
	LOSS [training: 0.12963070543166455 | validation: 0.1814379895591951]
	TIME [epoch: 9.09 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14973785561874647		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.14973785561874647 | validation: 0.1042825316208849]
	TIME [epoch: 9.09 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11531873053021953		[learning rate: 0.0046615]
	Learning Rate: 0.00466151
	LOSS [training: 0.11531873053021953 | validation: 0.08838571150215972]
	TIME [epoch: 9.08 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22128997265053077		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.22128997265053077 | validation: 0.1674571249819846]
	TIME [epoch: 9.07 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18485779179081546		[learning rate: 0.004639]
	Learning Rate: 0.00463896
	LOSS [training: 0.18485779179081546 | validation: 0.09826080652643265]
	TIME [epoch: 9.08 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1546397617983383		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.1546397617983383 | validation: 0.27218811185983166]
	TIME [epoch: 9.1 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18345663706074944		[learning rate: 0.0046165]
	Learning Rate: 0.00461653
	LOSS [training: 0.18345663706074944 | validation: 0.1599589641763356]
	TIME [epoch: 9.09 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2745875753168971		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.2745875753168971 | validation: 0.1867737869994186]
	TIME [epoch: 9.08 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15602059181344938		[learning rate: 0.0045942]
	Learning Rate: 0.00459421
	LOSS [training: 0.15602059181344938 | validation: 0.10026718290427929]
	TIME [epoch: 9.08 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1282691701640776		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.1282691701640776 | validation: 0.13316461225671575]
	TIME [epoch: 9.08 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12229820131780995		[learning rate: 0.004572]
	Learning Rate: 0.00457199
	LOSS [training: 0.12229820131780995 | validation: 0.09557455621637612]
	TIME [epoch: 9.09 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08152329924601567		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.08152329924601567 | validation: 0.12241329051066102]
	TIME [epoch: 9.08 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10936819664263334		[learning rate: 0.0045499]
	Learning Rate: 0.00454988
	LOSS [training: 0.10936819664263334 | validation: 0.0803629752218128]
	TIME [epoch: 9.07 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12483491299097023		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.12483491299097023 | validation: 0.0692520466507771]
	TIME [epoch: 9.08 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11561697967770838		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.11561697967770838 | validation: 0.06662297025529232]
	TIME [epoch: 9.09 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11831403528441449		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.11831403528441449 | validation: 0.3335050173570513]
	TIME [epoch: 9.08 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18760000226284781		[learning rate: 0.004506]
	Learning Rate: 0.00450598
	LOSS [training: 0.18760000226284781 | validation: 0.1398504303250569]
	TIME [epoch: 9.07 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18551426690427916		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.18551426690427916 | validation: 0.3139454573671149]
	TIME [epoch: 9.07 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13434963518970872		[learning rate: 0.0044842]
	Learning Rate: 0.00448419
	LOSS [training: 0.13434963518970872 | validation: 0.12760695789278298]
	TIME [epoch: 9.07 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10944551412335617		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.10944551412335617 | validation: 0.05818379900246609]
	TIME [epoch: 9.1 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08725245443898763		[learning rate: 0.0044625]
	Learning Rate: 0.00446251
	LOSS [training: 0.08725245443898763 | validation: 0.11342945263686709]
	TIME [epoch: 9.08 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09990424748492717		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.09990424748492717 | validation: 0.19295092575475303]
	TIME [epoch: 9.07 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14488154606876358		[learning rate: 0.0044409]
	Learning Rate: 0.00444093
	LOSS [training: 0.14488154606876358 | validation: 0.1132248699283114]
	TIME [epoch: 9.07 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10882100758282678		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.10882100758282678 | validation: 0.15784265178427764]
	TIME [epoch: 9.07 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09048714845646191		[learning rate: 0.0044195]
	Learning Rate: 0.00441945
	LOSS [training: 0.09048714845646191 | validation: 0.07287785708430744]
	TIME [epoch: 9.08 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08378028436331605		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.08378028436331605 | validation: 0.08677046862909737]
	TIME [epoch: 9.07 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11394912045677792		[learning rate: 0.0043981]
	Learning Rate: 0.00439808
	LOSS [training: 0.11394912045677792 | validation: 0.1700365178718783]
	TIME [epoch: 9.06 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16179292348722144		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.16179292348722144 | validation: 0.16063702375733954]
	TIME [epoch: 9.07 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23724676859420518		[learning rate: 0.0043768]
	Learning Rate: 0.00437681
	LOSS [training: 0.23724676859420518 | validation: 0.2700733776511837]
	TIME [epoch: 9.08 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1912522790295756		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.1912522790295756 | validation: 0.15822239422360423]
	TIME [epoch: 9.07 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13279652160187128		[learning rate: 0.0043556]
	Learning Rate: 0.00435565
	LOSS [training: 0.13279652160187128 | validation: 0.12369359543883965]
	TIME [epoch: 9.07 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15204883725262325		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.15204883725262325 | validation: 0.11913368574915295]
	TIME [epoch: 9.07 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08464696819459631		[learning rate: 0.0043346]
	Learning Rate: 0.00433458
	LOSS [training: 0.08464696819459631 | validation: 0.12775933648234014]
	TIME [epoch: 9.08 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11935026405153426		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.11935026405153426 | validation: 0.23093373856517535]
	TIME [epoch: 9.08 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12767150938043698		[learning rate: 0.0043136]
	Learning Rate: 0.00431362
	LOSS [training: 0.12767150938043698 | validation: 0.07523000836790372]
	TIME [epoch: 9.08 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0946134081291454		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.0946134081291454 | validation: 0.2597082566555485]
	TIME [epoch: 9.07 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13822141764051454		[learning rate: 0.0042928]
	Learning Rate: 0.00429276
	LOSS [training: 0.13822141764051454 | validation: 0.10859465198578444]
	TIME [epoch: 9.07 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10157486801753843		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.10157486801753843 | validation: 0.09769151343236532]
	TIME [epoch: 9.08 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12273896117570438		[learning rate: 0.004272]
	Learning Rate: 0.004272
	LOSS [training: 0.12273896117570438 | validation: 0.14288154913212742]
	TIME [epoch: 9.07 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13573791715186476		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.13573791715186476 | validation: 0.11213296821999051]
	TIME [epoch: 9.07 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13312601912647073		[learning rate: 0.0042513]
	Learning Rate: 0.00425134
	LOSS [training: 0.13312601912647073 | validation: 0.20428443832341925]
	TIME [epoch: 9.07 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08476585611080206		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.08476585611080206 | validation: 0.16647147679433794]
	TIME [epoch: 9.07 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28219032883619527		[learning rate: 0.0042308]
	Learning Rate: 0.00423079
	LOSS [training: 0.28219032883619527 | validation: 0.13405796403788492]
	TIME [epoch: 9.09 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11888673866445516		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.11888673866445516 | validation: 0.13531768781886822]
	TIME [epoch: 9.07 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10774767354364409		[learning rate: 0.0042103]
	Learning Rate: 0.00421033
	LOSS [training: 0.10774767354364409 | validation: 0.07028489046514952]
	TIME [epoch: 9.08 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08242488315796245		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.08242488315796245 | validation: 0.11268556292425586]
	TIME [epoch: 9.07 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1264500746435924		[learning rate: 0.00419]
	Learning Rate: 0.00418997
	LOSS [training: 0.1264500746435924 | validation: 0.09242494931510584]
	TIME [epoch: 9.09 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10506517404970861		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.10506517404970861 | validation: 0.0882454425186399]
	TIME [epoch: 9.08 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08780418500485292		[learning rate: 0.0041697]
	Learning Rate: 0.0041697
	LOSS [training: 0.08780418500485292 | validation: 0.08486436054028315]
	TIME [epoch: 9.07 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08295124019102824		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.08295124019102824 | validation: 0.10336286243297475]
	TIME [epoch: 9.07 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11798561781705683		[learning rate: 0.0041495]
	Learning Rate: 0.00414954
	LOSS [training: 0.11798561781705683 | validation: 0.19237641721035917]
	TIME [epoch: 9.07 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08322096002560828		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.08322096002560828 | validation: 0.06401963195288812]
	TIME [epoch: 9.09 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07512328587260196		[learning rate: 0.0041295]
	Learning Rate: 0.00412947
	LOSS [training: 0.07512328587260196 | validation: 0.05446202629128742]
	TIME [epoch: 9.07 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11327491846153129		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.11327491846153129 | validation: 0.08623606593870764]
	TIME [epoch: 9.07 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10932861921143044		[learning rate: 0.0041095]
	Learning Rate: 0.0041095
	LOSS [training: 0.10932861921143044 | validation: 0.14754594040295213]
	TIME [epoch: 9.07 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11692134088298996		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.11692134088298996 | validation: 0.05840560944903239]
	TIME [epoch: 9.08 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0863266323322446		[learning rate: 0.0040896]
	Learning Rate: 0.00408963
	LOSS [training: 0.0863266323322446 | validation: 0.07973621637533886]
	TIME [epoch: 9.08 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06579820400999839		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.06579820400999839 | validation: 0.06591970149109624]
	TIME [epoch: 9.07 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09429118625761611		[learning rate: 0.0040699]
	Learning Rate: 0.00406985
	LOSS [training: 0.09429118625761611 | validation: 0.17980383848617612]
	TIME [epoch: 9.08 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12178833433577921		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.12178833433577921 | validation: 0.0985362670298726]
	TIME [epoch: 9.08 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09801227729190352		[learning rate: 0.0040502]
	Learning Rate: 0.00405017
	LOSS [training: 0.09801227729190352 | validation: 0.10243936182583042]
	TIME [epoch: 9.09 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12912761582039362		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.12912761582039362 | validation: 0.3216390957686275]
	TIME [epoch: 9.07 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12687200850930352		[learning rate: 0.0040306]
	Learning Rate: 0.00403059
	LOSS [training: 0.12687200850930352 | validation: 0.04850923914224049]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_475.pth
	Model improved!!!
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07528295228396215		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.07528295228396215 | validation: 0.06638995693935938]
	TIME [epoch: 9.06 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12976861095313222		[learning rate: 0.0040111]
	Learning Rate: 0.0040111
	LOSS [training: 0.12976861095313222 | validation: 0.10969010087973223]
	TIME [epoch: 9.09 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08915894815597106		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.08915894815597106 | validation: 0.12264600322450422]
	TIME [epoch: 9.09 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08209982433683075		[learning rate: 0.0039917]
	Learning Rate: 0.0039917
	LOSS [training: 0.08209982433683075 | validation: 0.1089667077394294]
	TIME [epoch: 9.08 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06974069406846224		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.06974069406846224 | validation: 0.07406446194404914]
	TIME [epoch: 9.07 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06619687090108722		[learning rate: 0.0039724]
	Learning Rate: 0.0039724
	LOSS [training: 0.06619687090108722 | validation: 0.06271627012742416]
	TIME [epoch: 9.06 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.091394917308656		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.091394917308656 | validation: 0.09589688764083479]
	TIME [epoch: 9.09 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12544490709793849		[learning rate: 0.0039532]
	Learning Rate: 0.00395319
	LOSS [training: 0.12544490709793849 | validation: 0.19508260182100784]
	TIME [epoch: 9.07 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13439202344033957		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.13439202344033957 | validation: 0.12410054094120104]
	TIME [epoch: 9.07 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12529965395864173		[learning rate: 0.0039341]
	Learning Rate: 0.00393407
	LOSS [training: 0.12529965395864173 | validation: 0.11664475361915198]
	TIME [epoch: 9.08 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13487991842269403		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.13487991842269403 | validation: 0.12119281540382298]
	TIME [epoch: 9.07 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1268872127988927		[learning rate: 0.003915]
	Learning Rate: 0.00391505
	LOSS [training: 0.1268872127988927 | validation: 0.07859690380116671]
	TIME [epoch: 9.09 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0861632458806065		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.0861632458806065 | validation: 0.1575935592933258]
	TIME [epoch: 9.06 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13534006772802798		[learning rate: 0.0038961]
	Learning Rate: 0.00389611
	LOSS [training: 0.13534006772802798 | validation: 0.07573384807416739]
	TIME [epoch: 9.07 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08900716588230362		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.08900716588230362 | validation: 0.10088914467379329]
	TIME [epoch: 9.07 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12127637628231033		[learning rate: 0.0038773]
	Learning Rate: 0.00387727
	LOSS [training: 0.12127637628231033 | validation: 0.10903158214983655]
	TIME [epoch: 9.08 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13388234863365006		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.13388234863365006 | validation: 0.18143325219308187]
	TIME [epoch: 9.09 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13550674774947727		[learning rate: 0.0038585]
	Learning Rate: 0.00385852
	LOSS [training: 0.13550674774947727 | validation: 0.12553738399981496]
	TIME [epoch: 9.07 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09960287435755553		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.09960287435755553 | validation: 0.058226946860889195]
	TIME [epoch: 9.06 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07911549468367315		[learning rate: 0.0038399]
	Learning Rate: 0.00383986
	LOSS [training: 0.07911549468367315 | validation: 0.06325535341910604]
	TIME [epoch: 9.07 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14727845970222186		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.14727845970222186 | validation: 0.1154579576806063]
	TIME [epoch: 9.09 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1571666448099715		[learning rate: 0.0038213]
	Learning Rate: 0.00382129
	LOSS [training: 0.1571666448099715 | validation: 0.20166251616147765]
	TIME [epoch: 9.08 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10489052065495867		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.10489052065495867 | validation: 0.08120172900603873]
	TIME [epoch: 9.07 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12390744975008652		[learning rate: 0.0038028]
	Learning Rate: 0.00380282
	LOSS [training: 0.12390744975008652 | validation: 0.1392887261005716]
	TIME [epoch: 9.07 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12710384147016762		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.12710384147016762 | validation: 0.08641818401544896]
	TIME [epoch: 9.08 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07889682864077516		[learning rate: 0.0037844]
	Learning Rate: 0.00378443
	LOSS [training: 0.07889682864077516 | validation: 0.20302586790777088]
	TIME [epoch: 9.08 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14393466273230687		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.14393466273230687 | validation: 0.08036515415172638]
	TIME [epoch: 9.07 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10228942182202963		[learning rate: 0.0037661]
	Learning Rate: 0.00376613
	LOSS [training: 0.10228942182202963 | validation: 0.1215294186349376]
	TIME [epoch: 9.07 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0741820044431448		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.0741820044431448 | validation: 0.07228623388218272]
	TIME [epoch: 9.07 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07742039948029676		[learning rate: 0.0037479]
	Learning Rate: 0.00374791
	LOSS [training: 0.07742039948029676 | validation: 0.15444997283136008]
	TIME [epoch: 9.08 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16524726602521453		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.16524726602521453 | validation: 0.11066664694455601]
	TIME [epoch: 9.07 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12056165209354072		[learning rate: 0.0037298]
	Learning Rate: 0.00372979
	LOSS [training: 0.12056165209354072 | validation: 0.13198016452039468]
	TIME [epoch: 9.07 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13172197065482577		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.13172197065482577 | validation: 0.093055169414278]
	TIME [epoch: 9.07 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08386413500251613		[learning rate: 0.0037118]
	Learning Rate: 0.00371175
	LOSS [training: 0.08386413500251613 | validation: 0.06234748347265429]
	TIME [epoch: 9.07 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1026535562053374		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.1026535562053374 | validation: 0.11595746683783467]
	TIME [epoch: 9.1 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10498118450153957		[learning rate: 0.0036938]
	Learning Rate: 0.0036938
	LOSS [training: 0.10498118450153957 | validation: 0.0793750688530146]
	TIME [epoch: 9.08 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11433647807971485		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.11433647807971485 | validation: 0.11294971972190879]
	TIME [epoch: 9.07 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10860844051061194		[learning rate: 0.0036759]
	Learning Rate: 0.00367594
	LOSS [training: 0.10860844051061194 | validation: 0.08331437548589854]
	TIME [epoch: 9.08 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15329063324637288		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.15329063324637288 | validation: 0.11727216501906411]
	TIME [epoch: 9.09 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13851540386640573		[learning rate: 0.0036582]
	Learning Rate: 0.00365816
	LOSS [training: 0.13851540386640573 | validation: 0.07026130966843946]
	TIME [epoch: 9.07 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09219461750331934		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.09219461750331934 | validation: 0.11408744102925017]
	TIME [epoch: 9.08 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08709263176396471		[learning rate: 0.0036405]
	Learning Rate: 0.00364047
	LOSS [training: 0.08709263176396471 | validation: 0.12152860660607058]
	TIME [epoch: 9.07 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1536977016403009		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.1536977016403009 | validation: 0.331000378755418]
	TIME [epoch: 9.08 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19737179561263124		[learning rate: 0.0036229]
	Learning Rate: 0.00362287
	LOSS [training: 0.19737179561263124 | validation: 0.18671196677194524]
	TIME [epoch: 9.1 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2162909748793654		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.2162909748793654 | validation: 0.1449010931926038]
	TIME [epoch: 9.07 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10862903549100496		[learning rate: 0.0036053]
	Learning Rate: 0.00360535
	LOSS [training: 0.10862903549100496 | validation: 0.14874607670674012]
	TIME [epoch: 9.08 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1405847483561077		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.1405847483561077 | validation: 0.19167511295552542]
	TIME [epoch: 9.08 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16604831987266094		[learning rate: 0.0035879]
	Learning Rate: 0.00358791
	LOSS [training: 0.16604831987266094 | validation: 0.11869634410394775]
	TIME [epoch: 9.09 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12457302793213328		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.12457302793213328 | validation: 0.13613332941459516]
	TIME [epoch: 9.1 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1433732427124387		[learning rate: 0.0035706]
	Learning Rate: 0.00357056
	LOSS [training: 0.1433732427124387 | validation: 0.14947397653895347]
	TIME [epoch: 9.08 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14937027624305646		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.14937027624305646 | validation: 0.1475520955898298]
	TIME [epoch: 9.09 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11507377131411341		[learning rate: 0.0035533]
	Learning Rate: 0.0035533
	LOSS [training: 0.11507377131411341 | validation: 0.12067200589088593]
	TIME [epoch: 9.07 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13730459391797825		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.13730459391797825 | validation: 0.21681510271186755]
	TIME [epoch: 9.1 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1795681372278094		[learning rate: 0.0035361]
	Learning Rate: 0.00353611
	LOSS [training: 0.1795681372278094 | validation: 0.12244238562052823]
	TIME [epoch: 9.08 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15665312053377797		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.15665312053377797 | validation: 0.6474968669617157]
	TIME [epoch: 9.07 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44398971858738745		[learning rate: 0.003519]
	Learning Rate: 0.00351901
	LOSS [training: 0.44398971858738745 | validation: 0.3791631816545708]
	TIME [epoch: 9.08 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21609263984677965		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.21609263984677965 | validation: 0.1394660616317371]
	TIME [epoch: 9.08 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18874548500280883		[learning rate: 0.003502]
	Learning Rate: 0.003502
	LOSS [training: 0.18874548500280883 | validation: 0.10710059083015627]
	TIME [epoch: 9.09 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22913324117830602		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.22913324117830602 | validation: 0.2952804767950311]
	TIME [epoch: 9.08 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21904792803180628		[learning rate: 0.0034851]
	Learning Rate: 0.00348506
	LOSS [training: 0.21904792803180628 | validation: 0.1991314799328465]
	TIME [epoch: 9.08 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20145972743568138		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.20145972743568138 | validation: 0.08695443866013204]
	TIME [epoch: 9.08 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14229941124307094		[learning rate: 0.0034682]
	Learning Rate: 0.00346821
	LOSS [training: 0.14229941124307094 | validation: 0.08342424195964603]
	TIME [epoch: 9.1 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08018313959453834		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.08018313959453834 | validation: 0.10818158572558015]
	TIME [epoch: 9.09 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13032957932484476		[learning rate: 0.0034514]
	Learning Rate: 0.00345144
	LOSS [training: 0.13032957932484476 | validation: 0.13659090114553765]
	TIME [epoch: 9.09 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17878994331253098		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.17878994331253098 | validation: 0.15212068195132122]
	TIME [epoch: 9.07 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09685346936773195		[learning rate: 0.0034347]
	Learning Rate: 0.00343475
	LOSS [training: 0.09685346936773195 | validation: 0.07268577940035204]
	TIME [epoch: 9.08 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10490270087740709		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.10490270087740709 | validation: 0.078915544007847]
	TIME [epoch: 9.1 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06795209731587108		[learning rate: 0.0034181]
	Learning Rate: 0.00341814
	LOSS [training: 0.06795209731587108 | validation: 0.07889690935913266]
	TIME [epoch: 9.08 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14302337432708517		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.14302337432708517 | validation: 0.12962625608227696]
	TIME [epoch: 9.09 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0774547871079907		[learning rate: 0.0034016]
	Learning Rate: 0.00340161
	LOSS [training: 0.0774547871079907 | validation: 0.11880246546130852]
	TIME [epoch: 9.08 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12194151212078219		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.12194151212078219 | validation: 0.18517848832758285]
	TIME [epoch: 9.1 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1637718243267716		[learning rate: 0.0033852]
	Learning Rate: 0.00338516
	LOSS [training: 0.1637718243267716 | validation: 0.09517536191018847]
	TIME [epoch: 9.08 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11935513831133249		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.11935513831133249 | validation: 0.3338811098037028]
	TIME [epoch: 9.08 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19848046401898659		[learning rate: 0.0033688]
	Learning Rate: 0.00336879
	LOSS [training: 0.19848046401898659 | validation: 0.1377831044698382]
	TIME [epoch: 9.08 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10246440492837076		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.10246440492837076 | validation: 0.1018177539746513]
	TIME [epoch: 9.08 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1203645814985973		[learning rate: 0.0033525]
	Learning Rate: 0.0033525
	LOSS [training: 0.1203645814985973 | validation: 0.08827126513387298]
	TIME [epoch: 9.12 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08260940426622107		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.08260940426622107 | validation: 0.049322559195804354]
	TIME [epoch: 9.09 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11776935880317892		[learning rate: 0.0033363]
	Learning Rate: 0.00333629
	LOSS [training: 0.11776935880317892 | validation: 0.20804912503765527]
	TIME [epoch: 9.08 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16556590177303113		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.16556590177303113 | validation: 0.1028908588410763]
	TIME [epoch: 9.08 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08018804464476784		[learning rate: 0.0033202]
	Learning Rate: 0.00332015
	LOSS [training: 0.08018804464476784 | validation: 0.07594037160831857]
	TIME [epoch: 9.08 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10643448131189596		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.10643448131189596 | validation: 0.09664194315342654]
	TIME [epoch: 9.09 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11483521948324629		[learning rate: 0.0033041]
	Learning Rate: 0.0033041
	LOSS [training: 0.11483521948324629 | validation: 0.13485416215651214]
	TIME [epoch: 9.06 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11196943348989064		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.11196943348989064 | validation: 0.10178104095245227]
	TIME [epoch: 9.08 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11572333054438103		[learning rate: 0.0032881]
	Learning Rate: 0.00328812
	LOSS [training: 0.11572333054438103 | validation: 0.15244127434153826]
	TIME [epoch: 9.09 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13152284504842787		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.13152284504842787 | validation: 0.12380792103956717]
	TIME [epoch: 9.1 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12016763867716285		[learning rate: 0.0032722]
	Learning Rate: 0.00327222
	LOSS [training: 0.12016763867716285 | validation: 0.06895199642539726]
	TIME [epoch: 9.09 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10743639323847351		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.10743639323847351 | validation: 0.1237455086459989]
	TIME [epoch: 9.08 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10854593439784557		[learning rate: 0.0032564]
	Learning Rate: 0.00325639
	LOSS [training: 0.10854593439784557 | validation: 0.06611157595336105]
	TIME [epoch: 9.09 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0969720099962473		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.0969720099962473 | validation: 0.08849391455698431]
	TIME [epoch: 9.08 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11936195316698002		[learning rate: 0.0032406]
	Learning Rate: 0.00324065
	LOSS [training: 0.11936195316698002 | validation: 0.0787747666112934]
	TIME [epoch: 9.09 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07741412219153157		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.07741412219153157 | validation: 0.08053401138728145]
	TIME [epoch: 9.07 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15659530705975278		[learning rate: 0.003225]
	Learning Rate: 0.00322497
	LOSS [training: 0.15659530705975278 | validation: 0.08545694978126336]
	TIME [epoch: 9.08 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0877707034552908		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.0877707034552908 | validation: 0.0602797684948151]
	TIME [epoch: 9.08 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0761556981148023		[learning rate: 0.0032094]
	Learning Rate: 0.00320938
	LOSS [training: 0.0761556981148023 | validation: 0.08453782484420183]
	TIME [epoch: 9.09 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11652162521506586		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.11652162521506586 | validation: 0.08053330983859755]
	TIME [epoch: 9.06 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11185394315855979		[learning rate: 0.0031939]
	Learning Rate: 0.00319386
	LOSS [training: 0.11185394315855979 | validation: 0.1465652030220376]
	TIME [epoch: 9.08 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1355895780325454		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.1355895780325454 | validation: 0.07321098085788336]
	TIME [epoch: 9.08 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12065521497402536		[learning rate: 0.0031784]
	Learning Rate: 0.00317841
	LOSS [training: 0.12065521497402536 | validation: 0.08824005556376036]
	TIME [epoch: 9.07 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1095004362219139		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.1095004362219139 | validation: 0.08600505179017945]
	TIME [epoch: 9.1 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09274218932136936		[learning rate: 0.003163]
	Learning Rate: 0.00316304
	LOSS [training: 0.09274218932136936 | validation: 0.09167361603084094]
	TIME [epoch: 9.07 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43534266146684714		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.43534266146684714 | validation: 0.7291682041232534]
	TIME [epoch: 9.07 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3594390059731836		[learning rate: 0.0031477]
	Learning Rate: 0.00314775
	LOSS [training: 0.3594390059731836 | validation: 0.146316158181655]
	TIME [epoch: 9.08 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15996197245467547		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.15996197245467547 | validation: 0.24141217841892]
	TIME [epoch: 9.08 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35870205096010943		[learning rate: 0.0031325]
	Learning Rate: 0.00313253
	LOSS [training: 0.35870205096010943 | validation: 0.3081411050086459]
	TIME [epoch: 9.1 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24697440375193738		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.24697440375193738 | validation: 0.1675672146437811]
	TIME [epoch: 9.08 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15141190678435779		[learning rate: 0.0031174]
	Learning Rate: 0.00311738
	LOSS [training: 0.15141190678435779 | validation: 0.09704054993347215]
	TIME [epoch: 9.08 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11774464427791058		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.11774464427791058 | validation: 0.07013607671845001]
	TIME [epoch: 9.07 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09196187133194957		[learning rate: 0.0031023]
	Learning Rate: 0.0031023
	LOSS [training: 0.09196187133194957 | validation: 0.06339350082693365]
	TIME [epoch: 9.09 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08870882576839415		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.08870882576839415 | validation: 0.09483555037769743]
	TIME [epoch: 9.07 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0760085799041186		[learning rate: 0.0030873]
	Learning Rate: 0.0030873
	LOSS [training: 0.0760085799041186 | validation: 0.05467016054955963]
	TIME [epoch: 9.07 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07255110124976634		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.07255110124976634 | validation: 0.0917385216828924]
	TIME [epoch: 9.07 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06937633737032968		[learning rate: 0.0030724]
	Learning Rate: 0.00307237
	LOSS [training: 0.06937633737032968 | validation: 0.07280248561425585]
	TIME [epoch: 9.08 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07309258442249525		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.07309258442249525 | validation: 0.09288071974647263]
	TIME [epoch: 9.08 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0722128047771661		[learning rate: 0.0030575]
	Learning Rate: 0.00305751
	LOSS [training: 0.0722128047771661 | validation: 0.04310655195679322]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_589.pth
	Model improved!!!
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07581740906613024		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.07581740906613024 | validation: 0.07467639650018491]
	TIME [epoch: 9.08 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07824343217787716		[learning rate: 0.0030427]
	Learning Rate: 0.00304273
	LOSS [training: 0.07824343217787716 | validation: 0.09759629061481959]
	TIME [epoch: 9.08 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.078738195368706		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.078738195368706 | validation: 0.1146570365476415]
	TIME [epoch: 9.09 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09477530242033202		[learning rate: 0.003028]
	Learning Rate: 0.00302801
	LOSS [training: 0.09477530242033202 | validation: 0.061026493028282246]
	TIME [epoch: 9.07 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08344003431803702		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.08344003431803702 | validation: 0.1274427793947805]
	TIME [epoch: 9.07 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06579547263251947		[learning rate: 0.0030134]
	Learning Rate: 0.00301337
	LOSS [training: 0.06579547263251947 | validation: 0.05629518656607925]
	TIME [epoch: 9.06 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09881350413627353		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.09881350413627353 | validation: 0.14285761735754426]
	TIME [epoch: 9.07 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10145771689176533		[learning rate: 0.0029988]
	Learning Rate: 0.0029988
	LOSS [training: 0.10145771689176533 | validation: 0.13840311331385255]
	TIME [epoch: 9.1 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08795911130983411		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.08795911130983411 | validation: 0.07523860478776245]
	TIME [epoch: 9.07 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11778728528702179		[learning rate: 0.0029843]
	Learning Rate: 0.0029843
	LOSS [training: 0.11778728528702179 | validation: 0.40849697582728994]
	TIME [epoch: 9.07 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20788934002960788		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.20788934002960788 | validation: 0.07523079199527259]
	TIME [epoch: 9.06 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06786323876589198		[learning rate: 0.0029699]
	Learning Rate: 0.00296987
	LOSS [training: 0.06786323876589198 | validation: 0.06999174742000368]
	TIME [epoch: 9.1 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057710269085259905		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.057710269085259905 | validation: 0.0834797369239364]
	TIME [epoch: 9.08 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04096757399125243		[learning rate: 0.0029555]
	Learning Rate: 0.0029555
	LOSS [training: 0.04096757399125243 | validation: 0.0752841800675706]
	TIME [epoch: 9.08 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10529966968685925		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.10529966968685925 | validation: 0.11002264584516132]
	TIME [epoch: 9.07 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07678310094134469		[learning rate: 0.0029412]
	Learning Rate: 0.00294121
	LOSS [training: 0.07678310094134469 | validation: 0.06204572163914063]
	TIME [epoch: 9.07 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06183928961522515		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.06183928961522515 | validation: 0.06462482231588723]
	TIME [epoch: 9.09 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20353873482151474		[learning rate: 0.002927]
	Learning Rate: 0.00292699
	LOSS [training: 0.20353873482151474 | validation: 0.13838840039428918]
	TIME [epoch: 9.07 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11281834345932551		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.11281834345932551 | validation: 0.1167914591218249]
	TIME [epoch: 9.07 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09099487582242433		[learning rate: 0.0029128]
	Learning Rate: 0.00291283
	LOSS [training: 0.09099487582242433 | validation: 0.07485453551695255]
	TIME [epoch: 9.07 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07334587974737107		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.07334587974737107 | validation: 0.07701129061936116]
	TIME [epoch: 9.08 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07160013240764633		[learning rate: 0.0028987]
	Learning Rate: 0.00289875
	LOSS [training: 0.07160013240764633 | validation: 0.07772206092513334]
	TIME [epoch: 9.08 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07445070412402387		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.07445070412402387 | validation: 0.08855964657632333]
	TIME [epoch: 9.07 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09597648040982446		[learning rate: 0.0028847]
	Learning Rate: 0.00288473
	LOSS [training: 0.09597648040982446 | validation: 0.08126449410202313]
	TIME [epoch: 9.07 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08575907869713736		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.08575907869713736 | validation: 0.12155320370344708]
	TIME [epoch: 9.08 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10088187296367765		[learning rate: 0.0028708]
	Learning Rate: 0.00287078
	LOSS [training: 0.10088187296367765 | validation: 0.08823183739410204]
	TIME [epoch: 9.09 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08078792639357853		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.08078792639357853 | validation: 0.05356611516937476]
	TIME [epoch: 9.08 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06868941685963732		[learning rate: 0.0028569]
	Learning Rate: 0.0028569
	LOSS [training: 0.06868941685963732 | validation: 0.09317570405693253]
	TIME [epoch: 9.08 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06805863548816557		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.06805863548816557 | validation: 0.0781775774510525]
	TIME [epoch: 9.08 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06839324361602447		[learning rate: 0.0028431]
	Learning Rate: 0.00284308
	LOSS [training: 0.06839324361602447 | validation: 0.07764985454156553]
	TIME [epoch: 9.08 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15410684266177435		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.15410684266177435 | validation: 0.0835120999028757]
	TIME [epoch: 9.1 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0785995955871869		[learning rate: 0.0028293]
	Learning Rate: 0.00282933
	LOSS [training: 0.0785995955871869 | validation: 0.10263582515168518]
	TIME [epoch: 9.07 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0761154547541393		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.0761154547541393 | validation: 0.05545990839996212]
	TIME [epoch: 9.07 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08787636207625792		[learning rate: 0.0028157]
	Learning Rate: 0.00281565
	LOSS [training: 0.08787636207625792 | validation: 0.074155108304367]
	TIME [epoch: 9.07 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07053838665137378		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.07053838665137378 | validation: 0.049490780132111174]
	TIME [epoch: 9.09 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08539613815521832		[learning rate: 0.002802]
	Learning Rate: 0.00280204
	LOSS [training: 0.08539613815521832 | validation: 0.06707682115886512]
	TIME [epoch: 9.07 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08765254290548216		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.08765254290548216 | validation: 0.05524693696107143]
	TIME [epoch: 9.07 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07679733865662428		[learning rate: 0.0027885]
	Learning Rate: 0.00278849
	LOSS [training: 0.07679733865662428 | validation: 0.08997699816657531]
	TIME [epoch: 9.07 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08761572993597395		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.08761572993597395 | validation: 0.04773098780407557]
	TIME [epoch: 9.08 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043843035177363356		[learning rate: 0.002775]
	Learning Rate: 0.002775
	LOSS [training: 0.043843035177363356 | validation: 0.05691241660521415]
	TIME [epoch: 9.1 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1021309510546983		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.1021309510546983 | validation: 0.06868396652823922]
	TIME [epoch: 9.08 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07734079792466748		[learning rate: 0.0027616]
	Learning Rate: 0.00276158
	LOSS [training: 0.07734079792466748 | validation: 0.08481945113726251]
	TIME [epoch: 9.07 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07054779873821646		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.07054779873821646 | validation: 0.07763997624387647]
	TIME [epoch: 9.07 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1679564214214804		[learning rate: 0.0027482]
	Learning Rate: 0.00274823
	LOSS [training: 0.1679564214214804 | validation: 0.20972581849532057]
	TIME [epoch: 9.09 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16323348898014073		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.16323348898014073 | validation: 0.09470671570647582]
	TIME [epoch: 9.08 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08018136784533594		[learning rate: 0.0027349]
	Learning Rate: 0.00273494
	LOSS [training: 0.08018136784533594 | validation: 0.062036862954499006]
	TIME [epoch: 9.07 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.092582819289578		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.092582819289578 | validation: 0.1230078988236743]
	TIME [epoch: 9.07 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09429424642415314		[learning rate: 0.0027217]
	Learning Rate: 0.00272171
	LOSS [training: 0.09429424642415314 | validation: 0.11623615645255336]
	TIME [epoch: 9.08 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.162836086207602		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.162836086207602 | validation: 0.09934067900644747]
	TIME [epoch: 9.1 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05491366266187521		[learning rate: 0.0027086]
	Learning Rate: 0.00270855
	LOSS [training: 0.05491366266187521 | validation: 0.05637492910952578]
	TIME [epoch: 9.07 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11999445925247802		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.11999445925247802 | validation: 0.11398823538818034]
	TIME [epoch: 9.07 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1404143486718041		[learning rate: 0.0026955]
	Learning Rate: 0.00269545
	LOSS [training: 0.1404143486718041 | validation: 0.12789195806056555]
	TIME [epoch: 9.08 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09781039109292368		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.09781039109292368 | validation: 0.15809321259531595]
	TIME [epoch: 9.1 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11681145790033334		[learning rate: 0.0026824]
	Learning Rate: 0.00268242
	LOSS [training: 0.11681145790033334 | validation: 0.06457360554618227]
	TIME [epoch: 9.09 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.136690887718971		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.136690887718971 | validation: 0.12653544649421475]
	TIME [epoch: 9.07 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10719381400722257		[learning rate: 0.0026694]
	Learning Rate: 0.00266945
	LOSS [training: 0.10719381400722257 | validation: 0.0657303786450433]
	TIME [epoch: 9.08 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0666010807272885		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.0666010807272885 | validation: 0.07306213448762207]
	TIME [epoch: 9.06 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07163042710061007		[learning rate: 0.0026565]
	Learning Rate: 0.00265654
	LOSS [training: 0.07163042710061007 | validation: 0.0468594724917399]
	TIME [epoch: 9.09 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0541151471604705		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.0541151471604705 | validation: 0.06243466209709768]
	TIME [epoch: 9.08 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07506672045126475		[learning rate: 0.0026437]
	Learning Rate: 0.00264369
	LOSS [training: 0.07506672045126475 | validation: 0.11242727660011978]
	TIME [epoch: 9.08 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1535119633992363		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.1535119633992363 | validation: 0.5419618221222205]
	TIME [epoch: 9.07 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49177167510439074		[learning rate: 0.0026309]
	Learning Rate: 0.00263091
	LOSS [training: 0.49177167510439074 | validation: 0.09191742818380999]
	TIME [epoch: 9.09 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0898807012850775		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.0898807012850775 | validation: 0.048298310777921974]
	TIME [epoch: 9.08 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09116168956416743		[learning rate: 0.0026182]
	Learning Rate: 0.00261818
	LOSS [training: 0.09116168956416743 | validation: 0.05222199307836231]
	TIME [epoch: 9.07 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06272273313464811		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.06272273313464811 | validation: 0.06784895095784671]
	TIME [epoch: 9.08 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05137507323731988		[learning rate: 0.0026055]
	Learning Rate: 0.00260552
	LOSS [training: 0.05137507323731988 | validation: 0.07724432612996543]
	TIME [epoch: 9.07 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05336263827850649		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.05336263827850649 | validation: 0.03091097189544114]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_656.pth
	Model improved!!!
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02748026682434978		[learning rate: 0.0025929]
	Learning Rate: 0.00259292
	LOSS [training: 0.02748026682434978 | validation: 0.035992634050853324]
	TIME [epoch: 9.08 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03299392349090645		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.03299392349090645 | validation: 0.08582381312001851]
	TIME [epoch: 9.08 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05991747056160317		[learning rate: 0.0025804]
	Learning Rate: 0.00258038
	LOSS [training: 0.05991747056160317 | validation: 0.043125148632159604]
	TIME [epoch: 9.06 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05159585551434165		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.05159585551434165 | validation: 0.055641115429526294]
	TIME [epoch: 9.07 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05083218294877338		[learning rate: 0.0025679]
	Learning Rate: 0.0025679
	LOSS [training: 0.05083218294877338 | validation: 0.07202804294756318]
	TIME [epoch: 9.09 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05768467154246955		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.05768467154246955 | validation: 0.04326788386084258]
	TIME [epoch: 9.07 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048807881712463495		[learning rate: 0.0025555]
	Learning Rate: 0.00255549
	LOSS [training: 0.048807881712463495 | validation: 0.025844097383618703]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_663.pth
	Model improved!!!
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05025639305474337		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.05025639305474337 | validation: 0.03347916011878851]
	TIME [epoch: 9.08 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07914188494616509		[learning rate: 0.0025431]
	Learning Rate: 0.00254313
	LOSS [training: 0.07914188494616509 | validation: 0.08134385194691962]
	TIME [epoch: 9.1 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05663929565373634		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.05663929565373634 | validation: 0.06085469863813127]
	TIME [epoch: 9.08 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0463869988996892		[learning rate: 0.0025308]
	Learning Rate: 0.00253083
	LOSS [training: 0.0463869988996892 | validation: 0.07352378824879291]
	TIME [epoch: 9.07 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04337532210438816		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.04337532210438816 | validation: 0.06117780859842246]
	TIME [epoch: 9.07 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09898220637859338		[learning rate: 0.0025186]
	Learning Rate: 0.00251859
	LOSS [training: 0.09898220637859338 | validation: 0.08896333645128207]
	TIME [epoch: 9.08 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07160381763424335		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.07160381763424335 | validation: 0.03772045950873605]
	TIME [epoch: 9.11 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052500804657946945		[learning rate: 0.0025064]
	Learning Rate: 0.00250641
	LOSS [training: 0.052500804657946945 | validation: 0.08670299665928335]
	TIME [epoch: 9.08 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0669463595094407		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.0669463595094407 | validation: 0.14436695289945028]
	TIME [epoch: 9.08 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06897438287595674		[learning rate: 0.0024943]
	Learning Rate: 0.00249429
	LOSS [training: 0.06897438287595674 | validation: 0.05201551594951]
	TIME [epoch: 9.08 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09249354318188378		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.09249354318188378 | validation: 0.04826139120506792]
	TIME [epoch: 9.09 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04859595725839593		[learning rate: 0.0024822]
	Learning Rate: 0.00248223
	LOSS [training: 0.04859595725839593 | validation: 0.059969535701936486]
	TIME [epoch: 9.09 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06157759011836861		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.06157759011836861 | validation: 0.08111853243127776]
	TIME [epoch: 9.08 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04620841764534085		[learning rate: 0.0024702]
	Learning Rate: 0.00247023
	LOSS [training: 0.04620841764534085 | validation: 0.04420737707616432]
	TIME [epoch: 9.08 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06528690434481274		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.06528690434481274 | validation: 0.07429472254701078]
	TIME [epoch: 9.07 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0963334578183477		[learning rate: 0.0024583]
	Learning Rate: 0.00245828
	LOSS [training: 0.0963334578183477 | validation: 0.11069355286667609]
	TIME [epoch: 9.09 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08731985239390122		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.08731985239390122 | validation: 0.08005315585254444]
	TIME [epoch: 9.08 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0739302793114885		[learning rate: 0.0024464]
	Learning Rate: 0.00244639
	LOSS [training: 0.0739302793114885 | validation: 0.0962229862729082]
	TIME [epoch: 9.07 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06688242875045695		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.06688242875045695 | validation: 0.097774559720001]
	TIME [epoch: 9.08 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08131410179520071		[learning rate: 0.0024346]
	Learning Rate: 0.00243456
	LOSS [training: 0.08131410179520071 | validation: 0.10786084571592655]
	TIME [epoch: 9.1 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05439730891619441		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.05439730891619441 | validation: 0.050680244686078915]
	TIME [epoch: 9.1 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07298767300298399		[learning rate: 0.0024228]
	Learning Rate: 0.00242279
	LOSS [training: 0.07298767300298399 | validation: 0.07842576877875118]
	TIME [epoch: 9.07 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07582598187110853		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.07582598187110853 | validation: 0.20896519465713806]
	TIME [epoch: 9.08 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08224269190349803		[learning rate: 0.0024111]
	Learning Rate: 0.00241107
	LOSS [training: 0.08224269190349803 | validation: 0.06534470705106982]
	TIME [epoch: 9.07 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04770417360958865		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.04770417360958865 | validation: 0.13927511266096415]
	TIME [epoch: 9.09 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07240423566305706		[learning rate: 0.0023994]
	Learning Rate: 0.00239941
	LOSS [training: 0.07240423566305706 | validation: 0.027258496915105564]
	TIME [epoch: 9.08 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05630546725308504		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.05630546725308504 | validation: 0.06500146985624251]
	TIME [epoch: 9.07 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0521145263218743		[learning rate: 0.0023878]
	Learning Rate: 0.00238781
	LOSS [training: 0.0521145263218743 | validation: 0.08141933860751777]
	TIME [epoch: 9.08 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10398285423078413		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.10398285423078413 | validation: 0.07236410774254146]
	TIME [epoch: 9.08 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04174428337109618		[learning rate: 0.0023763]
	Learning Rate: 0.00237626
	LOSS [training: 0.04174428337109618 | validation: 0.07660886014028048]
	TIME [epoch: 9.1 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05712388904077692		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.05712388904077692 | validation: 0.040138644001690746]
	TIME [epoch: 9.08 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09576432305297208		[learning rate: 0.0023648]
	Learning Rate: 0.00236477
	LOSS [training: 0.09576432305297208 | validation: 0.05209221399867087]
	TIME [epoch: 9.08 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05154947687601387		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.05154947687601387 | validation: 0.11715126180367538]
	TIME [epoch: 9.09 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0692191248752716		[learning rate: 0.0023533]
	Learning Rate: 0.00235334
	LOSS [training: 0.0692191248752716 | validation: 0.06477505306130037]
	TIME [epoch: 9.1 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04127840587552475		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.04127840587552475 | validation: 0.10135993015238531]
	TIME [epoch: 9.07 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09135232843614464		[learning rate: 0.002342]
	Learning Rate: 0.00234196
	LOSS [training: 0.09135232843614464 | validation: 0.046062123200344696]
	TIME [epoch: 9.08 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06731276547454108		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.06731276547454108 | validation: 0.084897126249388]
	TIME [epoch: 9.08 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05648741756386373		[learning rate: 0.0023306]
	Learning Rate: 0.00233063
	LOSS [training: 0.05648741756386373 | validation: 0.05718352879526761]
	TIME [epoch: 9.07 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04956029920991839		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.04956029920991839 | validation: 0.05109367988498871]
	TIME [epoch: 9.1 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0643802928103553		[learning rate: 0.0023194]
	Learning Rate: 0.00231936
	LOSS [training: 0.0643802928103553 | validation: 0.04011707967849388]
	TIME [epoch: 9.08 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05160980851456618		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.05160980851456618 | validation: 0.04972414144402826]
	TIME [epoch: 9.08 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07734371240801348		[learning rate: 0.0023081]
	Learning Rate: 0.00230815
	LOSS [training: 0.07734371240801348 | validation: 0.07254250503232354]
	TIME [epoch: 9.07 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07631392107519862		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.07631392107519862 | validation: 0.0639126182527255]
	TIME [epoch: 9.08 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2187629056154501		[learning rate: 0.002297]
	Learning Rate: 0.00229698
	LOSS [training: 0.2187629056154501 | validation: 0.1931117665312097]
	TIME [epoch: 9.09 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1817822109219116		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.1817822109219116 | validation: 0.15604448065645993]
	TIME [epoch: 9.08 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18409866867864247		[learning rate: 0.0022859]
	Learning Rate: 0.00228588
	LOSS [training: 0.18409866867864247 | validation: 0.07280446690431427]
	TIME [epoch: 9.08 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12632884894894625		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.12632884894894625 | validation: 0.11231596483991729]
	TIME [epoch: 9.08 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2031088524132693		[learning rate: 0.0022748]
	Learning Rate: 0.00227482
	LOSS [training: 0.2031088524132693 | validation: 0.23322936853455312]
	TIME [epoch: 9.09 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15054467819033188		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.15054467819033188 | validation: 0.1014111499671903]
	TIME [epoch: 9.08 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16585966943717018		[learning rate: 0.0022638]
	Learning Rate: 0.00226382
	LOSS [training: 0.16585966943717018 | validation: 0.13389025514118402]
	TIME [epoch: 9.08 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1336151297835208		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.1336151297835208 | validation: 0.08269805843553107]
	TIME [epoch: 9.07 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07855193818484846		[learning rate: 0.0022529]
	Learning Rate: 0.00225287
	LOSS [training: 0.07855193818484846 | validation: 0.13336180890520125]
	TIME [epoch: 9.08 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11750972350859093		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.11750972350859093 | validation: 0.17365843221347532]
	TIME [epoch: 9.09 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1115116686462749		[learning rate: 0.002242]
	Learning Rate: 0.00224198
	LOSS [training: 0.1115116686462749 | validation: 0.10392034409655546]
	TIME [epoch: 9.08 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08761801483086765		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.08761801483086765 | validation: 0.0848746720444081]
	TIME [epoch: 9.08 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09767144522380403		[learning rate: 0.0022311]
	Learning Rate: 0.00223114
	LOSS [training: 0.09767144522380403 | validation: 0.07053583111501796]
	TIME [epoch: 9.08 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060453420630607047		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.060453420630607047 | validation: 0.05161111003643981]
	TIME [epoch: 9.1 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0477708480459227		[learning rate: 0.0022203]
	Learning Rate: 0.00222035
	LOSS [training: 0.0477708480459227 | validation: 0.040871109133164774]
	TIME [epoch: 9.08 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13007046631968072		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.13007046631968072 | validation: 0.28705162788931426]
	TIME [epoch: 9.08 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17431780050387047		[learning rate: 0.0022096]
	Learning Rate: 0.00220961
	LOSS [training: 0.17431780050387047 | validation: 0.10980858527651438]
	TIME [epoch: 9.08 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0887650155086042		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.0887650155086042 | validation: 0.06087467903843663]
	TIME [epoch: 9.08 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056951838403279074		[learning rate: 0.0021989]
	Learning Rate: 0.00219893
	LOSS [training: 0.056951838403279074 | validation: 0.04564866638966427]
	TIME [epoch: 9.08 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057085994418175176		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.057085994418175176 | validation: 0.039920506314098575]
	TIME [epoch: 9.08 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10217016362595337		[learning rate: 0.0021883]
	Learning Rate: 0.00218829
	LOSS [training: 0.10217016362595337 | validation: 0.07981036150913699]
	TIME [epoch: 9.08 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054031410186377214		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.054031410186377214 | validation: 0.05499414111625255]
	TIME [epoch: 9.07 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03423185601005202		[learning rate: 0.0021777]
	Learning Rate: 0.00217771
	LOSS [training: 0.03423185601005202 | validation: 0.022183076577323338]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_729.pth
	Model improved!!!
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05599646570001611		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.05599646570001611 | validation: 0.04500025505814503]
	TIME [epoch: 9.09 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05645642154579914		[learning rate: 0.0021672]
	Learning Rate: 0.00216718
	LOSS [training: 0.05645642154579914 | validation: 0.04177999435292915]
	TIME [epoch: 9.07 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032472988260460654		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.032472988260460654 | validation: 0.0399671531276254]
	TIME [epoch: 9.07 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05136352554336561		[learning rate: 0.0021567]
	Learning Rate: 0.0021567
	LOSS [training: 0.05136352554336561 | validation: 0.06729446245651757]
	TIME [epoch: 9.06 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05577554729603355		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.05577554729603355 | validation: 0.040175622718984734]
	TIME [epoch: 9.1 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04375508150842513		[learning rate: 0.0021463]
	Learning Rate: 0.00214627
	LOSS [training: 0.04375508150842513 | validation: 0.03679599287246146]
	TIME [epoch: 9.07 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06695563581675984		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.06695563581675984 | validation: 0.07098817301011968]
	TIME [epoch: 9.07 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06985574006528453		[learning rate: 0.0021359]
	Learning Rate: 0.00213589
	LOSS [training: 0.06985574006528453 | validation: 0.0513643713027471]
	TIME [epoch: 9.07 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05106802202155943		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.05106802202155943 | validation: 0.05140594189281715]
	TIME [epoch: 9.07 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043007357658740065		[learning rate: 0.0021256]
	Learning Rate: 0.00212556
	LOSS [training: 0.043007357658740065 | validation: 0.05501740896626441]
	TIME [epoch: 9.08 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05981935786467053		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.05981935786467053 | validation: 0.05704262220198472]
	TIME [epoch: 9.07 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04530478038163352		[learning rate: 0.0021153]
	Learning Rate: 0.00211528
	LOSS [training: 0.04530478038163352 | validation: 0.06415689538037397]
	TIME [epoch: 9.07 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04446193426198405		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.04446193426198405 | validation: 0.024106739007987894]
	TIME [epoch: 9.07 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05276639802910517		[learning rate: 0.0021051]
	Learning Rate: 0.00210505
	LOSS [training: 0.05276639802910517 | validation: 0.1463217308028027]
	TIME [epoch: 9.09 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07925929721573031		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.07925929721573031 | validation: 0.13494315225993084]
	TIME [epoch: 9.07 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07290171503129622		[learning rate: 0.0020949]
	Learning Rate: 0.00209487
	LOSS [training: 0.07290171503129622 | validation: 0.090851389792379]
	TIME [epoch: 9.07 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06198086613623062		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.06198086613623062 | validation: 0.08909060429533625]
	TIME [epoch: 9.06 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05110252949827274		[learning rate: 0.0020847]
	Learning Rate: 0.00208474
	LOSS [training: 0.05110252949827274 | validation: 0.03424262539872503]
	TIME [epoch: 9.07 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046843630968616365		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.046843630968616365 | validation: 0.034352906434364186]
	TIME [epoch: 9.09 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03938790198644983		[learning rate: 0.0020747]
	Learning Rate: 0.00207466
	LOSS [training: 0.03938790198644983 | validation: 0.02964314604805547]
	TIME [epoch: 9.07 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033660578502483315		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.033660578502483315 | validation: 0.05706584178985215]
	TIME [epoch: 9.08 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10553932105558579		[learning rate: 0.0020646]
	Learning Rate: 0.00206463
	LOSS [training: 0.10553932105558579 | validation: 0.05348518256620055]
	TIME [epoch: 9.06 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061489687776971745		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.061489687776971745 | validation: 0.09512344243280782]
	TIME [epoch: 9.09 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10868046655642641		[learning rate: 0.0020546]
	Learning Rate: 0.00205465
	LOSS [training: 0.10868046655642641 | validation: 0.08538294655462692]
	TIME [epoch: 9.07 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12403347290768943		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.12403347290768943 | validation: 0.12011113925384222]
	TIME [epoch: 9.07 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12356413406344258		[learning rate: 0.0020447]
	Learning Rate: 0.00204471
	LOSS [training: 0.12356413406344258 | validation: 0.09360378747093559]
	TIME [epoch: 9.06 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1141940127187668		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.1141940127187668 | validation: 0.15327792938784407]
	TIME [epoch: 9.06 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.078992236773226		[learning rate: 0.0020348]
	Learning Rate: 0.00203482
	LOSS [training: 0.078992236773226 | validation: 0.046212550393779035]
	TIME [epoch: 9.1 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04931254370299253		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.04931254370299253 | validation: 0.07871518995022919]
	TIME [epoch: 9.06 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059900204084134524		[learning rate: 0.002025]
	Learning Rate: 0.00202498
	LOSS [training: 0.059900204084134524 | validation: 0.03668420417853275]
	TIME [epoch: 9.07 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06992750763313889		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.06992750763313889 | validation: 0.04031045867505236]
	TIME [epoch: 9.06 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03274148557708291		[learning rate: 0.0020152]
	Learning Rate: 0.00201519
	LOSS [training: 0.03274148557708291 | validation: 0.031272043692604466]
	TIME [epoch: 9.07 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041333467118819155		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.041333467118819155 | validation: 0.08357936715647278]
	TIME [epoch: 9.08 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06335078146463018		[learning rate: 0.0020054]
	Learning Rate: 0.00200544
	LOSS [training: 0.06335078146463018 | validation: 0.07189969288166553]
	TIME [epoch: 9.08 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047529422160059995		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.047529422160059995 | validation: 0.05193191104716843]
	TIME [epoch: 9.07 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04005836753093995		[learning rate: 0.0019957]
	Learning Rate: 0.00199575
	LOSS [training: 0.04005836753093995 | validation: 0.06465561534736514]
	TIME [epoch: 9.06 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04525600107020013		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.04525600107020013 | validation: 0.044530349773540104]
	TIME [epoch: 9.09 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038261570205352556		[learning rate: 0.0019861]
	Learning Rate: 0.00198609
	LOSS [training: 0.038261570205352556 | validation: 0.028679095939381102]
	TIME [epoch: 9.07 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025154766668200206		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.025154766668200206 | validation: 0.03206053903964885]
	TIME [epoch: 9.06 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05611943436820688		[learning rate: 0.0019765]
	Learning Rate: 0.00197649
	LOSS [training: 0.05611943436820688 | validation: 0.03604365187548961]
	TIME [epoch: 9.06 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0560162999925418		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.0560162999925418 | validation: 0.0450860681990162]
	TIME [epoch: 9.08 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04302438564862786		[learning rate: 0.0019669]
	Learning Rate: 0.00196693
	LOSS [training: 0.04302438564862786 | validation: 0.0514419094788804]
	TIME [epoch: 9.08 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04545954771994981		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.04545954771994981 | validation: 0.03854186090475691]
	TIME [epoch: 9.07 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04409531957357912		[learning rate: 0.0019574]
	Learning Rate: 0.00195742
	LOSS [training: 0.04409531957357912 | validation: 0.042133107747351434]
	TIME [epoch: 9.07 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051510606547696326		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.051510606547696326 | validation: 0.055428475669831355]
	TIME [epoch: 9.07 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05306369434546597		[learning rate: 0.001948]
	Learning Rate: 0.00194796
	LOSS [training: 0.05306369434546597 | validation: 0.03672482786031039]
	TIME [epoch: 9.08 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04232969051008082		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.04232969051008082 | validation: 0.061099472061479636]
	TIME [epoch: 9.07 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043174427684989865		[learning rate: 0.0019385]
	Learning Rate: 0.00193854
	LOSS [training: 0.043174427684989865 | validation: 0.04517382271492563]
	TIME [epoch: 9.07 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053011913155081615		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.053011913155081615 | validation: 0.030237020360450603]
	TIME [epoch: 9.07 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040120938057106155		[learning rate: 0.0019292]
	Learning Rate: 0.00192916
	LOSS [training: 0.040120938057106155 | validation: 0.05084728114289101]
	TIME [epoch: 9.08 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0633048440282434		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.0633048440282434 | validation: 0.17053306310516114]
	TIME [epoch: 9.09 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06380800429452065		[learning rate: 0.0019198]
	Learning Rate: 0.00191983
	LOSS [training: 0.06380800429452065 | validation: 0.049602493779392076]
	TIME [epoch: 9.06 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06651746808588657		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.06651746808588657 | validation: 0.046980337481056705]
	TIME [epoch: 9.07 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03156961638551009		[learning rate: 0.0019105]
	Learning Rate: 0.00191055
	LOSS [training: 0.03156961638551009 | validation: 0.04364412580725252]
	TIME [epoch: 9.07 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024677902496194386		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.024677902496194386 | validation: 0.025403877810966438]
	TIME [epoch: 9.09 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03378132709550895		[learning rate: 0.0019013]
	Learning Rate: 0.00190131
	LOSS [training: 0.03378132709550895 | validation: 0.03401018294857128]
	TIME [epoch: 9.07 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.071552004035659		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.071552004035659 | validation: 0.10815928596375028]
	TIME [epoch: 9.07 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05763422290497262		[learning rate: 0.0018921]
	Learning Rate: 0.00189211
	LOSS [training: 0.05763422290497262 | validation: 0.08344168238167224]
	TIME [epoch: 9.07 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044897262753891845		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.044897262753891845 | validation: 0.04598148338409714]
	TIME [epoch: 9.08 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04315397643025381		[learning rate: 0.001883]
	Learning Rate: 0.00188296
	LOSS [training: 0.04315397643025381 | validation: 0.06890125800698625]
	TIME [epoch: 9.1 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059742150507848604		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.059742150507848604 | validation: 0.06189776369800598]
	TIME [epoch: 9.07 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06093919283227035		[learning rate: 0.0018739]
	Learning Rate: 0.00187386
	LOSS [training: 0.06093919283227035 | validation: 0.05687757856731068]
	TIME [epoch: 9.08 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035415829029124726		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.035415829029124726 | validation: 0.04479947684545444]
	TIME [epoch: 9.07 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04358513656383522		[learning rate: 0.0018648]
	Learning Rate: 0.0018648
	LOSS [training: 0.04358513656383522 | validation: 0.05945669220607068]
	TIME [epoch: 9.08 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046687895388433556		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.046687895388433556 | validation: 0.05671854504593443]
	TIME [epoch: 9.08 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055760898749723585		[learning rate: 0.0018558]
	Learning Rate: 0.00185578
	LOSS [training: 0.055760898749723585 | validation: 0.1266416547529863]
	TIME [epoch: 9.08 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08086408352064792		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.08086408352064792 | validation: 0.020774573737541956]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_796.pth
	Model improved!!!
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0362622662871873		[learning rate: 0.0018468]
	Learning Rate: 0.0018468
	LOSS [training: 0.0362622662871873 | validation: 0.040438239680129745]
	TIME [epoch: 9.09 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03319286412129263		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.03319286412129263 | validation: 0.025988277095809458]
	TIME [epoch: 9.1 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12293805197507116		[learning rate: 0.0018379]
	Learning Rate: 0.00183787
	LOSS [training: 0.12293805197507116 | validation: 0.07567493347642658]
	TIME [epoch: 9.08 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06598561511979985		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.06598561511979985 | validation: 0.03355958725351432]
	TIME [epoch: 9.08 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05086468281580238		[learning rate: 0.001829]
	Learning Rate: 0.00182899
	LOSS [training: 0.05086468281580238 | validation: 0.052943158982818136]
	TIME [epoch: 9.08 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07175063867610094		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.07175063867610094 | validation: 0.15610053102082969]
	TIME [epoch: 9.09 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0975356721947109		[learning rate: 0.0018201]
	Learning Rate: 0.00182014
	LOSS [training: 0.0975356721947109 | validation: 0.04496911665779218]
	TIME [epoch: 9.09 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20541375328461053		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.20541375328461053 | validation: 0.38134552773862485]
	TIME [epoch: 9.08 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25275206538848904		[learning rate: 0.0018113]
	Learning Rate: 0.00181134
	LOSS [training: 0.25275206538848904 | validation: 0.1712904982516526]
	TIME [epoch: 9.07 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11666983230428592		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.11666983230428592 | validation: 0.07839971851860668]
	TIME [epoch: 9.08 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10926168830291967		[learning rate: 0.0018026]
	Learning Rate: 0.00180258
	LOSS [training: 0.10926168830291967 | validation: 0.13032979054531976]
	TIME [epoch: 9.09 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19993857275632085		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.19993857275632085 | validation: 0.2781402005753061]
	TIME [epoch: 9.08 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2867959891375977		[learning rate: 0.0017939]
	Learning Rate: 0.00179386
	LOSS [training: 0.2867959891375977 | validation: 0.1382384185127451]
	TIME [epoch: 9.07 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19560027852717501		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.19560027852717501 | validation: 0.148555654954182]
	TIME [epoch: 9.08 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16991109793769005		[learning rate: 0.0017852]
	Learning Rate: 0.00178519
	LOSS [training: 0.16991109793769005 | validation: 0.25712878482412405]
	TIME [epoch: 9.08 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2614073007989555		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.2614073007989555 | validation: 0.11840300004461832]
	TIME [epoch: 9.09 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13117078938664217		[learning rate: 0.0017766]
	Learning Rate: 0.00177656
	LOSS [training: 0.13117078938664217 | validation: 0.14374530332498497]
	TIME [epoch: 9.08 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08490021744676972		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.08490021744676972 | validation: 0.050903242482135624]
	TIME [epoch: 9.08 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08417139896634829		[learning rate: 0.001768]
	Learning Rate: 0.00176797
	LOSS [training: 0.08417139896634829 | validation: 0.06593823545559105]
	TIME [epoch: 9.08 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08611580848065956		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.08611580848065956 | validation: 0.18840207039206341]
	TIME [epoch: 9.1 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1932353417685492		[learning rate: 0.0017594]
	Learning Rate: 0.00175942
	LOSS [training: 0.1932353417685492 | validation: 0.131291621425541]
	TIME [epoch: 9.08 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15301720223153598		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.15301720223153598 | validation: 0.2845401479056129]
	TIME [epoch: 9.08 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1434365835760702		[learning rate: 0.0017509]
	Learning Rate: 0.00175091
	LOSS [training: 0.1434365835760702 | validation: 0.05954570604978918]
	TIME [epoch: 9.08 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06934156841608727		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.06934156841608727 | validation: 0.07455332495694503]
	TIME [epoch: 9.07 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06409066751987588		[learning rate: 0.0017424]
	Learning Rate: 0.00174244
	LOSS [training: 0.06409066751987588 | validation: 0.10456535555651808]
	TIME [epoch: 9.1 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06601660443126735		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.06601660443126735 | validation: 0.06787878048531386]
	TIME [epoch: 9.08 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07532203350218847		[learning rate: 0.001734]
	Learning Rate: 0.00173401
	LOSS [training: 0.07532203350218847 | validation: 0.066510087440436]
	TIME [epoch: 9.08 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061861398195966436		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.061861398195966436 | validation: 0.0638607071706998]
	TIME [epoch: 9.07 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07023800590794163		[learning rate: 0.0017256]
	Learning Rate: 0.00172563
	LOSS [training: 0.07023800590794163 | validation: 0.07543490571285204]
	TIME [epoch: 9.08 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08048175613828942		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.08048175613828942 | validation: 0.08979339769886925]
	TIME [epoch: 9.09 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05811771270304269		[learning rate: 0.0017173]
	Learning Rate: 0.00171728
	LOSS [training: 0.05811771270304269 | validation: 0.044260452072218154]
	TIME [epoch: 9.08 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04364784816998919		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.04364784816998919 | validation: 0.07942680194545756]
	TIME [epoch: 9.09 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07850858793348965		[learning rate: 0.001709]
	Learning Rate: 0.00170898
	LOSS [training: 0.07850858793348965 | validation: 0.07313106124930169]
	TIME [epoch: 9.08 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0576664677173366		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.0576664677173366 | validation: 0.03707880544782053]
	TIME [epoch: 9.1 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04680563442542156		[learning rate: 0.0017007]
	Learning Rate: 0.00170072
	LOSS [training: 0.04680563442542156 | validation: 0.04430610369356971]
	TIME [epoch: 9.09 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06226430596312377		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.06226430596312377 | validation: 0.03615804305229112]
	TIME [epoch: 9.08 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039651431094267574		[learning rate: 0.0016925]
	Learning Rate: 0.00169249
	LOSS [training: 0.039651431094267574 | validation: 0.043163303996649666]
	TIME [epoch: 9.08 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04607908395960207		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.04607908395960207 | validation: 0.061088165319764944]
	TIME [epoch: 9.09 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06079779703840538		[learning rate: 0.0016843]
	Learning Rate: 0.00168431
	LOSS [training: 0.06079779703840538 | validation: 0.04995144383645281]
	TIME [epoch: 9.09 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07752842749890522		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.07752842749890522 | validation: 0.08048097272537227]
	TIME [epoch: 9.08 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06165049403463483		[learning rate: 0.0016762]
	Learning Rate: 0.00167616
	LOSS [training: 0.06165049403463483 | validation: 0.1341163971804301]
	TIME [epoch: 9.08 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08396882858030295		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.08396882858030295 | validation: 0.06887559784708092]
	TIME [epoch: 9.08 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03793674350515815		[learning rate: 0.0016681]
	Learning Rate: 0.00166806
	LOSS [training: 0.03793674350515815 | validation: 0.04071411007229504]
	TIME [epoch: 9.1 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03871013024416501		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.03871013024416501 | validation: 0.03828594552339061]
	TIME [epoch: 9.08 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04728484806488298		[learning rate: 0.00166]
	Learning Rate: 0.00165999
	LOSS [training: 0.04728484806488298 | validation: 0.042519049711874174]
	TIME [epoch: 9.08 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049672613222996494		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.049672613222996494 | validation: 0.04067747066871813]
	TIME [epoch: 9.08 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04250780914478899		[learning rate: 0.001652]
	Learning Rate: 0.00165196
	LOSS [training: 0.04250780914478899 | validation: 0.04372640836440334]
	TIME [epoch: 9.08 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04239231075380316		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.04239231075380316 | validation: 0.06200988808774006]
	TIME [epoch: 9.1 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05800939425320615		[learning rate: 0.001644]
	Learning Rate: 0.00164397
	LOSS [training: 0.05800939425320615 | validation: 0.05292950217574429]
	TIME [epoch: 9.08 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057027366939332615		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.057027366939332615 | validation: 0.051991355507168206]
	TIME [epoch: 9.08 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056673158412794335		[learning rate: 0.001636]
	Learning Rate: 0.00163602
	LOSS [training: 0.056673158412794335 | validation: 0.059525154593732255]
	TIME [epoch: 9.07 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06801382405342343		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.06801382405342343 | validation: 0.062054824846568615]
	TIME [epoch: 9.1 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044556119479661795		[learning rate: 0.0016281]
	Learning Rate: 0.00162811
	LOSS [training: 0.044556119479661795 | validation: 0.030865208035789748]
	TIME [epoch: 9.09 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0651302541714499		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.0651302541714499 | validation: 0.0713104697018914]
	TIME [epoch: 9.1 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05307875153123861		[learning rate: 0.0016202]
	Learning Rate: 0.00162024
	LOSS [training: 0.05307875153123861 | validation: 0.05268946225991207]
	TIME [epoch: 9.08 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07226696823956352		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.07226696823956352 | validation: 0.040044477402315065]
	TIME [epoch: 9.08 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03273084177939524		[learning rate: 0.0016124]
	Learning Rate: 0.0016124
	LOSS [training: 0.03273084177939524 | validation: 0.04323330100606606]
	TIME [epoch: 9.1 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0876769948417005		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.0876769948417005 | validation: 0.14441081929911403]
	TIME [epoch: 9.07 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06393933995003198		[learning rate: 0.0016046]
	Learning Rate: 0.00160461
	LOSS [training: 0.06393933995003198 | validation: 0.03776644637879547]
	TIME [epoch: 9.08 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03868842252644968		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.03868842252644968 | validation: 0.040233480719585706]
	TIME [epoch: 9.08 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03879989817542981		[learning rate: 0.0015968]
	Learning Rate: 0.00159685
	LOSS [training: 0.03879989817542981 | validation: 0.05941912089849036]
	TIME [epoch: 9.08 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03567398501649719		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.03567398501649719 | validation: 0.027546481299113773]
	TIME [epoch: 9.09 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035972892519913494		[learning rate: 0.0015891]
	Learning Rate: 0.00158912
	LOSS [training: 0.035972892519913494 | validation: 0.0392107986933395]
	TIME [epoch: 9.08 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053283596035008006		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.053283596035008006 | validation: 0.11958027053865039]
	TIME [epoch: 9.08 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07568077674900013		[learning rate: 0.0015814]
	Learning Rate: 0.00158144
	LOSS [training: 0.07568077674900013 | validation: 0.11794470414348682]
	TIME [epoch: 9.08 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.068347969563344		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.068347969563344 | validation: 0.05669068923134381]
	TIME [epoch: 9.1 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14698961293816457		[learning rate: 0.0015738]
	Learning Rate: 0.00157379
	LOSS [training: 0.14698961293816457 | validation: 0.10083293611148689]
	TIME [epoch: 9.08 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05330950871398443		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.05330950871398443 | validation: 0.027733974312235406]
	TIME [epoch: 9.08 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025497939421845233		[learning rate: 0.0015662]
	Learning Rate: 0.00156618
	LOSS [training: 0.025497939421845233 | validation: 0.03892382351046162]
	TIME [epoch: 9.08 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023487466702701482		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.023487466702701482 | validation: 0.04986427989738501]
	TIME [epoch: 9.09 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02995259789025364		[learning rate: 0.0015586]
	Learning Rate: 0.00155861
	LOSS [training: 0.02995259789025364 | validation: 0.015264156018755413]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_867.pth
	Model improved!!!
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03629780808365424		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.03629780808365424 | validation: 0.08778608872482507]
	TIME [epoch: 9.09 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05666740432879436		[learning rate: 0.0015511]
	Learning Rate: 0.00155107
	LOSS [training: 0.05666740432879436 | validation: 0.05344089452861349]
	TIME [epoch: 9.08 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041939062281632494		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.041939062281632494 | validation: 0.02918954946869547]
	TIME [epoch: 9.07 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035917786810433276		[learning rate: 0.0015436]
	Learning Rate: 0.00154357
	LOSS [training: 0.035917786810433276 | validation: 0.04465963310235478]
	TIME [epoch: 9.09 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03824053630915569		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.03824053630915569 | validation: 0.030044982737336044]
	TIME [epoch: 9.08 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057508854774161046		[learning rate: 0.0015361]
	Learning Rate: 0.00153611
	LOSS [training: 0.057508854774161046 | validation: 0.05242702834483347]
	TIME [epoch: 9.08 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07634849325974574		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.07634849325974574 | validation: 0.09249462909731346]
	TIME [epoch: 9.08 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07997366969986183		[learning rate: 0.0015287]
	Learning Rate: 0.00152868
	LOSS [training: 0.07997366969986183 | validation: 0.0497171600069124]
	TIME [epoch: 9.08 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06416071305969942		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.06416071305969942 | validation: 0.04128965945786705]
	TIME [epoch: 9.09 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054684408815010375		[learning rate: 0.0015213]
	Learning Rate: 0.00152128
	LOSS [training: 0.054684408815010375 | validation: 0.11112584466408926]
	TIME [epoch: 9.08 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07071641079779131		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.07071641079779131 | validation: 0.03761647281571158]
	TIME [epoch: 9.07 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05373395275061488		[learning rate: 0.0015139]
	Learning Rate: 0.00151393
	LOSS [training: 0.05373395275061488 | validation: 0.04303671519065882]
	TIME [epoch: 9.08 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057792944833105084		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.057792944833105084 | validation: 0.060158013241945765]
	TIME [epoch: 9.1 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06082370720037853		[learning rate: 0.0015066]
	Learning Rate: 0.00150661
	LOSS [training: 0.06082370720037853 | validation: 0.049931553020414715]
	TIME [epoch: 9.09 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05643985212955464		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.05643985212955464 | validation: 0.05773300943082817]
	TIME [epoch: 9.08 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054044983725546114		[learning rate: 0.0014993]
	Learning Rate: 0.00149932
	LOSS [training: 0.054044983725546114 | validation: 0.0477035383021882]
	TIME [epoch: 9.08 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03628002464206065		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.03628002464206065 | validation: 0.051694950148101174]
	TIME [epoch: 9.08 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03511651750690174		[learning rate: 0.0014921]
	Learning Rate: 0.00149207
	LOSS [training: 0.03511651750690174 | validation: 0.04042805675784619]
	TIME [epoch: 9.1 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03619656273384898		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.03619656273384898 | validation: 0.047369020518102406]
	TIME [epoch: 9.07 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05079538101558319		[learning rate: 0.0014849]
	Learning Rate: 0.00148486
	LOSS [training: 0.05079538101558319 | validation: 0.057567478715047166]
	TIME [epoch: 9.08 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04635107064106969		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.04635107064106969 | validation: 0.0373739911129784]
	TIME [epoch: 9.08 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0540313434395651		[learning rate: 0.0014777]
	Learning Rate: 0.00147768
	LOSS [training: 0.0540313434395651 | validation: 0.0740764745730132]
	TIME [epoch: 9.08 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046948876515662756		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.046948876515662756 | validation: 0.039918467146370255]
	TIME [epoch: 9.09 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04802540737552804		[learning rate: 0.0014705]
	Learning Rate: 0.00147053
	LOSS [training: 0.04802540737552804 | validation: 0.0461115910013464]
	TIME [epoch: 9.08 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0575007291549958		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.0575007291549958 | validation: 0.10749644218531032]
	TIME [epoch: 9.08 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06773338959109182		[learning rate: 0.0014634]
	Learning Rate: 0.00146342
	LOSS [training: 0.06773338959109182 | validation: 0.05954391229985531]
	TIME [epoch: 9.08 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06140918218870082		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.06140918218870082 | validation: 0.04872085246510323]
	TIME [epoch: 9.1 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052211859379803674		[learning rate: 0.0014563]
	Learning Rate: 0.00145634
	LOSS [training: 0.052211859379803674 | validation: 0.04529717584360736]
	TIME [epoch: 9.08 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04298983207769539		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.04298983207769539 | validation: 0.035229812075143224]
	TIME [epoch: 9.07 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03384570854713219		[learning rate: 0.0014493]
	Learning Rate: 0.0014493
	LOSS [training: 0.03384570854713219 | validation: 0.027453077781976518]
	TIME [epoch: 9.08 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04450449897652357		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.04450449897652357 | validation: 0.0428111540185254]
	TIME [epoch: 9.08 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034374992076962076		[learning rate: 0.0014423]
	Learning Rate: 0.00144229
	LOSS [training: 0.034374992076962076 | validation: 0.03768696273369497]
	TIME [epoch: 9.09 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04919756756237244		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.04919756756237244 | validation: 0.04834592044970531]
	TIME [epoch: 9.08 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03726068866722636		[learning rate: 0.0014353]
	Learning Rate: 0.00143532
	LOSS [training: 0.03726068866722636 | validation: 0.0566733664683902]
	TIME [epoch: 9.08 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08523233438807074		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.08523233438807074 | validation: 0.09018732321812178]
	TIME [epoch: 9.08 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06407050394396849		[learning rate: 0.0014284]
	Learning Rate: 0.00142837
	LOSS [training: 0.06407050394396849 | validation: 0.04820361373793622]
	TIME [epoch: 9.1 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0539722904629333		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.0539722904629333 | validation: 0.045613047397765345]
	TIME [epoch: 9.08 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046453598279783695		[learning rate: 0.0014215]
	Learning Rate: 0.00142147
	LOSS [training: 0.046453598279783695 | validation: 0.03981158690113641]
	TIME [epoch: 9.09 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0381766538077503		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.0381766538077503 | validation: 0.05732140265450372]
	TIME [epoch: 9.08 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04039478704013963		[learning rate: 0.0014146]
	Learning Rate: 0.00141459
	LOSS [training: 0.04039478704013963 | validation: 0.05292397511783572]
	TIME [epoch: 9.09 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031967592423385975		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.031967592423385975 | validation: 0.03671187005616602]
	TIME [epoch: 9.1 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04712713950567132		[learning rate: 0.0014078]
	Learning Rate: 0.00140775
	LOSS [training: 0.04712713950567132 | validation: 0.045370912768755434]
	TIME [epoch: 9.07 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03895489471345663		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.03895489471345663 | validation: 0.05254166480634199]
	TIME [epoch: 9.08 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04164532199464224		[learning rate: 0.0014009]
	Learning Rate: 0.00140094
	LOSS [training: 0.04164532199464224 | validation: 0.04963099746891001]
	TIME [epoch: 9.08 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03217601351241748		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.03217601351241748 | validation: 0.03713335109998635]
	TIME [epoch: 9.1 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022323480587794632		[learning rate: 0.0013942]
	Learning Rate: 0.00139417
	LOSS [training: 0.022323480587794632 | validation: 0.026287564356745438]
	TIME [epoch: 9.08 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043530179366618585		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.043530179366618585 | validation: 0.029853211794303294]
	TIME [epoch: 9.08 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03815202479747078		[learning rate: 0.0013874]
	Learning Rate: 0.00138743
	LOSS [training: 0.03815202479747078 | validation: 0.02491802244297605]
	TIME [epoch: 9.08 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04205733397190896		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.04205733397190896 | validation: 0.041746329467305235]
	TIME [epoch: 9.08 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030153806451848675		[learning rate: 0.0013807]
	Learning Rate: 0.00138072
	LOSS [training: 0.030153806451848675 | validation: 0.0460872729119977]
	TIME [epoch: 9.1 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07034158070351375		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.07034158070351375 | validation: 0.0656740644897333]
	TIME [epoch: 9.09 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04845194749524895		[learning rate: 0.001374]
	Learning Rate: 0.00137404
	LOSS [training: 0.04845194749524895 | validation: 0.05095579491366442]
	TIME [epoch: 9.08 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07252708268474886		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.07252708268474886 | validation: 0.08647466499888792]
	TIME [epoch: 9.08 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06586575551171052		[learning rate: 0.0013674]
	Learning Rate: 0.0013674
	LOSS [training: 0.06586575551171052 | validation: 0.049981778149675166]
	TIME [epoch: 9.08 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05681530474426336		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.05681530474426336 | validation: 0.054534543168172064]
	TIME [epoch: 9.09 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04229326788844769		[learning rate: 0.0013608]
	Learning Rate: 0.00136078
	LOSS [training: 0.04229326788844769 | validation: 0.04761004841458899]
	TIME [epoch: 9.07 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043749196007783105		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.043749196007783105 | validation: 0.05100679983761609]
	TIME [epoch: 9.07 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04254110966667263		[learning rate: 0.0013542]
	Learning Rate: 0.0013542
	LOSS [training: 0.04254110966667263 | validation: 0.05136790746550574]
	TIME [epoch: 9.08 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03873640992674465		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.03873640992674465 | validation: 0.053360576488105396]
	TIME [epoch: 9.09 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04982485560545633		[learning rate: 0.0013477]
	Learning Rate: 0.00134766
	LOSS [training: 0.04982485560545633 | validation: 0.04611073428319647]
	TIME [epoch: 9.08 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031601152768436586		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.031601152768436586 | validation: 0.03512034970749178]
	TIME [epoch: 9.08 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027418593278160007		[learning rate: 0.0013411]
	Learning Rate: 0.00134114
	LOSS [training: 0.027418593278160007 | validation: 0.04007267363115925]
	TIME [epoch: 9.07 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023620777540483202		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.023620777540483202 | validation: 0.0330464851397651]
	TIME [epoch: 9.09 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03501536114421598		[learning rate: 0.0013347]
	Learning Rate: 0.00133465
	LOSS [training: 0.03501536114421598 | validation: 0.03902773439088812]
	TIME [epoch: 9.09 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03950547931353292		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.03950547931353292 | validation: 0.036956835110748994]
	TIME [epoch: 9.08 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042961449978401914		[learning rate: 0.0013282]
	Learning Rate: 0.0013282
	LOSS [training: 0.042961449978401914 | validation: 0.04784435863590248]
	TIME [epoch: 9.08 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0355643938408257		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.0355643938408257 | validation: 0.04354229283077281]
	TIME [epoch: 9.08 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03520884063621684		[learning rate: 0.0013218]
	Learning Rate: 0.00132178
	LOSS [training: 0.03520884063621684 | validation: 0.04496345150739845]
	TIME [epoch: 9.11 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039109074707853506		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.039109074707853506 | validation: 0.06547949369857464]
	TIME [epoch: 9.08 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05560460246567689		[learning rate: 0.0013154]
	Learning Rate: 0.00131538
	LOSS [training: 0.05560460246567689 | validation: 0.06697444864399318]
	TIME [epoch: 9.07 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07018078417283394		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.07018078417283394 | validation: 0.08429269044792267]
	TIME [epoch: 9.08 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08969343735929444		[learning rate: 0.001309]
	Learning Rate: 0.00130902
	LOSS [training: 0.08969343735929444 | validation: 0.042416155058534286]
	TIME [epoch: 9.08 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06342498337993183		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.06342498337993183 | validation: 0.2009303727573452]
	TIME [epoch: 9.1 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17303170403078488		[learning rate: 0.0013027]
	Learning Rate: 0.00130269
	LOSS [training: 0.17303170403078488 | validation: 0.05537241441802383]
	TIME [epoch: 9.08 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04686204241967591		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.04686204241967591 | validation: 0.0632593593375185]
	TIME [epoch: 9.07 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05990926161581309		[learning rate: 0.0012964]
	Learning Rate: 0.00129639
	LOSS [training: 0.05990926161581309 | validation: 0.13568457896522226]
	TIME [epoch: 9.08 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09076754643514412		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.09076754643514412 | validation: 0.0513193457317523]
	TIME [epoch: 9.08 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06139046935968222		[learning rate: 0.0012901]
	Learning Rate: 0.00129012
	LOSS [training: 0.06139046935968222 | validation: 0.06906419885794449]
	TIME [epoch: 9.09 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07066471073122267		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.07066471073122267 | validation: 0.10134936197837338]
	TIME [epoch: 9.08 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05012769463590011		[learning rate: 0.0012839]
	Learning Rate: 0.00128389
	LOSS [training: 0.05012769463590011 | validation: 0.035047292179178645]
	TIME [epoch: 9.08 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0452295676470006		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.0452295676470006 | validation: 0.06881779166752586]
	TIME [epoch: 9.08 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05729457731821237		[learning rate: 0.0012777]
	Learning Rate: 0.00127768
	LOSS [training: 0.05729457731821237 | validation: 0.07462944122348711]
	TIME [epoch: 9.1 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06601643616604612		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.06601643616604612 | validation: 0.07502897568281489]
	TIME [epoch: 9.07 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09322285571120772		[learning rate: 0.0012715]
	Learning Rate: 0.0012715
	LOSS [training: 0.09322285571120772 | validation: 0.06289010019901134]
	TIME [epoch: 9.07 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05617837154210934		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.05617837154210934 | validation: 0.06308253835619593]
	TIME [epoch: 9.07 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1217122114329057		[learning rate: 0.0012653]
	Learning Rate: 0.00126535
	LOSS [training: 0.1217122114329057 | validation: 0.19425728281403373]
	TIME [epoch: 9.08 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21715702418509658		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.21715702418509658 | validation: 0.11704613284115792]
	TIME [epoch: 9.08 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14818848571759974		[learning rate: 0.0012592]
	Learning Rate: 0.00125923
	LOSS [training: 0.14818848571759974 | validation: 0.18220520277261715]
	TIME [epoch: 9.07 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3208180823282425		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.3208180823282425 | validation: 0.3500302830961322]
	TIME [epoch: 9.08 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2620543247793635		[learning rate: 0.0012531]
	Learning Rate: 0.00125314
	LOSS [training: 0.2620543247793635 | validation: 0.10626223800926488]
	TIME [epoch: 9.07 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1145271410103644		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.1145271410103644 | validation: 0.13692073325338341]
	TIME [epoch: 9.09 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16991272559760726		[learning rate: 0.0012471]
	Learning Rate: 0.00124708
	LOSS [training: 0.16991272559760726 | validation: 0.10696745045876968]
	TIME [epoch: 9.07 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12362238460347072		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.12362238460347072 | validation: 0.14153336775825343]
	TIME [epoch: 9.07 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3883961974536894		[learning rate: 0.0012411]
	Learning Rate: 0.00124105
	LOSS [training: 0.3883961974536894 | validation: 0.15326019231328886]
	TIME [epoch: 9.07 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10632619861211864		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.10632619861211864 | validation: 0.054535739651980567]
	TIME [epoch: 9.07 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10740776609475873		[learning rate: 0.001235]
	Learning Rate: 0.00123505
	LOSS [training: 0.10740776609475873 | validation: 0.09011751450583763]
	TIME [epoch: 9.1 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06225439254794178		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.06225439254794178 | validation: 0.04821721188553666]
	TIME [epoch: 9.08 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06142015598289914		[learning rate: 0.0012291]
	Learning Rate: 0.00122908
	LOSS [training: 0.06142015598289914 | validation: 0.10214412931499828]
	TIME [epoch: 9.07 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12176638507621682		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.12176638507621682 | validation: 0.1003981399556652]
	TIME [epoch: 9.08 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11524215103150126		[learning rate: 0.0012231]
	Learning Rate: 0.00122313
	LOSS [training: 0.11524215103150126 | validation: 0.10884836966896907]
	TIME [epoch: 9.09 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06791958195363328		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.06791958195363328 | validation: 0.07691902977342271]
	TIME [epoch: 9.08 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054418461310169995		[learning rate: 0.0012172]
	Learning Rate: 0.00121722
	LOSS [training: 0.054418461310169995 | validation: 0.07445535118104353]
	TIME [epoch: 9.08 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06561082614862049		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.06561082614862049 | validation: 0.09072161011481032]
	TIME [epoch: 9.07 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06379361124871157		[learning rate: 0.0012113]
	Learning Rate: 0.00121133
	LOSS [training: 0.06379361124871157 | validation: 0.08323710486105473]
	TIME [epoch: 9.08 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1016403022943519		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.1016403022943519 | validation: 0.15473053892857408]
	TIME [epoch: 9.1 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15596783055334806		[learning rate: 0.0012055]
	Learning Rate: 0.00120547
	LOSS [training: 0.15596783055334806 | validation: 0.19035046021875301]
	TIME [epoch: 9.07 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16833630652261664		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.16833630652261664 | validation: 0.1418475530181587]
	TIME [epoch: 9.08 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15866670733121993		[learning rate: 0.0011996]
	Learning Rate: 0.00119964
	LOSS [training: 0.15866670733121993 | validation: 0.2461351426385906]
	TIME [epoch: 9.07 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2103257902328158		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.2103257902328158 | validation: 0.24450284862815763]
	TIME [epoch: 9.09 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15250972592511783		[learning rate: 0.0011938]
	Learning Rate: 0.00119384
	LOSS [training: 0.15250972592511783 | validation: 0.14604068428737071]
	TIME [epoch: 9.08 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1222487933909435		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.1222487933909435 | validation: 0.10249690819483712]
	TIME [epoch: 9.08 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0885739969091657		[learning rate: 0.0011881]
	Learning Rate: 0.00118807
	LOSS [training: 0.0885739969091657 | validation: 0.09325207788332325]
	TIME [epoch: 9.08 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11058372620002772		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.11058372620002772 | validation: 0.11577237641170243]
	TIME [epoch: 9.07 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0828675558019668		[learning rate: 0.0011823]
	Learning Rate: 0.00118232
	LOSS [training: 0.0828675558019668 | validation: 0.08023832846984028]
	TIME [epoch: 9.1 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1070620079169882		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.1070620079169882 | validation: 0.07620973749486123]
	TIME [epoch: 9.08 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06338675973500515		[learning rate: 0.0011766]
	Learning Rate: 0.00117661
	LOSS [training: 0.06338675973500515 | validation: 0.0688721684737768]
	TIME [epoch: 9.07 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09770536697915214		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.09770536697915214 | validation: 0.11740526172217414]
	TIME [epoch: 9.08 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10948762182903023		[learning rate: 0.0011709]
	Learning Rate: 0.00117092
	LOSS [training: 0.10948762182903023 | validation: 0.06824881734063129]
	TIME [epoch: 9.08 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07072928999157775		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.07072928999157775 | validation: 0.08258978502997341]
	TIME [epoch: 9.1 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10325738960102988		[learning rate: 0.0011653]
	Learning Rate: 0.00116526
	LOSS [training: 0.10325738960102988 | validation: 0.12612000600895718]
	TIME [epoch: 9.07 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0693759559501011		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.0693759559501011 | validation: 0.039591311764714136]
	TIME [epoch: 9.07 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028350391914019318		[learning rate: 0.0011596]
	Learning Rate: 0.00115962
	LOSS [training: 0.028350391914019318 | validation: 0.024205839669951452]
	TIME [epoch: 9.07 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03721095793559969		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.03721095793559969 | validation: 0.06544398879425553]
	TIME [epoch: 9.09 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047023654073741795		[learning rate: 0.001154]
	Learning Rate: 0.00115401
	LOSS [training: 0.047023654073741795 | validation: 0.026522416497510814]
	TIME [epoch: 9.08 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06760791939685731		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.06760791939685731 | validation: 0.043469214250392824]
	TIME [epoch: 9.08 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044930555839002885		[learning rate: 0.0011484]
	Learning Rate: 0.00114843
	LOSS [training: 0.044930555839002885 | validation: 0.04291136657005527]
	TIME [epoch: 9.07 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03748703754581504		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.03748703754581504 | validation: 0.041904643322958186]
	TIME [epoch: 9.08 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0445768401307996		[learning rate: 0.0011429]
	Learning Rate: 0.00114288
	LOSS [training: 0.0445768401307996 | validation: 0.04859269196712937]
	TIME [epoch: 9.09 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031286917233536334		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.031286917233536334 | validation: 0.03219241087804022]
	TIME [epoch: 9.08 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02828202021679955		[learning rate: 0.0011374]
	Learning Rate: 0.00113735
	LOSS [training: 0.02828202021679955 | validation: 0.033369433006075845]
	TIME [epoch: 9.07 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04747789068148418		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.04747789068148418 | validation: 0.0863144211440577]
	TIME [epoch: 9.07 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056648561825472156		[learning rate: 0.0011319]
	Learning Rate: 0.00113185
	LOSS [training: 0.056648561825472156 | validation: 0.04165802402467239]
	TIME [epoch: 9.1 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04059968817604142		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.04059968817604142 | validation: 0.05644234514098419]
	TIME [epoch: 9.08 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05679911247726158		[learning rate: 0.0011264]
	Learning Rate: 0.00112638
	LOSS [training: 0.05679911247726158 | validation: 0.03370699457755943]
	TIME [epoch: 9.08 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057899369264633696		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.057899369264633696 | validation: 0.04464994145290369]
	TIME [epoch: 9.08 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03717654569274168		[learning rate: 0.0011209]
	Learning Rate: 0.00112093
	LOSS [training: 0.03717654569274168 | validation: 0.08157577668382776]
	TIME [epoch: 9.07 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08608222131264776		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.08608222131264776 | validation: 0.0913967932870722]
	TIME [epoch: 9.1 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05668407657408434		[learning rate: 0.0011155]
	Learning Rate: 0.00111551
	LOSS [training: 0.05668407657408434 | validation: 0.04914750390764512]
	TIME [epoch: 9.08 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04454530383481736		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.04454530383481736 | validation: 0.08180043346088683]
	TIME [epoch: 9.08 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04185958759890595		[learning rate: 0.0011101]
	Learning Rate: 0.00111012
	LOSS [training: 0.04185958759890595 | validation: 0.03064688945829487]
	TIME [epoch: 9.08 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03566216818697821		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.03566216818697821 | validation: 0.04574230407384358]
	TIME [epoch: 9.08 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03698852497326738		[learning rate: 0.0011047]
	Learning Rate: 0.00110475
	LOSS [training: 0.03698852497326738 | validation: 0.02619443285401084]
	TIME [epoch: 9.09 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04193998678169327		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.04193998678169327 | validation: 0.03311899527464888]
	TIME [epoch: 9.07 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030984868847268664		[learning rate: 0.0010994]
	Learning Rate: 0.00109941
	LOSS [training: 0.030984868847268664 | validation: 0.029949736661024]
	TIME [epoch: 9.08 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022846340921231233		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.022846340921231233 | validation: 0.02403824702381558]
	TIME [epoch: 9.08 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01873113856606438		[learning rate: 0.0010941]
	Learning Rate: 0.00109409
	LOSS [training: 0.01873113856606438 | validation: 0.03318261874010081]
	TIME [epoch: 9.1 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024213144302477722		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.024213144302477722 | validation: 0.029892456144208508]
	TIME [epoch: 9.08 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03534287734053139		[learning rate: 0.0010888]
	Learning Rate: 0.0010888
	LOSS [training: 0.03534287734053139 | validation: 0.05139315348466102]
	TIME [epoch: 9.07 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039693215061155085		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.039693215061155085 | validation: 0.030262338472572384]
	TIME [epoch: 9.07 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04470531808139288		[learning rate: 0.0010835]
	Learning Rate: 0.00108353
	LOSS [training: 0.04470531808139288 | validation: 0.041681264058233074]
	TIME [epoch: 9.09 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03313292285385476		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.03313292285385476 | validation: 0.040591257614598766]
	TIME [epoch: 9.08 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024263440186475266		[learning rate: 0.0010783]
	Learning Rate: 0.00107829
	LOSS [training: 0.024263440186475266 | validation: 0.04081939600495443]
	TIME [epoch: 9.07 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028035463758654077		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.028035463758654077 | validation: 0.03017281530071452]
	TIME [epoch: 9.07 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036375877492466346		[learning rate: 0.0010731]
	Learning Rate: 0.00107308
	LOSS [training: 0.036375877492466346 | validation: 0.04808297085129736]
	TIME [epoch: 9.07 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04178455061956889		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.04178455061956889 | validation: 0.039468171747128675]
	TIME [epoch: 9.09 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03151252714870054		[learning rate: 0.0010679]
	Learning Rate: 0.00106789
	LOSS [training: 0.03151252714870054 | validation: 0.030627800648255484]
	TIME [epoch: 9.08 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02702823013050244		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.02702823013050244 | validation: 0.04567190490062929]
	TIME [epoch: 9.08 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026892800219431644		[learning rate: 0.0010627]
	Learning Rate: 0.00106273
	LOSS [training: 0.026892800219431644 | validation: 0.03640774684821039]
	TIME [epoch: 9.09 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027497580396954612		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.027497580396954612 | validation: 0.03635424125463082]
	TIME [epoch: 9.08 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025726433798993375		[learning rate: 0.0010576]
	Learning Rate: 0.00105759
	LOSS [training: 0.025726433798993375 | validation: 0.04047426258553988]
	TIME [epoch: 9.1 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03376724509997352		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.03376724509997352 | validation: 0.03823165518259297]
	TIME [epoch: 9.08 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03850089175323514		[learning rate: 0.0010525]
	Learning Rate: 0.00105247
	LOSS [training: 0.03850089175323514 | validation: 0.033657375303522946]
	TIME [epoch: 9.09 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01611257548073472		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.01611257548073472 | validation: 0.031602049651448125]
	TIME [epoch: 9.07 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02489334785462255		[learning rate: 0.0010474]
	Learning Rate: 0.00104738
	LOSS [training: 0.02489334785462255 | validation: 0.026678736254353012]
	TIME [epoch: 9.09 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02524467588114606		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.02524467588114606 | validation: 0.02594129995387146]
	TIME [epoch: 9.09 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017914637265121207		[learning rate: 0.0010423]
	Learning Rate: 0.00104232
	LOSS [training: 0.017914637265121207 | validation: 0.015582525834712846]
	TIME [epoch: 9.08 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04843304727650595		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.04843304727650595 | validation: 0.03673083763333327]
	TIME [epoch: 9.09 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036070547426922374		[learning rate: 0.0010373]
	Learning Rate: 0.00103728
	LOSS [training: 0.036070547426922374 | validation: 0.036286283014256]
	TIME [epoch: 9.08 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015277089274800834		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.015277089274800834 | validation: 0.023611810671597958]
	TIME [epoch: 9.1 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02130663910413983		[learning rate: 0.0010323]
	Learning Rate: 0.00103226
	LOSS [training: 0.02130663910413983 | validation: 0.03911185280197104]
	TIME [epoch: 9.09 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043598791290877834		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.043598791290877834 | validation: 0.03465088241797466]
	TIME [epoch: 9.08 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02646632749843366		[learning rate: 0.0010273]
	Learning Rate: 0.00102727
	LOSS [training: 0.02646632749843366 | validation: 0.04290058061298128]
	TIME [epoch: 9.08 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023517623694083476		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.023517623694083476 | validation: 0.026601305820690913]
	TIME [epoch: 9.09 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015095752519803995		[learning rate: 0.0010223]
	Learning Rate: 0.0010223
	LOSS [training: 0.015095752519803995 | validation: 0.021658650652387902]
	TIME [epoch: 9.08 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03591266023147066		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.03591266023147066 | validation: 0.09544200630562118]
	TIME [epoch: 9.08 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04310885704506495		[learning rate: 0.0010174]
	Learning Rate: 0.00101736
	LOSS [training: 0.04310885704506495 | validation: 0.04621083427977971]
	TIME [epoch: 9.07 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05294578810618496		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.05294578810618496 | validation: 0.045547142407744726]
	TIME [epoch: 9.07 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03304510644517344		[learning rate: 0.0010124]
	Learning Rate: 0.00101244
	LOSS [training: 0.03304510644517344 | validation: 0.02873142949680878]
	TIME [epoch: 9.09 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03145439072816343		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.03145439072816343 | validation: 0.030879056026647974]
	TIME [epoch: 9.08 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020205550497789524		[learning rate: 0.0010075]
	Learning Rate: 0.00100754
	LOSS [training: 0.020205550497789524 | validation: 0.02558311294803648]
	TIME [epoch: 9.07 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02384707945849216		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.02384707945849216 | validation: 0.04684658620986253]
	TIME [epoch: 9.07 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04232909997835088		[learning rate: 0.0010027]
	Learning Rate: 0.00100267
	LOSS [training: 0.04232909997835088 | validation: 0.02955542160138969]
	TIME [epoch: 9.08 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019504885218316684		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.019504885218316684 | validation: 0.02572367067816752]
	TIME [epoch: 9.09 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01114154069760886		[learning rate: 0.00099782]
	Learning Rate: 0.000997821
	LOSS [training: 0.01114154069760886 | validation: 0.026451846538889615]
	TIME [epoch: 9.08 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015116148450910685		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.015116148450910685 | validation: 0.019599269478312132]
	TIME [epoch: 9.08 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019245018493713205		[learning rate: 0.000993]
	Learning Rate: 0.000992996
	LOSS [training: 0.019245018493713205 | validation: 0.025745400330295317]
	TIME [epoch: 9.08 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014500974192627475		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.014500974192627475 | validation: 0.010140209893162614]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_1054.pth
	Model improved!!!
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021552759791376296		[learning rate: 0.00098819]
	Learning Rate: 0.000988194
	LOSS [training: 0.021552759791376296 | validation: 0.027292342112105704]
	TIME [epoch: 9.09 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01708785607036628		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.01708785607036628 | validation: 0.018752953986929017]
	TIME [epoch: 9.08 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019181379209233025		[learning rate: 0.00098341]
	Learning Rate: 0.000983415
	LOSS [training: 0.019181379209233025 | validation: 0.015708602086032357]
	TIME [epoch: 9.09 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012531868411344776		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.012531868411344776 | validation: 0.018453426431418493]
	TIME [epoch: 9.08 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01652060160630197		[learning rate: 0.00097866]
	Learning Rate: 0.000978659
	LOSS [training: 0.01652060160630197 | validation: 0.025193919940888446]
	TIME [epoch: 9.1 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018481912689000533		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 0.018481912689000533 | validation: 0.03325951911846875]
	TIME [epoch: 9.09 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04757875750249578		[learning rate: 0.00097393]
	Learning Rate: 0.000973927
	LOSS [training: 0.04757875750249578 | validation: 0.031955206922058395]
	TIME [epoch: 9.08 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053684208574042394		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.053684208574042394 | validation: 0.059546604383861376]
	TIME [epoch: 9.07 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027256255349775355		[learning rate: 0.00096922]
	Learning Rate: 0.000969217
	LOSS [training: 0.027256255349775355 | validation: 0.03317282777384127]
	TIME [epoch: 9.1 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02329065925915511		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.02329065925915511 | validation: 0.04167160970418597]
	TIME [epoch: 9.09 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06035141004414783		[learning rate: 0.00096453]
	Learning Rate: 0.00096453
	LOSS [training: 0.06035141004414783 | validation: 0.067892828943411]
	TIME [epoch: 9.09 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03922647523495209		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.03922647523495209 | validation: 0.026066129778897617]
	TIME [epoch: 9.08 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0349748159354749		[learning rate: 0.00095987]
	Learning Rate: 0.000959866
	LOSS [training: 0.0349748159354749 | validation: 0.038222664840831616]
	TIME [epoch: 9.08 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02095244387301562		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.02095244387301562 | validation: 0.0438002755761773]
	TIME [epoch: 9.1 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034952723403381826		[learning rate: 0.00095522]
	Learning Rate: 0.000955224
	LOSS [training: 0.034952723403381826 | validation: 0.059268640381083204]
	TIME [epoch: 9.08 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044261408175967645		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.044261408175967645 | validation: 0.03268047933193871]
	TIME [epoch: 9.08 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04426220452386181		[learning rate: 0.0009506]
	Learning Rate: 0.000950605
	LOSS [training: 0.04426220452386181 | validation: 0.06330656996980916]
	TIME [epoch: 9.07 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03258351989516241		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.03258351989516241 | validation: 0.012432223699595783]
	TIME [epoch: 9.09 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009530376456875336		[learning rate: 0.00094601]
	Learning Rate: 0.000946008
	LOSS [training: 0.009530376456875336 | validation: 0.024316661411514486]
	TIME [epoch: 9.1 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04290770771328614		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.04290770771328614 | validation: 0.15244252191397217]
	TIME [epoch: 9.07 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07499779411616325		[learning rate: 0.00094143]
	Learning Rate: 0.000941433
	LOSS [training: 0.07499779411616325 | validation: 0.03327967571630027]
	TIME [epoch: 9.08 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02956603291104697		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.02956603291104697 | validation: 0.04529580908522245]
	TIME [epoch: 9.08 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0328330487365404		[learning rate: 0.00093688]
	Learning Rate: 0.00093688
	LOSS [training: 0.0328330487365404 | validation: 0.057066645077262244]
	TIME [epoch: 9.11 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03569733442026522		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.03569733442026522 | validation: 0.03222633910847282]
	TIME [epoch: 9.09 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015192476293303942		[learning rate: 0.00093235]
	Learning Rate: 0.00093235
	LOSS [training: 0.015192476293303942 | validation: 0.018867744959100142]
	TIME [epoch: 9.08 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018018092335527057		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.018018092335527057 | validation: 0.02087741757157882]
	TIME [epoch: 9.09 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019906119731748034		[learning rate: 0.00092784]
	Learning Rate: 0.000927841
	LOSS [training: 0.019906119731748034 | validation: 0.03436217156845172]
	TIME [epoch: 9.09 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026024357601442484		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.026024357601442484 | validation: 0.02435749875104526]
	TIME [epoch: 9.08 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036270734683964814		[learning rate: 0.00092335]
	Learning Rate: 0.000923354
	LOSS [training: 0.036270734683964814 | validation: 0.03366266465196627]
	TIME [epoch: 9.09 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017252412442314385		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.017252412442314385 | validation: 0.04530676659036213]
	TIME [epoch: 9.08 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020683840882734193		[learning rate: 0.00091889]
	Learning Rate: 0.000918889
	LOSS [training: 0.020683840882734193 | validation: 0.020546411668755152]
	TIME [epoch: 9.08 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017640754635098198		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.017640754635098198 | validation: 0.019932206777424324]
	TIME [epoch: 9.1 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015049811731293878		[learning rate: 0.00091445]
	Learning Rate: 0.000914446
	LOSS [training: 0.015049811731293878 | validation: 0.07380260174412576]
	TIME [epoch: 9.08 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03382668478892936		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.03382668478892936 | validation: 0.02296497918634318]
	TIME [epoch: 9.08 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030658636762400958		[learning rate: 0.00091002]
	Learning Rate: 0.000910024
	LOSS [training: 0.030658636762400958 | validation: 0.025542645218064798]
	TIME [epoch: 9.08 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02350431679276404		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.02350431679276404 | validation: 0.030168378614037775]
	TIME [epoch: 9.08 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02506659232225202		[learning rate: 0.00090562]
	Learning Rate: 0.000905623
	LOSS [training: 0.02506659232225202 | validation: 0.04741971639580081]
	TIME [epoch: 9.1 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023553461212055815		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.023553461212055815 | validation: 0.036927749221092085]
	TIME [epoch: 9.08 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03019949425136926		[learning rate: 0.00090124]
	Learning Rate: 0.000901243
	LOSS [training: 0.03019949425136926 | validation: 0.027497874949401972]
	TIME [epoch: 9.08 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05099246775375678		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.05099246775375678 | validation: 0.09464958845746006]
	TIME [epoch: 9.07 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03577966676178851		[learning rate: 0.00089689]
	Learning Rate: 0.000896885
	LOSS [training: 0.03577966676178851 | validation: 0.01594573210917855]
	TIME [epoch: 9.09 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017126202093145023		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.017126202093145023 | validation: 0.03869309362126868]
	TIME [epoch: 9.08 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016820196219373643		[learning rate: 0.00089255]
	Learning Rate: 0.000892548
	LOSS [training: 0.016820196219373643 | validation: 0.019284965989259786]
	TIME [epoch: 9.08 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013397940640037067		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.013397940640037067 | validation: 0.030985808205228595]
	TIME [epoch: 9.07 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030870952675783818		[learning rate: 0.00088823]
	Learning Rate: 0.000888232
	LOSS [training: 0.030870952675783818 | validation: 0.0867218761388247]
	TIME [epoch: 9.08 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09820317177830573		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.09820317177830573 | validation: 0.08233078277963461]
	TIME [epoch: 9.1 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045583279054604256		[learning rate: 0.00088394]
	Learning Rate: 0.000883936
	LOSS [training: 0.045583279054604256 | validation: 0.025132918033567778]
	TIME [epoch: 9.08 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026319410382171764		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.026319410382171764 | validation: 0.04750681059618144]
	TIME [epoch: 9.08 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035782914986204645		[learning rate: 0.00087966]
	Learning Rate: 0.000879662
	LOSS [training: 0.035782914986204645 | validation: 0.06090099531959942]
	TIME [epoch: 9.08 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07063296185538888		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.07063296185538888 | validation: 0.1401680151062671]
	TIME [epoch: 9.08 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07932648938997268		[learning rate: 0.00087541]
	Learning Rate: 0.000875408
	LOSS [training: 0.07932648938997268 | validation: 0.06496831055491001]
	TIME [epoch: 9.08 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0653467987434275		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.0653467987434275 | validation: 0.0592100504908714]
	TIME [epoch: 9.08 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05344985587456345		[learning rate: 0.00087117]
	Learning Rate: 0.000871175
	LOSS [training: 0.05344985587456345 | validation: 0.037336625094448316]
	TIME [epoch: 9.07 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027593138946000302		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.027593138946000302 | validation: 0.02268831396019098]
	TIME [epoch: 9.08 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022793780602824755		[learning rate: 0.00086696]
	Learning Rate: 0.000866962
	LOSS [training: 0.022793780602824755 | validation: 0.029991937433002498]
	TIME [epoch: 9.1 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020616225815131877		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.020616225815131877 | validation: 0.029111062860985328]
	TIME [epoch: 9.08 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021154864813450518		[learning rate: 0.00086277]
	Learning Rate: 0.000862769
	LOSS [training: 0.021154864813450518 | validation: 0.026087753377546073]
	TIME [epoch: 9.07 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028670834019919787		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.028670834019919787 | validation: 0.020242807821150104]
	TIME [epoch: 9.07 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023876056796379795		[learning rate: 0.0008586]
	Learning Rate: 0.000858597
	LOSS [training: 0.023876056796379795 | validation: 0.03178188560308104]
	TIME [epoch: 9.08 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025424392587407214		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.025424392587407214 | validation: 0.02304110543223779]
	TIME [epoch: 9.08 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030428721621557263		[learning rate: 0.00085445]
	Learning Rate: 0.000854445
	LOSS [training: 0.030428721621557263 | validation: 0.027397595858081523]
	TIME [epoch: 9.08 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03096848668327744		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.03096848668327744 | validation: 0.0636961826331591]
	TIME [epoch: 9.08 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06792482895553323		[learning rate: 0.00085031]
	Learning Rate: 0.000850313
	LOSS [training: 0.06792482895553323 | validation: 0.06935122932152023]
	TIME [epoch: 9.08 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06441456036853391		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.06441456036853391 | validation: 0.11086553280760819]
	TIME [epoch: 9.1 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09004715324117714		[learning rate: 0.0008462]
	Learning Rate: 0.000846201
	LOSS [training: 0.09004715324117714 | validation: 0.08025010089304266]
	TIME [epoch: 9.09 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057291600717282995		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.057291600717282995 | validation: 0.06408781997006222]
	TIME [epoch: 9.08 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05164664934970505		[learning rate: 0.00084211]
	Learning Rate: 0.000842109
	LOSS [training: 0.05164664934970505 | validation: 0.04705701591553515]
	TIME [epoch: 9.08 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0361676340675741		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.0361676340675741 | validation: 0.050533334614283706]
	TIME [epoch: 9.08 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043883726096801856		[learning rate: 0.00083804]
	Learning Rate: 0.000838037
	LOSS [training: 0.043883726096801856 | validation: 0.04430437775976731]
	TIME [epoch: 9.09 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03664654892905224		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.03664654892905224 | validation: 0.043769498370785406]
	TIME [epoch: 9.08 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038524063829332746		[learning rate: 0.00083398]
	Learning Rate: 0.000833984
	LOSS [training: 0.038524063829332746 | validation: 0.046366139358090495]
	TIME [epoch: 9.08 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04425396518148293		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.04425396518148293 | validation: 0.06416335731155373]
	TIME [epoch: 9.07 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04746067632573325		[learning rate: 0.00082995]
	Learning Rate: 0.000829951
	LOSS [training: 0.04746067632573325 | validation: 0.04097603500647712]
	TIME [epoch: 9.09 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030919887762653097		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.030919887762653097 | validation: 0.03741525956374403]
	TIME [epoch: 9.08 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04308838729483415		[learning rate: 0.00082594]
	Learning Rate: 0.000825938
	LOSS [training: 0.04308838729483415 | validation: 0.07005318522974356]
	TIME [epoch: 9.08 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051575197375641035		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.051575197375641035 | validation: 0.03798229576036903]
	TIME [epoch: 9.08 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03740350619764778		[learning rate: 0.00082194]
	Learning Rate: 0.000821944
	LOSS [training: 0.03740350619764778 | validation: 0.05076357213279417]
	TIME [epoch: 9.08 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03496903788428426		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.03496903788428426 | validation: 0.0639248419153855]
	TIME [epoch: 9.11 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047055265041276266		[learning rate: 0.00081797]
	Learning Rate: 0.000817969
	LOSS [training: 0.047055265041276266 | validation: 0.03264029316833653]
	TIME [epoch: 9.07 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029513174431754698		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.029513174431754698 | validation: 0.03470831293196583]
	TIME [epoch: 9.08 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03551323634812156		[learning rate: 0.00081401]
	Learning Rate: 0.000814014
	LOSS [training: 0.03551323634812156 | validation: 0.04411538716879733]
	TIME [epoch: 9.07 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03277604329239966		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.03277604329239966 | validation: 0.024496642482270018]
	TIME [epoch: 9.09 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016245223051314345		[learning rate: 0.00081008]
	Learning Rate: 0.000810077
	LOSS [training: 0.016245223051314345 | validation: 0.025653536140615676]
	TIME [epoch: 9.09 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01272437895165438		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.01272437895165438 | validation: 0.023094860452392542]
	TIME [epoch: 9.07 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036352255939316874		[learning rate: 0.00080616]
	Learning Rate: 0.00080616
	LOSS [training: 0.036352255939316874 | validation: 0.03638813072329514]
	TIME [epoch: 9.08 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038925011311145494		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.038925011311145494 | validation: 0.046385753966898716]
	TIME [epoch: 9.08 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023839294957860142		[learning rate: 0.00080226]
	Learning Rate: 0.000802261
	LOSS [training: 0.023839294957860142 | validation: 0.025316594458371998]
	TIME [epoch: 9.1 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025644772142779586		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.025644772142779586 | validation: 0.03180397796281128]
	TIME [epoch: 9.08 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03720050469771243		[learning rate: 0.00079838]
	Learning Rate: 0.000798382
	LOSS [training: 0.03720050469771243 | validation: 0.043895952317089745]
	TIME [epoch: 9.08 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03385531526871853		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.03385531526871853 | validation: 0.04176774925867645]
	TIME [epoch: 9.08 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029701037968841403		[learning rate: 0.00079452]
	Learning Rate: 0.000794521
	LOSS [training: 0.029701037968841403 | validation: 0.039958797580025324]
	TIME [epoch: 9.09 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03013349135498517		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.03013349135498517 | validation: 0.02232757244859975]
	TIME [epoch: 9.09 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02255538801477351		[learning rate: 0.00079068]
	Learning Rate: 0.000790679
	LOSS [training: 0.02255538801477351 | validation: 0.03186534147612402]
	TIME [epoch: 9.07 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025478058175758878		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.025478058175758878 | validation: 0.03217402931550463]
	TIME [epoch: 9.07 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03061046695512811		[learning rate: 0.00078686]
	Learning Rate: 0.000786855
	LOSS [training: 0.03061046695512811 | validation: 0.03338012873182704]
	TIME [epoch: 9.08 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026283125360389008		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.026283125360389008 | validation: 0.03233352391467476]
	TIME [epoch: 9.1 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019110394274163167		[learning rate: 0.00078305]
	Learning Rate: 0.00078305
	LOSS [training: 0.019110394274163167 | validation: 0.028732292760790583]
	TIME [epoch: 9.08 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01771580113299489		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.01771580113299489 | validation: 0.027744279292455057]
	TIME [epoch: 9.08 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016146448276625442		[learning rate: 0.00077926]
	Learning Rate: 0.000779263
	LOSS [training: 0.016146448276625442 | validation: 0.01031141763569973]
	TIME [epoch: 9.07 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016115752893069695		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.016115752893069695 | validation: 0.018366166025009054]
	TIME [epoch: 9.08 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019360177891938207		[learning rate: 0.00077549]
	Learning Rate: 0.000775495
	LOSS [training: 0.019360177891938207 | validation: 0.024017072771825455]
	TIME [epoch: 9.1 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024796326590036263		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.024796326590036263 | validation: 0.051669520895710794]
	TIME [epoch: 9.09 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030752263258417057		[learning rate: 0.00077174]
	Learning Rate: 0.000771745
	LOSS [training: 0.030752263258417057 | validation: 0.024318848710039455]
	TIME [epoch: 9.08 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02620462291505541		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.02620462291505541 | validation: 0.0389766559068546]
	TIME [epoch: 9.08 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024631915675811127		[learning rate: 0.00076801]
	Learning Rate: 0.000768013
	LOSS [training: 0.024631915675811127 | validation: 0.03778478674528196]
	TIME [epoch: 9.1 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03424736472520718		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.03424736472520718 | validation: 0.040819964601939804]
	TIME [epoch: 9.08 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0424476980338654		[learning rate: 0.0007643]
	Learning Rate: 0.000764299
	LOSS [training: 0.0424476980338654 | validation: 0.06295040166268162]
	TIME [epoch: 9.07 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046498246391227814		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.046498246391227814 | validation: 0.04852709282605698]
	TIME [epoch: 9.08 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03311635978176396		[learning rate: 0.0007606]
	Learning Rate: 0.000760603
	LOSS [training: 0.03311635978176396 | validation: 0.03670012476570468]
	TIME [epoch: 9.07 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02109510826658159		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.02109510826658159 | validation: 0.02981231804292282]
	TIME [epoch: 9.1 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022016576125299222		[learning rate: 0.00075692]
	Learning Rate: 0.000756925
	LOSS [training: 0.022016576125299222 | validation: 0.025814182298870954]
	TIME [epoch: 9.08 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024129615470050294		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.024129615470050294 | validation: 0.03345195277109443]
	TIME [epoch: 9.08 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026035564794583778		[learning rate: 0.00075326]
	Learning Rate: 0.000753264
	LOSS [training: 0.026035564794583778 | validation: 0.0401672169389823]
	TIME [epoch: 9.08 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027057170096022782		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.027057170096022782 | validation: 0.034156002673844006]
	TIME [epoch: 9.08 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020724795841382128		[learning rate: 0.00074962]
	Learning Rate: 0.000749622
	LOSS [training: 0.020724795841382128 | validation: 0.016182011604619788]
	TIME [epoch: 9.09 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013685675019812044		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.013685675019812044 | validation: 0.01586733010831917]
	TIME [epoch: 9.08 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0138786788369311		[learning rate: 0.000746]
	Learning Rate: 0.000745997
	LOSS [training: 0.0138786788369311 | validation: 0.02673623427178576]
	TIME [epoch: 9.08 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01765438484353094		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.01765438484353094 | validation: 0.02730789515019042]
	TIME [epoch: 9.08 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014706993033324423		[learning rate: 0.00074239]
	Learning Rate: 0.000742389
	LOSS [training: 0.014706993033324423 | validation: 0.03773541897116127]
	TIME [epoch: 9.09 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03410924967602858		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.03410924967602858 | validation: 0.02296942837232034]
	TIME [epoch: 9.08 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021877186169242394		[learning rate: 0.0007388]
	Learning Rate: 0.000738799
	LOSS [training: 0.021877186169242394 | validation: 0.02741161012210647]
	TIME [epoch: 9.07 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017700623055783897		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.017700623055783897 | validation: 0.02329229218556183]
	TIME [epoch: 9.08 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027502079297354425		[learning rate: 0.00073523]
	Learning Rate: 0.000735226
	LOSS [training: 0.027502079297354425 | validation: 0.04398864166691982]
	TIME [epoch: 9.09 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021717738616085537		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.021717738616085537 | validation: 0.018150743468399032]
	TIME [epoch: 9.09 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01177364995409156		[learning rate: 0.00073167]
	Learning Rate: 0.000731671
	LOSS [training: 0.01177364995409156 | validation: 0.01616798415727186]
	TIME [epoch: 9.08 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015411385334076863		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.015411385334076863 | validation: 0.03137480834396322]
	TIME [epoch: 9.08 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02081822214969175		[learning rate: 0.00072813]
	Learning Rate: 0.000728133
	LOSS [training: 0.02081822214969175 | validation: 0.029045118100988105]
	TIME [epoch: 9.08 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013726785858328983		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.013726785858328983 | validation: 0.011485670219192296]
	TIME [epoch: 9.1 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018794838079843595		[learning rate: 0.00072461]
	Learning Rate: 0.000724612
	LOSS [training: 0.018794838079843595 | validation: 0.029684458220024634]
	TIME [epoch: 9.08 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02003499401384198		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.02003499401384198 | validation: 0.027824338296082142]
	TIME [epoch: 9.08 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01936466131832751		[learning rate: 0.00072111]
	Learning Rate: 0.000721107
	LOSS [training: 0.01936466131832751 | validation: 0.03169165593373789]
	TIME [epoch: 9.08 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015101785714747948		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.015101785714747948 | validation: 0.025244627297772142]
	TIME [epoch: 9.08 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019180758749400888		[learning rate: 0.00071762]
	Learning Rate: 0.00071762
	LOSS [training: 0.019180758749400888 | validation: 0.01720276237310736]
	TIME [epoch: 9.1 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009646894237700657		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.009646894237700657 | validation: 0.030651361332097823]
	TIME [epoch: 9.07 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04689077794546707		[learning rate: 0.00071415]
	Learning Rate: 0.00071415
	LOSS [training: 0.04689077794546707 | validation: 0.04406306996473277]
	TIME [epoch: 9.08 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024996049757282778		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.024996049757282778 | validation: 0.03439284012154614]
	TIME [epoch: 9.08 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03158049321896239		[learning rate: 0.0007107]
	Learning Rate: 0.000710697
	LOSS [training: 0.03158049321896239 | validation: 0.05411412295447694]
	TIME [epoch: 9.09 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029008592949632955		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.029008592949632955 | validation: 0.02491737293074072]
	TIME [epoch: 9.1 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019136667118450364		[learning rate: 0.00070726]
	Learning Rate: 0.00070726
	LOSS [training: 0.019136667118450364 | validation: 0.012383174461204498]
	TIME [epoch: 9.09 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01709675084796047		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.01709675084796047 | validation: 0.011987088724625523]
	TIME [epoch: 9.07 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01477933364954645		[learning rate: 0.00070384]
	Learning Rate: 0.00070384
	LOSS [training: 0.01477933364954645 | validation: 0.016217001333544652]
	TIME [epoch: 9.09 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015176498426458384		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.015176498426458384 | validation: 0.0274356537259368]
	TIME [epoch: 9.1 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018744178441358703		[learning rate: 0.00070044]
	Learning Rate: 0.000700436
	LOSS [training: 0.018744178441358703 | validation: 0.02252817103043991]
	TIME [epoch: 9.08 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019785932156127468		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.019785932156127468 | validation: 0.022655785925272585]
	TIME [epoch: 9.09 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021010041312771937		[learning rate: 0.00069705]
	Learning Rate: 0.000697049
	LOSS [training: 0.021010041312771937 | validation: 0.04275640205797351]
	TIME [epoch: 9.08 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053892995883623264		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.053892995883623264 | validation: 0.030428079802657982]
	TIME [epoch: 9.08 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026857901717745845		[learning rate: 0.00069368]
	Learning Rate: 0.000693678
	LOSS [training: 0.026857901717745845 | validation: 0.02537525295435923]
	TIME [epoch: 9.07 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015070157542812695		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.015070157542812695 | validation: 0.018521902873973494]
	TIME [epoch: 9.08 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01575699649714034		[learning rate: 0.00069032]
	Learning Rate: 0.000690324
	LOSS [training: 0.01575699649714034 | validation: 0.021442041709918733]
	TIME [epoch: 9.08 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020216017984614858		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.020216017984614858 | validation: 0.032534311457419085]
	TIME [epoch: 9.09 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016355587448247465		[learning rate: 0.00068699]
	Learning Rate: 0.000686985
	LOSS [training: 0.016355587448247465 | validation: 0.023841129719545873]
	TIME [epoch: 9.11 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030287425230136982		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.030287425230136982 | validation: 0.021018712988100593]
	TIME [epoch: 9.09 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03167295771878238		[learning rate: 0.00068366]
	Learning Rate: 0.000683663
	LOSS [training: 0.03167295771878238 | validation: 0.025426020735209817]
	TIME [epoch: 9.08 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020614042527987587		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.020614042527987587 | validation: 0.053464966868322146]
	TIME [epoch: 9.08 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044517890694608285		[learning rate: 0.00068036]
	Learning Rate: 0.000680357
	LOSS [training: 0.044517890694608285 | validation: 0.044440328781478695]
	TIME [epoch: 9.09 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04699117080892036		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.04699117080892036 | validation: 0.06650857292117358]
	TIME [epoch: 9.12 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04253438008413563		[learning rate: 0.00067707]
	Learning Rate: 0.000677067
	LOSS [training: 0.04253438008413563 | validation: 0.04100199333744832]
	TIME [epoch: 9.09 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028436280723985585		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.028436280723985585 | validation: 0.04187704686534472]
	TIME [epoch: 9.08 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027722898171832218		[learning rate: 0.00067379]
	Learning Rate: 0.000673793
	LOSS [training: 0.027722898171832218 | validation: 0.03139274058601667]
	TIME [epoch: 9.09 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021204966369139103		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.021204966369139103 | validation: 0.018493100792112863]
	TIME [epoch: 9.1 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017958390450218947		[learning rate: 0.00067053]
	Learning Rate: 0.000670534
	LOSS [training: 0.017958390450218947 | validation: 0.018983759140450113]
	TIME [epoch: 9.08 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01869860809828459		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.01869860809828459 | validation: 0.018819524234698216]
	TIME [epoch: 9.08 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020663384965000284		[learning rate: 0.00066729]
	Learning Rate: 0.000667292
	LOSS [training: 0.020663384965000284 | validation: 0.03285816528904653]
	TIME [epoch: 9.08 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01933584510658674		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.01933584510658674 | validation: 0.023779362180816645]
	TIME [epoch: 9.08 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021017798206255704		[learning rate: 0.00066406]
	Learning Rate: 0.000664065
	LOSS [training: 0.021017798206255704 | validation: 0.028174272326896118]
	TIME [epoch: 9.09 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02212929864452523		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.02212929864452523 | validation: 0.02960468283425044]
	TIME [epoch: 9.08 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026494957715534957		[learning rate: 0.00066085]
	Learning Rate: 0.000660854
	LOSS [training: 0.026494957715534957 | validation: 0.043241458751017134]
	TIME [epoch: 9.08 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02588909501193822		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.02588909501193822 | validation: 0.05078313567049204]
	TIME [epoch: 9.08 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03229593572906894		[learning rate: 0.00065766]
	Learning Rate: 0.000657658
	LOSS [training: 0.03229593572906894 | validation: 0.04733616891115703]
	TIME [epoch: 9.1 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029390582275913023		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.029390582275913023 | validation: 0.031047490584258847]
	TIME [epoch: 9.09 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024784265553051434		[learning rate: 0.00065448]
	Learning Rate: 0.000654478
	LOSS [training: 0.024784265553051434 | validation: 0.031887499123874785]
	TIME [epoch: 9.08 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02449894559982605		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.02449894559982605 | validation: 0.03230737895166827]
	TIME [epoch: 9.08 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023244919505574498		[learning rate: 0.00065131]
	Learning Rate: 0.000651313
	LOSS [training: 0.023244919505574498 | validation: 0.026748969601508278]
	TIME [epoch: 9.07 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01856629095204829		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.01856629095204829 | validation: 0.028609184291591688]
	TIME [epoch: 9.11 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01901065795351885		[learning rate: 0.00064816]
	Learning Rate: 0.000648163
	LOSS [training: 0.01901065795351885 | validation: 0.03216938644785845]
	TIME [epoch: 9.08 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021122920165624056		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.021122920165624056 | validation: 0.013603459236224719]
	TIME [epoch: 9.08 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022028296997458015		[learning rate: 0.00064503]
	Learning Rate: 0.000645029
	LOSS [training: 0.022028296997458015 | validation: 0.04363703105045803]
	TIME [epoch: 9.07 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015493244308716052		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.015493244308716052 | validation: 0.027427446805117755]
	TIME [epoch: 9.09 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014691913261989108		[learning rate: 0.00064191]
	Learning Rate: 0.000641909
	LOSS [training: 0.014691913261989108 | validation: 0.02400631893330534]
	TIME [epoch: 9.09 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01676800427260806		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.01676800427260806 | validation: 0.024596536423306174]
	TIME [epoch: 9.07 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013295259025968648		[learning rate: 0.00063881]
	Learning Rate: 0.000638805
	LOSS [training: 0.013295259025968648 | validation: 0.020030559367664628]
	TIME [epoch: 9.07 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014793836742988512		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.014793836742988512 | validation: 0.037634828169957786]
	TIME [epoch: 9.09 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035371057386450855		[learning rate: 0.00063572]
	Learning Rate: 0.000635716
	LOSS [training: 0.035371057386450855 | validation: 0.024152588079810758]
	TIME [epoch: 9.11 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013989350119291005		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.013989350119291005 | validation: 0.015073934513102067]
	TIME [epoch: 9.09 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009302771708594287		[learning rate: 0.00063264]
	Learning Rate: 0.000632642
	LOSS [training: 0.009302771708594287 | validation: 0.011953030716852067]
	TIME [epoch: 9.08 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014378103302700507		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.014378103302700507 | validation: 0.022487849522404634]
	TIME [epoch: 9.08 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019146338696146133		[learning rate: 0.00062958]
	Learning Rate: 0.000629582
	LOSS [training: 0.019146338696146133 | validation: 0.018557727979083147]
	TIME [epoch: 9.08 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01646625114860491		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.01646625114860491 | validation: 0.015155399131611276]
	TIME [epoch: 9.1 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013931403321486712		[learning rate: 0.00062654]
	Learning Rate: 0.000626538
	LOSS [training: 0.013931403321486712 | validation: 0.014262608493750913]
	TIME [epoch: 9.08 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013299152784753378		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.013299152784753378 | validation: 0.0343790625891517]
	TIME [epoch: 9.08 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032105369647852544		[learning rate: 0.00062351]
	Learning Rate: 0.000623508
	LOSS [training: 0.032105369647852544 | validation: 0.04643313030636853]
	TIME [epoch: 9.08 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03981496388084762		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.03981496388084762 | validation: 0.04386357785789459]
	TIME [epoch: 9.1 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028463041143850325		[learning rate: 0.00062049]
	Learning Rate: 0.000620493
	LOSS [training: 0.028463041143850325 | validation: 0.026771384921246776]
	TIME [epoch: 9.08 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015122973418172463		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.015122973418172463 | validation: 0.009986616161156918]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_1248.pth
	Model improved!!!
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00913201782657803		[learning rate: 0.00061749]
	Learning Rate: 0.000617492
	LOSS [training: 0.00913201782657803 | validation: 0.010900663573876394]
	TIME [epoch: 9.08 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011758490041478595		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.011758490041478595 | validation: 0.010053792175824106]
	TIME [epoch: 9.08 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0091476005594023		[learning rate: 0.00061451]
	Learning Rate: 0.000614506
	LOSS [training: 0.0091476005594023 | validation: 0.01641788280496254]
	TIME [epoch: 9.1 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013280722428258635		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: 0.013280722428258635 | validation: 0.026927960334747102]
	TIME [epoch: 9.07 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021553965684837126		[learning rate: 0.00061153]
	Learning Rate: 0.000611535
	LOSS [training: 0.021553965684837126 | validation: 0.02288048717759337]
	TIME [epoch: 9.07 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02015216428865763		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.02015216428865763 | validation: 0.0289115223590315]
	TIME [epoch: 9.07 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026318076595508045		[learning rate: 0.00060858]
	Learning Rate: 0.000608577
	LOSS [training: 0.026318076595508045 | validation: 0.021546619477838223]
	TIME [epoch: 9.09 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015602847734540265		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.015602847734540265 | validation: 0.025157571699056996]
	TIME [epoch: 9.08 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015291986488320586		[learning rate: 0.00060563]
	Learning Rate: 0.000605634
	LOSS [training: 0.015291986488320586 | validation: 0.022301141378827098]
	TIME [epoch: 9.08 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018224654299260103		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.018224654299260103 | validation: 0.02760303225841596]
	TIME [epoch: 9.08 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019213903452090418		[learning rate: 0.00060271]
	Learning Rate: 0.000602706
	LOSS [training: 0.019213903452090418 | validation: 0.029021470142963333]
	TIME [epoch: 9.07 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01690226265373742		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.01690226265373742 | validation: 0.023035830385053666]
	TIME [epoch: 9.1 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014100731728542953		[learning rate: 0.00059979]
	Learning Rate: 0.000599791
	LOSS [training: 0.014100731728542953 | validation: 0.015011682909637983]
	TIME [epoch: 9.08 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016623571937855387		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.016623571937855387 | validation: 0.0402324098242823]
	TIME [epoch: 9.09 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034146778825015676		[learning rate: 0.00059689]
	Learning Rate: 0.000596891
	LOSS [training: 0.034146778825015676 | validation: 0.032547688432231006]
	TIME [epoch: 9.07 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019424710798353884		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.019424710798353884 | validation: 0.014131373791069404]
	TIME [epoch: 9.1 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018941457645013114		[learning rate: 0.000594]
	Learning Rate: 0.000594004
	LOSS [training: 0.018941457645013114 | validation: 0.013786292795322752]
	TIME [epoch: 9.1 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015837804071164113		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.015837804071164113 | validation: 0.025352065242342382]
	TIME [epoch: 9.08 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01624762958417253		[learning rate: 0.00059113]
	Learning Rate: 0.000591132
	LOSS [training: 0.01624762958417253 | validation: 0.018793124811174452]
	TIME [epoch: 9.07 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01773620581870415		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.01773620581870415 | validation: 0.02473096707764529]
	TIME [epoch: 9.07 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016539262869401262		[learning rate: 0.00058827]
	Learning Rate: 0.000588273
	LOSS [training: 0.016539262869401262 | validation: 0.030681961877921174]
	TIME [epoch: 9.1 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021899927841391793		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.021899927841391793 | validation: 0.037968942392215724]
	TIME [epoch: 9.09 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03194418791703281		[learning rate: 0.00058543]
	Learning Rate: 0.000585428
	LOSS [training: 0.03194418791703281 | validation: 0.03952709112905205]
	TIME [epoch: 9.08 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027410704710803768		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.027410704710803768 | validation: 0.03825119227222097]
	TIME [epoch: 9.08 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022549427436288873		[learning rate: 0.0005826]
	Learning Rate: 0.000582597
	LOSS [training: 0.022549427436288873 | validation: 0.024731092399657473]
	TIME [epoch: 9.08 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014486173814838488		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.014486173814838488 | validation: 0.020793903661287656]
	TIME [epoch: 9.1 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020206221752424633		[learning rate: 0.00057978]
	Learning Rate: 0.00057978
	LOSS [training: 0.020206221752424633 | validation: 0.019060632437343947]
	TIME [epoch: 9.08 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030487295359681733		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.030487295359681733 | validation: 0.042629858656252774]
	TIME [epoch: 9.09 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023246383970871844		[learning rate: 0.00057698]
	Learning Rate: 0.000576976
	LOSS [training: 0.023246383970871844 | validation: 0.02655017486713934]
	TIME [epoch: 9.08 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013372766392289338		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.013372766392289338 | validation: 0.0328926800438098]
	TIME [epoch: 9.1 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02090013707352425		[learning rate: 0.00057419]
	Learning Rate: 0.000574186
	LOSS [training: 0.02090013707352425 | validation: 0.031377894694342136]
	TIME [epoch: 9.07 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032677135664761096		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.032677135664761096 | validation: 0.03095982590031711]
	TIME [epoch: 9.08 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031045486196899015		[learning rate: 0.00057141]
	Learning Rate: 0.000571409
	LOSS [training: 0.031045486196899015 | validation: 0.04482058733234855]
	TIME [epoch: 9.08 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03183800319121514		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.03183800319121514 | validation: 0.02612618918306513]
	TIME [epoch: 9.09 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028040234076329874		[learning rate: 0.00056865]
	Learning Rate: 0.000568646
	LOSS [training: 0.028040234076329874 | validation: 0.0344913089569876]
	TIME [epoch: 9.09 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028232411225319803		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.028232411225319803 | validation: 0.027026985256149917]
	TIME [epoch: 9.08 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025867372334481914		[learning rate: 0.0005659]
	Learning Rate: 0.000565896
	LOSS [training: 0.025867372334481914 | validation: 0.023011678508761155]
	TIME [epoch: 9.08 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03398937112482366		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.03398937112482366 | validation: 0.0525018527947483]
	TIME [epoch: 9.07 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0416572683480228		[learning rate: 0.00056316]
	Learning Rate: 0.00056316
	LOSS [training: 0.0416572683480228 | validation: 0.04534198493232956]
	TIME [epoch: 9.1 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04533110886871738		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.04533110886871738 | validation: 0.06150453958849106]
	TIME [epoch: 9.09 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035083892674310564		[learning rate: 0.00056044]
	Learning Rate: 0.000560436
	LOSS [training: 0.035083892674310564 | validation: 0.04257442824881922]
	TIME [epoch: 9.07 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03341804144740311		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.03341804144740311 | validation: 0.03897599504355571]
	TIME [epoch: 9.08 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03794592615185343		[learning rate: 0.00055773]
	Learning Rate: 0.000557726
	LOSS [training: 0.03794592615185343 | validation: 0.046732205890779574]
	TIME [epoch: 9.07 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033647207077601944		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.033647207077601944 | validation: 0.041773434708408066]
	TIME [epoch: 9.1 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03014287217670152		[learning rate: 0.00055503]
	Learning Rate: 0.000555029
	LOSS [training: 0.03014287217670152 | validation: 0.0361383399997107]
	TIME [epoch: 9.08 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031571100504737215		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.031571100504737215 | validation: 0.036218642602009424]
	TIME [epoch: 9.08 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03407636361121342		[learning rate: 0.00055235]
	Learning Rate: 0.000552345
	LOSS [training: 0.03407636361121342 | validation: 0.04026592744115173]
	TIME [epoch: 9.08 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03044607193751788		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.03044607193751788 | validation: 0.035527225033546724]
	TIME [epoch: 9.08 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035599736644895005		[learning rate: 0.00054967]
	Learning Rate: 0.000549674
	LOSS [training: 0.035599736644895005 | validation: 0.05602368004376432]
	TIME [epoch: 9.09 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04922507918943771		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.04922507918943771 | validation: 0.06063943171357995]
	TIME [epoch: 9.08 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033422613556000014		[learning rate: 0.00054702]
	Learning Rate: 0.000547016
	LOSS [training: 0.033422613556000014 | validation: 0.039308936106172435]
	TIME [epoch: 9.07 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03802512925980819		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.03802512925980819 | validation: 0.049208840108239046]
	TIME [epoch: 9.08 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04081142437376882		[learning rate: 0.00054437]
	Learning Rate: 0.000544371
	LOSS [training: 0.04081142437376882 | validation: 0.044853085897860044]
	TIME [epoch: 9.09 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032208468851197866		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.032208468851197866 | validation: 0.04206483368098878]
	TIME [epoch: 9.09 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030836394260157475		[learning rate: 0.00054174]
	Learning Rate: 0.000541738
	LOSS [training: 0.030836394260157475 | validation: 0.03770872865223505]
	TIME [epoch: 9.08 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029525053599648726		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.029525053599648726 | validation: 0.04794561978752074]
	TIME [epoch: 9.07 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030907091149081446		[learning rate: 0.00053912]
	Learning Rate: 0.000539118
	LOSS [training: 0.030907091149081446 | validation: 0.02880974194860702]
	TIME [epoch: 9.09 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02591267250466047		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.02591267250466047 | validation: 0.03096297939308411]
	TIME [epoch: 9.09 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024459520710760678		[learning rate: 0.00053651]
	Learning Rate: 0.000536511
	LOSS [training: 0.024459520710760678 | validation: 0.024356548598424094]
	TIME [epoch: 9.07 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026263246429250976		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.026263246429250976 | validation: 0.04108692213828547]
	TIME [epoch: 9.08 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026719607766199305		[learning rate: 0.00053392]
	Learning Rate: 0.000533917
	LOSS [training: 0.026719607766199305 | validation: 0.03506818248529803]
	TIME [epoch: 9.08 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02664864532138858		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.02664864532138858 | validation: 0.0412892453866438]
	TIME [epoch: 9.1 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022781165139327875		[learning rate: 0.00053134]
	Learning Rate: 0.000531335
	LOSS [training: 0.022781165139327875 | validation: 0.037597881899383706]
	TIME [epoch: 9.07 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02514050369061254		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.02514050369061254 | validation: 0.03498223921087946]
	TIME [epoch: 9.08 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024349091629916823		[learning rate: 0.00052877]
	Learning Rate: 0.000528766
	LOSS [training: 0.024349091629916823 | validation: 0.027455279399566688]
	TIME [epoch: 9.08 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016776401110454194		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.016776401110454194 | validation: 0.028612143817417626]
	TIME [epoch: 9.08 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019343378664590034		[learning rate: 0.00052621]
	Learning Rate: 0.000526208
	LOSS [training: 0.019343378664590034 | validation: 0.0320524689461478]
	TIME [epoch: 9.11 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023515336007461685		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.023515336007461685 | validation: 0.03537664830584798]
	TIME [epoch: 9.07 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026449136415474677		[learning rate: 0.00052366]
	Learning Rate: 0.000523664
	LOSS [training: 0.026449136415474677 | validation: 0.04077231261923708]
	TIME [epoch: 9.07 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03903322209458968		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.03903322209458968 | validation: 0.08792291130530674]
	TIME [epoch: 9.07 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053542402226076966		[learning rate: 0.00052113]
	Learning Rate: 0.000521132
	LOSS [training: 0.053542402226076966 | validation: 0.06259356809573276]
	TIME [epoch: 9.09 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06885963781638182		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.06885963781638182 | validation: 0.09159896469491881]
	TIME [epoch: 9.08 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05242962357396032		[learning rate: 0.00051861]
	Learning Rate: 0.000518611
	LOSS [training: 0.05242962357396032 | validation: 0.0584021884504788]
	TIME [epoch: 9.07 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04125072693851465		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.04125072693851465 | validation: 0.05220727186424794]
	TIME [epoch: 9.08 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033570113038764685		[learning rate: 0.0005161]
	Learning Rate: 0.000516104
	LOSS [training: 0.033570113038764685 | validation: 0.03996603995223644]
	TIME [epoch: 9.07 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026815589065062085		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.026815589065062085 | validation: 0.03151579633496777]
	TIME [epoch: 9.1 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03127238293609916		[learning rate: 0.00051361]
	Learning Rate: 0.000513608
	LOSS [training: 0.03127238293609916 | validation: 0.04130872980311194]
	TIME [epoch: 9.08 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04297390372302309		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.04297390372302309 | validation: 0.04902944870771243]
	TIME [epoch: 9.08 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024812490198317706		[learning rate: 0.00051112]
	Learning Rate: 0.000511124
	LOSS [training: 0.024812490198317706 | validation: 0.031622437911939444]
	TIME [epoch: 9.08 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02641100348551805		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.02641100348551805 | validation: 0.028071564868147467]
	TIME [epoch: 9.09 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022377204509395596		[learning rate: 0.00050865]
	Learning Rate: 0.000508652
	LOSS [training: 0.022377204509395596 | validation: 0.025625128215879915]
	TIME [epoch: 9.08 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027489727738252014		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.027489727738252014 | validation: 0.03936027441070521]
	TIME [epoch: 9.07 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023177981126603027		[learning rate: 0.00050619]
	Learning Rate: 0.000506193
	LOSS [training: 0.023177981126603027 | validation: 0.03892179190498947]
	TIME [epoch: 9.07 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02319991157999831		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.02319991157999831 | validation: 0.02370271646606418]
	TIME [epoch: 9.08 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01745409292639672		[learning rate: 0.00050374]
	Learning Rate: 0.000503745
	LOSS [training: 0.01745409292639672 | validation: 0.020743644681416127]
	TIME [epoch: 9.1 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012893222961603445		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.012893222961603445 | validation: 0.020275745869275927]
	TIME [epoch: 9.07 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012419790283310353		[learning rate: 0.00050131]
	Learning Rate: 0.000501309
	LOSS [training: 0.012419790283310353 | validation: 0.01839736243276748]
	TIME [epoch: 9.07 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013822355277393283		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: 0.013822355277393283 | validation: 0.024516094058996636]
	TIME [epoch: 9.07 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023817569415098192		[learning rate: 0.00049888]
	Learning Rate: 0.000498885
	LOSS [training: 0.023817569415098192 | validation: 0.023083962446180193]
	TIME [epoch: 9.08 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015448466839882189		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.015448466839882189 | validation: 0.012450353700967674]
	TIME [epoch: 9.09 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010758323699046		[learning rate: 0.00049647]
	Learning Rate: 0.000496472
	LOSS [training: 0.010758323699046 | validation: 0.01368347552779397]
	TIME [epoch: 9.07 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01350956595708232		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.01350956595708232 | validation: 0.020342959832913014]
	TIME [epoch: 9.07 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01341238228059946		[learning rate: 0.00049407]
	Learning Rate: 0.000494071
	LOSS [training: 0.01341238228059946 | validation: 0.018916605698192878]
	TIME [epoch: 9.07 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010948604904598426		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.010948604904598426 | validation: 0.02662044913457568]
	TIME [epoch: 9.09 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015568529070223		[learning rate: 0.00049168]
	Learning Rate: 0.000491682
	LOSS [training: 0.015568529070223 | validation: 0.020780588351417544]
	TIME [epoch: 9.07 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009914747179892077		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.009914747179892077 | validation: 0.027123888098717703]
	TIME [epoch: 9.07 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015119116741536768		[learning rate: 0.0004893]
	Learning Rate: 0.000489304
	LOSS [training: 0.015119116741536768 | validation: 0.027622815115458648]
	TIME [epoch: 9.07 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020531392410621706		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.020531392410621706 | validation: 0.019405436894791843]
	TIME [epoch: 9.07 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012087696838617362		[learning rate: 0.00048694]
	Learning Rate: 0.000486938
	LOSS [training: 0.012087696838617362 | validation: 0.01213797326836314]
	TIME [epoch: 9.09 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01030822472351675		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.01030822472351675 | validation: 0.014504364844620593]
	TIME [epoch: 9.06 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010951162079747128		[learning rate: 0.00048458]
	Learning Rate: 0.000484583
	LOSS [training: 0.010951162079747128 | validation: 0.03226221790839218]
	TIME [epoch: 9.08 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019728561750205608		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.019728561750205608 | validation: 0.028371405736127505]
	TIME [epoch: 9.07 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011084287481099625		[learning rate: 0.00048224]
	Learning Rate: 0.00048224
	LOSS [training: 0.011084287481099625 | validation: 0.011096577600877351]
	TIME [epoch: 9.09 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022442698449611685		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.022442698449611685 | validation: 0.017341800750648714]
	TIME [epoch: 9.08 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023595141043770064		[learning rate: 0.00047991]
	Learning Rate: 0.000479908
	LOSS [training: 0.023595141043770064 | validation: 0.026514192077100467]
	TIME [epoch: 9.08 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024145286436044307		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: 0.024145286436044307 | validation: 0.020925530747977636]
	TIME [epoch: 9.08 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016209415338685855		[learning rate: 0.00047759]
	Learning Rate: 0.000477587
	LOSS [training: 0.016209415338685855 | validation: 0.024673354739928252]
	TIME [epoch: 9.08 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022025585841147534		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.022025585841147534 | validation: 0.027968073665112038]
	TIME [epoch: 9.11 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019809207699428236		[learning rate: 0.00047528]
	Learning Rate: 0.000475278
	LOSS [training: 0.019809207699428236 | validation: -0.0005974896561933007]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_1357.pth
	Model improved!!!
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013213063314998413		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.013213063314998413 | validation: 0.01802017367397315]
	TIME [epoch: 9.08 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010782657998904311		[learning rate: 0.00047298]
	Learning Rate: 0.000472979
	LOSS [training: 0.010782657998904311 | validation: 0.02800128708963786]
	TIME [epoch: 9.08 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015489132443718984		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.015489132443718984 | validation: 0.029911886033538677]
	TIME [epoch: 9.07 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01777898594176387		[learning rate: 0.00047069]
	Learning Rate: 0.000470692
	LOSS [training: 0.01777898594176387 | validation: 0.009547335658097877]
	TIME [epoch: 9.08 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00692851939638941		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: 0.00692851939638941 | validation: 0.005917591464467367]
	TIME [epoch: 9.07 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016304311882024358		[learning rate: 0.00046842]
	Learning Rate: 0.000468416
	LOSS [training: 0.016304311882024358 | validation: 0.013213623674507395]
	TIME [epoch: 9.08 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006767711367225243		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: 0.006767711367225243 | validation: 0.019551195942683612]
	TIME [epoch: 9.07 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008850928216778183		[learning rate: 0.00046615]
	Learning Rate: 0.000466151
	LOSS [training: 0.008850928216778183 | validation: 0.01567791394956917]
	TIME [epoch: 9.09 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01350686902526826		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 0.01350686902526826 | validation: 0.008192315394017472]
	TIME [epoch: 9.08 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010189964321552147		[learning rate: 0.0004639]
	Learning Rate: 0.000463896
	LOSS [training: 0.010189964321552147 | validation: 0.025677358446786938]
	TIME [epoch: 9.08 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025258462130341885		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: 0.025258462130341885 | validation: 0.025816736820905937]
	TIME [epoch: 9.09 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022360680649307654		[learning rate: 0.00046165]
	Learning Rate: 0.000461653
	LOSS [training: 0.022360680649307654 | validation: 0.036548739513812475]
	TIME [epoch: 9.1 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019411975854096996		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.019411975854096996 | validation: 0.030139546487554406]
	TIME [epoch: 9.08 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02010302235279604		[learning rate: 0.00045942]
	Learning Rate: 0.000459421
	LOSS [training: 0.02010302235279604 | validation: 0.019058805520558966]
	TIME [epoch: 9.07 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021174792443047513		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.021174792443047513 | validation: 0.018727252120342534]
	TIME [epoch: 9.07 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021050690132446002		[learning rate: 0.0004572]
	Learning Rate: 0.000457199
	LOSS [training: 0.021050690132446002 | validation: 0.0061808939371264075]
	TIME [epoch: 9.07 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012552414890070196		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.012552414890070196 | validation: 0.017844446354186267]
	TIME [epoch: 9.1 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00785692344460807		[learning rate: 0.00045499]
	Learning Rate: 0.000454988
	LOSS [training: 0.00785692344460807 | validation: 0.014469578381376236]
	TIME [epoch: 9.08 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01156577742839728		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: 0.01156577742839728 | validation: 0.00507856366421646]
	TIME [epoch: 9.08 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012392896387747578		[learning rate: 0.00045279]
	Learning Rate: 0.000452788
	LOSS [training: 0.012392896387747578 | validation: 0.019808099657639106]
	TIME [epoch: 9.08 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017110692534478736		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.017110692534478736 | validation: 0.024012851549743735]
	TIME [epoch: 9.07 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008049549555754893		[learning rate: 0.0004506]
	Learning Rate: 0.000450598
	LOSS [training: 0.008049549555754893 | validation: 0.014382474116690616]
	TIME [epoch: 9.1 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010290354503726869		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: 0.010290354503726869 | validation: 0.007670782327964231]
	TIME [epoch: 9.08 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018922321143136085		[learning rate: 0.00044842]
	Learning Rate: 0.000448419
	LOSS [training: 0.018922321143136085 | validation: 0.024155507195139456]
	TIME [epoch: 9.09 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03476524468219053		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.03476524468219053 | validation: 0.05813105090393222]
	TIME [epoch: 9.08 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04044197958372658		[learning rate: 0.00044625]
	Learning Rate: 0.000446251
	LOSS [training: 0.04044197958372658 | validation: 0.01822363254557912]
	TIME [epoch: 9.1 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017288412847890094		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.017288412847890094 | validation: 0.022550816661593566]
	TIME [epoch: 9.08 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018734109928815912		[learning rate: 0.00044409]
	Learning Rate: 0.000444093
	LOSS [training: 0.018734109928815912 | validation: 0.028808375348110496]
	TIME [epoch: 9.08 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025605552647018047		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: 0.025605552647018047 | validation: 0.04346397882390271]
	TIME [epoch: 9.08 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02402180670856328		[learning rate: 0.00044195]
	Learning Rate: 0.000441945
	LOSS [training: 0.02402180670856328 | validation: 0.016852147380611564]
	TIME [epoch: 9.08 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017185770084067496		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.017185770084067496 | validation: 0.016598681425662485]
	TIME [epoch: 9.1 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02202201541628255		[learning rate: 0.00043981]
	Learning Rate: 0.000439808
	LOSS [training: 0.02202201541628255 | validation: 0.017007798089255448]
	TIME [epoch: 9.07 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01748049348153379		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.01748049348153379 | validation: 0.018814670062780647]
	TIME [epoch: 9.07 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014080279277741196		[learning rate: 0.00043768]
	Learning Rate: 0.000437681
	LOSS [training: 0.014080279277741196 | validation: 0.007710008636286014]
	TIME [epoch: 9.08 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013896627248476881		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: 0.013896627248476881 | validation: 0.00880508308933939]
	TIME [epoch: 9.09 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019067422224827078		[learning rate: 0.00043556]
	Learning Rate: 0.000435565
	LOSS [training: 0.019067422224827078 | validation: 0.03553714928968735]
	TIME [epoch: 9.1 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015203558145567486		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: 0.015203558145567486 | validation: 0.020001300282076244]
	TIME [epoch: 9.09 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023971538371386884		[learning rate: 0.00043346]
	Learning Rate: 0.000433458
	LOSS [training: 0.023971538371386884 | validation: 0.04008837891757655]
	TIME [epoch: 9.08 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025819264062685567		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.025819264062685567 | validation: 0.02826460618562705]
	TIME [epoch: 9.07 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016603598059211237		[learning rate: 0.00043136]
	Learning Rate: 0.000431362
	LOSS [training: 0.016603598059211237 | validation: 0.031800446340378374]
	TIME [epoch: 9.09 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021325826301227254		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.021325826301227254 | validation: 0.021500013495169765]
	TIME [epoch: 9.06 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018578137704980287		[learning rate: 0.00042928]
	Learning Rate: 0.000429276
	LOSS [training: 0.018578137704980287 | validation: 0.02090562880910449]
	TIME [epoch: 9.07 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010094698379580944		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: 0.010094698379580944 | validation: 0.010565364718013219]
	TIME [epoch: 9.07 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018909417945500304		[learning rate: 0.0004272]
	Learning Rate: 0.0004272
	LOSS [training: 0.018909417945500304 | validation: 0.02183016694278706]
	TIME [epoch: 9.08 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02075368330611132		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.02075368330611132 | validation: 0.02403632466701152]
	TIME [epoch: 9.08 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01956884065898978		[learning rate: 0.00042513]
	Learning Rate: 0.000425134
	LOSS [training: 0.01956884065898978 | validation: 0.01753109382227276]
	TIME [epoch: 9.06 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010094694792560348		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: 0.010094694792560348 | validation: 0.016437715538094595]
	TIME [epoch: 9.07 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015006898800383172		[learning rate: 0.00042308]
	Learning Rate: 0.000423079
	LOSS [training: 0.015006898800383172 | validation: 0.007630662700328059]
	TIME [epoch: 9.07 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011975971069284951		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.011975971069284951 | validation: 0.014441655495398917]
	TIME [epoch: 9.1 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011681650946701858		[learning rate: 0.00042103]
	Learning Rate: 0.000421033
	LOSS [training: 0.011681650946701858 | validation: 0.014110394240382669]
	TIME [epoch: 9.07 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011862562834050148		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: 0.011862562834050148 | validation: 0.020342273965333293]
	TIME [epoch: 9.07 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012291804963707628		[learning rate: 0.000419]
	Learning Rate: 0.000418997
	LOSS [training: 0.012291804963707628 | validation: 0.009590665506391512]
	TIME [epoch: 9.07 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013781079084046449		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.013781079084046449 | validation: 0.021496544299341377]
	TIME [epoch: 9.07 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01041849944100679		[learning rate: 0.00041697]
	Learning Rate: 0.00041697
	LOSS [training: 0.01041849944100679 | validation: 0.011143943655745756]
	TIME [epoch: 9.08 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012504071092189279		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.012504071092189279 | validation: 0.015952166744224672]
	TIME [epoch: 9.07 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011073607980088261		[learning rate: 0.00041495]
	Learning Rate: 0.000414954
	LOSS [training: 0.011073607980088261 | validation: 0.01383728032013274]
	TIME [epoch: 9.07 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021905583870509657		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.021905583870509657 | validation: 0.022933773259577326]
	TIME [epoch: 9.07 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014109419477608309		[learning rate: 0.00041295]
	Learning Rate: 0.000412947
	LOSS [training: 0.014109419477608309 | validation: 0.01859826513150994]
	TIME [epoch: 9.09 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01142279706006165		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.01142279706006165 | validation: 0.01636947977051523]
	TIME [epoch: 9.1 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009434553040695692		[learning rate: 0.00041095]
	Learning Rate: 0.00041095
	LOSS [training: 0.009434553040695692 | validation: 0.009125728640544697]
	TIME [epoch: 9.08 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007436579535819865		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.007436579535819865 | validation: 0.009969901295153766]
	TIME [epoch: 9.07 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007668075151225475		[learning rate: 0.00040896]
	Learning Rate: 0.000408963
	LOSS [training: 0.007668075151225475 | validation: 0.014093658726699557]
	TIME [epoch: 9.08 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007847723874950191		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.007847723874950191 | validation: 0.010777657821784538]
	TIME [epoch: 9.09 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004898003227289437		[learning rate: 0.00040699]
	Learning Rate: 0.000406986
	LOSS [training: 0.004898003227289437 | validation: 0.008465417106984615]
	TIME [epoch: 9.08 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008101381433814852		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.008101381433814852 | validation: 0.00870355533154852]
	TIME [epoch: 9.08 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01618042207850968		[learning rate: 0.00040502]
	Learning Rate: 0.000405017
	LOSS [training: 0.01618042207850968 | validation: 0.0015111689320477491]
	TIME [epoch: 9.07 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004116325553169453		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.004116325553169453 | validation: 0.005462996003947201]
	TIME [epoch: 9.08 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007620028235532759		[learning rate: 0.00040306]
	Learning Rate: 0.000403059
	LOSS [training: 0.007620028235532759 | validation: 0.01891731646184602]
	TIME [epoch: 9.09 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005634067456784793		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.005634067456784793 | validation: 0.016231743046815197]
	TIME [epoch: 9.08 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005924502437291463		[learning rate: 0.00040111]
	Learning Rate: 0.00040111
	LOSS [training: 0.005924502437291463 | validation: 0.01594206236801433]
	TIME [epoch: 9.07 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017385572811067302		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.017385572811067302 | validation: 0.021837301774888282]
	TIME [epoch: 9.07 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015948064409749246		[learning rate: 0.00039917]
	Learning Rate: 0.00039917
	LOSS [training: 0.015948064409749246 | validation: 0.022182016762341134]
	TIME [epoch: 9.09 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01036094085781714		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.01036094085781714 | validation: 0.008075207615753236]
	TIME [epoch: 9.07 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00999410919281981		[learning rate: 0.00039724]
	Learning Rate: 0.00039724
	LOSS [training: 0.00999410919281981 | validation: 0.011235362260177205]
	TIME [epoch: 9.08 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008783173202486755		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.008783173202486755 | validation: 0.019390883662980783]
	TIME [epoch: 9.08 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008618841119861376		[learning rate: 0.00039532]
	Learning Rate: 0.000395319
	LOSS [training: 0.008618841119861376 | validation: 0.02459778453079773]
	TIME [epoch: 9.09 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007049161521745026		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.007049161521745026 | validation: 0.01645388397013995]
	TIME [epoch: 9.09 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010419624784877398		[learning rate: 0.00039341]
	Learning Rate: 0.000393407
	LOSS [training: 0.010419624784877398 | validation: 0.012526332385629276]
	TIME [epoch: 9.08 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008213020922075993		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.008213020922075993 | validation: 0.012005981300545893]
	TIME [epoch: 9.07 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010877285563070518		[learning rate: 0.0003915]
	Learning Rate: 0.000391505
	LOSS [training: 0.010877285563070518 | validation: 0.02722735732597854]
	TIME [epoch: 9.07 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013293963833790678		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.013293963833790678 | validation: 0.022993146707971646]
	TIME [epoch: 9.09 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009700955529277862		[learning rate: 0.00038961]
	Learning Rate: 0.000389611
	LOSS [training: 0.009700955529277862 | validation: 0.02439422733491614]
	TIME [epoch: 9.07 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021127136163285442		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.021127136163285442 | validation: 0.026690410918594153]
	TIME [epoch: 9.07 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020944593110974696		[learning rate: 0.00038773]
	Learning Rate: 0.000387727
	LOSS [training: 0.020944593110974696 | validation: 0.03261910911315591]
	TIME [epoch: 9.07 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01722548134327808		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 0.01722548134327808 | validation: 0.02341890769081787]
	TIME [epoch: 9.07 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010564303404656675		[learning rate: 0.00038585]
	Learning Rate: 0.000385852
	LOSS [training: 0.010564303404656675 | validation: 0.01672023257249434]
	TIME [epoch: 9.1 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012893909278934157		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.012893909278934157 | validation: 0.017228443899762243]
	TIME [epoch: 9.06 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010434509411869556		[learning rate: 0.00038399]
	Learning Rate: 0.000383986
	LOSS [training: 0.010434509411869556 | validation: 0.016523006284172193]
	TIME [epoch: 9.08 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009984445372161114		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.009984445372161114 | validation: 0.02538667741213176]
	TIME [epoch: 9.08 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016674258604492682		[learning rate: 0.00038213]
	Learning Rate: 0.000382129
	LOSS [training: 0.016674258604492682 | validation: 0.03935510789286037]
	TIME [epoch: 9.1 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02237685905774402		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.02237685905774402 | validation: 0.019468771776794833]
	TIME [epoch: 9.09 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017124231133268		[learning rate: 0.00038028]
	Learning Rate: 0.000380282
	LOSS [training: 0.017124231133268 | validation: 0.02351121899138575]
	TIME [epoch: 9.07 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01447179131414023		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.01447179131414023 | validation: 0.01434394918625312]
	TIME [epoch: 9.07 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011207440411813915		[learning rate: 0.00037844]
	Learning Rate: 0.000378443
	LOSS [training: 0.011207440411813915 | validation: 0.021993274456493794]
	TIME [epoch: 9.06 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017126430796429296		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.017126430796429296 | validation: 0.03600795117669868]
	TIME [epoch: 9.09 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018997601966834997		[learning rate: 0.00037661]
	Learning Rate: 0.000376612
	LOSS [training: 0.018997601966834997 | validation: 0.01562690723659679]
	TIME [epoch: 9.08 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013303619633765468		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: 0.013303619633765468 | validation: 0.02754108206783086]
	TIME [epoch: 9.07 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016094759884991282		[learning rate: 0.00037479]
	Learning Rate: 0.000374791
	LOSS [training: 0.016094759884991282 | validation: 0.032930336109247386]
	TIME [epoch: 9.08 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012710327965172246		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.012710327965172246 | validation: 0.021521055926094098]
	TIME [epoch: 9.09 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011952621738490845		[learning rate: 0.00037298]
	Learning Rate: 0.000372979
	LOSS [training: 0.011952621738490845 | validation: 0.020382430347002566]
	TIME [epoch: 9.08 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012921830047048551		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.012921830047048551 | validation: 0.02956104071063826]
	TIME [epoch: 9.08 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01491721031787252		[learning rate: 0.00037118]
	Learning Rate: 0.000371175
	LOSS [training: 0.01491721031787252 | validation: 0.021734224062695758]
	TIME [epoch: 9.07 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020137077178706945		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.020137077178706945 | validation: 0.041546588631631604]
	TIME [epoch: 9.08 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041689106004049306		[learning rate: 0.00036938]
	Learning Rate: 0.00036938
	LOSS [training: 0.041689106004049306 | validation: 0.04585901703855326]
	TIME [epoch: 9.07 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02567239042092756		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.02567239042092756 | validation: 0.031175828582171054]
	TIME [epoch: 9.07 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029247446045772063		[learning rate: 0.00036759]
	Learning Rate: 0.000367594
	LOSS [training: 0.029247446045772063 | validation: 0.028432803097178314]
	TIME [epoch: 9.07 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025807979800610427		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: 0.025807979800610427 | validation: 0.029418621866304142]
	TIME [epoch: 9.06 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03358357588292773		[learning rate: 0.00036582]
	Learning Rate: 0.000365816
	LOSS [training: 0.03358357588292773 | validation: 0.04384245481755477]
	TIME [epoch: 9.07 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029507556720378685		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.029507556720378685 | validation: 0.03556820982669129]
	TIME [epoch: 9.09 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024814246163501207		[learning rate: 0.00036405]
	Learning Rate: 0.000364047
	LOSS [training: 0.024814246163501207 | validation: 0.03859092817798476]
	TIME [epoch: 9.07 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035018954661184654		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.035018954661184654 | validation: 0.05029028180595539]
	TIME [epoch: 9.07 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04241550157022549		[learning rate: 0.00036229]
	Learning Rate: 0.000362287
	LOSS [training: 0.04241550157022549 | validation: 0.06144619863578131]
	TIME [epoch: 9.07 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03657838830208637		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: 0.03657838830208637 | validation: 0.035001746427149705]
	TIME [epoch: 9.08 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029391020271724855		[learning rate: 0.00036053]
	Learning Rate: 0.000360535
	LOSS [training: 0.029391020271724855 | validation: 0.03243071422338837]
	TIME [epoch: 9.07 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013823849122187265		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.013823849122187265 | validation: 0.018922479079450865]
	TIME [epoch: 9.07 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013418589685432228		[learning rate: 0.00035879]
	Learning Rate: 0.000358791
	LOSS [training: 0.013418589685432228 | validation: 0.01397066556004642]
	TIME [epoch: 9.07 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01570062240501234		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.01570062240501234 | validation: 0.02328902844310823]
	TIME [epoch: 9.07 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014950069856618203		[learning rate: 0.00035706]
	Learning Rate: 0.000357056
	LOSS [training: 0.014950069856618203 | validation: 0.02080084930603527]
	TIME [epoch: 9.1 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01422391064861384		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.01422391064861384 | validation: 0.019725360292374712]
	TIME [epoch: 9.08 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01952269657796198		[learning rate: 0.00035533]
	Learning Rate: 0.00035533
	LOSS [training: 0.01952269657796198 | validation: 0.01575082376192428]
	TIME [epoch: 9.06 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01062613198044865		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.01062613198044865 | validation: 0.027678471757565694]
	TIME [epoch: 9.08 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010316043741882181		[learning rate: 0.00035361]
	Learning Rate: 0.000353611
	LOSS [training: 0.010316043741882181 | validation: 0.03111771263333695]
	TIME [epoch: 9.08 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016246682109858808		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: 0.016246682109858808 | validation: 0.024783445063727184]
	TIME [epoch: 9.08 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015360047295319753		[learning rate: 0.0003519]
	Learning Rate: 0.000351901
	LOSS [training: 0.015360047295319753 | validation: 0.022187106436425127]
	TIME [epoch: 9.08 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011292873694646618		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: 0.011292873694646618 | validation: 0.03172092294208234]
	TIME [epoch: 9.07 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016790379597492962		[learning rate: 0.0003502]
	Learning Rate: 0.0003502
	LOSS [training: 0.016790379597492962 | validation: 0.021509568292989868]
	TIME [epoch: 9.08 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007060219733135852		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.007060219733135852 | validation: 0.018135069626246125]
	TIME [epoch: 9.09 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01425949582072152		[learning rate: 0.00034851]
	Learning Rate: 0.000348506
	LOSS [training: 0.01425949582072152 | validation: 0.015180531994579952]
	TIME [epoch: 9.07 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01829267686223374		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.01829267686223374 | validation: 0.03566686223850661]
	TIME [epoch: 9.08 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013899361743218666		[learning rate: 0.00034682]
	Learning Rate: 0.000346821
	LOSS [training: 0.013899361743218666 | validation: 0.018773138922575434]
	TIME [epoch: 9.07 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013376198116106398		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: 0.013376198116106398 | validation: 0.02003839003067575]
	TIME [epoch: 9.09 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02207993216886684		[learning rate: 0.00034514]
	Learning Rate: 0.000345144
	LOSS [training: 0.02207993216886684 | validation: 0.023158449604714172]
	TIME [epoch: 9.08 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020337197725315836		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: 0.020337197725315836 | validation: 0.04495187165887656]
	TIME [epoch: 9.07 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03454723537670544		[learning rate: 0.00034347]
	Learning Rate: 0.000343475
	LOSS [training: 0.03454723537670544 | validation: 0.049145500286952255]
	TIME [epoch: 9.07 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03452607269018286		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.03452607269018286 | validation: 0.037204093026574986]
	TIME [epoch: 9.07 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02007054230537088		[learning rate: 0.00034181]
	Learning Rate: 0.000341814
	LOSS [training: 0.02007054230537088 | validation: 0.041324483828808004]
	TIME [epoch: 9.09 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027210046579934827		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.027210046579934827 | validation: 0.0346847107465998]
	TIME [epoch: 9.08 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03493643154922452		[learning rate: 0.00034016]
	Learning Rate: 0.000340161
	LOSS [training: 0.03493643154922452 | validation: 0.055860160959477795]
	TIME [epoch: 9.07 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032832401702419925		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: 0.032832401702419925 | validation: 0.048146259102858614]
	TIME [epoch: 9.07 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02544480273813231		[learning rate: 0.00033852]
	Learning Rate: 0.000338516
	LOSS [training: 0.02544480273813231 | validation: 0.04951583453822622]
	TIME [epoch: 9.06 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026500850523290348		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.026500850523290348 | validation: 0.03172161902539111]
	TIME [epoch: 9.09 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02177501986628665		[learning rate: 0.00033688]
	Learning Rate: 0.000336879
	LOSS [training: 0.02177501986628665 | validation: 0.031155298239993245]
	TIME [epoch: 9.08 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02048674168888957		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.02048674168888957 | validation: 0.02886308597940729]
	TIME [epoch: 9.07 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018767701143920342		[learning rate: 0.00033525]
	Learning Rate: 0.00033525
	LOSS [training: 0.018767701143920342 | validation: 0.032049762943535294]
	TIME [epoch: 9.07 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02347489965621148		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: 0.02347489965621148 | validation: 0.02308446288249948]
	TIME [epoch: 9.08 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020683878889878014		[learning rate: 0.00033363]
	Learning Rate: 0.000333629
	LOSS [training: 0.020683878889878014 | validation: 0.03350438029724954]
	TIME [epoch: 9.06 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017341899730066203		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.017341899730066203 | validation: 0.02988524999421508]
	TIME [epoch: 9.08 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01880468949134246		[learning rate: 0.00033202]
	Learning Rate: 0.000332015
	LOSS [training: 0.01880468949134246 | validation: 0.01708885531758947]
	TIME [epoch: 9.07 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016925290723331207		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.016925290723331207 | validation: 0.030840086605500503]
	TIME [epoch: 9.08 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020558830246416398		[learning rate: 0.00033041]
	Learning Rate: 0.00033041
	LOSS [training: 0.020558830246416398 | validation: 0.027688659780423876]
	TIME [epoch: 9.09 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011835434544498896		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: 0.011835434544498896 | validation: 0.01487575319480549]
	TIME [epoch: 9.07 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013051932772930912		[learning rate: 0.00032881]
	Learning Rate: 0.000328812
	LOSS [training: 0.013051932772930912 | validation: 0.011758707375764288]
	TIME [epoch: 9.06 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016010166151143874		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: 0.016010166151143874 | validation: 0.012670854762434007]
	TIME [epoch: 9.07 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015299856037689541		[learning rate: 0.00032722]
	Learning Rate: 0.000327222
	LOSS [training: 0.015299856037689541 | validation: 0.036152702041071696]
	TIME [epoch: 9.08 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025175754228255003		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.025175754228255003 | validation: 0.024882807132865437]
	TIME [epoch: 9.09 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011415600284287867		[learning rate: 0.00032564]
	Learning Rate: 0.000325639
	LOSS [training: 0.011415600284287867 | validation: 0.022633424054472006]
	TIME [epoch: 9.06 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016595229020009154		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: 0.016595229020009154 | validation: 0.023298578641141487]
	TIME [epoch: 9.07 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01379562920581565		[learning rate: 0.00032406]
	Learning Rate: 0.000324065
	LOSS [training: 0.01379562920581565 | validation: 0.03758225073989012]
	TIME [epoch: 9.07 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026367326449488564		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: 0.026367326449488564 | validation: 0.03628603718237805]
	TIME [epoch: 9.09 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02252880168858946		[learning rate: 0.0003225]
	Learning Rate: 0.000322497
	LOSS [training: 0.02252880168858946 | validation: 0.06170968242840506]
	TIME [epoch: 9.07 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039401636214287675		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: 0.039401636214287675 | validation: 0.038713248681842685]
	TIME [epoch: 9.07 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03278351555635704		[learning rate: 0.00032094]
	Learning Rate: 0.000320938
	LOSS [training: 0.03278351555635704 | validation: 0.04059489566869531]
	TIME [epoch: 9.07 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02229995732703566		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: 0.02229995732703566 | validation: 0.0169727449171943]
	TIME [epoch: 9.08 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021154331882974747		[learning rate: 0.00031939]
	Learning Rate: 0.000319386
	LOSS [training: 0.021154331882974747 | validation: 0.014085730449126335]
	TIME [epoch: 9.08 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022077759212872323		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.022077759212872323 | validation: 0.02498977538874685]
	TIME [epoch: 9.07 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018022850092371596		[learning rate: 0.00031784]
	Learning Rate: 0.000317841
	LOSS [training: 0.018022850092371596 | validation: 0.022721454024694318]
	TIME [epoch: 9.07 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020531444256101893		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.020531444256101893 | validation: 0.015508657981790682]
	TIME [epoch: 9.07 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017308709956584404		[learning rate: 0.0003163]
	Learning Rate: 0.000316304
	LOSS [training: 0.017308709956584404 | validation: 0.027773053739886346]
	TIME [epoch: 9.09 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01001635495637231		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.01001635495637231 | validation: 0.015020060640937388]
	TIME [epoch: 9.08 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008683053846762531		[learning rate: 0.00031477]
	Learning Rate: 0.000314775
	LOSS [training: 0.008683053846762531 | validation: 0.0219769184515315]
	TIME [epoch: 9.08 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01792154815186513		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.01792154815186513 | validation: 0.030879415046158695]
	TIME [epoch: 9.08 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025250018341060228		[learning rate: 0.00031325]
	Learning Rate: 0.000313253
	LOSS [training: 0.025250018341060228 | validation: 0.030399745319328424]
	TIME [epoch: 9.08 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01841292440088712		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.01841292440088712 | validation: 0.029574484879449005]
	TIME [epoch: 9.09 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022532106456154097		[learning rate: 0.00031174]
	Learning Rate: 0.000311738
	LOSS [training: 0.022532106456154097 | validation: 0.014103509810279326]
	TIME [epoch: 9.08 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020622571191740983		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: 0.020622571191740983 | validation: 0.020311092822297237]
	TIME [epoch: 9.08 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01824131427523589		[learning rate: 0.00031023]
	Learning Rate: 0.00031023
	LOSS [training: 0.01824131427523589 | validation: 0.026873915973989207]
	TIME [epoch: 9.07 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014922241310771547		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: 0.014922241310771547 | validation: 0.021895233657242753]
	TIME [epoch: 9.09 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017665601970829815		[learning rate: 0.00030873]
	Learning Rate: 0.00030873
	LOSS [training: 0.017665601970829815 | validation: 0.023357854636211428]
	TIME [epoch: 9.08 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015171511695523568		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.015171511695523568 | validation: 0.023375141807863986]
	TIME [epoch: 9.07 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024015287011036737		[learning rate: 0.00030724]
	Learning Rate: 0.000307237
	LOSS [training: 0.024015287011036737 | validation: 0.036568752693197766]
	TIME [epoch: 9.06 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02752094279741384		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: 0.02752094279741384 | validation: 0.022223357375214293]
	TIME [epoch: 9.07 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026739164901188866		[learning rate: 0.00030575]
	Learning Rate: 0.000305751
	LOSS [training: 0.026739164901188866 | validation: 0.04470760185967981]
	TIME [epoch: 9.1 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0309456721491705		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: 0.0309456721491705 | validation: 0.045793028454207144]
	TIME [epoch: 9.07 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029987368827001433		[learning rate: 0.00030427]
	Learning Rate: 0.000304273
	LOSS [training: 0.029987368827001433 | validation: 0.023875183574306433]
	TIME [epoch: 9.06 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019766106488490615		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.019766106488490615 | validation: 0.029305845081852182]
	TIME [epoch: 9.07 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017743274561848432		[learning rate: 0.0003028]
	Learning Rate: 0.000302801
	LOSS [training: 0.017743274561848432 | validation: 0.02954637904812131]
	TIME [epoch: 9.07 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025928635131837983		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: 0.025928635131837983 | validation: 0.037710873169994594]
	TIME [epoch: 9.08 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027759436567287143		[learning rate: 0.00030134]
	Learning Rate: 0.000301337
	LOSS [training: 0.027759436567287143 | validation: 0.026529673552365705]
	TIME [epoch: 9.06 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019867733618789105		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.019867733618789105 | validation: 0.03412891450221707]
	TIME [epoch: 9.06 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02577719492514412		[learning rate: 0.00029988]
	Learning Rate: 0.00029988
	LOSS [training: 0.02577719492514412 | validation: 0.03069096483795401]
	TIME [epoch: 9.07 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02408640617829878		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: 0.02408640617829878 | validation: 0.03160135767297364]
	TIME [epoch: 9.09 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021945087148540297		[learning rate: 0.00029843]
	Learning Rate: 0.00029843
	LOSS [training: 0.021945087148540297 | validation: 0.030206195407403]
	TIME [epoch: 9.08 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017328500115507222		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: 0.017328500115507222 | validation: 0.019818049423255747]
	TIME [epoch: 9.07 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01373828307924238		[learning rate: 0.00029699]
	Learning Rate: 0.000296987
	LOSS [training: 0.01373828307924238 | validation: 0.018120500412751785]
	TIME [epoch: 9.07 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01481251723918986		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.01481251723918986 | validation: 0.01736686066388259]
	TIME [epoch: 9.09 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014714621142989635		[learning rate: 0.00029555]
	Learning Rate: 0.00029555
	LOSS [training: 0.014714621142989635 | validation: 0.03394483414234389]
	TIME [epoch: 9.08 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012500122276925018		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: 0.012500122276925018 | validation: 0.015198394698511171]
	TIME [epoch: 9.07 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012842974993807033		[learning rate: 0.00029412]
	Learning Rate: 0.000294121
	LOSS [training: 0.012842974993807033 | validation: 0.021661153951533063]
	TIME [epoch: 9.07 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015125658630215463		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: 0.015125658630215463 | validation: 0.016519610494561826]
	TIME [epoch: 9.07 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015934770167341215		[learning rate: 0.0002927]
	Learning Rate: 0.000292699
	LOSS [training: 0.015934770167341215 | validation: 0.019921242796812157]
	TIME [epoch: 9.09 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012586888394083475		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: 0.012586888394083475 | validation: 0.020038000432093066]
	TIME [epoch: 9.08 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01094467654131203		[learning rate: 0.00029128]
	Learning Rate: 0.000291283
	LOSS [training: 0.01094467654131203 | validation: 0.025201319591596695]
	TIME [epoch: 9.08 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013040293998072989		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: 0.013040293998072989 | validation: 0.014853392033910662]
	TIME [epoch: 9.08 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008421948646020933		[learning rate: 0.00028987]
	Learning Rate: 0.000289875
	LOSS [training: 0.008421948646020933 | validation: 0.016606422618137516]
	TIME [epoch: 9.08 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01577476388843007		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: 0.01577476388843007 | validation: 0.03402200699975148]
	TIME [epoch: 9.09 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019750553133835325		[learning rate: 0.00028847]
	Learning Rate: 0.000288473
	LOSS [training: 0.019750553133835325 | validation: 0.027653807595204104]
	TIME [epoch: 9.07 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01455951144950103		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: 0.01455951144950103 | validation: 0.016944204310785128]
	TIME [epoch: 9.08 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009069369061546765		[learning rate: 0.00028708]
	Learning Rate: 0.000287078
	LOSS [training: 0.009069369061546765 | validation: 0.019450819665949616]
	TIME [epoch: 9.08 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00812117564848704		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: 0.00812117564848704 | validation: 0.01678246872896151]
	TIME [epoch: 9.1 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010304778965325279		[learning rate: 0.00028569]
	Learning Rate: 0.00028569
	LOSS [training: 0.010304778965325279 | validation: 0.0017551042858141887]
	TIME [epoch: 9.08 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009356602236019711		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: 0.009356602236019711 | validation: 0.018706620417057354]
	TIME [epoch: 9.08 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018435228835417358		[learning rate: 0.00028431]
	Learning Rate: 0.000284308
	LOSS [training: 0.018435228835417358 | validation: 0.033250522293679884]
	TIME [epoch: 9.08 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020479295741021475		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: 0.020479295741021475 | validation: 0.03598077719338927]
	TIME [epoch: 9.08 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035985636160102065		[learning rate: 0.00028293]
	Learning Rate: 0.000282933
	LOSS [training: 0.035985636160102065 | validation: 0.04098686386319621]
	TIME [epoch: 9.09 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033815587089924666		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.033815587089924666 | validation: 0.029872979459334502]
	TIME [epoch: 9.07 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024262401684650055		[learning rate: 0.00028157]
	Learning Rate: 0.000281565
	LOSS [training: 0.024262401684650055 | validation: 0.028043878754234225]
	TIME [epoch: 9.08 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019295771469070355		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: 0.019295771469070355 | validation: 0.02737609858804521]
	TIME [epoch: 9.08 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034372159017905586		[learning rate: 0.0002802]
	Learning Rate: 0.000280204
	LOSS [training: 0.034372159017905586 | validation: 0.029190659155437323]
	TIME [epoch: 9.09 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021963023902166114		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: 0.021963023902166114 | validation: 0.026041612167499593]
	TIME [epoch: 9.09 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015797177643833118		[learning rate: 0.00027885]
	Learning Rate: 0.000278849
	LOSS [training: 0.015797177643833118 | validation: 0.025945762854011283]
	TIME [epoch: 9.08 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015496615823462572		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: 0.015496615823462572 | validation: 0.02596802096937237]
	TIME [epoch: 9.08 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015358759447121575		[learning rate: 0.0002775]
	Learning Rate: 0.0002775
	LOSS [training: 0.015358759447121575 | validation: 0.014269083383717254]
	TIME [epoch: 9.08 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01706763430310503		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: 0.01706763430310503 | validation: 0.018954329732543216]
	TIME [epoch: 9.1 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010966604653723355		[learning rate: 0.00027616]
	Learning Rate: 0.000276158
	LOSS [training: 0.010966604653723355 | validation: 0.016786393267464787]
	TIME [epoch: 9.08 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011103477055479889		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: 0.011103477055479889 | validation: 0.028194602461693974]
	TIME [epoch: 9.08 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015750950933683484		[learning rate: 0.00027482]
	Learning Rate: 0.000274823
	LOSS [training: 0.015750950933683484 | validation: 0.009195661305454891]
	TIME [epoch: 9.08 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01268808199714697		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: 0.01268808199714697 | validation: 0.025594398244838806]
	TIME [epoch: 9.08 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024054295298156683		[learning rate: 0.00027349]
	Learning Rate: 0.000273494
	LOSS [training: 0.024054295298156683 | validation: 0.023752942416904933]
	TIME [epoch: 9.09 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011412944729358894		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: 0.011412944729358894 | validation: 0.017002979081244284]
	TIME [epoch: 9.08 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011783091783728012		[learning rate: 0.00027217]
	Learning Rate: 0.000272171
	LOSS [training: 0.011783091783728012 | validation: 0.026692223025439745]
	TIME [epoch: 9.07 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018032287244740233		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 0.018032287244740233 | validation: 0.018035220501948713]
	TIME [epoch: 9.08 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014663674166937677		[learning rate: 0.00027086]
	Learning Rate: 0.000270855
	LOSS [training: 0.014663674166937677 | validation: 0.006060468813593685]
	TIME [epoch: 9.08 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012224437465814243		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: 0.012224437465814243 | validation: 0.012008715101879366]
	TIME [epoch: 9.08 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012026631326602807		[learning rate: 0.00026955]
	Learning Rate: 0.000269545
	LOSS [training: 0.012026631326602807 | validation: 0.021943942438349368]
	TIME [epoch: 9.09 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01113602009676896		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: 0.01113602009676896 | validation: 0.010755868750428858]
	TIME [epoch: 9.07 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015150382288470631		[learning rate: 0.00026824]
	Learning Rate: 0.000268242
	LOSS [training: 0.015150382288470631 | validation: 0.022275933785154536]
	TIME [epoch: 9.08 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01333753488574349		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: 0.01333753488574349 | validation: 0.01963400543539119]
	TIME [epoch: 9.09 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007845626774445355		[learning rate: 0.00026694]
	Learning Rate: 0.000266945
	LOSS [training: 0.007845626774445355 | validation: 0.0200096669067632]
	TIME [epoch: 9.07 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011053529326958448		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.011053529326958448 | validation: 0.012560425787764045]
	TIME [epoch: 9.07 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012967619395853506		[learning rate: 0.00026565]
	Learning Rate: 0.000265654
	LOSS [training: 0.012967619395853506 | validation: 0.013070557933208393]
	TIME [epoch: 9.07 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010558440784669759		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.010558440784669759 | validation: 0.008253906209840182]
	TIME [epoch: 9.09 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014104806244384187		[learning rate: 0.00026437]
	Learning Rate: 0.000264369
	LOSS [training: 0.014104806244384187 | validation: 0.016366884033127773]
	TIME [epoch: 9.07 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012852814935747478		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: 0.012852814935747478 | validation: 0.019324152298626968]
	TIME [epoch: 9.07 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018905061518349343		[learning rate: 0.00026309]
	Learning Rate: 0.000263091
	LOSS [training: 0.018905061518349343 | validation: 0.020921813754916148]
	TIME [epoch: 9.08 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007737444780640643		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: 0.007737444780640643 | validation: 0.01617749238251858]
	TIME [epoch: 9.07 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009229372126246988		[learning rate: 0.00026182]
	Learning Rate: 0.000261818
	LOSS [training: 0.009229372126246988 | validation: 0.012684824421480745]
	TIME [epoch: 9.1 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011636365983259839		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: 0.011636365983259839 | validation: 0.01221733389143315]
	TIME [epoch: 9.08 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007919897795973872		[learning rate: 0.00026055]
	Learning Rate: 0.000260552
	LOSS [training: 0.007919897795973872 | validation: 0.008356390877955176]
	TIME [epoch: 9.07 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009709526640753042		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: 0.009709526640753042 | validation: 0.015304227441733553]
	TIME [epoch: 9.07 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009613781541905368		[learning rate: 0.00025929]
	Learning Rate: 0.000259292
	LOSS [training: 0.009613781541905368 | validation: 0.009943260555599484]
	TIME [epoch: 9.08 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009619525580412569		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.009619525580412569 | validation: 0.016656580875336634]
	TIME [epoch: 9.09 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008532230455563065		[learning rate: 0.00025804]
	Learning Rate: 0.000258038
	LOSS [training: 0.008532230455563065 | validation: 0.014613980482264222]
	TIME [epoch: 9.07 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011391017004782048		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: 0.011391017004782048 | validation: 0.019732070911724582]
	TIME [epoch: 9.08 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012584566862025682		[learning rate: 0.00025679]
	Learning Rate: 0.00025679
	LOSS [training: 0.012584566862025682 | validation: 0.019708498604809617]
	TIME [epoch: 9.07 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01324213547687535		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: 0.01324213547687535 | validation: 0.01903189654874683]
	TIME [epoch: 9.09 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010891686293115233		[learning rate: 0.00025555]
	Learning Rate: 0.000255549
	LOSS [training: 0.010891686293115233 | validation: 0.003593158136312202]
	TIME [epoch: 9.07 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006050434522653565		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: 0.006050434522653565 | validation: 0.018608992788285948]
	TIME [epoch: 9.06 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012828805033462027		[learning rate: 0.00025431]
	Learning Rate: 0.000254313
	LOSS [training: 0.012828805033462027 | validation: 0.014261350772946595]
	TIME [epoch: 9.08 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016537900510498846		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: 0.016537900510498846 | validation: 0.022083681212929262]
	TIME [epoch: 9.08 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01384552101202105		[learning rate: 0.00025308]
	Learning Rate: 0.000253083
	LOSS [training: 0.01384552101202105 | validation: 0.012193054461395255]
	TIME [epoch: 9.09 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014637059726136112		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: 0.014637059726136112 | validation: 0.024027735347801046]
	TIME [epoch: 9.07 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01604438884629674		[learning rate: 0.00025186]
	Learning Rate: 0.000251859
	LOSS [training: 0.01604438884629674 | validation: 0.02351834457438013]
	TIME [epoch: 9.08 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018346663325637624		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.018346663325637624 | validation: 0.01270466940607295]
	TIME [epoch: 9.08 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009861343975974369		[learning rate: 0.00025064]
	Learning Rate: 0.000250641
	LOSS [training: 0.009861343975974369 | validation: 0.010263909211516549]
	TIME [epoch: 9.09 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009977691510888962		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: 0.009977691510888962 | validation: 0.010979977861976138]
	TIME [epoch: 9.07 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009951628022353852		[learning rate: 0.00024943]
	Learning Rate: 0.000249429
	LOSS [training: 0.009951628022353852 | validation: 0.02099517315809246]
	TIME [epoch: 9.07 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014384560112545583		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: 0.014384560112545583 | validation: 0.014464860292000845]
	TIME [epoch: 9.06 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011354836327908386		[learning rate: 0.00024822]
	Learning Rate: 0.000248223
	LOSS [training: 0.011354836327908386 | validation: 0.025222718900149453]
	TIME [epoch: 9.07 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015934863761410834		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: 0.015934863761410834 | validation: 0.013159293231237996]
	TIME [epoch: 9.1 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009159181092960685		[learning rate: 0.00024702]
	Learning Rate: 0.000247023
	LOSS [training: 0.009159181092960685 | validation: 0.013297728596309233]
	TIME [epoch: 9.08 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011055736159870148		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: 0.011055736159870148 | validation: 0.017708870860369784]
	TIME [epoch: 9.07 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013449392623568247		[learning rate: 0.00024583]
	Learning Rate: 0.000245828
	LOSS [training: 0.013449392623568247 | validation: 0.014613993642486748]
	TIME [epoch: 9.07 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010067775510770777		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.010067775510770777 | validation: 0.014574029951166884]
	TIME [epoch: 9.09 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01060615777416608		[learning rate: 0.00024464]
	Learning Rate: 0.000244639
	LOSS [training: 0.01060615777416608 | validation: 0.016594210844476265]
	TIME [epoch: 9.07 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00855661559282631		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.00855661559282631 | validation: 0.014863743938591596]
	TIME [epoch: 9.07 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013308137147591995		[learning rate: 0.00024346]
	Learning Rate: 0.000243456
	LOSS [training: 0.013308137147591995 | validation: 0.020409460144710685]
	TIME [epoch: 9.07 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023538221288304968		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.023538221288304968 | validation: 0.0367206391004324]
	TIME [epoch: 9.06 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023098855462990557		[learning rate: 0.00024228]
	Learning Rate: 0.000242279
	LOSS [training: 0.023098855462990557 | validation: 0.020074414276470085]
	TIME [epoch: 9.09 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01838762816242359		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: 0.01838762816242359 | validation: 0.030428801018580795]
	TIME [epoch: 9.07 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037357760861798754		[learning rate: 0.00024111]
	Learning Rate: 0.000241107
	LOSS [training: 0.037357760861798754 | validation: 0.029571616997587126]
	TIME [epoch: 9.07 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028069114962106245		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: 0.028069114962106245 | validation: 0.022049267771284242]
	TIME [epoch: 9.06 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02129540611054053		[learning rate: 0.00023994]
	Learning Rate: 0.000239941
	LOSS [training: 0.02129540611054053 | validation: 0.022304701338756026]
	TIME [epoch: 9.08 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0186999128193947		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: 0.0186999128193947 | validation: 0.03095518867592323]
	TIME [epoch: 9.08 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023981834018298603		[learning rate: 0.00023878]
	Learning Rate: 0.000238781
	LOSS [training: 0.023981834018298603 | validation: 0.020513736195676376]
	TIME [epoch: 9.07 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020682562480092127		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: 0.020682562480092127 | validation: 0.022104927817527164]
	TIME [epoch: 9.06 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020561451122539633		[learning rate: 0.00023763]
	Learning Rate: 0.000237626
	LOSS [training: 0.020561451122539633 | validation: 0.013467051142032165]
	TIME [epoch: 9.07 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01790263412963543		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: 0.01790263412963543 | validation: 0.019697107457702735]
	TIME [epoch: 9.09 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015296136203228053		[learning rate: 0.00023648]
	Learning Rate: 0.000236477
	LOSS [training: 0.015296136203228053 | validation: 0.024550449953366443]
	TIME [epoch: 9.07 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013319960047845681		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.013319960047845681 | validation: 0.011483859718904884]
	TIME [epoch: 9.08 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011627967607676943		[learning rate: 0.00023533]
	Learning Rate: 0.000235334
	LOSS [training: 0.011627967607676943 | validation: 0.01660586657548029]
	TIME [epoch: 9.07 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01089358819203156		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.01089358819203156 | validation: 0.02654395695858354]
	TIME [epoch: 9.07 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012280929219737464		[learning rate: 0.0002342]
	Learning Rate: 0.000234196
	LOSS [training: 0.012280929219737464 | validation: 0.01900809960753786]
	TIME [epoch: 9.08 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013344747788696409		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: 0.013344747788696409 | validation: 0.021791643402487345]
	TIME [epoch: 9.07 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010474023099844599		[learning rate: 0.00023306]
	Learning Rate: 0.000233063
	LOSS [training: 0.010474023099844599 | validation: 0.01996855322829619]
	TIME [epoch: 9.07 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01075804661711816		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: 0.01075804661711816 | validation: 0.01868767788674046]
	TIME [epoch: 9.06 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010891273132918206		[learning rate: 0.00023194]
	Learning Rate: 0.000231936
	LOSS [training: 0.010891273132918206 | validation: 0.01944093088601942]
	TIME [epoch: 9.09 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008237902649308935		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: 0.008237902649308935 | validation: 0.02006898673700707]
	TIME [epoch: 9.06 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01464318635340433		[learning rate: 0.00023081]
	Learning Rate: 0.000230814
	LOSS [training: 0.01464318635340433 | validation: 0.018692457606514168]
	TIME [epoch: 9.06 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021457231498067858		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: 0.021457231498067858 | validation: 0.03127458918395583]
	TIME [epoch: 9.07 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022821545843395123		[learning rate: 0.0002297]
	Learning Rate: 0.000229698
	LOSS [training: 0.022821545843395123 | validation: 0.01332970461818786]
	TIME [epoch: 9.08 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014693967790639301		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: 0.014693967790639301 | validation: 0.01646554385850007]
	TIME [epoch: 9.1 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014956167068597478		[learning rate: 0.00022859]
	Learning Rate: 0.000228588
	LOSS [training: 0.014956167068597478 | validation: 0.016593423633954635]
	TIME [epoch: 9.07 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014750617391224952		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: 0.014750617391224952 | validation: 0.0151734682992943]
	TIME [epoch: 9.07 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006947173852925491		[learning rate: 0.00022748]
	Learning Rate: 0.000227482
	LOSS [training: 0.006947173852925491 | validation: 0.010579297971002063]
	TIME [epoch: 9.08 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008726998680133215		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: 0.008726998680133215 | validation: 0.010582048445632486]
	TIME [epoch: 9.09 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009691511036629706		[learning rate: 0.00022638]
	Learning Rate: 0.000226382
	LOSS [training: 0.009691511036629706 | validation: 0.019543025899405517]
	TIME [epoch: 9.08 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011441007841940149		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: 0.011441007841940149 | validation: 0.021128271985970934]
	TIME [epoch: 9.08 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011249233697362637		[learning rate: 0.00022529]
	Learning Rate: 0.000225287
	LOSS [training: 0.011249233697362637 | validation: 0.024241091534546347]
	TIME [epoch: 9.07 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02114040605309019		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: 0.02114040605309019 | validation: 0.025307753569959394]
	TIME [epoch: 9.07 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03129796513628568		[learning rate: 0.0002242]
	Learning Rate: 0.000224198
	LOSS [training: 0.03129796513628568 | validation: 0.024033524339859235]
	TIME [epoch: 9.09 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021068674203023583		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: 0.021068674203023583 | validation: 0.02606120366261557]
	TIME [epoch: 9.06 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025771077545903305		[learning rate: 0.00022311]
	Learning Rate: 0.000223114
	LOSS [training: 0.025771077545903305 | validation: 0.026221701671610767]
	TIME [epoch: 9.06 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020840456558581383		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: 0.020840456558581383 | validation: 0.019509193838035545]
	TIME [epoch: 9.07 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025657147437602133		[learning rate: 0.00022203]
	Learning Rate: 0.000222035
	LOSS [training: 0.025657147437602133 | validation: 0.030773265145170498]
	TIME [epoch: 9.08 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0253025271273943		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.0253025271273943 | validation: 0.03215076692497561]
	TIME [epoch: 9.09 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02228892035482839		[learning rate: 0.00022096]
	Learning Rate: 0.000220961
	LOSS [training: 0.02228892035482839 | validation: 0.013854567905218254]
	TIME [epoch: 9.07 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013858721609501759		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: 0.013858721609501759 | validation: 0.017469263254271995]
	TIME [epoch: 9.07 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012413128728025757		[learning rate: 0.00021989]
	Learning Rate: 0.000219893
	LOSS [training: 0.012413128728025757 | validation: 0.019778476176185625]
	TIME [epoch: 9.06 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0099429699171597		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: 0.0099429699171597 | validation: 0.02129452153262921]
	TIME [epoch: 9.09 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015677193674781473		[learning rate: 0.00021883]
	Learning Rate: 0.000218829
	LOSS [training: 0.015677193674781473 | validation: 0.024146877886881378]
	TIME [epoch: 9.08 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022430355166852427		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: 0.022430355166852427 | validation: 0.04252282856853489]
	TIME [epoch: 9.07 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03300743307895598		[learning rate: 0.00021777]
	Learning Rate: 0.000217771
	LOSS [training: 0.03300743307895598 | validation: 0.035924977100263704]
	TIME [epoch: 9.07 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019456938758355354		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: 0.019456938758355354 | validation: 0.0165157714383214]
	TIME [epoch: 9.08 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012372093699420711		[learning rate: 0.00021672]
	Learning Rate: 0.000216718
	LOSS [training: 0.012372093699420711 | validation: 0.013668603101484891]
	TIME [epoch: 9.08 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011335622306783215		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: 0.011335622306783215 | validation: 0.020722408103868686]
	TIME [epoch: 9.07 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017999501184622645		[learning rate: 0.00021567]
	Learning Rate: 0.00021567
	LOSS [training: 0.017999501184622645 | validation: 0.022798318337106615]
	TIME [epoch: 9.07 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020174224490275644		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: 0.020174224490275644 | validation: 0.014897888356784595]
	TIME [epoch: 9.07 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018403584671212107		[learning rate: 0.00021463]
	Learning Rate: 0.000214627
	LOSS [training: 0.018403584671212107 | validation: 0.026285598196537086]
	TIME [epoch: 9.09 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018059895214175125		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: 0.018059895214175125 | validation: 0.0190493906681281]
	TIME [epoch: 9.06 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015482687177629817		[learning rate: 0.00021359]
	Learning Rate: 0.000213589
	LOSS [training: 0.015482687177629817 | validation: 0.012185445871977101]
	TIME [epoch: 9.06 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011333902269989236		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.011333902269989236 | validation: 0.010579489766707605]
	TIME [epoch: 9.06 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01227721498634837		[learning rate: 0.00021256]
	Learning Rate: 0.000212556
	LOSS [training: 0.01227721498634837 | validation: 0.018934065027217648]
	TIME [epoch: 9.06 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013749934346437296		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.013749934346437296 | validation: 0.018905131892197422]
	TIME [epoch: 9.09 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015747054128342153		[learning rate: 0.00021153]
	Learning Rate: 0.000211528
	LOSS [training: 0.015747054128342153 | validation: 0.009817910355343098]
	TIME [epoch: 9.06 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01035093886163811		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.01035093886163811 | validation: 0.01652768369442314]
	TIME [epoch: 9.07 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008171905036542642		[learning rate: 0.00021051]
	Learning Rate: 0.000210505
	LOSS [training: 0.008171905036542642 | validation: 0.016767219354368913]
	TIME [epoch: 9.06 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0142401421562175		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.0142401421562175 | validation: 0.018292187320840453]
	TIME [epoch: 9.07 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02376976862106158		[learning rate: 0.00020949]
	Learning Rate: 0.000209487
	LOSS [training: 0.02376976862106158 | validation: 0.0184526109991443]
	TIME [epoch: 9.08 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01957506538911066		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.01957506538911066 | validation: 0.02507557191189596]
	TIME [epoch: 9.07 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03596282820206055		[learning rate: 0.00020847]
	Learning Rate: 0.000208474
	LOSS [training: 0.03596282820206055 | validation: 0.051768206158152016]
	TIME [epoch: 9.07 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04276646645126013		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.04276646645126013 | validation: 0.0527010283248735]
	TIME [epoch: 9.07 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05209439285271443		[learning rate: 0.00020747]
	Learning Rate: 0.000207466
	LOSS [training: 0.05209439285271443 | validation: 0.04079684009970755]
	TIME [epoch: 9.08 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04270336249501079		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: 0.04270336249501079 | validation: 0.04244370484578677]
	TIME [epoch: 9.07 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04000560073331314		[learning rate: 0.00020646]
	Learning Rate: 0.000206463
	LOSS [training: 0.04000560073331314 | validation: 0.03233067092438294]
	TIME [epoch: 9.06 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03180265204953087		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.03180265204953087 | validation: 0.01732961405635121]
	TIME [epoch: 9.07 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028442114132108426		[learning rate: 0.00020546]
	Learning Rate: 0.000205465
	LOSS [training: 0.028442114132108426 | validation: 0.04486397266493226]
	TIME [epoch: 9.07 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03419129641308056		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.03419129641308056 | validation: 0.03146942474828018]
	TIME [epoch: 9.08 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03201910772653686		[learning rate: 0.00020447]
	Learning Rate: 0.000204471
	LOSS [training: 0.03201910772653686 | validation: 0.03660194153361623]
	TIME [epoch: 9.07 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026007323889312046		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: 0.026007323889312046 | validation: 0.02403280070506222]
	TIME [epoch: 9.07 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02105606901130959		[learning rate: 0.00020348]
	Learning Rate: 0.000203482
	LOSS [training: 0.02105606901130959 | validation: 0.019596867217005813]
	TIME [epoch: 9.06 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02026471774262849		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: 0.02026471774262849 | validation: 0.015510402301633511]
	TIME [epoch: 9.08 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013354625227607341		[learning rate: 0.0002025]
	Learning Rate: 0.000202498
	LOSS [training: 0.013354625227607341 | validation: 0.015175721619173604]
	TIME [epoch: 9.07 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012742232574717346		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.012742232574717346 | validation: 0.02087711617882879]
	TIME [epoch: 9.07 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01403268820321411		[learning rate: 0.00020152]
	Learning Rate: 0.000201519
	LOSS [training: 0.01403268820321411 | validation: 0.015298655642296584]
	TIME [epoch: 9.06 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01313359897932494		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.01313359897932494 | validation: 0.015016379008869749]
	TIME [epoch: 9.07 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013342832963332978		[learning rate: 0.00020054]
	Learning Rate: 0.000200544
	LOSS [training: 0.013342832963332978 | validation: 0.01563589920851005]
	TIME [epoch: 9.08 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01363740545290911		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.01363740545290911 | validation: 0.004079710593622559]
	TIME [epoch: 9.06 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015291379762585678		[learning rate: 0.00019957]
	Learning Rate: 0.000199575
	LOSS [training: 0.015291379762585678 | validation: 0.01739324879706845]
	TIME [epoch: 9.07 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010643105073267248		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: 0.010643105073267248 | validation: 0.017669692755979165]
	TIME [epoch: 9.07 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011001939513708675		[learning rate: 0.00019861]
	Learning Rate: 0.000198609
	LOSS [training: 0.011001939513708675 | validation: 0.015217619625898965]
	TIME [epoch: 9.08 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013639497587810875		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: 0.013639497587810875 | validation: 0.016210800048728522]
	TIME [epoch: 9.07 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01221806400770691		[learning rate: 0.00019765]
	Learning Rate: 0.000197649
	LOSS [training: 0.01221806400770691 | validation: 0.020898674508686897]
	TIME [epoch: 9.06 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014791365797289518		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: 0.014791365797289518 | validation: 0.009508254865082146]
	TIME [epoch: 9.07 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014254873066320159		[learning rate: 0.00019669]
	Learning Rate: 0.000196693
	LOSS [training: 0.014254873066320159 | validation: 0.01035472217039761]
	TIME [epoch: 9.06 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01711056015693836		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: 0.01711056015693836 | validation: 0.02762929851795399]
	TIME [epoch: 9.1 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02365152957866601		[learning rate: 0.00019574]
	Learning Rate: 0.000195742
	LOSS [training: 0.02365152957866601 | validation: 0.02428151900833043]
	TIME [epoch: 9.07 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019990652123686146		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: 0.019990652123686146 | validation: 0.021455684571277788]
	TIME [epoch: 9.08 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016241534244035093		[learning rate: 0.0001948]
	Learning Rate: 0.000194796
	LOSS [training: 0.016241534244035093 | validation: 0.024660426345407122]
	TIME [epoch: 9.08 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023470567566853215		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: 0.023470567566853215 | validation: 0.024966509353280337]
	TIME [epoch: 9.08 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022120560476468036		[learning rate: 0.00019385]
	Learning Rate: 0.000193853
	LOSS [training: 0.022120560476468036 | validation: 0.015995409325043917]
	TIME [epoch: 9.07 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02018150375807862		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: 0.02018150375807862 | validation: 0.02620764411229003]
	TIME [epoch: 9.07 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02016414470361731		[learning rate: 0.00019292]
	Learning Rate: 0.000192916
	LOSS [training: 0.02016414470361731 | validation: 0.013176116336405214]
	TIME [epoch: 9.07 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02643172158654846		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: 0.02643172158654846 | validation: 0.021484416080852914]
	TIME [epoch: 9.07 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024847220092402172		[learning rate: 0.00019198]
	Learning Rate: 0.000191983
	LOSS [training: 0.024847220092402172 | validation: 0.024315539037340884]
	TIME [epoch: 9.08 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019700015570920104		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: 0.019700015570920104 | validation: 0.015754120279948082]
	TIME [epoch: 9.07 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02219584061744277		[learning rate: 0.00019105]
	Learning Rate: 0.000191055
	LOSS [training: 0.02219584061744277 | validation: 0.0151152055551845]
	TIME [epoch: 9.07 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021351548972514317		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: 0.021351548972514317 | validation: 0.03583685219472918]
	TIME [epoch: 9.06 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03928256007632357		[learning rate: 0.00019013]
	Learning Rate: 0.000190131
	LOSS [training: 0.03928256007632357 | validation: 0.041713607110081485]
	TIME [epoch: 9.08 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04817792266142738		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: 0.04817792266142738 | validation: 0.04661193777476687]
	TIME [epoch: 9.08 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046137884215942795		[learning rate: 0.00018921]
	Learning Rate: 0.000189211
	LOSS [training: 0.046137884215942795 | validation: 0.04553045457139673]
	TIME [epoch: 9.07 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04336529982299132		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: 0.04336529982299132 | validation: 0.04350673773866028]
	TIME [epoch: 9.08 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03488469205976493		[learning rate: 0.0001883]
	Learning Rate: 0.000188296
	LOSS [training: 0.03488469205976493 | validation: 0.02040815292015091]
	TIME [epoch: 9.07 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026055921587699087		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: 0.026055921587699087 | validation: 0.014868181941436964]
	TIME [epoch: 9.09 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02177482532338404		[learning rate: 0.00018739]
	Learning Rate: 0.000187386
	LOSS [training: 0.02177482532338404 | validation: 0.031164858375437872]
	TIME [epoch: 9.07 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023744362953464153		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: 0.023744362953464153 | validation: 0.012480238997789139]
	TIME [epoch: 9.06 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022288769847880707		[learning rate: 0.00018648]
	Learning Rate: 0.00018648
	LOSS [training: 0.022288769847880707 | validation: 0.01908721001210951]
	TIME [epoch: 9.07 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017690104602517735		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: 0.017690104602517735 | validation: 0.01079720893338646]
	TIME [epoch: 9.06 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019302650084760738		[learning rate: 0.00018558]
	Learning Rate: 0.000185578
	LOSS [training: 0.019302650084760738 | validation: 0.0130438158271584]
	TIME [epoch: 9.08 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022188342183235944		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: 0.022188342183235944 | validation: 0.025266516723794954]
	TIME [epoch: 9.07 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020245844289419952		[learning rate: 0.00018468]
	Learning Rate: 0.00018468
	LOSS [training: 0.020245844289419952 | validation: 0.017370319573321608]
	TIME [epoch: 9.06 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01620448876585548		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: 0.01620448876585548 | validation: 0.010002022542969882]
	TIME [epoch: 9.07 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020277381462532267		[learning rate: 0.00018379]
	Learning Rate: 0.000183787
	LOSS [training: 0.020277381462532267 | validation: 0.02061107921239676]
	TIME [epoch: 9.09 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0278566471193497		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: 0.0278566471193497 | validation: 0.028585232197691025]
	TIME [epoch: 9.07 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025947235459634104		[learning rate: 0.0001829]
	Learning Rate: 0.000182899
	LOSS [training: 0.025947235459634104 | validation: 0.024379546186678595]
	TIME [epoch: 9.07 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02491719178547356		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: 0.02491719178547356 | validation: 0.026000713171797706]
	TIME [epoch: 9.06 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023484202600454918		[learning rate: 0.00018201]
	Learning Rate: 0.000182014
	LOSS [training: 0.023484202600454918 | validation: 0.019631469142320786]
	TIME [epoch: 9.07 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030430859074479493		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: 0.030430859074479493 | validation: 0.038692372623823336]
	TIME [epoch: 9.09 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04170901309049023		[learning rate: 0.00018113]
	Learning Rate: 0.000181134
	LOSS [training: 0.04170901309049023 | validation: 0.03388884750105564]
	TIME [epoch: 9.07 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031448850331844094		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: 0.031448850331844094 | validation: 0.030871528463367225]
	TIME [epoch: 9.07 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024636331060545753		[learning rate: 0.00018026]
	Learning Rate: 0.000180258
	LOSS [training: 0.024636331060545753 | validation: 0.027822644649266624]
	TIME [epoch: 9.06 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020471261286908325		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: 0.020471261286908325 | validation: 0.028426669055485798]
	TIME [epoch: 9.08 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016323694622098615		[learning rate: 0.00017939]
	Learning Rate: 0.000179386
	LOSS [training: 0.016323694622098615 | validation: 0.01083876419383462]
	TIME [epoch: 9.08 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014273869070547984		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: 0.014273869070547984 | validation: 0.023813496355924085]
	TIME [epoch: 9.07 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01466161877154921		[learning rate: 0.00017852]
	Learning Rate: 0.000178519
	LOSS [training: 0.01466161877154921 | validation: 0.0167025224082695]
	TIME [epoch: 9.06 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01656874078435556		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: 0.01656874078435556 | validation: 0.012901235042004657]
	TIME [epoch: 9.07 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013285440419887145		[learning rate: 0.00017766]
	Learning Rate: 0.000177656
	LOSS [training: 0.013285440419887145 | validation: 0.019541324404923992]
	TIME [epoch: 9.09 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0139556234766672		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: 0.0139556234766672 | validation: 0.015163441237434102]
	TIME [epoch: 9.08 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017304337095690618		[learning rate: 0.0001768]
	Learning Rate: 0.000176797
	LOSS [training: 0.017304337095690618 | validation: 0.019071234432707838]
	TIME [epoch: 9.06 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011558469938579008		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: 0.011558469938579008 | validation: 0.012447459444162048]
	TIME [epoch: 9.07 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015008833978742014		[learning rate: 0.00017594]
	Learning Rate: 0.000175942
	LOSS [training: 0.015008833978742014 | validation: 0.018814407847522703]
	TIME [epoch: 9.08 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02205118216200003		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: 0.02205118216200003 | validation: 0.015085244719180388]
	TIME [epoch: 9.08 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011537046479706945		[learning rate: 0.00017509]
	Learning Rate: 0.000175091
	LOSS [training: 0.011537046479706945 | validation: 0.018084332293490945]
	TIME [epoch: 9.07 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011032122041043493		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: 0.011032122041043493 | validation: 0.017843649109444016]
	TIME [epoch: 9.07 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013945537461303675		[learning rate: 0.00017424]
	Learning Rate: 0.000174244
	LOSS [training: 0.013945537461303675 | validation: 0.012424977460721916]
	TIME [epoch: 9.08 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009766999047448177		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: 0.009766999047448177 | validation: 0.017424926836732708]
	TIME [epoch: 9.08 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011190677079360178		[learning rate: 0.0001734]
	Learning Rate: 0.000173401
	LOSS [training: 0.011190677079360178 | validation: 0.01625102461118006]
	TIME [epoch: 9.07 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011793558599738168		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.011793558599738168 | validation: 0.011046145568261055]
	TIME [epoch: 9.07 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011574651711221903		[learning rate: 0.00017256]
	Learning Rate: 0.000172563
	LOSS [training: 0.011574651711221903 | validation: 0.019957640300173288]
	TIME [epoch: 9.07 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011319213645407212		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: 0.011319213645407212 | validation: 0.01898371971790798]
	TIME [epoch: 9.07 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006102752661935574		[learning rate: 0.00017173]
	Learning Rate: 0.000171728
	LOSS [training: 0.006102752661935574 | validation: 0.01745345160741743]
	TIME [epoch: 9.09 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007741065237360159		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: 0.007741065237360159 | validation: 0.005493078101058452]
	TIME [epoch: 9.06 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008474383393059531		[learning rate: 0.0001709]
	Learning Rate: 0.000170898
	LOSS [training: 0.008474383393059531 | validation: 0.018895039163732513]
	TIME [epoch: 9.07 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016863065254964033		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.016863065254964033 | validation: 0.017245368674589645]
	TIME [epoch: 9.06 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02477422411134645		[learning rate: 0.00017007]
	Learning Rate: 0.000170072
	LOSS [training: 0.02477422411134645 | validation: 0.0311712461967191]
	TIME [epoch: 9.08 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023778746767872425		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: 0.023778746767872425 | validation: 0.01766268820534693]
	TIME [epoch: 9.07 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018858435766178263		[learning rate: 0.00016925]
	Learning Rate: 0.000169249
	LOSS [training: 0.018858435766178263 | validation: 0.015728227670528477]
	TIME [epoch: 9.07 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012834404781742465		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: 0.012834404781742465 | validation: 0.013371099154409302]
	TIME [epoch: 9.07 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014053029006654985		[learning rate: 0.00016843]
	Learning Rate: 0.000168431
	LOSS [training: 0.014053029006654985 | validation: 0.016114039126986102]
	TIME [epoch: 9.06 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008744637080960883		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.008744637080960883 | validation: 0.012363397611619004]
	TIME [epoch: 9.09 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029075696458292204		[learning rate: 0.00016762]
	Learning Rate: 0.000167616
	LOSS [training: 0.0029075696458292204 | validation: 0.017946366080925553]
	TIME [epoch: 9.07 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010829861936777933		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.010829861936777933 | validation: 0.00884662520197269]
	TIME [epoch: 9.07 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009277423891822009		[learning rate: 0.00016681]
	Learning Rate: 0.000166806
	LOSS [training: 0.009277423891822009 | validation: 0.01499340901989477]
	TIME [epoch: 9.07 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01106481545125523		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: 0.01106481545125523 | validation: 0.011111647203537404]
	TIME [epoch: 9.08 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006458403267242341		[learning rate: 0.000166]
	Learning Rate: 0.000165999
	LOSS [training: 0.006458403267242341 | validation: 0.017117242777101756]
	TIME [epoch: 9.08 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006811584123416113		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: 0.006811584123416113 | validation: 0.016719024110292614]
	TIME [epoch: 9.07 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009574406358742665		[learning rate: 0.0001652]
	Learning Rate: 0.000165196
	LOSS [training: 0.009574406358742665 | validation: 0.01193058709707341]
	TIME [epoch: 9.07 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00828339190172677		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: 0.00828339190172677 | validation: 0.007002043873158432]
	TIME [epoch: 9.07 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005331783381218281		[learning rate: 0.0001644]
	Learning Rate: 0.000164397
	LOSS [training: 0.005331783381218281 | validation: 0.014897420911093365]
	TIME [epoch: 9.09 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007878980894819126		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: 0.007878980894819126 | validation: 0.01858419803219863]
	TIME [epoch: 9.07 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009911035622045237		[learning rate: 0.0001636]
	Learning Rate: 0.000163602
	LOSS [training: 0.009911035622045237 | validation: 0.022879338284387367]
	TIME [epoch: 9.07 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011151581200345729		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: 0.011151581200345729 | validation: 0.008251042417952513]
	TIME [epoch: 9.06 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011411144283375935		[learning rate: 0.00016281]
	Learning Rate: 0.000162811
	LOSS [training: 0.011411144283375935 | validation: 0.008768895575423749]
	TIME [epoch: 9.08 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006049361968880755		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: 0.006049361968880755 | validation: 0.017788479703078005]
	TIME [epoch: 9.08 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01105938034424716		[learning rate: 0.00016202]
	Learning Rate: 0.000162024
	LOSS [training: 0.01105938034424716 | validation: 0.010731084104154189]
	TIME [epoch: 9.07 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008789983012157197		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: 0.008789983012157197 | validation: 0.014185428632291386]
	TIME [epoch: 9.07 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009138451270265531		[learning rate: 0.00016124]
	Learning Rate: 0.00016124
	LOSS [training: 0.009138451270265531 | validation: 0.015808405357501373]
	TIME [epoch: 9.07 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011022613276822406		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: 0.011022613276822406 | validation: 0.014461338356983345]
	TIME [epoch: 9.09 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008948324486472882		[learning rate: 0.00016046]
	Learning Rate: 0.000160461
	LOSS [training: 0.008948324486472882 | validation: 0.011492925674785628]
	TIME [epoch: 9.07 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00852838073974464		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: 0.00852838073974464 | validation: 0.010066357296023155]
	TIME [epoch: 9.07 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008319748727299646		[learning rate: 0.00015968]
	Learning Rate: 0.000159685
	LOSS [training: 0.008319748727299646 | validation: 0.013412508580645698]
	TIME [epoch: 9.07 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01799638610994314		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.01799638610994314 | validation: 0.01828770298956469]
	TIME [epoch: 9.07 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015484335360477563		[learning rate: 0.00015891]
	Learning Rate: 0.000158912
	LOSS [training: 0.015484335360477563 | validation: 0.02176623819280099]
	TIME [epoch: 9.09 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01722276129686736		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: 0.01722276129686736 | validation: 0.026266086678146994]
	TIME [epoch: 9.07 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022481266106391735		[learning rate: 0.00015814]
	Learning Rate: 0.000158144
	LOSS [training: 0.022481266106391735 | validation: 0.019373134763458612]
	TIME [epoch: 9.07 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02077086374309583		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: 0.02077086374309583 | validation: 0.01845100792901212]
	TIME [epoch: 9.06 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015917547951787767		[learning rate: 0.00015738]
	Learning Rate: 0.000157379
	LOSS [training: 0.015917547951787767 | validation: 0.025357554953005495]
	TIME [epoch: 9.08 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02651188311656149		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.02651188311656149 | validation: 0.02995828422318636]
	TIME [epoch: 9.08 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024154850491302882		[learning rate: 0.00015662]
	Learning Rate: 0.000156618
	LOSS [training: 0.024154850491302882 | validation: 0.01402664594525758]
	TIME [epoch: 9.07 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017716863338952952		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: 0.017716863338952952 | validation: 0.020006144083594746]
	TIME [epoch: 9.07 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02064840499768732		[learning rate: 0.00015586]
	Learning Rate: 0.000155861
	LOSS [training: 0.02064840499768732 | validation: 0.027512044413062372]
	TIME [epoch: 9.07 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014643411513201351		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: 0.014643411513201351 | validation: 0.012074757699807108]
	TIME [epoch: 9.09 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010813457321186184		[learning rate: 0.00015511]
	Learning Rate: 0.000155107
	LOSS [training: 0.010813457321186184 | validation: 0.013759245603366707]
	TIME [epoch: 9.07 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011580171222291397		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.011580171222291397 | validation: 0.010692173379794969]
	TIME [epoch: 9.07 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014903815556295627		[learning rate: 0.00015436]
	Learning Rate: 0.000154357
	LOSS [training: 0.014903815556295627 | validation: 0.022660327709064235]
	TIME [epoch: 9.07 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01079873252286788		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.01079873252286788 | validation: 0.006113314648249745]
	TIME [epoch: 9.08 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007300317035220748		[learning rate: 0.00015361]
	Learning Rate: 0.000153611
	LOSS [training: 0.007300317035220748 | validation: 0.011454494649992658]
	TIME [epoch: 9.08 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005367736095750238		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: 0.005367736095750238 | validation: 0.012255998776337368]
	TIME [epoch: 9.07 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005754925382578555		[learning rate: 0.00015287]
	Learning Rate: 0.000152868
	LOSS [training: 0.005754925382578555 | validation: 0.004611402725356744]
	TIME [epoch: 9.07 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007799654861203804		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: 0.007799654861203804 | validation: 0.011495341249355447]
	TIME [epoch: 9.07 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003989580854600742		[learning rate: 0.00015213]
	Learning Rate: 0.000152128
	LOSS [training: 0.003989580854600742 | validation: 0.005932405425823249]
	TIME [epoch: 9.09 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004399944436210872		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: 0.004399944436210872 | validation: 0.013403527481865705]
	TIME [epoch: 9.07 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007393895167242093		[learning rate: 0.00015139]
	Learning Rate: 0.000151393
	LOSS [training: 0.007393895167242093 | validation: 0.009565291795401772]
	TIME [epoch: 9.08 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007173868834360081		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: 0.007173868834360081 | validation: 0.008439891689104456]
	TIME [epoch: 9.07 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003087314486953373		[learning rate: 0.00015066]
	Learning Rate: 0.000150661
	LOSS [training: 0.003087314486953373 | validation: 0.0082237674789068]
	TIME [epoch: 9.07 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005157690445734017		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: 0.005157690445734017 | validation: 0.020262152787697]
	TIME [epoch: 9.08 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00542309681386879		[learning rate: 0.00014993]
	Learning Rate: 0.000149932
	LOSS [training: 0.00542309681386879 | validation: 0.016368221379299504]
	TIME [epoch: 9.07 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008916011758872775		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: 0.008916011758872775 | validation: 0.009632003385646536]
	TIME [epoch: 9.06 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015318319457703816		[learning rate: 0.00014921]
	Learning Rate: 0.000149207
	LOSS [training: 0.015318319457703816 | validation: 0.012054453572423327]
	TIME [epoch: 9.07 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012022199882640772		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: 0.012022199882640772 | validation: 0.01684208725082597]
	TIME [epoch: 9.08 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015167763925528165		[learning rate: 0.00014849]
	Learning Rate: 0.000148486
	LOSS [training: 0.015167763925528165 | validation: 0.022060369092134935]
	TIME [epoch: 9.07 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007112431857187187		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: 0.007112431857187187 | validation: 0.012883466141829272]
	TIME [epoch: 9.06 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013562312335221963		[learning rate: 0.00014777]
	Learning Rate: 0.000147768
	LOSS [training: 0.013562312335221963 | validation: 0.00777708451352361]
	TIME [epoch: 9.06 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008611468510684523		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.008611468510684523 | validation: 0.007929690218104713]
	TIME [epoch: 9.07 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0070920813529843805		[learning rate: 0.00014705]
	Learning Rate: 0.000147053
	LOSS [training: 0.0070920813529843805 | validation: 0.011790372568671775]
	TIME [epoch: 9.09 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009064563952855837		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: 0.009064563952855837 | validation: 0.010291380379886361]
	TIME [epoch: 9.08 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006875360232011546		[learning rate: 0.00014634]
	Learning Rate: 0.000146342
	LOSS [training: 0.006875360232011546 | validation: 0.012987757863155643]
	TIME [epoch: 9.07 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011045005894231913		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.011045005894231913 | validation: 0.015171456968230433]
	TIME [epoch: 9.06 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011408553019154848		[learning rate: 0.00014563]
	Learning Rate: 0.000145634
	LOSS [training: 0.011408553019154848 | validation: 0.015525241976783054]
	TIME [epoch: 9.09 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011769525294394494		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.011769525294394494 | validation: 0.012700897074010833]
	TIME [epoch: 9.06 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007743995548021953		[learning rate: 0.00014493]
	Learning Rate: 0.00014493
	LOSS [training: 0.007743995548021953 | validation: 0.0063680784920294685]
	TIME [epoch: 9.06 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003089474673697427		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: 0.003089474673697427 | validation: 0.015375814981535217]
	TIME [epoch: 9.06 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00596269620033463		[learning rate: 0.00014423]
	Learning Rate: 0.000144229
	LOSS [training: 0.00596269620033463 | validation: 0.0003939182074204888]
	TIME [epoch: 9.06 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003389546680931021		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.003389546680931021 | validation: 0.011449227102906566]
	TIME [epoch: 9.1 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007530006288946739		[learning rate: 0.00014353]
	Learning Rate: 0.000143532
	LOSS [training: 0.007530006288946739 | validation: 0.011850772325796836]
	TIME [epoch: 9.07 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004223606139012834		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.004223606139012834 | validation: 0.0063315226570831865]
	TIME [epoch: 9.06 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0003520405633779406		[learning rate: 0.00014284]
	Learning Rate: 0.000142837
	LOSS [training: -0.0003520405633779406 | validation: 0.008016379067515036]
	TIME [epoch: 9.07 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005872436243304982		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.005872436243304982 | validation: 0.013273684128198593]
	TIME [epoch: 9.08 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005694508367092969		[learning rate: 0.00014215]
	Learning Rate: 0.000142147
	LOSS [training: 0.005694508367092969 | validation: 0.017368780393517937]
	TIME [epoch: 9.09 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005371033942529793		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: 0.005371033942529793 | validation: 0.014812868149157943]
	TIME [epoch: 9.08 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019944525272321237		[learning rate: 0.00014146]
	Learning Rate: 0.000141459
	LOSS [training: 0.0019944525272321237 | validation: 0.006117421758885972]
	TIME [epoch: 9.07 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008268409918038618		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: 0.008268409918038618 | validation: 0.009697408995951031]
	TIME [epoch: 9.07 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0055005908696865525		[learning rate: 0.00014078]
	Learning Rate: 0.000140775
	LOSS [training: 0.0055005908696865525 | validation: 0.002115764002441658]
	TIME [epoch: 9.09 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0023703344724998964		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: 0.0023703344724998964 | validation: 0.019723006996051062]
	TIME [epoch: 9.07 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010376905253552072		[learning rate: 0.00014009]
	Learning Rate: 0.000140094
	LOSS [training: 0.010376905253552072 | validation: 0.014476046072662696]
	TIME [epoch: 9.06 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0056089312159708846		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: 0.0056089312159708846 | validation: 0.008270130467397122]
	TIME [epoch: 9.07 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0011639193367106557		[learning rate: 0.00013942]
	Learning Rate: 0.000139417
	LOSS [training: 0.0011639193367106557 | validation: 0.014586102637844716]
	TIME [epoch: 9.08 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006572239314948764		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: 0.006572239314948764 | validation: 0.01120656671799223]
	TIME [epoch: 9.08 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009551908843450922		[learning rate: 0.00013874]
	Learning Rate: 0.000138743
	LOSS [training: 0.009551908843450922 | validation: 0.014654343070784549]
	TIME [epoch: 9.06 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00525579580622398		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: 0.00525579580622398 | validation: 0.012783852677731113]
	TIME [epoch: 9.06 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0004206173718948418		[learning rate: 0.00013807]
	Learning Rate: 0.000138072
	LOSS [training: 0.0004206173718948418 | validation: 0.004202484927456687]
	TIME [epoch: 9.07 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016083210910181737		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: 0.0016083210910181737 | validation: 0.013642703123713098]
	TIME [epoch: 9.09 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002871459009043273		[learning rate: 0.0001374]
	Learning Rate: 0.000137404
	LOSS [training: 0.002871459009043273 | validation: 0.015546126165957352]
	TIME [epoch: 9.07 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008025024888928634		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: 0.008025024888928634 | validation: 0.01795186433148218]
	TIME [epoch: 9.07 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00763108714091722		[learning rate: 0.00013674]
	Learning Rate: 0.00013674
	LOSS [training: 0.00763108714091722 | validation: 0.021878951499561983]
	TIME [epoch: 9.07 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005379522586223625		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: 0.005379522586223625 | validation: 0.017334220468445977]
	TIME [epoch: 9.07 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0025123893756894165		[learning rate: 0.00013608]
	Learning Rate: 0.000136078
	LOSS [training: 0.0025123893756894165 | validation: 0.006636473406708218]
	TIME [epoch: 9.09 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00774816504345185		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: 0.00774816504345185 | validation: 0.009363574259876715]
	TIME [epoch: 9.07 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005711115858983784		[learning rate: 0.00013542]
	Learning Rate: 0.00013542
	LOSS [training: 0.005711115858983784 | validation: 0.0008448231850009414]
	TIME [epoch: 9.07 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00638655536692021		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: 0.00638655536692021 | validation: 0.016477495064706457]
	TIME [epoch: 9.06 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006741607585797976		[learning rate: 0.00013477]
	Learning Rate: 0.000134766
	LOSS [training: 0.006741607585797976 | validation: 0.011489904039616467]
	TIME [epoch: 9.09 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004023230507800027		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: 0.004023230507800027 | validation: 0.010099458334594587]
	TIME [epoch: 9.07 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008089837861788466		[learning rate: 0.00013411]
	Learning Rate: 0.000134114
	LOSS [training: 0.008089837861788466 | validation: 0.006832979902868251]
	TIME [epoch: 9.07 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006743825582269966		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: 0.006743825582269966 | validation: 0.007439297703813463]
	TIME [epoch: 9.08 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003889304742321728		[learning rate: 0.00013347]
	Learning Rate: 0.000133465
	LOSS [training: 0.003889304742321728 | validation: 0.014930073073714101]
	TIME [epoch: 9.06 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0036517252999232813		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.0036517252999232813 | validation: 0.018814523712165653]
	TIME [epoch: 9.09 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00842085054781094		[learning rate: 0.00013282]
	Learning Rate: 0.00013282
	LOSS [training: 0.00842085054781094 | validation: 0.02152589385938774]
	TIME [epoch: 9.06 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00568302160406791		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: 0.00568302160406791 | validation: 0.007435110503690638]
	TIME [epoch: 9.07 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008909703204067934		[learning rate: 0.00013218]
	Learning Rate: 0.000132178
	LOSS [training: 0.008909703204067934 | validation: 0.023111428129793814]
	TIME [epoch: 9.07 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005786466000648326		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: 0.005786466000648326 | validation: 0.016539877138885967]
	TIME [epoch: 9.08 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006894996711363581		[learning rate: 0.00013154]
	Learning Rate: 0.000131538
	LOSS [training: 0.006894996711363581 | validation: 0.004760633734379056]
	TIME [epoch: 9.08 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0041488946892102386		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: 0.0041488946892102386 | validation: 0.0072743212130942795]
	TIME [epoch: 9.07 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004931093642188222		[learning rate: 0.0001309]
	Learning Rate: 0.000130902
	LOSS [training: 0.004931093642188222 | validation: 0.001122742077978833]
	TIME [epoch: 9.06 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0066678351685963404		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: 0.0066678351685963404 | validation: 0.001924750679791796]
	TIME [epoch: 9.06 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002423057689352861		[learning rate: 0.00013027]
	Learning Rate: 0.000130269
	LOSS [training: 0.002423057689352861 | validation: 0.006667806083558424]
	TIME [epoch: 9.09 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005542148842694957		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: 0.005542148842694957 | validation: 0.01984006633414458]
	TIME [epoch: 9.06 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004127867027450457		[learning rate: 0.00012964]
	Learning Rate: 0.000129639
	LOSS [training: 0.004127867027450457 | validation: 0.012210813250545719]
	TIME [epoch: 9.07 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003911228273241243		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: 0.003911228273241243 | validation: 0.0163440386828629]
	TIME [epoch: 9.07 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007984582822451559		[learning rate: 0.00012901]
	Learning Rate: 0.000129012
	LOSS [training: 0.007984582822451559 | validation: 0.00035392756225542145]
	TIME [epoch: 9.07 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0024950048294237596		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.0024950048294237596 | validation: 0.007116166726030552]
	TIME [epoch: 9.08 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006969260016370171		[learning rate: 0.00012839]
	Learning Rate: 0.000128389
	LOSS [training: 0.006969260016370171 | validation: 0.007303976761756106]
	TIME [epoch: 9.06 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004724253226426892		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: 0.004724253226426892 | validation: 0.01100060433525058]
	TIME [epoch: 9.06 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0044259769796887675		[learning rate: 0.00012777]
	Learning Rate: 0.000127768
	LOSS [training: 0.0044259769796887675 | validation: -0.00247696970726078]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_1899.pth
	Model improved!!!
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008195025628098075		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: 0.008195025628098075 | validation: 0.01646366376645579]
	TIME [epoch: 9.08 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0001858515155739447		[learning rate: 0.00012715]
	Learning Rate: 0.00012715
	LOSS [training: -0.0001858515155739447 | validation: 0.012719345438092822]
	TIME [epoch: 9.07 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00632588511312797		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: 0.00632588511312797 | validation: 0.010978555500116666]
	TIME [epoch: 9.05 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006728562154188875		[learning rate: 0.00012653]
	Learning Rate: 0.000126535
	LOSS [training: 0.006728562154188875 | validation: 0.007031028337355227]
	TIME [epoch: 9.06 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007858462566812848		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: 0.007858462566812848 | validation: 0.007920153245729037]
	TIME [epoch: 9.06 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009794432529868658		[learning rate: 0.00012592]
	Learning Rate: 0.000125923
	LOSS [training: 0.009794432529868658 | validation: 0.014607328569968485]
	TIME [epoch: 9.08 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012557791695644107		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: 0.012557791695644107 | validation: 0.010747427058139605]
	TIME [epoch: 9.06 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012218363896609599		[learning rate: 0.00012531]
	Learning Rate: 0.000125314
	LOSS [training: 0.012218363896609599 | validation: 0.01701072602440207]
	TIME [epoch: 9.06 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010475687698496846		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: 0.010475687698496846 | validation: 0.016899170979449703]
	TIME [epoch: 9.07 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005428012014147756		[learning rate: 0.00012471]
	Learning Rate: 0.000124708
	LOSS [training: 0.005428012014147756 | validation: 0.010708503194986736]
	TIME [epoch: 9.08 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0042693342946235075		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: 0.0042693342946235075 | validation: 0.013558044324451533]
	TIME [epoch: 9.06 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004227593211518871		[learning rate: 0.00012411]
	Learning Rate: 0.000124105
	LOSS [training: 0.004227593211518871 | validation: 0.00944954583262443]
	TIME [epoch: 9.06 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003929454112021823		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.003929454112021823 | validation: 0.007687360011811467]
	TIME [epoch: 9.06 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006507611682783342		[learning rate: 0.0001235]
	Learning Rate: 0.000123505
	LOSS [training: 0.006507611682783342 | validation: 0.011842950781136667]
	TIME [epoch: 9.05 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006977175007557947		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: 0.006977175007557947 | validation: 0.006916220181566029]
	TIME [epoch: 9.08 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007332189312583353		[learning rate: 0.00012291]
	Learning Rate: 0.000122908
	LOSS [training: 0.007332189312583353 | validation: 0.012470017245826309]
	TIME [epoch: 9.05 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006378818942000465		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: 0.006378818942000465 | validation: 0.015579488112414677]
	TIME [epoch: 9.06 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0064328495292419585		[learning rate: 0.00012231]
	Learning Rate: 0.000122313
	LOSS [training: 0.0064328495292419585 | validation: 0.006514836306264592]
	TIME [epoch: 9.06 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008348257072320595		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: 0.008348257072320595 | validation: 0.006865573438167967]
	TIME [epoch: 9.06 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002974425562710021		[learning rate: 0.00012172]
	Learning Rate: 0.000121722
	LOSS [training: 0.002974425562710021 | validation: 0.019660421417645246]
	TIME [epoch: 9.08 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009273356013454793		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: 0.009273356013454793 | validation: 0.011634426394116753]
	TIME [epoch: 9.06 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006980197660014703		[learning rate: 0.00012113]
	Learning Rate: 0.000121133
	LOSS [training: 0.006980197660014703 | validation: 0.011973010172925265]
	TIME [epoch: 9.08 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007151129562497481		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: 0.007151129562497481 | validation: 0.01406988003703844]
	TIME [epoch: 9.07 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009001870371183404		[learning rate: 0.00012055]
	Learning Rate: 0.000120547
	LOSS [training: 0.009001870371183404 | validation: 0.01869807960400837]
	TIME [epoch: 9.08 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014634465639185162		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: 0.014634465639185162 | validation: 0.0180414242180823]
	TIME [epoch: 9.07 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01565012159741725		[learning rate: 0.00011996]
	Learning Rate: 0.000119964
	LOSS [training: 0.01565012159741725 | validation: 0.017821032215928]
	TIME [epoch: 9.06 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008345143943954659		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: 0.008345143943954659 | validation: 0.017839968044971642]
	TIME [epoch: 9.07 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008133250253693283		[learning rate: 0.00011938]
	Learning Rate: 0.000119384
	LOSS [training: 0.008133250253693283 | validation: 0.004218834214099224]
	TIME [epoch: 9.07 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009830027418501756		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: 0.009830027418501756 | validation: 0.015511541216405906]
	TIME [epoch: 9.07 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01189088115510642		[learning rate: 0.00011881]
	Learning Rate: 0.000118807
	LOSS [training: 0.01189088115510642 | validation: 0.005943087834154109]
	TIME [epoch: 9.06 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010501810935391934		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: 0.010501810935391934 | validation: 0.007027291082194389]
	TIME [epoch: 9.06 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00376906777612271		[learning rate: 0.00011823]
	Learning Rate: 0.000118232
	LOSS [training: 0.00376906777612271 | validation: 0.009576844048301393]
	TIME [epoch: 9.07 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0032368766871591842		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: 0.0032368766871591842 | validation: 0.0052396832936421585]
	TIME [epoch: 9.08 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005039412110942987		[learning rate: 0.00011766]
	Learning Rate: 0.000117661
	LOSS [training: 0.005039412110942987 | validation: 0.01515544516559381]
	TIME [epoch: 9.07 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006738024864948686		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: 0.006738024864948686 | validation: 0.0031277703195364825]
	TIME [epoch: 9.07 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008065914586638826		[learning rate: 0.00011709]
	Learning Rate: 0.000117092
	LOSS [training: 0.008065914586638826 | validation: 0.015140754671667887]
	TIME [epoch: 9.07 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006867319793096606		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: 0.006867319793096606 | validation: 0.017668361488472402]
	TIME [epoch: 9.07 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011250903795689297		[learning rate: 0.00011653]
	Learning Rate: 0.000116526
	LOSS [training: 0.011250903795689297 | validation: 0.019259639565974124]
	TIME [epoch: 9.09 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009825505653363466		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: 0.009825505653363466 | validation: 0.014135508786192397]
	TIME [epoch: 9.06 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006752395166843792		[learning rate: 0.00011596]
	Learning Rate: 0.000115962
	LOSS [training: 0.006752395166843792 | validation: 0.008435161740961358]
	TIME [epoch: 9.07 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00828166787479058		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: 0.00828166787479058 | validation: 0.01579753025230258]
	TIME [epoch: 9.06 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009206275180124342		[learning rate: 0.0001154]
	Learning Rate: 0.000115401
	LOSS [training: 0.009206275180124342 | validation: 0.010291208271223089]
	TIME [epoch: 9.08 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004388524185900711		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: 0.004388524185900711 | validation: 0.016393100660140516]
	TIME [epoch: 9.07 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008319696054357237		[learning rate: 0.00011484]
	Learning Rate: 0.000114843
	LOSS [training: 0.008319696054357237 | validation: 0.003279088049297256]
	TIME [epoch: 9.06 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006734160490899911		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: 0.006734160490899911 | validation: 0.015957354993397208]
	TIME [epoch: 9.07 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006189707596863383		[learning rate: 0.00011429]
	Learning Rate: 0.000114288
	LOSS [training: 0.006189707596863383 | validation: 0.016544230828740854]
	TIME [epoch: 9.06 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013799753509947402		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: 0.013799753509947402 | validation: 0.01023699804840778]
	TIME [epoch: 9.09 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009169444764918183		[learning rate: 0.00011374]
	Learning Rate: 0.000113735
	LOSS [training: 0.009169444764918183 | validation: 0.004576418102908513]
	TIME [epoch: 9.07 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00571390695042306		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: 0.00571390695042306 | validation: 0.0059276347521338806]
	TIME [epoch: 9.06 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006818494930559594		[learning rate: 0.00011319]
	Learning Rate: 0.000113185
	LOSS [training: 0.006818494930559594 | validation: 0.006205746624537762]
	TIME [epoch: 9.06 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004537668434205252		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: 0.004537668434205252 | validation: -0.002613108278098961]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r3_20240219_183142/states/model_tr_study4_1950.pth
	Model improved!!!
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00802422189393763		[learning rate: 0.00011264]
	Learning Rate: 0.000112638
	LOSS [training: 0.00802422189393763 | validation: 0.009522418140912826]
	TIME [epoch: 9.08 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005191540436832374		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: 0.005191540436832374 | validation: 0.01666489224485778]
	TIME [epoch: 9.07 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007563067085781845		[learning rate: 0.00011209]
	Learning Rate: 0.000112093
	LOSS [training: 0.007563067085781845 | validation: 0.01584036842926803]
	TIME [epoch: 9.06 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005796239357590776		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: 0.005796239357590776 | validation: 0.01286919716343369]
	TIME [epoch: 9.07 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004328917784958907		[learning rate: 0.00011155]
	Learning Rate: 0.000111551
	LOSS [training: 0.004328917784958907 | validation: 0.011391634644722443]
	TIME [epoch: 9.08 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004505962365102407		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: 0.004505962365102407 | validation: 0.01283451371003747]
	TIME [epoch: 9.06 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006656228606654213		[learning rate: 0.00011101]
	Learning Rate: 0.000111012
	LOSS [training: 0.006656228606654213 | validation: 0.005417931373135188]
	TIME [epoch: 9.06 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00024176137907655848		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: -0.00024176137907655848 | validation: 0.014130250826145219]
	TIME [epoch: 9.06 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010985111029100247		[learning rate: 0.00011047]
	Learning Rate: 0.000110475
	LOSS [training: 0.010985111029100247 | validation: 0.00628890894159613]
	TIME [epoch: 9.08 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0036749791242204704		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: 0.0036749791242204704 | validation: 0.01730171585122582]
	TIME [epoch: 9.08 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005756332612446793		[learning rate: 0.00010994]
	Learning Rate: 0.000109941
	LOSS [training: 0.005756332612446793 | validation: 0.010530284782516712]
	TIME [epoch: 9.07 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008066300670180956		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.008066300670180956 | validation: 0.008947786761390528]
	TIME [epoch: 9.06 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007547778311011858		[learning rate: 0.00010941]
	Learning Rate: 0.000109409
	LOSS [training: 0.007547778311011858 | validation: 0.009352385955863476]
	TIME [epoch: 9.06 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017746335786806202		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: 0.0017746335786806202 | validation: 0.0031627308670184135]
	TIME [epoch: 9.08 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003934993022189307		[learning rate: 0.00010888]
	Learning Rate: 0.00010888
	LOSS [training: 0.003934993022189307 | validation: 0.011992452838190322]
	TIME [epoch: 9.07 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002824779525962807		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: 0.002824779525962807 | validation: 0.015325320526811834]
	TIME [epoch: 9.06 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006191003489680836		[learning rate: 0.00010835]
	Learning Rate: 0.000108353
	LOSS [training: 0.006191003489680836 | validation: 0.005320303333377015]
	TIME [epoch: 9.07 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00714928651702394		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: 0.00714928651702394 | validation: 0.01841485717604899]
	TIME [epoch: 9.06 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002942531498333107		[learning rate: 0.00010783]
	Learning Rate: 0.000107829
	LOSS [training: 0.002942531498333107 | validation: 0.007925213698254024]
	TIME [epoch: 9.08 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007716221067019494		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: 0.007716221067019494 | validation: 0.007843277443880392]
	TIME [epoch: 9.06 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0030127838261351458		[learning rate: 0.00010731]
	Learning Rate: 0.000107308
	LOSS [training: 0.0030127838261351458 | validation: 0.010807504455034988]
	TIME [epoch: 9.06 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008376161298570144		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: 0.008376161298570144 | validation: 0.0190547948001342]
	TIME [epoch: 9.06 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0043410190059995635		[learning rate: 0.00010679]
	Learning Rate: 0.000106789
	LOSS [training: 0.0043410190059995635 | validation: 0.01190838239880478]
	TIME [epoch: 9.08 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006487145523782217		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: 0.006487145523782217 | validation: 0.0065430027297783385]
	TIME [epoch: 9.07 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009252862118669497		[learning rate: 0.00010627]
	Learning Rate: 0.000106273
	LOSS [training: 0.009252862118669497 | validation: -0.0007238462160815166]
	TIME [epoch: 9.06 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004817949579495961		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: 0.004817949579495961 | validation: 0.010061262941833533]
	TIME [epoch: 9.07 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001276659887504664		[learning rate: 0.00010576]
	Learning Rate: 0.000105759
	LOSS [training: 0.001276659887504664 | validation: 0.007830998074233089]
	TIME [epoch: 9.06 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004129210501024969		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: 0.004129210501024969 | validation: 0.008349724991684796]
	TIME [epoch: 9.08 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014188558342029018		[learning rate: 0.00010525]
	Learning Rate: 0.000105247
	LOSS [training: 0.0014188558342029018 | validation: 0.00010801831229452843]
	TIME [epoch: 9.07 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005632529079937869		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.005632529079937869 | validation: 0.007573203181770497]
	TIME [epoch: 9.06 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004874387295265169		[learning rate: 0.00010474]
	Learning Rate: 0.000104738
	LOSS [training: 0.004874387295265169 | validation: 0.017638780256456876]
	TIME [epoch: 9.06 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004306884459931047		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.004306884459931047 | validation: 0.0017919494050706178]
	TIME [epoch: 9.07 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005463938655924104		[learning rate: 0.00010423]
	Learning Rate: 0.000104232
	LOSS [training: 0.005463938655924104 | validation: 0.015952498692270528]
	TIME [epoch: 9.07 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00999904457157511		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: 0.00999904457157511 | validation: 0.011175393937806758]
	TIME [epoch: 9.06 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00900453071255364		[learning rate: 0.00010373]
	Learning Rate: 0.000103728
	LOSS [training: 0.00900453071255364 | validation: 0.006007233084793309]
	TIME [epoch: 9.07 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005495086733486082		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: 0.0005495086733486082 | validation: 0.006318858816961764]
	TIME [epoch: 9.06 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005880260798939167		[learning rate: 0.00010323]
	Learning Rate: 0.000103226
	LOSS [training: 0.005880260798939167 | validation: 0.0074227909202656565]
	TIME [epoch: 9.09 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002678419744644142		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: 0.002678419744644142 | validation: 0.004419634575874872]
	TIME [epoch: 9.07 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007739525093628885		[learning rate: 0.00010273]
	Learning Rate: 0.000102727
	LOSS [training: 0.007739525093628885 | validation: 0.00801706611913722]
	TIME [epoch: 9.06 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007569775787750238		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: 0.007569775787750238 | validation: 0.010625619246755025]
	TIME [epoch: 9.07 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002231986259023443		[learning rate: 0.00010223]
	Learning Rate: 0.00010223
	LOSS [training: 0.002231986259023443 | validation: 0.012117488744068193]
	TIME [epoch: 9.06 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008587755966938067		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: 0.008587755966938067 | validation: 0.014015153539596033]
	TIME [epoch: 9.08 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004181049233367389		[learning rate: 0.00010174]
	Learning Rate: 0.000101736
	LOSS [training: 0.004181049233367389 | validation: 0.006819601175544454]
	TIME [epoch: 9.06 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0053935050251034105		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: 0.0053935050251034105 | validation: 0.018308877161839106]
	TIME [epoch: 9.06 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004049604305917287		[learning rate: 0.00010124]
	Learning Rate: 0.000101244
	LOSS [training: 0.004049604305917287 | validation: 0.011705401237860518]
	TIME [epoch: 9.06 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006791199277966702		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: 0.0006791199277966702 | validation: 0.005356142433166867]
	TIME [epoch: 9.08 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005885045144168996		[learning rate: 0.00010075]
	Learning Rate: 0.000100754
	LOSS [training: 0.005885045144168996 | validation: 0.006594284570680047]
	TIME [epoch: 9.06 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003471523692685959		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.003471523692685959 | validation: 0.00787019454204387]
	TIME [epoch: 9.06 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0012877028692618963		[learning rate: 0.00010027]
	Learning Rate: 0.000100267
	LOSS [training: 0.0012877028692618963 | validation: 0.011583621083870385]
	TIME [epoch: 9.07 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004285932300767187		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.004285932300767187 | validation: 0.006063582716154055]
	TIME [epoch: 9.04 sec]
Finished training in 18270.163 seconds.
