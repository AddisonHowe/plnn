Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r1', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 176265972

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.960479738571195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.960479738571195 | validation: 8.913573928336834]
	TIME [epoch: 79.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 10/10] avg loss: 10.573975009602698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.573975009602698 | validation: 9.715549290973769]
	TIME [epoch: 8.38 sec]
EPOCH 3/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.783639778090388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.783639778090388 | validation: 7.73774542341414]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.543019320903753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.543019320903753 | validation: 5.960274190121002]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.691788265201225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.691788265201225 | validation: 9.242338459852926]
	TIME [epoch: 8.37 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 10/10] avg loss: 8.007139787920924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.007139787920924 | validation: 7.501274888096322]
	TIME [epoch: 8.36 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.584630798820865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.584630798820865 | validation: 5.81886546767927]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.657413488226636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.657413488226636 | validation: 6.392460558922522]
	TIME [epoch: 8.36 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.232960809424429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.232960809424429 | validation: 5.634532237068516]
	TIME [epoch: 8.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.46023580044599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.46023580044599 | validation: 6.095861814675873]
	TIME [epoch: 8.36 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.281910291906554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.281910291906554 | validation: 5.645580573377383]
	TIME [epoch: 8.36 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.159665632997177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.159665632997177 | validation: 5.181278123599117]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.837293857361601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.837293857361601 | validation: 6.151930659575724]
	TIME [epoch: 8.38 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.109244256391594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.109244256391594 | validation: 6.209741327019582]
	TIME [epoch: 8.36 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 10/10] avg loss: 6.199551506869673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.199551506869673 | validation: 6.871435954893061]
	TIME [epoch: 8.35 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.930773112556139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.930773112556139 | validation: 6.023165089451681]
	TIME [epoch: 8.35 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.578199824780668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.578199824780668 | validation: 4.525750043820921]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 10/10] avg loss: 7.137984581745506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.137984581745506 | validation: 4.19617014936974]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.746762500638582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.746762500638582 | validation: 5.241327006860995]
	TIME [epoch: 8.36 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.963599823150605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.963599823150605 | validation: 4.3002396254033695]
	TIME [epoch: 8.36 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.367589846346766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.367589846346766 | validation: 4.422534857588817]
	TIME [epoch: 8.37 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.71838620495589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.71838620495589 | validation: 6.084866074249496]
	TIME [epoch: 8.38 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.890458067338136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.890458067338136 | validation: 4.532059353689821]
	TIME [epoch: 8.36 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.381766788237806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.381766788237806 | validation: 4.095980040801976]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.132887433768127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.132887433768127 | validation: 4.638046368463884]
	TIME [epoch: 8.35 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.618782035107624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.618782035107624 | validation: 4.769028041739311]
	TIME [epoch: 8.37 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.137090278231621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.137090278231621 | validation: 5.914954810490865]
	TIME [epoch: 8.34 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 10/10] avg loss: 5.040147565734509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.040147565734509 | validation: 4.669144321804291]
	TIME [epoch: 8.34 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.213160159133851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.213160159133851 | validation: 4.194368648431545]
	TIME [epoch: 8.34 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.863414675208451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.863414675208451 | validation: 4.046822823606887]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.8957990874730806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8957990874730806 | validation: 4.21875711637689]
	TIME [epoch: 8.35 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.935019361257274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.935019361257274 | validation: 5.026372840977929]
	TIME [epoch: 8.34 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.513361279687129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.513361279687129 | validation: 4.775377271459886]
	TIME [epoch: 8.34 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.957439896856478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.957439896856478 | validation: 4.036442378410431]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.7385083160046393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7385083160046393 | validation: 3.724329699437034]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.445087458183065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.445087458183065 | validation: 3.7665420466696444]
	TIME [epoch: 8.35 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.133243623461663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.133243623461663 | validation: 3.7915225781271946]
	TIME [epoch: 8.35 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.5923356959308186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5923356959308186 | validation: 3.6639132186455505]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.578218889607581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.578218889607581 | validation: 3.970991846886961]
	TIME [epoch: 8.38 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.541032657892307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.541032657892307 | validation: 3.1424433562372425]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.24812778103288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.24812778103288 | validation: 4.730433306658834]
	TIME [epoch: 8.35 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.7684599651351744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7684599651351744 | validation: 5.569822335991639]
	TIME [epoch: 8.35 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.093585664012436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.093585664012436 | validation: 3.4888259602789358]
	TIME [epoch: 8.37 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.058718623954477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.058718623954477 | validation: 5.410338881621701]
	TIME [epoch: 8.35 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.353179543879705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.353179543879705 | validation: 3.5802982429522188]
	TIME [epoch: 8.35 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.376407899906898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.376407899906898 | validation: 3.272859409875415]
	TIME [epoch: 8.35 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.7412059741713506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7412059741713506 | validation: 4.115385013465526]
	TIME [epoch: 8.36 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 10/10] avg loss: 4.017977390170641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.017977390170641 | validation: 3.239025971220091]
	TIME [epoch: 8.36 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.3640920320755185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3640920320755185 | validation: 3.0589103107182067]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.32915184651187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.32915184651187 | validation: 3.16491092477112]
	TIME [epoch: 8.34 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.5010257067036625		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 3.5010257067036625 | validation: 3.7015102915866747]
	TIME [epoch: 8.35 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.493133154329274		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 3.493133154329274 | validation: 2.579808869313665]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_52.pth
	Model improved!!!
EPOCH 53/1000:
	Training over batches...
		[batch 10/10] avg loss: 3.0373228093761684		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 3.0373228093761684 | validation: 2.3542635624971577]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_53.pth
	Model improved!!!
EPOCH 54/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.869657020489419		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 2.869657020489419 | validation: 2.053428743552077]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_54.pth
	Model improved!!!
EPOCH 55/1000:
	Training over batches...
		[batch 10/10] avg loss: 2.0640296653697052		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 2.0640296653697052 | validation: 1.7063059592870555]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_55.pth
	Model improved!!!
EPOCH 56/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6872160276287396		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 1.6872160276287396 | validation: 1.5103355338783038]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5654120332985166		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 1.5654120332985166 | validation: 1.4153458924014284]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_57.pth
	Model improved!!!
EPOCH 58/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.8801963298863467		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 1.8801963298863467 | validation: 1.6245207073850318]
	TIME [epoch: 8.34 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5089139059325614		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 1.5089139059325614 | validation: 1.2586165998125285]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_59.pth
	Model improved!!!
EPOCH 60/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4434855904480433		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 1.4434855904480433 | validation: 1.4762476284414219]
	TIME [epoch: 8.37 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.516993659482906		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 1.516993659482906 | validation: 1.4259349249228732]
	TIME [epoch: 8.34 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4525089591150397		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 1.4525089591150397 | validation: 1.5131885297846401]
	TIME [epoch: 8.34 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5752350774577142		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 1.5752350774577142 | validation: 1.2070364150607034]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_63.pth
	Model improved!!!
EPOCH 64/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4229863513894176		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 1.4229863513894176 | validation: 1.2994757436555229]
	TIME [epoch: 8.36 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5129363921636025		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 1.5129363921636025 | validation: 1.3871524533357031]
	TIME [epoch: 8.35 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.9042262295305168		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 1.9042262295305168 | validation: 1.2446687484448533]
	TIME [epoch: 8.34 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.425374680932845		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 1.425374680932845 | validation: 2.085696418631211]
	TIME [epoch: 8.33 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.7085899045287682		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 1.7085899045287682 | validation: 1.343404101717691]
	TIME [epoch: 8.34 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.563009328509364		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 1.563009328509364 | validation: 1.5047900190604253]
	TIME [epoch: 8.36 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6915547173067254		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 1.6915547173067254 | validation: 1.9412212651949596]
	TIME [epoch: 8.33 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6106394296169353		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.6106394296169353 | validation: 1.2646220701170292]
	TIME [epoch: 8.33 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.570186597828793		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 1.570186597828793 | validation: 1.7700471516520377]
	TIME [epoch: 8.33 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5566905506775484		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 1.5566905506775484 | validation: 1.3960894722758042]
	TIME [epoch: 8.36 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4704864691565847		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 1.4704864691565847 | validation: 2.0649889901059124]
	TIME [epoch: 8.34 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.510627265828688		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 1.510627265828688 | validation: 1.2472425258406457]
	TIME [epoch: 8.34 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4457458921280169		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 1.4457458921280169 | validation: 1.637176419584075]
	TIME [epoch: 8.34 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4878673677563807		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 1.4878673677563807 | validation: 1.5190500513978853]
	TIME [epoch: 8.35 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6111436680699036		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 1.6111436680699036 | validation: 1.1792003176816226]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_78.pth
	Model improved!!!
EPOCH 79/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5656481386551473		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 1.5656481386551473 | validation: 1.5709133217279667]
	TIME [epoch: 8.34 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.481160594828968		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 1.481160594828968 | validation: 1.4472633674778497]
	TIME [epoch: 8.34 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3741861231478594		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 1.3741861231478594 | validation: 1.3256344285852901]
	TIME [epoch: 8.35 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5234420127944222		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 1.5234420127944222 | validation: 1.3713805939697896]
	TIME [epoch: 8.36 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3136517029849064		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 1.3136517029849064 | validation: 1.0557040078210462]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_83.pth
	Model improved!!!
EPOCH 84/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3053524069759228		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 1.3053524069759228 | validation: 1.3280477156907826]
	TIME [epoch: 8.34 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3851174919484985		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 1.3851174919484985 | validation: 1.2171223479508972]
	TIME [epoch: 8.33 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3148590141628635		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 1.3148590141628635 | validation: 1.3410189378742072]
	TIME [epoch: 8.37 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3053052833764895		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 1.3053052833764895 | validation: 1.4360383974202815]
	TIME [epoch: 8.34 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3318786171161732		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.3318786171161732 | validation: 1.2078379313156216]
	TIME [epoch: 8.34 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3141306688209853		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.3141306688209853 | validation: 1.1105045183016435]
	TIME [epoch: 8.34 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2450160122787448		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.2450160122787448 | validation: 1.4617369163633867]
	TIME [epoch: 8.36 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3791392389276915		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 1.3791392389276915 | validation: 1.3146785442604818]
	TIME [epoch: 8.34 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3382086649251441		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 1.3382086649251441 | validation: 1.438050888319053]
	TIME [epoch: 8.35 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3183808655603806		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 1.3183808655603806 | validation: 1.039812991426583]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_93.pth
	Model improved!!!
EPOCH 94/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.368438170015642		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 1.368438170015642 | validation: 1.1861590845880752]
	TIME [epoch: 8.35 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.307859648237471		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 1.307859648237471 | validation: 1.1153617016862303]
	TIME [epoch: 8.36 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3943655066388252		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.3943655066388252 | validation: 1.2256797717492396]
	TIME [epoch: 8.34 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4336615882382622		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 1.4336615882382622 | validation: 1.632139503901692]
	TIME [epoch: 8.34 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3940163368386558		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.3940163368386558 | validation: 1.7167028374197009]
	TIME [epoch: 8.34 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3850203163087278		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.3850203163087278 | validation: 1.1322850681495205]
	TIME [epoch: 8.37 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2664243882943542		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.2664243882943542 | validation: 1.4751689453362762]
	TIME [epoch: 8.34 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2549402165964931		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.2549402165964931 | validation: 2.009525039499647]
	TIME [epoch: 8.34 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.44421905802957		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.44421905802957 | validation: 1.7317189779759974]
	TIME [epoch: 8.34 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.347209861843671		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.347209861843671 | validation: 1.3033862446257434]
	TIME [epoch: 8.37 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2721374242541554		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.2721374242541554 | validation: 1.2936685515070707]
	TIME [epoch: 8.35 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4122772964405812		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 1.4122772964405812 | validation: 1.4642944346538114]
	TIME [epoch: 8.34 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2123086536555983		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 1.2123086536555983 | validation: 3.1309783867865724]
	TIME [epoch: 8.35 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.552541083176363		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 1.552541083176363 | validation: 1.2287399645689034]
	TIME [epoch: 8.36 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1589214906727157		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.1589214906727157 | validation: 1.1276035597218304]
	TIME [epoch: 8.36 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4543790878970797		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.4543790878970797 | validation: 1.0205128900424305]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_109.pth
	Model improved!!!
EPOCH 110/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3032667866893703		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.3032667866893703 | validation: 1.393150218297671]
	TIME [epoch: 8.35 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5328323939402346		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.5328323939402346 | validation: 1.1637745307930594]
	TIME [epoch: 8.34 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.4842866054928283		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 1.4842866054928283 | validation: 1.3149331794848136]
	TIME [epoch: 8.37 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.212513784617633		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 1.212513784617633 | validation: 1.169373352570453]
	TIME [epoch: 8.34 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.211072510067358		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 1.211072510067358 | validation: 1.1260514405149085]
	TIME [epoch: 8.34 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.236223929240483		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.236223929240483 | validation: 1.6093233297386507]
	TIME [epoch: 8.34 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3598888007555037		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 1.3598888007555037 | validation: 1.5199181539695341]
	TIME [epoch: 8.36 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2468885790067326		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 1.2468885790067326 | validation: 1.155567527748174]
	TIME [epoch: 8.34 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1793852036187595		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 1.1793852036187595 | validation: 1.2702224148013523]
	TIME [epoch: 8.34 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2130016621909139		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 1.2130016621909139 | validation: 1.1029675622195156]
	TIME [epoch: 8.34 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2762705686552116		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.2762705686552116 | validation: 1.6040708092098896]
	TIME [epoch: 8.34 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1993224015650037		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 1.1993224015650037 | validation: 1.091815333004499]
	TIME [epoch: 8.36 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3328302644008423		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 1.3328302644008423 | validation: 1.024438659512101]
	TIME [epoch: 8.34 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1664880636553938		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 1.1664880636553938 | validation: 0.9789370091247611]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_123.pth
	Model improved!!!
EPOCH 124/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1526866101926683		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 1.1526866101926683 | validation: 1.1412545608021538]
	TIME [epoch: 8.34 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2066188628487837		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 1.2066188628487837 | validation: 1.030999143261742]
	TIME [epoch: 8.37 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.266037700271882		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 1.266037700271882 | validation: 1.0935033048266845]
	TIME [epoch: 8.34 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.6087201980293568		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 1.6087201980293568 | validation: 1.0470850047303841]
	TIME [epoch: 8.33 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.233472703640901		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.233472703640901 | validation: 1.0447411268331304]
	TIME [epoch: 8.34 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0980333414177728		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 1.0980333414177728 | validation: 1.1288872004906252]
	TIME [epoch: 8.36 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.242039259843955		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 1.242039259843955 | validation: 1.6791697003687895]
	TIME [epoch: 8.34 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3145370477397185		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 1.3145370477397185 | validation: 0.9410392298055232]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_131.pth
	Model improved!!!
EPOCH 132/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1587561678572897		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 1.1587561678572897 | validation: 1.0377440897261738]
	TIME [epoch: 8.34 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.063692428251717		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 1.063692428251717 | validation: 0.9715624969360634]
	TIME [epoch: 8.35 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1996820521264469		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 1.1996820521264469 | validation: 0.8544848919305651]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_134.pth
	Model improved!!!
EPOCH 135/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1121649377169036		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 1.1121649377169036 | validation: 1.5792049941297597]
	TIME [epoch: 8.34 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.347187982879971		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 1.347187982879971 | validation: 2.2475490882830216]
	TIME [epoch: 8.34 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3950595302098185		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 1.3950595302098185 | validation: 1.3712156728655516]
	TIME [epoch: 8.34 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1853616842119923		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.1853616842119923 | validation: 0.9738624587426271]
	TIME [epoch: 8.36 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3087009523944984		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 1.3087009523944984 | validation: 2.8597365591797064]
	TIME [epoch: 8.33 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.5703381928073976		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 1.5703381928073976 | validation: 1.515465612180055]
	TIME [epoch: 8.33 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1613530694355731		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 1.1613530694355731 | validation: 0.9967980415388555]
	TIME [epoch: 8.33 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.196381738875149		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 1.196381738875149 | validation: 1.1310874394268224]
	TIME [epoch: 8.36 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1007755007159141		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 1.1007755007159141 | validation: 0.9466301143797756]
	TIME [epoch: 8.34 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2666691620198096		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 1.2666691620198096 | validation: 1.088897404342799]
	TIME [epoch: 8.34 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.356976260641625		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 1.356976260641625 | validation: 1.456708402556754]
	TIME [epoch: 8.34 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.374572446995858		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 1.374572446995858 | validation: 1.2332487602620281]
	TIME [epoch: 8.35 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.14070015040523		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 1.14070015040523 | validation: 0.9920112700022327]
	TIME [epoch: 8.35 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1576523364440707		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 1.1576523364440707 | validation: 1.243209235571452]
	TIME [epoch: 8.34 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.244772203177313		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 1.244772203177313 | validation: 1.0873057143413813]
	TIME [epoch: 8.33 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0750643014642007		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 1.0750643014642007 | validation: 1.1003485547304837]
	TIME [epoch: 8.33 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0562043070428486		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 1.0562043070428486 | validation: 0.9775114041227255]
	TIME [epoch: 8.36 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0884105699674103		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 1.0884105699674103 | validation: 0.9455292084681686]
	TIME [epoch: 8.33 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1403509591596934		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 1.1403509591596934 | validation: 0.8635149809685493]
	TIME [epoch: 8.34 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0921509349033156		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 1.0921509349033156 | validation: 0.9112807125114182]
	TIME [epoch: 8.33 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1108387463720955		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 1.1108387463720955 | validation: 1.343346299533944]
	TIME [epoch: 8.36 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.16266255996869		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 1.16266255996869 | validation: 1.174900055245409]
	TIME [epoch: 8.34 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2179094339542307		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 1.2179094339542307 | validation: 1.2376934646560593]
	TIME [epoch: 8.34 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2289838106778785		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 1.2289838106778785 | validation: 1.0803445534246274]
	TIME [epoch: 8.34 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0647338934757202		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 1.0647338934757202 | validation: 1.0145260961850857]
	TIME [epoch: 8.35 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.157608545812241		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 1.157608545812241 | validation: 1.1558219569854162]
	TIME [epoch: 8.35 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2486051093486326		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 1.2486051093486326 | validation: 1.0036970102560718]
	TIME [epoch: 8.34 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0509465898912143		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 1.0509465898912143 | validation: 1.1947984870561985]
	TIME [epoch: 8.34 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1290272488181512		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 1.1290272488181512 | validation: 0.9959820815747029]
	TIME [epoch: 8.33 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1638831287878566		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 1.1638831287878566 | validation: 0.9557524832389808]
	TIME [epoch: 8.37 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0455035447854195		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 1.0455035447854195 | validation: 1.121302246780316]
	TIME [epoch: 8.34 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0078564469295317		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 1.0078564469295317 | validation: 1.168592307571978]
	TIME [epoch: 8.33 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.094930788287622		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 1.094930788287622 | validation: 0.8791736858811625]
	TIME [epoch: 8.34 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.03147777216842		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 1.03147777216842 | validation: 1.2040705508174931]
	TIME [epoch: 8.36 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.2578878991229638		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 1.2578878991229638 | validation: 1.1375150634345603]
	TIME [epoch: 8.34 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.146410533955636		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 1.146410533955636 | validation: 1.4805173593637813]
	TIME [epoch: 8.34 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1395913933487989		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 1.1395913933487989 | validation: 1.4616178828625963]
	TIME [epoch: 8.34 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.487114343220108		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 1.487114343220108 | validation: 1.0336015062657897]
	TIME [epoch: 8.35 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0032223552539772		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 1.0032223552539772 | validation: 0.9080876347331446]
	TIME [epoch: 8.36 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1049507223886441		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 1.1049507223886441 | validation: 1.006949330791305]
	TIME [epoch: 8.35 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.97595919479523		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.97595919479523 | validation: 0.9654660402527098]
	TIME [epoch: 8.34 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9810932885708119		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.9810932885708119 | validation: 0.9017883141128475]
	TIME [epoch: 8.34 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0812749087551263		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 1.0812749087551263 | validation: 0.8067434839602466]
	TIME [epoch: 8.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_177.pth
	Model improved!!!
EPOCH 178/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9811462477414921		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.9811462477414921 | validation: 0.8513080179337009]
	TIME [epoch: 8.33 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9796528223503541		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.9796528223503541 | validation: 1.0559342764743813]
	TIME [epoch: 8.33 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.341707964555558		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 1.341707964555558 | validation: 0.9769695528569996]
	TIME [epoch: 8.33 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0665387277865306		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 1.0665387277865306 | validation: 0.8875633979874302]
	TIME [epoch: 8.36 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9834116090495426		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.9834116090495426 | validation: 0.9098685896970651]
	TIME [epoch: 8.33 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0935713198361856		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 1.0935713198361856 | validation: 1.498309835052074]
	TIME [epoch: 8.33 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.015209185215165		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 1.015209185215165 | validation: 0.8915145743986841]
	TIME [epoch: 8.33 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1990145652778306		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 1.1990145652778306 | validation: 1.0638430265007586]
	TIME [epoch: 8.34 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.982250747692964		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.982250747692964 | validation: 0.8329557892508552]
	TIME [epoch: 8.34 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0401942223871536		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 1.0401942223871536 | validation: 0.7909469867627428]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_187.pth
	Model improved!!!
EPOCH 188/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3808156658197241		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 1.3808156658197241 | validation: 0.9647751013217609]
	TIME [epoch: 8.32 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.153310112374037		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 1.153310112374037 | validation: 0.7766771247179103]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_189.pth
	Model improved!!!
EPOCH 190/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1592924430175602		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 1.1592924430175602 | validation: 0.9420260861587276]
	TIME [epoch: 8.37 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0203273866820322		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 1.0203273866820322 | validation: 0.9440245467414881]
	TIME [epoch: 8.34 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.038075865129339		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 1.038075865129339 | validation: 0.8814110427221423]
	TIME [epoch: 8.33 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1942174065117044		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 1.1942174065117044 | validation: 1.1626858143337373]
	TIME [epoch: 8.32 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1601653253708164		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 1.1601653253708164 | validation: 1.074146619073097]
	TIME [epoch: 8.35 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9477690638340158		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.9477690638340158 | validation: 0.8328037958239916]
	TIME [epoch: 8.32 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9334937209833445		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.9334937209833445 | validation: 1.0340257967043047]
	TIME [epoch: 8.33 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1148294254272193		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 1.1148294254272193 | validation: 0.8502067619346266]
	TIME [epoch: 8.32 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9538850416973543		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.9538850416973543 | validation: 1.041533699818134]
	TIME [epoch: 8.34 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9961405992633872		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.9961405992633872 | validation: 0.9529915498918722]
	TIME [epoch: 8.33 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9417454165505796		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.9417454165505796 | validation: 0.981202827915774]
	TIME [epoch: 8.32 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0878916835100099		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 1.0878916835100099 | validation: 0.7595506546728442]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_201.pth
	Model improved!!!
EPOCH 202/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9250223389675731		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.9250223389675731 | validation: 0.8409198966148668]
	TIME [epoch: 8.34 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.204521305676667		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 1.204521305676667 | validation: 1.3308053665554467]
	TIME [epoch: 8.37 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0622537700130825		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 1.0622537700130825 | validation: 0.8273749507358061]
	TIME [epoch: 8.34 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9827893077256604		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.9827893077256604 | validation: 1.0675544997224116]
	TIME [epoch: 8.33 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1328304978720418		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 1.1328304978720418 | validation: 1.01607478767803]
	TIME [epoch: 8.32 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9640014399455789		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.9640014399455789 | validation: 2.613066284052862]
	TIME [epoch: 8.37 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.3794906626682744		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 1.3794906626682744 | validation: 1.1490581625791143]
	TIME [epoch: 8.33 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9248924694109014		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.9248924694109014 | validation: 0.7343945758064716]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_209.pth
	Model improved!!!
EPOCH 210/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0731197848341936		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 1.0731197848341936 | validation: 0.8379138897573186]
	TIME [epoch: 8.34 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.007399711653617		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 1.007399711653617 | validation: 0.9283593629955155]
	TIME [epoch: 8.35 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0443010199782727		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 1.0443010199782727 | validation: 0.9924056126046699]
	TIME [epoch: 8.34 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9580873995551753		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.9580873995551753 | validation: 0.7516211894437831]
	TIME [epoch: 8.33 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9709445689320851		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.9709445689320851 | validation: 0.7843244204993308]
	TIME [epoch: 8.33 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0127031908771253		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 1.0127031908771253 | validation: 0.8748306518681501]
	TIME [epoch: 8.34 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9980137376544415		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.9980137376544415 | validation: 0.7389490333675663]
	TIME [epoch: 8.36 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8785947239205194		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.8785947239205194 | validation: 1.1938704579541617]
	TIME [epoch: 8.32 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.982827343705017		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.982827343705017 | validation: 1.0156658612672813]
	TIME [epoch: 8.34 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9144487731692271		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.9144487731692271 | validation: 0.805051524916046]
	TIME [epoch: 8.33 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9977582888533905		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.9977582888533905 | validation: 1.112939429988825]
	TIME [epoch: 8.36 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1587473536291144		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 1.1587473536291144 | validation: 0.8000175480854246]
	TIME [epoch: 8.33 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0448392316230488		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 1.0448392316230488 | validation: 1.0854119177825143]
	TIME [epoch: 8.33 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9404240374618924		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.9404240374618924 | validation: 0.8544013121815515]
	TIME [epoch: 8.33 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8559023081870348		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.8559023081870348 | validation: 1.4167996487419126]
	TIME [epoch: 8.33 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.1058936419876804		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 1.1058936419876804 | validation: 0.7820939493887731]
	TIME [epoch: 8.33 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.871021642771416		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.871021642771416 | validation: 0.8162770377409645]
	TIME [epoch: 8.32 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0285255773497035		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 1.0285255773497035 | validation: 0.7509210250292144]
	TIME [epoch: 8.31 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0256678103893384		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 1.0256678103893384 | validation: 1.0437695525846555]
	TIME [epoch: 8.32 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0374246331484924		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 1.0374246331484924 | validation: 0.878896987383428]
	TIME [epoch: 8.34 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0372346817883085		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 1.0372346817883085 | validation: 1.083382273650643]
	TIME [epoch: 8.32 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9456819500668132		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.9456819500668132 | validation: 0.7655769013585594]
	TIME [epoch: 8.31 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.890316483042852		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.890316483042852 | validation: 0.7470177820773235]
	TIME [epoch: 8.32 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9341439933877596		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.9341439933877596 | validation: 1.2470464541856816]
	TIME [epoch: 8.34 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9967391100745395		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.9967391100745395 | validation: 0.9487422959063534]
	TIME [epoch: 8.32 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9504136797955114		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.9504136797955114 | validation: 0.831775460412338]
	TIME [epoch: 8.32 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.904686618173223		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.904686618173223 | validation: 0.8902457121552102]
	TIME [epoch: 8.32 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9239328792917998		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.9239328792917998 | validation: 0.8447055479428334]
	TIME [epoch: 8.33 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8713035142426625		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.8713035142426625 | validation: 0.8880735183613757]
	TIME [epoch: 8.33 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9061503758495603		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.9061503758495603 | validation: 0.7331188471122987]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_239.pth
	Model improved!!!
EPOCH 240/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8335499281653289		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.8335499281653289 | validation: 0.847374424333644]
	TIME [epoch: 8.34 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0787860500792819		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 1.0787860500792819 | validation: 0.7414847376346068]
	TIME [epoch: 8.32 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9195560054897266		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.9195560054897266 | validation: 0.9997463308463038]
	TIME [epoch: 8.35 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0014182343167302		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 1.0014182343167302 | validation: 0.8615468932695014]
	TIME [epoch: 8.32 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0285807168613903		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 1.0285807168613903 | validation: 0.7646558477504858]
	TIME [epoch: 8.32 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9102153027844299		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.9102153027844299 | validation: 0.9886710368754815]
	TIME [epoch: 8.32 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8499643623134376		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.8499643623134376 | validation: 0.9063792117993277]
	TIME [epoch: 8.35 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.864949768791989		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.864949768791989 | validation: 1.127483101859283]
	TIME [epoch: 8.32 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8576786210171343		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.8576786210171343 | validation: 0.8554991009866731]
	TIME [epoch: 8.32 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8891661992032404		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.8891661992032404 | validation: 0.8244184030338596]
	TIME [epoch: 8.32 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8288129114556929		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.8288129114556929 | validation: 0.7451871226878481]
	TIME [epoch: 8.33 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8908003531033744		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.8908003531033744 | validation: 0.8025515492293391]
	TIME [epoch: 8.33 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9068575508849619		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.9068575508849619 | validation: 0.7087489342288499]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_252.pth
	Model improved!!!
EPOCH 253/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9350241666033549		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.9350241666033549 | validation: 0.7647926571740287]
	TIME [epoch: 8.33 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9576114210160211		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.9576114210160211 | validation: 0.8926116438465982]
	TIME [epoch: 8.33 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9839376183305337		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.9839376183305337 | validation: 0.8530257205961244]
	TIME [epoch: 8.35 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9004585863346083		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.9004585863346083 | validation: 0.7618606206575418]
	TIME [epoch: 8.32 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9636127911433471		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.9636127911433471 | validation: 0.8757938028025773]
	TIME [epoch: 8.32 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8462963121151104		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.8462963121151104 | validation: 0.9336213185694655]
	TIME [epoch: 8.32 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8734028257779723		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.8734028257779723 | validation: 1.2429148088664324]
	TIME [epoch: 8.35 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0089514145670289		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 1.0089514145670289 | validation: 1.0865098514208569]
	TIME [epoch: 8.32 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9978623124186005		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.9978623124186005 | validation: 0.7417676265512952]
	TIME [epoch: 8.32 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8365166165988305		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.8365166165988305 | validation: 0.7916969705437992]
	TIME [epoch: 8.32 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9425316414089056		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.9425316414089056 | validation: 0.6585455988954283]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_263.pth
	Model improved!!!
EPOCH 264/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.0147263987007296		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 1.0147263987007296 | validation: 0.7590647260525829]
	TIME [epoch: 8.36 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.901008918007568		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.901008918007568 | validation: 1.0824280133726694]
	TIME [epoch: 8.35 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9217904590069086		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.9217904590069086 | validation: 0.7947636554774566]
	TIME [epoch: 8.35 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.903230559308391		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.903230559308391 | validation: 0.702102570207368]
	TIME [epoch: 8.35 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9442761198556161		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.9442761198556161 | validation: 0.9188350577264472]
	TIME [epoch: 8.38 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8958915114143924		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.8958915114143924 | validation: 1.0744691051701785]
	TIME [epoch: 8.35 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8072739468567596		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.8072739468567596 | validation: 0.7985690907915943]
	TIME [epoch: 8.35 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9307152458027769		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.9307152458027769 | validation: 1.2380850578232936]
	TIME [epoch: 8.34 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8931104622100854		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.8931104622100854 | validation: 0.8028230685743087]
	TIME [epoch: 8.37 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7969180017143193		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.7969180017143193 | validation: 1.1208149679325135]
	TIME [epoch: 8.35 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9586787822548016		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.9586787822548016 | validation: 0.7365371403598997]
	TIME [epoch: 8.35 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.904740670539565		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.904740670539565 | validation: 0.7615047215797706]
	TIME [epoch: 8.35 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.84385937591589		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.84385937591589 | validation: 0.7628505312002285]
	TIME [epoch: 8.36 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8237075129310577		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.8237075129310577 | validation: 0.7077562696148791]
	TIME [epoch: 8.36 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9632559074383469		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.9632559074383469 | validation: 0.8158490700167381]
	TIME [epoch: 8.35 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8388075229074261		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.8388075229074261 | validation: 0.7109674751853566]
	TIME [epoch: 8.35 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 10/10] avg loss: 1.091479203511476		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 1.091479203511476 | validation: 0.9513234257504077]
	TIME [epoch: 8.35 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.850336450462264		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.850336450462264 | validation: 0.6516370909248823]
	TIME [epoch: 8.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_281.pth
	Model improved!!!
EPOCH 282/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8016743723520741		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.8016743723520741 | validation: 0.8626047586161305]
	TIME [epoch: 8.35 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8280014333829431		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.8280014333829431 | validation: 0.6681996793789831]
	TIME [epoch: 8.35 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8010476043643813		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.8010476043643813 | validation: 0.9526089651927927]
	TIME [epoch: 8.34 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8213394204650598		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.8213394204650598 | validation: 0.7570804493006906]
	TIME [epoch: 8.37 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9172197207692794		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.9172197207692794 | validation: 0.6808173444827887]
	TIME [epoch: 8.35 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7893443583880291		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.7893443583880291 | validation: 0.5950276554825602]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_287.pth
	Model improved!!!
EPOCH 288/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7545405883726914		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.7545405883726914 | validation: 0.6794766129011028]
	TIME [epoch: 8.35 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7409278075728634		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.7409278075728634 | validation: 0.9131063887993341]
	TIME [epoch: 8.36 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7841374695050275		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.7841374695050275 | validation: 0.619507926832625]
	TIME [epoch: 8.36 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8230243525918132		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.8230243525918132 | validation: 0.766211985440463]
	TIME [epoch: 8.35 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7756101277390451		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.7756101277390451 | validation: 0.7029603252700143]
	TIME [epoch: 8.35 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7618347239910747		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.7618347239910747 | validation: 0.7109739331830709]
	TIME [epoch: 8.35 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7273352105912895		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.7273352105912895 | validation: 0.6227934998862111]
	TIME [epoch: 8.38 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7544113118044609		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.7544113118044609 | validation: 0.6334019334372754]
	TIME [epoch: 8.35 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.775986825194447		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.775986825194447 | validation: 0.7512521099173817]
	TIME [epoch: 8.35 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7257595323340948		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.7257595323340948 | validation: 0.6258606470663894]
	TIME [epoch: 8.35 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7383735431487467		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.7383735431487467 | validation: 0.6149435584232656]
	TIME [epoch: 8.37 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7138070104623213		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.7138070104623213 | validation: 0.6458619758183932]
	TIME [epoch: 8.35 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9523917749123039		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.9523917749123039 | validation: 0.7599740345655379]
	TIME [epoch: 8.35 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7838537643142107		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.7838537643142107 | validation: 0.6129947747095117]
	TIME [epoch: 8.35 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7807539902019507		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.7807539902019507 | validation: 1.3763609114541158]
	TIME [epoch: 8.37 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9540433460253421		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.9540433460253421 | validation: 1.1060563360794295]
	TIME [epoch: 8.36 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9405466273878786		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.9405466273878786 | validation: 0.8797218677122114]
	TIME [epoch: 8.35 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7573770752213289		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.7573770752213289 | validation: 0.6767315660222357]
	TIME [epoch: 8.35 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7303631282881531		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.7303631282881531 | validation: 0.5720215422094115]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_306.pth
	Model improved!!!
EPOCH 307/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6918805318582664		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.6918805318582664 | validation: 0.6907744911956601]
	TIME [epoch: 8.37 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7278577686044378		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.7278577686044378 | validation: 0.7687707600241109]
	TIME [epoch: 8.34 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8517938412863602		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.8517938412863602 | validation: 0.6379757204930452]
	TIME [epoch: 8.35 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7580925006480184		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.7580925006480184 | validation: 0.7763395783609461]
	TIME [epoch: 8.34 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7342458125210507		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.7342458125210507 | validation: 0.7040188731446884]
	TIME [epoch: 8.37 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9182434965628218		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.9182434965628218 | validation: 0.5293509037133477]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_312.pth
	Model improved!!!
EPOCH 313/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9289221106968275		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.9289221106968275 | validation: 0.850972090793285]
	TIME [epoch: 8.35 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9664236683456547		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.9664236683456547 | validation: 0.8686916696703464]
	TIME [epoch: 8.35 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9173370371112378		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.9173370371112378 | validation: 0.7029870423764905]
	TIME [epoch: 8.37 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8741883495708833		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.8741883495708833 | validation: 0.7109634394462059]
	TIME [epoch: 8.35 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8548319996235744		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.8548319996235744 | validation: 0.7549101203729882]
	TIME [epoch: 8.35 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.9196531312308502		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.9196531312308502 | validation: 0.6940325158241597]
	TIME [epoch: 8.35 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7708754384902583		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.7708754384902583 | validation: 0.646052904872656]
	TIME [epoch: 8.36 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7514101526092776		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.7514101526092776 | validation: 0.5709087582103871]
	TIME [epoch: 8.37 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.746914090269769		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.746914090269769 | validation: 0.8823623165146999]
	TIME [epoch: 8.34 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8362558190710025		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.8362558190710025 | validation: 1.3144494743461088]
	TIME [epoch: 8.34 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8497867036092753		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.8497867036092753 | validation: 0.8917930709833561]
	TIME [epoch: 8.34 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7563474657255298		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.7563474657255298 | validation: 0.6321833892391652]
	TIME [epoch: 8.37 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7416511055936947		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.7416511055936947 | validation: 0.5983173434845166]
	TIME [epoch: 8.33 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.733893109218785		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.733893109218785 | validation: 0.5768503278851486]
	TIME [epoch: 8.33 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6604242248494172		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.6604242248494172 | validation: 0.6189954315000243]
	TIME [epoch: 8.33 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8984276301520691		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.8984276301520691 | validation: 0.7139084939262923]
	TIME [epoch: 8.36 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.742330921109614		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.742330921109614 | validation: 0.6048795356363796]
	TIME [epoch: 8.34 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7931222444747863		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.7931222444747863 | validation: 0.6059786228090679]
	TIME [epoch: 8.34 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6985210771916966		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.6985210771916966 | validation: 0.6449891571147459]
	TIME [epoch: 8.33 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7080033660128845		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.7080033660128845 | validation: 0.6404851111036963]
	TIME [epoch: 8.34 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.741523311122689		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.741523311122689 | validation: 1.001732114047715]
	TIME [epoch: 8.36 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7633468587249747		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.7633468587249747 | validation: 0.6595395365561126]
	TIME [epoch: 8.33 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6424422193362144		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.6424422193362144 | validation: 0.6909088400795643]
	TIME [epoch: 8.34 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7953296478198879		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.7953296478198879 | validation: 0.5819678555135321]
	TIME [epoch: 8.33 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7518341470942257		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.7518341470942257 | validation: 1.1355990972725913]
	TIME [epoch: 8.36 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8391656419523039		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.8391656419523039 | validation: 0.9922221243602682]
	TIME [epoch: 8.34 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8286223237113031		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.8286223237113031 | validation: 0.8700246383150914]
	TIME [epoch: 8.33 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7771458736375984		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.7771458736375984 | validation: 0.9240524975006077]
	TIME [epoch: 8.33 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7956341539534162		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.7956341539534162 | validation: 0.9177005876866307]
	TIME [epoch: 8.35 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7209976525424437		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.7209976525424437 | validation: 1.0058473410498612]
	TIME [epoch: 8.34 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8104570049173857		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.8104570049173857 | validation: 0.9697686103422938]
	TIME [epoch: 8.34 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8076499422713843		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.8076499422713843 | validation: 0.9940057317748022]
	TIME [epoch: 8.33 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8190061569254844		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.8190061569254844 | validation: 0.7938576919858887]
	TIME [epoch: 8.34 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7568907324025993		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.7568907324025993 | validation: 0.7703191832066087]
	TIME [epoch: 8.36 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8040526657941927		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.8040526657941927 | validation: 0.789087022835463]
	TIME [epoch: 8.33 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7184732647776327		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.7184732647776327 | validation: 0.7641382493933772]
	TIME [epoch: 8.33 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.769134049295775		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.769134049295775 | validation: 0.671040607932472]
	TIME [epoch: 8.33 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6200758325373986		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.6200758325373986 | validation: 0.552426642313123]
	TIME [epoch: 8.36 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6471054023781536		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.6471054023781536 | validation: 0.5153624271553985]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_351.pth
	Model improved!!!
EPOCH 352/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7133364428417159		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.7133364428417159 | validation: 0.731267845537328]
	TIME [epoch: 8.33 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7422065524018524		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.7422065524018524 | validation: 0.973448235343771]
	TIME [epoch: 8.33 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8173401613660645		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.8173401613660645 | validation: 0.5767754085889191]
	TIME [epoch: 8.35 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.732702212675591		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.732702212675591 | validation: 0.6844178228509168]
	TIME [epoch: 8.33 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6592532320644165		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.6592532320644165 | validation: 0.5423571181084903]
	TIME [epoch: 8.33 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.8069205686647883		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.8069205686647883 | validation: 0.6316068966959532]
	TIME [epoch: 8.33 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7720385949880415		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.7720385949880415 | validation: 0.5613949701452781]
	TIME [epoch: 8.34 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6167046223937545		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.6167046223937545 | validation: 0.7571691438015562]
	TIME [epoch: 8.35 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6236710738333466		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.6236710738333466 | validation: 0.47371509045749227]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_360.pth
	Model improved!!!
EPOCH 361/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6566130602096762		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.6566130602096762 | validation: 0.6935984397351587]
	TIME [epoch: 8.34 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7752411293131041		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.7752411293131041 | validation: 0.6419370997890606]
	TIME [epoch: 8.33 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7034691803434063		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.7034691803434063 | validation: 0.5934196079445351]
	TIME [epoch: 8.36 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7352850568608891		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.7352850568608891 | validation: 0.7749013956497603]
	TIME [epoch: 8.33 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6660761632163251		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.6660761632163251 | validation: 0.5827861227983826]
	TIME [epoch: 8.33 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6060544484444002		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.6060544484444002 | validation: 0.5149931248002201]
	TIME [epoch: 8.33 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.643165004495925		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.643165004495925 | validation: 1.3627099381883956]
	TIME [epoch: 8.36 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7150932851410682		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.7150932851410682 | validation: 0.5318186501590858]
	TIME [epoch: 8.34 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7995929688924978		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.7995929688924978 | validation: 0.716028359752514]
	TIME [epoch: 8.33 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7349760406251338		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.7349760406251338 | validation: 0.8689713315836902]
	TIME [epoch: 8.33 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7096288142006626		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.7096288142006626 | validation: 0.9697425280533665]
	TIME [epoch: 8.34 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7168305959764876		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.7168305959764876 | validation: 0.6572090565587766]
	TIME [epoch: 8.36 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7181382432938583		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.7181382432938583 | validation: 0.7376790362843472]
	TIME [epoch: 8.33 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5962200464284216		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.5962200464284216 | validation: 1.2313196375323894]
	TIME [epoch: 8.33 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7743921128239764		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.7743921128239764 | validation: 0.8598208403975939]
	TIME [epoch: 8.34 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7757875786326481		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.7757875786326481 | validation: 0.6821314525777209]
	TIME [epoch: 8.36 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7493047002700616		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.7493047002700616 | validation: 0.6387400810984586]
	TIME [epoch: 8.34 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6225676624330466		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.6225676624330466 | validation: 0.5167592081903438]
	TIME [epoch: 8.33 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5958775436835216		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.5958775436835216 | validation: 0.5972981746277893]
	TIME [epoch: 8.34 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6210794522487251		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.6210794522487251 | validation: 0.4491869874211695]
	TIME [epoch: 8.36 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_380.pth
	Model improved!!!
EPOCH 381/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.666957184083739		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.666957184083739 | validation: 0.8200448008034491]
	TIME [epoch: 8.34 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7590588697322053		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.7590588697322053 | validation: 0.6320293385243934]
	TIME [epoch: 8.34 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7145214470167291		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.7145214470167291 | validation: 0.76687888367745]
	TIME [epoch: 8.34 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7323249580969972		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.7323249580969972 | validation: 0.8161805359353063]
	TIME [epoch: 8.34 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7293491708878793		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.7293491708878793 | validation: 0.7848373903517716]
	TIME [epoch: 8.35 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.766235088337117		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.766235088337117 | validation: 0.498996838477201]
	TIME [epoch: 8.33 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7447600057426864		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.7447600057426864 | validation: 1.2468090975015835]
	TIME [epoch: 8.33 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7083644736525516		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.7083644736525516 | validation: 0.4489571316785284]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_388.pth
	Model improved!!!
EPOCH 389/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7190485749970132		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.7190485749970132 | validation: 0.6182364397138347]
	TIME [epoch: 8.36 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6202355286665677		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.6202355286665677 | validation: 0.46841686168513663]
	TIME [epoch: 8.33 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5332565031159627		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.5332565031159627 | validation: 0.5616962221788185]
	TIME [epoch: 8.32 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5681738692505169		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.5681738692505169 | validation: 0.6354964989661651]
	TIME [epoch: 8.33 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7463223260798653		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.7463223260798653 | validation: 1.034695068173538]
	TIME [epoch: 8.35 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7171129770340634		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.7171129770340634 | validation: 1.0612542526404856]
	TIME [epoch: 8.33 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7615265271493982		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.7615265271493982 | validation: 0.7795019394391841]
	TIME [epoch: 8.33 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6116394712821511		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.6116394712821511 | validation: 1.2100409505896306]
	TIME [epoch: 8.33 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7311231758594984		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.7311231758594984 | validation: 0.529309487849317]
	TIME [epoch: 8.34 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5262500329778128		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.5262500329778128 | validation: 1.6273873264217706]
	TIME [epoch: 8.35 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7503893732421567		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.7503893732421567 | validation: 0.48952073517065864]
	TIME [epoch: 8.33 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5672710135104707		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.5672710135104707 | validation: 0.928918109581044]
	TIME [epoch: 8.33 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7860707945298084		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.7860707945298084 | validation: 0.9526850107283424]
	TIME [epoch: 8.33 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6892917688714302		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.6892917688714302 | validation: 0.7501377846814057]
	TIME [epoch: 8.36 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6083281210749302		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.6083281210749302 | validation: 0.6838650175588252]
	TIME [epoch: 8.33 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7044859652205002		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.7044859652205002 | validation: 0.8549097485526629]
	TIME [epoch: 8.33 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6942228325188098		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.6942228325188098 | validation: 0.8070528995772912]
	TIME [epoch: 8.32 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6829061431931486		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.6829061431931486 | validation: 0.6769805299281453]
	TIME [epoch: 8.35 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5596323559296347		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.5596323559296347 | validation: 0.8199401760019701]
	TIME [epoch: 8.33 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6723908088397812		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.6723908088397812 | validation: 1.5374591537240563]
	TIME [epoch: 8.33 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7373157285831471		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.7373157285831471 | validation: 0.4939680245924716]
	TIME [epoch: 8.33 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5177384555638272		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.5177384555638272 | validation: 0.5110207420541685]
	TIME [epoch: 8.34 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6212404412505187		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.6212404412505187 | validation: 0.4800693585108796]
	TIME [epoch: 8.35 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5701324157698942		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.5701324157698942 | validation: 1.1047586194322307]
	TIME [epoch: 8.33 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.7078613014148887		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.7078613014148887 | validation: 0.7514059020681243]
	TIME [epoch: 8.33 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6346749223088571		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.6346749223088571 | validation: 1.1580412507454654]
	TIME [epoch: 8.33 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6553136613267523		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.6553136613267523 | validation: 0.5088771498905855]
	TIME [epoch: 8.35 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6029625061774259		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.6029625061774259 | validation: 0.5247029807609049]
	TIME [epoch: 8.32 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6522782036605983		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.6522782036605983 | validation: 0.5600342467644339]
	TIME [epoch: 8.32 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6304158826558962		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.6304158826558962 | validation: 0.4313930336994152]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_418.pth
	Model improved!!!
EPOCH 419/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5166568560998399		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.5166568560998399 | validation: 0.8130405743546144]
	TIME [epoch: 8.35 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5708733450620795		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.5708733450620795 | validation: 0.43344826230956557]
	TIME [epoch: 8.33 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5671263715141429		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.5671263715141429 | validation: 0.42301898569211493]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_421.pth
	Model improved!!!
EPOCH 422/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6459866521000086		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.6459866521000086 | validation: 0.7866062382422097]
	TIME [epoch: 8.33 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6759336837527656		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.6759336837527656 | validation: 0.5927227060588813]
	TIME [epoch: 8.33 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6461307677054288		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.6461307677054288 | validation: 0.9533696831484461]
	TIME [epoch: 8.35 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5305662768530575		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.5305662768530575 | validation: 0.5480966693448506]
	TIME [epoch: 8.33 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6650967308766841		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.6650967308766841 | validation: 0.46203137569572794]
	TIME [epoch: 8.33 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5569413882881896		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.5569413882881896 | validation: 0.41703169993854716]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_427.pth
	Model improved!!!
EPOCH 428/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5482840784477088		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.5482840784477088 | validation: 0.8566186422244693]
	TIME [epoch: 8.36 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6540944794130633		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.6540944794130633 | validation: 0.7881717310749938]
	TIME [epoch: 8.33 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6494766452850711		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.6494766452850711 | validation: 0.5984282862400641]
	TIME [epoch: 8.32 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6018457429445847		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.6018457429445847 | validation: 0.770169475627157]
	TIME [epoch: 8.33 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6509249484873721		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.6509249484873721 | validation: 0.7019340385467332]
	TIME [epoch: 8.35 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6376703193970195		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.6376703193970195 | validation: 0.8285600874276375]
	TIME [epoch: 8.33 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6137046093079948		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.6137046093079948 | validation: 0.7905046030868659]
	TIME [epoch: 8.33 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6665273241075453		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.6665273241075453 | validation: 0.6694559760552028]
	TIME [epoch: 8.32 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5889391364185174		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.5889391364185174 | validation: 0.5893428517087126]
	TIME [epoch: 8.34 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6127562372142152		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.6127562372142152 | validation: 0.48122228030761394]
	TIME [epoch: 8.34 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.518996466152825		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.518996466152825 | validation: 0.5798901126832459]
	TIME [epoch: 8.33 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6233267348058382		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.6233267348058382 | validation: 0.8197579031795319]
	TIME [epoch: 8.32 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.677064099955324		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.677064099955324 | validation: 0.6117006342510776]
	TIME [epoch: 8.32 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6076462544061125		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.6076462544061125 | validation: 0.39661087613672674]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_441.pth
	Model improved!!!
EPOCH 442/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6174040344548548		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.6174040344548548 | validation: 0.8760832105181244]
	TIME [epoch: 8.33 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6049886232513527		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.6049886232513527 | validation: 0.7918194461246719]
	TIME [epoch: 8.32 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6145061848369427		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.6145061848369427 | validation: 0.8072866036265705]
	TIME [epoch: 8.32 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4902133876005621		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.4902133876005621 | validation: 0.4700134156898146]
	TIME [epoch: 8.35 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5423796225974714		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.5423796225974714 | validation: 0.6071718281951519]
	TIME [epoch: 8.32 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6056788950733653		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.6056788950733653 | validation: 0.7986068057113622]
	TIME [epoch: 8.32 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5356783148683395		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.5356783148683395 | validation: 0.7886665466054513]
	TIME [epoch: 8.32 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6385559748455174		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.6385559748455174 | validation: 0.5180271347074881]
	TIME [epoch: 8.34 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.599649689456247		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.599649689456247 | validation: 0.4999046920133561]
	TIME [epoch: 8.33 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5527190802016395		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.5527190802016395 | validation: 0.6447579309377325]
	TIME [epoch: 8.33 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6081908588723656		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.6081908588723656 | validation: 0.6505937539310751]
	TIME [epoch: 8.33 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5660258515923131		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.5660258515923131 | validation: 0.9388613953247384]
	TIME [epoch: 8.33 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5725328732903028		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.5725328732903028 | validation: 0.3681670592916599]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_454.pth
	Model improved!!!
EPOCH 455/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6419519527494982		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.6419519527494982 | validation: 0.3672573681706107]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_455.pth
	Model improved!!!
EPOCH 456/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4311258758144497		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.4311258758144497 | validation: 0.4063467633440677]
	TIME [epoch: 8.32 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4896684233525739		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.4896684233525739 | validation: 0.479122306518449]
	TIME [epoch: 8.33 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6458879702813838		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.6458879702813838 | validation: 0.47421481844019314]
	TIME [epoch: 8.35 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6000560759519452		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.6000560759519452 | validation: 0.36961836677087667]
	TIME [epoch: 8.33 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5994540347151356		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.5994540347151356 | validation: 0.4392029914348279]
	TIME [epoch: 8.33 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6017258705799826		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.6017258705799826 | validation: 0.4448132219409747]
	TIME [epoch: 8.32 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5557219617485575		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.5557219617485575 | validation: 0.3726256336421797]
	TIME [epoch: 8.34 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5958766662963125		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.5958766662963125 | validation: 0.4075564480548375]
	TIME [epoch: 8.33 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4995598011372449		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.4995598011372449 | validation: 0.3859878603468684]
	TIME [epoch: 8.32 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5012767843713064		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.5012767843713064 | validation: 0.40462065361649335]
	TIME [epoch: 8.33 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6668844172625202		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.6668844172625202 | validation: 0.4857482035205124]
	TIME [epoch: 8.33 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5856555733379729		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.5856555733379729 | validation: 0.8763682186255675]
	TIME [epoch: 8.36 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5541570564056358		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.5541570564056358 | validation: 0.6127478348700764]
	TIME [epoch: 8.33 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5727226261569892		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.5727226261569892 | validation: 0.3877194879170845]
	TIME [epoch: 8.32 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5856347811985957		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.5856347811985957 | validation: 0.3654104292911463]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_470.pth
	Model improved!!!
EPOCH 471/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5063837103556754		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.5063837103556754 | validation: 0.5620070524065801]
	TIME [epoch: 8.35 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5296183408507253		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.5296183408507253 | validation: 0.36776272785107883]
	TIME [epoch: 8.33 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5482398626350002		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.5482398626350002 | validation: 0.3635029775875265]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_473.pth
	Model improved!!!
EPOCH 474/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47037519298848063		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.47037519298848063 | validation: 0.5050853527937693]
	TIME [epoch: 8.33 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4513492200466773		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.4513492200466773 | validation: 0.35692591377851424]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_475.pth
	Model improved!!!
EPOCH 476/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5527490785240384		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.5527490785240384 | validation: 0.4523639824202017]
	TIME [epoch: 8.34 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4311545064526762		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.4311545064526762 | validation: 0.4130824496686591]
	TIME [epoch: 8.32 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45346488387552697		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.45346488387552697 | validation: 0.5099922644251701]
	TIME [epoch: 8.32 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49963718978724475		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.49963718978724475 | validation: 0.323509990670793]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_479.pth
	Model improved!!!
EPOCH 480/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.520973219466004		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.520973219466004 | validation: 0.4060397913305613]
	TIME [epoch: 8.38 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5171740914313092		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.5171740914313092 | validation: 0.3566780224740903]
	TIME [epoch: 8.33 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45956883777301627		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.45956883777301627 | validation: 0.4625430233826721]
	TIME [epoch: 8.33 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5076141615557297		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.5076141615557297 | validation: 0.34716698945730395]
	TIME [epoch: 8.33 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5714253580904229		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.5714253580904229 | validation: 0.42323539025282875]
	TIME [epoch: 8.35 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4891444188305785		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.4891444188305785 | validation: 0.3266817626439356]
	TIME [epoch: 8.33 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.544189378700487		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.544189378700487 | validation: 0.41939621731338106]
	TIME [epoch: 8.32 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4888557120369817		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.4888557120369817 | validation: 0.3209953709806661]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_487.pth
	Model improved!!!
EPOCH 488/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5463753252525569		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.5463753252525569 | validation: 0.3674414667151495]
	TIME [epoch: 8.34 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5140748940053532		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.5140748940053532 | validation: 0.4365254176011457]
	TIME [epoch: 8.33 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43614586779722603		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.43614586779722603 | validation: 0.3366381036008503]
	TIME [epoch: 8.33 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.41240507251923564		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.41240507251923564 | validation: 0.33861318384444294]
	TIME [epoch: 8.32 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3862311171435385		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.3862311171435385 | validation: 0.7459730422739697]
	TIME [epoch: 8.33 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.6221823103006477		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.6221823103006477 | validation: 0.4852890872778468]
	TIME [epoch: 8.35 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46635058037393184		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.46635058037393184 | validation: 0.327861232336]
	TIME [epoch: 8.32 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.49198818407733913		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.49198818407733913 | validation: 0.7583275427108167]
	TIME [epoch: 8.32 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5762639399487657		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.5762639399487657 | validation: 0.34082057886931494]
	TIME [epoch: 8.32 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4282159673791325		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.4282159673791325 | validation: 0.4011015222745531]
	TIME [epoch: 8.35 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3744424793613547		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.3744424793613547 | validation: 0.3547917171838763]
	TIME [epoch: 8.33 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4403593990156289		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.4403593990156289 | validation: 0.3307969830820008]
	TIME [epoch: 8.32 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4158308037433365		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.4158308037433365 | validation: 0.5446389630713233]
	TIME [epoch: 8.32 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42233764093919957		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.42233764093919957 | validation: 0.3669695216998286]
	TIME [epoch: 8.33 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46451731330068374		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.46451731330068374 | validation: 0.4883885595270483]
	TIME [epoch: 8.33 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44705077829567197		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.44705077829567197 | validation: 0.4232024524988064]
	TIME [epoch: 8.32 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42314293388910784		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.42314293388910784 | validation: 0.2979370146467951]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_504.pth
	Model improved!!!
EPOCH 505/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3740118896742492		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.3740118896742492 | validation: 0.3385352697316081]
	TIME [epoch: 8.33 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.5225627469082421		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.5225627469082421 | validation: 0.46696945321288114]
	TIME [epoch: 8.35 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4769502181874682		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.4769502181874682 | validation: 0.34638192800074374]
	TIME [epoch: 8.32 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4273665575477311		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.4273665575477311 | validation: 0.7083166508811878]
	TIME [epoch: 8.32 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.44022939594076044		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.44022939594076044 | validation: 0.3077825393348607]
	TIME [epoch: 8.32 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39848267609272525		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.39848267609272525 | validation: 0.3432614211976045]
	TIME [epoch: 8.35 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3729872388448225		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.3729872388448225 | validation: 0.8177048018396045]
	TIME [epoch: 8.32 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46229457444462224		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.46229457444462224 | validation: 0.39256180802411744]
	TIME [epoch: 8.32 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3571756867074275		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.3571756867074275 | validation: 0.26789854701158544]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_513.pth
	Model improved!!!
EPOCH 514/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3762253732011391		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.3762253732011391 | validation: 0.3038629551293833]
	TIME [epoch: 8.33 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45383843950430103		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.45383843950430103 | validation: 0.6828578332738008]
	TIME [epoch: 8.33 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4368493513449125		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.4368493513449125 | validation: 0.26841908646040746]
	TIME [epoch: 8.31 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38373246198868133		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.38373246198868133 | validation: 0.49904972362948974]
	TIME [epoch: 8.31 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3560139285010537		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.3560139285010537 | validation: 0.39583661070342774]
	TIME [epoch: 8.31 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4136496947769319		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.4136496947769319 | validation: 0.41208020033986226]
	TIME [epoch: 8.35 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3772461516330753		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.3772461516330753 | validation: 0.33930969728665406]
	TIME [epoch: 8.32 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38589459333316806		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.38589459333316806 | validation: 0.573516761883013]
	TIME [epoch: 8.32 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4216488563749768		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.4216488563749768 | validation: 0.43541556333647874]
	TIME [epoch: 8.32 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42792243072964736		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.42792243072964736 | validation: 0.45717498255096434]
	TIME [epoch: 8.34 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.47560237518352944		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.47560237518352944 | validation: 0.26309837539941316]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_524.pth
	Model improved!!!
EPOCH 525/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42491497224152874		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.42491497224152874 | validation: 0.34647343528276403]
	TIME [epoch: 8.34 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4097696590103478		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.4097696590103478 | validation: 0.2740419343463766]
	TIME [epoch: 8.34 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4221559453958612		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.4221559453958612 | validation: 0.45895760000662733]
	TIME [epoch: 8.35 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3717061210297029		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.3717061210297029 | validation: 0.3990895004442239]
	TIME [epoch: 8.34 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38709482494235614		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.38709482494235614 | validation: 0.2741428539312857]
	TIME [epoch: 8.33 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32624989030022106		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.32624989030022106 | validation: 0.47364114045468136]
	TIME [epoch: 8.33 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.42337336709160106		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.42337336709160106 | validation: 0.2872670942904595]
	TIME [epoch: 8.32 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3902860708397162		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.3902860708397162 | validation: 0.29399235344028407]
	TIME [epoch: 8.35 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39532836005424954		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.39532836005424954 | validation: 0.24652367423653226]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_533.pth
	Model improved!!!
EPOCH 534/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.46014791515979264		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.46014791515979264 | validation: 0.5807684360427827]
	TIME [epoch: 8.33 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4002985267990987		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.4002985267990987 | validation: 0.2935260196058289]
	TIME [epoch: 8.32 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.38170567482352774		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.38170567482352774 | validation: 0.3794415466293616]
	TIME [epoch: 8.35 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4502916512264675		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.4502916512264675 | validation: 0.34302682169235127]
	TIME [epoch: 8.33 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34642007837487093		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.34642007837487093 | validation: 0.30387018900343343]
	TIME [epoch: 8.33 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3766272659547069		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.3766272659547069 | validation: 0.28719212860807664]
	TIME [epoch: 8.32 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31150929762198365		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.31150929762198365 | validation: 0.26165647179865453]
	TIME [epoch: 8.35 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.40788325267827635		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.40788325267827635 | validation: 0.28212474122641135]
	TIME [epoch: 8.33 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.43381926714952374		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.43381926714952374 | validation: 0.22422905606706012]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_542.pth
	Model improved!!!
EPOCH 543/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3216969051147588		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.3216969051147588 | validation: 0.22385898200602794]
	TIME [epoch: 8.33 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_543.pth
	Model improved!!!
EPOCH 544/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30159898352584047		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.30159898352584047 | validation: 0.24289724900201737]
	TIME [epoch: 8.34 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.298043524808237		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.298043524808237 | validation: 0.24792850825019325]
	TIME [epoch: 8.34 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3873949385003734		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.3873949385003734 | validation: 0.3607271034751859]
	TIME [epoch: 8.32 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34596520734755704		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.34596520734755704 | validation: 0.3403602329725748]
	TIME [epoch: 8.32 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35362648847920647		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.35362648847920647 | validation: 0.24219919799970488]
	TIME [epoch: 8.32 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34575821252673844		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.34575821252673844 | validation: 0.223241892494198]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_549.pth
	Model improved!!!
EPOCH 550/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33545553871160727		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.33545553871160727 | validation: 0.363126549994501]
	TIME [epoch: 8.34 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.399965130741058		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.399965130741058 | validation: 0.3270139089623769]
	TIME [epoch: 8.35 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2915203794878994		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.2915203794878994 | validation: 0.37053596280594797]
	TIME [epoch: 8.34 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3813742031368871		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.3813742031368871 | validation: 0.28740299630085836]
	TIME [epoch: 8.37 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3691631629358732		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.3691631629358732 | validation: 0.3013843456612218]
	TIME [epoch: 8.34 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.39278494141164194		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.39278494141164194 | validation: 0.3617206815379547]
	TIME [epoch: 8.35 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3230043086674721		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.3230043086674721 | validation: 0.4044187725246309]
	TIME [epoch: 8.34 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37631579000502435		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.37631579000502435 | validation: 0.27261516143890785]
	TIME [epoch: 8.36 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31079775592567		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.31079775592567 | validation: 0.27488598023834937]
	TIME [epoch: 8.35 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29209830428124517		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.29209830428124517 | validation: 0.2613166978954998]
	TIME [epoch: 8.34 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2608314984071979		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.2608314984071979 | validation: 0.2999911919646775]
	TIME [epoch: 8.34 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3473557620926185		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.3473557620926185 | validation: 0.2660891193929696]
	TIME [epoch: 8.34 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2830221824154634		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.2830221824154634 | validation: 0.3292274557386876]
	TIME [epoch: 8.37 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35786070724584695		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.35786070724584695 | validation: 0.20293304138262264]
	TIME [epoch: 8.35 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_563.pth
	Model improved!!!
EPOCH 564/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30686868910895493		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.30686868910895493 | validation: 0.1928261113927433]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_564.pth
	Model improved!!!
EPOCH 565/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4112930200610747		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.4112930200610747 | validation: 0.25971411429812724]
	TIME [epoch: 8.35 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3344848350205671		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.3344848350205671 | validation: 0.2593744188184772]
	TIME [epoch: 8.36 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3178815048923291		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.3178815048923291 | validation: 0.3066182515049089]
	TIME [epoch: 8.35 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28402915559145114		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.28402915559145114 | validation: 0.2420471984585359]
	TIME [epoch: 8.34 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3316618544803079		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.3316618544803079 | validation: 0.2886699612295091]
	TIME [epoch: 8.34 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.4055960055686736		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.4055960055686736 | validation: 0.25014764371991144]
	TIME [epoch: 8.35 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3113637462580754		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.3113637462580754 | validation: 0.2975319431467616]
	TIME [epoch: 8.35 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2539340540497213		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.2539340540497213 | validation: 0.6189385220392136]
	TIME [epoch: 8.34 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.354106793386241		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.354106793386241 | validation: 0.49563373972182967]
	TIME [epoch: 8.34 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3327995016947252		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.3327995016947252 | validation: 0.5081450692308328]
	TIME [epoch: 8.34 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3361305878460572		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.3361305878460572 | validation: 0.37731021850432855]
	TIME [epoch: 8.37 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3602010572315443		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.3602010572315443 | validation: 0.3641831267960184]
	TIME [epoch: 8.34 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3188813538535413		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.3188813538535413 | validation: 0.3291966050238349]
	TIME [epoch: 8.35 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30388639099076986		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.30388639099076986 | validation: 0.3825964570310427]
	TIME [epoch: 8.34 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33248214289295885		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.33248214289295885 | validation: 0.305245954948426]
	TIME [epoch: 8.36 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.34405092222987504		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.34405092222987504 | validation: 0.3540315192840908]
	TIME [epoch: 8.34 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3864432340995557		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.3864432340995557 | validation: 0.3141912656863479]
	TIME [epoch: 8.34 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31090676035539544		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.31090676035539544 | validation: 0.3691314015087681]
	TIME [epoch: 8.34 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33164752631340333		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.33164752631340333 | validation: 0.319340998415654]
	TIME [epoch: 8.35 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.37578125451209826		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.37578125451209826 | validation: 0.2470520938511953]
	TIME [epoch: 8.35 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.45707057371465565		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.45707057371465565 | validation: 0.24805153707046637]
	TIME [epoch: 8.33 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2719310736790325		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.2719310736790325 | validation: 0.38509090927002954]
	TIME [epoch: 8.33 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29739155997896716		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.29739155997896716 | validation: 0.21836030518459987]
	TIME [epoch: 8.33 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3027488588205723		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.3027488588205723 | validation: 0.5580866528262276]
	TIME [epoch: 8.36 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32089470579060486		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.32089470579060486 | validation: 0.20846847010636924]
	TIME [epoch: 8.33 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30975016059767035		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.30975016059767035 | validation: 0.2773583099653152]
	TIME [epoch: 8.33 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27680377639136283		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.27680377639136283 | validation: 0.47809470853462455]
	TIME [epoch: 8.33 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.333866458345059		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.333866458345059 | validation: 0.2921824041996533]
	TIME [epoch: 8.35 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3245704115572669		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.3245704115572669 | validation: 0.2443249808658632]
	TIME [epoch: 8.33 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31067926431509785		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.31067926431509785 | validation: 0.2880169102450806]
	TIME [epoch: 8.33 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26964217038460375		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.26964217038460375 | validation: 0.3389914056156422]
	TIME [epoch: 8.33 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3032616164371914		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.3032616164371914 | validation: 0.260264572337895]
	TIME [epoch: 8.35 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25402461346693916		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.25402461346693916 | validation: 0.3194329945716252]
	TIME [epoch: 8.34 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30236912811224237		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.30236912811224237 | validation: 0.189052353411075]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_598.pth
	Model improved!!!
EPOCH 599/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30927052225935886		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.30927052225935886 | validation: 0.19043349852611424]
	TIME [epoch: 8.33 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28748645589596195		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.28748645589596195 | validation: 0.48481832481735887]
	TIME [epoch: 8.33 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31064439678963013		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.31064439678963013 | validation: 0.3144265368997128]
	TIME [epoch: 8.36 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3181961270102862		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.3181961270102862 | validation: 0.4432446858895689]
	TIME [epoch: 8.33 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3524208858346133		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.3524208858346133 | validation: 0.23145864285276627]
	TIME [epoch: 8.33 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2863424111943077		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.2863424111943077 | validation: 0.2486464788922147]
	TIME [epoch: 8.32 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30888839706400045		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.30888839706400045 | validation: 0.2417478495912388]
	TIME [epoch: 8.35 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2981440664791858		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.2981440664791858 | validation: 0.4020943144973806]
	TIME [epoch: 8.33 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32982614906644514		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.32982614906644514 | validation: 0.2797722855848783]
	TIME [epoch: 8.33 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3040140488717513		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.3040140488717513 | validation: 0.20853946392258582]
	TIME [epoch: 8.33 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3042740218795128		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.3042740218795128 | validation: 0.8891480414350474]
	TIME [epoch: 8.34 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.35848332035743236		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.35848332035743236 | validation: 0.19373462313275241]
	TIME [epoch: 8.33 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.253072354470793		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.253072354470793 | validation: 0.2589863918325792]
	TIME [epoch: 8.33 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3703294054341556		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.3703294054341556 | validation: 0.2125050401938084]
	TIME [epoch: 8.33 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31997687456799895		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.31997687456799895 | validation: 0.21245499619800323]
	TIME [epoch: 8.33 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2712292230047274		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.2712292230047274 | validation: 0.19013678026887532]
	TIME [epoch: 8.35 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26878187825943745		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.26878187825943745 | validation: 0.238468211098586]
	TIME [epoch: 8.33 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.296979253235425		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.296979253235425 | validation: 0.20015850290651638]
	TIME [epoch: 8.33 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25873704264606434		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.25873704264606434 | validation: 0.20743590405762416]
	TIME [epoch: 8.32 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27849440744172443		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.27849440744172443 | validation: 0.20409104910212236]
	TIME [epoch: 8.34 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2807940735271829		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.2807940735271829 | validation: 0.4687447531676121]
	TIME [epoch: 8.33 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2868346062492333		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.2868346062492333 | validation: 0.46921306421044306]
	TIME [epoch: 8.32 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3049495423118585		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.3049495423118585 | validation: 0.2145977394220699]
	TIME [epoch: 8.32 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24977264360136714		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.24977264360136714 | validation: 0.18421385028776854]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_622.pth
	Model improved!!!
EPOCH 623/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24167853538123504		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.24167853538123504 | validation: 0.266181608394516]
	TIME [epoch: 8.34 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3882923914719756		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.3882923914719756 | validation: 0.28307527255503806]
	TIME [epoch: 8.32 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30791442220707677		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.30791442220707677 | validation: 0.2511928033959439]
	TIME [epoch: 8.32 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2604911647477822		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.2604911647477822 | validation: 0.2387200302328542]
	TIME [epoch: 8.32 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.32909298978542567		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.32909298978542567 | validation: 0.28666632279600923]
	TIME [epoch: 8.35 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24542503304822683		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.24542503304822683 | validation: 0.3412333781855896]
	TIME [epoch: 8.32 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29328914837894243		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.29328914837894243 | validation: 0.2858678905880003]
	TIME [epoch: 8.32 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2669307703002849		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.2669307703002849 | validation: 0.3315534747558555]
	TIME [epoch: 8.32 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29394540057142055		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.29394540057142055 | validation: 0.27220882737021257]
	TIME [epoch: 8.34 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24006309321270183		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.24006309321270183 | validation: 0.3337157011185059]
	TIME [epoch: 8.33 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28909384750525746		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.28909384750525746 | validation: 0.17260960352452165]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_633.pth
	Model improved!!!
EPOCH 634/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23430979350476955		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.23430979350476955 | validation: 0.19137097555828064]
	TIME [epoch: 8.32 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2976282122762247		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.2976282122762247 | validation: 0.34641600253285637]
	TIME [epoch: 8.33 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2728295152009517		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.2728295152009517 | validation: 0.23505139904161715]
	TIME [epoch: 8.33 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27896117649728475		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.27896117649728475 | validation: 0.2946703395434015]
	TIME [epoch: 8.32 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29440145465002576		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.29440145465002576 | validation: 0.209495378330059]
	TIME [epoch: 8.32 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2759919571338549		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.2759919571338549 | validation: 0.46722887104781663]
	TIME [epoch: 8.32 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2997572646807217		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.2997572646807217 | validation: 0.281608033124241]
	TIME [epoch: 8.35 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3015079598381453		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.3015079598381453 | validation: 0.26105242601567247]
	TIME [epoch: 8.32 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2554154125037358		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.2554154125037358 | validation: 0.29314241232888927]
	TIME [epoch: 8.32 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.265860360162235		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.265860360162235 | validation: 0.18475029070195453]
	TIME [epoch: 8.32 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26936855720568187		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.26936855720568187 | validation: 0.21074287481035864]
	TIME [epoch: 8.34 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2894906879292508		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.2894906879292508 | validation: 0.44660211072797196]
	TIME [epoch: 8.32 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27028409681897747		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.27028409681897747 | validation: 0.20709611276859746]
	TIME [epoch: 8.32 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2744365678829666		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.2744365678829666 | validation: 0.4346220480807804]
	TIME [epoch: 8.32 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2659031819541289		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.2659031819541289 | validation: 0.22216805448670196]
	TIME [epoch: 8.34 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2492229348836783		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.2492229348836783 | validation: 0.1972530223685406]
	TIME [epoch: 8.33 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26495618656309833		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.26495618656309833 | validation: 0.21062708754527676]
	TIME [epoch: 8.32 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25943877651148534		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.25943877651148534 | validation: 0.32340058356273405]
	TIME [epoch: 8.32 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30137521603504797		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.30137521603504797 | validation: 0.48587235963826914]
	TIME [epoch: 8.32 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30422653918686693		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.30422653918686693 | validation: 0.20054837928145786]
	TIME [epoch: 8.34 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22950683210238615		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.22950683210238615 | validation: 0.20592326226625093]
	TIME [epoch: 8.32 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2577792017292558		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.2577792017292558 | validation: 0.2716099230244114]
	TIME [epoch: 8.32 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2639126552644679		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.2639126552644679 | validation: 0.21221909726888813]
	TIME [epoch: 8.32 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29259636643691495		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.29259636643691495 | validation: 0.4400962391896939]
	TIME [epoch: 8.34 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33680376477976337		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.33680376477976337 | validation: 0.34044933127545346]
	TIME [epoch: 8.32 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2732291031885508		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.2732291031885508 | validation: 0.21083007502997628]
	TIME [epoch: 8.32 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2668285698868565		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.2668285698868565 | validation: 0.1924561310805677]
	TIME [epoch: 8.32 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2525030500473701		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.2525030500473701 | validation: 0.22715274585792405]
	TIME [epoch: 8.33 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24003676677407904		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.24003676677407904 | validation: 0.2431838821888136]
	TIME [epoch: 8.33 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31140565833262124		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.31140565833262124 | validation: 0.23340716689961122]
	TIME [epoch: 8.32 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2537492676118732		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.2537492676118732 | validation: 0.32982155214320236]
	TIME [epoch: 8.32 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.30336292277097077		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.30336292277097077 | validation: 0.2939307368526666]
	TIME [epoch: 8.32 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.29762701945628867		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.29762701945628867 | validation: 0.2308027214737889]
	TIME [epoch: 8.35 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2754951472741211		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.2754951472741211 | validation: 0.2369361386294675]
	TIME [epoch: 8.32 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22464212597587188		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.22464212597587188 | validation: 0.21017906145641607]
	TIME [epoch: 8.32 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22995297481362392		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.22995297481362392 | validation: 0.27976118199577227]
	TIME [epoch: 8.32 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27277017857471875		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.27277017857471875 | validation: 0.23642388458708624]
	TIME [epoch: 8.34 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21756457924733907		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.21756457924733907 | validation: 0.20746673295153556]
	TIME [epoch: 8.32 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2608084638448588		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.2608084638448588 | validation: 0.17645678671263]
	TIME [epoch: 8.32 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21839051551715513		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.21839051551715513 | validation: 0.3360263643024711]
	TIME [epoch: 8.32 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31438775425341914		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.31438775425341914 | validation: 0.20382465942505162]
	TIME [epoch: 8.34 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23660085443974332		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.23660085443974332 | validation: 0.17856667005983984]
	TIME [epoch: 8.33 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28733046284783387		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.28733046284783387 | validation: 0.23599742908025173]
	TIME [epoch: 8.32 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2382138214015848		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.2382138214015848 | validation: 0.20987846866288146]
	TIME [epoch: 8.32 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2816299145216692		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.2816299145216692 | validation: 0.22955607410351453]
	TIME [epoch: 8.32 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2394597152460895		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.2394597152460895 | validation: 0.4625799107739832]
	TIME [epoch: 8.34 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26575691517166355		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.26575691517166355 | validation: 0.24685776298827472]
	TIME [epoch: 8.33 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24264482155583428		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.24264482155583428 | validation: 0.2313708050018032]
	TIME [epoch: 8.32 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.31607876166621923		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.31607876166621923 | validation: 0.18224468273807956]
	TIME [epoch: 8.32 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23826908149563017		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.23826908149563017 | validation: 0.3151462646789639]
	TIME [epoch: 8.34 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24353230994228667		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.24353230994228667 | validation: 0.245133090216842]
	TIME [epoch: 8.32 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.3064669551192578		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.3064669551192578 | validation: 0.349310327123582]
	TIME [epoch: 8.32 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25959459643607696		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.25959459643607696 | validation: 0.20798505019735128]
	TIME [epoch: 8.32 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2875751568514676		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.2875751568514676 | validation: 0.18973715480763526]
	TIME [epoch: 8.34 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.26965008788119926		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.26965008788119926 | validation: 0.22348013326497046]
	TIME [epoch: 8.34 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22838710563852774		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.22838710563852774 | validation: 0.34998212136746276]
	TIME [epoch: 8.32 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2426572407781007		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.2426572407781007 | validation: 0.20025467775345593]
	TIME [epoch: 8.33 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24031114493905284		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.24031114493905284 | validation: 0.23160210482337784]
	TIME [epoch: 8.32 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24182631366488674		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.24182631366488674 | validation: 0.19926974026261168]
	TIME [epoch: 8.35 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21744748842830144		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.21744748842830144 | validation: 0.2627466556563639]
	TIME [epoch: 8.32 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2515221005464637		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.2515221005464637 | validation: 0.19830428447978554]
	TIME [epoch: 8.32 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2476764850452549		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.2476764850452549 | validation: 0.2600999745998512]
	TIME [epoch: 8.32 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24441971151679537		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.24441971151679537 | validation: 0.18778987405887398]
	TIME [epoch: 8.34 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24331483719328556		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.24331483719328556 | validation: 0.19435872143341054]
	TIME [epoch: 8.33 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2423562850819359		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.2423562850819359 | validation: 0.20615349404328728]
	TIME [epoch: 8.32 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23564114447418466		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.23564114447418466 | validation: 0.25136909196874235]
	TIME [epoch: 8.32 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27687743838098305		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.27687743838098305 | validation: 0.2398476073832505]
	TIME [epoch: 8.33 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23234822088813156		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.23234822088813156 | validation: 0.48895623026842333]
	TIME [epoch: 8.34 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.28392962585255066		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.28392962585255066 | validation: 0.2871842212411741]
	TIME [epoch: 8.32 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.258668586633499		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.258668586633499 | validation: 0.22288191268695257]
	TIME [epoch: 8.32 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2475429108537527		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.2475429108537527 | validation: 0.262840305914112]
	TIME [epoch: 8.33 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22024395097552021		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.22024395097552021 | validation: 0.20475099041276418]
	TIME [epoch: 8.34 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23914224629556013		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.23914224629556013 | validation: 0.24900456292210368]
	TIME [epoch: 8.32 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2173312343710326		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.2173312343710326 | validation: 0.2500825967456116]
	TIME [epoch: 8.32 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27385480553999064		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.27385480553999064 | validation: 0.29347817569635287]
	TIME [epoch: 8.32 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2262118822908815		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.2262118822908815 | validation: 0.22700510429051113]
	TIME [epoch: 8.35 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22044373699353398		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.22044373699353398 | validation: 0.18655559870597035]
	TIME [epoch: 8.32 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.33477720257349947		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.33477720257349947 | validation: 0.2520206251851518]
	TIME [epoch: 8.32 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22449740946283506		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.22449740946283506 | validation: 0.26483288067638266]
	TIME [epoch: 8.32 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25902393784288175		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.25902393784288175 | validation: 0.18370752499399162]
	TIME [epoch: 8.33 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22233073131731138		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.22233073131731138 | validation: 0.24336229575787255]
	TIME [epoch: 8.34 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23949630222155305		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.23949630222155305 | validation: 0.24274403778292164]
	TIME [epoch: 8.32 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22695727923132475		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.22695727923132475 | validation: 0.32680197254172044]
	TIME [epoch: 8.32 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2428142603824694		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.2428142603824694 | validation: 0.1755276812845347]
	TIME [epoch: 8.33 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25772207861093627		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.25772207861093627 | validation: 0.22518869881279988]
	TIME [epoch: 8.34 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23881012178118882		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.23881012178118882 | validation: 0.22967605387227477]
	TIME [epoch: 8.32 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23886330539490483		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.23886330539490483 | validation: 0.19495166547453358]
	TIME [epoch: 8.32 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24081188025234698		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.24081188025234698 | validation: 0.1807987268185014]
	TIME [epoch: 8.32 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22800567124583		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.22800567124583 | validation: 0.19410108830886358]
	TIME [epoch: 8.34 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21513611488434514		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.21513611488434514 | validation: 0.2374705540629109]
	TIME [epoch: 8.33 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23571868920056324		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.23571868920056324 | validation: 0.1776829844455031]
	TIME [epoch: 8.32 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22056367516467557		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.22056367516467557 | validation: 0.2765371847517665]
	TIME [epoch: 8.32 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2565392819114719		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.2565392819114719 | validation: 0.26044577963002236]
	TIME [epoch: 8.33 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2380476340444166		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.2380476340444166 | validation: 0.2431311319582588]
	TIME [epoch: 8.34 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24861178221638194		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.24861178221638194 | validation: 0.1961255049192377]
	TIME [epoch: 8.32 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2107221302192924		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.2107221302192924 | validation: 0.17001804871250317]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_729.pth
	Model improved!!!
EPOCH 730/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2293513175982614		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.2293513175982614 | validation: 0.22227797037760127]
	TIME [epoch: 8.33 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2425555194378725		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.2425555194378725 | validation: 0.20679116339937648]
	TIME [epoch: 8.35 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2566451935702464		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.2566451935702464 | validation: 0.18320640083095519]
	TIME [epoch: 8.32 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20475256600486222		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.20475256600486222 | validation: 0.23473485507752717]
	TIME [epoch: 8.32 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20846905826955378		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.20846905826955378 | validation: 0.2158532865453498]
	TIME [epoch: 8.32 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2588623687788626		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.2588623687788626 | validation: 0.1816303496710327]
	TIME [epoch: 8.34 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21850921387316785		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.21850921387316785 | validation: 0.18757616834840324]
	TIME [epoch: 8.32 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22273967993668392		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.22273967993668392 | validation: 0.23772518626759082]
	TIME [epoch: 8.32 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24879852170714994		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.24879852170714994 | validation: 0.23050968011649148]
	TIME [epoch: 8.32 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21305060387434435		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.21305060387434435 | validation: 0.2757564912471413]
	TIME [epoch: 8.32 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25304407748551716		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.25304407748551716 | validation: 0.2189530168043887]
	TIME [epoch: 8.34 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21373749636694814		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.21373749636694814 | validation: 0.32400536152271575]
	TIME [epoch: 8.32 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2515304681841796		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.2515304681841796 | validation: 0.19366945595909918]
	TIME [epoch: 8.32 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21906610997766623		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.21906610997766623 | validation: 0.23006156594121382]
	TIME [epoch: 8.32 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23385133994903623		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.23385133994903623 | validation: 0.2017718173063736]
	TIME [epoch: 8.35 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20667275500563814		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.20667275500563814 | validation: 0.2011462467230833]
	TIME [epoch: 8.32 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20408070047507257		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.20408070047507257 | validation: 0.18276757183367853]
	TIME [epoch: 8.32 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2115741874054878		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.2115741874054878 | validation: 0.17655191827802452]
	TIME [epoch: 8.32 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24788355864980788		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.24788355864980788 | validation: 0.22674195036104242]
	TIME [epoch: 8.34 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19527191712578457		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.19527191712578457 | validation: 0.23640346846404228]
	TIME [epoch: 8.32 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2242111894900626		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.2242111894900626 | validation: 0.19650155399513658]
	TIME [epoch: 8.32 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24507689923640993		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.24507689923640993 | validation: 0.1941008894011832]
	TIME [epoch: 8.32 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2934277853173325		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.2934277853173325 | validation: 0.19990611273768916]
	TIME [epoch: 8.33 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21416270047150077		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.21416270047150077 | validation: 0.17464367034177325]
	TIME [epoch: 8.34 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2141502640647927		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.2141502640647927 | validation: 0.3309849898376567]
	TIME [epoch: 8.32 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2309361199968254		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.2309361199968254 | validation: 0.21384129384578754]
	TIME [epoch: 8.32 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2660500402784697		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.2660500402784697 | validation: 0.2078717265674465]
	TIME [epoch: 8.32 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23356307781873303		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.23356307781873303 | validation: 0.21850512208562495]
	TIME [epoch: 8.34 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25122518448621733		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.25122518448621733 | validation: 0.1765288868867428]
	TIME [epoch: 8.32 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20960903863150754		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.20960903863150754 | validation: 0.19904518539775407]
	TIME [epoch: 8.32 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2427092908946363		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.2427092908946363 | validation: 0.2357327255495689]
	TIME [epoch: 8.32 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20391291161084038		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.20391291161084038 | validation: 0.18898940579794837]
	TIME [epoch: 8.34 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20727092201085617		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.20727092201085617 | validation: 0.19530894296004742]
	TIME [epoch: 8.33 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19961492260116387		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.19961492260116387 | validation: 0.17416194443076494]
	TIME [epoch: 8.32 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.216209617438163		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.216209617438163 | validation: 0.25313068934524624]
	TIME [epoch: 8.32 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23231850343658272		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.23231850343658272 | validation: 0.22849700710089563]
	TIME [epoch: 8.33 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.25803405734079987		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.25803405734079987 | validation: 0.45667684825657834]
	TIME [epoch: 8.34 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23963389115790865		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.23963389115790865 | validation: 0.20692472679160456]
	TIME [epoch: 8.32 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21874934887704		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.21874934887704 | validation: 0.22450252899108752]
	TIME [epoch: 8.32 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21685475817351504		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.21685475817351504 | validation: 0.19126535527924368]
	TIME [epoch: 8.32 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2193973461401113		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.2193973461401113 | validation: 0.25139470861280433]
	TIME [epoch: 8.34 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20862041013479543		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.20862041013479543 | validation: 0.18744612643357245]
	TIME [epoch: 8.32 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20327135732010873		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.20327135732010873 | validation: 0.24592951806074909]
	TIME [epoch: 8.32 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21996141198448327		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.21996141198448327 | validation: 0.19260252586261342]
	TIME [epoch: 8.33 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18670783041046246		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.18670783041046246 | validation: 0.2083245785788999]
	TIME [epoch: 8.34 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22122818852906273		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.22122818852906273 | validation: 0.1817707561281024]
	TIME [epoch: 8.33 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20363404199233526		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.20363404199233526 | validation: 0.24341239137633686]
	TIME [epoch: 8.32 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20517111206135513		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.20517111206135513 | validation: 0.1714881169701689]
	TIME [epoch: 8.33 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21256741835272913		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.21256741835272913 | validation: 0.24266160126328645]
	TIME [epoch: 8.33 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21708567006477733		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.21708567006477733 | validation: 0.17882275518973945]
	TIME [epoch: 8.35 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22324514282366667		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.22324514282366667 | validation: 0.2134383722199591]
	TIME [epoch: 8.33 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2201500999417168		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.2201500999417168 | validation: 0.21299473794215257]
	TIME [epoch: 8.33 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21846176686400706		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.21846176686400706 | validation: 0.1739152791771995]
	TIME [epoch: 8.33 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20616093556851678		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.20616093556851678 | validation: 0.22976181104681098]
	TIME [epoch: 8.35 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21373904905750138		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.21373904905750138 | validation: 0.20538388054501777]
	TIME [epoch: 8.33 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22022158550216048		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.22022158550216048 | validation: 0.174160598386967]
	TIME [epoch: 8.33 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1921710192162652		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.1921710192162652 | validation: 0.1888671154726103]
	TIME [epoch: 8.33 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21015446020688153		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.21015446020688153 | validation: 0.17171337122671523]
	TIME [epoch: 8.34 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20819433569278184		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.20819433569278184 | validation: 0.2034741025337817]
	TIME [epoch: 8.33 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21747714740794583		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.21747714740794583 | validation: 0.1768567105898658]
	TIME [epoch: 8.32 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22960131999626845		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.22960131999626845 | validation: 0.25880266363218]
	TIME [epoch: 8.32 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1943667710597386		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.1943667710597386 | validation: 0.18567204635224643]
	TIME [epoch: 8.32 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22316949547433396		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.22316949547433396 | validation: 0.25786091527201416]
	TIME [epoch: 8.35 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2434370395852589		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.2434370395852589 | validation: 0.225704593206753]
	TIME [epoch: 8.32 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.220168250676727		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.220168250676727 | validation: 0.18369131752784273]
	TIME [epoch: 8.32 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.24317944271761274		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.24317944271761274 | validation: 0.23729446961112935]
	TIME [epoch: 8.32 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21157808934715489		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.21157808934715489 | validation: 0.19840439830267592]
	TIME [epoch: 8.35 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2031991547622599		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.2031991547622599 | validation: 0.24810817094475457]
	TIME [epoch: 8.33 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.221461576363921		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.221461576363921 | validation: 0.18477127638392132]
	TIME [epoch: 8.33 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20613542428726062		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.20613542428726062 | validation: 0.20149426478312496]
	TIME [epoch: 8.33 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19852537008712617		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.19852537008712617 | validation: 0.2375933245746229]
	TIME [epoch: 8.34 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22103335093757778		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.22103335093757778 | validation: 0.18525276609874664]
	TIME [epoch: 8.33 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21742790705374979		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.21742790705374979 | validation: 0.19894413374898942]
	TIME [epoch: 8.33 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23965757854562772		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.23965757854562772 | validation: 0.239140387389681]
	TIME [epoch: 8.32 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19569539532171876		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.19569539532171876 | validation: 0.18833940172834598]
	TIME [epoch: 8.32 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19108170947840658		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.19108170947840658 | validation: 0.22646698581670296]
	TIME [epoch: 8.35 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22892157059441817		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.22892157059441817 | validation: 0.185901749447466]
	TIME [epoch: 8.33 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19172399675431898		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.19172399675431898 | validation: 0.18979200306114746]
	TIME [epoch: 8.33 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20071985115849408		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.20071985115849408 | validation: 0.17191454273290752]
	TIME [epoch: 8.33 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21205702618816655		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.21205702618816655 | validation: 0.2971850946676583]
	TIME [epoch: 8.35 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21621771210205573		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.21621771210205573 | validation: 0.2331025533832966]
	TIME [epoch: 8.32 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20549213139421196		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.20549213139421196 | validation: 0.3071623692652139]
	TIME [epoch: 8.32 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2151455278513116		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.2151455278513116 | validation: 0.18615724148693819]
	TIME [epoch: 8.32 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19009109265924345		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.19009109265924345 | validation: 0.20791206994998657]
	TIME [epoch: 8.34 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21043099257155587		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.21043099257155587 | validation: 0.21663769485080048]
	TIME [epoch: 8.33 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20312753227273378		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.20312753227273378 | validation: 0.22254315914527728]
	TIME [epoch: 8.32 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2567464099061901		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.2567464099061901 | validation: 0.2180340763906783]
	TIME [epoch: 8.32 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19375263674644888		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.19375263674644888 | validation: 0.18709893398475497]
	TIME [epoch: 8.33 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20507412557020865		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.20507412557020865 | validation: 0.18452952099625236]
	TIME [epoch: 8.35 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21306516457935656		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.21306516457935656 | validation: 0.2091785279731147]
	TIME [epoch: 8.32 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19680656458465934		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.19680656458465934 | validation: 0.1670784534412002]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_820.pth
	Model improved!!!
EPOCH 821/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2101753767166296		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.2101753767166296 | validation: 0.1786945518640501]
	TIME [epoch: 8.32 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1898070085804397		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.1898070085804397 | validation: 0.18900434249222986]
	TIME [epoch: 8.34 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20899976692372904		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.20899976692372904 | validation: 0.22723277047692597]
	TIME [epoch: 8.32 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23664124753032634		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.23664124753032634 | validation: 0.19861503689797422]
	TIME [epoch: 8.32 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22982662059602976		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.22982662059602976 | validation: 0.18727480888298914]
	TIME [epoch: 8.32 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18723001593271232		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.18723001593271232 | validation: 0.23193990459797564]
	TIME [epoch: 8.33 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22312636661379406		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.22312636661379406 | validation: 0.1809587645248002]
	TIME [epoch: 8.33 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19796947273985882		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.19796947273985882 | validation: 0.19234365976568074]
	TIME [epoch: 8.32 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1984376495953853		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.1984376495953853 | validation: 0.17279494428007713]
	TIME [epoch: 8.32 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18548017489037116		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.18548017489037116 | validation: 0.1627905725494797]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_830.pth
	Model improved!!!
EPOCH 831/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21558502959523232		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.21558502959523232 | validation: 0.19235490057486454]
	TIME [epoch: 8.34 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2014430237808293		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.2014430237808293 | validation: 0.1814423057125346]
	TIME [epoch: 8.32 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22819374037434653		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.22819374037434653 | validation: 0.2414823440429183]
	TIME [epoch: 8.32 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20045370999992723		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.20045370999992723 | validation: 0.1894841306444182]
	TIME [epoch: 8.31 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20460183771314638		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.20460183771314638 | validation: 0.18307895794636023]
	TIME [epoch: 8.34 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19744753542343202		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.19744753542343202 | validation: 0.2580726816844618]
	TIME [epoch: 8.32 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2133648695991409		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.2133648695991409 | validation: 0.20439337623473375]
	TIME [epoch: 8.31 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19373629933676015		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.19373629933676015 | validation: 0.2462836419021195]
	TIME [epoch: 8.32 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18880724309372124		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.18880724309372124 | validation: 0.18526692733089123]
	TIME [epoch: 8.34 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2015774911021277		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.2015774911021277 | validation: 0.17018200455830357]
	TIME [epoch: 8.33 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1854493445162228		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.1854493445162228 | validation: 0.18116755445752608]
	TIME [epoch: 8.32 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1865687434820533		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.1865687434820533 | validation: 0.23505255790500357]
	TIME [epoch: 8.32 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2575330531878496		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.2575330531878496 | validation: 0.21812006888773092]
	TIME [epoch: 8.32 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20624452829614826		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.20624452829614826 | validation: 0.16249957848145502]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_844.pth
	Model improved!!!
EPOCH 845/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19368248296669863		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.19368248296669863 | validation: 0.20786420245109738]
	TIME [epoch: 8.32 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20290861667138005		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.20290861667138005 | validation: 0.20147111220198488]
	TIME [epoch: 8.33 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23816678716054646		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.23816678716054646 | validation: 0.19461859382031677]
	TIME [epoch: 8.32 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19358509334920088		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.19358509334920088 | validation: 0.1886300905841431]
	TIME [epoch: 8.34 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21699171760916558		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.21699171760916558 | validation: 0.17979924886128512]
	TIME [epoch: 8.32 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20987737028531628		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.20987737028531628 | validation: 0.22689839365204595]
	TIME [epoch: 8.32 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19516488033474835		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.19516488033474835 | validation: 0.160112287107134]
	TIME [epoch: 8.32 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_851.pth
	Model improved!!!
EPOCH 852/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2043283621819234		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.2043283621819234 | validation: 0.17751552452218175]
	TIME [epoch: 8.33 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19812875549983883		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.19812875549983883 | validation: 0.2317137408935483]
	TIME [epoch: 8.32 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22030735027981466		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.22030735027981466 | validation: 0.2042478992476769]
	TIME [epoch: 8.33 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19927264270053385		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.19927264270053385 | validation: 0.22828210686236428]
	TIME [epoch: 8.32 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23786580080367298		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.23786580080367298 | validation: 0.21493464678033036]
	TIME [epoch: 8.32 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19540401118151626		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.19540401118151626 | validation: 0.16322125766671575]
	TIME [epoch: 8.33 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17908837312624998		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.17908837312624998 | validation: 0.20269957407670036]
	TIME [epoch: 8.32 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2081720792729307		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.2081720792729307 | validation: 0.27230075031372125]
	TIME [epoch: 8.32 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23212111834241217		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.23212111834241217 | validation: 0.23016989210054312]
	TIME [epoch: 8.32 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20555552918933645		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.20555552918933645 | validation: 0.17304582929172674]
	TIME [epoch: 8.34 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19236086807090352		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.19236086807090352 | validation: 0.19423000119917763]
	TIME [epoch: 8.33 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1775460128830053		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.1775460128830053 | validation: 0.20668534248569426]
	TIME [epoch: 8.33 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.27081100702285094		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.27081100702285094 | validation: 0.19231883146870737]
	TIME [epoch: 8.32 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1895393827669081		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.1895393827669081 | validation: 0.21610080792473801]
	TIME [epoch: 8.34 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2050050928839402		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.2050050928839402 | validation: 0.2703248078321551]
	TIME [epoch: 8.33 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20632227769310113		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.20632227769310113 | validation: 0.19480409481019217]
	TIME [epoch: 8.32 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19853131703682197		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.19853131703682197 | validation: 0.18435814911640552]
	TIME [epoch: 8.31 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18382463941063912		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.18382463941063912 | validation: 0.16922026921013267]
	TIME [epoch: 8.32 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1888134383469105		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.1888134383469105 | validation: 0.24154490002911172]
	TIME [epoch: 8.35 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20906241764282366		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.20906241764282366 | validation: 0.1823055713182664]
	TIME [epoch: 8.32 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19586221839440932		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.19586221839440932 | validation: 0.1878907854159525]
	TIME [epoch: 8.32 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20455608827647787		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.20455608827647787 | validation: 0.1950406955748049]
	TIME [epoch: 8.32 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18355755523291523		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.18355755523291523 | validation: 0.2292926268520268]
	TIME [epoch: 8.34 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2054222169811671		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.2054222169811671 | validation: 0.2281588463118079]
	TIME [epoch: 8.32 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2025623690167674		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.2025623690167674 | validation: 0.19410934727032497]
	TIME [epoch: 8.32 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19762738400300978		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.19762738400300978 | validation: 0.1804234452112486]
	TIME [epoch: 8.33 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20819465126558354		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.20819465126558354 | validation: 0.22480672280226593]
	TIME [epoch: 8.33 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19656921080052175		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.19656921080052175 | validation: 0.17675606438795927]
	TIME [epoch: 8.32 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1957593621069916		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.1957593621069916 | validation: 0.18191629745607307]
	TIME [epoch: 8.32 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1868894606991909		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.1868894606991909 | validation: 0.21285258880360197]
	TIME [epoch: 8.32 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.178324341777287		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.178324341777287 | validation: 0.16584553467477275]
	TIME [epoch: 8.31 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20294263395277098		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.20294263395277098 | validation: 0.18819784198386164]
	TIME [epoch: 8.34 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20662059868870086		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.20662059868870086 | validation: 0.18555159387088535]
	TIME [epoch: 8.32 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19540047206201555		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.19540047206201555 | validation: 0.172612019652459]
	TIME [epoch: 8.32 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18512648658069703		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.18512648658069703 | validation: 0.17106245181820912]
	TIME [epoch: 8.32 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21395004865938083		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.21395004865938083 | validation: 0.207424440091647]
	TIME [epoch: 8.34 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19263232135503755		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.19263232135503755 | validation: 0.17524002093729402]
	TIME [epoch: 8.33 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18750676444686395		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.18750676444686395 | validation: 0.1748964752114343]
	TIME [epoch: 8.32 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18480551910968696		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.18480551910968696 | validation: 0.17985620166513305]
	TIME [epoch: 8.32 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19822688151602597		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.19822688151602597 | validation: 0.2070847426719189]
	TIME [epoch: 8.33 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21617617376211032		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.21617617376211032 | validation: 0.16961899579288206]
	TIME [epoch: 8.33 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1992510234604224		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.1992510234604224 | validation: 0.17338645998636915]
	TIME [epoch: 8.32 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20376523508780142		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.20376523508780142 | validation: 0.2802498387203265]
	TIME [epoch: 8.32 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21784758751184197		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.21784758751184197 | validation: 0.1924366899526162]
	TIME [epoch: 8.32 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19364153781560214		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.19364153781560214 | validation: 0.20430258400620305]
	TIME [epoch: 8.34 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19014237635984838		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.19014237635984838 | validation: 0.18081740212085232]
	TIME [epoch: 8.32 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.20268878365190104		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.20268878365190104 | validation: 0.17820426040234377]
	TIME [epoch: 8.32 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19633480393986766		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.19633480393986766 | validation: 0.1920688884547385]
	TIME [epoch: 8.32 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19343064203663368		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.19343064203663368 | validation: 0.1771890256484609]
	TIME [epoch: 8.34 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1832213245720517		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.1832213245720517 | validation: 0.17844343488419043]
	TIME [epoch: 8.32 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19084027994233116		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.19084027994233116 | validation: 0.17748502186895204]
	TIME [epoch: 8.31 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21699409165136557		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.21699409165136557 | validation: 0.18714358914489132]
	TIME [epoch: 8.31 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18690389868498833		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.18690389868498833 | validation: 0.16431419296283306]
	TIME [epoch: 8.33 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18478509079855138		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.18478509079855138 | validation: 0.16676140211008292]
	TIME [epoch: 8.33 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1903596393258992		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.1903596393258992 | validation: 0.18894869622321192]
	TIME [epoch: 8.32 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19439586099033948		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.19439586099033948 | validation: 0.21277874939298191]
	TIME [epoch: 8.32 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18692867990260129		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.18692867990260129 | validation: 0.2350428777127734]
	TIME [epoch: 8.32 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21050836267907397		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.21050836267907397 | validation: 0.22137310254225856]
	TIME [epoch: 8.34 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1958765947816909		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.1958765947816909 | validation: 0.17862920456017894]
	TIME [epoch: 8.32 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18275803755010303		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.18275803755010303 | validation: 0.1687848620052308]
	TIME [epoch: 8.31 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18689410749321803		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.18689410749321803 | validation: 0.1749655693033713]
	TIME [epoch: 8.31 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17508429154612695		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.17508429154612695 | validation: 0.16686081661045704]
	TIME [epoch: 8.34 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.199206929129006		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.199206929129006 | validation: 0.20895644099709254]
	TIME [epoch: 8.32 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2024722369674925		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.2024722369674925 | validation: 0.18397308500514523]
	TIME [epoch: 8.32 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18588770860719694		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.18588770860719694 | validation: 0.17260935249274878]
	TIME [epoch: 8.31 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17507105683813007		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.17507105683813007 | validation: 0.18301880303379053]
	TIME [epoch: 8.33 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19160576641051213		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.19160576641051213 | validation: 0.17789114235989933]
	TIME [epoch: 8.32 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18422700083075272		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.18422700083075272 | validation: 0.1963975527568806]
	TIME [epoch: 8.32 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18332305025733103		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.18332305025733103 | validation: 0.17967094070248354]
	TIME [epoch: 8.31 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1824794344469919		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.1824794344469919 | validation: 0.1995099627290609]
	TIME [epoch: 8.32 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21193240572502306		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.21193240572502306 | validation: 0.2035087336098093]
	TIME [epoch: 8.34 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18075182245245752		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.18075182245245752 | validation: 0.18817590875783308]
	TIME [epoch: 8.32 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18856123360590754		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.18856123360590754 | validation: 0.1997240822543023]
	TIME [epoch: 8.31 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.23036798424712215		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.23036798424712215 | validation: 0.22054330224313384]
	TIME [epoch: 8.31 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19150873406549176		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.19150873406549176 | validation: 0.1774386497932905]
	TIME [epoch: 8.34 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19744580659294494		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.19744580659294494 | validation: 0.18494518497121967]
	TIME [epoch: 8.31 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18517944158931618		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.18517944158931618 | validation: 0.16920434025775194]
	TIME [epoch: 8.32 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1868449401003231		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.1868449401003231 | validation: 0.1750230297926212]
	TIME [epoch: 8.32 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1882721013631932		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.1882721013631932 | validation: 0.21472549997906365]
	TIME [epoch: 8.33 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19278911309014865		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.19278911309014865 | validation: 0.17870141690677327]
	TIME [epoch: 8.33 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1820629313270167		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.1820629313270167 | validation: 0.174723844577935]
	TIME [epoch: 8.32 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.22479585398721338		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.22479585398721338 | validation: 0.20201330608358423]
	TIME [epoch: 8.31 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19186441327662396		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.19186441327662396 | validation: 0.1687859052055225]
	TIME [epoch: 8.32 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18779464766235884		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.18779464766235884 | validation: 0.20013915262174836]
	TIME [epoch: 8.34 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1882905754967267		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.1882905754967267 | validation: 0.17541964694905618]
	TIME [epoch: 8.32 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1837329098443436		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.1837329098443436 | validation: 0.17630325270071398]
	TIME [epoch: 8.32 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18846972559488223		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.18846972559488223 | validation: 0.17463896593516562]
	TIME [epoch: 8.31 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18280579837938266		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.18280579837938266 | validation: 0.164842893780753]
	TIME [epoch: 8.34 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18244112503148754		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.18244112503148754 | validation: 0.1838327094650506]
	TIME [epoch: 8.31 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.2056740431599909		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.2056740431599909 | validation: 0.17835048213898352]
	TIME [epoch: 8.32 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18837711240295743		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.18837711240295743 | validation: 0.19160620543350876]
	TIME [epoch: 8.31 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18308740426617595		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.18308740426617595 | validation: 0.1606159583929131]
	TIME [epoch: 8.33 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19950403382815157		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.19950403382815157 | validation: 0.16699113768545115]
	TIME [epoch: 8.32 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19187826364459873		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.19187826364459873 | validation: 0.21095037426275984]
	TIME [epoch: 8.31 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19719661981665093		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.19719661981665093 | validation: 0.1976489183942374]
	TIME [epoch: 8.32 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18560454441515925		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.18560454441515925 | validation: 0.17223537388434434]
	TIME [epoch: 8.31 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1875649134121116		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.1875649134121116 | validation: 0.16993650697760757]
	TIME [epoch: 8.34 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17646161535683183		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.17646161535683183 | validation: 0.16285114652888058]
	TIME [epoch: 8.31 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17831616992571514		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.17831616992571514 | validation: 0.1789215203453155]
	TIME [epoch: 8.31 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17553433189238676		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.17553433189238676 | validation: 0.16963895251952427]
	TIME [epoch: 8.32 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16866278321967884		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.16866278321967884 | validation: 0.1624340642809894]
	TIME [epoch: 8.33 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17369288289451584		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.17369288289451584 | validation: 0.20176167352006286]
	TIME [epoch: 8.32 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19987441885788415		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.19987441885788415 | validation: 0.16759417657620712]
	TIME [epoch: 8.31 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18279378534714147		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.18279378534714147 | validation: 0.167020929648165]
	TIME [epoch: 8.31 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17865163680066629		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.17865163680066629 | validation: 0.1815575610280265]
	TIME [epoch: 8.32 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18281640386508594		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.18281640386508594 | validation: 0.16819423279782952]
	TIME [epoch: 8.33 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17986939501590393		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.17986939501590393 | validation: 0.18294682991352196]
	TIME [epoch: 8.32 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17890672735970697		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.17890672735970697 | validation: 0.20283785789627745]
	TIME [epoch: 8.31 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.197670525029244		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.197670525029244 | validation: 0.2022308994819606]
	TIME [epoch: 8.31 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19560589360296596		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.19560589360296596 | validation: 0.15713338330944043]
	TIME [epoch: 8.34 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r1_20240217_140928/states/model_tr_study4_961.pth
	Model improved!!!
EPOCH 962/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18153185448769432		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.18153185448769432 | validation: 0.1800396474735243]
	TIME [epoch: 8.31 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18950387343469313		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.18950387343469313 | validation: 0.16019711217433963]
	TIME [epoch: 8.31 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18354613161804928		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.18354613161804928 | validation: 0.17768650904333558]
	TIME [epoch: 8.31 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19316766448192718		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.19316766448192718 | validation: 0.18277591835900386]
	TIME [epoch: 8.33 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.181790988617834		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.181790988617834 | validation: 0.16775256513534048]
	TIME [epoch: 8.31 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19797604774424832		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.19797604774424832 | validation: 0.18018783801945748]
	TIME [epoch: 8.31 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18042716728981403		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.18042716728981403 | validation: 0.1640953698299621]
	TIME [epoch: 8.31 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17954798736415334		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.17954798736415334 | validation: 0.1897514439514225]
	TIME [epoch: 8.32 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19491004244194104		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.19491004244194104 | validation: 0.18863137989976425]
	TIME [epoch: 8.33 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19291966095766427		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.19291966095766427 | validation: 0.16748512894733786]
	TIME [epoch: 8.31 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1819735772102855		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.1819735772102855 | validation: 0.22046025518738188]
	TIME [epoch: 8.31 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.21623388634849472		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.21623388634849472 | validation: 0.18232609862667615]
	TIME [epoch: 8.31 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1809089921747104		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.1809089921747104 | validation: 0.16728984893991547]
	TIME [epoch: 8.34 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18171967552276097		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.18171967552276097 | validation: 0.1733500243509455]
	TIME [epoch: 8.31 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18700448173512246		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.18700448173512246 | validation: 0.1752092556479946]
	TIME [epoch: 8.31 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1813102536959117		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.1813102536959117 | validation: 0.17441026944164983]
	TIME [epoch: 8.31 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17429224017175945		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.17429224017175945 | validation: 0.1722342553521984]
	TIME [epoch: 8.33 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17623285583667916		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.17623285583667916 | validation: 0.1731495511248177]
	TIME [epoch: 8.32 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17841381673796158		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.17841381673796158 | validation: 0.17397928780398803]
	TIME [epoch: 8.32 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.16726150131878315		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.16726150131878315 | validation: 0.20392907036663638]
	TIME [epoch: 8.32 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17359833831930332		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.17359833831930332 | validation: 0.15958738506393821]
	TIME [epoch: 8.32 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17481136667441885		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.17481136667441885 | validation: 0.18232477202787312]
	TIME [epoch: 8.33 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17828572820873867		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.17828572820873867 | validation: 0.2162775507021071]
	TIME [epoch: 8.31 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1947606744075627		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.1947606744075627 | validation: 0.24968329027259112]
	TIME [epoch: 8.32 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19596606644819506		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.19596606644819506 | validation: 0.18140405575244534]
	TIME [epoch: 8.31 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17904762837652102		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.17904762837652102 | validation: 0.1710451264455326]
	TIME [epoch: 8.34 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18385471573693885		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.18385471573693885 | validation: 0.21007352148758773]
	TIME [epoch: 8.31 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19730831430765264		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.19730831430765264 | validation: 0.17391615956920142]
	TIME [epoch: 8.31 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18369881199178265		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.18369881199178265 | validation: 0.18974072122540075]
	TIME [epoch: 8.31 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1767501562295089		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.1767501562295089 | validation: 0.18320051089677603]
	TIME [epoch: 8.33 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18695815955095182		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.18695815955095182 | validation: 0.2123451445560487]
	TIME [epoch: 8.31 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1868730999670639		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.1868730999670639 | validation: 0.18554239931873015]
	TIME [epoch: 8.31 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1746304564226108		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.1746304564226108 | validation: 0.19588587121206225]
	TIME [epoch: 8.31 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1811635564895784		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.1811635564895784 | validation: 0.1873927542438959]
	TIME [epoch: 8.32 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18291567322917773		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.18291567322917773 | validation: 0.16162380611682253]
	TIME [epoch: 8.33 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.17428155034264953		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.17428155034264953 | validation: 0.17872099355055954]
	TIME [epoch: 8.31 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.1662317631617618		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.1662317631617618 | validation: 0.17667412403226818]
	TIME [epoch: 8.31 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.18549420624309718		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.18549420624309718 | validation: 0.21919421763795174]
	TIME [epoch: 8.32 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 10/10] avg loss: 0.19339737794029735		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.19339737794029735 | validation: 0.1897197955094227]
	TIME [epoch: 8.33 sec]
Finished training in 8447.047 seconds.
