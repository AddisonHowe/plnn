Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r0', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3921626113

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.12395076345896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.12395076345896 | validation: 8.361593486013348]
	TIME [epoch: 48.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.081961076270211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.081961076270211 | validation: 7.920786196808422]
	TIME [epoch: 9.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.6589242314040575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6589242314040575 | validation: 7.408789192650395]
	TIME [epoch: 9.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.285930348039552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.285930348039552 | validation: 6.942267849908294]
	TIME [epoch: 9.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.982975145594399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.982975145594399 | validation: 6.724873831708393]
	TIME [epoch: 9.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.771854320160122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.771854320160122 | validation: 6.482547318645822]
	TIME [epoch: 9.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.614695093288844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.614695093288844 | validation: 6.352995346903263]
	TIME [epoch: 9.27 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.488869799247809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.488869799247809 | validation: 6.364746014546453]
	TIME [epoch: 9.28 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.309218426491071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.309218426491071 | validation: 5.015348316843436]
	TIME [epoch: 9.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.220549555972713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.220549555972713 | validation: 2.9940714882919566]
	TIME [epoch: 9.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.894202035671602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.894202035671602 | validation: 3.5625143192332107]
	TIME [epoch: 9.29 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.088234148999093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.088234148999093 | validation: 2.826914506950957]
	TIME [epoch: 9.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7425239325233113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7425239325233113 | validation: 3.0812749659111796]
	TIME [epoch: 9.31 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7235363292198285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7235363292198285 | validation: 2.947296930642632]
	TIME [epoch: 9.28 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4498349842279596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4498349842279596 | validation: 2.2171124210964095]
	TIME [epoch: 9.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.467959887354085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.467959887354085 | validation: 2.2221294508279494]
	TIME [epoch: 9.29 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.040184546043852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.040184546043852 | validation: 2.3131357661138394]
	TIME [epoch: 9.3 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9130947720551537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9130947720551537 | validation: 1.9220138898838681]
	TIME [epoch: 9.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8654656134397691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8654656134397691 | validation: 1.6151223229529144]
	TIME [epoch: 9.27 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5120343738118776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5120343738118776 | validation: 1.562803440847565]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5258502385366683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5258502385366683 | validation: 1.3505004750252958]
	TIME [epoch: 9.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0980514602970772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0980514602970772 | validation: 0.9668756889599314]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9740960746917082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9740960746917082 | validation: 0.9249774060461765]
	TIME [epoch: 9.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8224468009842998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8224468009842998 | validation: 0.967615263914688]
	TIME [epoch: 9.27 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8168342726599072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8168342726599072 | validation: 0.8470480071209634]
	TIME [epoch: 9.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8523065939967802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8523065939967802 | validation: 0.7004211950686647]
	TIME [epoch: 9.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7319976539109009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7319976539109009 | validation: 0.7040047927451276]
	TIME [epoch: 9.28 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0220080538458711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0220080538458711 | validation: 0.84504878994252]
	TIME [epoch: 9.28 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8700805534439855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8700805534439855 | validation: 0.6635593047572415]
	TIME [epoch: 9.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7104353394924234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7104353394924234 | validation: 0.6012552367836721]
	TIME [epoch: 9.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6990570097939435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6990570097939435 | validation: 0.7353468491615935]
	TIME [epoch: 9.29 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6862529307436718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6862529307436718 | validation: 2.2455376306540273]
	TIME [epoch: 9.27 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8355725373194323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8355725373194323 | validation: 0.6807686002742817]
	TIME [epoch: 9.3 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6362622166636784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6362622166636784 | validation: 0.49388449445523136]
	TIME [epoch: 9.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4154899752573966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4154899752573966 | validation: 3.3788265492817344]
	TIME [epoch: 9.27 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.627866489514647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.627866489514647 | validation: 3.3698218886111606]
	TIME [epoch: 9.27 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8184794626741323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8184794626741323 | validation: 3.2770342482582615]
	TIME [epoch: 9.29 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6527231891996554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6527231891996554 | validation: 1.1886350902648422]
	TIME [epoch: 9.28 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0616443826328905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0616443826328905 | validation: 1.0175432071981656]
	TIME [epoch: 9.27 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7957632883530216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7957632883530216 | validation: 1.7341164703979346]
	TIME [epoch: 9.27 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9123977575291127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9123977575291127 | validation: 1.0845544404572638]
	TIME [epoch: 9.3 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6861572992566438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6861572992566438 | validation: 0.5843358189218384]
	TIME [epoch: 9.27 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6682217398525642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6682217398525642 | validation: 0.5054851636675706]
	TIME [epoch: 9.27 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5961605100159885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5961605100159885 | validation: 0.4736941457626478]
	TIME [epoch: 9.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5762040226021863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5762040226021863 | validation: 0.4112993752337565]
	TIME [epoch: 9.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.625624505842172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.625624505842172 | validation: 1.066284799833678]
	TIME [epoch: 9.26 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6355543924916506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6355543924916506 | validation: 0.5004303058762013]
	TIME [epoch: 9.26 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49467208917439176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49467208917439176 | validation: 0.5477042272305234]
	TIME [epoch: 9.27 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6741861956464774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6741861956464774 | validation: 0.5243693239609228]
	TIME [epoch: 9.29 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6202007644860099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6202007644860099 | validation: 0.7959652043245864]
	TIME [epoch: 9.26 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0512750364959156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0512750364959156 | validation: 3.0670940212903073]
	TIME [epoch: 9.26 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.592841782243878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.592841782243878 | validation: 2.803891868676723]
	TIME [epoch: 9.26 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.699908473295336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.699908473295336 | validation: 1.454639871034717]
	TIME [epoch: 9.28 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9013223042657295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9013223042657295 | validation: 1.1128133628090877]
	TIME [epoch: 9.27 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1538825079295836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1538825079295836 | validation: 0.7743625271957418]
	TIME [epoch: 9.27 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9427598830743749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9427598830743749 | validation: 0.6439281605298972]
	TIME [epoch: 9.26 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7560586175887222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7560586175887222 | validation: 0.5991590084598051]
	TIME [epoch: 9.29 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7594918739344102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7594918739344102 | validation: 0.7730162821514648]
	TIME [epoch: 9.27 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6948616361543332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6948616361543332 | validation: 0.7187069095794998]
	TIME [epoch: 9.26 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8302294569686351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8302294569686351 | validation: 0.6578262544492565]
	TIME [epoch: 9.26 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.835867449642647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.835867449642647 | validation: 0.6778386601586285]
	TIME [epoch: 9.28 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6449081545723477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6449081545723477 | validation: 0.6339687978296495]
	TIME [epoch: 9.27 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6779456508498247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6779456508498247 | validation: 0.6548295204915173]
	TIME [epoch: 9.26 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6283943121069521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6283943121069521 | validation: 0.757340863230558]
	TIME [epoch: 9.26 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6824956917453247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6824956917453247 | validation: 0.4524600084294378]
	TIME [epoch: 9.28 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46403701609801845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46403701609801845 | validation: 0.49618344800935793]
	TIME [epoch: 9.26 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5906877739583349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5906877739583349 | validation: 0.5274575619801769]
	TIME [epoch: 9.26 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5221058048997678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5221058048997678 | validation: 0.5697201296850065]
	TIME [epoch: 9.25 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5584579788468905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5584579788468905 | validation: 0.5149490279169072]
	TIME [epoch: 9.27 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6173879574982208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6173879574982208 | validation: 0.447174281320712]
	TIME [epoch: 9.26 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.468798261390435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.468798261390435 | validation: 0.6439075661128607]
	TIME [epoch: 9.25 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5776962138772823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5776962138772823 | validation: 0.30336866858214706]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46064656162986317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46064656162986317 | validation: 0.828925549128188]
	TIME [epoch: 9.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4912047736471127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4912047736471127 | validation: 1.77764446063888]
	TIME [epoch: 9.29 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6706932100194009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6706932100194009 | validation: 0.384271348458443]
	TIME [epoch: 9.26 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4009952390406378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4009952390406378 | validation: 0.7405606037580005]
	TIME [epoch: 9.26 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43224543378367863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43224543378367863 | validation: 0.4431447863324003]
	TIME [epoch: 9.26 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4746699322425238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4746699322425238 | validation: 0.6987011720594944]
	TIME [epoch: 9.29 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44912838178197917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44912838178197917 | validation: 0.47106955039657245]
	TIME [epoch: 9.27 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4639164870453736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4639164870453736 | validation: 0.37738853767892117]
	TIME [epoch: 9.27 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5967525025055319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5967525025055319 | validation: 1.094178812044764]
	TIME [epoch: 9.26 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5889237765674624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5889237765674624 | validation: 0.4357516207722477]
	TIME [epoch: 9.28 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4340537000010217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4340537000010217 | validation: 0.49577922558118903]
	TIME [epoch: 9.26 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49161290253790063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49161290253790063 | validation: 0.30479543378719137]
	TIME [epoch: 9.27 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46432375557570715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46432375557570715 | validation: 0.4010603934868736]
	TIME [epoch: 9.27 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4433574500183761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4433574500183761 | validation: 1.0655630002654053]
	TIME [epoch: 9.29 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5828722283773551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5828722283773551 | validation: 0.6953518447989315]
	TIME [epoch: 9.25 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8685040763093707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8685040763093707 | validation: 3.4903101815533004]
	TIME [epoch: 9.27 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5422019022134443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5422019022134443 | validation: 3.0687200073158447]
	TIME [epoch: 9.26 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.343542677413414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.343542677413414 | validation: 0.4517060204995193]
	TIME [epoch: 9.29 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5362944758076061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5362944758076061 | validation: 1.0745713562714885]
	TIME [epoch: 9.26 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6634456159226049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6634456159226049 | validation: 0.5774253660433668]
	TIME [epoch: 9.27 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6126362753385628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6126362753385628 | validation: 1.2594920200338744]
	TIME [epoch: 9.26 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5841993139710933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5841993139710933 | validation: 0.45204215314502183]
	TIME [epoch: 9.28 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3752401119370517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3752401119370517 | validation: 0.6363551669447691]
	TIME [epoch: 9.26 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48153805540779243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48153805540779243 | validation: 0.5178469668423382]
	TIME [epoch: 9.24 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42316610005682564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42316610005682564 | validation: 0.43019008351713023]
	TIME [epoch: 9.26 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33321359445001864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33321359445001864 | validation: 0.3238507594986424]
	TIME [epoch: 9.28 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40631767267119967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40631767267119967 | validation: 0.29897289337916316]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44368690570840164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44368690570840164 | validation: 0.23578863004615497]
	TIME [epoch: 9.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45779134021345785		[learning rate: 0.0099782]
	Learning Rate: 0.00997821
	LOSS [training: 0.45779134021345785 | validation: 0.6206158803832915]
	TIME [epoch: 9.28 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39812235035333154		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 0.39812235035333154 | validation: 0.40726480664031717]
	TIME [epoch: 9.29 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4335154227514203		[learning rate: 0.00993]
	Learning Rate: 0.00992996
	LOSS [training: 0.4335154227514203 | validation: 0.2366133818713052]
	TIME [epoch: 9.27 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31132740250712193		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 0.31132740250712193 | validation: 0.35229210284192203]
	TIME [epoch: 9.26 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.295605792628957		[learning rate: 0.0098819]
	Learning Rate: 0.00988194
	LOSS [training: 0.295605792628957 | validation: 0.3903158411517044]
	TIME [epoch: 9.27 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2981565754829347		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 0.2981565754829347 | validation: 0.34068877577664197]
	TIME [epoch: 9.28 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37073681890759197		[learning rate: 0.0098341]
	Learning Rate: 0.00983415
	LOSS [training: 0.37073681890759197 | validation: 0.39336518129429654]
	TIME [epoch: 9.27 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32711003629743024		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 0.32711003629743024 | validation: 0.8733052251875052]
	TIME [epoch: 9.26 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3594276901094622		[learning rate: 0.0097866]
	Learning Rate: 0.00978659
	LOSS [training: 0.3594276901094622 | validation: 0.4136703166351773]
	TIME [epoch: 9.26 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38714017010829394		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 0.38714017010829394 | validation: 0.5831569672616013]
	TIME [epoch: 9.28 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4769457756584842		[learning rate: 0.0097393]
	Learning Rate: 0.00973927
	LOSS [training: 0.4769457756584842 | validation: 0.2878557251668382]
	TIME [epoch: 9.26 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2908337466455248		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 0.2908337466455248 | validation: 0.27333648435249386]
	TIME [epoch: 9.27 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2702298902382179		[learning rate: 0.0096922]
	Learning Rate: 0.00969217
	LOSS [training: 0.2702298902382179 | validation: 0.31967202635200637]
	TIME [epoch: 9.27 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33724289985696426		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 0.33724289985696426 | validation: 0.22702004763368394]
	TIME [epoch: 9.29 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3346005101083		[learning rate: 0.0096453]
	Learning Rate: 0.0096453
	LOSS [training: 0.3346005101083 | validation: 0.21453396215890802]
	TIME [epoch: 9.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2922695811823826		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 1.2922695811823826 | validation: 0.27352731950369225]
	TIME [epoch: 9.27 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37101459678945686		[learning rate: 0.0095987]
	Learning Rate: 0.00959866
	LOSS [training: 0.37101459678945686 | validation: 0.2918604867563632]
	TIME [epoch: 9.27 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4440420057642137		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 0.4440420057642137 | validation: 0.2917857156832361]
	TIME [epoch: 9.29 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2303744968626352		[learning rate: 0.0095522]
	Learning Rate: 0.00955224
	LOSS [training: 0.2303744968626352 | validation: 0.2779610021996277]
	TIME [epoch: 9.27 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3793266918180256		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 0.3793266918180256 | validation: 0.2356183157034049]
	TIME [epoch: 9.27 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29113589562076014		[learning rate: 0.009506]
	Learning Rate: 0.00950605
	LOSS [training: 0.29113589562076014 | validation: 0.4501076339173651]
	TIME [epoch: 9.26 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2788553757719914		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 0.2788553757719914 | validation: 0.2723042632059199]
	TIME [epoch: 9.28 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23106251406320646		[learning rate: 0.0094601]
	Learning Rate: 0.00946008
	LOSS [training: 0.23106251406320646 | validation: 0.2051061302636779]
	TIME [epoch: 9.27 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32444655001135414		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 0.32444655001135414 | validation: 0.24652920708548082]
	TIME [epoch: 9.26 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2722815445166952		[learning rate: 0.0094143]
	Learning Rate: 0.00941433
	LOSS [training: 0.2722815445166952 | validation: 0.29698753788731025]
	TIME [epoch: 9.27 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24604900257177179		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 0.24604900257177179 | validation: 0.18297177290707]
	TIME [epoch: 9.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2700387638152077		[learning rate: 0.0093688]
	Learning Rate: 0.00936881
	LOSS [training: 0.2700387638152077 | validation: 0.4924097934146925]
	TIME [epoch: 9.27 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.591615081730857		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 0.591615081730857 | validation: 0.3109096848957783]
	TIME [epoch: 9.26 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46649511524381737		[learning rate: 0.0093235]
	Learning Rate: 0.0093235
	LOSS [training: 0.46649511524381737 | validation: 0.42523121638804184]
	TIME [epoch: 9.26 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33342174083962367		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 0.33342174083962367 | validation: 0.2358402694945002]
	TIME [epoch: 9.28 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6041843349949254		[learning rate: 0.0092784]
	Learning Rate: 0.00927841
	LOSS [training: 0.6041843349949254 | validation: 0.6676788085942964]
	TIME [epoch: 9.27 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4147776576466556		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 0.4147776576466556 | validation: 0.1859228781759486]
	TIME [epoch: 9.26 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2315668864258181		[learning rate: 0.0092335]
	Learning Rate: 0.00923354
	LOSS [training: 0.2315668864258181 | validation: 0.38207158025524846]
	TIME [epoch: 9.26 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7705580491890928		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 0.7705580491890928 | validation: 0.6034450604238131]
	TIME [epoch: 9.28 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6345824010920552		[learning rate: 0.0091889]
	Learning Rate: 0.00918889
	LOSS [training: 0.6345824010920552 | validation: 0.7365671221796786]
	TIME [epoch: 9.27 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6703570675823023		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 0.6703570675823023 | validation: 0.46566169254130785]
	TIME [epoch: 9.26 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4387068368768297		[learning rate: 0.0091445]
	Learning Rate: 0.00914446
	LOSS [training: 0.4387068368768297 | validation: 0.9199722580046685]
	TIME [epoch: 9.27 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34248349262373123		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 0.34248349262373123 | validation: 0.19675898633407862]
	TIME [epoch: 9.28 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.233533531659519		[learning rate: 0.0091002]
	Learning Rate: 0.00910024
	LOSS [training: 0.233533531659519 | validation: 0.29513248447102136]
	TIME [epoch: 9.28 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3617716825392417		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.3617716825392417 | validation: 0.27890917182449815]
	TIME [epoch: 9.27 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3799825416481356		[learning rate: 0.0090562]
	Learning Rate: 0.00905623
	LOSS [training: 0.3799825416481356 | validation: 0.3659125149208379]
	TIME [epoch: 9.26 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2787300954702318		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 0.2787300954702318 | validation: 0.2052596834998252]
	TIME [epoch: 9.26 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2341449697867019		[learning rate: 0.0090124]
	Learning Rate: 0.00901243
	LOSS [training: 0.2341449697867019 | validation: 0.19652244704749236]
	TIME [epoch: 9.28 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2578668289821234		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 0.2578668289821234 | validation: 0.37183827728852137]
	TIME [epoch: 9.29 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20590026308139325		[learning rate: 0.0089689]
	Learning Rate: 0.00896885
	LOSS [training: 0.20590026308139325 | validation: 0.2417671337710392]
	TIME [epoch: 9.26 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23727369191728193		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 0.23727369191728193 | validation: 0.27269397441411736]
	TIME [epoch: 9.26 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3140291099099358		[learning rate: 0.0089255]
	Learning Rate: 0.00892548
	LOSS [training: 0.3140291099099358 | validation: 0.32047767358763285]
	TIME [epoch: 9.28 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26599762014764894		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 0.26599762014764894 | validation: 0.3889801841654363]
	TIME [epoch: 9.26 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25200630692409354		[learning rate: 0.0088823]
	Learning Rate: 0.00888232
	LOSS [training: 0.25200630692409354 | validation: 0.3315229301715227]
	TIME [epoch: 9.26 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23034761580555055		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 0.23034761580555055 | validation: 0.21760728487733455]
	TIME [epoch: 9.26 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21961425465199774		[learning rate: 0.0088394]
	Learning Rate: 0.00883936
	LOSS [training: 0.21961425465199774 | validation: 0.23536555472814202]
	TIME [epoch: 9.28 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2536598656131372		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 0.2536598656131372 | validation: 0.3767423153361281]
	TIME [epoch: 9.26 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4803977737296464		[learning rate: 0.0087966]
	Learning Rate: 0.00879662
	LOSS [training: 0.4803977737296464 | validation: 0.46602816521699786]
	TIME [epoch: 9.26 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5218550217011589		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 0.5218550217011589 | validation: 0.719486206019837]
	TIME [epoch: 9.26 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3702681720573723		[learning rate: 0.0087541]
	Learning Rate: 0.00875408
	LOSS [training: 0.3702681720573723 | validation: 0.377804628319906]
	TIME [epoch: 9.28 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2685497283804701		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 0.2685497283804701 | validation: 0.24585736357384363]
	TIME [epoch: 9.26 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23222166390542354		[learning rate: 0.0087117]
	Learning Rate: 0.00871175
	LOSS [training: 0.23222166390542354 | validation: 0.21103374181929074]
	TIME [epoch: 9.26 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21005274239686123		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 0.21005274239686123 | validation: 0.1588353937203958]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6851799625541888		[learning rate: 0.0086696]
	Learning Rate: 0.00866962
	LOSS [training: 0.6851799625541888 | validation: 1.456617703181076]
	TIME [epoch: 9.26 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6727540799193055		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.6727540799193055 | validation: 0.41992593961710684]
	TIME [epoch: 9.24 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27366362158568835		[learning rate: 0.0086277]
	Learning Rate: 0.00862769
	LOSS [training: 0.27366362158568835 | validation: 0.2140071930004973]
	TIME [epoch: 9.25 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2440899869502017		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.2440899869502017 | validation: 0.20224970014284205]
	TIME [epoch: 9.24 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2176477671084344		[learning rate: 0.008586]
	Learning Rate: 0.00858597
	LOSS [training: 0.2176477671084344 | validation: 0.31119947023510014]
	TIME [epoch: 9.27 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40861153109773285		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 0.40861153109773285 | validation: 0.39559388108673343]
	TIME [epoch: 9.25 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2372730552004252		[learning rate: 0.0085445]
	Learning Rate: 0.00854445
	LOSS [training: 0.2372730552004252 | validation: 0.2204909072466722]
	TIME [epoch: 9.25 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2122183817186803		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 0.2122183817186803 | validation: 1.2262324080922704]
	TIME [epoch: 9.25 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48761673583229515		[learning rate: 0.0085031]
	Learning Rate: 0.00850313
	LOSS [training: 0.48761673583229515 | validation: 0.24358262524677105]
	TIME [epoch: 9.27 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16912720246355464		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.16912720246355464 | validation: 0.13647617971242704]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4423411515558623		[learning rate: 0.008462]
	Learning Rate: 0.00846201
	LOSS [training: 0.4423411515558623 | validation: 0.322357403580044]
	TIME [epoch: 9.24 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2334037557776933		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 0.2334037557776933 | validation: 0.2264104684642836]
	TIME [epoch: 9.23 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21092434301383217		[learning rate: 0.0084211]
	Learning Rate: 0.00842109
	LOSS [training: 0.21092434301383217 | validation: 0.2710046576825552]
	TIME [epoch: 9.26 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1879027203472342		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 0.1879027203472342 | validation: 0.25995005184467024]
	TIME [epoch: 9.24 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21249793119413832		[learning rate: 0.0083804]
	Learning Rate: 0.00838037
	LOSS [training: 0.21249793119413832 | validation: 0.3936156813643755]
	TIME [epoch: 9.24 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2645344091777875		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 0.2645344091777875 | validation: 0.15291295258387003]
	TIME [epoch: 9.25 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20670325474664725		[learning rate: 0.0083398]
	Learning Rate: 0.00833984
	LOSS [training: 0.20670325474664725 | validation: 0.2371805889296843]
	TIME [epoch: 9.26 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3027042350335251		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.3027042350335251 | validation: 0.4096089947971914]
	TIME [epoch: 9.25 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25200831518720146		[learning rate: 0.0082995]
	Learning Rate: 0.00829951
	LOSS [training: 0.25200831518720146 | validation: 0.21467398400736304]
	TIME [epoch: 9.25 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3381311104678188		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.3381311104678188 | validation: 0.22115936429760796]
	TIME [epoch: 9.25 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3473476603771239		[learning rate: 0.0082594]
	Learning Rate: 0.00825938
	LOSS [training: 0.3473476603771239 | validation: 1.7848591503131366]
	TIME [epoch: 9.26 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5283323678995029		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.5283323678995029 | validation: 0.18567432220814403]
	TIME [epoch: 9.23 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1916120486398161		[learning rate: 0.0082194]
	Learning Rate: 0.00821944
	LOSS [training: 0.1916120486398161 | validation: 0.2321500374394631]
	TIME [epoch: 9.23 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20184835279297747		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.20184835279297747 | validation: 0.22294976463298366]
	TIME [epoch: 9.23 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33412936498580176		[learning rate: 0.0081797]
	Learning Rate: 0.00817969
	LOSS [training: 0.33412936498580176 | validation: 1.2423240218933789]
	TIME [epoch: 9.26 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3824778149733861		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.3824778149733861 | validation: 0.1773603606184883]
	TIME [epoch: 9.25 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26797740109352614		[learning rate: 0.0081401]
	Learning Rate: 0.00814013
	LOSS [training: 0.26797740109352614 | validation: 0.2522293525311183]
	TIME [epoch: 9.24 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2006542377332591		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.2006542377332591 | validation: 0.2320933624623709]
	TIME [epoch: 9.25 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24196328107693574		[learning rate: 0.0081008]
	Learning Rate: 0.00810077
	LOSS [training: 0.24196328107693574 | validation: 0.1814266142541846]
	TIME [epoch: 9.25 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24876911606251087		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.24876911606251087 | validation: 0.9020989853583528]
	TIME [epoch: 9.25 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34370509736704313		[learning rate: 0.0080616]
	Learning Rate: 0.0080616
	LOSS [training: 0.34370509736704313 | validation: 0.2713262909529508]
	TIME [epoch: 9.24 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.270368467452217		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.270368467452217 | validation: 0.5965143214449873]
	TIME [epoch: 9.24 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2268457742717552		[learning rate: 0.0080226]
	Learning Rate: 0.00802261
	LOSS [training: 0.2268457742717552 | validation: 0.21236678762491537]
	TIME [epoch: 9.25 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19254852941595446		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.19254852941595446 | validation: 0.13961047262451404]
	TIME [epoch: 9.26 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2214527047750318		[learning rate: 0.0079838]
	Learning Rate: 0.00798382
	LOSS [training: 0.2214527047750318 | validation: 0.18402615254536386]
	TIME [epoch: 9.24 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20298406122255255		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.20298406122255255 | validation: 0.3494526970404762]
	TIME [epoch: 9.26 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2730224594077961		[learning rate: 0.0079452]
	Learning Rate: 0.00794521
	LOSS [training: 0.2730224594077961 | validation: 0.2678580130020913]
	TIME [epoch: 9.25 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2666277763933016		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.2666277763933016 | validation: 0.3164979832443967]
	TIME [epoch: 9.27 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2854964173421968		[learning rate: 0.0079068]
	Learning Rate: 0.00790679
	LOSS [training: 0.2854964173421968 | validation: 0.20937408859556317]
	TIME [epoch: 9.25 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35012941610508674		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.35012941610508674 | validation: 1.4031796513139583]
	TIME [epoch: 9.25 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3211604757512027		[learning rate: 0.0078685]
	Learning Rate: 0.00786855
	LOSS [training: 0.3211604757512027 | validation: 0.23904260887146983]
	TIME [epoch: 9.25 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15895438750624416		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.15895438750624416 | validation: 0.19963859608080542]
	TIME [epoch: 9.27 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21197471570740584		[learning rate: 0.0078305]
	Learning Rate: 0.0078305
	LOSS [training: 0.21197471570740584 | validation: 0.2696123369629672]
	TIME [epoch: 9.24 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1776861524665499		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.1776861524665499 | validation: 0.21088633583771194]
	TIME [epoch: 9.26 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1765794802778438		[learning rate: 0.0077926]
	Learning Rate: 0.00779263
	LOSS [training: 1.1765794802778438 | validation: 0.19114510712723426]
	TIME [epoch: 9.25 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1993211612027052		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.1993211612027052 | validation: 0.27819919856207603]
	TIME [epoch: 9.27 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21282895688325168		[learning rate: 0.0077549]
	Learning Rate: 0.00775495
	LOSS [training: 0.21282895688325168 | validation: 0.19681368048509235]
	TIME [epoch: 9.24 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46015563110633123		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.46015563110633123 | validation: 0.8010162853250484]
	TIME [epoch: 9.23 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35163514940081064		[learning rate: 0.0077174]
	Learning Rate: 0.00771745
	LOSS [training: 0.35163514940081064 | validation: 0.4238337222379767]
	TIME [epoch: 9.24 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5691817769520479		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.5691817769520479 | validation: 0.18587934955666913]
	TIME [epoch: 9.26 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19830995559608872		[learning rate: 0.0076801]
	Learning Rate: 0.00768013
	LOSS [training: 0.19830995559608872 | validation: 0.515023638902577]
	TIME [epoch: 9.24 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5685712284104772		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.5685712284104772 | validation: 0.3345680546113419]
	TIME [epoch: 9.24 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3104650511026416		[learning rate: 0.007643]
	Learning Rate: 0.00764299
	LOSS [training: 0.3104650511026416 | validation: 0.45181003476407655]
	TIME [epoch: 9.23 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26093875069015654		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.26093875069015654 | validation: 0.2132973790495362]
	TIME [epoch: 9.27 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31078970196909994		[learning rate: 0.007606]
	Learning Rate: 0.00760603
	LOSS [training: 0.31078970196909994 | validation: 0.36212788190120904]
	TIME [epoch: 9.25 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3962855605332465		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.3962855605332465 | validation: 0.2325276417690168]
	TIME [epoch: 9.23 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3261648507531883		[learning rate: 0.0075692]
	Learning Rate: 0.00756925
	LOSS [training: 0.3261648507531883 | validation: 0.26401302674266686]
	TIME [epoch: 9.26 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18551342133540213		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.18551342133540213 | validation: 0.33709156996043355]
	TIME [epoch: 9.27 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28666283817507104		[learning rate: 0.0075326]
	Learning Rate: 0.00753264
	LOSS [training: 0.28666283817507104 | validation: 0.20023419148983929]
	TIME [epoch: 9.26 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18459831387078235		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.18459831387078235 | validation: 0.2692837622301647]
	TIME [epoch: 9.24 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17914749886054465		[learning rate: 0.0074962]
	Learning Rate: 0.00749622
	LOSS [training: 0.17914749886054465 | validation: 0.25697123394528804]
	TIME [epoch: 9.25 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16994123077802986		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.16994123077802986 | validation: 0.1735668628517937]
	TIME [epoch: 9.27 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2626947356187717		[learning rate: 0.00746]
	Learning Rate: 0.00745997
	LOSS [training: 0.2626947356187717 | validation: 0.14615259547319542]
	TIME [epoch: 9.25 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21623733640358256		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.21623733640358256 | validation: 0.22954172042818]
	TIME [epoch: 9.25 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23583308508661585		[learning rate: 0.0074239]
	Learning Rate: 0.00742389
	LOSS [training: 0.23583308508661585 | validation: 0.3425925126404855]
	TIME [epoch: 9.25 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18809345939644434		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.18809345939644434 | validation: 0.3094338258936533]
	TIME [epoch: 9.26 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24117728370046976		[learning rate: 0.007388]
	Learning Rate: 0.00738799
	LOSS [training: 0.24117728370046976 | validation: 0.2520912342406324]
	TIME [epoch: 9.26 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4289320921345948		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.4289320921345948 | validation: 0.13299801143750412]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5211177814787452		[learning rate: 0.0073523]
	Learning Rate: 0.00735226
	LOSS [training: 0.5211177814787452 | validation: 0.8204910380927924]
	TIME [epoch: 9.25 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35638575658387806		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.35638575658387806 | validation: 0.5293951622435928]
	TIME [epoch: 9.29 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6749273501082589		[learning rate: 0.0073167]
	Learning Rate: 0.00731671
	LOSS [training: 0.6749273501082589 | validation: 0.5735711510357933]
	TIME [epoch: 9.28 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3662032950894034		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.3662032950894034 | validation: 0.15815397458194516]
	TIME [epoch: 9.27 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19469956733937183		[learning rate: 0.0072813]
	Learning Rate: 0.00728133
	LOSS [training: 0.19469956733937183 | validation: 0.19815527648834758]
	TIME [epoch: 9.27 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4242022489838373		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.4242022489838373 | validation: 0.5189546359679398]
	TIME [epoch: 9.28 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3969800103197384		[learning rate: 0.0072461]
	Learning Rate: 0.00724612
	LOSS [training: 0.3969800103197384 | validation: 0.5247625009148797]
	TIME [epoch: 9.27 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5890169424666561		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.5890169424666561 | validation: 0.598782667706603]
	TIME [epoch: 9.26 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5432954413142901		[learning rate: 0.0072111]
	Learning Rate: 0.00721107
	LOSS [training: 0.5432954413142901 | validation: 0.6148981419977035]
	TIME [epoch: 9.26 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3490092145549135		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.3490092145549135 | validation: 0.511396545510075]
	TIME [epoch: 9.26 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3375117649314535		[learning rate: 0.0071762]
	Learning Rate: 0.0071762
	LOSS [training: 0.3375117649314535 | validation: 0.4668758520312967]
	TIME [epoch: 9.26 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48148250591625913		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.48148250591625913 | validation: 0.4581673158149658]
	TIME [epoch: 9.25 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31934491697879624		[learning rate: 0.0071415]
	Learning Rate: 0.0071415
	LOSS [training: 0.31934491697879624 | validation: 0.36563613250014815]
	TIME [epoch: 9.25 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5038015865513318		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.5038015865513318 | validation: 0.2924935782119766]
	TIME [epoch: 9.27 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2852236335127212		[learning rate: 0.007107]
	Learning Rate: 0.00710696
	LOSS [training: 0.2852236335127212 | validation: 0.27798036807040094]
	TIME [epoch: 9.29 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3455480357750185		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.3455480357750185 | validation: 0.642421087903443]
	TIME [epoch: 9.26 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5908158171203721		[learning rate: 0.0070726]
	Learning Rate: 0.0070726
	LOSS [training: 0.5908158171203721 | validation: 1.7088357351171786]
	TIME [epoch: 9.26 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5599649284291514		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.5599649284291514 | validation: 0.307893235863674]
	TIME [epoch: 9.26 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25143325040239206		[learning rate: 0.0070384]
	Learning Rate: 0.0070384
	LOSS [training: 0.25143325040239206 | validation: 0.40568331629275856]
	TIME [epoch: 9.27 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2917375696633463		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.2917375696633463 | validation: 0.23723160191138004]
	TIME [epoch: 9.25 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22519972973274394		[learning rate: 0.0070044]
	Learning Rate: 0.00700436
	LOSS [training: 0.22519972973274394 | validation: 0.23048446924625066]
	TIME [epoch: 9.26 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1756105418531288		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.1756105418531288 | validation: 0.23132732077068607]
	TIME [epoch: 9.25 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21196431981280162		[learning rate: 0.0069705]
	Learning Rate: 0.00697049
	LOSS [training: 0.21196431981280162 | validation: 0.9391686036833389]
	TIME [epoch: 9.27 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6189111116426183		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.6189111116426183 | validation: 0.23286569864445114]
	TIME [epoch: 9.26 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18715659888616032		[learning rate: 0.0069368]
	Learning Rate: 0.00693678
	LOSS [training: 0.18715659888616032 | validation: 0.34492425504016366]
	TIME [epoch: 9.25 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5830396120519403		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.5830396120519403 | validation: 0.15653616906396967]
	TIME [epoch: 9.27 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24862302628036298		[learning rate: 0.0069032]
	Learning Rate: 0.00690323
	LOSS [training: 0.24862302628036298 | validation: 0.24022355067901588]
	TIME [epoch: 9.27 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21610022358694475		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.21610022358694475 | validation: 0.21662689360076653]
	TIME [epoch: 9.27 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20181506766850238		[learning rate: 0.0068699]
	Learning Rate: 0.00686985
	LOSS [training: 0.20181506766850238 | validation: 0.21097402098674178]
	TIME [epoch: 9.27 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15689892967731606		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.15689892967731606 | validation: 0.21343911396180593]
	TIME [epoch: 9.26 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16828038900157088		[learning rate: 0.0068366]
	Learning Rate: 0.00683663
	LOSS [training: 0.16828038900157088 | validation: 0.21525749986022386]
	TIME [epoch: 9.28 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23099520592791176		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.23099520592791176 | validation: 0.16433861955901807]
	TIME [epoch: 9.26 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19859345939562115		[learning rate: 0.0068036]
	Learning Rate: 0.00680357
	LOSS [training: 0.19859345939562115 | validation: 0.1878100000507247]
	TIME [epoch: 9.26 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21192876907489294		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.21192876907489294 | validation: 0.1420937921505135]
	TIME [epoch: 9.25 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24100367907762282		[learning rate: 0.0067707]
	Learning Rate: 0.00677067
	LOSS [training: 0.24100367907762282 | validation: 0.20421041096580977]
	TIME [epoch: 9.27 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23815518848588463		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.23815518848588463 | validation: 0.25944243589179783]
	TIME [epoch: 9.25 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18023427146488358		[learning rate: 0.0067379]
	Learning Rate: 0.00673793
	LOSS [training: 0.18023427146488358 | validation: 0.17341692702624975]
	TIME [epoch: 9.26 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20341371705239902		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.20341371705239902 | validation: 0.24152694250827922]
	TIME [epoch: 9.25 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2092891412037436		[learning rate: 0.0067053]
	Learning Rate: 0.00670534
	LOSS [training: 0.2092891412037436 | validation: 0.47619689011802524]
	TIME [epoch: 9.28 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24190497907210617		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.24190497907210617 | validation: 0.16885054986782055]
	TIME [epoch: 9.26 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19014058046457302		[learning rate: 0.0066729]
	Learning Rate: 0.00667292
	LOSS [training: 0.19014058046457302 | validation: 0.17056448695963053]
	TIME [epoch: 9.26 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16120197355575897		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.16120197355575897 | validation: 0.23323765682548953]
	TIME [epoch: 9.26 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15640530886488185		[learning rate: 0.0066406]
	Learning Rate: 0.00664065
	LOSS [training: 0.15640530886488185 | validation: 0.10769588818486181]
	TIME [epoch: 9.28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24933944174751219		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.24933944174751219 | validation: 0.1582109462118862]
	TIME [epoch: 9.27 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2499577348440422		[learning rate: 0.0066085]
	Learning Rate: 0.00660854
	LOSS [training: 0.2499577348440422 | validation: 0.43493709603911346]
	TIME [epoch: 9.27 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2569181243251398		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.2569181243251398 | validation: 0.0895078442780739]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_272.pth
	Model improved!!!
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16484460825354882		[learning rate: 0.0065766]
	Learning Rate: 0.00657658
	LOSS [training: 0.16484460825354882 | validation: 0.4390349763348791]
	TIME [epoch: 9.28 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23135774551689173		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.23135774551689173 | validation: 0.301381444525162]
	TIME [epoch: 9.27 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42377684294045387		[learning rate: 0.0065448]
	Learning Rate: 0.00654477
	LOSS [training: 0.42377684294045387 | validation: 0.4131036788442979]
	TIME [epoch: 9.26 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2683512158246493		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.2683512158246493 | validation: 0.30172305676978184]
	TIME [epoch: 9.26 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20647756534080547		[learning rate: 0.0065131]
	Learning Rate: 0.00651313
	LOSS [training: 0.20647756534080547 | validation: 0.10238544891403228]
	TIME [epoch: 9.27 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19222963627014394		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.19222963627014394 | validation: 0.10786628568593039]
	TIME [epoch: 9.26 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.235199876625882		[learning rate: 0.0064816]
	Learning Rate: 0.00648163
	LOSS [training: 0.235199876625882 | validation: 0.9976754430063098]
	TIME [epoch: 9.26 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2996271843996202		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.2996271843996202 | validation: 0.28646742723962326]
	TIME [epoch: 9.27 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9379171157140668		[learning rate: 0.0064503]
	Learning Rate: 0.00645029
	LOSS [training: 0.9379171157140668 | validation: 2.2165257581358926]
	TIME [epoch: 9.29 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5179432585219585		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.5179432585219585 | validation: 0.2560643420151421]
	TIME [epoch: 9.27 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2757645946423105		[learning rate: 0.0064191]
	Learning Rate: 0.00641909
	LOSS [training: 0.2757645946423105 | validation: 0.2141024640165473]
	TIME [epoch: 9.26 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11346438912628458		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.11346438912628458 | validation: 0.35382495781287115]
	TIME [epoch: 9.26 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20210191780721934		[learning rate: 0.0063881]
	Learning Rate: 0.00638805
	LOSS [training: 0.20210191780721934 | validation: 0.21552313779011115]
	TIME [epoch: 9.28 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17845947188412073		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.17845947188412073 | validation: 0.23366279966320347]
	TIME [epoch: 9.26 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25315581337128495		[learning rate: 0.0063572]
	Learning Rate: 0.00635716
	LOSS [training: 0.25315581337128495 | validation: 0.4505322268373818]
	TIME [epoch: 9.26 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20548618422309523		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.20548618422309523 | validation: 0.3629086110868055]
	TIME [epoch: 9.26 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1390874123210481		[learning rate: 0.0063264]
	Learning Rate: 0.00632642
	LOSS [training: 0.1390874123210481 | validation: 0.21070304820367453]
	TIME [epoch: 9.27 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.246170274927099		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.246170274927099 | validation: 0.22133541337181517]
	TIME [epoch: 9.27 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3993788732425437		[learning rate: 0.0062958]
	Learning Rate: 0.00629582
	LOSS [training: 0.3993788732425437 | validation: 0.3435116812740241]
	TIME [epoch: 9.26 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16780058625134717		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.16780058625134717 | validation: 0.08683957959263472]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33327465146401175		[learning rate: 0.0062654]
	Learning Rate: 0.00626538
	LOSS [training: 0.33327465146401175 | validation: 0.16460962813834673]
	TIME [epoch: 9.27 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10526187689389785		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.10526187689389785 | validation: 0.09225413239327737]
	TIME [epoch: 9.27 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13331951006853804		[learning rate: 0.0062351]
	Learning Rate: 0.00623508
	LOSS [training: 0.13331951006853804 | validation: 0.12955374594124155]
	TIME [epoch: 9.25 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11743296094999751		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.11743296094999751 | validation: 0.24758470597368493]
	TIME [epoch: 9.26 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17594456154527963		[learning rate: 0.0062049]
	Learning Rate: 0.00620493
	LOSS [training: 0.17594456154527963 | validation: 0.17284517642239486]
	TIME [epoch: 9.25 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18739586815751982		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.18739586815751982 | validation: 0.17684618316149256]
	TIME [epoch: 9.28 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15633554773863678		[learning rate: 0.0061749]
	Learning Rate: 0.00617492
	LOSS [training: 0.15633554773863678 | validation: 0.1638702666117658]
	TIME [epoch: 9.25 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18581676862766977		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.18581676862766977 | validation: 0.37403837886765895]
	TIME [epoch: 9.26 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35987822909434924		[learning rate: 0.0061451]
	Learning Rate: 0.00614506
	LOSS [training: 0.35987822909434924 | validation: 0.21513890235399086]
	TIME [epoch: 9.25 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17431264042238556		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.17431264042238556 | validation: 0.20166138736391864]
	TIME [epoch: 9.28 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1426533777149484		[learning rate: 0.0061153]
	Learning Rate: 0.00611535
	LOSS [training: 0.1426533777149484 | validation: 0.1435438690761632]
	TIME [epoch: 9.25 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2114096192172863		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.2114096192172863 | validation: 0.20294734099452028]
	TIME [epoch: 9.25 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3744437663581153		[learning rate: 0.0060858]
	Learning Rate: 0.00608577
	LOSS [training: 0.3744437663581153 | validation: 0.39857534553556695]
	TIME [epoch: 9.26 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3743219255056911		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.3743219255056911 | validation: 0.6014812487957093]
	TIME [epoch: 9.28 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23150160485233404		[learning rate: 0.0060563]
	Learning Rate: 0.00605634
	LOSS [training: 0.23150160485233404 | validation: 0.1716476061205815]
	TIME [epoch: 9.26 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13861500189843873		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.13861500189843873 | validation: 0.14888817852313552]
	TIME [epoch: 9.25 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12739842191548004		[learning rate: 0.0060271]
	Learning Rate: 0.00602706
	LOSS [training: 0.12739842191548004 | validation: 0.09472383769212914]
	TIME [epoch: 9.25 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23676184014550877		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.23676184014550877 | validation: 0.23426094021119076]
	TIME [epoch: 9.28 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16993494652473623		[learning rate: 0.0059979]
	Learning Rate: 0.00599791
	LOSS [training: 0.16993494652473623 | validation: 0.14943157572292942]
	TIME [epoch: 9.25 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18317743606865586		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.18317743606865586 | validation: 0.13715068239753564]
	TIME [epoch: 9.26 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20175054435452364		[learning rate: 0.0059689]
	Learning Rate: 0.00596891
	LOSS [training: 0.20175054435452364 | validation: 0.1541244631990074]
	TIME [epoch: 9.26 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12766144744091062		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.12766144744091062 | validation: 0.09008252102557421]
	TIME [epoch: 9.27 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14127682157652469		[learning rate: 0.00594]
	Learning Rate: 0.00594004
	LOSS [training: 0.14127682157652469 | validation: 0.1509949377662005]
	TIME [epoch: 9.25 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12904477206082715		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.12904477206082715 | validation: 0.21366604034386744]
	TIME [epoch: 9.25 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4993440236500534		[learning rate: 0.0059113]
	Learning Rate: 0.00591132
	LOSS [training: 0.4993440236500534 | validation: 0.31970899818283705]
	TIME [epoch: 9.25 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1774172270149808		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.1774172270149808 | validation: 0.11768068827419204]
	TIME [epoch: 9.28 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20241882593932586		[learning rate: 0.0058827]
	Learning Rate: 0.00588273
	LOSS [training: 0.20241882593932586 | validation: 0.5837168576966398]
	TIME [epoch: 9.25 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22743300436843997		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.22743300436843997 | validation: 0.24592375800708977]
	TIME [epoch: 9.26 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46854754441475954		[learning rate: 0.0058543]
	Learning Rate: 0.00585428
	LOSS [training: 0.46854754441475954 | validation: 0.5725925649233647]
	TIME [epoch: 9.25 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2516422365036486		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 1.2516422365036486 | validation: 0.8578437665190817]
	TIME [epoch: 9.27 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45925934201295915		[learning rate: 0.005826]
	Learning Rate: 0.00582597
	LOSS [training: 0.45925934201295915 | validation: 0.4185825404865865]
	TIME [epoch: 9.25 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.62524905846303		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.62524905846303 | validation: 0.3720785336734939]
	TIME [epoch: 9.24 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21276317885952162		[learning rate: 0.0057978]
	Learning Rate: 0.0057978
	LOSS [training: 0.21276317885952162 | validation: 0.26446728043453926]
	TIME [epoch: 9.25 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11535267416527303		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.11535267416527303 | validation: 0.10014260638460226]
	TIME [epoch: 9.27 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14412065828892312		[learning rate: 0.0057698]
	Learning Rate: 0.00576976
	LOSS [training: 0.14412065828892312 | validation: 0.1126424053750675]
	TIME [epoch: 9.26 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4179404128950119		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.4179404128950119 | validation: 0.7873202915152064]
	TIME [epoch: 9.25 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3305644750837361		[learning rate: 0.0057419]
	Learning Rate: 0.00574186
	LOSS [training: 0.3305644750837361 | validation: 0.24020011616749165]
	TIME [epoch: 9.25 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17400760606042537		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.17400760606042537 | validation: 0.07907124946523131]
	TIME [epoch: 9.27 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14041930736979877		[learning rate: 0.0057141]
	Learning Rate: 0.00571409
	LOSS [training: 0.14041930736979877 | validation: 0.2725407743297861]
	TIME [epoch: 9.26 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15880461353864744		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.15880461353864744 | validation: 0.2678861737402871]
	TIME [epoch: 9.26 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14992211050313375		[learning rate: 0.0056865]
	Learning Rate: 0.00568646
	LOSS [training: 0.14992211050313375 | validation: 0.1290613908404548]
	TIME [epoch: 9.26 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2485660346689155		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.2485660346689155 | validation: 0.19248761063799813]
	TIME [epoch: 9.28 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17037304890527744		[learning rate: 0.005659]
	Learning Rate: 0.00565896
	LOSS [training: 0.17037304890527744 | validation: 0.765698605312129]
	TIME [epoch: 9.26 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33071388611101166		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.33071388611101166 | validation: 0.2877454231696346]
	TIME [epoch: 9.26 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17916737398057486		[learning rate: 0.0056316]
	Learning Rate: 0.0056316
	LOSS [training: 0.17916737398057486 | validation: 0.1231828786265408]
	TIME [epoch: 9.25 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23604509697701545		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.23604509697701545 | validation: 0.2193215600601751]
	TIME [epoch: 9.27 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27574900349756526		[learning rate: 0.0056044]
	Learning Rate: 0.00560436
	LOSS [training: 0.27574900349756526 | validation: 0.5358483487730479]
	TIME [epoch: 9.27 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3515251075274869		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.3515251075274869 | validation: 0.3788845878676413]
	TIME [epoch: 9.26 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21857213414314405		[learning rate: 0.0055773]
	Learning Rate: 0.00557726
	LOSS [training: 0.21857213414314405 | validation: 0.20654061612798927]
	TIME [epoch: 9.26 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2285992760336839		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.2285992760336839 | validation: 0.24094029012546309]
	TIME [epoch: 9.27 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23123170166451903		[learning rate: 0.0055503]
	Learning Rate: 0.00555029
	LOSS [training: 0.23123170166451903 | validation: 0.2369498120681118]
	TIME [epoch: 9.28 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2079882032402307		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.2079882032402307 | validation: 0.512918185999641]
	TIME [epoch: 9.27 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2416403280588831		[learning rate: 0.0055235]
	Learning Rate: 0.00552345
	LOSS [training: 0.2416403280588831 | validation: 0.1769142405216556]
	TIME [epoch: 9.26 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2128304151679445		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.2128304151679445 | validation: 0.4066887602842896]
	TIME [epoch: 9.26 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5513773097939747		[learning rate: 0.0054967]
	Learning Rate: 0.00549674
	LOSS [training: 0.5513773097939747 | validation: 0.8323648164220443]
	TIME [epoch: 9.28 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4736135886485041		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.4736135886485041 | validation: 0.6770966770772597]
	TIME [epoch: 9.26 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30296728929295014		[learning rate: 0.0054702]
	Learning Rate: 0.00547016
	LOSS [training: 0.30296728929295014 | validation: 0.18797291028565438]
	TIME [epoch: 9.25 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1825038283559059		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.1825038283559059 | validation: 0.22347000785839105]
	TIME [epoch: 9.25 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1739047074368397		[learning rate: 0.0054437]
	Learning Rate: 0.00544371
	LOSS [training: 0.1739047074368397 | validation: 0.16427984124605025]
	TIME [epoch: 9.28 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24993773662888671		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.24993773662888671 | validation: 0.29236292426649885]
	TIME [epoch: 9.25 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17236500803504348		[learning rate: 0.0054174]
	Learning Rate: 0.00541738
	LOSS [training: 0.17236500803504348 | validation: 0.2648278146528164]
	TIME [epoch: 9.25 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19871439125500248		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.19871439125500248 | validation: 0.4521057278284403]
	TIME [epoch: 9.26 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2691402240271899		[learning rate: 0.0053912]
	Learning Rate: 0.00539118
	LOSS [training: 0.2691402240271899 | validation: 0.2156338761566794]
	TIME [epoch: 9.29 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2061469679255273		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.2061469679255273 | validation: 0.19422733161877082]
	TIME [epoch: 9.26 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19566865527777344		[learning rate: 0.0053651]
	Learning Rate: 0.00536511
	LOSS [training: 0.19566865527777344 | validation: 0.24828184904687894]
	TIME [epoch: 9.27 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3233331788241774		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.3233331788241774 | validation: 0.456067070175459]
	TIME [epoch: 9.26 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3601002055177828		[learning rate: 0.0053392]
	Learning Rate: 0.00533917
	LOSS [training: 0.3601002055177828 | validation: 0.5904599216718276]
	TIME [epoch: 9.29 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.293764110641961		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.293764110641961 | validation: 0.15297833553311074]
	TIME [epoch: 9.26 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2881040054174191		[learning rate: 0.0053133]
	Learning Rate: 0.00531335
	LOSS [training: 0.2881040054174191 | validation: 0.3086195255980368]
	TIME [epoch: 9.25 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1970827104832074		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 0.1970827104832074 | validation: 0.15584372946827918]
	TIME [epoch: 9.26 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16644236105752366		[learning rate: 0.0052877]
	Learning Rate: 0.00528766
	LOSS [training: 0.16644236105752366 | validation: 0.15232430999443647]
	TIME [epoch: 9.28 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1954632659952819		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.1954632659952819 | validation: 0.12985675302124128]
	TIME [epoch: 9.25 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15292051958368535		[learning rate: 0.0052621]
	Learning Rate: 0.00526209
	LOSS [training: 0.15292051958368535 | validation: 0.3124989459845551]
	TIME [epoch: 9.25 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36186244540422596		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 0.36186244540422596 | validation: 0.30459703001903304]
	TIME [epoch: 9.25 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.300734222151461		[learning rate: 0.0052366]
	Learning Rate: 0.00523664
	LOSS [training: 0.300734222151461 | validation: 0.2414120608819735]
	TIME [epoch: 9.27 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18335934613944854		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.18335934613944854 | validation: 0.17743198873157248]
	TIME [epoch: 9.25 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18499470922685596		[learning rate: 0.0052113]
	Learning Rate: 0.00521132
	LOSS [training: 0.18499470922685596 | validation: 0.176078781443734]
	TIME [epoch: 9.25 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3743979151723272		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.3743979151723272 | validation: 0.24626363316527472]
	TIME [epoch: 9.27 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17411815663087055		[learning rate: 0.0051861]
	Learning Rate: 0.00518611
	LOSS [training: 0.17411815663087055 | validation: 0.22419906387813476]
	TIME [epoch: 9.28 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20743509919376263		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.20743509919376263 | validation: 0.18803221846411383]
	TIME [epoch: 9.27 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23116644503389522		[learning rate: 0.005161]
	Learning Rate: 0.00516104
	LOSS [training: 0.23116644503389522 | validation: 0.20968435113513356]
	TIME [epoch: 9.25 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20544875242950397		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.20544875242950397 | validation: 0.2623868433813593]
	TIME [epoch: 9.25 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2068455225889072		[learning rate: 0.0051361]
	Learning Rate: 0.00513608
	LOSS [training: 0.2068455225889072 | validation: 0.34393834466663]
	TIME [epoch: 9.27 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37620299599971024		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.37620299599971024 | validation: 0.40714791375589665]
	TIME [epoch: 9.26 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1878086782254521		[learning rate: 0.0051112]
	Learning Rate: 0.00511124
	LOSS [training: 0.1878086782254521 | validation: 0.18817200808824597]
	TIME [epoch: 9.26 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20988455498401168		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.20988455498401168 | validation: 0.33538999393011437]
	TIME [epoch: 9.25 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19184046887901632		[learning rate: 0.0050865]
	Learning Rate: 0.00508652
	LOSS [training: 0.19184046887901632 | validation: 0.16641840085018184]
	TIME [epoch: 9.27 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17581983820110805		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.17581983820110805 | validation: 0.24585287576900225]
	TIME [epoch: 9.26 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2508015687049746		[learning rate: 0.0050619]
	Learning Rate: 0.00506193
	LOSS [training: 0.2508015687049746 | validation: 0.304557634070207]
	TIME [epoch: 9.25 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24242043601042912		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.24242043601042912 | validation: 0.18302023295352826]
	TIME [epoch: 9.24 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1855608957751695		[learning rate: 0.0050374]
	Learning Rate: 0.00503745
	LOSS [training: 0.1855608957751695 | validation: 0.42116616749058744]
	TIME [epoch: 9.27 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20306945442860375		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.20306945442860375 | validation: 0.2302999131682122]
	TIME [epoch: 9.26 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16606233390720296		[learning rate: 0.0050131]
	Learning Rate: 0.00501309
	LOSS [training: 0.16606233390720296 | validation: 0.12595899270153765]
	TIME [epoch: 9.24 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17075289734585336		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.17075289734585336 | validation: 0.1996955923018234]
	TIME [epoch: 9.25 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14669924008187527		[learning rate: 0.0049888]
	Learning Rate: 0.00498884
	LOSS [training: 0.14669924008187527 | validation: 0.1623314580232043]
	TIME [epoch: 9.27 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1374584362688717		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.1374584362688717 | validation: 0.12033877659643086]
	TIME [epoch: 9.26 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16980548054086628		[learning rate: 0.0049647]
	Learning Rate: 0.00496472
	LOSS [training: 0.16980548054086628 | validation: 0.12624809755479752]
	TIME [epoch: 9.25 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18001661395080998		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.18001661395080998 | validation: 0.20172319337274328]
	TIME [epoch: 9.25 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1617234961987674		[learning rate: 0.0049407]
	Learning Rate: 0.00494071
	LOSS [training: 0.1617234961987674 | validation: 0.3329929996493384]
	TIME [epoch: 9.25 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16702887456771948		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.16702887456771948 | validation: 0.12090449962639371]
	TIME [epoch: 9.27 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1512910478570652		[learning rate: 0.0049168]
	Learning Rate: 0.00491682
	LOSS [training: 0.1512910478570652 | validation: 0.16521858571776263]
	TIME [epoch: 9.25 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19902045860398357		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.19902045860398357 | validation: 0.24372624673455198]
	TIME [epoch: 9.26 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2288849650214843		[learning rate: 0.004893]
	Learning Rate: 0.00489304
	LOSS [training: 0.2288849650214843 | validation: 0.39424242311032165]
	TIME [epoch: 9.25 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27263935689498864		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.27263935689498864 | validation: 0.40371324817698034]
	TIME [epoch: 9.29 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7909309261167176		[learning rate: 0.0048694]
	Learning Rate: 0.00486938
	LOSS [training: 0.7909309261167176 | validation: 0.833804271353231]
	TIME [epoch: 9.26 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48837675745805703		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.48837675745805703 | validation: 0.44074522131397764]
	TIME [epoch: 9.26 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21980088499731526		[learning rate: 0.0048458]
	Learning Rate: 0.00484583
	LOSS [training: 0.21980088499731526 | validation: 0.21677683178216453]
	TIME [epoch: 9.26 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18821016020816686		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.18821016020816686 | validation: 0.18783529405678245]
	TIME [epoch: 9.26 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1999511324879226		[learning rate: 0.0048224]
	Learning Rate: 0.0048224
	LOSS [training: 0.1999511324879226 | validation: 0.14524055331626357]
	TIME [epoch: 9.25 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23554931346080554		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.23554931346080554 | validation: 0.15899056298880004]
	TIME [epoch: 9.25 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19492797032196432		[learning rate: 0.0047991]
	Learning Rate: 0.00479908
	LOSS [training: 0.19492797032196432 | validation: 0.16199542034900744]
	TIME [epoch: 9.26 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16818602227625223		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.16818602227625223 | validation: 0.169452445615966]
	TIME [epoch: 9.28 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15027489517606138		[learning rate: 0.0047759]
	Learning Rate: 0.00477587
	LOSS [training: 0.15027489517606138 | validation: 0.1956876339863478]
	TIME [epoch: 9.25 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17627803647828186		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.17627803647828186 | validation: 0.13638555096589833]
	TIME [epoch: 9.25 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1962021501882965		[learning rate: 0.0047528]
	Learning Rate: 0.00475278
	LOSS [training: 0.1962021501882965 | validation: 0.23145704996921462]
	TIME [epoch: 9.25 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16139291388618957		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.16139291388618957 | validation: 0.19016818297052518]
	TIME [epoch: 9.26 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17599457270769558		[learning rate: 0.0047298]
	Learning Rate: 0.00472979
	LOSS [training: 0.17599457270769558 | validation: 0.1916483546073524]
	TIME [epoch: 9.26 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14748336909992193		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.14748336909992193 | validation: 0.12990400828275928]
	TIME [epoch: 9.26 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16964747444842834		[learning rate: 0.0047069]
	Learning Rate: 0.00470692
	LOSS [training: 0.16964747444842834 | validation: 0.17596645101811598]
	TIME [epoch: 9.26 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12197114293377935		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.12197114293377935 | validation: 0.11794333656932238]
	TIME [epoch: 9.28 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12767084942367518		[learning rate: 0.0046842]
	Learning Rate: 0.00468416
	LOSS [training: 0.12767084942367518 | validation: 0.11085197542840652]
	TIME [epoch: 9.25 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15601189228170145		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.15601189228170145 | validation: 0.1950897789542493]
	TIME [epoch: 9.25 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15707298933757968		[learning rate: 0.0046615]
	Learning Rate: 0.00466151
	LOSS [training: 0.15707298933757968 | validation: 0.14916825187791602]
	TIME [epoch: 9.25 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1582663202126006		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.1582663202126006 | validation: 0.12297074311025288]
	TIME [epoch: 9.26 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14043805384144653		[learning rate: 0.004639]
	Learning Rate: 0.00463896
	LOSS [training: 0.14043805384144653 | validation: 0.2290410547158362]
	TIME [epoch: 9.26 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15052601425021006		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.15052601425021006 | validation: 0.250177725193811]
	TIME [epoch: 9.24 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1648816888145171		[learning rate: 0.0046165]
	Learning Rate: 0.00461653
	LOSS [training: 0.1648816888145171 | validation: 0.16256978574607028]
	TIME [epoch: 9.24 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14748908967611257		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.14748908967611257 | validation: 0.1650071619850721]
	TIME [epoch: 9.25 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15594032695577134		[learning rate: 0.0045942]
	Learning Rate: 0.00459421
	LOSS [training: 0.15594032695577134 | validation: 0.1363435480961219]
	TIME [epoch: 9.25 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14278431966395896		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.14278431966395896 | validation: 0.255306484658182]
	TIME [epoch: 9.24 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1945081448094724		[learning rate: 0.004572]
	Learning Rate: 0.00457199
	LOSS [training: 0.1945081448094724 | validation: 0.1611022035730993]
	TIME [epoch: 9.25 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19859416710286978		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.19859416710286978 | validation: 0.14621054152677695]
	TIME [epoch: 9.27 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1431099856540605		[learning rate: 0.0045499]
	Learning Rate: 0.00454988
	LOSS [training: 0.1431099856540605 | validation: 0.09620728200230855]
	TIME [epoch: 9.24 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14667530808795445		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.14667530808795445 | validation: 0.24300330940252518]
	TIME [epoch: 9.23 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2548159549163149		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.2548159549163149 | validation: 0.12765963805982877]
	TIME [epoch: 9.24 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16232698046985486		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.16232698046985486 | validation: 0.24673160821881734]
	TIME [epoch: 9.26 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5214944213600622		[learning rate: 0.004506]
	Learning Rate: 0.00450598
	LOSS [training: 0.5214944213600622 | validation: 0.7901912222984153]
	TIME [epoch: 9.24 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5460165669379456		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.5460165669379456 | validation: 0.7849167289184327]
	TIME [epoch: 9.24 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5402665940346606		[learning rate: 0.0044842]
	Learning Rate: 0.00448419
	LOSS [training: 0.5402665940346606 | validation: 0.4256687764474227]
	TIME [epoch: 9.24 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.296311337301674		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.296311337301674 | validation: 0.3690609323554519]
	TIME [epoch: 9.25 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2612578189361426		[learning rate: 0.0044625]
	Learning Rate: 0.00446251
	LOSS [training: 0.2612578189361426 | validation: 0.21438975218245726]
	TIME [epoch: 9.25 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2326110553392639		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.2326110553392639 | validation: 0.4707498606830284]
	TIME [epoch: 9.24 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3694087153754321		[learning rate: 0.0044409]
	Learning Rate: 0.00444093
	LOSS [training: 0.3694087153754321 | validation: 0.21689452820436217]
	TIME [epoch: 9.25 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3016069878528717		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.3016069878528717 | validation: 0.894579687371608]
	TIME [epoch: 9.26 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4675758432969356		[learning rate: 0.0044195]
	Learning Rate: 0.00441945
	LOSS [training: 0.4675758432969356 | validation: 0.6866922249818245]
	TIME [epoch: 9.26 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2850624133546804		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.2850624133546804 | validation: 0.1906458783334093]
	TIME [epoch: 9.24 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20436555012142596		[learning rate: 0.0043981]
	Learning Rate: 0.00439808
	LOSS [training: 0.20436555012142596 | validation: 0.1789566913744065]
	TIME [epoch: 9.24 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10381624587342256		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.10381624587342256 | validation: 0.1125128680276497]
	TIME [epoch: 9.24 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15698933062524223		[learning rate: 0.0043768]
	Learning Rate: 0.00437681
	LOSS [training: 0.15698933062524223 | validation: 0.1505388589654899]
	TIME [epoch: 9.26 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17201771773992153		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.17201771773992153 | validation: 0.27286315292713753]
	TIME [epoch: 9.24 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19166024820910055		[learning rate: 0.0043556]
	Learning Rate: 0.00435565
	LOSS [training: 0.19166024820910055 | validation: 0.0949605140817168]
	TIME [epoch: 9.24 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1136273067945777		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.1136273067945777 | validation: 0.11455441691963333]
	TIME [epoch: 9.24 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11376175586428668		[learning rate: 0.0043346]
	Learning Rate: 0.00433458
	LOSS [training: 0.11376175586428668 | validation: 0.11028105283109327]
	TIME [epoch: 9.26 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15902594649682586		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.15902594649682586 | validation: 0.1160567350302254]
	TIME [epoch: 9.25 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13954274038106243		[learning rate: 0.0043136]
	Learning Rate: 0.00431362
	LOSS [training: 0.13954274038106243 | validation: 0.16661521736839663]
	TIME [epoch: 9.24 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19353445109137865		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.19353445109137865 | validation: 0.2847328183622205]
	TIME [epoch: 9.25 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17000906670532875		[learning rate: 0.0042928]
	Learning Rate: 0.00429276
	LOSS [training: 0.17000906670532875 | validation: 0.14233236995918852]
	TIME [epoch: 9.27 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12967391279088777		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.12967391279088777 | validation: 0.14722748313617287]
	TIME [epoch: 9.25 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1492590592981222		[learning rate: 0.004272]
	Learning Rate: 0.004272
	LOSS [training: 0.1492590592981222 | validation: 0.16595771814238836]
	TIME [epoch: 9.23 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13697629514440898		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.13697629514440898 | validation: 0.16227385598468397]
	TIME [epoch: 9.23 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15218185261565692		[learning rate: 0.0042513]
	Learning Rate: 0.00425134
	LOSS [training: 0.15218185261565692 | validation: 0.137008393493155]
	TIME [epoch: 9.25 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12990149196132203		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.12990149196132203 | validation: 0.10503974992665485]
	TIME [epoch: 9.25 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16508747938310223		[learning rate: 0.0042308]
	Learning Rate: 0.00423079
	LOSS [training: 0.16508747938310223 | validation: 0.12552740697060633]
	TIME [epoch: 9.24 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13132064625472906		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.13132064625472906 | validation: 0.12940293066792624]
	TIME [epoch: 9.26 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14603581199094384		[learning rate: 0.0042103]
	Learning Rate: 0.00421033
	LOSS [training: 0.14603581199094384 | validation: 0.10557796620786912]
	TIME [epoch: 9.27 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13113375550751388		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.13113375550751388 | validation: 0.2204670914537089]
	TIME [epoch: 9.25 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14971343992555042		[learning rate: 0.00419]
	Learning Rate: 0.00418997
	LOSS [training: 0.14971343992555042 | validation: 0.21583155818165722]
	TIME [epoch: 9.25 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41743982393671225		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.41743982393671225 | validation: 0.1579762937210255]
	TIME [epoch: 9.24 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15633165391400566		[learning rate: 0.0041697]
	Learning Rate: 0.0041697
	LOSS [training: 0.15633165391400566 | validation: 0.17100520040906866]
	TIME [epoch: 9.27 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15157221194222595		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.15157221194222595 | validation: 0.12830093003052345]
	TIME [epoch: 9.26 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14173893438698842		[learning rate: 0.0041495]
	Learning Rate: 0.00414954
	LOSS [training: 0.14173893438698842 | validation: 0.13503970720753558]
	TIME [epoch: 9.25 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11614204869432365		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.11614204869432365 | validation: 0.1598103952420517]
	TIME [epoch: 9.25 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14021987742799302		[learning rate: 0.0041295]
	Learning Rate: 0.00412947
	LOSS [training: 0.14021987742799302 | validation: 0.15670440860063578]
	TIME [epoch: 9.26 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15013379514018035		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.15013379514018035 | validation: 0.13951741918331487]
	TIME [epoch: 9.25 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12683869494496947		[learning rate: 0.0041095]
	Learning Rate: 0.0041095
	LOSS [training: 0.12683869494496947 | validation: 0.16153219970979385]
	TIME [epoch: 9.26 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15107515133898924		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.15107515133898924 | validation: 0.13952059344141676]
	TIME [epoch: 9.25 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13718170805020266		[learning rate: 0.0040896]
	Learning Rate: 0.00408963
	LOSS [training: 0.13718170805020266 | validation: 0.10816275562897575]
	TIME [epoch: 9.27 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12733527599845712		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.12733527599845712 | validation: 0.16776215041936782]
	TIME [epoch: 9.25 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1493781153763189		[learning rate: 0.0040699]
	Learning Rate: 0.00406985
	LOSS [training: 0.1493781153763189 | validation: 0.16265599612875414]
	TIME [epoch: 9.24 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25816200722351024		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.25816200722351024 | validation: 0.508360578684005]
	TIME [epoch: 9.25 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2275165194919882		[learning rate: 0.0040502]
	Learning Rate: 0.00405017
	LOSS [training: 0.2275165194919882 | validation: 0.12724106589443376]
	TIME [epoch: 9.27 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1303870341495658		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.1303870341495658 | validation: 0.17321397674689173]
	TIME [epoch: 9.26 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10802732762232678		[learning rate: 0.0040306]
	Learning Rate: 0.00403059
	LOSS [training: 0.10802732762232678 | validation: 0.1203713884744608]
	TIME [epoch: 9.26 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11268030534975812		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.11268030534975812 | validation: 0.24048802108599954]
	TIME [epoch: 9.25 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16867445520663915		[learning rate: 0.0040111]
	Learning Rate: 0.0040111
	LOSS [training: 0.16867445520663915 | validation: 0.19827233618379542]
	TIME [epoch: 9.26 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1909194228766042		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.1909194228766042 | validation: 0.1636240101360132]
	TIME [epoch: 9.25 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1360202028250896		[learning rate: 0.0039917]
	Learning Rate: 0.0039917
	LOSS [training: 0.1360202028250896 | validation: 0.15716810314512805]
	TIME [epoch: 9.25 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18510508522588084		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.18510508522588084 | validation: 0.08320902215633846]
	TIME [epoch: 9.25 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07627271176716985		[learning rate: 0.0039724]
	Learning Rate: 0.0039724
	LOSS [training: 0.07627271176716985 | validation: 0.09627257503884154]
	TIME [epoch: 9.24 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10965379691197767		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.10965379691197767 | validation: 0.19744469726739244]
	TIME [epoch: 9.26 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33356514239954355		[learning rate: 0.0039532]
	Learning Rate: 0.00395319
	LOSS [training: 0.33356514239954355 | validation: 0.18768421846364236]
	TIME [epoch: 9.25 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13416369591253602		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.13416369591253602 | validation: 0.16651332228752153]
	TIME [epoch: 9.24 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24969552698019823		[learning rate: 0.0039341]
	Learning Rate: 0.00393407
	LOSS [training: 0.24969552698019823 | validation: 0.2268975432653679]
	TIME [epoch: 9.24 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14740105740091328		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.14740105740091328 | validation: 0.12585842551581988]
	TIME [epoch: 9.27 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11021830508017356		[learning rate: 0.003915]
	Learning Rate: 0.00391505
	LOSS [training: 0.11021830508017356 | validation: 0.21881079875492412]
	TIME [epoch: 9.24 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13208851002210587		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.13208851002210587 | validation: 0.13063560551043002]
	TIME [epoch: 9.25 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1340132418643517		[learning rate: 0.0038961]
	Learning Rate: 0.00389611
	LOSS [training: 0.1340132418643517 | validation: 0.13118886320130957]
	TIME [epoch: 9.25 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11554130013394762		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.11554130013394762 | validation: 0.11496526272927421]
	TIME [epoch: 9.26 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10559872355131791		[learning rate: 0.0038773]
	Learning Rate: 0.00387727
	LOSS [training: 0.10559872355131791 | validation: 0.1612126463832192]
	TIME [epoch: 9.25 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1422344759492858		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.1422344759492858 | validation: 0.14415657578030447]
	TIME [epoch: 9.24 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13314611771158075		[learning rate: 0.0038585]
	Learning Rate: 0.00385852
	LOSS [training: 0.13314611771158075 | validation: 0.22417259448179344]
	TIME [epoch: 9.24 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12646183143431938		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.12646183143431938 | validation: 0.10575565554815199]
	TIME [epoch: 9.26 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16987073029254152		[learning rate: 0.0038399]
	Learning Rate: 0.00383986
	LOSS [training: 0.16987073029254152 | validation: 0.2698004100367476]
	TIME [epoch: 9.25 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14766014222818039		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.14766014222818039 | validation: 0.13966674371618587]
	TIME [epoch: 9.24 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13488883887992956		[learning rate: 0.0038213]
	Learning Rate: 0.00382129
	LOSS [training: 0.13488883887992956 | validation: 0.09372839320042423]
	TIME [epoch: 9.24 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10781230504502297		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.10781230504502297 | validation: 0.15629289494348664]
	TIME [epoch: 9.27 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1474791790644041		[learning rate: 0.0038028]
	Learning Rate: 0.00380282
	LOSS [training: 0.1474791790644041 | validation: 0.23205062448019825]
	TIME [epoch: 9.25 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16036273248387212		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.16036273248387212 | validation: 0.09308357911519086]
	TIME [epoch: 9.25 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10165247873123957		[learning rate: 0.0037844]
	Learning Rate: 0.00378443
	LOSS [training: 0.10165247873123957 | validation: 0.09585738157901014]
	TIME [epoch: 9.24 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10015385793927685		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.10015385793927685 | validation: 0.21019445121310293]
	TIME [epoch: 9.26 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33858274962576085		[learning rate: 0.0037661]
	Learning Rate: 0.00376613
	LOSS [training: 0.33858274962576085 | validation: 1.4254587841894537]
	TIME [epoch: 9.24 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44029351100696024		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.44029351100696024 | validation: 0.1160580836917103]
	TIME [epoch: 9.24 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1364252198804564		[learning rate: 0.0037479]
	Learning Rate: 0.00374791
	LOSS [training: 0.1364252198804564 | validation: 0.28609902016798894]
	TIME [epoch: 9.23 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14380300471503513		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.14380300471503513 | validation: 0.43659517466030096]
	TIME [epoch: 9.27 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4029822285960254		[learning rate: 0.0037298]
	Learning Rate: 0.00372979
	LOSS [training: 0.4029822285960254 | validation: 0.526679976185249]
	TIME [epoch: 9.25 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44050232916406645		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.44050232916406645 | validation: 0.4504847557905826]
	TIME [epoch: 9.24 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38780313018475		[learning rate: 0.0037118]
	Learning Rate: 0.00371175
	LOSS [training: 0.38780313018475 | validation: 0.5102574401036526]
	TIME [epoch: 9.24 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3843473786443311		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.3843473786443311 | validation: 0.7095689859932637]
	TIME [epoch: 9.26 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4740274621521154		[learning rate: 0.0036938]
	Learning Rate: 0.0036938
	LOSS [training: 0.4740274621521154 | validation: 0.21926776058399056]
	TIME [epoch: 9.25 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18297004269495978		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.18297004269495978 | validation: 0.17607720082554612]
	TIME [epoch: 9.25 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13170597703302556		[learning rate: 0.0036759]
	Learning Rate: 0.00367594
	LOSS [training: 0.13170597703302556 | validation: 0.1985394864051393]
	TIME [epoch: 9.24 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21331930991396422		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.21331930991396422 | validation: 0.0917246349468327]
	TIME [epoch: 9.28 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12756250235164002		[learning rate: 0.0036582]
	Learning Rate: 0.00365816
	LOSS [training: 0.12756250235164002 | validation: 0.26441048715286586]
	TIME [epoch: 9.24 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1284434436931635		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.1284434436931635 | validation: 0.11254172753434807]
	TIME [epoch: 9.25 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.154906127245642		[learning rate: 0.0036405]
	Learning Rate: 0.00364047
	LOSS [training: 0.154906127245642 | validation: 0.23902189221608683]
	TIME [epoch: 9.24 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2704207821036511		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.2704207821036511 | validation: 0.1917587328669807]
	TIME [epoch: 9.26 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12077805930119503		[learning rate: 0.0036229]
	Learning Rate: 0.00362287
	LOSS [training: 0.12077805930119503 | validation: 0.09932547213540224]
	TIME [epoch: 9.25 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08192786784197398		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.08192786784197398 | validation: 0.10092695254490419]
	TIME [epoch: 9.25 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08872404738086388		[learning rate: 0.0036053]
	Learning Rate: 0.00360535
	LOSS [training: 0.08872404738086388 | validation: 0.14987029947379873]
	TIME [epoch: 9.24 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13711607210418478		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.13711607210418478 | validation: 0.0799887224379563]
	TIME [epoch: 9.26 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0689614276222328		[learning rate: 0.0035879]
	Learning Rate: 0.00358791
	LOSS [training: 0.0689614276222328 | validation: 0.1300518182769051]
	TIME [epoch: 9.26 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09650210230700398		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.09650210230700398 | validation: 0.13578898056156724]
	TIME [epoch: 9.24 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18599592411723934		[learning rate: 0.0035706]
	Learning Rate: 0.00357056
	LOSS [training: 0.18599592411723934 | validation: 0.07507642080517893]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_525.pth
	Model improved!!!
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07972774362526222		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.07972774362526222 | validation: 0.0747065585493186]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_526.pth
	Model improved!!!
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06668941323747606		[learning rate: 0.0035533]
	Learning Rate: 0.0035533
	LOSS [training: 0.06668941323747606 | validation: 0.08134996727194227]
	TIME [epoch: 9.28 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06176619909121979		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.06176619909121979 | validation: 0.3137609233809213]
	TIME [epoch: 9.25 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15892324792057844		[learning rate: 0.0035361]
	Learning Rate: 0.00353611
	LOSS [training: 0.15892324792057844 | validation: 0.17856518063422025]
	TIME [epoch: 9.25 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13579441597378145		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.13579441597378145 | validation: 0.25309844909391566]
	TIME [epoch: 9.25 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11427307422948538		[learning rate: 0.003519]
	Learning Rate: 0.00351901
	LOSS [training: 0.11427307422948538 | validation: 0.1429078662848085]
	TIME [epoch: 9.27 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13194533549714987		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.13194533549714987 | validation: 0.12290501702036785]
	TIME [epoch: 9.25 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08865011390268726		[learning rate: 0.003502]
	Learning Rate: 0.003502
	LOSS [training: 0.08865011390268726 | validation: 0.10202847622558744]
	TIME [epoch: 9.26 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.149854796471738		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.149854796471738 | validation: 0.7507464494034406]
	TIME [epoch: 9.24 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37029912577363866		[learning rate: 0.0034851]
	Learning Rate: 0.00348506
	LOSS [training: 0.37029912577363866 | validation: 0.48352428968248384]
	TIME [epoch: 9.27 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35812666851971164		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.35812666851971164 | validation: 0.21421628341103993]
	TIME [epoch: 9.24 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19552710900498865		[learning rate: 0.0034682]
	Learning Rate: 0.00346821
	LOSS [training: 0.19552710900498865 | validation: 0.1301626031811295]
	TIME [epoch: 9.23 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11539839950117026		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.11539839950117026 | validation: 0.21825184949341178]
	TIME [epoch: 9.24 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0974620818304658		[learning rate: 0.0034514]
	Learning Rate: 0.00345144
	LOSS [training: 0.0974620818304658 | validation: 0.11200552395257843]
	TIME [epoch: 9.26 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09146817977101143		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.09146817977101143 | validation: 0.0975402859038365]
	TIME [epoch: 9.25 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07969191462505229		[learning rate: 0.0034347]
	Learning Rate: 0.00343475
	LOSS [training: 0.07969191462505229 | validation: 0.08302756608006151]
	TIME [epoch: 9.25 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12052025614934239		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.12052025614934239 | validation: 0.1383751275157765]
	TIME [epoch: 9.24 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.149279879806353		[learning rate: 0.0034181]
	Learning Rate: 0.00341814
	LOSS [training: 0.149279879806353 | validation: 0.2220543385294673]
	TIME [epoch: 9.26 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17497311816184888		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.17497311816184888 | validation: 0.251351125313985]
	TIME [epoch: 9.24 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16998886482289707		[learning rate: 0.0034016]
	Learning Rate: 0.00340161
	LOSS [training: 0.16998886482289707 | validation: 0.37852606178162235]
	TIME [epoch: 9.24 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20157709469452584		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.20157709469452584 | validation: 0.2026527338790468]
	TIME [epoch: 9.24 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1781957308619751		[learning rate: 0.0033852]
	Learning Rate: 0.00338516
	LOSS [training: 0.1781957308619751 | validation: 0.4946359167728078]
	TIME [epoch: 9.25 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3371557044083422		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.3371557044083422 | validation: 0.159695803334075]
	TIME [epoch: 9.25 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19766575953555232		[learning rate: 0.0033688]
	Learning Rate: 0.00336879
	LOSS [training: 0.19766575953555232 | validation: 0.24974455992279143]
	TIME [epoch: 9.23 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11711659172322664		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.11711659172322664 | validation: 0.05472388484027724]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_550.pth
	Model improved!!!
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07022292190597013		[learning rate: 0.0033525]
	Learning Rate: 0.0033525
	LOSS [training: 0.07022292190597013 | validation: 0.07869674332090752]
	TIME [epoch: 9.28 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07701280608578386		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.07701280608578386 | validation: 0.15488262347141996]
	TIME [epoch: 9.24 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1249908229440547		[learning rate: 0.0033363]
	Learning Rate: 0.00333629
	LOSS [training: 0.1249908229440547 | validation: 0.19969398406555458]
	TIME [epoch: 9.25 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10358680843540732		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.10358680843540732 | validation: 0.09156906726161698]
	TIME [epoch: 9.24 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09159441471021881		[learning rate: 0.0033202]
	Learning Rate: 0.00332015
	LOSS [training: 0.09159441471021881 | validation: 0.09973320280064718]
	TIME [epoch: 9.26 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1063803889477524		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.1063803889477524 | validation: 0.14483467595669636]
	TIME [epoch: 9.25 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07374039693424483		[learning rate: 0.0033041]
	Learning Rate: 0.0033041
	LOSS [training: 0.07374039693424483 | validation: 0.04429081540129782]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_557.pth
	Model improved!!!
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3249329939354058		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.3249329939354058 | validation: 1.0617686615264788]
	TIME [epoch: 9.24 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7849175968920671		[learning rate: 0.0032881]
	Learning Rate: 0.00328812
	LOSS [training: 0.7849175968920671 | validation: 0.3718882769819349]
	TIME [epoch: 9.26 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23858950529758274		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.23858950529758274 | validation: 0.2022516498529499]
	TIME [epoch: 9.25 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15975546625798676		[learning rate: 0.0032722]
	Learning Rate: 0.00327222
	LOSS [training: 0.15975546625798676 | validation: 0.11331995359277684]
	TIME [epoch: 9.25 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3712491754900585		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.3712491754900585 | validation: 0.17753793424366376]
	TIME [epoch: 9.25 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17551290834241415		[learning rate: 0.0032564]
	Learning Rate: 0.00325639
	LOSS [training: 0.17551290834241415 | validation: 0.2616856226243229]
	TIME [epoch: 9.26 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12336268709394457		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.12336268709394457 | validation: 0.2087159772264341]
	TIME [epoch: 9.25 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2544066772687189		[learning rate: 0.0032406]
	Learning Rate: 0.00324065
	LOSS [training: 0.2544066772687189 | validation: 0.18661798463710522]
	TIME [epoch: 9.24 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13050292702228478		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.13050292702228478 | validation: 0.04918614928929632]
	TIME [epoch: 9.25 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05387618032565574		[learning rate: 0.003225]
	Learning Rate: 0.00322497
	LOSS [training: 0.05387618032565574 | validation: 0.13180246586412125]
	TIME [epoch: 9.26 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06515528680875936		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.06515528680875936 | validation: 0.1393305559196466]
	TIME [epoch: 9.25 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10187041969927506		[learning rate: 0.0032094]
	Learning Rate: 0.00320938
	LOSS [training: 0.10187041969927506 | validation: 0.07787338120714049]
	TIME [epoch: 9.25 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08180627877418725		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.08180627877418725 | validation: 0.14877526251664097]
	TIME [epoch: 9.24 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09293133687894052		[learning rate: 0.0031939]
	Learning Rate: 0.00319386
	LOSS [training: 0.09293133687894052 | validation: 0.22873804523783112]
	TIME [epoch: 9.27 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10537197034535065		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.10537197034535065 | validation: 0.1184644657653432]
	TIME [epoch: 9.26 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07183478391574799		[learning rate: 0.0031784]
	Learning Rate: 0.00317841
	LOSS [training: 0.07183478391574799 | validation: 0.09329950324824574]
	TIME [epoch: 9.24 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07587621147837911		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.07587621147837911 | validation: 0.05471136213197021]
	TIME [epoch: 9.25 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1138753780023789		[learning rate: 0.003163]
	Learning Rate: 0.00316304
	LOSS [training: 0.1138753780023789 | validation: 0.18973698479589624]
	TIME [epoch: 9.27 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12457219509489614		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.12457219509489614 | validation: 0.14596949797363537]
	TIME [epoch: 9.25 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1438901003942319		[learning rate: 0.0031477]
	Learning Rate: 0.00314775
	LOSS [training: 0.1438901003942319 | validation: 0.07868755809009154]
	TIME [epoch: 9.25 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10438905822319378		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.10438905822319378 | validation: 0.1434812949964313]
	TIME [epoch: 9.25 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08509312113597406		[learning rate: 0.0031325]
	Learning Rate: 0.00313253
	LOSS [training: 0.08509312113597406 | validation: 0.07267167852479507]
	TIME [epoch: 9.25 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058992547719122615		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.058992547719122615 | validation: 0.10558092996093445]
	TIME [epoch: 9.27 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06407772023748973		[learning rate: 0.0031174]
	Learning Rate: 0.00311738
	LOSS [training: 0.06407772023748973 | validation: 0.08737274538179987]
	TIME [epoch: 9.24 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08837754308744233		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.08837754308744233 | validation: 0.07369823472911236]
	TIME [epoch: 9.24 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06414906397904169		[learning rate: 0.0031023]
	Learning Rate: 0.0031023
	LOSS [training: 0.06414906397904169 | validation: 0.05264226674009452]
	TIME [epoch: 9.24 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04317431073982501		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.04317431073982501 | validation: 0.03657032033935457]
	TIME [epoch: 9.27 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_584.pth
	Model improved!!!
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06696565067138309		[learning rate: 0.0030873]
	Learning Rate: 0.0030873
	LOSS [training: 0.06696565067138309 | validation: 0.10926563472543843]
	TIME [epoch: 9.25 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13237723397985496		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.13237723397985496 | validation: 0.09258965481194664]
	TIME [epoch: 9.24 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08865560037663081		[learning rate: 0.0030724]
	Learning Rate: 0.00307237
	LOSS [training: 0.08865560037663081 | validation: 0.09043807888762351]
	TIME [epoch: 9.25 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07825429158001805		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.07825429158001805 | validation: 0.0858168969442318]
	TIME [epoch: 9.27 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06535051099298242		[learning rate: 0.0030575]
	Learning Rate: 0.00305751
	LOSS [training: 0.06535051099298242 | validation: 0.06679413637403195]
	TIME [epoch: 9.24 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06869495716147042		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.06869495716147042 | validation: 0.08215756313121347]
	TIME [epoch: 9.25 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042756230090400006		[learning rate: 0.0030427]
	Learning Rate: 0.00304273
	LOSS [training: 0.042756230090400006 | validation: 0.15272655839631985]
	TIME [epoch: 9.25 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08523287821008033		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.08523287821008033 | validation: 0.05164671234813245]
	TIME [epoch: 9.27 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05201727307488655		[learning rate: 0.003028]
	Learning Rate: 0.00302801
	LOSS [training: 0.05201727307488655 | validation: 0.0984453658391079]
	TIME [epoch: 9.25 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08062505762104559		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.08062505762104559 | validation: 0.19849137667262118]
	TIME [epoch: 9.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1306292677321254		[learning rate: 0.0030134]
	Learning Rate: 0.00301337
	LOSS [training: 0.1306292677321254 | validation: 0.1034547869673372]
	TIME [epoch: 9.25 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09816388332601737		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.09816388332601737 | validation: 0.08653186044604222]
	TIME [epoch: 9.27 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10935412278494956		[learning rate: 0.0029988]
	Learning Rate: 0.0029988
	LOSS [training: 0.10935412278494956 | validation: 0.12145630487444906]
	TIME [epoch: 9.25 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13131290789678343		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.13131290789678343 | validation: 0.052794102605581594]
	TIME [epoch: 9.26 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09834826967519365		[learning rate: 0.0029843]
	Learning Rate: 0.0029843
	LOSS [training: 0.09834826967519365 | validation: 0.23082472619771333]
	TIME [epoch: 9.25 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.150146023225045		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.150146023225045 | validation: 0.09957336208171208]
	TIME [epoch: 9.27 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08971327584013056		[learning rate: 0.0029699]
	Learning Rate: 0.00296987
	LOSS [training: 0.08971327584013056 | validation: 0.06853807443717204]
	TIME [epoch: 9.25 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09505033796323079		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.09505033796323079 | validation: 0.07739889634765301]
	TIME [epoch: 9.25 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07194063852039867		[learning rate: 0.0029555]
	Learning Rate: 0.0029555
	LOSS [training: 0.07194063852039867 | validation: 0.10133871042570794]
	TIME [epoch: 9.25 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07591547429969563		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.07591547429969563 | validation: 0.05116735064823322]
	TIME [epoch: 9.27 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05647288013557465		[learning rate: 0.0029412]
	Learning Rate: 0.00294121
	LOSS [training: 0.05647288013557465 | validation: 0.07079035565433286]
	TIME [epoch: 9.26 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1668956438561176		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.1668956438561176 | validation: 0.21333956983996422]
	TIME [epoch: 9.25 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07247846217663559		[learning rate: 0.002927]
	Learning Rate: 0.00292699
	LOSS [training: 0.07247846217663559 | validation: 0.04921302900776331]
	TIME [epoch: 9.25 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18945886251175859		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.18945886251175859 | validation: 0.17688509423799553]
	TIME [epoch: 9.27 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08966211548483033		[learning rate: 0.0029128]
	Learning Rate: 0.00291283
	LOSS [training: 0.08966211548483033 | validation: 0.09703755317977078]
	TIME [epoch: 9.25 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07261339202920222		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.07261339202920222 | validation: 0.10434313701284331]
	TIME [epoch: 9.25 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09405025380862567		[learning rate: 0.0028987]
	Learning Rate: 0.00289875
	LOSS [training: 0.09405025380862567 | validation: 0.08725514573591844]
	TIME [epoch: 9.25 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10427968244080565		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.10427968244080565 | validation: 0.23150396563463072]
	TIME [epoch: 9.26 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13889198249009177		[learning rate: 0.0028847]
	Learning Rate: 0.00288473
	LOSS [training: 0.13889198249009177 | validation: 0.12616660247859698]
	TIME [epoch: 9.25 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0811164378555307		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.0811164378555307 | validation: 0.1158365099819168]
	TIME [epoch: 9.25 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09648711737180324		[learning rate: 0.0028708]
	Learning Rate: 0.00287078
	LOSS [training: 0.09648711737180324 | validation: 0.23009701939662935]
	TIME [epoch: 9.24 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21227348732913764		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.21227348732913764 | validation: 0.3354886514857645]
	TIME [epoch: 9.27 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3197707280902644		[learning rate: 0.0028569]
	Learning Rate: 0.0028569
	LOSS [training: 0.3197707280902644 | validation: 0.2637138737196404]
	TIME [epoch: 9.25 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23401644605420707		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.23401644605420707 | validation: 0.31988707351506585]
	TIME [epoch: 9.25 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15945050740053565		[learning rate: 0.0028431]
	Learning Rate: 0.00284308
	LOSS [training: 0.15945050740053565 | validation: 0.14816670678082097]
	TIME [epoch: 9.24 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12383127525185397		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.12383127525185397 | validation: 0.12023294144102567]
	TIME [epoch: 9.26 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07227023856179686		[learning rate: 0.0028293]
	Learning Rate: 0.00282933
	LOSS [training: 0.07227023856179686 | validation: 0.06644999359428036]
	TIME [epoch: 9.25 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06632632065323282		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.06632632065323282 | validation: 0.06230047250830014]
	TIME [epoch: 9.25 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05463608213622565		[learning rate: 0.0028157]
	Learning Rate: 0.00281565
	LOSS [training: 0.05463608213622565 | validation: 0.050860735331634294]
	TIME [epoch: 9.24 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04208655831479508		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.04208655831479508 | validation: 0.08828590970614547]
	TIME [epoch: 9.26 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0723123483925229		[learning rate: 0.002802]
	Learning Rate: 0.00280204
	LOSS [training: 0.0723123483925229 | validation: 0.14218677232504318]
	TIME [epoch: 9.26 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10206798092857439		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.10206798092857439 | validation: 0.06311839006217305]
	TIME [epoch: 9.24 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06270200540381797		[learning rate: 0.0027885]
	Learning Rate: 0.00278849
	LOSS [training: 0.06270200540381797 | validation: 0.10544501804394338]
	TIME [epoch: 9.24 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06831478353698173		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.06831478353698173 | validation: 0.08583629800304579]
	TIME [epoch: 9.24 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13438858007040175		[learning rate: 0.002775]
	Learning Rate: 0.002775
	LOSS [training: 0.13438858007040175 | validation: 0.4443660720087401]
	TIME [epoch: 9.28 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23199596329446304		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.23199596329446304 | validation: 0.2351909597398508]
	TIME [epoch: 9.25 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1403606207271944		[learning rate: 0.0027616]
	Learning Rate: 0.00276158
	LOSS [training: 0.1403606207271944 | validation: 0.1199221584023068]
	TIME [epoch: 9.25 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10404456448490555		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.10404456448490555 | validation: 0.08624484503974073]
	TIME [epoch: 9.25 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0870300742027895		[learning rate: 0.0027482]
	Learning Rate: 0.00274823
	LOSS [training: 0.0870300742027895 | validation: 0.09888378458228]
	TIME [epoch: 9.27 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05802343838493401		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.05802343838493401 | validation: 0.060670247878004485]
	TIME [epoch: 9.25 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042322492802516744		[learning rate: 0.0027349]
	Learning Rate: 0.00273494
	LOSS [training: 0.042322492802516744 | validation: 0.0603119064881327]
	TIME [epoch: 9.25 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04064515319373908		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.04064515319373908 | validation: 0.08781143182699255]
	TIME [epoch: 9.24 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07115338944528607		[learning rate: 0.0027217]
	Learning Rate: 0.00272171
	LOSS [training: 0.07115338944528607 | validation: 0.054480396284873195]
	TIME [epoch: 9.27 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06862922847450131		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.06862922847450131 | validation: 0.11294792938815494]
	TIME [epoch: 9.25 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10239157871880675		[learning rate: 0.0027086]
	Learning Rate: 0.00270855
	LOSS [training: 0.10239157871880675 | validation: 0.0910883279228187]
	TIME [epoch: 9.24 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07494150906555465		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.07494150906555465 | validation: 0.05810820666985084]
	TIME [epoch: 9.25 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05402855078978962		[learning rate: 0.0026955]
	Learning Rate: 0.00269545
	LOSS [training: 0.05402855078978962 | validation: 0.07784608790522116]
	TIME [epoch: 9.27 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07438961594273541		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.07438961594273541 | validation: 0.1593994578631015]
	TIME [epoch: 9.26 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05498731731251845		[learning rate: 0.0026824]
	Learning Rate: 0.00268242
	LOSS [training: 0.05498731731251845 | validation: 0.07424167812896501]
	TIME [epoch: 9.25 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06607161544201265		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.06607161544201265 | validation: 0.08487361686959821]
	TIME [epoch: 9.25 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07269154527233154		[learning rate: 0.0026694]
	Learning Rate: 0.00266945
	LOSS [training: 0.07269154527233154 | validation: 0.08131055844371951]
	TIME [epoch: 9.27 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05772605728325445		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.05772605728325445 | validation: 0.05738848610138328]
	TIME [epoch: 9.25 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05653421853735156		[learning rate: 0.0026565]
	Learning Rate: 0.00265654
	LOSS [training: 0.05653421853735156 | validation: 0.08778328235598698]
	TIME [epoch: 9.25 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14101694416243132		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.14101694416243132 | validation: 0.1450691060846328]
	TIME [epoch: 9.25 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10409758006686923		[learning rate: 0.0026437]
	Learning Rate: 0.00264369
	LOSS [training: 0.10409758006686923 | validation: 0.15943348929597403]
	TIME [epoch: 9.27 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09537280153236684		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.09537280153236684 | validation: 0.08191926207942446]
	TIME [epoch: 9.25 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09349319418108146		[learning rate: 0.0026309]
	Learning Rate: 0.00263091
	LOSS [training: 0.09349319418108146 | validation: 0.12111818852055144]
	TIME [epoch: 9.25 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.092110414751538		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.092110414751538 | validation: 0.08051997005747466]
	TIME [epoch: 9.24 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06767887269587178		[learning rate: 0.0026182]
	Learning Rate: 0.00261818
	LOSS [training: 0.06767887269587178 | validation: 0.09315661399621145]
	TIME [epoch: 9.27 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10225720536374397		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.10225720536374397 | validation: 0.1133317677837089]
	TIME [epoch: 9.25 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08907422809859418		[learning rate: 0.0026055]
	Learning Rate: 0.00260552
	LOSS [training: 0.08907422809859418 | validation: 0.09583625418963365]
	TIME [epoch: 9.26 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08637293018499416		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.08637293018499416 | validation: 0.10427914582117892]
	TIME [epoch: 9.25 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06459668001709098		[learning rate: 0.0025929]
	Learning Rate: 0.00259292
	LOSS [training: 0.06459668001709098 | validation: 0.09049931781412825]
	TIME [epoch: 9.27 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061491989130110655		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.061491989130110655 | validation: 0.046467967867065946]
	TIME [epoch: 9.26 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09097190115500811		[learning rate: 0.0025804]
	Learning Rate: 0.00258038
	LOSS [training: 0.09097190115500811 | validation: 0.13499163357581967]
	TIME [epoch: 9.25 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0867166998782961		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.0867166998782961 | validation: 0.07101012907517498]
	TIME [epoch: 9.25 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07606597514979357		[learning rate: 0.0025679]
	Learning Rate: 0.0025679
	LOSS [training: 0.07606597514979357 | validation: 0.08681122648146944]
	TIME [epoch: 9.28 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044619205353155306		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.044619205353155306 | validation: 0.04479189267383952]
	TIME [epoch: 9.26 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05617997302408077		[learning rate: 0.0025555]
	Learning Rate: 0.00255549
	LOSS [training: 0.05617997302408077 | validation: 0.06970735936205705]
	TIME [epoch: 9.25 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07176289093305965		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.07176289093305965 | validation: 0.07631382519945343]
	TIME [epoch: 9.25 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07005399867623233		[learning rate: 0.0025431]
	Learning Rate: 0.00254313
	LOSS [training: 0.07005399867623233 | validation: 0.1039729650493362]
	TIME [epoch: 9.26 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0978990472423873		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.0978990472423873 | validation: 0.12937002690945465]
	TIME [epoch: 9.25 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12513552912529982		[learning rate: 0.0025308]
	Learning Rate: 0.00253083
	LOSS [training: 0.12513552912529982 | validation: 0.17337032522740664]
	TIME [epoch: 9.24 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11478080436063005		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.11478080436063005 | validation: 0.11858816078048273]
	TIME [epoch: 9.25 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07450597050307273		[learning rate: 0.0025186]
	Learning Rate: 0.00251859
	LOSS [training: 0.07450597050307273 | validation: 0.09767285142384907]
	TIME [epoch: 9.26 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07404298750677564		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.07404298750677564 | validation: 0.0674357917947444]
	TIME [epoch: 9.26 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07125444674066614		[learning rate: 0.0025064]
	Learning Rate: 0.00250641
	LOSS [training: 0.07125444674066614 | validation: 0.09431350665309676]
	TIME [epoch: 9.25 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08430502545755805		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.08430502545755805 | validation: 0.1884423306286325]
	TIME [epoch: 9.25 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10059030675327489		[learning rate: 0.0024943]
	Learning Rate: 0.00249429
	LOSS [training: 0.10059030675327489 | validation: 0.13961202273618087]
	TIME [epoch: 9.25 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08866397605706738		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.08866397605706738 | validation: 0.13990866107959204]
	TIME [epoch: 9.28 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0982321996629121		[learning rate: 0.0024822]
	Learning Rate: 0.00248223
	LOSS [training: 0.0982321996629121 | validation: 0.09428361245121004]
	TIME [epoch: 9.25 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0626493070135289		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.0626493070135289 | validation: 0.10028700653110664]
	TIME [epoch: 9.26 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0922998972733681		[learning rate: 0.0024702]
	Learning Rate: 0.00247023
	LOSS [training: 0.0922998972733681 | validation: 0.0782864663359832]
	TIME [epoch: 9.25 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05905607497922584		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.05905607497922584 | validation: 0.06631090300733342]
	TIME [epoch: 9.27 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06905937287836178		[learning rate: 0.0024583]
	Learning Rate: 0.00245828
	LOSS [training: 0.06905937287836178 | validation: 0.07952035959232859]
	TIME [epoch: 9.26 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0869300144205997		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.0869300144205997 | validation: 0.07519989229708995]
	TIME [epoch: 9.26 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07559144242511413		[learning rate: 0.0024464]
	Learning Rate: 0.00244639
	LOSS [training: 0.07559144242511413 | validation: 0.07220712656211525]
	TIME [epoch: 9.25 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06345354228027258		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.06345354228027258 | validation: 0.06780283681230272]
	TIME [epoch: 9.28 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056044898748838265		[learning rate: 0.0024346]
	Learning Rate: 0.00243456
	LOSS [training: 0.056044898748838265 | validation: 0.05757470019677166]
	TIME [epoch: 9.25 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0795161888494226		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.0795161888494226 | validation: 0.07780925099377253]
	TIME [epoch: 9.25 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08240389170996568		[learning rate: 0.0024228]
	Learning Rate: 0.00242279
	LOSS [training: 0.08240389170996568 | validation: 0.1992818358790589]
	TIME [epoch: 9.25 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11791221413699278		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.11791221413699278 | validation: 0.06334216280683429]
	TIME [epoch: 9.27 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05517794818567717		[learning rate: 0.0024111]
	Learning Rate: 0.00241107
	LOSS [training: 0.05517794818567717 | validation: 0.05493681746707871]
	TIME [epoch: 9.25 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07821925135460196		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.07821925135460196 | validation: 0.14614172857696214]
	TIME [epoch: 9.25 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10554004893948168		[learning rate: 0.0023994]
	Learning Rate: 0.00239941
	LOSS [training: 0.10554004893948168 | validation: 0.1133436569721692]
	TIME [epoch: 9.26 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12091347430562016		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.12091347430562016 | validation: 0.2586296440394497]
	TIME [epoch: 9.27 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19609111123250364		[learning rate: 0.0023878]
	Learning Rate: 0.00238781
	LOSS [training: 0.19609111123250364 | validation: 0.31524638652499204]
	TIME [epoch: 9.25 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14446183846691515		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.14446183846691515 | validation: 0.1234479630465956]
	TIME [epoch: 9.25 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.087267922032052		[learning rate: 0.0023763]
	Learning Rate: 0.00237626
	LOSS [training: 0.087267922032052 | validation: 0.12342588209762512]
	TIME [epoch: 9.26 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09946832072368285		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.09946832072368285 | validation: 0.1285859684521171]
	TIME [epoch: 9.28 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11126545964726638		[learning rate: 0.0023648]
	Learning Rate: 0.00236477
	LOSS [training: 0.11126545964726638 | validation: 0.053181423443951714]
	TIME [epoch: 9.26 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07143347101976047		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.07143347101976047 | validation: 0.08734121446311144]
	TIME [epoch: 9.25 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05779680828700682		[learning rate: 0.0023533]
	Learning Rate: 0.00235334
	LOSS [training: 0.05779680828700682 | validation: 0.08392778593109809]
	TIME [epoch: 9.25 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08081432900336007		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.08081432900336007 | validation: 0.07894335804262606]
	TIME [epoch: 9.27 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07248992839844942		[learning rate: 0.002342]
	Learning Rate: 0.00234196
	LOSS [training: 0.07248992839844942 | validation: 0.08399619505457151]
	TIME [epoch: 9.25 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08208567921072893		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.08208567921072893 | validation: 0.08304501558981356]
	TIME [epoch: 9.26 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09324535282801652		[learning rate: 0.0023306]
	Learning Rate: 0.00233063
	LOSS [training: 0.09324535282801652 | validation: 0.08331793942666897]
	TIME [epoch: 9.26 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12146514869345967		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.12146514869345967 | validation: 0.09250248256874355]
	TIME [epoch: 9.27 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09757800696320822		[learning rate: 0.0023194]
	Learning Rate: 0.00231936
	LOSS [training: 0.09757800696320822 | validation: 0.1382395296447835]
	TIME [epoch: 9.25 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1109868966110582		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.1109868966110582 | validation: 0.10833279612174632]
	TIME [epoch: 9.25 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10174280903304758		[learning rate: 0.0023081]
	Learning Rate: 0.00230815
	LOSS [training: 0.10174280903304758 | validation: 0.13271694105624388]
	TIME [epoch: 9.26 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11343853013329137		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.11343853013329137 | validation: 0.1294054231273523]
	TIME [epoch: 9.27 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10800016381610471		[learning rate: 0.002297]
	Learning Rate: 0.00229698
	LOSS [training: 0.10800016381610471 | validation: 0.09680981778040451]
	TIME [epoch: 9.27 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11627877352776714		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.11627877352776714 | validation: 0.3142459103475433]
	TIME [epoch: 9.26 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1504661817333804		[learning rate: 0.0022859]
	Learning Rate: 0.00228588
	LOSS [training: 0.1504661817333804 | validation: 0.09103186164330612]
	TIME [epoch: 9.26 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10224025296960593		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.10224025296960593 | validation: 0.14027919333177816]
	TIME [epoch: 9.27 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10991995433508228		[learning rate: 0.0022748]
	Learning Rate: 0.00227482
	LOSS [training: 0.10991995433508228 | validation: 0.13329392324767078]
	TIME [epoch: 9.26 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09827637264601854		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.09827637264601854 | validation: 0.11673889396543233]
	TIME [epoch: 9.26 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0953953678052267		[learning rate: 0.0022638]
	Learning Rate: 0.00226382
	LOSS [training: 0.0953953678052267 | validation: 0.1838114882537881]
	TIME [epoch: 9.26 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1301628287730109		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.1301628287730109 | validation: 0.13693189838964226]
	TIME [epoch: 9.28 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11944684775216467		[learning rate: 0.0022529]
	Learning Rate: 0.00225287
	LOSS [training: 0.11944684775216467 | validation: 0.15482806181414527]
	TIME [epoch: 9.26 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08013525809057603		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.08013525809057603 | validation: 0.07935297424140772]
	TIME [epoch: 9.25 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08306233255009729		[learning rate: 0.002242]
	Learning Rate: 0.00224198
	LOSS [training: 0.08306233255009729 | validation: 0.10233037300772718]
	TIME [epoch: 9.25 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08418090114675555		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.08418090114675555 | validation: 0.08417919430643853]
	TIME [epoch: 9.26 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07519371838322705		[learning rate: 0.0022311]
	Learning Rate: 0.00223114
	LOSS [training: 0.07519371838322705 | validation: 0.08427398542112818]
	TIME [epoch: 9.27 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08353767123235353		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.08353767123235353 | validation: 0.09700485333440055]
	TIME [epoch: 9.26 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06407479879533103		[learning rate: 0.0022203]
	Learning Rate: 0.00222035
	LOSS [training: 0.06407479879533103 | validation: 0.08487578872790702]
	TIME [epoch: 9.27 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10751160758595127		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.10751160758595127 | validation: 0.11089315526358791]
	TIME [epoch: 9.26 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09425072890126221		[learning rate: 0.0022096]
	Learning Rate: 0.00220961
	LOSS [training: 0.09425072890126221 | validation: 0.07368481687090297]
	TIME [epoch: 9.28 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061811258268609226		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.061811258268609226 | validation: 0.09610207617317665]
	TIME [epoch: 9.26 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0878026407286389		[learning rate: 0.0021989]
	Learning Rate: 0.00219893
	LOSS [training: 0.0878026407286389 | validation: 0.08453399921638916]
	TIME [epoch: 9.26 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07050362606457607		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.07050362606457607 | validation: 0.07081955922288699]
	TIME [epoch: 9.26 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060828134410749135		[learning rate: 0.0021883]
	Learning Rate: 0.00218829
	LOSS [training: 0.060828134410749135 | validation: 0.05929360114696096]
	TIME [epoch: 9.28 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05290063369703296		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.05290063369703296 | validation: 0.08631695190385631]
	TIME [epoch: 9.26 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08232264271047848		[learning rate: 0.0021777]
	Learning Rate: 0.00217771
	LOSS [training: 0.08232264271047848 | validation: 0.12245504308464086]
	TIME [epoch: 9.26 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09131136452903746		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.09131136452903746 | validation: 0.13391766673617755]
	TIME [epoch: 9.26 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0692591689886604		[learning rate: 0.0021672]
	Learning Rate: 0.00216718
	LOSS [training: 0.0692591689886604 | validation: 0.07921984652212566]
	TIME [epoch: 9.29 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060954322520848536		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.060954322520848536 | validation: 0.0882359127659065]
	TIME [epoch: 9.28 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.066264340949149		[learning rate: 0.0021567]
	Learning Rate: 0.0021567
	LOSS [training: 0.066264340949149 | validation: 0.07910548886459667]
	TIME [epoch: 9.27 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07332554301233549		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.07332554301233549 | validation: 0.08778748298665137]
	TIME [epoch: 9.27 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08673897106325804		[learning rate: 0.0021463]
	Learning Rate: 0.00214627
	LOSS [training: 0.08673897106325804 | validation: 0.0742457937251838]
	TIME [epoch: 9.29 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08654501849701746		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.08654501849701746 | validation: 0.09613336585454606]
	TIME [epoch: 9.27 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0796149844063188		[learning rate: 0.0021359]
	Learning Rate: 0.00213589
	LOSS [training: 0.0796149844063188 | validation: 0.14725974798545485]
	TIME [epoch: 9.26 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07604159524269445		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.07604159524269445 | validation: 0.0506322243299816]
	TIME [epoch: 9.27 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052145088379396506		[learning rate: 0.0021256]
	Learning Rate: 0.00212556
	LOSS [training: 0.052145088379396506 | validation: 0.11689513146515318]
	TIME [epoch: 9.28 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05945929678397973		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.05945929678397973 | validation: 0.09659714296692185]
	TIME [epoch: 9.27 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09534151329066405		[learning rate: 0.0021153]
	Learning Rate: 0.00211528
	LOSS [training: 0.09534151329066405 | validation: 0.07570802821809737]
	TIME [epoch: 9.26 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0654417523037349		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.0654417523037349 | validation: 0.0918000914092148]
	TIME [epoch: 9.27 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06747270896232234		[learning rate: 0.0021051]
	Learning Rate: 0.00210505
	LOSS [training: 0.06747270896232234 | validation: 0.08571888506325644]
	TIME [epoch: 9.29 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04583387619055792		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.04583387619055792 | validation: 0.07119430159629123]
	TIME [epoch: 9.26 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09968761537069429		[learning rate: 0.0020949]
	Learning Rate: 0.00209487
	LOSS [training: 0.09968761537069429 | validation: 0.09782811390760046]
	TIME [epoch: 9.27 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05394822286842467		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.05394822286842467 | validation: 0.04774869662291402]
	TIME [epoch: 9.27 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05231501906794682		[learning rate: 0.0020847]
	Learning Rate: 0.00208474
	LOSS [training: 0.05231501906794682 | validation: 0.05212193489234443]
	TIME [epoch: 9.3 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18146448214914512		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.18146448214914512 | validation: 0.27613153577991845]
	TIME [epoch: 9.28 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2692238380572653		[learning rate: 0.0020747]
	Learning Rate: 0.00207466
	LOSS [training: 0.2692238380572653 | validation: 0.2730579389538811]
	TIME [epoch: 9.26 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23403104178298398		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.23403104178298398 | validation: 0.270507048553866]
	TIME [epoch: 9.26 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1857929302629489		[learning rate: 0.0020646]
	Learning Rate: 0.00206463
	LOSS [training: 0.1857929302629489 | validation: 0.10436716772585833]
	TIME [epoch: 9.28 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07636972256523786		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.07636972256523786 | validation: 0.08254850785064038]
	TIME [epoch: 9.27 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08078868591816919		[learning rate: 0.0020546]
	Learning Rate: 0.00205465
	LOSS [training: 0.08078868591816919 | validation: 0.32207964219450497]
	TIME [epoch: 9.27 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11737563761428282		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.11737563761428282 | validation: 0.10536287221895678]
	TIME [epoch: 9.26 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0997437688009523		[learning rate: 0.0020447]
	Learning Rate: 0.00204471
	LOSS [training: 0.0997437688009523 | validation: 0.10084785097800988]
	TIME [epoch: 9.28 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08175059949915144		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.08175059949915144 | validation: 0.11210701228339826]
	TIME [epoch: 9.27 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.070087607205957		[learning rate: 0.0020348]
	Learning Rate: 0.00203482
	LOSS [training: 0.070087607205957 | validation: 0.08382438426834202]
	TIME [epoch: 9.26 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10582936514927219		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.10582936514927219 | validation: 0.16969983642126296]
	TIME [epoch: 9.27 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10883413477473533		[learning rate: 0.002025]
	Learning Rate: 0.00202498
	LOSS [training: 0.10883413477473533 | validation: 0.12233675715869655]
	TIME [epoch: 9.28 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08130437122329794		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.08130437122329794 | validation: 0.14826270232248723]
	TIME [epoch: 9.27 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1094997102215413		[learning rate: 0.0020152]
	Learning Rate: 0.00201519
	LOSS [training: 0.1094997102215413 | validation: 0.17507015366234607]
	TIME [epoch: 9.27 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1117932969338514		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.1117932969338514 | validation: 0.07422049204692045]
	TIME [epoch: 9.26 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08335986825956579		[learning rate: 0.0020054]
	Learning Rate: 0.00200544
	LOSS [training: 0.08335986825956579 | validation: 0.3208243642237738]
	TIME [epoch: 9.29 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14006114948747816		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.14006114948747816 | validation: 0.049127643575842775]
	TIME [epoch: 9.26 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04581187449023317		[learning rate: 0.0019957]
	Learning Rate: 0.00199575
	LOSS [training: 0.04581187449023317 | validation: 0.22895979273772848]
	TIME [epoch: 9.26 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19970251628677899		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.19970251628677899 | validation: 0.08336040970277325]
	TIME [epoch: 9.27 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05862548890071713		[learning rate: 0.0019861]
	Learning Rate: 0.00198609
	LOSS [training: 0.05862548890071713 | validation: 0.06519026081367621]
	TIME [epoch: 9.27 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04843854630508867		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.04843854630508867 | validation: 0.07629222577149852]
	TIME [epoch: 9.28 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07548828845189014		[learning rate: 0.0019765]
	Learning Rate: 0.00197649
	LOSS [training: 0.07548828845189014 | validation: 0.06722706200886402]
	TIME [epoch: 9.26 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07489383312885113		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.07489383312885113 | validation: 0.10090096178316843]
	TIME [epoch: 9.26 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06796750895573116		[learning rate: 0.0019669]
	Learning Rate: 0.00196693
	LOSS [training: 0.06796750895573116 | validation: 0.10335384713531803]
	TIME [epoch: 9.27 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06940996479161407		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.06940996479161407 | validation: 0.0995662138884785]
	TIME [epoch: 9.28 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056055563330039825		[learning rate: 0.0019574]
	Learning Rate: 0.00195742
	LOSS [training: 0.056055563330039825 | validation: 0.07614488543783146]
	TIME [epoch: 9.27 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05455189669995003		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.05455189669995003 | validation: 0.061105595664326606]
	TIME [epoch: 9.26 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0560798507498524		[learning rate: 0.001948]
	Learning Rate: 0.00194796
	LOSS [training: 0.0560798507498524 | validation: 0.06816259039063384]
	TIME [epoch: 9.26 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07583189080769405		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.07583189080769405 | validation: 0.10710025036622109]
	TIME [epoch: 9.28 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06222485225999843		[learning rate: 0.0019385]
	Learning Rate: 0.00193854
	LOSS [training: 0.06222485225999843 | validation: 0.06300420088765664]
	TIME [epoch: 9.26 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05000328500916172		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.05000328500916172 | validation: 0.11631734635564468]
	TIME [epoch: 9.26 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07042002594041964		[learning rate: 0.0019292]
	Learning Rate: 0.00192916
	LOSS [training: 0.07042002594041964 | validation: 0.09201432272661207]
	TIME [epoch: 9.27 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07322488191737848		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.07322488191737848 | validation: 0.08046590798157997]
	TIME [epoch: 9.29 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06539605655966119		[learning rate: 0.0019198]
	Learning Rate: 0.00191983
	LOSS [training: 0.06539605655966119 | validation: 0.11658359459811722]
	TIME [epoch: 9.27 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051777320148666775		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.051777320148666775 | validation: 0.08758665373913846]
	TIME [epoch: 9.27 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03958506353839876		[learning rate: 0.0019105]
	Learning Rate: 0.00191055
	LOSS [training: 0.03958506353839876 | validation: 0.051820725988610566]
	TIME [epoch: 9.26 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05040753834860441		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.05040753834860441 | validation: 0.05715418379668892]
	TIME [epoch: 9.29 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04615546006130075		[learning rate: 0.0019013]
	Learning Rate: 0.00190131
	LOSS [training: 0.04615546006130075 | validation: 0.05632296371277483]
	TIME [epoch: 9.27 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052115966000139256		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.052115966000139256 | validation: 0.04522750467092827]
	TIME [epoch: 9.27 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06448508437580865		[learning rate: 0.0018921]
	Learning Rate: 0.00189211
	LOSS [training: 0.06448508437580865 | validation: 0.10486751870528661]
	TIME [epoch: 9.27 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1111907557561785		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.1111907557561785 | validation: 0.10988708217842949]
	TIME [epoch: 9.28 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06912277438200798		[learning rate: 0.001883]
	Learning Rate: 0.00188296
	LOSS [training: 0.06912277438200798 | validation: 0.06916155054198186]
	TIME [epoch: 9.26 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06592215354318724		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.06592215354318724 | validation: 0.07441701614675475]
	TIME [epoch: 9.26 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05728576159686827		[learning rate: 0.0018739]
	Learning Rate: 0.00187386
	LOSS [training: 0.05728576159686827 | validation: 0.0850790904131953]
	TIME [epoch: 9.26 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057219082653839945		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.057219082653839945 | validation: 0.12898009505469016]
	TIME [epoch: 9.29 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1311274977477302		[learning rate: 0.0018648]
	Learning Rate: 0.0018648
	LOSS [training: 0.1311274977477302 | validation: 0.1827566212282371]
	TIME [epoch: 9.26 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0942438062641391		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.0942438062641391 | validation: 0.09214148563984648]
	TIME [epoch: 9.26 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0783579351089331		[learning rate: 0.0018558]
	Learning Rate: 0.00185578
	LOSS [training: 0.0783579351089331 | validation: 0.10760375951246762]
	TIME [epoch: 9.26 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19366813283826448		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.19366813283826448 | validation: 0.1722123244728413]
	TIME [epoch: 9.28 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0849666934803454		[learning rate: 0.0018468]
	Learning Rate: 0.0018468
	LOSS [training: 0.0849666934803454 | validation: 0.06909126659768648]
	TIME [epoch: 9.28 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05377685550061995		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.05377685550061995 | validation: 0.05648619229291818]
	TIME [epoch: 9.27 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04169281536293588		[learning rate: 0.0018379]
	Learning Rate: 0.00183787
	LOSS [training: 0.04169281536293588 | validation: 0.07263490060015136]
	TIME [epoch: 9.26 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06558479031095397		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.06558479031095397 | validation: 0.0511756641136666]
	TIME [epoch: 9.3 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08392784866043164		[learning rate: 0.001829]
	Learning Rate: 0.00182899
	LOSS [training: 0.08392784866043164 | validation: 0.08662986802549556]
	TIME [epoch: 9.26 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0659066239730888		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.0659066239730888 | validation: 0.0659622111839609]
	TIME [epoch: 9.27 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06292488268427869		[learning rate: 0.0018201]
	Learning Rate: 0.00182014
	LOSS [training: 0.06292488268427869 | validation: 0.13373377871685174]
	TIME [epoch: 9.27 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0589174796814327		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.0589174796814327 | validation: 0.09331614870240289]
	TIME [epoch: 9.28 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06203025936702243		[learning rate: 0.0018113]
	Learning Rate: 0.00181134
	LOSS [training: 0.06203025936702243 | validation: 0.05814484425398693]
	TIME [epoch: 9.28 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04856628852560882		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.04856628852560882 | validation: 0.09918907340804223]
	TIME [epoch: 9.27 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05171367949494747		[learning rate: 0.0018026]
	Learning Rate: 0.00180258
	LOSS [training: 0.05171367949494747 | validation: 0.05165434875054771]
	TIME [epoch: 9.27 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041101403391510985		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.041101403391510985 | validation: 0.05176152124595952]
	TIME [epoch: 9.29 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040923601692036314		[learning rate: 0.0017939]
	Learning Rate: 0.00179386
	LOSS [training: 0.040923601692036314 | validation: 0.03706665334761049]
	TIME [epoch: 9.27 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039534189401346925		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.039534189401346925 | validation: 0.0611407169245258]
	TIME [epoch: 9.27 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039126066378742615		[learning rate: 0.0017852]
	Learning Rate: 0.00178519
	LOSS [training: 0.039126066378742615 | validation: 0.04321993204896294]
	TIME [epoch: 9.28 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0332462022489996		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.0332462022489996 | validation: 0.061365003109615665]
	TIME [epoch: 9.29 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0485480788206378		[learning rate: 0.0017766]
	Learning Rate: 0.00177656
	LOSS [training: 0.0485480788206378 | validation: 0.06081780556389719]
	TIME [epoch: 9.27 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05866267683934682		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.05866267683934682 | validation: 0.05301141002697478]
	TIME [epoch: 9.26 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05195553160745168		[learning rate: 0.001768]
	Learning Rate: 0.00176797
	LOSS [training: 0.05195553160745168 | validation: 0.04548764820015782]
	TIME [epoch: 9.27 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061077272475746625		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.061077272475746625 | validation: 0.05563205503018133]
	TIME [epoch: 9.28 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052031673724648154		[learning rate: 0.0017594]
	Learning Rate: 0.00175942
	LOSS [training: 0.052031673724648154 | validation: 0.061074091863890456]
	TIME [epoch: 9.28 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07112204275977947		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.07112204275977947 | validation: 0.07415368379909623]
	TIME [epoch: 9.26 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059350109427476885		[learning rate: 0.0017509]
	Learning Rate: 0.00175091
	LOSS [training: 0.059350109427476885 | validation: 0.060540564201242854]
	TIME [epoch: 9.26 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060617664153486975		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.060617664153486975 | validation: 0.07945023506002093]
	TIME [epoch: 9.27 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04764404071211973		[learning rate: 0.0017424]
	Learning Rate: 0.00174244
	LOSS [training: 0.04764404071211973 | validation: 0.08649943664021184]
	TIME [epoch: 9.27 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07449139796150808		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.07449139796150808 | validation: 0.06338169568930928]
	TIME [epoch: 9.26 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08218304556393116		[learning rate: 0.001734]
	Learning Rate: 0.00173401
	LOSS [training: 0.08218304556393116 | validation: 0.09338471896874309]
	TIME [epoch: 9.27 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0846441336945283		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.0846441336945283 | validation: 0.09919771763558177]
	TIME [epoch: 9.27 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07346000197342181		[learning rate: 0.0017256]
	Learning Rate: 0.00172563
	LOSS [training: 0.07346000197342181 | validation: 0.07459012174831178]
	TIME [epoch: 9.29 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06341921284889199		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.06341921284889199 | validation: 0.06664828890310621]
	TIME [epoch: 9.26 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08796318359421519		[learning rate: 0.0017173]
	Learning Rate: 0.00171728
	LOSS [training: 0.08796318359421519 | validation: 0.1192351800542502]
	TIME [epoch: 9.27 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07771366973220178		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.07771366973220178 | validation: 0.06669390141210686]
	TIME [epoch: 9.25 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07603002676811281		[learning rate: 0.001709]
	Learning Rate: 0.00170898
	LOSS [training: 0.07603002676811281 | validation: 0.09814671591970386]
	TIME [epoch: 9.29 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08460742831675357		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.08460742831675357 | validation: 0.05539995010954225]
	TIME [epoch: 9.27 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07186307189558257		[learning rate: 0.0017007]
	Learning Rate: 0.00170072
	LOSS [training: 0.07186307189558257 | validation: 0.06970548775115767]
	TIME [epoch: 9.27 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04122263257664468		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.04122263257664468 | validation: 0.06450677940404562]
	TIME [epoch: 9.27 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051160180500545646		[learning rate: 0.0016925]
	Learning Rate: 0.00169249
	LOSS [training: 0.051160180500545646 | validation: 0.04999025990981372]
	TIME [epoch: 9.28 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048323550921145264		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.048323550921145264 | validation: 0.06986045844778996]
	TIME [epoch: 9.26 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050825906258258856		[learning rate: 0.0016843]
	Learning Rate: 0.00168431
	LOSS [training: 0.050825906258258856 | validation: 0.09055058213012616]
	TIME [epoch: 9.26 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08943627249353928		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.08943627249353928 | validation: 0.11907599580040679]
	TIME [epoch: 9.26 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06152731892176846		[learning rate: 0.0016762]
	Learning Rate: 0.00167616
	LOSS [training: 0.06152731892176846 | validation: 0.09415530313787408]
	TIME [epoch: 9.29 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04958664652119653		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.04958664652119653 | validation: 0.06281151036037647]
	TIME [epoch: 9.27 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04848653351799666		[learning rate: 0.0016681]
	Learning Rate: 0.00166806
	LOSS [training: 0.04848653351799666 | validation: 0.062436511258741695]
	TIME [epoch: 9.26 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0708495402742085		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.0708495402742085 | validation: 0.048382729668774486]
	TIME [epoch: 9.26 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05068769580984549		[learning rate: 0.00166]
	Learning Rate: 0.00165999
	LOSS [training: 0.05068769580984549 | validation: 0.05570260758377665]
	TIME [epoch: 9.28 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04155713171722186		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.04155713171722186 | validation: 0.0646514109029398]
	TIME [epoch: 9.27 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04413330737096917		[learning rate: 0.001652]
	Learning Rate: 0.00165196
	LOSS [training: 0.04413330737096917 | validation: 0.0288616457772094]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_843.pth
	Model improved!!!
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037548031606921065		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.037548031606921065 | validation: 0.08899002411221466]
	TIME [epoch: 9.25 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05488282627650938		[learning rate: 0.001644]
	Learning Rate: 0.00164397
	LOSS [training: 0.05488282627650938 | validation: 0.07202651996961373]
	TIME [epoch: 9.27 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04045249898539213		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.04045249898539213 | validation: 0.03488243602960815]
	TIME [epoch: 9.24 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03269614576399975		[learning rate: 0.001636]
	Learning Rate: 0.00163602
	LOSS [training: 0.03269614576399975 | validation: 0.035032963943881154]
	TIME [epoch: 9.24 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03035670772465311		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.03035670772465311 | validation: 0.04508539371085331]
	TIME [epoch: 9.24 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04272346873761397		[learning rate: 0.0016281]
	Learning Rate: 0.00162811
	LOSS [training: 0.04272346873761397 | validation: 0.06154958317164422]
	TIME [epoch: 9.27 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0665249244289707		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.0665249244289707 | validation: 0.07899202530347216]
	TIME [epoch: 9.25 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0534034758921317		[learning rate: 0.0016202]
	Learning Rate: 0.00162024
	LOSS [training: 0.0534034758921317 | validation: 0.0847473140840691]
	TIME [epoch: 9.25 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06626692999277187		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.06626692999277187 | validation: 0.07859417226908233]
	TIME [epoch: 9.24 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07243940610390909		[learning rate: 0.0016124]
	Learning Rate: 0.0016124
	LOSS [training: 0.07243940610390909 | validation: 0.06802630032775066]
	TIME [epoch: 9.26 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056554234576618165		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.056554234576618165 | validation: 0.059676642002537944]
	TIME [epoch: 9.24 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037297018304002665		[learning rate: 0.0016046]
	Learning Rate: 0.00160461
	LOSS [training: 0.037297018304002665 | validation: 0.039925927770737835]
	TIME [epoch: 9.25 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10136692308083606		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.10136692308083606 | validation: 0.15523274321558528]
	TIME [epoch: 9.24 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04996193461271808		[learning rate: 0.0015968]
	Learning Rate: 0.00159685
	LOSS [training: 0.04996193461271808 | validation: 0.059881987816679805]
	TIME [epoch: 9.26 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034190181809997035		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.034190181809997035 | validation: 0.041002726371322795]
	TIME [epoch: 9.25 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1253537444019433		[learning rate: 0.0015891]
	Learning Rate: 0.00158912
	LOSS [training: 0.1253537444019433 | validation: 0.15650757143136906]
	TIME [epoch: 9.23 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12793330591722568		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.12793330591722568 | validation: 0.22639950941538198]
	TIME [epoch: 9.23 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09749800852412911		[learning rate: 0.0015814]
	Learning Rate: 0.00158144
	LOSS [training: 0.09749800852412911 | validation: 0.042037283374421947]
	TIME [epoch: 9.26 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04296715831178997		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.04296715831178997 | validation: 0.045012957109085525]
	TIME [epoch: 9.25 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023139581211266823		[learning rate: 0.0015738]
	Learning Rate: 0.00157379
	LOSS [training: 0.023139581211266823 | validation: 0.06307178383731313]
	TIME [epoch: 9.25 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05917678198380975		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.05917678198380975 | validation: 0.041427182612088415]
	TIME [epoch: 9.24 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03850818981601167		[learning rate: 0.0015662]
	Learning Rate: 0.00156618
	LOSS [training: 0.03850818981601167 | validation: 0.08402709590745724]
	TIME [epoch: 9.26 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06009786431584736		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.06009786431584736 | validation: 0.05871811980206969]
	TIME [epoch: 9.25 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04095838300775694		[learning rate: 0.0015586]
	Learning Rate: 0.00155861
	LOSS [training: 0.04095838300775694 | validation: 0.023650457561348308]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_867.pth
	Model improved!!!
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02342329846552382		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.02342329846552382 | validation: 0.029178248966799825]
	TIME [epoch: 9.25 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017978795798560203		[learning rate: 0.0015511]
	Learning Rate: 0.00155107
	LOSS [training: 0.017978795798560203 | validation: 0.056450629878490435]
	TIME [epoch: 9.26 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0553885254012076		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.0553885254012076 | validation: 0.1776088888059621]
	TIME [epoch: 9.26 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05031976342591647		[learning rate: 0.0015436]
	Learning Rate: 0.00154357
	LOSS [training: 0.05031976342591647 | validation: 0.05620588723040281]
	TIME [epoch: 9.25 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022493251847563518		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.022493251847563518 | validation: 0.031454096931775144]
	TIME [epoch: 9.24 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03531273145092515		[learning rate: 0.0015361]
	Learning Rate: 0.00153611
	LOSS [training: 0.03531273145092515 | validation: 0.06260974298722297]
	TIME [epoch: 9.26 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05037620815513415		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.05037620815513415 | validation: 0.050148268686121725]
	TIME [epoch: 9.26 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044240225158585736		[learning rate: 0.0015287]
	Learning Rate: 0.00152868
	LOSS [training: 0.044240225158585736 | validation: 0.08873685224714917]
	TIME [epoch: 9.25 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03637914218001305		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.03637914218001305 | validation: 0.062496370203352344]
	TIME [epoch: 9.25 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04471680485503658		[learning rate: 0.0015213]
	Learning Rate: 0.00152128
	LOSS [training: 0.04471680485503658 | validation: 0.1381992133923296]
	TIME [epoch: 9.24 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08572314805317814		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.08572314805317814 | validation: 0.09310631754175142]
	TIME [epoch: 9.27 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1126571421760701		[learning rate: 0.0015139]
	Learning Rate: 0.00151393
	LOSS [training: 0.1126571421760701 | validation: 0.18630843303508404]
	TIME [epoch: 9.25 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13699646952567637		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.13699646952567637 | validation: 0.06330669385695695]
	TIME [epoch: 9.25 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03706933291881942		[learning rate: 0.0015066]
	Learning Rate: 0.00150661
	LOSS [training: 0.03706933291881942 | validation: 0.034379038458426533]
	TIME [epoch: 9.25 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01827521234868603		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.01827521234868603 | validation: 0.0427580779648233]
	TIME [epoch: 9.27 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05753700054361514		[learning rate: 0.0014993]
	Learning Rate: 0.00149932
	LOSS [training: 0.05753700054361514 | validation: 0.052030700663277654]
	TIME [epoch: 9.25 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05886766885962892		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.05886766885962892 | validation: 0.12510879608214515]
	TIME [epoch: 9.25 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1039474031749356		[learning rate: 0.0014921]
	Learning Rate: 0.00149207
	LOSS [training: 0.1039474031749356 | validation: 0.06463029265537447]
	TIME [epoch: 9.25 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03905443844168064		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.03905443844168064 | validation: 0.037940537456487705]
	TIME [epoch: 9.27 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031231578139051648		[learning rate: 0.0014849]
	Learning Rate: 0.00148486
	LOSS [training: 0.031231578139051648 | validation: 0.04182612927754862]
	TIME [epoch: 9.26 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025429053005243014		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.025429053005243014 | validation: 0.10150218715052124]
	TIME [epoch: 9.25 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03204550974058103		[learning rate: 0.0014777]
	Learning Rate: 0.00147768
	LOSS [training: 0.03204550974058103 | validation: 0.021975748227189604]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_889.pth
	Model improved!!!
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022552505951910988		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.022552505951910988 | validation: 0.05717450159802931]
	TIME [epoch: 9.27 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05531973310877351		[learning rate: 0.0014705]
	Learning Rate: 0.00147053
	LOSS [training: 0.05531973310877351 | validation: 0.0682119745264442]
	TIME [epoch: 9.24 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025689241311404532		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.025689241311404532 | validation: 0.04388159196598025]
	TIME [epoch: 9.25 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019232388691379908		[learning rate: 0.0014634]
	Learning Rate: 0.00146342
	LOSS [training: 0.019232388691379908 | validation: 0.04951735507508567]
	TIME [epoch: 9.24 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01847707581197654		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.01847707581197654 | validation: 0.032350225314241365]
	TIME [epoch: 9.27 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025280115728783033		[learning rate: 0.0014563]
	Learning Rate: 0.00145634
	LOSS [training: 0.025280115728783033 | validation: 0.02858148278228141]
	TIME [epoch: 9.25 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022703187936005766		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.022703187936005766 | validation: 0.024224806422833322]
	TIME [epoch: 9.24 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037049804850597313		[learning rate: 0.0014493]
	Learning Rate: 0.0014493
	LOSS [training: 0.037049804850597313 | validation: 0.04766034346129901]
	TIME [epoch: 9.25 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036543821473739205		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.036543821473739205 | validation: 0.056696068324587234]
	TIME [epoch: 9.27 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04314718568344132		[learning rate: 0.0014423]
	Learning Rate: 0.00144229
	LOSS [training: 0.04314718568344132 | validation: 0.03177079419452263]
	TIME [epoch: 9.24 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04726607080224983		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.04726607080224983 | validation: 0.046503969044820404]
	TIME [epoch: 9.25 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03785181841940934		[learning rate: 0.0014353]
	Learning Rate: 0.00143532
	LOSS [training: 0.03785181841940934 | validation: 0.08906942823377634]
	TIME [epoch: 9.24 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07412095593777455		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.07412095593777455 | validation: 0.09191410058140703]
	TIME [epoch: 9.27 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03682779307849462		[learning rate: 0.0014284]
	Learning Rate: 0.00142837
	LOSS [training: 0.03682779307849462 | validation: 0.033535455968391366]
	TIME [epoch: 9.25 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032300159444312936		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.032300159444312936 | validation: 0.08881832683569364]
	TIME [epoch: 9.24 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04521316217157786		[learning rate: 0.0014215]
	Learning Rate: 0.00142147
	LOSS [training: 0.04521316217157786 | validation: 0.06944844654136217]
	TIME [epoch: 9.24 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05814476342043262		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.05814476342043262 | validation: 0.03710768142264591]
	TIME [epoch: 9.26 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01808967767101955		[learning rate: 0.0014146]
	Learning Rate: 0.00141459
	LOSS [training: 0.01808967767101955 | validation: 0.03889607885104318]
	TIME [epoch: 9.25 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028169746742361584		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.028169746742361584 | validation: 0.03453589217425593]
	TIME [epoch: 9.25 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025177249353935244		[learning rate: 0.0014078]
	Learning Rate: 0.00140775
	LOSS [training: 0.025177249353935244 | validation: 0.0485454586824783]
	TIME [epoch: 9.24 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048858146618625475		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.048858146618625475 | validation: 0.08984057717219268]
	TIME [epoch: 9.27 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0406452088823568		[learning rate: 0.0014009]
	Learning Rate: 0.00140094
	LOSS [training: 0.0406452088823568 | validation: 0.05654259710211024]
	TIME [epoch: 9.26 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037089649661909786		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.037089649661909786 | validation: 0.06574293288215327]
	TIME [epoch: 9.25 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03934081028614977		[learning rate: 0.0013942]
	Learning Rate: 0.00139417
	LOSS [training: 0.03934081028614977 | validation: 0.09574704958883673]
	TIME [epoch: 9.26 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04979564158181029		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.04979564158181029 | validation: 0.07008859955763891]
	TIME [epoch: 9.28 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042987271549135495		[learning rate: 0.0013874]
	Learning Rate: 0.00138743
	LOSS [training: 0.042987271549135495 | validation: 0.07476882749942515]
	TIME [epoch: 9.26 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047312826065673344		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.047312826065673344 | validation: 0.053798794868696063]
	TIME [epoch: 9.25 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046128666708059915		[learning rate: 0.0013807]
	Learning Rate: 0.00138072
	LOSS [training: 0.046128666708059915 | validation: 0.05899054503130654]
	TIME [epoch: 9.25 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04444025270453229		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.04444025270453229 | validation: 0.1426783777376841]
	TIME [epoch: 9.26 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060298352001482855		[learning rate: 0.001374]
	Learning Rate: 0.00137404
	LOSS [training: 0.060298352001482855 | validation: 0.03570119799378857]
	TIME [epoch: 9.25 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04376189903600512		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.04376189903600512 | validation: 0.053816959929337514]
	TIME [epoch: 9.24 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021856104323154775		[learning rate: 0.0013674]
	Learning Rate: 0.0013674
	LOSS [training: 0.021856104323154775 | validation: 0.019147077568922793]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_921.pth
	Model improved!!!
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020488781989447716		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.020488781989447716 | validation: 0.06374115201984315]
	TIME [epoch: 9.26 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038582835146852325		[learning rate: 0.0013608]
	Learning Rate: 0.00136078
	LOSS [training: 0.038582835146852325 | validation: 0.04279444439891125]
	TIME [epoch: 9.26 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04340193269305405		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.04340193269305405 | validation: 0.05199627528563196]
	TIME [epoch: 9.25 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038824039059321185		[learning rate: 0.0013542]
	Learning Rate: 0.0013542
	LOSS [training: 0.038824039059321185 | validation: 0.07304386302983178]
	TIME [epoch: 9.25 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04161649733234644		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.04161649733234644 | validation: 0.04679607022634053]
	TIME [epoch: 9.25 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028206903607846223		[learning rate: 0.0013477]
	Learning Rate: 0.00134766
	LOSS [training: 0.028206903607846223 | validation: 0.05094827820613847]
	TIME [epoch: 9.27 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08975542677875917		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.08975542677875917 | validation: 0.1455325552946578]
	TIME [epoch: 9.25 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06948415226476515		[learning rate: 0.0013411]
	Learning Rate: 0.00134114
	LOSS [training: 0.06948415226476515 | validation: 0.02860202814541029]
	TIME [epoch: 9.25 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02707689177657645		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.02707689177657645 | validation: 0.09060251217706002]
	TIME [epoch: 9.24 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021554037971727592		[learning rate: 0.0013347]
	Learning Rate: 0.00133465
	LOSS [training: 0.021554037971727592 | validation: 0.02409300828123575]
	TIME [epoch: 9.27 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038262548476218385		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.038262548476218385 | validation: 0.14662269227195202]
	TIME [epoch: 9.25 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06427516640872993		[learning rate: 0.0013282]
	Learning Rate: 0.0013282
	LOSS [training: 0.06427516640872993 | validation: 0.025591907846586444]
	TIME [epoch: 9.25 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021587535065283374		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.021587535065283374 | validation: 0.036306042209422615]
	TIME [epoch: 9.25 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02194102394992292		[learning rate: 0.0013218]
	Learning Rate: 0.00132178
	LOSS [training: 0.02194102394992292 | validation: 0.03009250969622429]
	TIME [epoch: 9.27 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031041326183676214		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.031041326183676214 | validation: 0.037234174944407034]
	TIME [epoch: 9.24 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025763276809723522		[learning rate: 0.0013154]
	Learning Rate: 0.00131538
	LOSS [training: 0.025763276809723522 | validation: 0.05789053953500755]
	TIME [epoch: 9.25 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07608850909158668		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.07608850909158668 | validation: 0.18717984002291377]
	TIME [epoch: 9.24 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09162569874244922		[learning rate: 0.001309]
	Learning Rate: 0.00130902
	LOSS [training: 0.09162569874244922 | validation: 0.07975774350911904]
	TIME [epoch: 9.27 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2425706681149839		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.2425706681149839 | validation: 0.34870245503587605]
	TIME [epoch: 9.25 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13505563425833333		[learning rate: 0.0013027]
	Learning Rate: 0.00130269
	LOSS [training: 0.13505563425833333 | validation: 0.16428669267336118]
	TIME [epoch: 9.24 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061918663151754635		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.061918663151754635 | validation: 0.03807682950745528]
	TIME [epoch: 9.25 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053541673780908		[learning rate: 0.0012964]
	Learning Rate: 0.00129639
	LOSS [training: 0.053541673780908 | validation: 0.059194112000387974]
	TIME [epoch: 9.26 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02680876987208821		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.02680876987208821 | validation: 0.048098621725425734]
	TIME [epoch: 9.24 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02878748725004403		[learning rate: 0.0012901]
	Learning Rate: 0.00129012
	LOSS [training: 0.02878748725004403 | validation: 0.02447848386152164]
	TIME [epoch: 9.24 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018345377971564387		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.018345377971564387 | validation: 0.019649534930654255]
	TIME [epoch: 9.24 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022665914098582797		[learning rate: 0.0012839]
	Learning Rate: 0.00128389
	LOSS [training: 0.022665914098582797 | validation: 0.039526619906979386]
	TIME [epoch: 9.26 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031059768345450694		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.031059768345450694 | validation: 0.027649078300585682]
	TIME [epoch: 9.24 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027653908709097497		[learning rate: 0.0012777]
	Learning Rate: 0.00127768
	LOSS [training: 0.027653908709097497 | validation: 0.0642882917378478]
	TIME [epoch: 9.24 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039961796293722415		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.039961796293722415 | validation: 0.06045389940429254]
	TIME [epoch: 9.24 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03323322202695657		[learning rate: 0.0012715]
	Learning Rate: 0.0012715
	LOSS [training: 0.03323322202695657 | validation: 0.03864674838173496]
	TIME [epoch: 9.27 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04250256246883184		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.04250256246883184 | validation: 0.10123204723405219]
	TIME [epoch: 9.25 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05610266577630667		[learning rate: 0.0012653]
	Learning Rate: 0.00126535
	LOSS [training: 0.05610266577630667 | validation: 0.029805240776463106]
	TIME [epoch: 9.25 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03450756903078768		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.03450756903078768 | validation: 0.07382188826079294]
	TIME [epoch: 9.25 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04548844044889226		[learning rate: 0.0012592]
	Learning Rate: 0.00125923
	LOSS [training: 0.04548844044889226 | validation: 0.039219512170375795]
	TIME [epoch: 9.27 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055147588818758184		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.055147588818758184 | validation: 0.17395503253749467]
	TIME [epoch: 9.24 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055375259969137		[learning rate: 0.0012531]
	Learning Rate: 0.00125314
	LOSS [training: 0.055375259969137 | validation: 0.054638823502721805]
	TIME [epoch: 9.24 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03573218489727165		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.03573218489727165 | validation: 0.01589224471149135]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_958.pth
	Model improved!!!
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07216139407435737		[learning rate: 0.0012471]
	Learning Rate: 0.00124708
	LOSS [training: 0.07216139407435737 | validation: 0.174121712965081]
	TIME [epoch: 9.28 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10910693000995708		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.10910693000995708 | validation: 0.12336939224489464]
	TIME [epoch: 9.26 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044791407462142205		[learning rate: 0.0012411]
	Learning Rate: 0.00124105
	LOSS [training: 0.044791407462142205 | validation: 0.0523195744282763]
	TIME [epoch: 9.25 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03603426245546159		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.03603426245546159 | validation: 0.014795171600600449]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_962.pth
	Model improved!!!
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013775486575838583		[learning rate: 0.001235]
	Learning Rate: 0.00123505
	LOSS [training: 0.013775486575838583 | validation: 0.016287665068084756]
	TIME [epoch: 9.27 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019826206993509142		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.019826206993509142 | validation: 0.030950507373140562]
	TIME [epoch: 9.26 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010430321458947974		[learning rate: 0.0012291]
	Learning Rate: 0.00122908
	LOSS [training: 0.010430321458947974 | validation: 0.019390604282416814]
	TIME [epoch: 9.26 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029331970255092536		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.029331970255092536 | validation: 0.04795413948151867]
	TIME [epoch: 9.26 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013568423265473006		[learning rate: 0.0012231]
	Learning Rate: 0.00122313
	LOSS [training: 0.013568423265473006 | validation: 0.0344850599378575]
	TIME [epoch: 9.27 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02446593823355215		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.02446593823355215 | validation: 0.01848150520276815]
	TIME [epoch: 9.26 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01862653948400466		[learning rate: 0.0012172]
	Learning Rate: 0.00121722
	LOSS [training: 0.01862653948400466 | validation: 0.10048276813807633]
	TIME [epoch: 9.25 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04396999163783047		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.04396999163783047 | validation: 0.06415470441978942]
	TIME [epoch: 9.25 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030072564488084104		[learning rate: 0.0012113]
	Learning Rate: 0.00121133
	LOSS [training: 0.030072564488084104 | validation: 0.05063037923392211]
	TIME [epoch: 9.27 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038497924070501496		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.038497924070501496 | validation: 0.033854288369078535]
	TIME [epoch: 9.25 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023218569981263645		[learning rate: 0.0012055]
	Learning Rate: 0.00120547
	LOSS [training: 0.023218569981263645 | validation: 0.02914221243149554]
	TIME [epoch: 9.25 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027422598955546752		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.027422598955546752 | validation: 0.059752505994309]
	TIME [epoch: 9.25 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038127061430885394		[learning rate: 0.0011996]
	Learning Rate: 0.00119964
	LOSS [training: 0.038127061430885394 | validation: 0.03619395950129267]
	TIME [epoch: 9.26 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03157028470253502		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.03157028470253502 | validation: 0.032515148640098565]
	TIME [epoch: 9.27 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0431637908907569		[learning rate: 0.0011938]
	Learning Rate: 0.00119384
	LOSS [training: 0.0431637908907569 | validation: 0.07449450676249715]
	TIME [epoch: 9.26 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03766626406504788		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.03766626406504788 | validation: 0.04030964109391881]
	TIME [epoch: 9.26 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03887498555190537		[learning rate: 0.0011881]
	Learning Rate: 0.00118807
	LOSS [training: 0.03887498555190537 | validation: 0.03329189273336704]
	TIME [epoch: 9.27 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04594862305564809		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.04594862305564809 | validation: 0.08249236578178037]
	TIME [epoch: 9.28 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052881382009261305		[learning rate: 0.0011823]
	Learning Rate: 0.00118232
	LOSS [training: 0.052881382009261305 | validation: 0.10412643586282867]
	TIME [epoch: 9.25 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06740920375362082		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.06740920375362082 | validation: 0.04555861528405088]
	TIME [epoch: 9.25 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03563358558184858		[learning rate: 0.0011766]
	Learning Rate: 0.00117661
	LOSS [training: 0.03563358558184858 | validation: 0.023205632546732975]
	TIME [epoch: 9.25 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044229782118651216		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.044229782118651216 | validation: 0.047447641177808794]
	TIME [epoch: 9.28 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027418961371555667		[learning rate: 0.0011709]
	Learning Rate: 0.00117092
	LOSS [training: 0.027418961371555667 | validation: 0.05283655863680224]
	TIME [epoch: 9.25 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03421008200756684		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.03421008200756684 | validation: 0.057351607528034684]
	TIME [epoch: 9.26 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025851013025145763		[learning rate: 0.0011653]
	Learning Rate: 0.00116526
	LOSS [training: 0.025851013025145763 | validation: 0.06287592488904417]
	TIME [epoch: 9.26 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03396459924108525		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.03396459924108525 | validation: 0.031016080779705676]
	TIME [epoch: 9.27 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02962047375841269		[learning rate: 0.0011596]
	Learning Rate: 0.00115962
	LOSS [training: 0.02962047375841269 | validation: 0.054060171369479396]
	TIME [epoch: 9.26 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10599219137006133		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.10599219137006133 | validation: 0.1734142552666808]
	TIME [epoch: 9.26 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1231078995015823		[learning rate: 0.001154]
	Learning Rate: 0.00115401
	LOSS [training: 0.1231078995015823 | validation: 0.07030600606780071]
	TIME [epoch: 9.26 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03985443600486842		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.03985443600486842 | validation: 0.08795870495569702]
	TIME [epoch: 9.29 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07830390994234679		[learning rate: 0.0011484]
	Learning Rate: 0.00114843
	LOSS [training: 0.07830390994234679 | validation: 0.10739050672251937]
	TIME [epoch: 9.25 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07038233676797681		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.07038233676797681 | validation: 0.06726798322336427]
	TIME [epoch: 9.25 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05263562602856033		[learning rate: 0.0011429]
	Learning Rate: 0.00114288
	LOSS [training: 0.05263562602856033 | validation: 0.040417959657800206]
	TIME [epoch: 9.25 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04148541303144339		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.04148541303144339 | validation: 0.04918781630839006]
	TIME [epoch: 9.27 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027983104382030177		[learning rate: 0.0011374]
	Learning Rate: 0.00113735
	LOSS [training: 0.027983104382030177 | validation: 0.05541305062267596]
	TIME [epoch: 9.26 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03309361862776861		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.03309361862776861 | validation: 0.091129799828972]
	TIME [epoch: 9.25 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1008066316980086		[learning rate: 0.0011319]
	Learning Rate: 0.00113185
	LOSS [training: 0.1008066316980086 | validation: 0.12207776521712588]
	TIME [epoch: 9.25 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04838554691603114		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.04838554691603114 | validation: 0.03293931449764971]
	TIME [epoch: 9.27 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029765454724489476		[learning rate: 0.0011264]
	Learning Rate: 0.00112638
	LOSS [training: 0.029765454724489476 | validation: 0.051305518813325277]
	TIME [epoch: 9.25 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03415358358651875		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.03415358358651875 | validation: 0.04206623213401703]
	TIME [epoch: 9.25 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059018442591289445		[learning rate: 0.0011209]
	Learning Rate: 0.00112093
	LOSS [training: 0.059018442591289445 | validation: 0.22271926455640584]
	TIME [epoch: 9.26 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15554565332198453		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.15554565332198453 | validation: 0.1642329808229443]
	TIME [epoch: 9.28 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10561314831514287		[learning rate: 0.0011155]
	Learning Rate: 0.00111551
	LOSS [training: 0.10561314831514287 | validation: 0.06512823915006595]
	TIME [epoch: 9.26 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05226804527332614		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.05226804527332614 | validation: 0.04963733738844938]
	TIME [epoch: 9.25 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0317593420490629		[learning rate: 0.0011101]
	Learning Rate: 0.00111012
	LOSS [training: 0.0317593420490629 | validation: 0.03642256859466021]
	TIME [epoch: 9.25 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038585223434910464		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.038585223434910464 | validation: 0.17685978537771757]
	TIME [epoch: 9.27 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20975883365157744		[learning rate: 0.0011047]
	Learning Rate: 0.00110475
	LOSS [training: 0.20975883365157744 | validation: 0.21434318623457543]
	TIME [epoch: 9.25 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12814767958828877		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.12814767958828877 | validation: 0.1561815119220315]
	TIME [epoch: 9.25 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049058294979492136		[learning rate: 0.0010994]
	Learning Rate: 0.00109941
	LOSS [training: 0.049058294979492136 | validation: 0.03840142480093346]
	TIME [epoch: 9.26 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042190876811274806		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.042190876811274806 | validation: 0.06081596057635965]
	TIME [epoch: 9.27 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04587669369216263		[learning rate: 0.0010941]
	Learning Rate: 0.00109409
	LOSS [training: 0.04587669369216263 | validation: 0.050928433884847114]
	TIME [epoch: 9.26 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06398328768850273		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.06398328768850273 | validation: 0.12058487467421877]
	TIME [epoch: 9.25 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15461900475162735		[learning rate: 0.0010888]
	Learning Rate: 0.0010888
	LOSS [training: 0.15461900475162735 | validation: 0.251432680558181]
	TIME [epoch: 9.26 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18252887095285583		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.18252887095285583 | validation: 0.2447870356888706]
	TIME [epoch: 9.28 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1195665710330041		[learning rate: 0.0010835]
	Learning Rate: 0.00108353
	LOSS [training: 0.1195665710330041 | validation: 0.10625437192314743]
	TIME [epoch: 9.26 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07397367968806519		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.07397367968806519 | validation: 0.06773572175696639]
	TIME [epoch: 9.26 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07048334982297541		[learning rate: 0.0010783]
	Learning Rate: 0.00107829
	LOSS [training: 0.07048334982297541 | validation: 0.06269235779237628]
	TIME [epoch: 9.26 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058022863736858984		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.058022863736858984 | validation: 0.07369796496985939]
	TIME [epoch: 9.27 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05851404597047059		[learning rate: 0.0010731]
	Learning Rate: 0.00107308
	LOSS [training: 0.05851404597047059 | validation: 0.04472293463912781]
	TIME [epoch: 9.25 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06568948752767705		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.06568948752767705 | validation: 0.07547470880605696]
	TIME [epoch: 9.25 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04625639178823242		[learning rate: 0.0010679]
	Learning Rate: 0.00106789
	LOSS [training: 0.04625639178823242 | validation: 0.05387717748381433]
	TIME [epoch: 9.25 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06535610195241562		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.06535610195241562 | validation: 0.09927778520833863]
	TIME [epoch: 9.26 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06254186657645869		[learning rate: 0.0010627]
	Learning Rate: 0.00106273
	LOSS [training: 0.06254186657645869 | validation: 0.0613361717838367]
	TIME [epoch: 9.26 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045609493879465675		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.045609493879465675 | validation: 0.0680281292439779]
	TIME [epoch: 9.25 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06835724980292401		[learning rate: 0.0010576]
	Learning Rate: 0.00105759
	LOSS [training: 0.06835724980292401 | validation: 0.05626356361872243]
	TIME [epoch: 9.25 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047487678054932404		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.047487678054932404 | validation: 0.11252652195531246]
	TIME [epoch: 9.26 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08597766077983346		[learning rate: 0.0010525]
	Learning Rate: 0.00105247
	LOSS [training: 0.08597766077983346 | validation: 0.04248466047461111]
	TIME [epoch: 9.28 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04653424112383088		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.04653424112383088 | validation: 0.061585671554716725]
	TIME [epoch: 9.26 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04625563717385729		[learning rate: 0.0010474]
	Learning Rate: 0.00104738
	LOSS [training: 0.04625563717385729 | validation: 0.05424441717187685]
	TIME [epoch: 9.26 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04386035202188337		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.04386035202188337 | validation: 0.04109805917667479]
	TIME [epoch: 9.26 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043216122941713966		[learning rate: 0.0010423]
	Learning Rate: 0.00104232
	LOSS [training: 0.043216122941713966 | validation: 0.058647236112490966]
	TIME [epoch: 9.27 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05338132681182615		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.05338132681182615 | validation: 0.052318118614820594]
	TIME [epoch: 9.26 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030581935293703934		[learning rate: 0.0010373]
	Learning Rate: 0.00103728
	LOSS [training: 0.030581935293703934 | validation: 0.05374526253102985]
	TIME [epoch: 9.25 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07353323161014069		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.07353323161014069 | validation: 0.053527520997565345]
	TIME [epoch: 9.25 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050217219949738955		[learning rate: 0.0010323]
	Learning Rate: 0.00103226
	LOSS [training: 0.050217219949738955 | validation: 0.04964672034714872]
	TIME [epoch: 9.27 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033922038323358376		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.033922038323358376 | validation: 0.04415386304526896]
	TIME [epoch: 9.25 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03154667841305213		[learning rate: 0.0010273]
	Learning Rate: 0.00102727
	LOSS [training: 0.03154667841305213 | validation: 0.03370431020462264]
	TIME [epoch: 9.26 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028639649852227354		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.028639649852227354 | validation: 0.05231762340666988]
	TIME [epoch: 9.25 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05127590174612186		[learning rate: 0.0010223]
	Learning Rate: 0.0010223
	LOSS [training: 0.05127590174612186 | validation: 0.05634644110542114]
	TIME [epoch: 9.28 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03981060553544029		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.03981060553544029 | validation: 0.021697596946055702]
	TIME [epoch: 9.26 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02426307034398812		[learning rate: 0.0010174]
	Learning Rate: 0.00101736
	LOSS [training: 0.02426307034398812 | validation: 0.0463815031236653]
	TIME [epoch: 9.26 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021544085359587496		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.021544085359587496 | validation: 0.019827218962623086]
	TIME [epoch: 9.26 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03375327322741427		[learning rate: 0.0010124]
	Learning Rate: 0.00101244
	LOSS [training: 0.03375327322741427 | validation: 0.08434994965706312]
	TIME [epoch: 9.28 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07611976822197444		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.07611976822197444 | validation: 0.06677105222342099]
	TIME [epoch: 9.25 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06182461879876812		[learning rate: 0.0010075]
	Learning Rate: 0.00100754
	LOSS [training: 0.06182461879876812 | validation: 0.046630904771834285]
	TIME [epoch: 9.25 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027574415931592666		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.027574415931592666 | validation: 0.04101232484329746]
	TIME [epoch: 9.25 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03629752154765631		[learning rate: 0.0010027]
	Learning Rate: 0.00100267
	LOSS [training: 0.03629752154765631 | validation: 0.028680112360503628]
	TIME [epoch: 9.27 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033734791908135914		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.033734791908135914 | validation: 0.041053230117019085]
	TIME [epoch: 9.25 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029164996556228905		[learning rate: 0.00099782]
	Learning Rate: 0.000997821
	LOSS [training: 0.029164996556228905 | validation: 0.0483691767862355]
	TIME [epoch: 9.25 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0319777015563774		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.0319777015563774 | validation: 0.05172021725131343]
	TIME [epoch: 9.26 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04252430367820698		[learning rate: 0.000993]
	Learning Rate: 0.000992996
	LOSS [training: 0.04252430367820698 | validation: 0.04924186055090203]
	TIME [epoch: 9.27 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04770736084586574		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.04770736084586574 | validation: 0.04695390266383746]
	TIME [epoch: 9.25 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0458285334645388		[learning rate: 0.00098819]
	Learning Rate: 0.000988194
	LOSS [training: 0.0458285334645388 | validation: 0.05892048399585898]
	TIME [epoch: 9.25 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053068679725280135		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.053068679725280135 | validation: 0.06534177471400401]
	TIME [epoch: 9.25 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04874523024183515		[learning rate: 0.00098341]
	Learning Rate: 0.000983415
	LOSS [training: 0.04874523024183515 | validation: 0.059647948931692334]
	TIME [epoch: 9.28 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0436177702534222		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.0436177702534222 | validation: 0.05000197537401642]
	TIME [epoch: 9.25 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03648484411995767		[learning rate: 0.00097866]
	Learning Rate: 0.000978659
	LOSS [training: 0.03648484411995767 | validation: 0.05327792409213726]
	TIME [epoch: 9.25 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04305340206459639		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 0.04305340206459639 | validation: 0.052897545164860976]
	TIME [epoch: 9.25 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04723940260568006		[learning rate: 0.00097393]
	Learning Rate: 0.000973927
	LOSS [training: 0.04723940260568006 | validation: 0.0615602378953197]
	TIME [epoch: 9.26 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06617160643056438		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.06617160643056438 | validation: 0.05342295866265026]
	TIME [epoch: 9.26 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039363989673232805		[learning rate: 0.00096922]
	Learning Rate: 0.000969217
	LOSS [training: 0.039363989673232805 | validation: 0.042697788651758724]
	TIME [epoch: 9.25 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033281561460563394		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.033281561460563394 | validation: 0.03959042059242201]
	TIME [epoch: 9.24 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031710727949015576		[learning rate: 0.00096453]
	Learning Rate: 0.00096453
	LOSS [training: 0.031710727949015576 | validation: 0.035292970757527076]
	TIME [epoch: 9.27 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03866168605820448		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.03866168605820448 | validation: 0.08133974693650202]
	TIME [epoch: 9.25 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054781412033236485		[learning rate: 0.00095987]
	Learning Rate: 0.000959866
	LOSS [training: 0.054781412033236485 | validation: 0.054801400397149834]
	TIME [epoch: 9.25 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03233248434675171		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.03233248434675171 | validation: 0.03508183491095135]
	TIME [epoch: 9.24 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05605285602667973		[learning rate: 0.00095522]
	Learning Rate: 0.000955224
	LOSS [training: 0.05605285602667973 | validation: 0.11369719663505862]
	TIME [epoch: 9.26 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053791066192225824		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.053791066192225824 | validation: 0.04808709083446941]
	TIME [epoch: 9.26 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02587015964888742		[learning rate: 0.0009506]
	Learning Rate: 0.000950605
	LOSS [training: 0.02587015964888742 | validation: 0.027412357422002653]
	TIME [epoch: 9.25 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01772456165300719		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.01772456165300719 | validation: 0.0091088832402867]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_1072.pth
	Model improved!!!
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01445811371089328		[learning rate: 0.00094601]
	Learning Rate: 0.000946008
	LOSS [training: 0.01445811371089328 | validation: 0.03218558620711679]
	TIME [epoch: 9.26 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012943542668181197		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.012943542668181197 | validation: 0.03384326581009909]
	TIME [epoch: 9.26 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04816033664672097		[learning rate: 0.00094143]
	Learning Rate: 0.000941433
	LOSS [training: 0.04816033664672097 | validation: 0.08995878886142433]
	TIME [epoch: 9.25 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052002149033838284		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.052002149033838284 | validation: 0.07740076178523038]
	TIME [epoch: 9.24 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02833137732014887		[learning rate: 0.00093688]
	Learning Rate: 0.00093688
	LOSS [training: 0.02833137732014887 | validation: 0.024890280528047763]
	TIME [epoch: 9.24 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014779103061286034		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.014779103061286034 | validation: 0.018489642241048418]
	TIME [epoch: 9.26 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015524950854192343		[learning rate: 0.00093235]
	Learning Rate: 0.00093235
	LOSS [training: 0.015524950854192343 | validation: 0.017700531568510675]
	TIME [epoch: 9.24 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013920205826380039		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.013920205826380039 | validation: 0.044119786114405785]
	TIME [epoch: 9.25 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011907550470161123		[learning rate: 0.00092784]
	Learning Rate: 0.000927841
	LOSS [training: 0.011907550470161123 | validation: 0.008249823732569774]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_1081.pth
	Model improved!!!
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00957099878990131		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.00957099878990131 | validation: 0.02359392836199913]
	TIME [epoch: 9.28 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013424657500649284		[learning rate: 0.00092335]
	Learning Rate: 0.000923354
	LOSS [training: 0.013424657500649284 | validation: 0.0185540231424907]
	TIME [epoch: 9.25 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020409413370567314		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.020409413370567314 | validation: 0.05577746915220158]
	TIME [epoch: 9.25 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038395040024364016		[learning rate: 0.00091889]
	Learning Rate: 0.000918889
	LOSS [training: 0.038395040024364016 | validation: 0.04154984281566072]
	TIME [epoch: 9.24 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01748628037647932		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.01748628037647932 | validation: 0.036988976495408984]
	TIME [epoch: 9.27 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05179032133944787		[learning rate: 0.00091445]
	Learning Rate: 0.000914446
	LOSS [training: 0.05179032133944787 | validation: 0.03689354329225853]
	TIME [epoch: 9.25 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019799650704650625		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.019799650704650625 | validation: 0.04285100509610959]
	TIME [epoch: 9.24 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01790140573837607		[learning rate: 0.00091002]
	Learning Rate: 0.000910024
	LOSS [training: 0.01790140573837607 | validation: 0.020008632206181175]
	TIME [epoch: 9.25 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023215370073947975		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.023215370073947975 | validation: 0.032620312875109456]
	TIME [epoch: 9.28 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03022605914753091		[learning rate: 0.00090562]
	Learning Rate: 0.000905623
	LOSS [training: 0.03022605914753091 | validation: 0.042839006390638194]
	TIME [epoch: 9.25 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014479597345685397		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.014479597345685397 | validation: 0.051977216822749764]
	TIME [epoch: 9.24 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027158595289255294		[learning rate: 0.00090124]
	Learning Rate: 0.000901243
	LOSS [training: 0.027158595289255294 | validation: 0.016502791948695396]
	TIME [epoch: 9.25 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015423602126466835		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.015423602126466835 | validation: 0.031240321800563305]
	TIME [epoch: 9.27 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015533909472947378		[learning rate: 0.00089689]
	Learning Rate: 0.000896885
	LOSS [training: 0.015533909472947378 | validation: 0.017170107841934814]
	TIME [epoch: 9.26 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043828262898850744		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.043828262898850744 | validation: 0.19456241777736616]
	TIME [epoch: 9.25 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20544375611735805		[learning rate: 0.00089255]
	Learning Rate: 0.000892548
	LOSS [training: 0.20544375611735805 | validation: 0.2538106642943261]
	TIME [epoch: 9.25 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11119564272199382		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.11119564272199382 | validation: 0.033086852768576855]
	TIME [epoch: 9.27 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031676714903413034		[learning rate: 0.00088823]
	Learning Rate: 0.000888232
	LOSS [training: 0.031676714903413034 | validation: 0.057329239227307635]
	TIME [epoch: 9.25 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028360327024488652		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.028360327024488652 | validation: 0.035319153430895193]
	TIME [epoch: 9.24 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014974731184593904		[learning rate: 0.00088394]
	Learning Rate: 0.000883936
	LOSS [training: 0.014974731184593904 | validation: 0.015703558530540798]
	TIME [epoch: 9.24 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0073594351117461905		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.0073594351117461905 | validation: 0.018558441905282667]
	TIME [epoch: 9.27 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020437627840404114		[learning rate: 0.00087966]
	Learning Rate: 0.000879662
	LOSS [training: 0.020437627840404114 | validation: 0.02424251004561178]
	TIME [epoch: 9.25 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009533543873523039		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.009533543873523039 | validation: 0.009419701860900357]
	TIME [epoch: 9.24 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013614881740750252		[learning rate: 0.00087541]
	Learning Rate: 0.000875408
	LOSS [training: 0.013614881740750252 | validation: 0.0061982539323633115]
	TIME [epoch: 9.24 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_1105.pth
	Model improved!!!
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02517079132982324		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.02517079132982324 | validation: 0.07136602043289789]
	TIME [epoch: 9.27 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03143196157511526		[learning rate: 0.00087117]
	Learning Rate: 0.000871175
	LOSS [training: 0.03143196157511526 | validation: 0.011508695998666916]
	TIME [epoch: 9.25 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005628942089018369		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.005628942089018369 | validation: 0.03506137785613408]
	TIME [epoch: 9.25 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02098668648972456		[learning rate: 0.00086696]
	Learning Rate: 0.000866962
	LOSS [training: 0.02098668648972456 | validation: 0.025728936801952512]
	TIME [epoch: 9.25 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017909736530358256		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.017909736530358256 | validation: 0.03249551764141431]
	TIME [epoch: 9.26 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007672826033828151		[learning rate: 0.00086277]
	Learning Rate: 0.000862769
	LOSS [training: 0.007672826033828151 | validation: 0.016553378457506165]
	TIME [epoch: 9.25 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009786807095741647		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.009786807095741647 | validation: 0.020628404318877983]
	TIME [epoch: 9.24 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013381219279397122		[learning rate: 0.0008586]
	Learning Rate: 0.000858597
	LOSS [training: 0.013381219279397122 | validation: 0.033957512996637296]
	TIME [epoch: 9.25 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027597805276855052		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.027597805276855052 | validation: 0.031426409246890906]
	TIME [epoch: 9.26 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031172257805556908		[learning rate: 0.00085445]
	Learning Rate: 0.000854445
	LOSS [training: 0.031172257805556908 | validation: 0.07176576465777566]
	TIME [epoch: 9.25 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06163626432695999		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.06163626432695999 | validation: 0.03961748614779859]
	TIME [epoch: 9.24 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021830053218978573		[learning rate: 0.00085031]
	Learning Rate: 0.000850313
	LOSS [training: 0.021830053218978573 | validation: 0.022869235678095574]
	TIME [epoch: 9.24 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01347203649626407		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.01347203649626407 | validation: 0.029458689498550406]
	TIME [epoch: 9.26 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024417549761787068		[learning rate: 0.0008462]
	Learning Rate: 0.000846201
	LOSS [training: 0.024417549761787068 | validation: 0.032244110663902495]
	TIME [epoch: 9.25 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015566650552206443		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.015566650552206443 | validation: 0.029430185006319387]
	TIME [epoch: 9.25 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019388483205634705		[learning rate: 0.00084211]
	Learning Rate: 0.000842109
	LOSS [training: 0.019388483205634705 | validation: 0.020350192593663104]
	TIME [epoch: 9.25 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039202417694849986		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.039202417694849986 | validation: 0.03911125022457282]
	TIME [epoch: 9.27 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032363229948719		[learning rate: 0.00083804]
	Learning Rate: 0.000838037
	LOSS [training: 0.032363229948719 | validation: 0.02932218321008029]
	TIME [epoch: 9.25 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017299275227051047		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.017299275227051047 | validation: 0.016386093686516758]
	TIME [epoch: 9.24 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01273454227927422		[learning rate: 0.00083398]
	Learning Rate: 0.000833984
	LOSS [training: 0.01273454227927422 | validation: 0.02384469756255484]
	TIME [epoch: 9.24 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014424559335517192		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.014424559335517192 | validation: 0.04048144254482153]
	TIME [epoch: 9.26 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03230665521091754		[learning rate: 0.00082995]
	Learning Rate: 0.000829951
	LOSS [training: 0.03230665521091754 | validation: 0.04864384918947513]
	TIME [epoch: 9.25 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021159886071387198		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.021159886071387198 | validation: 0.01591539068895899]
	TIME [epoch: 9.25 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005667042105609645		[learning rate: 0.00082594]
	Learning Rate: 0.000825938
	LOSS [training: 0.005667042105609645 | validation: 0.017765787205497735]
	TIME [epoch: 9.24 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007925393624231064		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.007925393624231064 | validation: 0.026628956200355207]
	TIME [epoch: 9.25 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01163177825200694		[learning rate: 0.00082194]
	Learning Rate: 0.000821944
	LOSS [training: 0.01163177825200694 | validation: 0.021649841176289673]
	TIME [epoch: 9.25 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012715397597097384		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.012715397597097384 | validation: 0.012085072320726654]
	TIME [epoch: 9.25 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009494487608719715		[learning rate: 0.00081797]
	Learning Rate: 0.000817969
	LOSS [training: 0.009494487608719715 | validation: 0.006472907659283761]
	TIME [epoch: 9.25 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0158084415109132		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.0158084415109132 | validation: 0.02795523505719059]
	TIME [epoch: 9.24 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006533517542884578		[learning rate: 0.00081401]
	Learning Rate: 0.000814014
	LOSS [training: 0.006533517542884578 | validation: 0.014705075361287822]
	TIME [epoch: 9.27 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003632719602189932		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.003632719602189932 | validation: 0.01283221406931289]
	TIME [epoch: 9.24 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010999308913045593		[learning rate: 0.00081008]
	Learning Rate: 0.000810077
	LOSS [training: 0.010999308913045593 | validation: 0.008982291287686585]
	TIME [epoch: 9.24 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01304681337638019		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.01304681337638019 | validation: 0.03721118443250325]
	TIME [epoch: 9.24 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019148471048123707		[learning rate: 0.00080616]
	Learning Rate: 0.00080616
	LOSS [training: 0.019148471048123707 | validation: 0.04040568696869111]
	TIME [epoch: 9.26 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011197183463058742		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.011197183463058742 | validation: 0.015598718817250237]
	TIME [epoch: 9.24 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004687118607373962		[learning rate: 0.00080226]
	Learning Rate: 0.000802261
	LOSS [training: 0.004687118607373962 | validation: 0.010017423923804303]
	TIME [epoch: 9.23 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007163240223280312		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.007163240223280312 | validation: 0.019974714924615528]
	TIME [epoch: 9.23 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02407197711677626		[learning rate: 0.00079838]
	Learning Rate: 0.000798382
	LOSS [training: 0.02407197711677626 | validation: 0.018822402886713635]
	TIME [epoch: 9.25 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016162499776250727		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.016162499776250727 | validation: 0.033842069956579006]
	TIME [epoch: 9.24 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026072859309026412		[learning rate: 0.00079452]
	Learning Rate: 0.000794521
	LOSS [training: 0.026072859309026412 | validation: 0.11202927369712627]
	TIME [epoch: 9.24 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043087769696766955		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.043087769696766955 | validation: 0.05125101080587055]
	TIME [epoch: 9.24 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035372016038083244		[learning rate: 0.00079068]
	Learning Rate: 0.000790679
	LOSS [training: 0.035372016038083244 | validation: 0.05153291045577042]
	TIME [epoch: 9.26 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04876887498073438		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.04876887498073438 | validation: 0.029497280914322473]
	TIME [epoch: 9.24 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030037777432447017		[learning rate: 0.00078686]
	Learning Rate: 0.000786855
	LOSS [training: 0.030037777432447017 | validation: 0.046060878492725395]
	TIME [epoch: 9.23 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01274173496784852		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.01274173496784852 | validation: 0.018445444638932947]
	TIME [epoch: 9.23 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01436997399864667		[learning rate: 0.00078305]
	Learning Rate: 0.00078305
	LOSS [training: 0.01436997399864667 | validation: 0.03442221270626528]
	TIME [epoch: 9.25 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042960454523346445		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.042960454523346445 | validation: 0.0799758811519124]
	TIME [epoch: 9.24 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039604674368934466		[learning rate: 0.00077926]
	Learning Rate: 0.000779263
	LOSS [training: 0.039604674368934466 | validation: 0.021529200069280455]
	TIME [epoch: 9.24 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011720774239531962		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.011720774239531962 | validation: 0.019611664813901298]
	TIME [epoch: 9.24 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005392504537385915		[learning rate: 0.00077549]
	Learning Rate: 0.000775495
	LOSS [training: 0.005392504537385915 | validation: -0.0009310268740620083]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_1155.pth
	Model improved!!!
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015259890885204372		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.0015259890885204372 | validation: 0.0065991577522441155]
	TIME [epoch: 9.25 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0042760661701788895		[learning rate: 0.00077174]
	Learning Rate: 0.000771745
	LOSS [training: 0.0042760661701788895 | validation: 0.017458659002476735]
	TIME [epoch: 9.24 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011357586696335135		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.011357586696335135 | validation: 0.02850877274071722]
	TIME [epoch: 9.24 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02719059632544852		[learning rate: 0.00076801]
	Learning Rate: 0.000768013
	LOSS [training: 0.02719059632544852 | validation: 0.03241161253257764]
	TIME [epoch: 9.26 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032352394229303416		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.032352394229303416 | validation: 0.03234046737117339]
	TIME [epoch: 9.25 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02176223547497172		[learning rate: 0.0007643]
	Learning Rate: 0.000764299
	LOSS [training: 0.02176223547497172 | validation: 0.03082258656948376]
	TIME [epoch: 9.24 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019717007036153616		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.019717007036153616 | validation: 0.05143523501361437]
	TIME [epoch: 9.23 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02750047472775824		[learning rate: 0.0007606]
	Learning Rate: 0.000760603
	LOSS [training: 0.02750047472775824 | validation: 0.04302663307185382]
	TIME [epoch: 9.26 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02765487542562034		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.02765487542562034 | validation: 0.04728786461379467]
	TIME [epoch: 9.24 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03726844501459407		[learning rate: 0.00075692]
	Learning Rate: 0.000756925
	LOSS [training: 0.03726844501459407 | validation: 0.05785387985673021]
	TIME [epoch: 9.25 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05644948548214198		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.05644948548214198 | validation: 0.060965641615881194]
	TIME [epoch: 9.24 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04816774229588584		[learning rate: 0.00075326]
	Learning Rate: 0.000753264
	LOSS [training: 0.04816774229588584 | validation: 0.04789923435902198]
	TIME [epoch: 9.25 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03741111852214725		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.03741111852214725 | validation: 0.0358530389132825]
	TIME [epoch: 9.25 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0330493156076115		[learning rate: 0.00074962]
	Learning Rate: 0.000749622
	LOSS [training: 0.0330493156076115 | validation: 0.037337986536500445]
	TIME [epoch: 9.24 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0354140849564197		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.0354140849564197 | validation: 0.03732474024390335]
	TIME [epoch: 9.24 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03126482001741475		[learning rate: 0.000746]
	Learning Rate: 0.000745997
	LOSS [training: 0.03126482001741475 | validation: 0.050291463688679316]
	TIME [epoch: 9.26 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03151563416744552		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.03151563416744552 | validation: 0.03469550221676248]
	TIME [epoch: 9.25 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04319744088979803		[learning rate: 0.00074239]
	Learning Rate: 0.000742389
	LOSS [training: 0.04319744088979803 | validation: 0.04481978441690053]
	TIME [epoch: 9.25 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035424638063927844		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.035424638063927844 | validation: 0.04050782350630986]
	TIME [epoch: 9.25 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03156725779098494		[learning rate: 0.0007388]
	Learning Rate: 0.000738799
	LOSS [training: 0.03156725779098494 | validation: 0.041759886293682234]
	TIME [epoch: 9.25 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031133022335767896		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.031133022335767896 | validation: 0.0403323829135506]
	TIME [epoch: 9.26 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027083654670527313		[learning rate: 0.00073523]
	Learning Rate: 0.000735226
	LOSS [training: 0.027083654670527313 | validation: 0.02724188925659365]
	TIME [epoch: 9.24 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02456203080655755		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.02456203080655755 | validation: 0.02719724849253008]
	TIME [epoch: 9.24 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022243298846639295		[learning rate: 0.00073167]
	Learning Rate: 0.000731671
	LOSS [training: 0.022243298846639295 | validation: 0.03796797383901791]
	TIME [epoch: 9.24 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023955251355468693		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.023955251355468693 | validation: 0.03472350648580008]
	TIME [epoch: 9.25 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02230755023164713		[learning rate: 0.00072813]
	Learning Rate: 0.000728133
	LOSS [training: 0.02230755023164713 | validation: 0.03258780247412297]
	TIME [epoch: 9.24 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02737900237111924		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.02737900237111924 | validation: 0.044975112418803115]
	TIME [epoch: 9.24 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020875721598028075		[learning rate: 0.00072461]
	Learning Rate: 0.000724612
	LOSS [training: 0.020875721598028075 | validation: 0.0318490926211063]
	TIME [epoch: 9.24 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020913360193823036		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.020913360193823036 | validation: 0.029585496730451313]
	TIME [epoch: 9.27 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02858867839227831		[learning rate: 0.00072111]
	Learning Rate: 0.000721107
	LOSS [training: 0.02858867839227831 | validation: 0.0377783851698808]
	TIME [epoch: 9.25 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045665034826394904		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.045665034826394904 | validation: 0.08048313457741003]
	TIME [epoch: 9.25 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04936045549473368		[learning rate: 0.00071762]
	Learning Rate: 0.00071762
	LOSS [training: 0.04936045549473368 | validation: 0.03941019109521945]
	TIME [epoch: 9.25 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040033460705229736		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.040033460705229736 | validation: 0.03890701188438337]
	TIME [epoch: 9.26 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04495295393491679		[learning rate: 0.00071415]
	Learning Rate: 0.00071415
	LOSS [training: 0.04495295393491679 | validation: 0.06553507629179851]
	TIME [epoch: 9.24 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041874418840346816		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.041874418840346816 | validation: 0.03995992614415056]
	TIME [epoch: 9.23 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0348053639357409		[learning rate: 0.0007107]
	Learning Rate: 0.000710697
	LOSS [training: 0.0348053639357409 | validation: 0.057257852789026314]
	TIME [epoch: 9.24 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03638612234927095		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.03638612234927095 | validation: 0.05419245861312779]
	TIME [epoch: 9.27 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04083347415781967		[learning rate: 0.00070726]
	Learning Rate: 0.00070726
	LOSS [training: 0.04083347415781967 | validation: 0.040161274143110846]
	TIME [epoch: 9.25 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03566819433853093		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.03566819433853093 | validation: 0.06644158126038788]
	TIME [epoch: 9.24 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04461538329532437		[learning rate: 0.00070384]
	Learning Rate: 0.00070384
	LOSS [training: 0.04461538329532437 | validation: 0.08567512025881532]
	TIME [epoch: 9.23 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035406455388754796		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.035406455388754796 | validation: 0.03549690071501273]
	TIME [epoch: 9.26 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026536186736963514		[learning rate: 0.00070044]
	Learning Rate: 0.000700436
	LOSS [training: 0.026536186736963514 | validation: 0.0330133123533128]
	TIME [epoch: 9.25 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027192584451295083		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.027192584451295083 | validation: 0.06604384049582854]
	TIME [epoch: 9.25 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029305508858233686		[learning rate: 0.00069705]
	Learning Rate: 0.000697049
	LOSS [training: 0.029305508858233686 | validation: 0.04489756551501069]
	TIME [epoch: 9.25 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02342654154230226		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.02342654154230226 | validation: 0.03219590121433554]
	TIME [epoch: 9.27 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022057706838793215		[learning rate: 0.00069368]
	Learning Rate: 0.000693678
	LOSS [training: 0.022057706838793215 | validation: 0.03178118748849562]
	TIME [epoch: 9.25 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014184963032570589		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.014184963032570589 | validation: 0.03253296022539914]
	TIME [epoch: 9.24 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03732653673368206		[learning rate: 0.00069032]
	Learning Rate: 0.000690324
	LOSS [training: 0.03732653673368206 | validation: 0.0346190817421177]
	TIME [epoch: 9.24 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01720618391174425		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.01720618391174425 | validation: 0.02983670703989336]
	TIME [epoch: 9.26 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01339791732427878		[learning rate: 0.00068699]
	Learning Rate: 0.000686985
	LOSS [training: 0.01339791732427878 | validation: 0.02379170224797332]
	TIME [epoch: 9.24 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011621729268651498		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.011621729268651498 | validation: 0.014487159819599166]
	TIME [epoch: 9.25 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008588352615066368		[learning rate: 0.00068366]
	Learning Rate: 0.000683663
	LOSS [training: 0.008588352615066368 | validation: 0.042860287784131534]
	TIME [epoch: 9.24 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02151379225189928		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.02151379225189928 | validation: 0.0326815414415415]
	TIME [epoch: 9.25 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014111253971808114		[learning rate: 0.00068036]
	Learning Rate: 0.000680357
	LOSS [training: 0.014111253971808114 | validation: 0.012638065983405986]
	TIME [epoch: 9.24 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012371909661848531		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.012371909661848531 | validation: 0.02867809643709705]
	TIME [epoch: 9.25 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019443077340920906		[learning rate: 0.00067707]
	Learning Rate: 0.000677067
	LOSS [training: 0.019443077340920906 | validation: 0.040813260215887326]
	TIME [epoch: 9.25 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027281402522476246		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.027281402522476246 | validation: 0.030237645698885297]
	TIME [epoch: 9.26 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022684987500352412		[learning rate: 0.00067379]
	Learning Rate: 0.000673793
	LOSS [training: 0.022684987500352412 | validation: 0.023895219458344358]
	TIME [epoch: 9.25 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014162719227062151		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.014162719227062151 | validation: 0.025772845894872103]
	TIME [epoch: 9.23 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01538769322298721		[learning rate: 0.00067053]
	Learning Rate: 0.000670534
	LOSS [training: 0.01538769322298721 | validation: 0.009291548324501228]
	TIME [epoch: 9.24 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004969079001691327		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.004969079001691327 | validation: 0.00770733771486206]
	TIME [epoch: 9.25 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006620815301203555		[learning rate: 0.00066729]
	Learning Rate: 0.000667292
	LOSS [training: 0.006620815301203555 | validation: 0.024346493698214254]
	TIME [epoch: 9.25 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010431469135639427		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.010431469135639427 | validation: 0.00030165981995148314]
	TIME [epoch: 9.24 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007806541549333254		[learning rate: 0.00066406]
	Learning Rate: 0.000664065
	LOSS [training: 0.007806541549333254 | validation: 0.008680660579340558]
	TIME [epoch: 9.24 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014660122295697029		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.014660122295697029 | validation: 0.020736547896373934]
	TIME [epoch: 9.26 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012867441109579708		[learning rate: 0.00066085]
	Learning Rate: 0.000660854
	LOSS [training: 0.012867441109579708 | validation: 0.014890800262490109]
	TIME [epoch: 9.25 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010337011390666803		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.010337011390666803 | validation: 0.012468939996522047]
	TIME [epoch: 9.24 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004294808808505524		[learning rate: 0.00065766]
	Learning Rate: 0.000657658
	LOSS [training: 0.004294808808505524 | validation: 0.022586615686638976]
	TIME [epoch: 9.25 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02195186335584911		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.02195186335584911 | validation: 0.024389866132631235]
	TIME [epoch: 9.25 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05488947751434155		[learning rate: 0.00065448]
	Learning Rate: 0.000654478
	LOSS [training: 0.05488947751434155 | validation: 0.06461019326653224]
	TIME [epoch: 9.26 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04327373346081685		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.04327373346081685 | validation: 0.025374950112376178]
	TIME [epoch: 9.24 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009108093073228329		[learning rate: 0.00065131]
	Learning Rate: 0.000651313
	LOSS [training: 0.009108093073228329 | validation: 0.011557715792271914]
	TIME [epoch: 9.25 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011647054994464801		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.011647054994464801 | validation: 0.023510035333097715]
	TIME [epoch: 9.24 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02527824378769558		[learning rate: 0.00064816]
	Learning Rate: 0.000648163
	LOSS [training: 0.02527824378769558 | validation: 0.004808366089341098]
	TIME [epoch: 9.27 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018906824925006286		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.018906824925006286 | validation: 0.03297466150452596]
	TIME [epoch: 9.24 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01884234137087219		[learning rate: 0.00064503]
	Learning Rate: 0.000645029
	LOSS [training: 0.01884234137087219 | validation: 0.0236033843068056]
	TIME [epoch: 9.25 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014718885494859427		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.014718885494859427 | validation: 0.03250162270045198]
	TIME [epoch: 9.24 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007554157330053568		[learning rate: 0.00064191]
	Learning Rate: 0.000641909
	LOSS [training: 0.007554157330053568 | validation: 0.023210938940218473]
	TIME [epoch: 9.27 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009198493853551891		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.009198493853551891 | validation: 0.015206031435567242]
	TIME [epoch: 9.24 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007651561008111438		[learning rate: 0.00063881]
	Learning Rate: 0.000638805
	LOSS [training: 0.007651561008111438 | validation: 0.007702192362630346]
	TIME [epoch: 9.25 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01050014440767407		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.01050014440767407 | validation: 0.015246269944352766]
	TIME [epoch: 9.25 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012853080526495506		[learning rate: 0.00063572]
	Learning Rate: 0.000635716
	LOSS [training: 0.012853080526495506 | validation: 0.025251035959549695]
	TIME [epoch: 9.27 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0037551468172504396		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.0037551468172504396 | validation: 0.0117574759501493]
	TIME [epoch: 9.25 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013876147155867925		[learning rate: 0.00063264]
	Learning Rate: 0.000632642
	LOSS [training: 0.013876147155867925 | validation: 0.01293390265551117]
	TIME [epoch: 9.24 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009313122745637416		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.009313122745637416 | validation: 0.010010302419851017]
	TIME [epoch: 9.24 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0023956788910159317		[learning rate: 0.00062958]
	Learning Rate: 0.000629582
	LOSS [training: 0.0023956788910159317 | validation: 0.02983476286520035]
	TIME [epoch: 9.25 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013247355854373477		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.013247355854373477 | validation: 0.023440198641399228]
	TIME [epoch: 9.25 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014094193086481927		[learning rate: 0.00062654]
	Learning Rate: 0.000626538
	LOSS [training: 0.014094193086481927 | validation: 0.04368525790802473]
	TIME [epoch: 9.24 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012414904039336993		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.012414904039336993 | validation: 0.023553598722009163]
	TIME [epoch: 9.25 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008812497726631643		[learning rate: 0.00062351]
	Learning Rate: 0.000623508
	LOSS [training: 0.008812497726631643 | validation: -0.0031081912716719954]
	TIME [epoch: 9.27 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_1245.pth
	Model improved!!!
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00566253933149754		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.00566253933149754 | validation: 0.011129739222359054]
	TIME [epoch: 9.25 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001684945100760447		[learning rate: 0.00062049]
	Learning Rate: 0.000620493
	LOSS [training: 0.001684945100760447 | validation: 0.032846219817863835]
	TIME [epoch: 9.24 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03295375695509968		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.03295375695509968 | validation: 0.06680123355003958]
	TIME [epoch: 9.24 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061038717632990194		[learning rate: 0.00061749]
	Learning Rate: 0.000617492
	LOSS [training: 0.061038717632990194 | validation: 0.061451513464889834]
	TIME [epoch: 9.27 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02295469406399422		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.02295469406399422 | validation: 0.03714623298964499]
	TIME [epoch: 9.26 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0028833352091710606		[learning rate: 0.00061451]
	Learning Rate: 0.000614506
	LOSS [training: 0.0028833352091710606 | validation: -0.0017985854494362709]
	TIME [epoch: 9.25 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0021808773674001744		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: -0.0021808773674001744 | validation: 0.008558538950784345]
	TIME [epoch: 9.24 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006464616765111103		[learning rate: 0.00061153]
	Learning Rate: 0.000611535
	LOSS [training: 0.006464616765111103 | validation: 0.044862622628832685]
	TIME [epoch: 9.26 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01998749485125483		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.01998749485125483 | validation: 0.021229606981492385]
	TIME [epoch: 9.25 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004205278561177977		[learning rate: 0.00060858]
	Learning Rate: 0.000608577
	LOSS [training: 0.004205278561177977 | validation: 0.019066525549828378]
	TIME [epoch: 9.24 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02339284641529917		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.02339284641529917 | validation: 0.06795608531700223]
	TIME [epoch: 9.24 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06684080643828641		[learning rate: 0.00060563]
	Learning Rate: 0.000605634
	LOSS [training: 0.06684080643828641 | validation: 0.09141800979080814]
	TIME [epoch: 9.27 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0403407283279843		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.0403407283279843 | validation: 0.02855323519453378]
	TIME [epoch: 9.25 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012329738134370868		[learning rate: 0.00060271]
	Learning Rate: 0.000602706
	LOSS [training: 0.012329738134370868 | validation: 0.04710882259200479]
	TIME [epoch: 9.24 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024760426081137366		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.024760426081137366 | validation: 0.023070275511519862]
	TIME [epoch: 9.24 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012874020430021097		[learning rate: 0.00059979]
	Learning Rate: 0.000599791
	LOSS [training: 0.012874020430021097 | validation: 0.015164889517023883]
	TIME [epoch: 9.26 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014024277400317953		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.0014024277400317953 | validation: 0.02050848706375185]
	TIME [epoch: 9.26 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011304770037168668		[learning rate: 0.00059689]
	Learning Rate: 0.000596891
	LOSS [training: 0.011304770037168668 | validation: 0.013752473922295404]
	TIME [epoch: 9.25 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018711270451718713		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.018711270451718713 | validation: 0.03385905857107176]
	TIME [epoch: 9.25 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01830658984517454		[learning rate: 0.000594]
	Learning Rate: 0.000594004
	LOSS [training: 0.01830658984517454 | validation: 0.013380514763265074]
	TIME [epoch: 9.26 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01631542110740148		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.01631542110740148 | validation: 0.02230638325763915]
	TIME [epoch: 9.24 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010265594651474384		[learning rate: 0.00059113]
	Learning Rate: 0.000591132
	LOSS [training: 0.010265594651474384 | validation: 0.022100302333836135]
	TIME [epoch: 9.24 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008756339946761161		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.008756339946761161 | validation: 0.019696667205525133]
	TIME [epoch: 9.24 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008325353721038195		[learning rate: 0.00058827]
	Learning Rate: 0.000588273
	LOSS [training: 0.008325353721038195 | validation: 0.006613223993476653]
	TIME [epoch: 9.26 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0063540940040054065		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.0063540940040054065 | validation: 0.01453189672871771]
	TIME [epoch: 9.25 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012101977074572359		[learning rate: 0.00058543]
	Learning Rate: 0.000585428
	LOSS [training: 0.012101977074572359 | validation: 0.027382952452628697]
	TIME [epoch: 9.24 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005702807551285813		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.005702807551285813 | validation: 0.023492754844169253]
	TIME [epoch: 9.24 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009571560060930354		[learning rate: 0.0005826]
	Learning Rate: 0.000582597
	LOSS [training: 0.009571560060930354 | validation: 0.00900795662118393]
	TIME [epoch: 9.26 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029755223422585136		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.0029755223422585136 | validation: -0.0002867448276118556]
	TIME [epoch: 9.25 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003730048778990224		[learning rate: 0.00057978]
	Learning Rate: 0.00057978
	LOSS [training: 0.003730048778990224 | validation: 0.009777465319191353]
	TIME [epoch: 9.25 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012189358644817894		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.012189358644817894 | validation: 0.02006102850221719]
	TIME [epoch: 9.25 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004573886381467359		[learning rate: 0.00057698]
	Learning Rate: 0.000576976
	LOSS [training: 0.004573886381467359 | validation: -0.004328868604754358]
	TIME [epoch: 9.25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_1277.pth
	Model improved!!!
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00019305769255528903		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.00019305769255528903 | validation: 0.012509426806341734]
	TIME [epoch: 9.27 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006781451150060448		[learning rate: 0.00057419]
	Learning Rate: 0.000574186
	LOSS [training: 0.006781451150060448 | validation: 0.006821934333337137]
	TIME [epoch: 9.25 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007490589563867464		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.007490589563867464 | validation: 0.00759982641266936]
	TIME [epoch: 9.25 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007927846219085159		[learning rate: 0.00057141]
	Learning Rate: 0.000571409
	LOSS [training: 0.007927846219085159 | validation: 0.012454318012140864]
	TIME [epoch: 9.25 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007878684144574485		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.007878684144574485 | validation: 0.007984014835281874]
	TIME [epoch: 9.26 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019269925694787283		[learning rate: 0.00056865]
	Learning Rate: 0.000568646
	LOSS [training: 0.0019269925694787283 | validation: 0.006496944856392949]
	TIME [epoch: 9.25 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005145618925198398		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.0005145618925198398 | validation: 0.01691355230933845]
	TIME [epoch: 9.25 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015330166605333529		[learning rate: 0.0005659]
	Learning Rate: 0.000565896
	LOSS [training: 0.015330166605333529 | validation: 0.020145550111573016]
	TIME [epoch: 9.24 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004145773916304269		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.004145773916304269 | validation: 0.004139975882410018]
	TIME [epoch: 9.27 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02223625183762972		[learning rate: 0.00056316]
	Learning Rate: 0.00056316
	LOSS [training: 0.02223625183762972 | validation: 0.03211890426397693]
	TIME [epoch: 9.25 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01564788787671141		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.01564788787671141 | validation: 0.02198058431666368]
	TIME [epoch: 9.25 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00933506234276878		[learning rate: 0.00056044]
	Learning Rate: 0.000560436
	LOSS [training: 0.00933506234276878 | validation: 0.014027208828585908]
	TIME [epoch: 9.25 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019223928133339317		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.019223928133339317 | validation: 0.019807091414069798]
	TIME [epoch: 9.27 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01466963702211498		[learning rate: 0.00055773]
	Learning Rate: 0.000557726
	LOSS [training: 0.01466963702211498 | validation: 0.014999478609374818]
	TIME [epoch: 9.25 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009776820694660177		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.009776820694660177 | validation: 0.014659806229365833]
	TIME [epoch: 9.25 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005902629047569663		[learning rate: 0.00055503]
	Learning Rate: 0.000555029
	LOSS [training: 0.005902629047569663 | validation: 0.018729172081708743]
	TIME [epoch: 9.25 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016357895157094814		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.016357895157094814 | validation: 0.02918437316900279]
	TIME [epoch: 9.26 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015625976188439413		[learning rate: 0.00055235]
	Learning Rate: 0.000552345
	LOSS [training: 0.015625976188439413 | validation: 0.01872039364134947]
	TIME [epoch: 9.25 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011682898227637779		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.011682898227637779 | validation: 0.026692147361228047]
	TIME [epoch: 9.24 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02389056203568992		[learning rate: 0.00054967]
	Learning Rate: 0.000549674
	LOSS [training: 0.02389056203568992 | validation: 0.025033669205861107]
	TIME [epoch: 9.24 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023547630560452802		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.023547630560452802 | validation: 0.02363913128807172]
	TIME [epoch: 9.26 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020415522395870408		[learning rate: 0.00054702]
	Learning Rate: 0.000547016
	LOSS [training: 0.020415522395870408 | validation: 0.017848131236205857]
	TIME [epoch: 9.24 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021842959103252978		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.021842959103252978 | validation: 0.029566776340142487]
	TIME [epoch: 9.25 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02272997213004757		[learning rate: 0.00054437]
	Learning Rate: 0.000544371
	LOSS [training: 0.02272997213004757 | validation: 0.0198610457543514]
	TIME [epoch: 9.25 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025739548563483004		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.025739548563483004 | validation: 0.02938185492749701]
	TIME [epoch: 9.28 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021933049153395882		[learning rate: 0.00054174]
	Learning Rate: 0.000541738
	LOSS [training: 0.021933049153395882 | validation: 0.0311384245183977]
	TIME [epoch: 9.25 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012598662578381072		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.012598662578381072 | validation: 0.014037463198619256]
	TIME [epoch: 9.25 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014040909853784495		[learning rate: 0.00053912]
	Learning Rate: 0.000539118
	LOSS [training: 0.014040909853784495 | validation: 0.04398383542798977]
	TIME [epoch: 9.25 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019510086275441874		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.019510086275441874 | validation: 0.03148185315030545]
	TIME [epoch: 9.26 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014529834450771963		[learning rate: 0.00053651]
	Learning Rate: 0.000536511
	LOSS [training: 0.014529834450771963 | validation: 0.02654878699085502]
	TIME [epoch: 9.25 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010084277061656913		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.010084277061656913 | validation: 0.017521530433364484]
	TIME [epoch: 9.25 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015325481635166593		[learning rate: 0.00053392]
	Learning Rate: 0.000533917
	LOSS [training: 0.015325481635166593 | validation: 0.03984008507657675]
	TIME [epoch: 9.24 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012173080761194102		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.012173080761194102 | validation: 0.023161958781089877]
	TIME [epoch: 9.26 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011624505599516045		[learning rate: 0.00053134]
	Learning Rate: 0.000531335
	LOSS [training: 0.011624505599516045 | validation: 0.02410078726598742]
	TIME [epoch: 9.25 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007787221316015383		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.007787221316015383 | validation: 0.0179896900564921]
	TIME [epoch: 9.25 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019363588055714153		[learning rate: 0.00052877]
	Learning Rate: 0.000528766
	LOSS [training: 0.019363588055714153 | validation: 0.014789724797146676]
	TIME [epoch: 9.24 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005291561411988504		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.005291561411988504 | validation: 0.01641049225575248]
	TIME [epoch: 9.26 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009522968462798135		[learning rate: 0.00052621]
	Learning Rate: 0.000526208
	LOSS [training: 0.009522968462798135 | validation: 4.074889464341768e-05]
	TIME [epoch: 9.25 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008130575313844856		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.008130575313844856 | validation: 0.0058008069526327265]
	TIME [epoch: 9.24 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006706519511620311		[learning rate: 0.00052366]
	Learning Rate: 0.000523664
	LOSS [training: 0.006706519511620311 | validation: -0.0007601516348022025]
	TIME [epoch: 9.24 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001852606407341412		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.001852606407341412 | validation: 0.015520589009097429]
	TIME [epoch: 9.26 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009767048261410006		[learning rate: 0.00052113]
	Learning Rate: 0.000521132
	LOSS [training: 0.0009767048261410006 | validation: 0.016552072882383584]
	TIME [epoch: 9.25 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029575004590800848		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.0029575004590800848 | validation: 0.016271015580051444]
	TIME [epoch: 9.25 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0033502764969919113		[learning rate: 0.00051861]
	Learning Rate: 0.000518611
	LOSS [training: 0.0033502764969919113 | validation: 0.025083702989669825]
	TIME [epoch: 9.24 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011087697075014726		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.011087697075014726 | validation: 0.004743145046113014]
	TIME [epoch: 9.25 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003876527105112384		[learning rate: 0.0005161]
	Learning Rate: 0.000516104
	LOSS [training: 0.003876527105112384 | validation: 0.0011526157713897412]
	TIME [epoch: 9.26 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00241605682287097		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.00241605682287097 | validation: 0.02251448211629132]
	TIME [epoch: 9.24 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006299335543617199		[learning rate: 0.00051361]
	Learning Rate: 0.000513608
	LOSS [training: 0.006299335543617199 | validation: 0.011544779068334024]
	TIME [epoch: 9.25 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0051229019433088555		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.0051229019433088555 | validation: 0.019172503800275652]
	TIME [epoch: 9.26 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017103899681686668		[learning rate: 0.00051112]
	Learning Rate: 0.000511124
	LOSS [training: 0.017103899681686668 | validation: 0.02761917215438342]
	TIME [epoch: 9.26 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008287581778063127		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.008287581778063127 | validation: 0.03202503614334433]
	TIME [epoch: 9.25 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011912253313858335		[learning rate: 0.00050865]
	Learning Rate: 0.000508652
	LOSS [training: 0.011912253313858335 | validation: 0.015427788218989828]
	TIME [epoch: 9.25 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003657233778709661		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.003657233778709661 | validation: 0.014698663853726108]
	TIME [epoch: 9.24 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004619053757284845		[learning rate: 0.00050619]
	Learning Rate: 0.000506193
	LOSS [training: 0.004619053757284845 | validation: 0.011629061286789685]
	TIME [epoch: 9.27 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019713864804443544		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.019713864804443544 | validation: 0.04829070973291727]
	TIME [epoch: 9.24 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01697614365566958		[learning rate: 0.00050374]
	Learning Rate: 0.000503745
	LOSS [training: 0.01697614365566958 | validation: 0.022036785938269444]
	TIME [epoch: 9.24 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009624574631168092		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.009624574631168092 | validation: 0.008074406781952006]
	TIME [epoch: 9.24 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008893225639481928		[learning rate: 0.00050131]
	Learning Rate: 0.000501309
	LOSS [training: 0.0008893225639481928 | validation: 0.009338165019127934]
	TIME [epoch: 9.27 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: -7.659730341384591e-05		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: -7.659730341384591e-05 | validation: 0.004729387324035126]
	TIME [epoch: 9.25 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007402310510956386		[learning rate: 0.00049888]
	Learning Rate: 0.000498885
	LOSS [training: 0.007402310510956386 | validation: 0.010526677023477135]
	TIME [epoch: 9.24 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001004791079486975		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.001004791079486975 | validation: 0.030673531974498167]
	TIME [epoch: 9.25 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02036898722085174		[learning rate: 0.00049647]
	Learning Rate: 0.000496472
	LOSS [training: 0.02036898722085174 | validation: 0.022288449082587713]
	TIME [epoch: 9.27 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0062123672226749		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.0062123672226749 | validation: 0.04115963636060278]
	TIME [epoch: 9.25 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014573208801012668		[learning rate: 0.00049407]
	Learning Rate: 0.000494071
	LOSS [training: 0.014573208801012668 | validation: 0.02174504260803324]
	TIME [epoch: 9.25 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014917345343535162		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.014917345343535162 | validation: 0.04881456461280549]
	TIME [epoch: 9.26 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027432304745965103		[learning rate: 0.00049168]
	Learning Rate: 0.000491682
	LOSS [training: 0.027432304745965103 | validation: 0.039720386559515236]
	TIME [epoch: 9.27 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034385053559558065		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.034385053559558065 | validation: 0.08753650195502899]
	TIME [epoch: 9.25 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03243543112010006		[learning rate: 0.0004893]
	Learning Rate: 0.000489304
	LOSS [training: 0.03243543112010006 | validation: 0.057306572562045244]
	TIME [epoch: 9.25 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018934002105811504		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.018934002105811504 | validation: 0.016312571418909492]
	TIME [epoch: 9.26 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008757400798409243		[learning rate: 0.00048694]
	Learning Rate: 0.000486938
	LOSS [training: 0.008757400798409243 | validation: 0.011170011321119]
	TIME [epoch: 9.27 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011724525976367915		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.011724525976367915 | validation: 0.013048465898532577]
	TIME [epoch: 9.25 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012504560780957902		[learning rate: 0.00048458]
	Learning Rate: 0.000484583
	LOSS [training: 0.012504560780957902 | validation: 0.028347783975711933]
	TIME [epoch: 9.25 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008889233768366466		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.008889233768366466 | validation: 0.009372523015595484]
	TIME [epoch: 9.25 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00011606983949969101		[learning rate: 0.00048224]
	Learning Rate: 0.00048224
	LOSS [training: -0.00011606983949969101 | validation: 0.0076292936655291054]
	TIME [epoch: 9.27 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007219422868899787		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.007219422868899787 | validation: 0.01665103309166901]
	TIME [epoch: 9.26 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029232701553166397		[learning rate: 0.00047991]
	Learning Rate: 0.000479908
	LOSS [training: 0.0029232701553166397 | validation: 0.0128371650120357]
	TIME [epoch: 9.25 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0019633207348418		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: -0.0019633207348418 | validation: 0.004072880335786701]
	TIME [epoch: 9.25 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017507736308231651		[learning rate: 0.00047759]
	Learning Rate: 0.000477587
	LOSS [training: 0.0017507736308231651 | validation: 0.02124360469802372]
	TIME [epoch: 9.27 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0098485234985313		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.0098485234985313 | validation: 0.023932686477108216]
	TIME [epoch: 9.25 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007670348095597419		[learning rate: 0.00047528]
	Learning Rate: 0.000475278
	LOSS [training: 0.007670348095597419 | validation: 0.015732849342282283]
	TIME [epoch: 9.24 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002882396864182234		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.002882396864182234 | validation: 0.0033839501140393337]
	TIME [epoch: 9.24 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0065410629367196604		[learning rate: 0.00047298]
	Learning Rate: 0.000472979
	LOSS [training: 0.0065410629367196604 | validation: 0.006218011528630427]
	TIME [epoch: 9.26 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007976942232663148		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.007976942232663148 | validation: 0.0012544392274769305]
	TIME [epoch: 9.25 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.870818547145911e-06		[learning rate: 0.00047069]
	Learning Rate: 0.000470692
	LOSS [training: 4.870818547145911e-06 | validation: 0.00955741988866528]
	TIME [epoch: 9.25 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00019125083888612911		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: -0.00019125083888612911 | validation: 0.0024982530684465416]
	TIME [epoch: 9.25 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0044029723462355825		[learning rate: 0.00046842]
	Learning Rate: 0.000468416
	LOSS [training: -0.0044029723462355825 | validation: 0.001409623908643768]
	TIME [epoch: 9.26 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005032728486609796		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: -0.0005032728486609796 | validation: 0.013297627795599598]
	TIME [epoch: 9.25 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00034048199878785115		[learning rate: 0.00046615]
	Learning Rate: 0.000466151
	LOSS [training: -0.00034048199878785115 | validation: 0.0005321647969263482]
	TIME [epoch: 9.25 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.873325950550237e-05		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 8.873325950550237e-05 | validation: 0.010166827462252288]
	TIME [epoch: 9.25 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006013541182660184		[learning rate: 0.0004639]
	Learning Rate: 0.000463896
	LOSS [training: 0.0006013541182660184 | validation: 0.0075113614758370965]
	TIME [epoch: 9.27 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: -2.0968905091670085e-05		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: -2.0968905091670085e-05 | validation: 0.0017115277572783798]
	TIME [epoch: 9.25 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004711252666247848		[learning rate: 0.00046165]
	Learning Rate: 0.000461653
	LOSS [training: 0.004711252666247848 | validation: 0.010768587848703055]
	TIME [epoch: 9.24 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01258035503790407		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.01258035503790407 | validation: 0.08358145684372764]
	TIME [epoch: 9.25 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0377246051168728		[learning rate: 0.00045942]
	Learning Rate: 0.000459421
	LOSS [training: 0.0377246051168728 | validation: 0.022980167019705733]
	TIME [epoch: 9.25 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012740838586325734		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.012740838586325734 | validation: 0.027248511748461872]
	TIME [epoch: 9.26 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011353775246836789		[learning rate: 0.0004572]
	Learning Rate: 0.000457199
	LOSS [training: 0.011353775246836789 | validation: 0.017183173964356667]
	TIME [epoch: 9.25 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008386168601263445		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.008386168601263445 | validation: 0.015575043869502975]
	TIME [epoch: 9.24 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013129212357494322		[learning rate: 0.00045499]
	Learning Rate: 0.000454988
	LOSS [training: 0.013129212357494322 | validation: 0.021671543964342545]
	TIME [epoch: 9.25 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01105063577012946		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: 0.01105063577012946 | validation: 0.004290998782386674]
	TIME [epoch: 9.26 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010662678286542849		[learning rate: 0.00045279]
	Learning Rate: 0.000452788
	LOSS [training: 0.010662678286542849 | validation: 0.024089474156683915]
	TIME [epoch: 9.24 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022793205711978425		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.022793205711978425 | validation: 0.03594032059679987]
	TIME [epoch: 9.25 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02828440793758775		[learning rate: 0.0004506]
	Learning Rate: 0.000450598
	LOSS [training: 0.02828440793758775 | validation: 0.019204477271662385]
	TIME [epoch: 9.25 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017184255798393774		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: 0.017184255798393774 | validation: 0.020907135209605]
	TIME [epoch: 9.28 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008426329750474757		[learning rate: 0.00044842]
	Learning Rate: 0.000448419
	LOSS [training: 0.008426329750474757 | validation: 0.011750038725979437]
	TIME [epoch: 9.25 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019131968584692907		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.0019131968584692907 | validation: 0.014884157932828327]
	TIME [epoch: 9.25 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0059244204666206255		[learning rate: 0.00044625]
	Learning Rate: 0.000446251
	LOSS [training: 0.0059244204666206255 | validation: 0.025122266745047216]
	TIME [epoch: 9.24 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005012202660173144		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.005012202660173144 | validation: 0.01060920092758703]
	TIME [epoch: 9.27 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004014943905337757		[learning rate: 0.00044409]
	Learning Rate: 0.000444093
	LOSS [training: 0.004014943905337757 | validation: 0.00528171097659773]
	TIME [epoch: 9.25 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004306616160294253		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: 0.004306616160294253 | validation: -0.0003504368173030281]
	TIME [epoch: 9.26 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004688835788023102		[learning rate: 0.00044195]
	Learning Rate: 0.000441945
	LOSS [training: 0.004688835788023102 | validation: 0.014166668561974093]
	TIME [epoch: 9.25 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008632008696547391		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.008632008696547391 | validation: 0.019477793706657403]
	TIME [epoch: 9.27 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009130919356838532		[learning rate: 0.00043981]
	Learning Rate: 0.000439808
	LOSS [training: 0.009130919356838532 | validation: 0.00907496691698343]
	TIME [epoch: 9.25 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005113550761978889		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.005113550761978889 | validation: 0.011359765123393702]
	TIME [epoch: 9.24 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011243855672471487		[learning rate: 0.00043768]
	Learning Rate: 0.000437681
	LOSS [training: 0.011243855672471487 | validation: 0.014689970824284042]
	TIME [epoch: 9.25 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012712457279520426		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: 0.012712457279520426 | validation: 0.021994337043616065]
	TIME [epoch: 9.27 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005780800258510992		[learning rate: 0.00043556]
	Learning Rate: 0.000435565
	LOSS [training: 0.005780800258510992 | validation: 0.0035946867005632946]
	TIME [epoch: 9.25 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0034349352145423553		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: 0.0034349352145423553 | validation: 0.0018390427337865785]
	TIME [epoch: 9.25 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00014100021432237735		[learning rate: 0.00043346]
	Learning Rate: 0.000433458
	LOSS [training: 0.00014100021432237735 | validation: 0.007307603332185036]
	TIME [epoch: 9.25 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0055468312938430405		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.0055468312938430405 | validation: 0.005082141753820155]
	TIME [epoch: 9.27 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005410934164463672		[learning rate: 0.00043136]
	Learning Rate: 0.000431362
	LOSS [training: 0.005410934164463672 | validation: 0.012121634132284283]
	TIME [epoch: 9.25 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0039625823492792835		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.0039625823492792835 | validation: 0.016739201508268076]
	TIME [epoch: 9.25 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.000571785741359329		[learning rate: 0.00042928]
	Learning Rate: 0.000429276
	LOSS [training: 0.000571785741359329 | validation: -0.003482434370754589]
	TIME [epoch: 9.25 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0015616099460086508		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: -0.0015616099460086508 | validation: 0.017896741486491105]
	TIME [epoch: 9.26 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0036885466585580146		[learning rate: 0.0004272]
	Learning Rate: 0.0004272
	LOSS [training: 0.0036885466585580146 | validation: 0.020318466042643292]
	TIME [epoch: 9.25 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015008773470029687		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.0015008773470029687 | validation: -0.0041544578659307736]
	TIME [epoch: 9.25 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002137300533534288		[learning rate: 0.00042513]
	Learning Rate: 0.000425134
	LOSS [training: -0.002137300533534288 | validation: 0.0075594075624093844]
	TIME [epoch: 9.24 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013251819404446643		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: -0.0013251819404446643 | validation: 0.01882441281805937]
	TIME [epoch: 9.27 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009246371056070698		[learning rate: 0.00042308]
	Learning Rate: 0.000423079
	LOSS [training: 0.009246371056070698 | validation: 0.0207563687579269]
	TIME [epoch: 9.25 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012691498902500192		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.012691498902500192 | validation: 0.030954447710616326]
	TIME [epoch: 9.27 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0065362197160750216		[learning rate: 0.00042103]
	Learning Rate: 0.000421033
	LOSS [training: 0.0065362197160750216 | validation: 0.010792181605273019]
	TIME [epoch: 9.24 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009762381387205327		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: 0.009762381387205327 | validation: 0.006585606257971591]
	TIME [epoch: 9.26 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0025418237900781395		[learning rate: 0.000419]
	Learning Rate: 0.000418997
	LOSS [training: -0.0025418237900781395 | validation: -0.00029767669058256897]
	TIME [epoch: 9.25 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0027747194487744756		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.0027747194487744756 | validation: 0.01160302902695478]
	TIME [epoch: 9.24 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0002820519868491863		[learning rate: 0.00041697]
	Learning Rate: 0.00041697
	LOSS [training: -0.0002820519868491863 | validation: 0.008313062557738688]
	TIME [epoch: 9.24 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009766189121294528		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.009766189121294528 | validation: 0.018432932600187774]
	TIME [epoch: 9.27 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01661600737681518		[learning rate: 0.00041495]
	Learning Rate: 0.000414954
	LOSS [training: 0.01661600737681518 | validation: 0.011723535504582466]
	TIME [epoch: 9.25 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0118915439676984		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.0118915439676984 | validation: 0.010163391593932425]
	TIME [epoch: 9.24 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: -6.759884389535617e-05		[learning rate: 0.00041295]
	Learning Rate: 0.000412947
	LOSS [training: -6.759884389535617e-05 | validation: 0.003476694506021169]
	TIME [epoch: 9.24 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001668088028127861		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.001668088028127861 | validation: 0.01757676777642881]
	TIME [epoch: 9.27 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002742621282420172		[learning rate: 0.00041095]
	Learning Rate: 0.00041095
	LOSS [training: 0.002742621282420172 | validation: 0.017180216337754774]
	TIME [epoch: 9.25 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00021979206682169798		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.00021979206682169798 | validation: 0.0077542930154941726]
	TIME [epoch: 9.25 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010329020443899275		[learning rate: 0.00040896]
	Learning Rate: 0.000408963
	LOSS [training: 0.0010329020443899275 | validation: 0.012569935463610838]
	TIME [epoch: 9.25 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008054190760731921		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.008054190760731921 | validation: 0.010765141128155164]
	TIME [epoch: 9.26 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008526676908458214		[learning rate: 0.00040699]
	Learning Rate: 0.000406986
	LOSS [training: 0.008526676908458214 | validation: 0.00586877356428007]
	TIME [epoch: 9.26 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004854380829402536		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.004854380829402536 | validation: 0.015548216399906296]
	TIME [epoch: 9.24 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0025114379920501873		[learning rate: 0.00040502]
	Learning Rate: 0.000405017
	LOSS [training: -0.0025114379920501873 | validation: 0.01255144056847104]
	TIME [epoch: 9.25 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0007786028226336114		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.0007786028226336114 | validation: 0.009964411480955547]
	TIME [epoch: 9.26 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004109935052630783		[learning rate: 0.00040306]
	Learning Rate: 0.000403059
	LOSS [training: 0.004109935052630783 | validation: 0.0046810424615993905]
	TIME [epoch: 9.26 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004502098546460481		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.004502098546460481 | validation: 0.01647320775419063]
	TIME [epoch: 9.24 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017335618942475976		[learning rate: 0.00040111]
	Learning Rate: 0.00040111
	LOSS [training: 0.017335618942475976 | validation: 0.033892210394749434]
	TIME [epoch: 9.24 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01815063682946598		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.01815063682946598 | validation: 0.024650074361980544]
	TIME [epoch: 9.25 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01827104053088088		[learning rate: 0.00039917]
	Learning Rate: 0.00039917
	LOSS [training: 0.01827104053088088 | validation: 0.022116507526086203]
	TIME [epoch: 9.26 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01775821903038128		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.01775821903038128 | validation: 0.025574582063105283]
	TIME [epoch: 9.25 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015064521618169336		[learning rate: 0.00039724]
	Learning Rate: 0.00039724
	LOSS [training: 0.015064521618169336 | validation: 0.023313279869420576]
	TIME [epoch: 9.24 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012377886040237256		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.012377886040237256 | validation: 0.03397082894473593]
	TIME [epoch: 9.24 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010362916855846522		[learning rate: 0.00039532]
	Learning Rate: 0.000395319
	LOSS [training: 0.010362916855846522 | validation: 0.007773409298824776]
	TIME [epoch: 9.26 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0026790077192607306		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.0026790077192607306 | validation: 0.015841246065043876]
	TIME [epoch: 9.24 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0019615149120672188		[learning rate: 0.00039341]
	Learning Rate: 0.000393407
	LOSS [training: -0.0019615149120672188 | validation: 0.010921625715564577]
	TIME [epoch: 9.24 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0007252636072633715		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.0007252636072633715 | validation: 0.015575446301671384]
	TIME [epoch: 9.24 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0026446683067188116		[learning rate: 0.0003915]
	Learning Rate: 0.000391505
	LOSS [training: 0.0026446683067188116 | validation: 0.01611352626566896]
	TIME [epoch: 9.25 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00902261484944994		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.00902261484944994 | validation: 0.007344267702773298]
	TIME [epoch: 9.24 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005573792013864803		[learning rate: 0.00038961]
	Learning Rate: 0.000389611
	LOSS [training: 0.005573792013864803 | validation: 0.012295896330202517]
	TIME [epoch: 9.24 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005912355721796549		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.005912355721796549 | validation: 0.020935009468067853]
	TIME [epoch: 9.24 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016953930659891522		[learning rate: 0.00038773]
	Learning Rate: 0.000387727
	LOSS [training: 0.0016953930659891522 | validation: 0.008445318036267899]
	TIME [epoch: 9.25 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004652019969817176		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 0.004652019969817176 | validation: 0.013005442364137823]
	TIME [epoch: 9.24 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009558156383901315		[learning rate: 0.00038585]
	Learning Rate: 0.000385852
	LOSS [training: 0.009558156383901315 | validation: 0.021151962094044203]
	TIME [epoch: 9.25 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0013524436978303328		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.0013524436978303328 | validation: 0.009718203826765217]
	TIME [epoch: 9.25 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011891095240445584		[learning rate: 0.00038399]
	Learning Rate: 0.000383986
	LOSS [training: 0.011891095240445584 | validation: 0.02069851244894305]
	TIME [epoch: 9.26 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02236868072650917		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.02236868072650917 | validation: 0.032861738960711574]
	TIME [epoch: 9.24 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022768851376614947		[learning rate: 0.00038213]
	Learning Rate: 0.000382129
	LOSS [training: 0.022768851376614947 | validation: 0.02680901084794156]
	TIME [epoch: 9.24 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017963655397974558		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.017963655397974558 | validation: 0.023641910140814473]
	TIME [epoch: 9.24 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010053526309636813		[learning rate: 0.00038028]
	Learning Rate: 0.000380282
	LOSS [training: 0.010053526309636813 | validation: 0.018028029818255194]
	TIME [epoch: 9.26 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0022305390491959695		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.0022305390491959695 | validation: 0.012663464858134334]
	TIME [epoch: 9.24 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0038545398338289292		[learning rate: 0.00037844]
	Learning Rate: 0.000378443
	LOSS [training: 0.0038545398338289292 | validation: 0.013049347896514872]
	TIME [epoch: 9.24 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008826626091863283		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.008826626091863283 | validation: 0.021499968980100856]
	TIME [epoch: 9.24 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007486952354690314		[learning rate: 0.00037661]
	Learning Rate: 0.000376612
	LOSS [training: 0.007486952354690314 | validation: 0.008430530080701505]
	TIME [epoch: 9.26 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017175861015328656		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: -0.0017175861015328656 | validation: 0.01485229973507937]
	TIME [epoch: 9.25 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008834245438861911		[learning rate: 0.00037479]
	Learning Rate: 0.000374791
	LOSS [training: 0.008834245438861911 | validation: 0.012219613471400284]
	TIME [epoch: 9.24 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010393861144015247		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.010393861144015247 | validation: 0.007879259737563635]
	TIME [epoch: 9.25 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00171501131792938		[learning rate: 0.00037298]
	Learning Rate: 0.000372979
	LOSS [training: 0.00171501131792938 | validation: 0.014871142116152026]
	TIME [epoch: 9.26 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009169103930892942		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.009169103930892942 | validation: 0.017667445735252908]
	TIME [epoch: 9.25 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004572003300153643		[learning rate: 0.00037118]
	Learning Rate: 0.000371175
	LOSS [training: 0.004572003300153643 | validation: 0.021353338067852737]
	TIME [epoch: 9.24 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005445004023956499		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.005445004023956499 | validation: 0.019626332233861274]
	TIME [epoch: 9.24 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007198292222535869		[learning rate: 0.00036938]
	Learning Rate: 0.00036938
	LOSS [training: 0.007198292222535869 | validation: 0.010808074385456412]
	TIME [epoch: 9.26 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007999235297494202		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.007999235297494202 | validation: 0.006250495787426959]
	TIME [epoch: 9.25 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018633519280570627		[learning rate: 0.00036759]
	Learning Rate: 0.000367594
	LOSS [training: 0.0018633519280570627 | validation: 0.014615296004047386]
	TIME [epoch: 9.24 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01112319022611316		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: 0.01112319022611316 | validation: 0.014080254464167163]
	TIME [epoch: 9.24 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011350513279175868		[learning rate: 0.00036582]
	Learning Rate: 0.000365816
	LOSS [training: 0.011350513279175868 | validation: 0.023595342199607842]
	TIME [epoch: 9.26 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006985762821493736		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.006985762821493736 | validation: 0.002382675641559497]
	TIME [epoch: 9.24 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0032591912401777065		[learning rate: 0.00036405]
	Learning Rate: 0.000364047
	LOSS [training: 0.0032591912401777065 | validation: 0.01779700547450829]
	TIME [epoch: 9.24 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007978368211314509		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.007978368211314509 | validation: 0.013150751922843821]
	TIME [epoch: 9.24 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0047337828398915874		[learning rate: 0.00036229]
	Learning Rate: 0.000362287
	LOSS [training: 0.0047337828398915874 | validation: 0.005218063479541898]
	TIME [epoch: 9.26 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: -9.708748630386662e-05		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: -9.708748630386662e-05 | validation: 0.013520594424321321]
	TIME [epoch: 9.26 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001733124682378499		[learning rate: 0.00036053]
	Learning Rate: 0.000360535
	LOSS [training: 0.001733124682378499 | validation: 0.0072282211159454025]
	TIME [epoch: 9.25 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017667776149722625		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.0017667776149722625 | validation: 0.014731771658079904]
	TIME [epoch: 9.24 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0015542246455273554		[learning rate: 0.00035879]
	Learning Rate: 0.000358791
	LOSS [training: -0.0015542246455273554 | validation: 0.009670923178694005]
	TIME [epoch: 9.25 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004895958927467668		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.004895958927467668 | validation: 0.0049242139176083844]
	TIME [epoch: 9.26 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015584535006615608		[learning rate: 0.00035706]
	Learning Rate: 0.000357056
	LOSS [training: 0.0015584535006615608 | validation: 0.011372311484013832]
	TIME [epoch: 9.24 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0035768039174237363		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.0035768039174237363 | validation: 0.006571883464793859]
	TIME [epoch: 9.24 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005876159484396658		[learning rate: 0.00035533]
	Learning Rate: 0.00035533
	LOSS [training: -0.0005876159484396658 | validation: 0.004243709188476184]
	TIME [epoch: 9.24 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0056107453569231094		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.0056107453569231094 | validation: -0.0017901859464635782]
	TIME [epoch: 9.27 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0011518472855935006		[learning rate: 0.00035361]
	Learning Rate: 0.000353611
	LOSS [training: -0.0011518472855935006 | validation: 0.006861128931533846]
	TIME [epoch: 9.25 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00011354500302852792		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: -0.00011354500302852792 | validation: 0.01653932330299874]
	TIME [epoch: 9.25 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003782534704508659		[learning rate: 0.0003519]
	Learning Rate: 0.000351901
	LOSS [training: 0.003782534704508659 | validation: 0.0024487696715148975]
	TIME [epoch: 9.24 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006505172745282793		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: -0.006505172745282793 | validation: 0.0010445189288450986]
	TIME [epoch: 9.26 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00104189456001576		[learning rate: 0.0003502]
	Learning Rate: 0.0003502
	LOSS [training: -0.00104189456001576 | validation: 0.011105041842538296]
	TIME [epoch: 9.25 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006597653565792208		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.006597653565792208 | validation: 0.025528457713502258]
	TIME [epoch: 9.24 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004234406348945207		[learning rate: 0.00034851]
	Learning Rate: 0.000348506
	LOSS [training: 0.004234406348945207 | validation: 0.011452032113119449]
	TIME [epoch: 9.25 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003189701955634565		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.003189701955634565 | validation: -0.010030964714766484]
	TIME [epoch: 9.26 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240219_183145/states/model_tr_study4_1486.pth
	Model improved!!!
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0023884554614528627		[learning rate: 0.00034682]
	Learning Rate: 0.000346821
	LOSS [training: -0.0023884554614528627 | validation: 0.006051346011478371]
	TIME [epoch: 9.24 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00024571670208400133		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: -0.00024571670208400133 | validation: 0.016461869798676355]
	TIME [epoch: 9.24 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0023296335866972192		[learning rate: 0.00034514]
	Learning Rate: 0.000345144
	LOSS [training: 0.0023296335866972192 | validation: 0.004890595095374079]
	TIME [epoch: 9.24 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.000291663691214435		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: -0.000291663691214435 | validation: -0.00042332549234040716]
	TIME [epoch: 9.26 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009263255342395894		[learning rate: 0.00034347]
	Learning Rate: 0.000343475
	LOSS [training: 0.0009263255342395894 | validation: 0.010325827471580435]
	TIME [epoch: 9.25 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008814096399143325		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.008814096399143325 | validation: 0.010128087466160129]
	TIME [epoch: 9.24 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004059942814339084		[learning rate: 0.00034181]
	Learning Rate: 0.000341814
	LOSS [training: 0.004059942814339084 | validation: 0.013160820397449449]
	TIME [epoch: 9.24 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0024439316565163234		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.0024439316565163234 | validation: 0.01051466791402822]
	TIME [epoch: 9.26 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: -7.69150567831412e-05		[learning rate: 0.00034016]
	Learning Rate: 0.000340161
	LOSS [training: -7.69150567831412e-05 | validation: 0.007125023643800642]
	TIME [epoch: 9.25 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005787774950865561		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: -0.0005787774950865561 | validation: 0.004156098614577502]
	TIME [epoch: 9.25 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019273203432782983		[learning rate: 0.00033852]
	Learning Rate: 0.000338516
	LOSS [training: 0.0019273203432782983 | validation: 0.0021245627576088957]
	TIME [epoch: 9.25 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008997358606732137		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.008997358606732137 | validation: 0.006309024125568112]
	TIME [epoch: 9.26 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0070756404762961495		[learning rate: 0.00033688]
	Learning Rate: 0.000336879
	LOSS [training: 0.0070756404762961495 | validation: 0.013544091244327379]
	TIME [epoch: 9.24 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007207604407443569		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.007207604407443569 | validation: 0.02220167830399633]
	TIME [epoch: 9.24 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005533930020487602		[learning rate: 0.00033525]
	Learning Rate: 0.00033525
	LOSS [training: 0.005533930020487602 | validation: 0.010942920095534232]
	TIME [epoch: 9.25 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0011593139536259667		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: -0.0011593139536259667 | validation: 0.009234347166097771]
	TIME [epoch: 9.26 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013012378130632084		[learning rate: 0.00033363]
	Learning Rate: 0.000333629
	LOSS [training: -0.0013012378130632084 | validation: 0.0077918574828493205]
	TIME [epoch: 9.25 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016615298043967095		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.0016615298043967095 | validation: 0.015504117714122597]
	TIME [epoch: 9.25 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002172295097659989		[learning rate: 0.00033202]
	Learning Rate: 0.000332015
	LOSS [training: 0.002172295097659989 | validation: 0.000283201219283909]
	TIME [epoch: 9.24 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00034101985025067035		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.00034101985025067035 | validation: 0.0033300357946836126]
	TIME [epoch: 9.27 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.511307497171818e-05		[learning rate: 0.00033041]
	Learning Rate: 0.00033041
	LOSS [training: 6.511307497171818e-05 | validation: 0.009938605608391587]
	TIME [epoch: 9.25 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0001404624696279417		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: -0.0001404624696279417 | validation: 0.01748781871048296]
	TIME [epoch: 9.24 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0084286160077647		[learning rate: 0.00032881]
	Learning Rate: 0.000328812
	LOSS [training: 0.0084286160077647 | validation: 0.016301476571502552]
	TIME [epoch: 9.25 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003404666260427589		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: 0.003404666260427589 | validation: 0.013661766767661405]
	TIME [epoch: 9.26 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0034065783911615536		[learning rate: 0.00032722]
	Learning Rate: 0.000327222
	LOSS [training: -0.0034065783911615536 | validation: 0.0040953548606897485]
	TIME [epoch: 9.25 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00045313658880839335		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.00045313658880839335 | validation: 0.004670141884620416]
	TIME [epoch: 9.24 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014207032307925963		[learning rate: 0.00032564]
	Learning Rate: 0.000325639
	LOSS [training: 0.0014207032307925963 | validation: -0.007592201834856004]
	TIME [epoch: 9.24 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005905746364963464		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: -0.005905746364963464 | validation: -0.004793005272994558]
	TIME [epoch: 9.26 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0036091909665564555		[learning rate: 0.00032406]
	Learning Rate: 0.000324065
	LOSS [training: 0.0036091909665564555 | validation: -0.008741610502290494]
	TIME [epoch: 9.25 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002818278989934236		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: -0.002818278989934236 | validation: 0.013919446809220849]
	TIME [epoch: 9.24 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001351434697409928		[learning rate: 0.0003225]
	Learning Rate: 0.000322497
	LOSS [training: -0.001351434697409928 | validation: 0.005411843283755622]
	TIME [epoch: 9.24 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006970449253288262		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: 0.006970449253288262 | validation: 0.012378490187021461]
	TIME [epoch: 9.25 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0004005982759412295		[learning rate: 0.00032094]
	Learning Rate: 0.000320938
	LOSS [training: 0.0004005982759412295 | validation: -0.003919058049160011]
	TIME [epoch: 9.25 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006997485696269171		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: 0.0006997485696269171 | validation: 0.004282756988408079]
	TIME [epoch: 9.25 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017322487253776744		[learning rate: 0.00031939]
	Learning Rate: 0.000319386
	LOSS [training: 0.017322487253776744 | validation: 0.01527281523602034]
	TIME [epoch: 9.24 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025933483563894726		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.025933483563894726 | validation: 0.03051832076456862]
	TIME [epoch: 9.26 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009981698424625065		[learning rate: 0.00031784]
	Learning Rate: 0.000317841
	LOSS [training: 0.009981698424625065 | validation: 0.009575357869605904]
	TIME [epoch: 9.26 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016904495997605736		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.0016904495997605736 | validation: 0.004637699446459206]
	TIME [epoch: 9.23 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00028745917759317216		[learning rate: 0.0003163]
	Learning Rate: 0.000316304
	LOSS [training: 0.00028745917759317216 | validation: 0.01269698032224674]
	TIME [epoch: 9.24 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004719302877270692		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.004719302877270692 | validation: 0.008059594359456999]
	TIME [epoch: 9.24 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018706243321877346		[learning rate: 0.00031477]
	Learning Rate: 0.000314775
	LOSS [training: 0.0018706243321877346 | validation: 0.002686031597714927]
	TIME [epoch: 9.26 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005376678605595174		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.005376678605595174 | validation: 0.01250576780901186]
	TIME [epoch: 9.25 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00585540787668496		[learning rate: 0.00031325]
	Learning Rate: 0.000313253
	LOSS [training: 0.00585540787668496 | validation: 0.012207476879638695]
	TIME [epoch: 9.26 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005238354980050071		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.005238354980050071 | validation: 0.0027113908096703275]
	TIME [epoch: 9.25 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00100236371915242		[learning rate: 0.00031174]
	Learning Rate: 0.000311738
	LOSS [training: -0.00100236371915242 | validation: 0.0057852373939085225]
	TIME [epoch: 9.26 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0019355852003334235		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: -0.0019355852003334235 | validation: 0.007801446385725755]
	TIME [epoch: 9.24 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0038373972736715687		[learning rate: 0.00031023]
	Learning Rate: 0.00031023
	LOSS [training: 0.0038373972736715687 | validation: 0.00921734159812361]
	TIME [epoch: 9.25 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005451170947745753		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: 0.005451170947745753 | validation: 0.01267405948081276]
	TIME [epoch: 9.25 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0037638576305048166		[learning rate: 0.00030873]
	Learning Rate: 0.00030873
	LOSS [training: 0.0037638576305048166 | validation: 0.01663431285617568]
	TIME [epoch: 9.26 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0013496433051170243		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.0013496433051170243 | validation: 0.007825959455053834]
	TIME [epoch: 9.25 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0007955285753194596		[learning rate: 0.00030724]
	Learning Rate: 0.000307237
	LOSS [training: 0.0007955285753194596 | validation: 0.004637448747461195]
	TIME [epoch: 9.24 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006615790682405319		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: -0.006615790682405319 | validation: -0.000151971246744622]
	TIME [epoch: 9.24 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0028365545311928586		[learning rate: 0.00030575]
	Learning Rate: 0.000305751
	LOSS [training: -0.0028365545311928586 | validation: -0.0015016871731288119]
	TIME [epoch: 9.26 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0045365206575215195		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: -0.0045365206575215195 | validation: 0.0032101954907199134]
	TIME [epoch: 9.25 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0020389744041922958		[learning rate: 0.00030427]
	Learning Rate: 0.000304273
	LOSS [training: -0.0020389744041922958 | validation: 0.013537994568125964]
	TIME [epoch: 9.25 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0026437761233528015		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.0026437761233528015 | validation: 0.010216472277155962]
	TIME [epoch: 9.24 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008675354053278078		[learning rate: 0.0003028]
	Learning Rate: 0.000302801
	LOSS [training: 0.008675354053278078 | validation: 0.021822957834643206]
	TIME [epoch: 9.27 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011685883926020511		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: 0.011685883926020511 | validation: 0.03247617318058982]
	TIME [epoch: 9.24 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007808282269662568		[learning rate: 0.00030134]
	Learning Rate: 0.000301337
	LOSS [training: 0.007808282269662568 | validation: 0.013828166439402458]
	TIME [epoch: 9.24 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005722652074761072		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.0005722652074761072 | validation: -0.003043980414712928]
	TIME [epoch: 9.25 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0038135265415610853		[learning rate: 0.00029988]
	Learning Rate: 0.00029988
	LOSS [training: -0.0038135265415610853 | validation: -0.006119544144549347]
	TIME [epoch: 9.26 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001524117991160832		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: -0.001524117991160832 | validation: 0.012074726051489874]
	TIME [epoch: 9.25 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002517179586662601		[learning rate: 0.00029843]
	Learning Rate: 0.00029843
	LOSS [training: -0.002517179586662601 | validation: 0.005330104151766345]
	TIME [epoch: 9.25 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004663126350590416		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: -0.004663126350590416 | validation: -0.0019749095556718024]
	TIME [epoch: 9.24 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003828862038939584		[learning rate: 0.00029699]
	Learning Rate: 0.000296987
	LOSS [training: -0.003828862038939584 | validation: 0.004724300904470329]
	TIME [epoch: 9.27 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005269891050936459		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.0005269891050936459 | validation: 0.011864650695731269]
	TIME [epoch: 9.25 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0047674161066568275		[learning rate: 0.00029555]
	Learning Rate: 0.00029555
	LOSS [training: 0.0047674161066568275 | validation: 0.0012733190103863432]
	TIME [epoch: 9.24 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0010945322672386874		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: -0.0010945322672386874 | validation: 0.002918020070889061]
	TIME [epoch: 9.25 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0039007668972285644		[learning rate: 0.00029412]
	Learning Rate: 0.000294121
	LOSS [training: -0.0039007668972285644 | validation: 0.010280701496835576]
	TIME [epoch: 9.25 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002025171436612181		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: -0.002025171436612181 | validation: 0.005216046018341405]
	TIME [epoch: 9.25 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004516273043719976		[learning rate: 0.0002927]
	Learning Rate: 0.000292699
	LOSS [training: -0.004516273043719976 | validation: 0.005941574105626424]
	TIME [epoch: 9.24 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001954400219276712		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: -0.001954400219276712 | validation: 0.011173604823472516]
	TIME [epoch: 9.24 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017362162545284058		[learning rate: 0.00029128]
	Learning Rate: 0.000291283
	LOSS [training: 0.0017362162545284058 | validation: 0.011404892286085551]
	TIME [epoch: 9.27 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.000240516023604221		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: -0.000240516023604221 | validation: 0.005132102180116583]
	TIME [epoch: 9.25 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001838768574960527		[learning rate: 0.00028987]
	Learning Rate: 0.000289875
	LOSS [training: 0.001838768574960527 | validation: 0.007855504326959774]
	TIME [epoch: 9.25 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00239212350821334		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: -0.00239212350821334 | validation: 0.002052243056795167]
	TIME [epoch: 9.25 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004902237885074688		[learning rate: 0.00028847]
	Learning Rate: 0.000288473
	LOSS [training: 0.004902237885074688 | validation: 0.008826995388479917]
	TIME [epoch: 9.26 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0011489077031167868		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: -0.0011489077031167868 | validation: 0.0011878031986149707]
	TIME [epoch: 9.25 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006912577537673698		[learning rate: 0.00028708]
	Learning Rate: 0.000287078
	LOSS [training: -0.006912577537673698 | validation: 0.0018277508345047756]
	TIME [epoch: 9.24 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012709602421651805		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: -0.0012709602421651805 | validation: 0.001957854863906522]
	TIME [epoch: 9.24 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0031194936832680533		[learning rate: 0.00028569]
	Learning Rate: 0.00028569
	LOSS [training: -0.0031194936832680533 | validation: 0.016786271632745188]
	TIME [epoch: 9.26 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005823248709291416		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: -0.005823248709291416 | validation: 0.010839146493917028]
	TIME [epoch: 9.26 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002183338486515081		[learning rate: 0.00028431]
	Learning Rate: 0.000284308
	LOSS [training: -0.002183338486515081 | validation: 0.007268807422821067]
	TIME [epoch: 9.24 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002566847090358586		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: -0.002566847090358586 | validation: 0.011591119572801633]
	TIME [epoch: 9.24 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0021079419167055013		[learning rate: 0.00028293]
	Learning Rate: 0.000282933
	LOSS [training: -0.0021079419167055013 | validation: 0.01857752830384784]
	TIME [epoch: 9.24 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018047428763579333		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.0018047428763579333 | validation: 0.009135982042624804]
	TIME [epoch: 9.27 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003613446114050606		[learning rate: 0.00028157]
	Learning Rate: 0.000281565
	LOSS [training: -0.003613446114050606 | validation: -0.0038077282072024707]
	TIME [epoch: 9.25 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0023994834273429965		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: -0.0023994834273429965 | validation: -0.0015037607701121004]
	TIME [epoch: 9.24 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006135633236864236		[learning rate: 0.0002802]
	Learning Rate: 0.000280204
	LOSS [training: 0.0006135633236864236 | validation: 0.00786085515667611]
	TIME [epoch: 9.25 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009602990347845312		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: -0.0009602990347845312 | validation: 0.006901282823871566]
	TIME [epoch: 9.27 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0003298785621130652		[learning rate: 0.00027885]
	Learning Rate: 0.000278849
	LOSS [training: -0.0003298785621130652 | validation: -0.002253568720105358]
	TIME [epoch: 9.24 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0014433413959247675		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: -0.0014433413959247675 | validation: 0.00810099155149164]
	TIME [epoch: 9.24 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0028723649426627383		[learning rate: 0.0002775]
	Learning Rate: 0.0002775
	LOSS [training: -0.0028723649426627383 | validation: 0.004809504636721846]
	TIME [epoch: 9.24 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007730679644927299		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: -0.0007730679644927299 | validation: -0.004898129187043276]
	TIME [epoch: 9.27 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001655976364462048		[learning rate: 0.00027616]
	Learning Rate: 0.000276158
	LOSS [training: 0.001655976364462048 | validation: 0.0061048101859397215]
	TIME [epoch: 9.24 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00018494297811797697		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: 0.00018494297811797697 | validation: -0.00027730927489442227]
	TIME [epoch: 9.24 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006287468033182568		[learning rate: 0.00027482]
	Learning Rate: 0.000274823
	LOSS [training: 0.0006287468033182568 | validation: 0.005501528859540897]
	TIME [epoch: 9.25 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006073611584909414		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: -0.006073611584909414 | validation: -0.0025513952098716484]
	TIME [epoch: 9.26 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016685843052418499		[learning rate: 0.00027349]
	Learning Rate: 0.000273494
	LOSS [training: 0.0016685843052418499 | validation: 0.003892624246245131]
	TIME [epoch: 9.25 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019600564256509775		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: 0.0019600564256509775 | validation: 0.01272284347780215]
	TIME [epoch: 9.24 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00044727643378235035		[learning rate: 0.00027217]
	Learning Rate: 0.000272171
	LOSS [training: 0.00044727643378235035 | validation: 0.0011061745574397525]
	TIME [epoch: 9.25 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003445085436145692		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 0.003445085436145692 | validation: -5.088767131178562e-05]
	TIME [epoch: 9.27 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004707798301121832		[learning rate: 0.00027086]
	Learning Rate: 0.000270855
	LOSS [training: 0.004707798301121832 | validation: 0.00312015005083286]
	TIME [epoch: 9.25 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001793262901840073		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: 0.001793262901840073 | validation: -0.00027834895381923875]
	TIME [epoch: 9.24 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0010677249819804036		[learning rate: 0.00026955]
	Learning Rate: 0.000269545
	LOSS [training: -0.0010677249819804036 | validation: 0.008350925203753893]
	TIME [epoch: 9.25 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001223133413119359		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: 0.001223133413119359 | validation: -0.001266043242509964]
	TIME [epoch: 9.26 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004000045547058061		[learning rate: 0.00026824]
	Learning Rate: 0.000268242
	LOSS [training: 0.004000045547058061 | validation: 0.015546861536923747]
	TIME [epoch: 9.25 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019430731744189307		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: 0.0019430731744189307 | validation: 0.012625957689138777]
	TIME [epoch: 9.25 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010810800045259867		[learning rate: 0.00026694]
	Learning Rate: 0.000266945
	LOSS [training: 0.0010810800045259867 | validation: 0.004367789200044721]
	TIME [epoch: 9.24 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004324197426782623		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.004324197426782623 | validation: 0.015161274007926703]
	TIME [epoch: 9.26 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002320338999078917		[learning rate: 0.00026565]
	Learning Rate: 0.000265654
	LOSS [training: 0.002320338999078917 | validation: -0.0016226242432772868]
	TIME [epoch: 9.25 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017217882897023675		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.0017217882897023675 | validation: 0.013972593915805763]
	TIME [epoch: 9.25 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0024214751951178374		[learning rate: 0.00026437]
	Learning Rate: 0.000264369
	LOSS [training: -0.0024214751951178374 | validation: 0.00719253976883431]
	TIME [epoch: 9.25 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0023532495118034963		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: -0.0023532495118034963 | validation: -0.004134176092259358]
	TIME [epoch: 9.27 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00130397177782495		[learning rate: 0.00026309]
	Learning Rate: 0.000263091
	LOSS [training: 0.00130397177782495 | validation: 0.00667204413990963]
	TIME [epoch: 9.25 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: -6.856111542848098e-05		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: -6.856111542848098e-05 | validation: -0.0023836328165065144]
	TIME [epoch: 9.24 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009555487443573679		[learning rate: 0.00026182]
	Learning Rate: 0.000261818
	LOSS [training: 0.0009555487443573679 | validation: 0.0034876243162524083]
	TIME [epoch: 9.24 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0028412965238522516		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: -0.0028412965238522516 | validation: -4.758153928097864e-05]
	TIME [epoch: 9.26 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002058259127234475		[learning rate: 0.00026055]
	Learning Rate: 0.000260552
	LOSS [training: 0.002058259127234475 | validation: 0.020187103714854104]
	TIME [epoch: 9.24 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0030383358989428738		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: 0.0030383358989428738 | validation: 0.007813350356782373]
	TIME [epoch: 9.24 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0037480870733583487		[learning rate: 0.00025929]
	Learning Rate: 0.000259292
	LOSS [training: -0.0037480870733583487 | validation: 0.0019319750869614906]
	TIME [epoch: 9.24 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003379030830204418		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.003379030830204418 | validation: 0.0010621705705343167]
	TIME [epoch: 9.25 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00544610673897815		[learning rate: 0.00025804]
	Learning Rate: 0.000258038
	LOSS [training: -0.00544610673897815 | validation: 0.006248261436088331]
	TIME [epoch: 9.24 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0027785312083030474		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: -0.0027785312083030474 | validation: 0.008184264685303604]
	TIME [epoch: 9.24 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0034416551382502906		[learning rate: 0.00025679]
	Learning Rate: 0.00025679
	LOSS [training: 0.0034416551382502906 | validation: 0.007965987855833571]
	TIME [epoch: 9.25 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004356499204112832		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: 0.004356499204112832 | validation: 0.012014034413057142]
	TIME [epoch: 9.27 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004975333605788442		[learning rate: 0.00025555]
	Learning Rate: 0.000255549
	LOSS [training: 0.004975333605788442 | validation: 0.01277416725798916]
	TIME [epoch: 9.25 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008659757636503871		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: 0.008659757636503871 | validation: 0.015435675025357462]
	TIME [epoch: 9.24 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01191506353870178		[learning rate: 0.00025431]
	Learning Rate: 0.000254313
	LOSS [training: 0.01191506353870178 | validation: 0.010595491292401837]
	TIME [epoch: 9.24 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004720163457141166		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: 0.004720163457141166 | validation: 0.005417931556034782]
	TIME [epoch: 9.25 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0014304325791738711		[learning rate: 0.00025308]
	Learning Rate: 0.000253083
	LOSS [training: -0.0014304325791738711 | validation: -0.00035195722217553184]
	TIME [epoch: 9.26 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001151408499175699		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: -0.001151408499175699 | validation: 0.00011437060518441401]
	TIME [epoch: 9.24 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013815555236423066		[learning rate: 0.00025186]
	Learning Rate: 0.000251859
	LOSS [training: -0.0013815555236423066 | validation: 0.003717683878552582]
	TIME [epoch: 9.25 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002654480826002549		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.002654480826002549 | validation: 0.0042706024481601445]
	TIME [epoch: 9.25 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0025939090872606095		[learning rate: 0.00025064]
	Learning Rate: 0.000250641
	LOSS [training: 0.0025939090872606095 | validation: 0.009004586424679332]
	TIME [epoch: 9.26 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004011990553718467		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: -0.0004011990553718467 | validation: 0.013966087713600844]
	TIME [epoch: 9.24 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00022098717009391727		[learning rate: 0.00024943]
	Learning Rate: 0.000249429
	LOSS [training: 0.00022098717009391727 | validation: 0.0037242118714072396]
	TIME [epoch: 9.25 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0022508543840293656		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: -0.0022508543840293656 | validation: -0.0003481251085308112]
	TIME [epoch: 9.25 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.2630777034484366e-05		[learning rate: 0.00024822]
	Learning Rate: 0.000248223
	LOSS [training: 5.2630777034484366e-05 | validation: -0.005024344661690817]
	TIME [epoch: 9.28 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0039026771393341556		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: -0.0039026771393341556 | validation: 0.007008034453174687]
	TIME [epoch: 9.25 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015201198009882821		[learning rate: 0.00024702]
	Learning Rate: 0.000247023
	LOSS [training: 0.0015201198009882821 | validation: -0.0012291762067510308]
	TIME [epoch: 9.25 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0020838854533446775		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: -0.0020838854533446775 | validation: 0.011295579839464798]
	TIME [epoch: 9.24 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006023407214856547		[learning rate: 0.00024583]
	Learning Rate: 0.000245828
	LOSS [training: -0.0006023407214856547 | validation: 0.012030722525494905]
	TIME [epoch: 9.26 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004506827288138936		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.004506827288138936 | validation: 0.010603729132502477]
	TIME [epoch: 9.25 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021107636655190187		[learning rate: 0.00024464]
	Learning Rate: 0.000244639
	LOSS [training: 0.0021107636655190187 | validation: 0.009676133847701513]
	TIME [epoch: 9.25 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006288836499719575		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.006288836499719575 | validation: 0.02040520456638116]
	TIME [epoch: 9.25 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007054001475332754		[learning rate: 0.00024346]
	Learning Rate: 0.000243456
	LOSS [training: 0.007054001475332754 | validation: 0.018639935329684686]
	TIME [epoch: 9.26 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005069685839598789		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.005069685839598789 | validation: 0.017361948176449933]
	TIME [epoch: 9.25 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: -4.0661232089288064e-05		[learning rate: 0.00024228]
	Learning Rate: 0.000242279
	LOSS [training: -4.0661232089288064e-05 | validation: 0.009930533470347752]
	TIME [epoch: 9.24 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0036065406627095497		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: -0.0036065406627095497 | validation: 0.0013253098051132228]
	TIME [epoch: 9.25 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016540038347404354		[learning rate: 0.00024111]
	Learning Rate: 0.000241107
	LOSS [training: 0.0016540038347404354 | validation: 0.006916039576065328]
	TIME [epoch: 9.27 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003644489185372023		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: -0.003644489185372023 | validation: 0.004761467947885047]
	TIME [epoch: 9.26 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005526270324841009		[learning rate: 0.00023994]
	Learning Rate: 0.000239941
	LOSS [training: -0.005526270324841009 | validation: 0.0023596382401501947]
	TIME [epoch: 9.25 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002163307407775817		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: -0.002163307407775817 | validation: -0.0028143132667533626]
	TIME [epoch: 9.24 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004959169925095418		[learning rate: 0.00023878]
	Learning Rate: 0.000238781
	LOSS [training: -0.004959169925095418 | validation: 0.007091487039220592]
	TIME [epoch: 9.26 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0036401574296474073		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: -0.0036401574296474073 | validation: 0.0035553113867198543]
	TIME [epoch: 9.24 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0011718024076212467		[learning rate: 0.00023763]
	Learning Rate: 0.000237626
	LOSS [training: 0.0011718024076212467 | validation: 0.010562135320670768]
	TIME [epoch: 9.25 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017951389904196594		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: 0.0017951389904196594 | validation: 0.01012416711616941]
	TIME [epoch: 9.24 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0012185189239642034		[learning rate: 0.00023648]
	Learning Rate: 0.000236477
	LOSS [training: 0.0012185189239642034 | validation: 0.0066538006662819615]
	TIME [epoch: 9.27 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003835154523425522		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.003835154523425522 | validation: 0.0016471856234362098]
	TIME [epoch: 9.25 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016674810148256814		[learning rate: 0.00023533]
	Learning Rate: 0.000235334
	LOSS [training: 0.0016674810148256814 | validation: 0.0016663767993671777]
	TIME [epoch: 9.24 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005977550144314348		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.005977550144314348 | validation: 0.000425890807502004]
	TIME [epoch: 9.24 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009166986580626732		[learning rate: 0.0002342]
	Learning Rate: 0.000234196
	LOSS [training: 0.0009166986580626732 | validation: 0.007597302935378784]
	TIME [epoch: 9.26 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0008102591737816361		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: -0.0008102591737816361 | validation: 0.0044211148602888]
	TIME [epoch: 9.25 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005783153427657954		[learning rate: 0.00023306]
	Learning Rate: 0.000233063
	LOSS [training: -0.0005783153427657954 | validation: 0.004277889619077414]
	TIME [epoch: 9.25 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0016441279244354353		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: -0.0016441279244354353 | validation: 0.000643914236948272]
	TIME [epoch: 9.24 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0044674783134154555		[learning rate: 0.00023194]
	Learning Rate: 0.000231936
	LOSS [training: -0.0044674783134154555 | validation: 0.0014587945349219423]
	TIME [epoch: 9.26 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: -2.4338918343776962e-05		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: -2.4338918343776962e-05 | validation: -0.008666126913325346]
	TIME [epoch: 9.25 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0023103026231492225		[learning rate: 0.00023081]
	Learning Rate: 0.000230814
	LOSS [training: 0.0023103026231492225 | validation: -0.0010084154110516319]
	TIME [epoch: 9.24 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0028374244993124515		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: -0.0028374244993124515 | validation: 0.0040027668958225356]
	TIME [epoch: 9.24 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002691864988202396		[learning rate: 0.0002297]
	Learning Rate: 0.000229698
	LOSS [training: -0.002691864988202396 | validation: 0.008738708786067622]
	TIME [epoch: 9.26 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0026058534010962933		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: -0.0026058534010962933 | validation: -0.0012637117696682283]
	TIME [epoch: 9.25 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004698631226713525		[learning rate: 0.00022859]
	Learning Rate: 0.000228588
	LOSS [training: -0.004698631226713525 | validation: 0.0025863293311886018]
	TIME [epoch: 9.24 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013337678684848184		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: -0.0013337678684848184 | validation: 0.0036267939519980925]
	TIME [epoch: 9.24 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0014137286813846674		[learning rate: 0.00022748]
	Learning Rate: 0.000227482
	LOSS [training: -0.0014137286813846674 | validation: 0.0029443964380278143]
	TIME [epoch: 9.26 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001590785013321052		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: -0.001590785013321052 | validation: 0.002929967454495051]
	TIME [epoch: 9.25 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003298104581322159		[learning rate: 0.00022638]
	Learning Rate: 0.000226382
	LOSS [training: -0.003298104581322159 | validation: -0.006302805882741271]
	TIME [epoch: 9.25 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002799041931262792		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: -0.002799041931262792 | validation: 0.005170860076077453]
	TIME [epoch: 9.25 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005881084445872847		[learning rate: 0.00022529]
	Learning Rate: 0.000225287
	LOSS [training: -0.0005881084445872847 | validation: 0.006657997134280868]
	TIME [epoch: 9.25 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004461258259684644		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: -0.004461258259684644 | validation: -0.007269095589422561]
	TIME [epoch: 9.25 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006543986348212935		[learning rate: 0.0002242]
	Learning Rate: 0.000224198
	LOSS [training: 0.0006543986348212935 | validation: -0.004973509014322597]
	TIME [epoch: 9.24 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003639111121721676		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: -0.003639111121721676 | validation: 0.002520150077105612]
	TIME [epoch: 9.24 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: -2.323847327154807e-05		[learning rate: 0.00022311]
	Learning Rate: 0.000223114
	LOSS [training: -2.323847327154807e-05 | validation: 0.007842366621379092]
	TIME [epoch: 9.24 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017631491838686342		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: -0.0017631491838686342 | validation: 0.0021054087500609686]
	TIME [epoch: 9.26 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017103106736945518		[learning rate: 0.00022203]
	Learning Rate: 0.000222035
	LOSS [training: -0.0017103106736945518 | validation: 0.0011758193499148378]
	TIME [epoch: 9.24 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006147732115888574		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.006147732115888574 | validation: 0.018042856183772077]
	TIME [epoch: 9.25 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005177157772784877		[learning rate: 0.00022096]
	Learning Rate: 0.000220961
	LOSS [training: 0.005177157772784877 | validation: 0.009179297978642144]
	TIME [epoch: 9.24 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004764507031330303		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: 0.004764507031330303 | validation: 0.010082130358455583]
	TIME [epoch: 9.26 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005721620498906942		[learning rate: 0.00021989]
	Learning Rate: 0.000219893
	LOSS [training: 0.005721620498906942 | validation: 0.003425990670019248]
	TIME [epoch: 9.25 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005544534695323175		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: 0.005544534695323175 | validation: -0.00481631113676994]
	TIME [epoch: 9.25 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0034322539172313518		[learning rate: 0.00021883]
	Learning Rate: 0.000218829
	LOSS [training: 0.0034322539172313518 | validation: 0.007719980071693219]
	TIME [epoch: 9.25 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004440032382399701		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: -0.004440032382399701 | validation: 0.014094902862711811]
	TIME [epoch: 9.27 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004148326691509182		[learning rate: 0.00021777]
	Learning Rate: 0.000217771
	LOSS [training: -0.004148326691509182 | validation: -0.0019343555956141934]
	TIME [epoch: 9.25 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0011089317419102286		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: -0.0011089317419102286 | validation: -0.00016829997007789584]
	TIME [epoch: 9.24 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001779730411629123		[learning rate: 0.00021672]
	Learning Rate: 0.000216718
	LOSS [training: -0.001779730411629123 | validation: 0.006644586328547648]
	TIME [epoch: 9.24 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014307068716149138		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: 0.0014307068716149138 | validation: 0.008490332088485538]
	TIME [epoch: 9.26 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0022636308524063183		[learning rate: 0.00021567]
	Learning Rate: 0.00021567
	LOSS [training: -0.0022636308524063183 | validation: 0.004412112099457055]
	TIME [epoch: 9.25 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002493538409732845		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: -0.002493538409732845 | validation: 0.004016502792360988]
	TIME [epoch: 9.24 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00441015432062267		[learning rate: 0.00021463]
	Learning Rate: 0.000214627
	LOSS [training: -0.00441015432062267 | validation: -0.001173031161724002]
	TIME [epoch: 9.25 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002762638543835353		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: -0.002762638543835353 | validation: 0.009552887654879001]
	TIME [epoch: 9.26 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00475222584008449		[learning rate: 0.00021359]
	Learning Rate: 0.000213589
	LOSS [training: 0.00475222584008449 | validation: 0.013356909384156205]
	TIME [epoch: 9.24 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0030452522694904014		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.0030452522694904014 | validation: 0.010652569334250173]
	TIME [epoch: 9.25 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01545849955507268		[learning rate: 0.00021256]
	Learning Rate: 0.000212556
	LOSS [training: 0.01545849955507268 | validation: 0.021718667916014324]
	TIME [epoch: 9.25 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009233041779195043		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.009233041779195043 | validation: 0.008443865215663393]
	TIME [epoch: 9.27 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004856626696118813		[learning rate: 0.00021153]
	Learning Rate: 0.000211528
	LOSS [training: 0.004856626696118813 | validation: 0.022922269226546103]
	TIME [epoch: 9.25 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009881294110996173		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.009881294110996173 | validation: 0.016211995831342495]
	TIME [epoch: 9.24 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006225730936669309		[learning rate: 0.00021051]
	Learning Rate: 0.000210505
	LOSS [training: 0.006225730936669309 | validation: 0.019829955494361007]
	TIME [epoch: 9.24 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006277124131023536		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.006277124131023536 | validation: 0.012570949934201697]
	TIME [epoch: 9.26 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0045447445039857		[learning rate: 0.00020949]
	Learning Rate: 0.000209487
	LOSS [training: 0.0045447445039857 | validation: 0.017928772435862637]
	TIME [epoch: 9.25 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004726264048676861		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.004726264048676861 | validation: 0.005089051784032063]
	TIME [epoch: 9.25 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013507624786630607		[learning rate: 0.00020847]
	Learning Rate: 0.000208474
	LOSS [training: -0.0013507624786630607 | validation: 0.009574079339540898]
	TIME [epoch: 9.24 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0016415771901558494		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.0016415771901558494 | validation: 0.0037227803801596305]
	TIME [epoch: 9.27 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0011809445157324953		[learning rate: 0.00020747]
	Learning Rate: 0.000207466
	LOSS [training: 0.0011809445157324953 | validation: 0.008599260504735425]
	TIME [epoch: 9.25 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002248634043876574		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: -0.002248634043876574 | validation: 0.011791244722493115]
	TIME [epoch: 9.24 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001611884620604842		[learning rate: 0.00020646]
	Learning Rate: 0.000206463
	LOSS [training: 0.001611884620604842 | validation: 0.009900731230449503]
	TIME [epoch: 9.25 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014964516036602604		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.0014964516036602604 | validation: 0.009730282527398753]
	TIME [epoch: 9.26 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0032013808246896154		[learning rate: 0.00020546]
	Learning Rate: 0.000205465
	LOSS [training: 0.0032013808246896154 | validation: 0.010952152461335867]
	TIME [epoch: 9.26 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003693534858314583		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.003693534858314583 | validation: 0.014852196744859412]
	TIME [epoch: 9.25 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004809646997491358		[learning rate: 0.00020447]
	Learning Rate: 0.000204471
	LOSS [training: 0.004809646997491358 | validation: 0.01173446486580524]
	TIME [epoch: 9.25 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012754388459793498		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: -0.0012754388459793498 | validation: 0.006725881848559383]
	TIME [epoch: 9.26 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013918145636430618		[learning rate: 0.00020348]
	Learning Rate: 0.000203482
	LOSS [training: -0.0013918145636430618 | validation: 0.003377168534779397]
	TIME [epoch: 9.25 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00044572458109912416		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: -0.00044572458109912416 | validation: 0.00878434874411465]
	TIME [epoch: 9.24 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0009488507027907844		[learning rate: 0.0002025]
	Learning Rate: 0.000202498
	LOSS [training: 0.0009488507027907844 | validation: 0.001276662607483472]
	TIME [epoch: 9.24 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0003072690462939898		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.0003072690462939898 | validation: 0.0004837181766504826]
	TIME [epoch: 9.26 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012102039752209183		[learning rate: 0.00020152]
	Learning Rate: 0.000201519
	LOSS [training: -0.0012102039752209183 | validation: 0.0003598851216345205]
	TIME [epoch: 9.25 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0024529519536989975		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.0024529519536989975 | validation: 0.024273982209413732]
	TIME [epoch: 9.25 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008138320321027565		[learning rate: 0.00020054]
	Learning Rate: 0.000200544
	LOSS [training: 0.008138320321027565 | validation: 0.01623550143350526]
	TIME [epoch: 9.24 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0066231839254585435		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.0066231839254585435 | validation: 0.01156526670737329]
	TIME [epoch: 9.26 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004981112535135266		[learning rate: 0.00019957]
	Learning Rate: 0.000199575
	LOSS [training: 0.004981112535135266 | validation: 0.0013630623671738729]
	TIME [epoch: 9.26 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005629789671759757		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: 0.0005629789671759757 | validation: 0.008753539246080747]
	TIME [epoch: 9.24 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017623221215073196		[learning rate: 0.00019861]
	Learning Rate: 0.000198609
	LOSS [training: 0.0017623221215073196 | validation: 0.003179589064430654]
	TIME [epoch: 9.24 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0018443684464992897		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: -0.0018443684464992897 | validation: 0.006367725568798347]
	TIME [epoch: 9.24 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0034822673441409747		[learning rate: 0.00019765]
	Learning Rate: 0.000197649
	LOSS [training: -0.0034822673441409747 | validation: 0.012999651153256339]
	TIME [epoch: 9.26 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006817968898591598		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: -0.006817968898591598 | validation: 0.0005083594883878249]
	TIME [epoch: 9.24 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0025013252185142037		[learning rate: 0.00019669]
	Learning Rate: 0.000196693
	LOSS [training: -0.0025013252185142037 | validation: 0.0065327945990260785]
	TIME [epoch: 9.25 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004010560099336273		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: -0.004010560099336273 | validation: 0.0073889043937593124]
	TIME [epoch: 9.25 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0027201907101148323		[learning rate: 0.00019574]
	Learning Rate: 0.000195742
	LOSS [training: -0.0027201907101148323 | validation: 0.005594618524278191]
	TIME [epoch: 9.27 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0020347100659492867		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: -0.0020347100659492867 | validation: 0.006692044740300587]
	TIME [epoch: 9.24 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00063794307835289		[learning rate: 0.0001948]
	Learning Rate: 0.000194796
	LOSS [training: 0.00063794307835289 | validation: 0.0008541068286513432]
	TIME [epoch: 9.24 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005772906000643915		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: -0.005772906000643915 | validation: 0.0029171985619508324]
	TIME [epoch: 9.24 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003956361753443938		[learning rate: 0.00019385]
	Learning Rate: 0.000193853
	LOSS [training: -0.003956361753443938 | validation: -0.0004506142159768534]
	TIME [epoch: 9.28 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00035845644630934733		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: -0.00035845644630934733 | validation: 0.008663100583758087]
	TIME [epoch: 9.25 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0033589899987297492		[learning rate: 0.00019292]
	Learning Rate: 0.000192916
	LOSS [training: 0.0033589899987297492 | validation: -0.0044975501046504805]
	TIME [epoch: 9.25 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0057559901524214755		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: -0.0057559901524214755 | validation: 0.005678925370360673]
	TIME [epoch: 9.24 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: -5.4708415461531726e-05		[learning rate: 0.00019198]
	Learning Rate: 0.000191983
	LOSS [training: -5.4708415461531726e-05 | validation: 0.009318901656641966]
	TIME [epoch: 9.26 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008033125283746336		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: 0.008033125283746336 | validation: 0.00021937620706136834]
	TIME [epoch: 9.24 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005024624321853955		[learning rate: 0.00019105]
	Learning Rate: 0.000191055
	LOSS [training: -0.0005024624321853955 | validation: 0.006694534097559417]
	TIME [epoch: 9.24 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012369863977810837		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: -0.0012369863977810837 | validation: 0.01730012003396444]
	TIME [epoch: 9.25 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006801151081280066		[learning rate: 0.00019013]
	Learning Rate: 0.000190131
	LOSS [training: 0.0006801151081280066 | validation: 0.014970615175797702]
	TIME [epoch: 9.26 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.000991065097610977		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: -0.000991065097610977 | validation: 0.004318794975700804]
	TIME [epoch: 9.25 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002367693405935349		[learning rate: 0.00018921]
	Learning Rate: 0.000189211
	LOSS [training: -0.002367693405935349 | validation: 0.0038242489166333766]
	TIME [epoch: 9.24 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0015870101381155089		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: 0.0015870101381155089 | validation: 0.00460824941781948]
	TIME [epoch: 9.24 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007345945582450389		[learning rate: 0.0001883]
	Learning Rate: 0.000188296
	LOSS [training: -0.0007345945582450389 | validation: 0.004287944471463859]
	TIME [epoch: 9.26 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004671120260257589		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: 0.004671120260257589 | validation: -0.007343949705398414]
	TIME [epoch: 9.25 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005711919574390491		[learning rate: 0.00018739]
	Learning Rate: 0.000187386
	LOSS [training: -0.005711919574390491 | validation: 0.002202459603287503]
	TIME [epoch: 9.25 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003218764704464031		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: -0.003218764704464031 | validation: 0.005203627025035608]
	TIME [epoch: 9.25 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005520938053954927		[learning rate: 0.00018648]
	Learning Rate: 0.00018648
	LOSS [training: -0.0005520938053954927 | validation: -0.006432586740532384]
	TIME [epoch: 9.27 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003238636852387293		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: -0.003238636852387293 | validation: -0.0032885240198935]
	TIME [epoch: 9.24 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0024162927389463807		[learning rate: 0.00018558]
	Learning Rate: 0.000185578
	LOSS [training: -0.0024162927389463807 | validation: 0.002438871216016288]
	TIME [epoch: 9.25 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017436443717584766		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: -0.0017436443717584766 | validation: 8.549623110955598e-05]
	TIME [epoch: 9.24 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0033433097703938833		[learning rate: 0.00018468]
	Learning Rate: 0.00018468
	LOSS [training: -0.0033433097703938833 | validation: 0.007033961082558888]
	TIME [epoch: 9.26 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0055246553996249614		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: -0.0055246553996249614 | validation: 0.001854712116699667]
	TIME [epoch: 9.25 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004124056447547756		[learning rate: 0.00018379]
	Learning Rate: 0.000183787
	LOSS [training: -0.004124056447547756 | validation: 0.01095788094262832]
	TIME [epoch: 9.24 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006048097427689628		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: -0.006048097427689628 | validation: 0.003050459631490792]
	TIME [epoch: 9.24 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002258711613056757		[learning rate: 0.0001829]
	Learning Rate: 0.000182899
	LOSS [training: -0.002258711613056757 | validation: 0.01159429640071221]
	TIME [epoch: 9.26 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0023109981572332463		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: 0.0023109981572332463 | validation: 0.010316400718611242]
	TIME [epoch: 9.25 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006979705915761594		[learning rate: 0.00018201]
	Learning Rate: 0.000182014
	LOSS [training: 0.0006979705915761594 | validation: 0.001818855338438315]
	TIME [epoch: 9.25 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012753570743684064		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: -0.0012753570743684064 | validation: 0.008623909837887304]
	TIME [epoch: 9.25 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8605972587920926e-05		[learning rate: 0.00018113]
	Learning Rate: 0.000181134
	LOSS [training: 3.8605972587920926e-05 | validation: 0.006447584650728784]
	TIME [epoch: 9.27 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00020112816876289246		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: 0.00020112816876289246 | validation: 0.010162079317603328]
	TIME [epoch: 9.25 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008501445298769669		[learning rate: 0.00018026]
	Learning Rate: 0.000180258
	LOSS [training: 0.0008501445298769669 | validation: 0.00997850228326594]
	TIME [epoch: 9.24 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.1423866847301127e-05		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: 4.1423866847301127e-05 | validation: 0.005734527582939967]
	TIME [epoch: 9.25 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0020858251113299122		[learning rate: 0.00017939]
	Learning Rate: 0.000179386
	LOSS [training: -0.0020858251113299122 | validation: 0.010878695034582582]
	TIME [epoch: 9.26 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0051304335404227675		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: -0.0051304335404227675 | validation: 0.006223491309418758]
	TIME [epoch: 9.25 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004619270504496344		[learning rate: 0.00017852]
	Learning Rate: 0.000178519
	LOSS [training: -0.0004619270504496344 | validation: 0.0017666265525993754]
	TIME [epoch: 9.25 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003738134501974777		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: -0.003738134501974777 | validation: 0.005948854252985222]
	TIME [epoch: 9.24 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004492434844879911		[learning rate: 0.00017766]
	Learning Rate: 0.000177656
	LOSS [training: -0.004492434844879911 | validation: 0.008098503948356237]
	TIME [epoch: 9.25 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0015122534723847145		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: -0.0015122534723847145 | validation: 0.017146501096673795]
	TIME [epoch: 9.26 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006023094561137238		[learning rate: 0.0001768]
	Learning Rate: 0.000176797
	LOSS [training: 0.0006023094561137238 | validation: 0.011309833333698609]
	TIME [epoch: 9.24 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0046232817745638045		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: -0.0046232817745638045 | validation: 0.010511570125226237]
	TIME [epoch: 9.25 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0055682160722915625		[learning rate: 0.00017594]
	Learning Rate: 0.000175942
	LOSS [training: 0.0055682160722915625 | validation: 0.011216665147853314]
	TIME [epoch: 9.26 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00010652538620012815		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: 0.00010652538620012815 | validation: 0.0018011170681073972]
	TIME [epoch: 9.26 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00011551867296297098		[learning rate: 0.00017509]
	Learning Rate: 0.000175091
	LOSS [training: 0.00011551867296297098 | validation: 0.01361403385730373]
	TIME [epoch: 9.25 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009227785728891057		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: -0.0009227785728891057 | validation: 0.013586708246423308]
	TIME [epoch: 9.25 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003811387688177593		[learning rate: 0.00017424]
	Learning Rate: 0.000174244
	LOSS [training: -0.003811387688177593 | validation: -0.000785013895800647]
	TIME [epoch: 9.24 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0046113605573726325		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: -0.0046113605573726325 | validation: 0.010998599921862277]
	TIME [epoch: 9.26 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002996307546700203		[learning rate: 0.0001734]
	Learning Rate: 0.000173401
	LOSS [training: -0.002996307546700203 | validation: 0.012709156179972671]
	TIME [epoch: 9.25 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001989162552119582		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.001989162552119582 | validation: 0.001537344916874771]
	TIME [epoch: 9.25 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: -6.373147850463066e-05		[learning rate: 0.00017256]
	Learning Rate: 0.000172563
	LOSS [training: -6.373147850463066e-05 | validation: 0.002273796319078519]
	TIME [epoch: 9.24 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007118645315666689		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: -0.0007118645315666689 | validation: 0.0011885971720948308]
	TIME [epoch: 9.27 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0006831328720902519		[learning rate: 0.00017173]
	Learning Rate: 0.000171728
	LOSS [training: 0.0006831328720902519 | validation: 0.003355482896134549]
	TIME [epoch: 9.25 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0028628113985242265		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: 0.0028628113985242265 | validation: 0.00728424240191026]
	TIME [epoch: 9.24 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012131224516408788		[learning rate: 0.0001709]
	Learning Rate: 0.000170898
	LOSS [training: -0.0012131224516408788 | validation: -0.0023573046665904323]
	TIME [epoch: 9.25 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0020751807276659885		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.0020751807276659885 | validation: 0.008850863548675147]
	TIME [epoch: 9.27 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004786426843512747		[learning rate: 0.00017007]
	Learning Rate: 0.000170072
	LOSS [training: 0.004786426843512747 | validation: 0.013917441473019192]
	TIME [epoch: 9.26 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0012397253481996491		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: 0.0012397253481996491 | validation: 0.007335784951414193]
	TIME [epoch: 9.25 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0007124415913735019		[learning rate: 0.00016925]
	Learning Rate: 0.000169249
	LOSS [training: 0.0007124415913735019 | validation: 0.0017453385500657802]
	TIME [epoch: 9.25 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009509973344023076		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: -0.0009509973344023076 | validation: 0.005492082036052884]
	TIME [epoch: 9.25 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0003180863674309019		[learning rate: 0.00016843]
	Learning Rate: 0.000168431
	LOSS [training: -0.0003180863674309019 | validation: 0.004936067556659694]
	TIME [epoch: 9.24 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014026324608778183		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.0014026324608778183 | validation: 0.004941068027198997]
	TIME [epoch: 9.24 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0032451664551103863		[learning rate: 0.00016762]
	Learning Rate: 0.000167616
	LOSS [training: 0.0032451664551103863 | validation: 0.006164479609834714]
	TIME [epoch: 9.25 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00041557011477680214		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.00041557011477680214 | validation: 0.0003223407460440607]
	TIME [epoch: 9.27 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0051447374343669625		[learning rate: 0.00016681]
	Learning Rate: 0.000166806
	LOSS [training: -0.0051447374343669625 | validation: 0.005060435415551136]
	TIME [epoch: 9.25 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003325333066112755		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: -0.003325333066112755 | validation: 0.010753717523757526]
	TIME [epoch: 9.25 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0015248174874552146		[learning rate: 0.000166]
	Learning Rate: 0.000165999
	LOSS [training: -0.0015248174874552146 | validation: 0.007311459964629315]
	TIME [epoch: 9.24 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0037636448882126133		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: -0.0037636448882126133 | validation: -0.00338917744686238]
	TIME [epoch: 9.27 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005224597790953361		[learning rate: 0.0001652]
	Learning Rate: 0.000165196
	LOSS [training: -0.005224597790953361 | validation: 0.005171022082699224]
	TIME [epoch: 9.26 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0038618472320012176		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: -0.0038618472320012176 | validation: 0.00410710907101704]
	TIME [epoch: 9.25 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0026811783699849188		[learning rate: 0.0001644]
	Learning Rate: 0.000164397
	LOSS [training: -0.0026811783699849188 | validation: 0.009659651205001568]
	TIME [epoch: 9.24 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002833638110631362		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: -0.002833638110631362 | validation: 0.002669886401125733]
	TIME [epoch: 9.26 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.000966740790716579		[learning rate: 0.0001636]
	Learning Rate: 0.000163602
	LOSS [training: 0.000966740790716579 | validation: -0.0029894761332683708]
	TIME [epoch: 9.24 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007100756985482007		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: -0.0007100756985482007 | validation: 0.004172367631983209]
	TIME [epoch: 9.25 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001947256262926498		[learning rate: 0.00016281]
	Learning Rate: 0.000162811
	LOSS [training: -0.001947256262926498 | validation: 0.009100540979082925]
	TIME [epoch: 9.24 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0028495804664995595		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: -0.0028495804664995595 | validation: 0.004640936297800658]
	TIME [epoch: 9.26 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003836150714038955		[learning rate: 0.00016202]
	Learning Rate: 0.000162024
	LOSS [training: -0.003836150714038955 | validation: 0.0011103392744506802]
	TIME [epoch: 9.25 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0025166989712573267		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: -0.0025166989712573267 | validation: -8.704927571173637e-05]
	TIME [epoch: 9.24 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003930549572679716		[learning rate: 0.00016124]
	Learning Rate: 0.00016124
	LOSS [training: -0.003930549572679716 | validation: 0.003643390506319388]
	TIME [epoch: 9.24 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0027336764648585436		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: -0.0027336764648585436 | validation: 0.009359782782919976]
	TIME [epoch: 9.26 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0028987382991481126		[learning rate: 0.00016046]
	Learning Rate: 0.000160461
	LOSS [training: -0.0028987382991481126 | validation: -0.0009895843307377453]
	TIME [epoch: 9.25 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0015255708847103045		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: -0.0015255708847103045 | validation: 0.005143470866632234]
	TIME [epoch: 9.25 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0007700321478667539		[learning rate: 0.00015968]
	Learning Rate: 0.000159685
	LOSS [training: -0.0007700321478667539 | validation: 0.001063724830332866]
	TIME [epoch: 9.25 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005998038578501539		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.0005998038578501539 | validation: 0.007017708002284762]
	TIME [epoch: 9.26 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.043547030392236e-05		[learning rate: 0.00015891]
	Learning Rate: 0.000158912
	LOSS [training: 9.043547030392236e-05 | validation: -0.002045349455784315]
	TIME [epoch: 9.25 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.007480356663990689		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: -0.007480356663990689 | validation: 0.005860855230179171]
	TIME [epoch: 9.23 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006622979564923975		[learning rate: 0.00015814]
	Learning Rate: 0.000158144
	LOSS [training: -0.006622979564923975 | validation: 0.0010600839738716793]
	TIME [epoch: 9.24 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006288366398855906		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: -0.006288366398855906 | validation: 0.006048069258849085]
	TIME [epoch: 9.25 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005127015270521085		[learning rate: 0.00015738]
	Learning Rate: 0.000157379
	LOSS [training: -0.005127015270521085 | validation: 0.008303765547334578]
	TIME [epoch: 9.26 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00038771116188683673		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.00038771116188683673 | validation: 0.003155323897922933]
	TIME [epoch: 9.25 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002174748652977453		[learning rate: 0.00015662]
	Learning Rate: 0.000156618
	LOSS [training: -0.002174748652977453 | validation: 0.00026343239340693384]
	TIME [epoch: 9.24 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003797654980411933		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: -0.003797654980411933 | validation: 0.005812438271298331]
	TIME [epoch: 9.25 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0014835029772262355		[learning rate: 0.00015586]
	Learning Rate: 0.000155861
	LOSS [training: -0.0014835029772262355 | validation: -2.126187264664403e-05]
	TIME [epoch: 9.26 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005935364548434558		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: -0.005935364548434558 | validation: 0.005749087688961799]
	TIME [epoch: 9.25 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005291797792067088		[learning rate: 0.00015511]
	Learning Rate: 0.000155107
	LOSS [training: -0.0005291797792067088 | validation: -0.001153774251252137]
	TIME [epoch: 9.25 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0020839809682522818		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.0020839809682522818 | validation: 0.005892152255332128]
	TIME [epoch: 9.25 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0040842110898038604		[learning rate: 0.00015436]
	Learning Rate: 0.000154357
	LOSS [training: 0.0040842110898038604 | validation: -0.002478953846260527]
	TIME [epoch: 9.27 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0007986625736885577		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.0007986625736885577 | validation: -0.003242944986308976]
	TIME [epoch: 9.25 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0018100947868077016		[learning rate: 0.00015361]
	Learning Rate: 0.000153611
	LOSS [training: -0.0018100947868077016 | validation: -0.001033662608928977]
	TIME [epoch: 9.25 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002652527585063891		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: -0.002652527585063891 | validation: 0.005715161111312968]
	TIME [epoch: 9.25 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: -9.562834862867189e-06		[learning rate: 0.00015287]
	Learning Rate: 0.000152868
	LOSS [training: -9.562834862867189e-06 | validation: 0.00254441232926244]
	TIME [epoch: 9.27 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003348168042559893		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: -0.003348168042559893 | validation: 0.0023997466784403247]
	TIME [epoch: 9.24 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005651155017843283		[learning rate: 0.00015213]
	Learning Rate: 0.000152128
	LOSS [training: -0.005651155017843283 | validation: 0.0056317118171485365]
	TIME [epoch: 9.24 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004003836704775041		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: -0.004003836704775041 | validation: 0.013943230005367818]
	TIME [epoch: 9.24 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004560887285696134		[learning rate: 0.00015139]
	Learning Rate: 0.000151393
	LOSS [training: -0.004560887285696134 | validation: 0.010040663991182596]
	TIME [epoch: 9.26 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0029333153790730244		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: -0.0029333153790730244 | validation: 0.0006494802332668143]
	TIME [epoch: 9.24 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003083612381409512		[learning rate: 0.00015066]
	Learning Rate: 0.000150661
	LOSS [training: -0.003083612381409512 | validation: 0.00889521680719138]
	TIME [epoch: 9.24 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0045024201981853544		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: -0.0045024201981853544 | validation: 0.0007419366638031482]
	TIME [epoch: 9.25 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004361327288099489		[learning rate: 0.00014993]
	Learning Rate: 0.000149932
	LOSS [training: -0.004361327288099489 | validation: 0.001788652157048017]
	TIME [epoch: 9.26 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0030271435585903653		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: -0.0030271435585903653 | validation: -0.005340459093085318]
	TIME [epoch: 9.24 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002351302756101937		[learning rate: 0.00014921]
	Learning Rate: 0.000149207
	LOSS [training: -0.002351302756101937 | validation: 0.008615662525507752]
	TIME [epoch: 9.24 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0021826876875479942		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: -0.0021826876875479942 | validation: 0.005037923787651517]
	TIME [epoch: 9.24 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0002778597443420719		[learning rate: 0.00014849]
	Learning Rate: 0.000148486
	LOSS [training: -0.0002778597443420719 | validation: 0.009920378402245727]
	TIME [epoch: 9.26 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0026453325075830015		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: -0.0026453325075830015 | validation: 0.009333113050584622]
	TIME [epoch: 9.25 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0013429204260085046		[learning rate: 0.00014777]
	Learning Rate: 0.000147768
	LOSS [training: 0.0013429204260085046 | validation: 0.012984895754720425]
	TIME [epoch: 9.24 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002538193807505453		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.002538193807505453 | validation: 0.013145682568202319]
	TIME [epoch: 9.24 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00025491921349894567		[learning rate: 0.00014705]
	Learning Rate: 0.000147053
	LOSS [training: 0.00025491921349894567 | validation: 0.019645251732075163]
	TIME [epoch: 9.26 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0020644970669663936		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: -0.0020644970669663936 | validation: 0.021488714864069704]
	TIME [epoch: 9.24 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01191138690388786		[learning rate: 0.00014634]
	Learning Rate: 0.000146342
	LOSS [training: 0.01191138690388786 | validation: 0.02012031355992462]
	TIME [epoch: 9.24 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006025103787592405		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.006025103787592405 | validation: 0.011640305336444669]
	TIME [epoch: 9.24 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005845962783090042		[learning rate: 0.00014563]
	Learning Rate: 0.000145634
	LOSS [training: 0.005845962783090042 | validation: 0.01409135101149841]
	TIME [epoch: 9.26 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0033996691955201475		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.0033996691955201475 | validation: 0.013606192508000364]
	TIME [epoch: 9.24 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0015148739291797589		[learning rate: 0.00014493]
	Learning Rate: 0.00014493
	LOSS [training: -0.0015148739291797589 | validation: 0.00658261091177538]
	TIME [epoch: 9.23 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013805310906057568		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: -0.0013805310906057568 | validation: 0.006064759488332008]
	TIME [epoch: 9.24 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004068491672354762		[learning rate: 0.00014423]
	Learning Rate: 0.000144229
	LOSS [training: 0.004068491672354762 | validation: 0.007003299302914151]
	TIME [epoch: 9.25 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010863016738703972		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.0010863016738703972 | validation: 0.004440564453585905]
	TIME [epoch: 9.24 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004173503760827979		[learning rate: 0.00014353]
	Learning Rate: 0.000143532
	LOSS [training: 0.004173503760827979 | validation: 0.004394916941095169]
	TIME [epoch: 9.24 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014843934899270422		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.0014843934899270422 | validation: 0.003316065120363642]
	TIME [epoch: 9.24 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008657643677387651		[learning rate: 0.00014284]
	Learning Rate: 0.000142837
	LOSS [training: 0.0008657643677387651 | validation: 0.009008153253103819]
	TIME [epoch: 9.26 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0001067851540433408		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.0001067851540433408 | validation: 0.006846994259530522]
	TIME [epoch: 9.24 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0021998446433109694		[learning rate: 0.00014215]
	Learning Rate: 0.000142147
	LOSS [training: -0.0021998446433109694 | validation: -0.00032630361137831517]
	TIME [epoch: 9.24 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012964618453397661		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: -0.0012964618453397661 | validation: 0.0016700354594081966]
	TIME [epoch: 9.25 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0023487259435581134		[learning rate: 0.00014146]
	Learning Rate: 0.000141459
	LOSS [training: 0.0023487259435581134 | validation: 0.0014712493046713142]
	TIME [epoch: 9.26 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0019993846687466794		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: -0.0019993846687466794 | validation: 0.006386296977760929]
	TIME [epoch: 9.25 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004043656683856161		[learning rate: 0.00014078]
	Learning Rate: 0.000140775
	LOSS [training: -0.004043656683856161 | validation: 0.008207411187138336]
	TIME [epoch: 9.24 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005846440556484909		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: -0.0005846440556484909 | validation: 0.0029664000549040085]
	TIME [epoch: 9.24 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0034752326013445787		[learning rate: 0.00014009]
	Learning Rate: 0.000140094
	LOSS [training: -0.0034752326013445787 | validation: -0.006519266615655327]
	TIME [epoch: 9.26 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00605535157994222		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: -0.00605535157994222 | validation: 0.005857119336613739]
	TIME [epoch: 9.25 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0034120438073686073		[learning rate: 0.00013942]
	Learning Rate: 0.000139417
	LOSS [training: -0.0034120438073686073 | validation: -0.0003319797763406591]
	TIME [epoch: 9.24 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0032867834926266		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: -0.0032867834926266 | validation: -0.005527886292511673]
	TIME [epoch: 9.24 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0008300742188671443		[learning rate: 0.00013874]
	Learning Rate: 0.000138743
	LOSS [training: -0.0008300742188671443 | validation: -0.004589959285410536]
	TIME [epoch: 9.25 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0022826117894205874		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: -0.0022826117894205874 | validation: 0.011129231904081084]
	TIME [epoch: 9.25 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0040765190493677		[learning rate: 0.00013807]
	Learning Rate: 0.000138072
	LOSS [training: -0.0040765190493677 | validation: 0.0039447966407000394]
	TIME [epoch: 9.25 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.007004554784816779		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: -0.007004554784816779 | validation: 0.003322190596991983]
	TIME [epoch: 9.24 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002266077514095983		[learning rate: 0.0001374]
	Learning Rate: 0.000137404
	LOSS [training: -0.002266077514095983 | validation: 0.0015895812359803833]
	TIME [epoch: 9.24 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00248610693044993		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: -0.00248610693044993 | validation: 0.00709067579219197]
	TIME [epoch: 9.26 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002409785087124881		[learning rate: 0.00013674]
	Learning Rate: 0.00013674
	LOSS [training: -0.002409785087124881 | validation: 0.0019524616799460482]
	TIME [epoch: 9.24 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00517646247833383		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: -0.00517646247833383 | validation: 0.0010029738486656728]
	TIME [epoch: 9.24 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005623483271189578		[learning rate: 0.00013608]
	Learning Rate: 0.000136078
	LOSS [training: -0.005623483271189578 | validation: 0.0008234140709416699]
	TIME [epoch: 9.25 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0003068166289534351		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: -0.0003068166289534351 | validation: 0.0024893234584243227]
	TIME [epoch: 9.26 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.007953213312495046		[learning rate: 0.00013542]
	Learning Rate: 0.00013542
	LOSS [training: -0.007953213312495046 | validation: 0.0066102428708196895]
	TIME [epoch: 9.24 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: -9.553634977441764e-05		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: -9.553634977441764e-05 | validation: -0.002159761663206113]
	TIME [epoch: 9.25 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00471472344847237		[learning rate: 0.00013477]
	Learning Rate: 0.000134766
	LOSS [training: -0.00471472344847237 | validation: -0.0016466728018491807]
	TIME [epoch: 9.24 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003846058892374448		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: -0.003846058892374448 | validation: -0.0009285091218774757]
	TIME [epoch: 9.26 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003581159036666231		[learning rate: 0.00013411]
	Learning Rate: 0.000134114
	LOSS [training: -0.003581159036666231 | validation: 0.010221694627832333]
	TIME [epoch: 9.25 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002748311030329657		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: -0.002748311030329657 | validation: 0.00941013556454972]
	TIME [epoch: 9.25 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004628851069626017		[learning rate: 0.00013347]
	Learning Rate: 0.000133465
	LOSS [training: -0.004628851069626017 | validation: 0.01221284322794752]
	TIME [epoch: 9.24 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017856786494374968		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.0017856786494374968 | validation: 0.008070186453366313]
	TIME [epoch: 9.27 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014753270106502513		[learning rate: 0.00013282]
	Learning Rate: 0.00013282
	LOSS [training: 0.0014753270106502513 | validation: 0.001929875758948985]
	TIME [epoch: 9.25 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00011285106901543388		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: 0.00011285106901543388 | validation: 0.006738354029579751]
	TIME [epoch: 9.25 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013803037459679686		[learning rate: 0.00013218]
	Learning Rate: 0.000132178
	LOSS [training: -0.0013803037459679686 | validation: 0.0007574161850281286]
	TIME [epoch: 9.25 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010858726281455465		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: 0.0010858726281455465 | validation: 0.0052141543415786225]
	TIME [epoch: 9.26 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0036658290384752523		[learning rate: 0.00013154]
	Learning Rate: 0.000131538
	LOSS [training: -0.0036658290384752523 | validation: 0.002932968158319048]
	TIME [epoch: 9.25 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0033647930895896344		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: -0.0033647930895896344 | validation: 0.005915304382407453]
	TIME [epoch: 9.24 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004346604592670768		[learning rate: 0.0001309]
	Learning Rate: 0.000130902
	LOSS [training: -0.004346604592670768 | validation: 0.0020258218223245285]
	TIME [epoch: 9.24 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0036828444107232404		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: -0.0036828444107232404 | validation: 0.0033920307229442456]
	TIME [epoch: 9.27 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003915204933062069		[learning rate: 0.00013027]
	Learning Rate: 0.000130269
	LOSS [training: -0.003915204933062069 | validation: 0.0011571834782029469]
	TIME [epoch: 9.24 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004043681082663878		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: -0.0004043681082663878 | validation: 0.004701040917690884]
	TIME [epoch: 9.25 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0005172568834529897		[learning rate: 0.00012964]
	Learning Rate: 0.000129639
	LOSS [training: -0.0005172568834529897 | validation: 0.0012752936196940273]
	TIME [epoch: 9.24 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0026623036215689243		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: -0.0026623036215689243 | validation: 0.010136759875210455]
	TIME [epoch: 9.26 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0043599807670483505		[learning rate: 0.00012901]
	Learning Rate: 0.000129012
	LOSS [training: -0.0043599807670483505 | validation: -0.0024183348132087133]
	TIME [epoch: 9.26 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005280782340607368		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.0005280782340607368 | validation: 0.005401947429169652]
	TIME [epoch: 9.25 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0012419444143158833		[learning rate: 0.00012839]
	Learning Rate: 0.000128389
	LOSS [training: 0.0012419444143158833 | validation: 0.00614867219186274]
	TIME [epoch: 9.25 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004532567752188245		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: -0.004532567752188245 | validation: 0.011242813728086139]
	TIME [epoch: 9.26 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0002747865461809678		[learning rate: 0.00012777]
	Learning Rate: 0.000127768
	LOSS [training: 0.0002747865461809678 | validation: 0.008741628326119544]
	TIME [epoch: 9.25 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0019664293887133805		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: -0.0019664293887133805 | validation: 0.007252067206520069]
	TIME [epoch: 9.24 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005569767102912022		[learning rate: 0.00012715]
	Learning Rate: 0.00012715
	LOSS [training: -0.005569767102912022 | validation: 0.0070707938710420325]
	TIME [epoch: 9.24 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012667575665522592		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: -0.0012667575665522592 | validation: -0.009796258550160277]
	TIME [epoch: 9.26 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00035770103329026625		[learning rate: 0.00012653]
	Learning Rate: 0.000126535
	LOSS [training: 0.00035770103329026625 | validation: 0.008490992714160272]
	TIME [epoch: 9.26 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0002223848702921128		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: -0.0002223848702921128 | validation: 0.0005131636198250916]
	TIME [epoch: 9.24 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.000825869093358728		[learning rate: 0.00012592]
	Learning Rate: 0.000125923
	LOSS [training: -0.000825869093358728 | validation: 0.003175015775568152]
	TIME [epoch: 9.24 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009840818093774725		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: -0.0009840818093774725 | validation: 0.0067967484139975914]
	TIME [epoch: 9.26 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001632150255622565		[learning rate: 0.00012531]
	Learning Rate: 0.000125314
	LOSS [training: 0.001632150255622565 | validation: 0.008664980655155145]
	TIME [epoch: 9.24 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0031171939507990466		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: -0.0031171939507990466 | validation: 0.0039625281801690055]
	TIME [epoch: 9.25 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0011925550087555775		[learning rate: 0.00012471]
	Learning Rate: 0.000124708
	LOSS [training: -0.0011925550087555775 | validation: 0.01066912621114114]
	TIME [epoch: 9.25 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0014990323380776457		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: 0.0014990323380776457 | validation: 0.009081810274361888]
	TIME [epoch: 9.26 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013303628456604103		[learning rate: 0.00012411]
	Learning Rate: 0.000124105
	LOSS [training: -0.0013303628456604103 | validation: 0.004303574270928078]
	TIME [epoch: 9.25 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005757715259516967		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.0005757715259516967 | validation: -0.001134975077372286]
	TIME [epoch: 9.25 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004380317320461677		[learning rate: 0.0001235]
	Learning Rate: 0.000123505
	LOSS [training: -0.004380317320461677 | validation: 0.0072982565970264954]
	TIME [epoch: 9.24 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0011093551413059546		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: -0.0011093551413059546 | validation: 0.0038668863703423544]
	TIME [epoch: 9.25 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.786452192536871e-05		[learning rate: 0.00012291]
	Learning Rate: 0.000122908
	LOSS [training: 1.786452192536871e-05 | validation: -0.00152898182285209]
	TIME [epoch: 9.25 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001301694001231967		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: -0.001301694001231967 | validation: 0.0023354735221975597]
	TIME [epoch: 9.25 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005405686243064314		[learning rate: 0.00012231]
	Learning Rate: 0.000122313
	LOSS [training: 0.0005405686243064314 | validation: -0.0005384347092570792]
	TIME [epoch: 9.25 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004608372599056236		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: 0.004608372599056236 | validation: -0.003038546697478252]
	TIME [epoch: 9.24 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004355913029363405		[learning rate: 0.00012172]
	Learning Rate: 0.000121722
	LOSS [training: 0.004355913029363405 | validation: 0.014045042683924945]
	TIME [epoch: 9.27 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005959841021215261		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: 0.005959841021215261 | validation: 0.008179802325120526]
	TIME [epoch: 9.24 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019058352571759067		[learning rate: 0.00012113]
	Learning Rate: 0.000121133
	LOSS [training: 0.0019058352571759067 | validation: 0.002828207828501226]
	TIME [epoch: 9.25 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003505617988636942		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: 0.003505617988636942 | validation: -0.0032634020631526327]
	TIME [epoch: 9.25 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001501963407323239		[learning rate: 0.00012055]
	Learning Rate: 0.000120547
	LOSS [training: 0.001501963407323239 | validation: 0.008827400660392422]
	TIME [epoch: 9.27 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.001280140829937919		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: -0.001280140829937919 | validation: 0.006622392800080637]
	TIME [epoch: 9.25 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004782040781639435		[learning rate: 0.00011996]
	Learning Rate: 0.000119964
	LOSS [training: 0.004782040781639435 | validation: 0.002309303404348344]
	TIME [epoch: 9.25 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0019152187380861014		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: -0.0019152187380861014 | validation: 0.008541170297435615]
	TIME [epoch: 9.25 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0010366485822089484		[learning rate: 0.00011938]
	Learning Rate: 0.000119384
	LOSS [training: -0.0010366485822089484 | validation: 0.008830320898139461]
	TIME [epoch: 9.27 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0031728640907480307		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: -0.0031728640907480307 | validation: 0.015080480506583532]
	TIME [epoch: 9.25 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0012616276695891012		[learning rate: 0.00011881]
	Learning Rate: 0.000118807
	LOSS [training: -0.0012616276695891012 | validation: 0.00042839693654789625]
	TIME [epoch: 9.25 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004344615218741825		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: -0.004344615218741825 | validation: 0.002540801409424807]
	TIME [epoch: 9.25 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.006246593624221285		[learning rate: 0.00011823]
	Learning Rate: 0.000118232
	LOSS [training: -0.006246593624221285 | validation: 0.008748093754498979]
	TIME [epoch: 9.27 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.000982571077494206		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: 0.000982571077494206 | validation: 0.009819156227377215]
	TIME [epoch: 9.26 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: -4.3697335318406205e-05		[learning rate: 0.00011766]
	Learning Rate: 0.000117661
	LOSS [training: -4.3697335318406205e-05 | validation: -0.00011032933220956775]
	TIME [epoch: 9.25 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0008200017696036327		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: -0.0008200017696036327 | validation: 0.0019341480493310992]
	TIME [epoch: 9.26 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0010791388156462633		[learning rate: 0.00011709]
	Learning Rate: 0.000117092
	LOSS [training: -0.0010791388156462633 | validation: 0.0060560938800709495]
	TIME [epoch: 9.28 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005639178211504546		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: -0.005639178211504546 | validation: 0.0014310181987441074]
	TIME [epoch: 9.26 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008557520932946916		[learning rate: 0.00011653]
	Learning Rate: 0.000116526
	LOSS [training: 0.0008557520932946916 | validation: -0.0015963345985380612]
	TIME [epoch: 9.25 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00508969186885713		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: -0.00508969186885713 | validation: 0.010468908079084162]
	TIME [epoch: 9.26 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0021051806003900197		[learning rate: 0.00011596]
	Learning Rate: 0.000115962
	LOSS [training: -0.0021051806003900197 | validation: -0.005912677697852727]
	TIME [epoch: 9.27 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004440848529293894		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: -0.0004440848529293894 | validation: 0.002664964657963077]
	TIME [epoch: 9.25 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.003781764329472942		[learning rate: 0.0001154]
	Learning Rate: 0.000115401
	LOSS [training: -0.003781764329472942 | validation: 0.006813435345587308]
	TIME [epoch: 9.26 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.929334831804555e-05		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: 6.929334831804555e-05 | validation: 0.0002156226624911396]
	TIME [epoch: 9.25 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0011422289121702932		[learning rate: 0.00011484]
	Learning Rate: 0.000114843
	LOSS [training: -0.0011422289121702932 | validation: 0.00702336445407147]
	TIME [epoch: 9.28 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021548706989239276		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: 0.0021548706989239276 | validation: 0.004940116597118922]
	TIME [epoch: 9.25 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007732249822372852		[learning rate: 0.00011429]
	Learning Rate: 0.000114288
	LOSS [training: 0.007732249822372852 | validation: 0.01022197094031876]
	TIME [epoch: 9.25 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006706285948399756		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: 0.006706285948399756 | validation: 0.012147512643483209]
	TIME [epoch: 9.25 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0048833989692014705		[learning rate: 0.00011374]
	Learning Rate: 0.000113735
	LOSS [training: 0.0048833989692014705 | validation: 0.011118776054066696]
	TIME [epoch: 9.28 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007661633610124468		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: 0.007661633610124468 | validation: 0.010404224616874548]
	TIME [epoch: 9.27 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004399670309073655		[learning rate: 0.00011319]
	Learning Rate: 0.000113185
	LOSS [training: 0.004399670309073655 | validation: 0.0025134606371635428]
	TIME [epoch: 9.26 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002722609173324535		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: 0.002722609173324535 | validation: 0.0130627871102059]
	TIME [epoch: 9.26 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002183320887020381		[learning rate: 0.00011264]
	Learning Rate: 0.000112638
	LOSS [training: 0.002183320887020381 | validation: 0.010175764733926814]
	TIME [epoch: 9.27 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0024899808389274103		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: 0.0024899808389274103 | validation: 0.009741023661910177]
	TIME [epoch: 9.24 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0017965890574396278		[learning rate: 0.00011209]
	Learning Rate: 0.000112093
	LOSS [training: 0.0017965890574396278 | validation: 0.003119590549652107]
	TIME [epoch: 9.23 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00033018386750523974		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: 0.00033018386750523974 | validation: 0.004772414781228233]
	TIME [epoch: 9.26 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003887487295954041		[learning rate: 0.00011155]
	Learning Rate: 0.000111551
	LOSS [training: 0.003887487295954041 | validation: 0.004866507871028941]
	TIME [epoch: 9.28 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009038865672543432		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: -0.0009038865672543432 | validation: 0.006376376475491336]
	TIME [epoch: 9.27 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0010583340156565515		[learning rate: 0.00011101]
	Learning Rate: 0.000111012
	LOSS [training: -0.0010583340156565515 | validation: 7.200387384757043e-06]
	TIME [epoch: 9.26 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002451101675095837		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: -0.002451101675095837 | validation: 0.0032767568759967357]
	TIME [epoch: 9.27 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00029749277770572556		[learning rate: 0.00011047]
	Learning Rate: 0.000110475
	LOSS [training: 0.00029749277770572556 | validation: 0.010696025179714831]
	TIME [epoch: 9.28 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0061171691723905085		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: 0.0061171691723905085 | validation: 0.016485732610466416]
	TIME [epoch: 9.29 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0019212451676990164		[learning rate: 0.00010994]
	Learning Rate: 0.000109941
	LOSS [training: 0.0019212451676990164 | validation: 0.010091984991237148]
	TIME [epoch: 9.27 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005878087653883094		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.005878087653883094 | validation: 0.020504634947953494]
	TIME [epoch: 9.26 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029342178130383188		[learning rate: 0.00010941]
	Learning Rate: 0.000109409
	LOSS [training: 0.0029342178130383188 | validation: 0.005899454122523475]
	TIME [epoch: 9.28 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0062957395510368445		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: 0.0062957395510368445 | validation: 0.005150721202811293]
	TIME [epoch: 9.29 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0004607054038291744		[learning rate: 0.00010888]
	Learning Rate: 0.00010888
	LOSS [training: 0.0004607054038291744 | validation: 0.006087486188035281]
	TIME [epoch: 9.27 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006673065085171786		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: -0.0006673065085171786 | validation: 0.0039454011965760535]
	TIME [epoch: 9.27 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00014733943019575122		[learning rate: 0.00010835]
	Learning Rate: 0.000108353
	LOSS [training: 0.00014733943019575122 | validation: -2.0775101788936875e-05]
	TIME [epoch: 9.27 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.00332451445440875		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: -0.00332451445440875 | validation: 0.003007950465385676]
	TIME [epoch: 9.28 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0023991171190731126		[learning rate: 0.00010783]
	Learning Rate: 0.000107829
	LOSS [training: -0.0023991171190731126 | validation: -0.0028196499335520916]
	TIME [epoch: 9.28 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0005312583555648037		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: 0.0005312583555648037 | validation: 0.007728632120552759]
	TIME [epoch: 9.28 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002983210630045386		[learning rate: 0.00010731]
	Learning Rate: 0.000107308
	LOSS [training: 0.002983210630045386 | validation: 0.00844765851519853]
	TIME [epoch: 9.28 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0006966737983897146		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: -0.0006966737983897146 | validation: -0.0019165639000356682]
	TIME [epoch: 9.3 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002252828939436232		[learning rate: 0.00010679]
	Learning Rate: 0.000106789
	LOSS [training: 0.002252828939436232 | validation: 0.007747068440616093]
	TIME [epoch: 9.28 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.005456385109849899		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: -0.005456385109849899 | validation: 0.007275630222626243]
	TIME [epoch: 9.29 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004047688625536091		[learning rate: 0.00010627]
	Learning Rate: 0.000106273
	LOSS [training: 0.004047688625536091 | validation: 0.0022751984049985755]
	TIME [epoch: 9.28 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004812723865799008		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: -0.0004812723865799008 | validation: 0.00885222232147085]
	TIME [epoch: 9.3 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0011661831316374135		[learning rate: 0.00010576]
	Learning Rate: 0.000105759
	LOSS [training: -0.0011661831316374135 | validation: 0.000392337097958219]
	TIME [epoch: 9.29 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0022765876938640557		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: -0.0022765876938640557 | validation: -0.0018830958089956587]
	TIME [epoch: 9.27 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002805944753401032		[learning rate: 0.00010525]
	Learning Rate: 0.000105247
	LOSS [training: -0.002805944753401032 | validation: 0.003207007705824507]
	TIME [epoch: 9.28 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.001775051332374046		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.001775051332374046 | validation: 0.003171694709344294]
	TIME [epoch: 9.29 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0020896613900353578		[learning rate: 0.00010474]
	Learning Rate: 0.000104738
	LOSS [training: -0.0020896613900353578 | validation: 0.003392778533583959]
	TIME [epoch: 9.27 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010433977801852221		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.0010433977801852221 | validation: 0.009933658915301048]
	TIME [epoch: 9.26 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0017149351490818514		[learning rate: 0.00010423]
	Learning Rate: 0.000104232
	LOSS [training: -0.0017149351490818514 | validation: 0.010230409632201929]
	TIME [epoch: 9.25 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004151668385771059		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: -0.004151668385771059 | validation: 0.004962702570109672]
	TIME [epoch: 9.28 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004868982285435543		[learning rate: 0.00010373]
	Learning Rate: 0.000103728
	LOSS [training: -0.004868982285435543 | validation: 0.00442929794732955]
	TIME [epoch: 9.27 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.004898331086475637		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: -0.004898331086475637 | validation: -0.00137751860159084]
	TIME [epoch: 9.27 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0014752342533303846		[learning rate: 0.00010323]
	Learning Rate: 0.000103226
	LOSS [training: -0.0014752342533303846 | validation: 0.004057354304487346]
	TIME [epoch: 9.27 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002964421035116572		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: -0.002964421035116572 | validation: 0.001965949899545988]
	TIME [epoch: 9.28 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0013791718516229282		[learning rate: 0.00010273]
	Learning Rate: 0.000102727
	LOSS [training: -0.0013791718516229282 | validation: 0.005303594663153888]
	TIME [epoch: 9.27 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002295986363209851		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: 0.002295986363209851 | validation: 0.004010188014077202]
	TIME [epoch: 9.27 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.000912384082574235		[learning rate: 0.00010223]
	Learning Rate: 0.00010223
	LOSS [training: -0.000912384082574235 | validation: 0.007670976243454319]
	TIME [epoch: 9.27 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004417884326938265		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: -0.0004417884326938265 | validation: 0.004162609399037604]
	TIME [epoch: 9.29 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0004154630233421828		[learning rate: 0.00010174]
	Learning Rate: 0.000101736
	LOSS [training: -0.0004154630233421828 | validation: -0.0042499728025699925]
	TIME [epoch: 9.28 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.0009542127998147648		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: -0.0009542127998147648 | validation: -0.0019316032282552793]
	TIME [epoch: 9.32 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002125329716722327		[learning rate: 0.00010124]
	Learning Rate: 0.000101244
	LOSS [training: -0.002125329716722327 | validation: 0.004932698299707064]
	TIME [epoch: 9.27 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: -0.002104691122920854		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: -0.002104691122920854 | validation: -0.002892306988976966]
	TIME [epoch: 9.29 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0004183470712747361		[learning rate: 0.00010075]
	Learning Rate: 0.000100754
	LOSS [training: 0.0004183470712747361 | validation: 0.004560841446958435]
	TIME [epoch: 9.27 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.000447160274464972		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.000447160274464972 | validation: 0.007984645167831348]
	TIME [epoch: 9.27 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0002820489902768602		[learning rate: 0.00010027]
	Learning Rate: 0.000100267
	LOSS [training: 0.0002820489902768602 | validation: 0.01425524622154766]
	TIME [epoch: 9.28 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0008275327319141122		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.0008275327319141122 | validation: -0.005125846314424259]
	TIME [epoch: 9.3 sec]
Finished training in 18628.028 seconds.
