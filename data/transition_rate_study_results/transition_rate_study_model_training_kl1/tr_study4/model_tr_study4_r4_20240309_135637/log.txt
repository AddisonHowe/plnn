Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r4', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1053579966

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.996324654151399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.996324654151399 | validation: 7.8346716955976605]
	TIME [epoch: 99.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.086996013033108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.086996013033108 | validation: 5.636483778442288]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.429128550903098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.429128550903098 | validation: 4.518425610993349]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.308576614284694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.308576614284694 | validation: 5.734227570459039]
	TIME [epoch: 11.5 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.613469898626984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.613469898626984 | validation: 3.675415977016267]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.106737780111624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.106737780111624 | validation: 3.663011892047353]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.746193423554359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.746193423554359 | validation: 3.440976135739686]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5795918631809145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5795918631809145 | validation: 3.4143242230664863]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.322939705375862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.322939705375862 | validation: 3.1584794409893875]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.288343247358861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.288343247358861 | validation: 4.262386434843482]
	TIME [epoch: 11.5 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5998057437388526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5998057437388526 | validation: 2.9524271530865303]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9692906970719246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9692906970719246 | validation: 2.9766987021916407]
	TIME [epoch: 11.5 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.898667834610452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.898667834610452 | validation: 4.195287698507384]
	TIME [epoch: 11.5 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.444714528638853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.444714528638853 | validation: 3.5866954925012546]
	TIME [epoch: 11.5 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2948636064805514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2948636064805514 | validation: 2.9811182611697746]
	TIME [epoch: 11.4 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9180346835646294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9180346835646294 | validation: 3.435655478759422]
	TIME [epoch: 11.5 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.560966864498912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.560966864498912 | validation: 2.8867709079470854]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7672110841213486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7672110841213486 | validation: 2.7581019134997065]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0199719931791025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0199719931791025 | validation: 2.6784811709127667]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.594408679328263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.594408679328263 | validation: 2.4348413904087556]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.782074789583014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.782074789583014 | validation: 3.1872601093751927]
	TIME [epoch: 11.4 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6835469547539406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6835469547539406 | validation: 2.7893847700017727]
	TIME [epoch: 11.4 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2217233581189646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2217233581189646 | validation: 3.3429046509278306]
	TIME [epoch: 11.5 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.828960758905984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.828960758905984 | validation: 2.445188214932401]
	TIME [epoch: 11.4 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.25199426560934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.25199426560934 | validation: 2.1285864504557073]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287073574427077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.287073574427077 | validation: 2.2074073408809345]
	TIME [epoch: 11.5 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083196918786207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.083196918786207 | validation: 1.9354586452958358]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8561885578180677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8561885578180677 | validation: 1.8293807078892468]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.578368025499534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.578368025499534 | validation: 1.4455964279148577]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7471703800175777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7471703800175777 | validation: 1.3282336375767063]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3200458268973794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3200458268973794 | validation: 1.6515536211655126]
	TIME [epoch: 11.5 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4552507536122725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4552507536122725 | validation: 1.3179834062246982]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1197896246418286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1197896246418286 | validation: 1.3907430277938457]
	TIME [epoch: 11.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2338879291928804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2338879291928804 | validation: 1.6529898724171346]
	TIME [epoch: 11.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2441361839148004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2441361839148004 | validation: 1.0880430607046356]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1643050402601514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1643050402601514 | validation: 1.0111656353343]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0591624057354048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0591624057354048 | validation: 2.126818735017755]
	TIME [epoch: 11.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3514690426371987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3514690426371987 | validation: 0.750944145976445]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8469409768803735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8469409768803735 | validation: 0.6601391613633694]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.742850804462212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.742850804462212 | validation: 0.5587957314942784]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8373880289358911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8373880289358911 | validation: 0.7467671872685062]
	TIME [epoch: 11.5 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9034475801031849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9034475801031849 | validation: 1.178126658956546]
	TIME [epoch: 11.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.950718853440952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.950718853440952 | validation: 1.487236381196218]
	TIME [epoch: 11.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0327905818214178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0327905818214178 | validation: 0.8906455019386005]
	TIME [epoch: 11.5 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9115709133846257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9115709133846257 | validation: 0.9222817044290761]
	TIME [epoch: 11.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9625420807746742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9625420807746742 | validation: 0.8042985787129118]
	TIME [epoch: 11.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7921129598063237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7921129598063237 | validation: 0.9294434119381672]
	TIME [epoch: 11.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218559718019276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7218559718019276 | validation: 0.6801409877132892]
	TIME [epoch: 11.5 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7071388427941198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7071388427941198 | validation: 1.15311756444723]
	TIME [epoch: 11.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8125050162631093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8125050162631093 | validation: 0.7754483646675272]
	TIME [epoch: 11.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.541532749459858		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.541532749459858 | validation: 1.6081561545299368]
	TIME [epoch: 11.5 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1716611855927581		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.1716611855927581 | validation: 0.790387774168481]
	TIME [epoch: 11.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7358661354468307		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.7358661354468307 | validation: 0.7553239416976771]
	TIME [epoch: 11.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7832100795181984		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.7832100795181984 | validation: 0.8906322232466886]
	TIME [epoch: 11.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8796723968605493		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.8796723968605493 | validation: 0.670324244845433]
	TIME [epoch: 11.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6623086394237485		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.6623086394237485 | validation: 0.6320001999586112]
	TIME [epoch: 11.5 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7771046209256		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.7771046209256 | validation: 1.340770424337437]
	TIME [epoch: 11.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1292997800312523		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.1292997800312523 | validation: 0.7219907366804411]
	TIME [epoch: 11.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7448362631183438		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.7448362631183438 | validation: 0.7506042565517381]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8094842564723361		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.8094842564723361 | validation: 0.6971299203785418]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7399721649752653		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.7399721649752653 | validation: 0.6319744544019088]
	TIME [epoch: 11.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.759782246149104		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.759782246149104 | validation: 0.6466526182818387]
	TIME [epoch: 11.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9962315394931438		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.9962315394931438 | validation: 0.9678810912552589]
	TIME [epoch: 11.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7414605837943691		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.7414605837943691 | validation: 1.2539063335826128]
	TIME [epoch: 11.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113724312383691		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.8113724312383691 | validation: 0.7100518278764681]
	TIME [epoch: 11.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2080545695464622		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.2080545695464622 | validation: 2.211693345323808]
	TIME [epoch: 11.5 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5014561421887538		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.5014561421887538 | validation: 1.0059265372160227]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8365151578132022		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.8365151578132022 | validation: 1.0619452651259214]
	TIME [epoch: 11.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9214776369223382		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.9214776369223382 | validation: 0.8616733259577619]
	TIME [epoch: 11.5 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8414325610714108		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.8414325610714108 | validation: 0.6778133777923236]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7054317269315746		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.7054317269315746 | validation: 0.7994532862286178]
	TIME [epoch: 11.5 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7482126776406197		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.7482126776406197 | validation: 0.6253867182407886]
	TIME [epoch: 11.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7658963921634886		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.7658963921634886 | validation: 0.6648667744008031]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984701785386601		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.6984701785386601 | validation: 0.7219177088288015]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7400763034905661		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.7400763034905661 | validation: 1.4913661329724466]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9438741782539929		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.9438741782539929 | validation: 0.8734035178630336]
	TIME [epoch: 11.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.792076638791048		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.792076638791048 | validation: 0.6849946073853918]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6903434901766955		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.6903434901766955 | validation: 0.6324167290689575]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.676818198026184		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.676818198026184 | validation: 0.6928158453983869]
	TIME [epoch: 11.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.320838514874363		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.320838514874363 | validation: 4.14367117862772]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.217301537433452		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.217301537433452 | validation: 3.6574974849651425]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6747078781242215		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.6747078781242215 | validation: 3.4689390319715154]
	TIME [epoch: 11.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.541966442943487		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.541966442943487 | validation: 3.371122329434143]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4918873362564993		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.4918873362564993 | validation: 3.53219285521443]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.552373703771792		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.552373703771792 | validation: 3.3394868844708343]
	TIME [epoch: 11.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4930010833006775		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.4930010833006775 | validation: 3.6979974110238807]
	TIME [epoch: 11.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7691747031362484		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.7691747031362484 | validation: 3.4213347646263355]
	TIME [epoch: 11.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4780240377788925		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.4780240377788925 | validation: 3.3173251466020974]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4298401757716714		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.4298401757716714 | validation: 3.4951781671909816]
	TIME [epoch: 11.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9152071651235705		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.9152071651235705 | validation: 3.024346490324939]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7125142762782497		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.7125142762782497 | validation: 3.4319676783796425]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2953465908828434		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.2953465908828434 | validation: 3.23324022697033]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1980762719020523		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.1980762719020523 | validation: 3.069007127185472]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.635627948251299		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.635627948251299 | validation: 3.250960545174735]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5560444105311593		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.5560444105311593 | validation: 3.559420282893475]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.501402202566097		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.501402202566097 | validation: 3.0853898366566774]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6133239079930934		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.6133239079930934 | validation: 2.894408921974858]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.186915817422103		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.186915817422103 | validation: 3.1357474049357394]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.263771810077513		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.263771810077513 | validation: 3.073805668615686]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.163296701228597		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.163296701228597 | validation: 3.2004510069198977]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1713125908279474		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.1713125908279474 | validation: 3.27874062359311]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1613874647573055		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.1613874647573055 | validation: 3.313248897448524]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1550116020339742		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.1550116020339742 | validation: 2.7938759779541384]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215854225250864		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.215854225250864 | validation: 2.923853153062997]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8814113903711362		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.8814113903711362 | validation: 1.7915692467853837]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6685338443548996		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.6685338443548996 | validation: 1.4968784869330056]
	TIME [epoch: 11.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0701509508870966		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.0701509508870966 | validation: 0.7192779867214878]
	TIME [epoch: 11.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9909469905284232		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.9909469905284232 | validation: 0.8303728360949707]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7415537132184458		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.7415537132184458 | validation: 0.9913621885240741]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8411848893068794		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.8411848893068794 | validation: 0.6982853932227282]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7125270868156568		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.7125270868156568 | validation: 0.7959335261993017]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8967036287162903		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.8967036287162903 | validation: 0.7075580709958752]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8377136432291092		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.8377136432291092 | validation: 0.7476383465401446]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7731125900571204		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.7731125900571204 | validation: 0.6976940518475044]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6565454843186842		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.6565454843186842 | validation: 1.3465964946540394]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.219930774834781		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.219930774834781 | validation: 0.8983417710786394]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.714188659916724		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.714188659916724 | validation: 0.9720142355851639]
	TIME [epoch: 11.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7328349004612346		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.7328349004612346 | validation: 0.6024483351661006]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5808246006666054		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.5808246006666054 | validation: 0.6477150298807761]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5839232881615607		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.5839232881615607 | validation: 1.228763947386789]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8885486439234075		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.8885486439234075 | validation: 0.5723102775513736]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6242575016212922		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.6242575016212922 | validation: 0.7015721139875893]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5895600153099302		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.5895600153099302 | validation: 0.5795837093268443]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5484108253080188		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.5484108253080188 | validation: 0.8023272935955441]
	TIME [epoch: 11.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963834971584987		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.6963834971584987 | validation: 0.5762171038850081]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6149093024273631		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.6149093024273631 | validation: 0.6538550968282664]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7255122063846127		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.7255122063846127 | validation: 0.6094047793733418]
	TIME [epoch: 11.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6709152101423865		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.6709152101423865 | validation: 0.5737507386731613]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6650151314326455		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.6650151314326455 | validation: 0.5601924991768124]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.706953801328135		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.706953801328135 | validation: 0.9938998230230874]
	TIME [epoch: 11.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7918548019160907		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.7918548019160907 | validation: 0.5660117866316398]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.745218530874722		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.745218530874722 | validation: 0.6129767982249369]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8107121560548869		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.8107121560548869 | validation: 0.7072572243508727]
	TIME [epoch: 11.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848770213883552		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.6848770213883552 | validation: 0.731774061157547]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7011868801577877		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.7011868801577877 | validation: 0.6670568659926696]
	TIME [epoch: 11.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9428084172805531		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.9428084172805531 | validation: 0.803515538777699]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049624372266364		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.7049624372266364 | validation: 0.6156315046783156]
	TIME [epoch: 11.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6008997481387901		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.6008997481387901 | validation: 0.6007912599115945]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6471424040581962		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.6471424040581962 | validation: 0.7124289692758492]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.970141635457674		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.970141635457674 | validation: 0.6230508841876637]
	TIME [epoch: 11.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5752067181882327		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.5752067181882327 | validation: 0.5367935288383034]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.598739043700228		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.598739043700228 | validation: 0.5578632755490008]
	TIME [epoch: 11.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9466925570686701		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.9466925570686701 | validation: 0.8303548357720442]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7112793816235023		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.7112793816235023 | validation: 0.6788200058885687]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5971304728780796		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.5971304728780796 | validation: 0.5459484018647771]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6176053067404315		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.6176053067404315 | validation: 0.6092193215268012]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8532549475729123		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.8532549475729123 | validation: 0.6956567775482294]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6779018286461287		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.6779018286461287 | validation: 0.5785774785062275]
	TIME [epoch: 11.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5350071493260876		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.5350071493260876 | validation: 0.5573183218360055]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7070705126303221		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.7070705126303221 | validation: 0.6423143601032024]
	TIME [epoch: 11.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6003641496017168		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.6003641496017168 | validation: 0.5470945835857791]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5415194813240568		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.5415194813240568 | validation: 0.5807639264868217]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5218065128424899		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.5218065128424899 | validation: 0.5006149124612392]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4760337880787584		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.4760337880787584 | validation: 0.5452896464468279]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5400808674509863		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.5400808674509863 | validation: 0.65694499271527]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3499674894185747		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.3499674894185747 | validation: 1.1806719942916772]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.970972213600261		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.970972213600261 | validation: 0.5689606990979325]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.658078125779122		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.658078125779122 | validation: 0.6245085736673917]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6597014207348186		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.6597014207348186 | validation: 0.687586202550285]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5826791837075966		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.5826791837075966 | validation: 0.5602267226455565]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5235130347694938		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.5235130347694938 | validation: 0.6187766717905774]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5885488248250612		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.5885488248250612 | validation: 0.48010859331470884]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7180769337736507		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.7180769337736507 | validation: 0.5552516485429785]
	TIME [epoch: 11.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5979003876207044		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.5979003876207044 | validation: 0.7093170488792311]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.546928104509635		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.546928104509635 | validation: 0.6789892551273069]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4938360120270851		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.4938360120270851 | validation: 0.46842395785771035]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5707527774226451		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.5707527774226451 | validation: 0.5183158522293929]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112413845645261		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.5112413845645261 | validation: 0.5050758797086659]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6714282843300441		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.6714282843300441 | validation: 0.49064274989207224]
	TIME [epoch: 11.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5361651378304229		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.5361651378304229 | validation: 0.6665980829662554]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6087327762256279		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.6087327762256279 | validation: 0.5197632841561368]
	TIME [epoch: 11.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5663169460943231		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.5663169460943231 | validation: 0.48633355351572366]
	TIME [epoch: 11.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5314157521992916		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.5314157521992916 | validation: 0.4627433590414093]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5018588140474317		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.5018588140474317 | validation: 0.4949635658842894]
	TIME [epoch: 11.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4337175521468802		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.4337175521468802 | validation: 0.6226023519610984]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5737091500098327		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.5737091500098327 | validation: 0.615180405251322]
	TIME [epoch: 11.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5294116920583136		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.5294116920583136 | validation: 0.711327761507265]
	TIME [epoch: 11.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5093861735452239		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.5093861735452239 | validation: 0.6123065896414097]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5828209278531838		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.5828209278531838 | validation: 0.607945358950405]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5197007145035121		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.5197007145035121 | validation: 0.4961774373949321]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579189795957407		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.5579189795957407 | validation: 0.8556018495401411]
	TIME [epoch: 11.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.644070724753013		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.644070724753013 | validation: 0.5611096185943383]
	TIME [epoch: 11.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.533900689204599		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.533900689204599 | validation: 0.46313274613401845]
	TIME [epoch: 11.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5127526330952286		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.5127526330952286 | validation: 0.5088373496055054]
	TIME [epoch: 11.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4812228029936929		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.4812228029936929 | validation: 0.8307680815852235]
	TIME [epoch: 11.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859649580491056		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.6859649580491056 | validation: 0.4696158422053234]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5369225965129882		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.5369225965129882 | validation: 0.5902973459358706]
	TIME [epoch: 11.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5291396591181013		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.5291396591181013 | validation: 0.5567307493405528]
	TIME [epoch: 11.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5060793369523846		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.5060793369523846 | validation: 0.5480390567217285]
	TIME [epoch: 11.4 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47768504683907487		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.47768504683907487 | validation: 0.4414199213891752]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.419767657341392		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.419767657341392 | validation: 0.4933855118227492]
	TIME [epoch: 11.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40575101073777553		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.40575101073777553 | validation: 0.46185918000934784]
	TIME [epoch: 11.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5724769770582697		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.5724769770582697 | validation: 0.6136100087579722]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49913215771371056		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.49913215771371056 | validation: 0.4852434921667988]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42059271897060807		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.42059271897060807 | validation: 0.42625645345052404]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390369216761977		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.6390369216761977 | validation: 0.48029497405771815]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45432164379770346		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.45432164379770346 | validation: 0.520989274153463]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48654231108398005		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.48654231108398005 | validation: 0.4855187460161538]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4140561901244159		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.4140561901244159 | validation: 0.40372669010362217]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6479082700016272		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.6479082700016272 | validation: 0.6061723720440833]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5224521086918523		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.5224521086918523 | validation: 0.544798058321949]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42623556528849454		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.42623556528849454 | validation: 0.3927310247603228]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4004432111437522		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.4004432111437522 | validation: 0.5780562022364713]
	TIME [epoch: 11.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4896848971350489		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.4896848971350489 | validation: 0.42243093998600856]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37685722094319246		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.37685722094319246 | validation: 0.3697142573283216]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5310288200016546		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.5310288200016546 | validation: 0.49594304581930887]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3904597589043243		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.3904597589043243 | validation: 0.37819366153668604]
	TIME [epoch: 11.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44743804744775534		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.44743804744775534 | validation: 0.3238657115314012]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4489610351940988		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.4489610351940988 | validation: 0.4990792116977735]
	TIME [epoch: 11.4 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42119063349139685		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.42119063349139685 | validation: 0.5292320038373564]
	TIME [epoch: 11.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568760223039462		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.568760223039462 | validation: 0.39611806885055173]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44061338598384214		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.44061338598384214 | validation: 0.6051263936215288]
	TIME [epoch: 11.4 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5331945130821302		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.5331945130821302 | validation: 0.5582639777426689]
	TIME [epoch: 11.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5469755523573195		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.5469755523573195 | validation: 0.4476915383312678]
	TIME [epoch: 11.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40404971892570607		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.40404971892570607 | validation: 0.3310500817014099]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35596728988143805		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.35596728988143805 | validation: 0.34763029916108673]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3391589919889433		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.3391589919889433 | validation: 0.4929197379701577]
	TIME [epoch: 11.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4741998924089363		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.4741998924089363 | validation: 0.692173276720408]
	TIME [epoch: 11.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5100122803075291		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.5100122803075291 | validation: 0.3150463817361998]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3880916575640589		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.3880916575640589 | validation: 0.44181739957907035]
	TIME [epoch: 11.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3407131958484472		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.3407131958484472 | validation: 0.3481791674465428]
	TIME [epoch: 11.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39629006509058146		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.39629006509058146 | validation: 0.6042201987743024]
	TIME [epoch: 11.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.433031496751967		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.433031496751967 | validation: 0.21950156962864134]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27953220407411494		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.27953220407411494 | validation: 0.6034068788176177]
	TIME [epoch: 11.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4589110130218243		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.4589110130218243 | validation: 0.3551900735950249]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36449658932680457		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.36449658932680457 | validation: 0.2862091735659535]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4126621459810098		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.4126621459810098 | validation: 0.353868392777544]
	TIME [epoch: 11.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37611145069125157		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.37611145069125157 | validation: 0.3490027931357879]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3016412368163413		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.3016412368163413 | validation: 0.2779797259481635]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2581450527783857		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.2581450527783857 | validation: 0.22935308446885586]
	TIME [epoch: 11.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4160775225415772		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.4160775225415772 | validation: 0.34388301652138076]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3414456138394011		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.3414456138394011 | validation: 0.2336920668445861]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24494823870287646		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.24494823870287646 | validation: 0.6411714424015432]
	TIME [epoch: 11.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4207927138398565		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.4207927138398565 | validation: 0.23815382242632172]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2808012718882351		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.2808012718882351 | validation: 0.34850313532536864]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3561235380670029		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.3561235380670029 | validation: 0.2076611057258313]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3685214973610983		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.3685214973610983 | validation: 0.47607628491369564]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45242625186476765		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.45242625186476765 | validation: 0.2206050101123359]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34529755455071376		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.34529755455071376 | validation: 0.1995587790552164]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2141741902029496		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.2141741902029496 | validation: 0.30525401470492314]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3934826200557615		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.3934826200557615 | validation: 0.27519109797384894]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4601225831570245		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.4601225831570245 | validation: 0.5980702718926353]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5365665722951654		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.5365665722951654 | validation: 0.3149829590917667]
	TIME [epoch: 11.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3023283182887608		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.3023283182887608 | validation: 0.24292716773684894]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2310310417084807		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.2310310417084807 | validation: 0.37104359039616636]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33355349336339735		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.33355349336339735 | validation: 0.28517280932700795]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5378412789813356		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.5378412789813356 | validation: 0.7689908603629821]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6090474947110252		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.6090474947110252 | validation: 0.4713329297899507]
	TIME [epoch: 11.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.430900439907823		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.430900439907823 | validation: 0.39498218893696974]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.375872371406828		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.375872371406828 | validation: 0.36372527337606936]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3512160784126104		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.3512160784126104 | validation: 0.5043814394604011]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36154217409653194		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.36154217409653194 | validation: 0.2970317172466291]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3115942727603269		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.3115942727603269 | validation: 0.329791695934016]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4056957514313901		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.4056957514313901 | validation: 0.5000915478599168]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4981636401133115		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.4981636401133115 | validation: 0.38116416328379127]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3033475359957765		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.3033475359957765 | validation: 0.24850544295024918]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3209599506739536		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.3209599506739536 | validation: 0.3658200256854242]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3913163049803367		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.3913163049803367 | validation: 0.2952184710741262]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2989589431087763		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.2989589431087763 | validation: 0.3207571949490374]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6230517132311587		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.6230517132311587 | validation: 0.8319025151027498]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49109719555860315		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.49109719555860315 | validation: 0.304447184927326]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34827350548738023		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.34827350548738023 | validation: 0.3373334557462202]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36032712698146524		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.36032712698146524 | validation: 0.3121572171662416]
	TIME [epoch: 11.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3705933615148809		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.3705933615148809 | validation: 0.2893086202696776]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37414437597106964		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.37414437597106964 | validation: 0.3792478699120679]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5208825737847553		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.5208825737847553 | validation: 0.3507986461246365]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36583836849026086		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.36583836849026086 | validation: 0.4147125524824037]
	TIME [epoch: 11.4 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42033307544713044		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.42033307544713044 | validation: 0.33206942422414615]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4868826887996033		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.4868826887996033 | validation: 0.27591864377066877]
	TIME [epoch: 11.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3201894624324437		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.3201894624324437 | validation: 0.28148786752495725]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30185418051922286		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.30185418051922286 | validation: 0.21365714023101995]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2548553635946619		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.2548553635946619 | validation: 0.33336292356717906]
	TIME [epoch: 11.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32777757864410606		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.32777757864410606 | validation: 0.3910471954851122]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4290740727097729		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.4290740727097729 | validation: 0.22607026209609246]
	TIME [epoch: 11.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37586249634944063		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.37586249634944063 | validation: 0.48089493380532505]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36114594597899485		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.36114594597899485 | validation: 0.28945764382041855]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27322162531079297		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.27322162531079297 | validation: 0.19303025600516108]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21236867400551307		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.21236867400551307 | validation: 0.301611351073303]
	TIME [epoch: 11.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2728033503937022		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.2728033503937022 | validation: 0.4349072668002985]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.453889008384376		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.453889008384376 | validation: 0.35138070456778137]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3270241148806272		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.3270241148806272 | validation: 0.36610412286757255]
	TIME [epoch: 11.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38101254789985195		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.38101254789985195 | validation: 0.5487075475197484]
	TIME [epoch: 11.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43991444108703515		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.43991444108703515 | validation: 0.22206332897806763]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2525770333869011		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.2525770333869011 | validation: 0.24896082309054152]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4801213156143655		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.4801213156143655 | validation: 0.31374597366213286]
	TIME [epoch: 11.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34486111884549264		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.34486111884549264 | validation: 0.2828721036682896]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44792203756714344		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.44792203756714344 | validation: 0.3472691274149491]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3245270935442308		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.3245270935442308 | validation: 0.28812229282870916]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2637963651353089		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.2637963651353089 | validation: 0.28101360217951843]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28659087630506425		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.28659087630506425 | validation: 0.34691831292388303]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25540249880749993		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.25540249880749993 | validation: 0.22182445405082563]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2344773939178782		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.2344773939178782 | validation: 0.44517914657653157]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29401963203037146		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.29401963203037146 | validation: 0.17506473106800985]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28515964195432997		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.28515964195432997 | validation: 0.20120047434965804]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34272757441491		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.34272757441491 | validation: 0.26138873268804413]
	TIME [epoch: 11.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30048664531504543		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.30048664531504543 | validation: 0.21657232183119152]
	TIME [epoch: 11.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22964221748215533		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.22964221748215533 | validation: 0.2776562271311529]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2920472031894851		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.2920472031894851 | validation: 0.3287906035843307]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25912978314179247		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.25912978314179247 | validation: 0.20891501821414246]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23223359332044086		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.23223359332044086 | validation: 0.2728441810337587]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23866255960850827		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.23866255960850827 | validation: 0.25018952863162575]
	TIME [epoch: 11.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.194529228588633		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.194529228588633 | validation: 0.33889030506597967]
	TIME [epoch: 11.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29391506005124457		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.29391506005124457 | validation: 0.29174480376199075]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2570910360757411		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.2570910360757411 | validation: 0.26009281731033745]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2610420809669933		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.2610420809669933 | validation: 0.3096528944908584]
	TIME [epoch: 11.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2075181014076216		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.2075181014076216 | validation: 0.20949732015036518]
	TIME [epoch: 11.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2482093510773934		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.2482093510773934 | validation: 0.2865571780349861]
	TIME [epoch: 11.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.223270439914497		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.223270439914497 | validation: 0.39241504556446316]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3964248034254012		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.3964248034254012 | validation: 0.21567158536529715]
	TIME [epoch: 11.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22210368597236357		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.22210368597236357 | validation: 0.2022697166138595]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2079608731216646		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.2079608731216646 | validation: 0.21199815191463828]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24236594682046844		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.24236594682046844 | validation: 0.23852809364462801]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22045921508337324		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.22045921508337324 | validation: 0.18109895988948455]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2022449625888776		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.2022449625888776 | validation: 0.15259802265726471]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21537269533528863		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.21537269533528863 | validation: 0.4706683119061299]
	TIME [epoch: 11.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5853016760681458		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.5853016760681458 | validation: 0.19689220887192257]
	TIME [epoch: 11.4 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3162241008606556		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.3162241008606556 | validation: 0.16383034420757853]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24602624630564096		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.24602624630564096 | validation: 0.18050030561976282]
	TIME [epoch: 11.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20368420770625156		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.20368420770625156 | validation: 0.19710228522774523]
	TIME [epoch: 11.4 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18878955393824204		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.18878955393824204 | validation: 0.3054564248731651]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26586160551033444		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.26586160551033444 | validation: 0.3161233617434469]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24771378125092286		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.24771378125092286 | validation: 0.20963528690122893]
	TIME [epoch: 11.4 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19979574703439712		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.19979574703439712 | validation: 0.4373674574184392]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32592621369354824		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.32592621369354824 | validation: 0.2215058713474879]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21679096353319993		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.21679096353319993 | validation: 0.32735321161445946]
	TIME [epoch: 11.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32140794019177793		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.32140794019177793 | validation: 0.16577718383881718]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23528970432902474		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.23528970432902474 | validation: 0.35964769880533654]
	TIME [epoch: 11.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.234624948774257		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.234624948774257 | validation: 0.23438180697639965]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.56164093364664		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.56164093364664 | validation: 0.5074758475042216]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516586511606963		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.516586511606963 | validation: 0.36447709219290386]
	TIME [epoch: 11.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36307296045847687		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.36307296045847687 | validation: 0.1660356530725027]
	TIME [epoch: 11.4 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17444900873775637		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.17444900873775637 | validation: 0.30526750962721383]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23234595573973224		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.23234595573973224 | validation: 0.18371896891701808]
	TIME [epoch: 11.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18513593414237842		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.18513593414237842 | validation: 0.19878191667225062]
	TIME [epoch: 11.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.221755670462681		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.221755670462681 | validation: 0.14836738390737622]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582679335683012		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.1582679335683012 | validation: 0.16107612860561524]
	TIME [epoch: 11.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477107460550738		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.1477107460550738 | validation: 0.1832085008123207]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1542926652362054		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.1542926652362054 | validation: 0.2134245689329174]
	TIME [epoch: 11.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17535357493117248		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.17535357493117248 | validation: 0.12033602465525453]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12049800811345293		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.12049800811345293 | validation: 0.11482951185618501]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16067270527714364		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.16067270527714364 | validation: 0.2155698504520236]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2203044539623637		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.2203044539623637 | validation: 0.3015088279022758]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2381370929701884		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.2381370929701884 | validation: 0.21297699223663302]
	TIME [epoch: 11.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22087506981592142		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.22087506981592142 | validation: 0.16155719182505401]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16483747431574036		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.16483747431574036 | validation: 0.169507411739815]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20104369881077724		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.20104369881077724 | validation: 0.11174227265120162]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11401898018190665		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.11401898018190665 | validation: 0.3029893431039678]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2557714400321651		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.2557714400321651 | validation: 0.244884627710919]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23030646919533793		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.23030646919533793 | validation: 0.17843723735741798]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14719671206664187		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.14719671206664187 | validation: 0.22925626029377455]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3235406204229818		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.3235406204229818 | validation: 0.14602067146124548]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17904092719949183		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.17904092719949183 | validation: 0.24253242286851695]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17491938996048365		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.17491938996048365 | validation: 0.08199854982001942]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17625805448030102		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.17625805448030102 | validation: 0.18172262178516566]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1643701145728398		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.1643701145728398 | validation: 0.10245215801577649]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17027169837917042		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.17027169837917042 | validation: 0.23988076018651136]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2911176693557175		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.2911176693557175 | validation: 0.16775777221543506]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17531112941181537		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.17531112941181537 | validation: 0.13812466945917246]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753589275393988		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.13753589275393988 | validation: 0.17345282271803428]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15596353404956076		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.15596353404956076 | validation: 0.1094304299715072]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13851770315707002		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.13851770315707002 | validation: 0.12874731199477935]
	TIME [epoch: 11.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37767908879732615		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.37767908879732615 | validation: 0.1476899655483014]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17851830391329454		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.17851830391329454 | validation: 0.16768815381526175]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2198229889274197		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.2198229889274197 | validation: 0.10304573847643876]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1309682645663598		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.1309682645663598 | validation: 0.18690334858741353]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408832870700807		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.1408832870700807 | validation: 0.37622174562561017]
	TIME [epoch: 11.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21897698276824198		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.21897698276824198 | validation: 0.12697835482024072]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1524749935910278		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.1524749935910278 | validation: 0.25630530757816017]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22845675434954454		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.22845675434954454 | validation: 0.22713153858629156]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19410508157632245		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.19410508157632245 | validation: 0.1759630419079339]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22192426083717395		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.22192426083717395 | validation: 0.26032176081661407]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20165095481285739		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.20165095481285739 | validation: 0.13255233852674528]
	TIME [epoch: 11.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15094097667305711		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.15094097667305711 | validation: 0.10348158667106903]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350603580330192		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.1350603580330192 | validation: 0.07112420631870295]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08320089674485034		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.08320089674485034 | validation: 0.11384018502402597]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11339654917953897		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.11339654917953897 | validation: 0.09600373764029556]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334900767386882		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.1334900767386882 | validation: 0.2516846665084718]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23810890234264037		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.23810890234264037 | validation: 0.20109862182688726]
	TIME [epoch: 11.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21601198827484036		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.21601198827484036 | validation: 0.2701769890544767]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3149518344918477		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.3149518344918477 | validation: 0.2408672993814652]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2344009004874314		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.2344009004874314 | validation: 0.2810465911633852]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25982330357588096		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.25982330357588096 | validation: 0.2673956090275616]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1901347542700911		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.1901347542700911 | validation: 0.16804881986957426]
	TIME [epoch: 11.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18719342049269053		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.18719342049269053 | validation: 0.12852587140042626]
	TIME [epoch: 11.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12891590655627647		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.12891590655627647 | validation: 0.13239359573371468]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17507652760088843		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.17507652760088843 | validation: 0.1737755845997746]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16828456221991756		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.16828456221991756 | validation: 0.09662770807893978]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15158609247516963		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.15158609247516963 | validation: 0.08571764094600492]
	TIME [epoch: 11.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17416751864828442		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.17416751864828442 | validation: 0.23240576643861174]
	TIME [epoch: 11.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15753167290847236		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.15753167290847236 | validation: 0.08340408842221347]
	TIME [epoch: 11.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2040458326866756		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.2040458326866756 | validation: 0.3740929948036624]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20927034443512316		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.20927034443512316 | validation: 0.1800983700148928]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13462553001144023		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.13462553001144023 | validation: 0.15159724473863423]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479087513958939		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.1479087513958939 | validation: 0.08697746054099698]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11503153364256313		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.11503153364256313 | validation: 0.07556642831279337]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08934510963136366		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.08934510963136366 | validation: 0.12087597116883245]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14031165400491397		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.14031165400491397 | validation: 0.08563875985072293]
	TIME [epoch: 11.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13267568959948778		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.13267568959948778 | validation: 0.14161324889215976]
	TIME [epoch: 11.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13664696275119473		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.13664696275119473 | validation: 0.14761471460107525]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18332581494065647		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.18332581494065647 | validation: 0.15537372238636624]
	TIME [epoch: 11.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24438575737338591		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.24438575737338591 | validation: 0.1631424098918126]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23436645363204545		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.23436645363204545 | validation: 0.16774221688760813]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21075299192384994		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.21075299192384994 | validation: 0.1776557693250855]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17508707627269707		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.17508707627269707 | validation: 0.1148264688687253]
	TIME [epoch: 11.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18367181982546932		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.18367181982546932 | validation: 0.2758963503497852]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1904517386170646		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.1904517386170646 | validation: 0.09662746418667427]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16650846105018682		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.16650846105018682 | validation: 0.12549826552339594]
	TIME [epoch: 11.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13197536662773982		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.13197536662773982 | validation: 0.1324259489174918]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1796031513787895		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.1796031513787895 | validation: 0.13139438975040496]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24319771577807758		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.24319771577807758 | validation: 0.13069787453963627]
	TIME [epoch: 11.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11488212841383057		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.11488212841383057 | validation: 0.09844453571069109]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1453681962454914		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.1453681962454914 | validation: 0.13707162975559758]
	TIME [epoch: 11.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16317184737402812		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.16317184737402812 | validation: 0.05544875324783757]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_413.pth
	Model improved!!!
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07493549711336649		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.07493549711336649 | validation: 0.06457539084074523]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08006322439907937		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.08006322439907937 | validation: 0.04389280800074321]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10412497702003615		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.10412497702003615 | validation: 0.07259278833571947]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11319359951096404		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.11319359951096404 | validation: 0.1261706593545223]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15090595372173637		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.15090595372173637 | validation: 0.11860159990281435]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15935254212693056		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.15935254212693056 | validation: 0.10331726333921623]
	TIME [epoch: 11.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18578513424028187		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.18578513424028187 | validation: 0.20675854020302845]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17049243461240732		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.17049243461240732 | validation: 0.16049596639505198]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1801394201737297		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.1801394201737297 | validation: 0.2454512843457553]
	TIME [epoch: 11.4 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17464607187768538		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.17464607187768538 | validation: 0.10145065016909391]
	TIME [epoch: 11.5 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14524639399436023		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.14524639399436023 | validation: 0.21401750167892908]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1854029574435599		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.1854029574435599 | validation: 0.2267703305666493]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16661828444056492		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.16661828444056492 | validation: 0.11490107980268555]
	TIME [epoch: 11.4 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16097807853581972		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.16097807853581972 | validation: 0.3012210202383337]
	TIME [epoch: 11.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20749424966063854		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.20749424966063854 | validation: 0.14200738628894494]
	TIME [epoch: 11.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16048734282734048		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.16048734282734048 | validation: 0.1504011687239251]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.150599857662602		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.150599857662602 | validation: 0.12432920704315123]
	TIME [epoch: 11.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2357565350779613		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.2357565350779613 | validation: 0.4245319519245503]
	TIME [epoch: 11.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30479971398972666		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.30479971398972666 | validation: 0.15952031971529723]
	TIME [epoch: 11.4 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15140879226985693		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.15140879226985693 | validation: 0.14736720859302938]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12249988642268549		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.12249988642268549 | validation: 0.13185841566142845]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12904824097048473		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.12904824097048473 | validation: 0.13092310118196263]
	TIME [epoch: 11.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13658275119287283		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.13658275119287283 | validation: 0.2625398472408642]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1752907335187616		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.1752907335187616 | validation: 0.1291461442787727]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10600964481510042		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.10600964481510042 | validation: 0.2734989420124927]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572659328681199		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.1572659328681199 | validation: 0.1223372988647016]
	TIME [epoch: 11.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130947873503126		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.130947873503126 | validation: 0.1435505360454233]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10974257819956018		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.10974257819956018 | validation: 0.06485470588279696]
	TIME [epoch: 11.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10403946181056811		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.10403946181056811 | validation: 0.15128981853043036]
	TIME [epoch: 11.4 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15806326097453646		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.15806326097453646 | validation: 0.0916698658639704]
	TIME [epoch: 11.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12527228066697635		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.12527228066697635 | validation: 0.05975142610647941]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355815825683803		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.1355815825683803 | validation: 0.22318654775237476]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15054487303454223		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.15054487303454223 | validation: 0.1333805251436495]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282074662974743		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.1282074662974743 | validation: 0.08937366660583784]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09023706830344147		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.09023706830344147 | validation: 0.06766768800216609]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08821328477738749		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.08821328477738749 | validation: 0.08793526729093287]
	TIME [epoch: 11.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0955356235021547		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.0955356235021547 | validation: 0.05791686398263627]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07326744000763187		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.07326744000763187 | validation: 0.05580672543341226]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09674675341242014		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.09674675341242014 | validation: 0.12095404618213755]
	TIME [epoch: 11.4 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09722405893736313		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.09722405893736313 | validation: 0.07832121706146765]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13045994290644886		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.13045994290644886 | validation: 0.09220848525504996]
	TIME [epoch: 11.4 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11767763796619024		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.11767763796619024 | validation: 0.22285132450846307]
	TIME [epoch: 11.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2151422623917231		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.2151422623917231 | validation: 0.13313560375117317]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12505048386375542		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.12505048386375542 | validation: 0.15074161191416094]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11892028523009515		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.11892028523009515 | validation: 0.11790542552224437]
	TIME [epoch: 11.4 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11232588429269491		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.11232588429269491 | validation: 0.09153200088224227]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09452687643787684		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.09452687643787684 | validation: 0.07816202016690645]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09642553680457482		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.09642553680457482 | validation: 0.10577629382239162]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21678405444175297		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.21678405444175297 | validation: 0.16057399065820427]
	TIME [epoch: 11.4 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16745560428815107		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.16745560428815107 | validation: 0.14195597828026854]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12649943341598469		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.12649943341598469 | validation: 0.07610646954203523]
	TIME [epoch: 11.4 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11558569125088627		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.11558569125088627 | validation: 0.08836267898104447]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08474437803440488		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.08474437803440488 | validation: 0.05912004048036222]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08112638098853525		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.08112638098853525 | validation: 0.14109400256987698]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1828158021236507		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.1828158021236507 | validation: 0.07544603297963909]
	TIME [epoch: 11.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07776592603481311		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.07776592603481311 | validation: 0.08566930607098495]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10687119287622915		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.10687119287622915 | validation: 0.09490607577049884]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14549401153648658		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.14549401153648658 | validation: 0.131390742229146]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13350029946084743		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.13350029946084743 | validation: 0.14801840994777243]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09001803552142833		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.09001803552142833 | validation: 0.08793538114725089]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07253488316983417		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.07253488316983417 | validation: 0.08718349335493991]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08855353621083868		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.08855353621083868 | validation: 0.11273623103747497]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09320271928192272		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.09320271928192272 | validation: 0.08038923099856245]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08948502631207453		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.08948502631207453 | validation: 0.13536935921362164]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2027522923586679		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.2027522923586679 | validation: 0.26216215073116933]
	TIME [epoch: 11.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1677307459416004		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.1677307459416004 | validation: 0.1109231122941996]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11710237238462537		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.11710237238462537 | validation: 0.08295123372159662]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09158709135785681		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.09158709135785681 | validation: 0.19787291598455767]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22384758921835726		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.22384758921835726 | validation: 0.3311005585813817]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33230956972320913		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.33230956972320913 | validation: 0.2028777119896003]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17212289603771935		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.17212289603771935 | validation: 0.19542954345477884]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3116488707251473		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.3116488707251473 | validation: 0.23475987871971296]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.204655530411578		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.204655530411578 | validation: 0.15802324422275313]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13790260490872686		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.13790260490872686 | validation: 0.137063673595207]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11704594070952132		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.11704594070952132 | validation: 0.12579848692978782]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13454063825676082		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.13454063825676082 | validation: 0.10535193935872507]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1358628081188832		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.1358628081188832 | validation: 0.19893331210774703]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1794812494113433		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.1794812494113433 | validation: 0.09071509732941058]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13689617429651374		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.13689617429651374 | validation: 0.30922762995882475]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41168807074609914		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.41168807074609914 | validation: 0.20086611324464046]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17755886775926927		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.17755886775926927 | validation: 0.12087302999506673]
	TIME [epoch: 11.4 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11061619266600367		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.11061619266600367 | validation: 0.0815809782862272]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11256623563746013		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.11256623563746013 | validation: 0.19842281813247475]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16211548828539302		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.16211548828539302 | validation: 0.27195111064140404]
	TIME [epoch: 11.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2474217404602305		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.2474217404602305 | validation: 0.15044915808880288]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12097332073202817		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.12097332073202817 | validation: 0.08640265092916076]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07888588510329242		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.07888588510329242 | validation: 0.1116468670044069]
	TIME [epoch: 11.4 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14290483437857782		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.14290483437857782 | validation: 0.11270152408686385]
	TIME [epoch: 11.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12240425713010394		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.12240425713010394 | validation: 0.11493488770950348]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13309639601428286		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.13309639601428286 | validation: 0.10189838929026306]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11751966114479497		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.11751966114479497 | validation: 0.10776026149571194]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0979850333929029		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.0979850333929029 | validation: 0.06209919108889018]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09904210247921508		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.09904210247921508 | validation: 0.0876517748627574]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12828581018852667		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.12828581018852667 | validation: 0.11237458274582665]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0972341806451053		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.0972341806451053 | validation: 0.10235698397669307]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11797893296737669		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.11797893296737669 | validation: 0.10412540141974148]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1192915948079863		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.1192915948079863 | validation: 0.1332396713225108]
	TIME [epoch: 11.4 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338361198374341		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.1338361198374341 | validation: 0.13816691204372838]
	TIME [epoch: 11.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13902531254300687		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.13902531254300687 | validation: 0.09482160439198646]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09233175639229005		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.09233175639229005 | validation: 0.11166330914220252]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12381339142304285		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.12381339142304285 | validation: 0.0655891948214925]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10657129739429089		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.10657129739429089 | validation: 0.1284924704002479]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12370231048629407		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.12370231048629407 | validation: 0.16725392377425272]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12910023683265548		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.12910023683265548 | validation: 0.06604157851889843]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09102056017527435		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.09102056017527435 | validation: 0.14087284197948827]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13076942831345575		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.13076942831345575 | validation: 0.08634111682359501]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09840950587142855		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.09840950587142855 | validation: 0.13767663224228924]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12225599726630092		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.12225599726630092 | validation: 0.0732786646424136]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0849204426947145		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.0849204426947145 | validation: 0.11114009927965247]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09691162586358333		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.09691162586358333 | validation: 0.16069794254354666]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12077160509008743		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.12077160509008743 | validation: 0.09334524859643857]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12945522463485098		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.12945522463485098 | validation: 0.09256689806962508]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11991249781175793		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.11991249781175793 | validation: 0.06817495472630541]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07452365502264904		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.07452365502264904 | validation: 0.05539653800921701]
	TIME [epoch: 11.4 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08126901271944166		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.08126901271944166 | validation: 0.09277209934762208]
	TIME [epoch: 11.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11810803847035481		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.11810803847035481 | validation: 0.055329970187953804]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08042570037642868		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.08042570037642868 | validation: 0.1010486275261296]
	TIME [epoch: 11.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09012542001179605		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.09012542001179605 | validation: 0.08047708002380521]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07770959444586473		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.07770959444586473 | validation: 0.12349463761065348]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11503919271097875		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.11503919271097875 | validation: 0.09182600328311329]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09711126423142928		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.09711126423142928 | validation: 0.09345840143572924]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07446101882657127		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.07446101882657127 | validation: 0.07940294007667376]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07674355317960611		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.07674355317960611 | validation: 0.06122013116591123]
	TIME [epoch: 11.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07692182565621214		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.07692182565621214 | validation: 0.05364284903733257]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08401268016761705		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.08401268016761705 | validation: 0.05572032606492664]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0851807815030236		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.0851807815030236 | validation: 0.11605897443653468]
	TIME [epoch: 11.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09403849578457196		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.09403849578457196 | validation: 0.13947536392267953]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10531102504710801		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.10531102504710801 | validation: 0.08239368448000146]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11779059857847288		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.11779059857847288 | validation: 0.25496577869055054]
	TIME [epoch: 11.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15130473490748425		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.15130473490748425 | validation: 0.10336910247364334]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12924845446728528		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.12924845446728528 | validation: 0.08996493862248063]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10726518002233304		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.10726518002233304 | validation: 0.08183303603357915]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08834710668018021		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.08834710668018021 | validation: 0.09217892411684969]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13536265288966057		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.13536265288966057 | validation: 0.09875354383121841]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10748876175967725		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.10748876175967725 | validation: 0.14734909683616246]
	TIME [epoch: 11.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15436070282599257		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.15436070282599257 | validation: 0.09780021505718015]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12202806889656431		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.12202806889656431 | validation: 0.10061766682254802]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10647965236977872		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.10647965236977872 | validation: 0.12556978757260004]
	TIME [epoch: 11.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13313846433309945		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.13313846433309945 | validation: 0.10754642269347255]
	TIME [epoch: 11.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12252927328815452		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.12252927328815452 | validation: 0.08912713700497864]
	TIME [epoch: 11.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09598317521593111		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.09598317521593111 | validation: 0.10505421316668308]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1364881230471534		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1364881230471534 | validation: 0.07513718539633668]
	TIME [epoch: 11.4 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09373706700147467		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.09373706700147467 | validation: 0.1860958986829877]
	TIME [epoch: 11.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16155433278967826		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.16155433278967826 | validation: 0.06282795972031804]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07242703636573487		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.07242703636573487 | validation: 0.06839293274774053]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09721703225630149		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.09721703225630149 | validation: 0.08567669325996151]
	TIME [epoch: 11.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08031086668706967		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.08031086668706967 | validation: 0.11657483323434502]
	TIME [epoch: 11.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13480127356981836		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.13480127356981836 | validation: 0.0993557634266723]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10370740992710188		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.10370740992710188 | validation: 0.08915791224726315]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14310833377014248		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.14310833377014248 | validation: 0.14201910944074822]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14080603751089724		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.14080603751089724 | validation: 0.12756796526897837]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11257964376092618		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.11257964376092618 | validation: 0.10285657428306458]
	TIME [epoch: 11.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13090114690186824		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.13090114690186824 | validation: 0.1522506313640422]
	TIME [epoch: 11.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509037198107079		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.1509037198107079 | validation: 0.09697728223268358]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13064043878855475		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.13064043878855475 | validation: 0.10300564197662039]
	TIME [epoch: 11.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14088741582172193		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.14088741582172193 | validation: 0.19397987956323715]
	TIME [epoch: 11.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20866347914873168		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.20866347914873168 | validation: 0.18392564390460395]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1803882893184987		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.1803882893184987 | validation: 0.11006320150374384]
	TIME [epoch: 11.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16872563819257888		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.16872563819257888 | validation: 0.18746861708489568]
	TIME [epoch: 11.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14690397997579022		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.14690397997579022 | validation: 0.10623774049029218]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12209537201053255		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.12209537201053255 | validation: 0.09674967207876856]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265401010855033		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.1265401010855033 | validation: 0.107019355253308]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323849625264315		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.1323849625264315 | validation: 0.1551930778762902]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20191163982905763		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.20191163982905763 | validation: 0.15009634947429482]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19514144317608637		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.19514144317608637 | validation: 0.13752239699700122]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1540363132749264		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.1540363132749264 | validation: 0.1504655091375111]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14375675606111704		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.14375675606111704 | validation: 0.0833263097651447]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1012660442778417		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.1012660442778417 | validation: 0.09137567610842492]
	TIME [epoch: 11.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09415771440367102		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.09415771440367102 | validation: 0.1069363208700328]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10380276131400637		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.10380276131400637 | validation: 0.06064952113443422]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07899018464541743		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.07899018464541743 | validation: 0.09291987915070993]
	TIME [epoch: 11.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1096835189219839		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.1096835189219839 | validation: 0.0710092200894347]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08118336833109792		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.08118336833109792 | validation: 0.08590559233957336]
	TIME [epoch: 11.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07730421853401948		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.07730421853401948 | validation: 0.07172928240474992]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08084635775609483		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.08084635775609483 | validation: 0.07410666571670715]
	TIME [epoch: 11.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791738631625989		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.0791738631625989 | validation: 0.06150828673819156]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08411130571634604		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.08411130571634604 | validation: 0.07217118652801137]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08834742109225624		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.08834742109225624 | validation: 0.060980959430988836]
	TIME [epoch: 11.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07996252284442622		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.07996252284442622 | validation: 0.10537210595005972]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12029980292956619		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.12029980292956619 | validation: 0.08653078973309114]
	TIME [epoch: 11.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07955646936060165		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.07955646936060165 | validation: 0.08566782999163017]
	TIME [epoch: 11.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09147516742987684		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.09147516742987684 | validation: 0.08150926044299565]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0912515133459978		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.0912515133459978 | validation: 0.15214759154897092]
	TIME [epoch: 11.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12214206764651409		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.12214206764651409 | validation: 0.06418291067590985]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0785644854957716		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.0785644854957716 | validation: 0.1109217920210025]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07774659403593738		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.07774659403593738 | validation: 0.06847852629332966]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0805476706584182		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.0805476706584182 | validation: 0.05405436193248705]
	TIME [epoch: 11.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08095585656210663		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.08095585656210663 | validation: 0.06277345771310643]
	TIME [epoch: 11.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10615653601243025		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.10615653601243025 | validation: 0.09455304093468408]
	TIME [epoch: 11.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09848481735654875		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.09848481735654875 | validation: 0.06335484655302454]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08239764648864123		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.08239764648864123 | validation: 0.06655892170642765]
	TIME [epoch: 11.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07822068955363796		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.07822068955363796 | validation: 0.06685585942793788]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07859589281979688		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.07859589281979688 | validation: 0.0663977862993315]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0949439093170998		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.0949439093170998 | validation: 0.07444061873911209]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07672077637861599		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.07672077637861599 | validation: 0.07789396321539288]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08070427968085658		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.08070427968085658 | validation: 0.0559480997910247]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0657900728158394		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.0657900728158394 | validation: 0.0944100777412034]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09921848839793133		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.09921848839793133 | validation: 0.11899502839174624]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17527139771196734		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.17527139771196734 | validation: 0.11058732386845323]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08419524437699985		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.08419524437699985 | validation: 0.16594436137811086]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16465971855812314		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.16465971855812314 | validation: 0.09186168721557204]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12702145256871317		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.12702145256871317 | validation: 0.09178753033834637]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07933954017686864		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.07933954017686864 | validation: 0.06446506109968184]
	TIME [epoch: 11.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06838335385788089		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.06838335385788089 | validation: 0.06469606052355953]
	TIME [epoch: 11.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07399703195587556		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.07399703195587556 | validation: 0.03987190859457202]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05449864072247132		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.05449864072247132 | validation: 0.04703186181358012]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05348228396455895		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.05348228396455895 | validation: 0.12886536878119087]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10718375163201256		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.10718375163201256 | validation: 0.0744746360392971]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07322450187760773		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.07322450187760773 | validation: 0.08015163109735285]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07272526073779796		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.07272526073779796 | validation: 0.05808080532977546]
	TIME [epoch: 11.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0783345082281381		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.0783345082281381 | validation: 0.09167635636941364]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08001020858504113		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.08001020858504113 | validation: 0.18856570951796797]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15651023763314353		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.15651023763314353 | validation: 0.11107808348172146]
	TIME [epoch: 11.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11605248106318343		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.11605248106318343 | validation: 0.13321264181401254]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25084454988101584		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.25084454988101584 | validation: 0.1429909095427669]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09582506650014085		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.09582506650014085 | validation: 0.06907393487460355]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06854015141996242		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.06854015141996242 | validation: 0.08093051626187833]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0717376746039261		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.0717376746039261 | validation: 0.06073139489153138]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07162826526086388		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.07162826526086388 | validation: 0.08002375364896402]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09247917373114586		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.09247917373114586 | validation: 0.05604455887931735]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06771770209793078		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.06771770209793078 | validation: 0.04728247805282571]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07006414637811678		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.07006414637811678 | validation: 0.031813931361169286]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_635.pth
	Model improved!!!
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0464858688394036		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.0464858688394036 | validation: 0.09771954671686811]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14361176188398528		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.14361176188398528 | validation: 0.11430788688736469]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08171576195075048		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.08171576195075048 | validation: 0.092251899856519]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08722506014164727		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.08722506014164727 | validation: 0.06799027549525541]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05318906724065017		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.05318906724065017 | validation: 0.04889410911501454]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06527657236405923		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.06527657236405923 | validation: 0.04703087480733846]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.079504821747931		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.079504821747931 | validation: 0.23341263864270112]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.207335819990696		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.207335819990696 | validation: 0.17371249732630645]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14896313214117146		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.14896313214117146 | validation: 0.0799893981009002]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08089032825863912		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.08089032825863912 | validation: 0.07222139365720864]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06493128655042338		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.06493128655042338 | validation: 0.04856091325439781]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05300849319599166		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.05300849319599166 | validation: 0.032247015038292345]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059204344936211864		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.059204344936211864 | validation: 0.05886111272804675]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0571656447448347		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.0571656447448347 | validation: 0.0557120147168396]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05004389009439428		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.05004389009439428 | validation: 0.04574162247408628]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06461624783068907		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.06461624783068907 | validation: 0.04115176981076324]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05627798985864853		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.05627798985864853 | validation: 0.07141376309083107]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08391688988414467		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.08391688988414467 | validation: 0.0562502246452981]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0754044017514492		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.0754044017514492 | validation: 0.061277345573318966]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05071171411494214		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.05071171411494214 | validation: 0.04563292522903339]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06866620741281698		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.06866620741281698 | validation: 0.07150575621601149]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06557970593969485		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.06557970593969485 | validation: 0.04463278011461409]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054716186263381136		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.054716186263381136 | validation: 0.033296015192002315]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05831426903292026		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.05831426903292026 | validation: 0.05344000701259742]
	TIME [epoch: 11.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05256132774597776		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.05256132774597776 | validation: 0.04458574921111755]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062164338507937816		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.062164338507937816 | validation: 0.05809717054690445]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08012613363607389		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.08012613363607389 | validation: 0.08438508631045952]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07626671841182504		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.07626671841182504 | validation: 0.10099188414491195]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07022936511048576		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.07022936511048576 | validation: 0.04260929444011627]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058639410282035856		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.058639410282035856 | validation: 0.04378932377179041]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06113592813716617		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.06113592813716617 | validation: 0.05172832545844995]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05650610638510864		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.05650610638510864 | validation: 0.048103781252947966]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05573094514437742		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.05573094514437742 | validation: 0.08824244298859324]
	TIME [epoch: 11.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07886667957655552		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.07886667957655552 | validation: 0.0553415023661664]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07835531816477942		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.07835531816477942 | validation: 0.08409611164866317]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08331789097558326		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.08331789097558326 | validation: 0.042045335362309956]
	TIME [epoch: 11.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05313488523678804		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.05313488523678804 | validation: 0.06799477468678809]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06432271620946647		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.06432271620946647 | validation: 0.07355192370980024]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08644313101988613		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.08644313101988613 | validation: 0.05635030526462234]
	TIME [epoch: 11.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0656414938689214		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.0656414938689214 | validation: 0.07071393144816958]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06234607600039583		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.06234607600039583 | validation: 0.041507305408943734]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06652481592811108		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.06652481592811108 | validation: 0.05316790222493724]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05965450348657249		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.05965450348657249 | validation: 0.11411061257038542]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17484529174426344		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.17484529174426344 | validation: 0.16490220722688545]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16307466762789263		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.16307466762789263 | validation: 0.07743454016253687]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07672107858642818		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.07672107858642818 | validation: 0.06691639237305975]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08060482262185144		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.08060482262185144 | validation: 0.11471013267908203]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10192852658979973		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.10192852658979973 | validation: 0.06736247792472279]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05834680607786239		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.05834680607786239 | validation: 0.05217601024930963]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07195152278003233		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.07195152278003233 | validation: 0.08942959301640156]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1042697339148045		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.1042697339148045 | validation: 0.08086048367146155]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07746748220043195		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.07746748220043195 | validation: 0.12372513317643705]
	TIME [epoch: 11.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10005732941675094		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.10005732941675094 | validation: 0.06821596781449785]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08345755103658732		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.08345755103658732 | validation: 0.07965336025725236]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08950359304288423		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.08950359304288423 | validation: 0.10406367229315558]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09439753427317812		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.09439753427317812 | validation: 0.0761781279232169]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09172175754900735		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.09172175754900735 | validation: 0.08771641560879452]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08948243634313087		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.08948243634313087 | validation: 0.08868624675602149]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07821327741753624		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.07821327741753624 | validation: 0.053594878875579344]
	TIME [epoch: 11.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.078118318827497		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.078118318827497 | validation: 0.07730561603051225]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09274415870316564		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.09274415870316564 | validation: 0.06564559068327806]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08712157085065633		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.08712157085065633 | validation: 0.07362849212848026]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1003040736513577		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.1003040736513577 | validation: 0.09645745655977983]
	TIME [epoch: 11.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07466586236237696		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.07466586236237696 | validation: 0.052829729314940455]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05170455735047677		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.05170455735047677 | validation: 0.045680401096899886]
	TIME [epoch: 11.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053715385536011115		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.053715385536011115 | validation: 0.04580274854212878]
	TIME [epoch: 11.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04830904377995488		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.04830904377995488 | validation: 0.04267771809154688]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.076497081421264		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.076497081421264 | validation: 0.0965700147745753]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09395389058420504		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.09395389058420504 | validation: 0.094944885135304]
	TIME [epoch: 11.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09061416048738681		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.09061416048738681 | validation: 0.09741956230453358]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12169275496678336		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.12169275496678336 | validation: 0.141544701155619]
	TIME [epoch: 11.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11303441252733035		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.11303441252733035 | validation: 0.12031632863712069]
	TIME [epoch: 11.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13719979912184654		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.13719979912184654 | validation: 0.09250942264046728]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09662799302988767		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.09662799302988767 | validation: 0.06376537913936495]
	TIME [epoch: 11.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09932356170889645		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.09932356170889645 | validation: 0.09444838457664093]
	TIME [epoch: 11.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07825632651198534		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.07825632651198534 | validation: 0.06553665017121794]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07110041904371758		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.07110041904371758 | validation: 0.04741966367485423]
	TIME [epoch: 11.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06582518597834092		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.06582518597834092 | validation: 0.053510350827648365]
	TIME [epoch: 11.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05412884135583922		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.05412884135583922 | validation: 0.04332856214788773]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04166370594780307		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.04166370594780307 | validation: 0.031112021007843178]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_715.pth
	Model improved!!!
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038247679126486404		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.038247679126486404 | validation: 0.0637162597343727]
	TIME [epoch: 11.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0711041915371276		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.0711041915371276 | validation: 0.05057057095151625]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05174092061146196		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.05174092061146196 | validation: 0.048158076004305495]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06372086061382623		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.06372086061382623 | validation: 0.06240879878310171]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07461861882270637		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.07461861882270637 | validation: 0.0749849537998414]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08287840334061763		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.08287840334061763 | validation: 0.06849855395313899]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07963867909158143		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.07963867909158143 | validation: 0.058964439054175144]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0653453916359148		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.0653453916359148 | validation: 0.05134125204028532]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05863562631752717		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.05863562631752717 | validation: 0.06424156322658447]
	TIME [epoch: 11.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05658351207103271		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.05658351207103271 | validation: 0.04529563982446939]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06451040405524355		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.06451040405524355 | validation: 0.08053186691073946]
	TIME [epoch: 11.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07928897807152728		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.07928897807152728 | validation: 0.11102701923079283]
	TIME [epoch: 11.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281976015006106		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.1281976015006106 | validation: 0.11057897718782954]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13073166128798114		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.13073166128798114 | validation: 0.11922994325772536]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11074312217083596		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.11074312217083596 | validation: 0.08025419170760867]
	TIME [epoch: 11.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09494080721392731		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.09494080721392731 | validation: 0.07486469801251974]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06550843245441018		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.06550843245441018 | validation: 0.055000377034143746]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07337392057595915		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.07337392057595915 | validation: 0.054793480536024716]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05438517548317343		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.05438517548317343 | validation: 0.041206046435755345]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04521477528348429		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.04521477528348429 | validation: 0.05347391112587941]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050092579541792484		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.050092579541792484 | validation: 0.04778291955682765]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05460659752196344		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.05460659752196344 | validation: 0.056542936799035284]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06746304526786855		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.06746304526786855 | validation: 0.06415993518665161]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09521784327178465		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.09521784327178465 | validation: 0.08509028187140842]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08298826853214214		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.08298826853214214 | validation: 0.0716895317306773]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07445251904501451		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.07445251904501451 | validation: 0.08040172639647387]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07502220195195854		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.07502220195195854 | validation: 0.048792467544934826]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06351694193671342		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.06351694193671342 | validation: 0.06048304227344941]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07449204446009476		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.07449204446009476 | validation: 0.07089653498854144]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06916982396425198		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.06916982396425198 | validation: 0.07467753241128212]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09154280285731034		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.09154280285731034 | validation: 0.11343915280564054]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09152203894154719		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.09152203894154719 | validation: 0.07224949314694709]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08274700191947205		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.08274700191947205 | validation: 0.08345162144953658]
	TIME [epoch: 11.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08054104756096901		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.08054104756096901 | validation: 0.04377427740332963]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056781726235327304		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.056781726235327304 | validation: 0.05889940909524009]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06516059183629413		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.06516059183629413 | validation: 0.05334647714728386]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051644770602266486		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.051644770602266486 | validation: 0.05576581371623707]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06836597179629653		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.06836597179629653 | validation: 0.06093533050100439]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07554582207597237		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.07554582207597237 | validation: 0.08678841305281551]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909631135940923		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.0909631135940923 | validation: 0.07792763067533176]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06590888700112868		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.06590888700112868 | validation: 0.05570433194724141]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05648490677951669		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.05648490677951669 | validation: 0.05214484404175461]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06098818451598405		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.06098818451598405 | validation: 0.06260006125954805]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07543120440505378		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.07543120440505378 | validation: 0.04975330310764193]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06220131253083744		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.06220131253083744 | validation: 0.05850610581860595]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05898887934892533		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.05898887934892533 | validation: 0.0540217342660668]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05391215558389279		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.05391215558389279 | validation: 0.03668636903075088]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04459514667894695		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.04459514667894695 | validation: 0.05079543908604582]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05474665621872915		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.05474665621872915 | validation: 0.049854802818521435]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04753983236651774		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.04753983236651774 | validation: 0.041300237915199184]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0484706677927967		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.0484706677927967 | validation: 0.046194155313771294]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04645951406211939		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.04645951406211939 | validation: 0.05500479776945759]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06343370684667987		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.06343370684667987 | validation: 0.05488492926492352]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05175401140374854		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.05175401140374854 | validation: 0.03778289996546479]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05611218146854094		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.05611218146854094 | validation: 0.049410254780314224]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057872857908500316		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.057872857908500316 | validation: 0.04149399161205585]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04970794033250087		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.04970794033250087 | validation: 0.040893304848174016]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04895148632613376		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.04895148632613376 | validation: 0.038954988319807725]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04610133072788328		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.04610133072788328 | validation: 0.05879164413969054]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07075742511858273		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.07075742511858273 | validation: 0.05087003155947491]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06637707330713903		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.06637707330713903 | validation: 0.05355401423875618]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0577370392654802		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.0577370392654802 | validation: 0.051330134018966335]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0455069230141352		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.0455069230141352 | validation: 0.03859548896961239]
	TIME [epoch: 11.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041491104262615666		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.041491104262615666 | validation: 0.024149227166477154]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_779.pth
	Model improved!!!
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037374301173688354		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.037374301173688354 | validation: 0.025248595558091776]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040971105878190736		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.040971105878190736 | validation: 0.03858530748486473]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05809770739420256		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.05809770739420256 | validation: 0.038571536844014036]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05392320559084424		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.05392320559084424 | validation: 0.04582372150845795]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061030834182296476		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.061030834182296476 | validation: 0.06961050709275232]
	TIME [epoch: 11.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10120126693855486		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.10120126693855486 | validation: 0.0884034346163255]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10809622499368832		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.10809622499368832 | validation: 0.1036734066508339]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08085594459299815		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.08085594459299815 | validation: 0.0512724694757804]
	TIME [epoch: 11.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07091755834162704		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.07091755834162704 | validation: 0.05731196855015305]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07350801995135585		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.07350801995135585 | validation: 0.0801455951298552]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08152904298140815		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.08152904298140815 | validation: 0.0508001848587017]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0628759991704414		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.0628759991704414 | validation: 0.05218766563042778]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059739702139044504		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.059739702139044504 | validation: 0.03899351743842448]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06379868963843668		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.06379868963843668 | validation: 0.057030293386669303]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07484259787590897		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.07484259787590897 | validation: 0.08536461922925113]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07218176261848197		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.07218176261848197 | validation: 0.11677090835639303]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0999125174697493		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.0999125174697493 | validation: 0.05796329691466004]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04984179534526657		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.04984179534526657 | validation: 0.04442280479604303]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04596810740600237		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.04596810740600237 | validation: 0.05695675065338197]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06777736122369551		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.06777736122369551 | validation: 0.06776440326548704]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06648738778923723		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.06648738778923723 | validation: 0.05343087540251025]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051401175034267874		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.051401175034267874 | validation: 0.04868653178062016]
	TIME [epoch: 11.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06213994001192373		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.06213994001192373 | validation: 0.06627143257451641]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058587972687303064		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.058587972687303064 | validation: 0.062112732981730416]
	TIME [epoch: 11.4 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06064431921348563		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.06064431921348563 | validation: 0.04445778615330895]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04676753229932441		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.04676753229932441 | validation: 0.04081934549579968]
	TIME [epoch: 11.4 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04396370272581774		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.04396370272581774 | validation: 0.041692901878966654]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04963000698187723		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.04963000698187723 | validation: 0.0662708103542982]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06586408280054182		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.06586408280054182 | validation: 0.03874591408797289]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04884108779350224		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.04884108779350224 | validation: 0.04157926877069182]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05388120122577611		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.05388120122577611 | validation: 0.036936190580469125]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045870595201515096		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.045870595201515096 | validation: 0.04597926589400442]
	TIME [epoch: 11.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05167113003408545		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.05167113003408545 | validation: 0.06258281153763644]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05864645152174462		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.05864645152174462 | validation: 0.04868281212355118]
	TIME [epoch: 11.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06691116645236661		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.06691116645236661 | validation: 0.04930251306373322]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05126568345244133		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.05126568345244133 | validation: 0.03846249136034776]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049714835442298454		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.049714835442298454 | validation: 0.05397851814965215]
	TIME [epoch: 11.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04362516934153119		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.04362516934153119 | validation: 0.03927265205114231]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036707050140148835		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.036707050140148835 | validation: 0.044173163492364075]
	TIME [epoch: 11.4 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053645389369001206		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.053645389369001206 | validation: 0.056998145289380374]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05913229420985401		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.05913229420985401 | validation: 0.041982490850397645]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04295359463345929		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.04295359463345929 | validation: 0.03508524094501363]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03975411596884163		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.03975411596884163 | validation: 0.044734062924642985]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047848362170007055		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.047848362170007055 | validation: 0.04598728919576803]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04819612644161417		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.04819612644161417 | validation: 0.042103254683218315]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0481387612292075		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.0481387612292075 | validation: 0.043433279696018456]
	TIME [epoch: 11.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05805048322146761		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.05805048322146761 | validation: 0.04786468108828375]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06312040826673185		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.06312040826673185 | validation: 0.07376422476821871]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06726365784372414		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.06726365784372414 | validation: 0.049704582236817334]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05687864807029092		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.05687864807029092 | validation: 0.051680280791818196]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050656854975558205		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.050656854975558205 | validation: 0.06537825281766399]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0815422514279899		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.0815422514279899 | validation: 0.07256528845798092]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08139118779852234		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.08139118779852234 | validation: 0.09036623850473893]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13014355520622545		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.13014355520622545 | validation: 0.12371638951789997]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13824863238541193		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.13824863238541193 | validation: 0.10675031032847111]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11065135823493523		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.11065135823493523 | validation: 0.11529497920341004]
	TIME [epoch: 11.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17987340746047337		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.17987340746047337 | validation: 0.21919596026284807]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23764425000216083		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.23764425000216083 | validation: 0.1419258008643094]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1380743685868921		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.1380743685868921 | validation: 0.0776056744105632]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08800828683376222		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.08800828683376222 | validation: 0.08138054983458215]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09218302783983391		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.09218302783983391 | validation: 0.09476490459272904]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0938325707487783		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.0938325707487783 | validation: 0.06971091701434677]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.080394806585561		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.080394806585561 | validation: 0.07198530881023993]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06978212761294422		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.06978212761294422 | validation: 0.05363836462356459]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057950087789876176		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.057950087789876176 | validation: 0.06610340558717406]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07545112614798294		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.07545112614798294 | validation: 0.07346639100890212]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08725987763962811		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.08725987763962811 | validation: 0.07222748431931277]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09659760615007046		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.09659760615007046 | validation: 0.0872795508331112]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09009712202555145		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.09009712202555145 | validation: 0.07845902145704671]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09409401776287243		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.09409401776287243 | validation: 0.08776089586838041]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08262570433205588		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.08262570433205588 | validation: 0.06392854834615655]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08322324521317799		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.08322324521317799 | validation: 0.07065313150176662]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08013299559043996		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.08013299559043996 | validation: 0.06248232191907729]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07700862363632949		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.07700862363632949 | validation: 0.06952729855955168]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08502858808990423		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.08502858808990423 | validation: 0.06432316090980829]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06349858479745653		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.06349858479745653 | validation: 0.05308055601208049]
	TIME [epoch: 11.4 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07660549393528437		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.07660549393528437 | validation: 0.06354719301662348]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0645721317071897		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.0645721317071897 | validation: 0.06736369797771365]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06270727991208774		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.06270727991208774 | validation: 0.06879891962566903]
	TIME [epoch: 11.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06707464283164724		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.06707464283164724 | validation: 0.054457398074907015]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0627187603609436		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.0627187603609436 | validation: 0.04761619398549126]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06062098775379068		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.06062098775379068 | validation: 0.04838392366138397]
	TIME [epoch: 11.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06946341754490168		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.06946341754490168 | validation: 0.06124461690690282]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05789930419599835		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.05789930419599835 | validation: 0.04411453591763859]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043865879501777214		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.043865879501777214 | validation: 0.0366501065751263]
	TIME [epoch: 11.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04943825516931606		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.04943825516931606 | validation: 0.04443072380277675]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05235108367964463		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.05235108367964463 | validation: 0.04041478317358535]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044032431151423995		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.044032431151423995 | validation: 0.03878803014500034]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04992499883753577		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.04992499883753577 | validation: 0.06055633198987949]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05207786018092466		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.05207786018092466 | validation: 0.04030290182009578]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0376911255323514		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.0376911255323514 | validation: 0.033335566716303194]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048337770616628514		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.048337770616628514 | validation: 0.05908060928921184]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050598779002116845		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.050598779002116845 | validation: 0.04013089788006264]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04335451870250115		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.04335451870250115 | validation: 0.0494903910045345]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0463054456088518		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.0463054456088518 | validation: 0.07565132745184577]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06879992665741583		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.06879992665741583 | validation: 0.05040981203701362]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04865561543531936		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.04865561543531936 | validation: 0.04992120910557917]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04436882534894352		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.04436882534894352 | validation: 0.036169785405787865]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04593768327020801		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.04593768327020801 | validation: 0.03246224302705305]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04605462146472616		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.04605462146472616 | validation: 0.053542481395045555]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05146923788699742		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.05146923788699742 | validation: 0.06215728077164366]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06746124183142813		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.06746124183142813 | validation: 0.06118511905461141]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07069118944706816		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.07069118944706816 | validation: 0.05835689550253351]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05887354137183344		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.05887354137183344 | validation: 0.06341204666998393]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04572752489904619		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.04572752489904619 | validation: 0.04719469559975425]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04663580691021425		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.04663580691021425 | validation: 0.05164249819534111]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05231060224807446		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.05231060224807446 | validation: 0.049590080510441885]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05666040508303259		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.05666040508303259 | validation: 0.027352463460783898]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036562003036779915		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.036562003036779915 | validation: 0.04914982727406438]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056596344633348075		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.056596344633348075 | validation: 0.05964579773492031]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06669888125038237		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.06669888125038237 | validation: 0.059495414785145376]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0582641161871207		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.0582641161871207 | validation: 0.03902522938497703]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04728309896865828		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.04728309896865828 | validation: 0.05277703244687993]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05239365001336985		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.05239365001336985 | validation: 0.05496549887073634]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053663236692606316		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.053663236692606316 | validation: 0.05491717816773216]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06282936575521111		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.06282936575521111 | validation: 0.050518759587834805]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06379174358160884		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.06379174358160884 | validation: 0.05416296906445449]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06135050005119156		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.06135050005119156 | validation: 0.05330694578731276]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058182581386949817		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.058182581386949817 | validation: 0.042707646539137493]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048873862867460725		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.048873862867460725 | validation: 0.05119393891804634]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05230066405192493		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.05230066405192493 | validation: 0.04123596124174636]
	TIME [epoch: 11.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05508611174582132		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.05508611174582132 | validation: 0.04755088735420201]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054723697440539135		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.054723697440539135 | validation: 0.038737076122462744]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04347439350293937		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.04347439350293937 | validation: 0.03991640388709595]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039348999574433906		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.039348999574433906 | validation: 0.04045764297723048]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04121167660643306		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.04121167660643306 | validation: 0.03502713253274734]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04114518113199794		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.04114518113199794 | validation: 0.04318917561702826]
	TIME [epoch: 11.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049295143257700895		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.049295143257700895 | validation: 0.05161457406525342]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05458966698105431		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.05458966698105431 | validation: 0.07530756003021774]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07098780166712264		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.07098780166712264 | validation: 0.05307255863426958]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05220244395079374		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.05220244395079374 | validation: 0.0440924640333895]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04518919923690725		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.04518919923690725 | validation: 0.03846510066100011]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04071424965036681		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.04071424965036681 | validation: 0.02880225246990853]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03359714142766713		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.03359714142766713 | validation: 0.028231735438771794]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034778957659023765		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.034778957659023765 | validation: 0.03877252402525774]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04068722352194939		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.04068722352194939 | validation: 0.042282132057831455]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07100622587052338		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.07100622587052338 | validation: 0.10101309393357687]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07560549890410836		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.07560549890410836 | validation: 0.05765137431052989]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0689343410601366		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.0689343410601366 | validation: 0.07124322740618257]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06677312791435737		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.06677312791435737 | validation: 0.06553301078541987]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08532324666935222		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.08532324666935222 | validation: 0.09021989862815094]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07501123982002285		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.07501123982002285 | validation: 0.07013201643027961]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06352530239003738		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.06352530239003738 | validation: 0.051371358107662475]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060031868444958184		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.060031868444958184 | validation: 0.0556394818662808]
	TIME [epoch: 11.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04978691721761084		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.04978691721761084 | validation: 0.032491118740059936]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04257447489412594		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.04257447489412594 | validation: 0.038274473386193525]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04501889483568219		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.04501889483568219 | validation: 0.051094596274338135]
	TIME [epoch: 11.4 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05426419652115304		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.05426419652115304 | validation: 0.04762324358762827]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05370374337150917		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.05370374337150917 | validation: 0.047232642716937015]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058768582214540004		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.058768582214540004 | validation: 0.050256839212283]
	TIME [epoch: 11.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04747589451002275		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.04747589451002275 | validation: 0.038653028589963424]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051237281300036124		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.051237281300036124 | validation: 0.04851714944936889]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059450482074468576		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.059450482074468576 | validation: 0.04937324173661159]
	TIME [epoch: 11.4 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05043073057253368		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.05043073057253368 | validation: 0.04732427438640685]
	TIME [epoch: 11.4 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05146771178549236		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.05146771178549236 | validation: 0.03187638356743883]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04494676785584996		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.04494676785584996 | validation: 0.040635442005995503]
	TIME [epoch: 11.4 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04438151035205399		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.04438151035205399 | validation: 0.03939271835982561]
	TIME [epoch: 11.4 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03593361429912766		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.03593361429912766 | validation: 0.03272223513940175]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03784349782686267		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.03784349782686267 | validation: 0.029017964554122717]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040739489258885125		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.040739489258885125 | validation: 0.0330932263360641]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04022799890951326		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.04022799890951326 | validation: 0.025703040891653633]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03955310385910994		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.03955310385910994 | validation: 0.024163492341743004]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03771013844722648		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.03771013844722648 | validation: 0.03753775250956252]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04859684423871813		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.04859684423871813 | validation: 0.05603189639114282]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642811332621429		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.0642811332621429 | validation: 0.054239182553923196]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05758927264167134		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.05758927264167134 | validation: 0.0355953832547071]
	TIME [epoch: 11.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03995774042872428		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.03995774042872428 | validation: 0.042627248604927816]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04304531935359871		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.04304531935359871 | validation: 0.03500140183746877]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04700067682258162		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.04700067682258162 | validation: 0.03981789300581521]
	TIME [epoch: 11.4 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05122205875910782		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.05122205875910782 | validation: 0.049865751496928325]
	TIME [epoch: 11.4 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05283979895212196		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.05283979895212196 | validation: 0.06286763703524839]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05428474133991873		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.05428474133991873 | validation: 0.04753658468864238]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05110795642521336		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.05110795642521336 | validation: 0.04573686000597148]
	TIME [epoch: 11.4 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04922235727006455		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.04922235727006455 | validation: 0.03936453761006614]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044006636708979065		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.044006636708979065 | validation: 0.044241005259613914]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048763397819758865		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.048763397819758865 | validation: 0.054611450193282306]
	TIME [epoch: 11.4 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04916095656305466		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.04916095656305466 | validation: 0.04503395086159447]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06155280492632208		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.06155280492632208 | validation: 0.04133241293815286]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059406124201436955		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.059406124201436955 | validation: 0.04768633224729735]
	TIME [epoch: 11.4 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05334098851603304		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.05334098851603304 | validation: 0.05570480314409497]
	TIME [epoch: 11.4 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06122197283354724		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.06122197283354724 | validation: 0.05579828807512496]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06896688302047034		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.06896688302047034 | validation: 0.0506296542892993]
	TIME [epoch: 11.4 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059368501501092207		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.059368501501092207 | validation: 0.04443183096175857]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04998593854632905		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.04998593854632905 | validation: 0.04249607887649432]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05296879366716542		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.05296879366716542 | validation: 0.03998820782040588]
	TIME [epoch: 11.4 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05974095922005502		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.05974095922005502 | validation: 0.0490766452731974]
	TIME [epoch: 11.4 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06029398154874593		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.06029398154874593 | validation: 0.06734254236675971]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06055911013840469		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.06055911013840469 | validation: 0.04944784639735342]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0608441401054921		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.0608441401054921 | validation: 0.04861731108571797]
	TIME [epoch: 11.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05870257108190532		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.05870257108190532 | validation: 0.043819514622042366]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05823556741427244		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.05823556741427244 | validation: 0.04963383264378022]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06584398503613954		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.06584398503613954 | validation: 0.05841556084643045]
	TIME [epoch: 11.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06118693401930343		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.06118693401930343 | validation: 0.04457015381015392]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058427382193360966		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.058427382193360966 | validation: 0.05903367106580412]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0651069778438067		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.0651069778438067 | validation: 0.042613735148862436]
	TIME [epoch: 11.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056215076809749055		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.056215076809749055 | validation: 0.04296992295509155]
	TIME [epoch: 11.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058082944000665604		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.058082944000665604 | validation: 0.04746038956490778]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06347773265617201		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.06347773265617201 | validation: 0.07502621359001388]
	TIME [epoch: 11.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07485199888783593		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.07485199888783593 | validation: 0.06302079988434969]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06579706996156018		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.06579706996156018 | validation: 0.046822554542665734]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058230872360130206		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.058230872360130206 | validation: 0.06309935498145698]
	TIME [epoch: 11.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06839260991525706		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.06839260991525706 | validation: 0.0544790998948521]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07227636007218613		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.07227636007218613 | validation: 0.061973078370879106]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08052040128129516		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.08052040128129516 | validation: 0.05076801885917068]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06694395312608578		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.06694395312608578 | validation: 0.057003661598977615]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07930041384050507		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.07930041384050507 | validation: 0.06476205399408158]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07651794975034164		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.07651794975034164 | validation: 0.05910542912396325]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05624061752020572		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.05624061752020572 | validation: 0.03776807223400791]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05148158268940513		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.05148158268940513 | validation: 0.03629817731990178]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05043906519535858		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.05043906519535858 | validation: 0.0467818849935591]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05666323266158551		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.05666323266158551 | validation: 0.05073007621170694]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07074514785468974		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.07074514785468974 | validation: 0.07102027796284943]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06302035221431139		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.06302035221431139 | validation: 0.049933144935084446]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05486145291831929		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.05486145291831929 | validation: 0.04907530255123407]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05383744606578762		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.05383744606578762 | validation: 0.04465497806420112]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05233640778571942		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.05233640778571942 | validation: 0.05751845030241341]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06541342358960528		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.06541342358960528 | validation: 0.05975391381460895]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872502698216066		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.07872502698216066 | validation: 0.0556017614145496]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06282235279798959		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.06282235279798959 | validation: 0.048751610817695655]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054418604676360394		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.054418604676360394 | validation: 0.049582929175883424]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05505982797326297		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.05505982797326297 | validation: 0.04861141640390395]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05732419932488195		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.05732419932488195 | validation: 0.043917198811539715]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058919255769647016		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.058919255769647016 | validation: 0.046251869164747376]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05117419082549933		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.05117419082549933 | validation: 0.054976791115422516]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0600601923177954		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.0600601923177954 | validation: 0.04274744611773099]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051094531995152924		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.051094531995152924 | validation: 0.04711273080655433]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05226524449920565		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.05226524449920565 | validation: 0.046434275235901934]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0482911888201811		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.0482911888201811 | validation: 0.03722837807439055]
	TIME [epoch: 11.4 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046346149716665536		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.046346149716665536 | validation: 0.04484475693548265]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053205724544657		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.053205724544657 | validation: 0.05155150135371374]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057835856586049436		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.057835856586049436 | validation: 0.03801899958030721]
	TIME [epoch: 11.4 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04856287908189081		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.04856287908189081 | validation: 0.04071912746883811]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053485615489572674		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.053485615489572674 | validation: 0.04470553593703635]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05390154787790584		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.05390154787790584 | validation: 0.05748448362958147]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06002082791354631		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.06002082791354631 | validation: 0.05909987484589877]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05355207819097549		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.05355207819097549 | validation: 0.03213276041197051]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04890585493498936		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.04890585493498936 | validation: 0.03499188060354624]
	TIME [epoch: 11.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04503705829491784		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.04503705829491784 | validation: 0.02891987513459003]
	TIME [epoch: 11.4 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033381869691636916		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.033381869691636916 | validation: 0.036335324002598306]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04516664971666104		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.04516664971666104 | validation: 0.047625416610016506]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050574446102431864		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.050574446102431864 | validation: 0.044507706882683885]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03787507520650175		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.03787507520650175 | validation: 0.024715125380245673]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03573497635481016		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.03573497635481016 | validation: 0.035933388733289794]
	TIME [epoch: 11.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036373408494378874		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.036373408494378874 | validation: 0.03968667258576085]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039005764489127175		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.039005764489127175 | validation: 0.03868476179009345]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04007210151294441		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.04007210151294441 | validation: 0.02832460917818358]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04034118612813284		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.04034118612813284 | validation: 0.037338365140869884]
	TIME [epoch: 11.4 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03649064038780709		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.03649064038780709 | validation: 0.03280834024293493]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03935883387849422		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.03935883387849422 | validation: 0.04722890074623425]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057284229355076946		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.057284229355076946 | validation: 0.05022093962908025]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05191748927909212		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.05191748927909212 | validation: 0.0451945522442349]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04153513592315311		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.04153513592315311 | validation: 0.028123976516587816]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03959095652327946		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.03959095652327946 | validation: 0.0470434981111164]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05326800803909734		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.05326800803909734 | validation: 0.039738120825502474]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048621253074909554		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.048621253074909554 | validation: 0.03934952923959056]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04820872591729139		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.04820872591729139 | validation: 0.032044158750040574]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04630495359861098		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.04630495359861098 | validation: 0.03624221368772955]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042073722363091655		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.042073722363091655 | validation: 0.02581535221275182]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03966898267281947		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.03966898267281947 | validation: 0.03210402980070271]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03862632419558296		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.03862632419558296 | validation: 0.026787698553505913]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03624455767171606		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.03624455767171606 | validation: 0.02751646174660813]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0398312876833822		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.0398312876833822 | validation: 0.02350417764207771]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_1041.pth
	Model improved!!!
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038077561651801026		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.038077561651801026 | validation: 0.03200432470690561]
	TIME [epoch: 11.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03423166297277773		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.03423166297277773 | validation: 0.034330791702140345]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03646726530623569		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.03646726530623569 | validation: 0.03232238721230755]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03572357364806833		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.03572357364806833 | validation: 0.04020417068708649]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037537555235430835		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.037537555235430835 | validation: 0.03352423066577322]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04041785790959444		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.04041785790959444 | validation: 0.03306273932444325]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04201138124697243		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.04201138124697243 | validation: 0.026639997690111522]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037910415972109854		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.037910415972109854 | validation: 0.03103695588012849]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03815854887583014		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.03815854887583014 | validation: 0.034136456872221006]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039280164041412484		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.039280164041412484 | validation: 0.03125100302365914]
	TIME [epoch: 11.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03483690959429495		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.03483690959429495 | validation: 0.04208268143261731]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041258813273608155		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.041258813273608155 | validation: 0.028427911030783626]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04253053231278626		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.04253053231278626 | validation: 0.03880380388227255]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04377498623446624		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.04377498623446624 | validation: 0.03769872664289736]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0464289347519988		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.0464289347519988 | validation: 0.030745746810820655]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035966975009058794		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.035966975009058794 | validation: 0.031553674045053576]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04036207614239951		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.04036207614239951 | validation: 0.04134769952752384]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047241025531881864		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.047241025531881864 | validation: 0.034994744965884644]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032397676216362234		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.032397676216362234 | validation: 0.021959313608034676]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_1060.pth
	Model improved!!!
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03414533942344858		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.03414533942344858 | validation: 0.03001124849569206]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031511865818340416		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.031511865818340416 | validation: 0.026568342186843254]
	TIME [epoch: 11.4 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0321362908742336		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.0321362908742336 | validation: 0.028363426940129405]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030434793375692458		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.030434793375692458 | validation: 0.036689441684011906]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04043078107553494		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.04043078107553494 | validation: 0.02791785549541322]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04071376975277254		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.04071376975277254 | validation: 0.048801162494450295]
	TIME [epoch: 11.4 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05175592961716894		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.05175592961716894 | validation: 0.04202518794062197]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04053573287525004		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.04053573287525004 | validation: 0.03898994506931871]
	TIME [epoch: 11.4 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03761387354119689		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.03761387354119689 | validation: 0.028568830982450708]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03269608009875648		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.03269608009875648 | validation: 0.02672074493592116]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0313425127620994		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.0313425127620994 | validation: 0.0289168508269006]
	TIME [epoch: 11.4 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03264448385409772		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.03264448385409772 | validation: 0.029064087230432252]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03481238399184132		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.03481238399184132 | validation: 0.021396622200977912]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_1073.pth
	Model improved!!!
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03622493057986475		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.03622493057986475 | validation: 0.0339563756892924]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03407623763368544		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.03407623763368544 | validation: 0.03252744157665293]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0390352024401237		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.0390352024401237 | validation: 0.028384873597880157]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03528732519252843		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.03528732519252843 | validation: 0.031152339825364698]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03486759648144777		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.03486759648144777 | validation: 0.029299337122471254]
	TIME [epoch: 11.4 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03432426129285749		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.03432426129285749 | validation: 0.030308084619077233]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032113980157058394		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.032113980157058394 | validation: 0.029237184051829353]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030223361938993214		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.030223361938993214 | validation: 0.02920030233173577]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034567701914372494		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.034567701914372494 | validation: 0.021862952487783957]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03420256655160765		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.03420256655160765 | validation: 0.024614104428430216]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03345675342081051		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.03345675342081051 | validation: 0.025710404465278964]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03544234408863384		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.03544234408863384 | validation: 0.03124627147709462]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034006361396506285		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.034006361396506285 | validation: 0.03281249448095151]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03261162238224834		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.03261162238224834 | validation: 0.029510639233131845]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03481220919560371		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.03481220919560371 | validation: 0.034770063743304894]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038707086039166436		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.038707086039166436 | validation: 0.030749728678159234]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037306536093350696		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.037306536093350696 | validation: 0.029644447741858784]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03746993264966968		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.03746993264966968 | validation: 0.031130365953093448]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036418335539935794		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.036418335539935794 | validation: 0.029956767387994444]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0412277438386241		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.0412277438386241 | validation: 0.030483648248186224]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03670986272763892		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.03670986272763892 | validation: 0.034080193817136]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037269129006581816		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.037269129006581816 | validation: 0.03972721027366618]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04056223177829321		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.04056223177829321 | validation: 0.039319922040198685]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041529404118244156		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.041529404118244156 | validation: 0.033826498947132924]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03903703573476078		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.03903703573476078 | validation: 0.029907116123631134]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03987777942120826		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.03987777942120826 | validation: 0.02569061656450706]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03410344412190641		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.03410344412190641 | validation: 0.024709211883112196]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03428271721384006		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.03428271721384006 | validation: 0.02986677979382021]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032694895947694425		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.032694895947694425 | validation: 0.04436319159296728]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05226481292770456		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.05226481292770456 | validation: 0.05567726071262789]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05947302217983878		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.05947302217983878 | validation: 0.04463421526060641]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03939803271835851		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.03939803271835851 | validation: 0.028345627777162867]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036690508574213694		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.036690508574213694 | validation: 0.025058817941452035]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03284979861048154		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.03284979861048154 | validation: 0.022716179736445432]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03578021603906018		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.03578021603906018 | validation: 0.02831550686344115]
	TIME [epoch: 11.4 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03770850581292333		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.03770850581292333 | validation: 0.02948751905165888]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032987831037920336		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.032987831037920336 | validation: 0.024217181543552735]
	TIME [epoch: 11.4 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357320272055907		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.0357320272055907 | validation: 0.032783524369766656]
	TIME [epoch: 11.4 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0367039086141011		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.0367039086141011 | validation: 0.031436024508383426]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0381389135853492		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.0381389135853492 | validation: 0.03440803676285314]
	TIME [epoch: 11.4 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03991950226173125		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.03991950226173125 | validation: 0.03557949505630594]
	TIME [epoch: 11.4 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035935243775150325		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.035935243775150325 | validation: 0.0315252202907843]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03599989819676031		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.03599989819676031 | validation: 0.02470682760261021]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03628154144020959		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.03628154144020959 | validation: 0.029689542643290937]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037543518702695206		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.037543518702695206 | validation: 0.033314601842697265]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03817208228373418		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.03817208228373418 | validation: 0.041451279842053615]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0444638824540453		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.0444638824540453 | validation: 0.0463080750192351]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044677121397440275		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.044677121397440275 | validation: 0.0379380787889043]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04254833247169688		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.04254833247169688 | validation: 0.047016841554976894]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04519497174571212		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.04519497174571212 | validation: 0.03125190987347931]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040315859539116		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.040315859539116 | validation: 0.023641781451733693]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03357454072305485		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.03357454072305485 | validation: 0.029766036994055806]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038805606868644746		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.038805606868644746 | validation: 0.03519443229667149]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03886781667744259		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.03886781667744259 | validation: 0.029991359352511814]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036846894712502076		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.036846894712502076 | validation: 0.025713193980990114]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03249894704924143		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.03249894704924143 | validation: 0.030600523970166337]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034779122163012745		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.034779122163012745 | validation: 0.027750380892123224]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03346837986091145		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.03346837986091145 | validation: 0.03340398249550374]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032706058807739774		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.032706058807739774 | validation: 0.029520696897598352]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03164115090121741		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.03164115090121741 | validation: 0.03236072243501272]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03516780717268063		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.03516780717268063 | validation: 0.0249785270985238]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03482896055749076		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.03482896055749076 | validation: 0.030299348632356376]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03844887440855971		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.03844887440855971 | validation: 0.02640112004060592]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03237393348392983		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.03237393348392983 | validation: 0.032833836290949145]
	TIME [epoch: 11.4 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03370551505721781		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.03370551505721781 | validation: 0.0322023795942071]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039276733983915006		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.039276733983915006 | validation: 0.03980530541969836]
	TIME [epoch: 11.4 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04496971362112333		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.04496971362112333 | validation: 0.046451539077143715]
	TIME [epoch: 11.4 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04858906317187062		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.04858906317187062 | validation: 0.03963624328184099]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03700640033846965		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.03700640033846965 | validation: 0.037053902169775214]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03773279836986747		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.03773279836986747 | validation: 0.030935045218809295]
	TIME [epoch: 11.4 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035639471217091274		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.035639471217091274 | validation: 0.035452318591179595]
	TIME [epoch: 11.4 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03592875922488757		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.03592875922488757 | validation: 0.034401465517150384]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035713426971109755		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.035713426971109755 | validation: 0.026938852575392608]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03416962540624226		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.03416962540624226 | validation: 0.031579005728265115]
	TIME [epoch: 11.4 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03773875983012723		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.03773875983012723 | validation: 0.038075629797071714]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03931713979585303		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.03931713979585303 | validation: 0.0321517369423948]
	TIME [epoch: 11.4 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03275967137904206		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.03275967137904206 | validation: 0.019179754403946453]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_1150.pth
	Model improved!!!
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03558731480648288		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.03558731480648288 | validation: 0.03608772876949606]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03795474729613646		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.03795474729613646 | validation: 0.0428719677261057]
	TIME [epoch: 11.4 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03709026448824268		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.03709026448824268 | validation: 0.025366727383119167]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02954656097421822		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.02954656097421822 | validation: 0.025965849459358613]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03332447819474359		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.03332447819474359 | validation: 0.027691285902821425]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03271308869247248		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.03271308869247248 | validation: 0.03290074656011554]
	TIME [epoch: 11.4 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0340494488682193		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.0340494488682193 | validation: 0.026198208946118646]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0390843012273999		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.0390843012273999 | validation: 0.04242534590558167]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046242239340048834		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.046242239340048834 | validation: 0.04370185122377148]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04426507198348231		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.04426507198348231 | validation: 0.037530494856657784]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04486467503594173		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.04486467503594173 | validation: 0.038695045537804264]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03883097889571274		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.03883097889571274 | validation: 0.0355170230418371]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03473802242515184		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.03473802242515184 | validation: 0.03683487213603637]
	TIME [epoch: 11.4 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03421448897162899		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.03421448897162899 | validation: 0.018628923619660807]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_1164.pth
	Model improved!!!
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030628662428691007		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.030628662428691007 | validation: 0.03657021902033535]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033440950699400375		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.033440950699400375 | validation: 0.03105975450964195]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030716331689805722		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.030716331689805722 | validation: 0.019451646790396605]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030956314568098737		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.030956314568098737 | validation: 0.02019836984694642]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033957903188915395		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.033957903188915395 | validation: 0.03351201866106346]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032559493334576445		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.032559493334576445 | validation: 0.028380755452723644]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036086226885116174		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.036086226885116174 | validation: 0.029472015105428004]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036574218552690475		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.036574218552690475 | validation: 0.024163690094585334]
	TIME [epoch: 11.4 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03483388592969939		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.03483388592969939 | validation: 0.02253833364354626]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03241522656548898		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.03241522656548898 | validation: 0.021688563160462318]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033748209222049214		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.033748209222049214 | validation: 0.03559068195488708]
	TIME [epoch: 11.4 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031465413505805714		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.031465413505805714 | validation: 0.04006752138226546]
	TIME [epoch: 11.4 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03207701992145921		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.03207701992145921 | validation: 0.028320943959127005]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03276725955307956		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.03276725955307956 | validation: 0.028265797202181222]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0306861275293702		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.0306861275293702 | validation: 0.027607692082481174]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03602258260754587		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.03602258260754587 | validation: 0.035351339207289244]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041802491555659155		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.041802491555659155 | validation: 0.0352799157944383]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036826402503364414		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.036826402503364414 | validation: 0.03035259198380869]
	TIME [epoch: 11.4 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03790851187730164		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.03790851187730164 | validation: 0.036359906544538856]
	TIME [epoch: 11.4 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03752772270332913		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.03752772270332913 | validation: 0.03705717550436064]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03563676014874797		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.03563676014874797 | validation: 0.03610982424097665]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037718783633770674		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.037718783633770674 | validation: 0.04299472002790353]
	TIME [epoch: 11.5 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03304986783086868		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.03304986783086868 | validation: 0.025748191148809624]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030836448370828353		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.030836448370828353 | validation: 0.021869246018827927]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031043826933087583		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.031043826933087583 | validation: 0.025403354790725037]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033216421933284924		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.033216421933284924 | validation: 0.028911894942392175]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03105871305332923		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.03105871305332923 | validation: 0.029406417487264642]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039338700412905686		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.039338700412905686 | validation: 0.03372382677866201]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03076204019711157		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.03076204019711157 | validation: 0.033375182039734066]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03443379259889105		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.03443379259889105 | validation: 0.021964364221176053]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04046656886131714		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.04046656886131714 | validation: 0.046546797335760885]
	TIME [epoch: 11.4 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04475725417004518		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.04475725417004518 | validation: 0.03694089039488234]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04885667508438696		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.04885667508438696 | validation: 0.04028219378907142]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047544505244113695		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.047544505244113695 | validation: 0.05062522149861953]
	TIME [epoch: 11.4 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051128572664246946		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.051128572664246946 | validation: 0.03656139506191724]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04204292815497898		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.04204292815497898 | validation: 0.028146111343762818]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03620780157986804		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.03620780157986804 | validation: 0.030481279814212416]
	TIME [epoch: 11.4 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03492508463776325		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.03492508463776325 | validation: 0.018358118517347793]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_1202.pth
	Model improved!!!
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031816521745539804		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.031816521745539804 | validation: 0.023477689267393142]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03292854326673358		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.03292854326673358 | validation: 0.016890388812996062]
	TIME [epoch: 11.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_1204.pth
	Model improved!!!
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03101747983352352		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.03101747983352352 | validation: 0.026814896913534163]
	TIME [epoch: 11.4 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02910262596882931		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.02910262596882931 | validation: 0.035301726441898044]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03221934114668325		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.03221934114668325 | validation: 0.033940713513476085]
	TIME [epoch: 11.4 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03175902623227196		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.03175902623227196 | validation: 0.030773634554585903]
	TIME [epoch: 11.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030674997201080127		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.030674997201080127 | validation: 0.031208678190693343]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035243218290835		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.035243218290835 | validation: 0.03063997169202173]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035758625192361795		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.035758625192361795 | validation: 0.03031461181892197]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03170108770812164		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.03170108770812164 | validation: 0.024075161806628224]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032007214698383614		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.032007214698383614 | validation: 0.025916398959021817]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03519492016536837		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.03519492016536837 | validation: 0.04107835458487655]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038476887387174086		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.038476887387174086 | validation: 0.038673078987856074]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04235888564233664		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.04235888564233664 | validation: 0.03987532343600409]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03600241584485207		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.03600241584485207 | validation: 0.03173516873373473]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03369230608004885		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.03369230608004885 | validation: 0.03244672774907999]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03491835660853225		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.03491835660853225 | validation: 0.033692219330566424]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03748494007712837		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.03748494007712837 | validation: 0.02998494164264556]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035217426814306396		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.035217426814306396 | validation: 0.03808120123080344]
	TIME [epoch: 11.4 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035495578829751566		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.035495578829751566 | validation: 0.03439643841626966]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03476618990983899		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.03476618990983899 | validation: 0.03460686080896199]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035333303048937045		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.035333303048937045 | validation: 0.02440143396074352]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035023736108575315		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.035023736108575315 | validation: 0.03621563001297038]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033734908053571405		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.033734908053571405 | validation: 0.02707172995441493]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03594769248964354		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.03594769248964354 | validation: 0.036967650193958076]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038436067602178846		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.038436067602178846 | validation: 0.03440472299828998]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03562893132915694		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.03562893132915694 | validation: 0.02928503247581345]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03874666364941054		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.03874666364941054 | validation: 0.030405946135398886]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037483429594811005		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.037483429594811005 | validation: 0.0338059144989227]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03533554007302627		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.03533554007302627 | validation: 0.036565162232302974]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043422989973586554		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.043422989973586554 | validation: 0.04482819420632127]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0442803010440142		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.0442803010440142 | validation: 0.039585799661471056]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0428427695002232		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.0428427695002232 | validation: 0.040730476645633645]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039697961137896365		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.039697961137896365 | validation: 0.030467202614004273]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04015796484401271		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.04015796484401271 | validation: 0.03589568190845896]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029281243819270445		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.029281243819270445 | validation: 0.026111021788916743]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03212974686062635		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.03212974686062635 | validation: 0.024376492025563926]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035284020173261044		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.035284020173261044 | validation: 0.03568070887091986]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03255794632148974		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.03255794632148974 | validation: 0.029813835505417243]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03659710279805317		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.03659710279805317 | validation: 0.02503301176932003]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03506624334870184		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.03506624334870184 | validation: 0.019058958247793755]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03410212919019392		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.03410212919019392 | validation: 0.031686292260099516]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03121823002054344		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.03121823002054344 | validation: 0.0264989995128602]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034503799237453545		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.034503799237453545 | validation: 0.0265884871620248]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03174772585598371		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.03174772585598371 | validation: 0.016943047208834213]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03223433761491131		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.03223433761491131 | validation: 0.03236133910217898]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03783189384190114		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.03783189384190114 | validation: 0.039804733960195515]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05003087090263461		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.05003087090263461 | validation: 0.04877583151177401]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043189406966827715		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.043189406966827715 | validation: 0.03811611484074126]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04151464326073361		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.04151464326073361 | validation: 0.03577379846334984]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04208273299339674		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.04208273299339674 | validation: 0.034817045005578445]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04094832086599652		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.04094832086599652 | validation: 0.03651428988419794]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03656914864696582		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.03656914864696582 | validation: 0.03652349559867808]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036726031949350806		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.036726031949350806 | validation: 0.03178640887385947]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03601972678750854		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.03601972678750854 | validation: 0.03331147106285699]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03755688198821377		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.03755688198821377 | validation: 0.028477622630382657]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03533651207974812		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.03533651207974812 | validation: 0.02866206610727614]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041221428084982796		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.041221428084982796 | validation: 0.03843801947003372]
	TIME [epoch: 11.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037018673083805236		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.037018673083805236 | validation: 0.03624332868613221]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034197192752753305		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.034197192752753305 | validation: 0.0313754731439805]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03427516300549677		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.03427516300549677 | validation: 0.03505774000105921]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03387268041899975		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.03387268041899975 | validation: 0.02500166674777229]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036721761494424805		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.036721761494424805 | validation: 0.0207864308687856]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0334290493255871		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.0334290493255871 | validation: 0.034619628357153695]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031337999408787856		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.031337999408787856 | validation: 0.019601713571132044]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033294629010342844		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.033294629010342844 | validation: 0.026156719665688267]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032128611492091085		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.032128611492091085 | validation: 0.025094143777455582]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030219950363006533		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.030219950363006533 | validation: 0.027751163408553485]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032119062557638065		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.032119062557638065 | validation: 0.02509938427998634]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03204713178043358		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.03204713178043358 | validation: 0.020586030490786996]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028635001329778934		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.028635001329778934 | validation: 0.026457342334599697]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0370321579514116		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.0370321579514116 | validation: 0.025963544643323344]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031203475818548536		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.031203475818548536 | validation: 0.016921093093986816]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027545242427609324		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.027545242427609324 | validation: 0.027091071092297213]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02973101174031239		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.02973101174031239 | validation: 0.02140653589645522]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030750574287726755		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.030750574287726755 | validation: 0.03181002973893756]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02948860168760135		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.02948860168760135 | validation: 0.0302855322569765]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03328642811140793		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.03328642811140793 | validation: 0.026198710244483052]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027435717342980382		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.027435717342980382 | validation: 0.02902214418779138]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03286161416687662		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.03286161416687662 | validation: 0.02862560792682649]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02764349992381242		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.02764349992381242 | validation: 0.02591139333103913]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03316608768507951		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.03316608768507951 | validation: 0.022986233764436176]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02820633757372531		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.02820633757372531 | validation: 0.02117957973487197]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030102572543079305		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.030102572543079305 | validation: 0.031350100903311064]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03825615224403517		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.03825615224403517 | validation: 0.023659568810395163]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0348788069235582		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.0348788069235582 | validation: 0.025337389833899885]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033225949641528245		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.033225949641528245 | validation: 0.018727347699708966]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030956119779862245		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.030956119779862245 | validation: 0.02615547911351772]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030814630621382413		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.030814630621382413 | validation: 0.02556084451153621]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029513035945168437		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.029513035945168437 | validation: 0.025111401371140204]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03046627436384766		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.03046627436384766 | validation: 0.02188653359976314]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031284276512923294		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.031284276512923294 | validation: 0.02154494969545552]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030507356581840728		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.030507356581840728 | validation: 0.023036646478799157]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03361838639138082		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.03361838639138082 | validation: 0.027116048531921743]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029656098480327336		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.029656098480327336 | validation: 0.026001273801965964]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030128189688415626		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.030128189688415626 | validation: 0.02534861826574711]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282972111528439		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.03282972111528439 | validation: 0.01950199957033188]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030804372217576224		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.030804372217576224 | validation: 0.02214883724665541]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031424232786065875		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.031424232786065875 | validation: 0.02631352855061497]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030029463518485507		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.030029463518485507 | validation: 0.0251848947660838]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03333689828439592		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.03333689828439592 | validation: 0.029045634756350438]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03201212423545038		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.03201212423545038 | validation: 0.022782290261179377]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033938739345090584		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.033938739345090584 | validation: 0.03261305584172746]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03053736681048884		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.03053736681048884 | validation: 0.03450065724233696]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03336483261250055		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.03336483261250055 | validation: 0.027749158960739054]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03283800205389925		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.03283800205389925 | validation: 0.024766831548302344]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032350431405133266		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.032350431405133266 | validation: 0.03611812522665177]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029528053630167767		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.029528053630167767 | validation: 0.02882030399329979]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031100289519867708		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.031100289519867708 | validation: 0.024002394319274405]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02942386587513285		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.02942386587513285 | validation: 0.031241685925255377]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030482809812457313		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.030482809812457313 | validation: 0.02444167189272977]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03315943187724783		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.03315943187724783 | validation: 0.024559274662459912]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026880853706564442		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.026880853706564442 | validation: 0.029959013156120064]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03290117653269214		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.03290117653269214 | validation: 0.033233363204830536]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0314164762762242		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.0314164762762242 | validation: 0.026619903203988448]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028738736823468947		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.028738736823468947 | validation: 0.022855668208163454]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028828402960893368		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.028828402960893368 | validation: 0.03193538103112277]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03214784294635395		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.03214784294635395 | validation: 0.028582503381684898]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029429169688256887		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.029429169688256887 | validation: 0.02713700703333763]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028323835893402993		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.028323835893402993 | validation: 0.022189487552500994]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029998933058669307		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.029998933058669307 | validation: 0.0287412647145259]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031826436779737455		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.031826436779737455 | validation: 0.022667094447087095]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035411374824569006		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.035411374824569006 | validation: 0.02850126210720655]
	TIME [epoch: 11.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035455534945928735		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.035455534945928735 | validation: 0.03229947776541904]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331506598239343		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.0331506598239343 | validation: 0.02853823811491112]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0337276343258978		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.0337276343258978 | validation: 0.029729876271871625]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03047688036477346		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.03047688036477346 | validation: 0.033759283120415956]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03545720743632755		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.03545720743632755 | validation: 0.033770801124942705]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03605930414171188		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.03605930414171188 | validation: 0.023866788035028178]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037885318421737854		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.037885318421737854 | validation: 0.0215239292192797]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030722515769517823		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.030722515769517823 | validation: 0.02948371315312053]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028749287708880314		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.028749287708880314 | validation: 0.026053691058122812]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028887613956208046		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.028887613956208046 | validation: 0.030371545584659463]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030844245652855134		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.030844245652855134 | validation: 0.026555857985740096]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028480731605276886		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.028480731605276886 | validation: 0.01579965346368333]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_1337.pth
	Model improved!!!
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031928626458111876		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.031928626458111876 | validation: 0.01678387276191544]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030333097374922718		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.030333097374922718 | validation: 0.0275219796249185]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03124049239797929		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.03124049239797929 | validation: 0.030733639948861868]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03210034408302313		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.03210034408302313 | validation: 0.030786495279616598]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03093078048514629		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.03093078048514629 | validation: 0.026414099508398483]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030618238829502348		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.030618238829502348 | validation: 0.017997642057173493]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02966527998495222		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.02966527998495222 | validation: 0.026208400609448193]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03429947907892793		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.03429947907892793 | validation: 0.034672971659198304]
	TIME [epoch: 11.4 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03239982280674464		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.03239982280674464 | validation: 0.04041672384146414]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03681405895203865		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.03681405895203865 | validation: 0.02699453717870393]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03004495243440103		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.03004495243440103 | validation: 0.02756627997563191]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030806920424028692		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.030806920424028692 | validation: 0.01449102845309067]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_1349.pth
	Model improved!!!
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026510970819902932		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.026510970819902932 | validation: 0.016190677351563987]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02883910545536969		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.02883910545536969 | validation: 0.018703292477889405]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02773201544076857		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.02773201544076857 | validation: 0.021609376152063202]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03197252792246062		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.03197252792246062 | validation: 0.019924966260124258]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03197805925490399		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.03197805925490399 | validation: 0.02814828358054193]
	TIME [epoch: 11.4 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03169868780627854		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.03169868780627854 | validation: 0.0341573930920613]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029860593674360593		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.029860593674360593 | validation: 0.03309655128671488]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027820067153594332		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.027820067153594332 | validation: 0.018863504984535366]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032855858216358245		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.032855858216358245 | validation: 0.036120905449586224]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028641078325995457		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.028641078325995457 | validation: 0.017501291484750704]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029991624991354077		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.029991624991354077 | validation: 0.030504467690725616]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03364925172824048		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.03364925172824048 | validation: 0.03329078954223467]
	TIME [epoch: 11.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027363153764369166		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.027363153764369166 | validation: 0.036965444441905436]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02699370099358277		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.02699370099358277 | validation: 0.027403101330382953]
	TIME [epoch: 11.4 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02784618384860795		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.02784618384860795 | validation: 0.028492226624466852]
	TIME [epoch: 11.4 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024242376624396194		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.024242376624396194 | validation: 0.021355622496157238]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03341012085713349		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.03341012085713349 | validation: 0.02898655855692614]
	TIME [epoch: 11.4 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031718363796815946		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.031718363796815946 | validation: 0.03746133920093908]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032083822768220985		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.032083822768220985 | validation: 0.027921226065422772]
	TIME [epoch: 11.4 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03245668511189728		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.03245668511189728 | validation: 0.028217146045481895]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033132036644984174		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.033132036644984174 | validation: 0.029661025289607228]
	TIME [epoch: 11.4 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032298974425009876		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.032298974425009876 | validation: 0.029298448503591458]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03589623115280037		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.03589623115280037 | validation: 0.024066010645096343]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03337451576506043		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.03337451576506043 | validation: 0.026128928530615714]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03467328344069601		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.03467328344069601 | validation: 0.029364097636407724]
	TIME [epoch: 11.4 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03606639159526976		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.03606639159526976 | validation: 0.03246466301768004]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03634505695766013		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.03634505695766013 | validation: 0.03765343395102873]
	TIME [epoch: 11.4 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0383063302669024		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.0383063302669024 | validation: 0.03356082706352707]
	TIME [epoch: 11.4 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04038513006930961		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.04038513006930961 | validation: 0.042285947652452]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039341816248782725		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.039341816248782725 | validation: 0.03811478123363582]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03998889424104991		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.03998889424104991 | validation: 0.029552213875023634]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03326843621767269		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.03326843621767269 | validation: 0.028879564979661376]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034757140714129886		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.034757140714129886 | validation: 0.03431482839076771]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030712210786471843		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.030712210786471843 | validation: 0.0274696632229399]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02917145688914962		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.02917145688914962 | validation: 0.03354441324316702]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03332480080854306		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.03332480080854306 | validation: 0.023858696596836815]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032761376731398874		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.032761376731398874 | validation: 0.029531574145257495]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030583741574445666		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.030583741574445666 | validation: 0.03192190594551309]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032413211578649945		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.032413211578649945 | validation: 0.028376594197357826]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030255614584690345		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.030255614584690345 | validation: 0.03451069823832625]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0323948075222905		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.0323948075222905 | validation: 0.0347539896053619]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03210010570569169		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.03210010570569169 | validation: 0.02621983967545525]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02896976359341068		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.02896976359341068 | validation: 0.024469747143710353]
	TIME [epoch: 11.4 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03156634684456476		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.03156634684456476 | validation: 0.027349379220321688]
	TIME [epoch: 11.4 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03272137779298977		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.03272137779298977 | validation: 0.021206412810779438]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031428673266126396		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.031428673266126396 | validation: 0.0215147100434561]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02775687674672055		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.02775687674672055 | validation: 0.02484439580819066]
	TIME [epoch: 11.4 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03021165480172354		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.03021165480172354 | validation: 0.02340767459080511]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02943190917953993		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.02943190917953993 | validation: 0.02519638898196673]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03300633748156911		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.03300633748156911 | validation: 0.0221654156684506]
	TIME [epoch: 11.4 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02957929510456108		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.02957929510456108 | validation: 0.02314836835449207]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030631015295230414		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.030631015295230414 | validation: 0.030221460403374617]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030576065942530612		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.030576065942530612 | validation: 0.030308887934756765]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026284194525754426		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.026284194525754426 | validation: 0.02743078858180579]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028548396389905677		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.028548396389905677 | validation: 0.02549105199569944]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030020690261135387		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.030020690261135387 | validation: 0.02647841331542324]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02968043998357862		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.02968043998357862 | validation: 0.03825536852974396]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033782652737114366		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.033782652737114366 | validation: 0.01736934494469818]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032042103316268555		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.032042103316268555 | validation: 0.026556291766181586]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03116825689800381		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.03116825689800381 | validation: 0.01883588686583738]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02979944324193203		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.02979944324193203 | validation: 0.027088209437318617]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028482505252753507		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.028482505252753507 | validation: 0.021884768368993543]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02706242006694879		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.02706242006694879 | validation: 0.02580370114867975]
	TIME [epoch: 11.4 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03346956360154667		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.03346956360154667 | validation: 0.028159687427520314]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03195097202932629		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.03195097202932629 | validation: 0.018562462199398416]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031402686467700947		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.031402686467700947 | validation: 0.022168299183226364]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029220585260758086		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.029220585260758086 | validation: 0.027879853135932598]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03013309679137823		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.03013309679137823 | validation: 0.016090070883869663]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03178609529351287		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.03178609529351287 | validation: 0.019864527695855054]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02634042283415533		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.02634042283415533 | validation: 0.02294273999386804]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02742847084948878		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.02742847084948878 | validation: 0.016742880948606133]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029816537351252375		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.029816537351252375 | validation: 0.0293934091248867]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028892558370470733		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.028892558370470733 | validation: 0.02835017909363752]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026382684294275982		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.026382684294275982 | validation: 0.025845480944083035]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0313739370442948		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.0313739370442948 | validation: 0.029346317068428388]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02357029699484959		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.02357029699484959 | validation: 0.03033142470176756]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02697642791441249		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.02697642791441249 | validation: 0.007357116060246589]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r4_20240309_135637/states/model_tr_study4_1426.pth
	Model improved!!!
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0308949355710512		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.0308949355710512 | validation: 0.020149627889177787]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026929371099074763		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.026929371099074763 | validation: 0.02969049548171084]
	TIME [epoch: 11.4 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034069809088307756		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.034069809088307756 | validation: 0.03455748905652533]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031129051938169984		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.031129051938169984 | validation: 0.027580549978609117]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029008975730769184		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.029008975730769184 | validation: 0.033030566938205025]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03534075134392349		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.03534075134392349 | validation: 0.03192596526220682]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0317555720380206		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.0317555720380206 | validation: 0.036278418792580265]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03335889860536734		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.03335889860536734 | validation: 0.031182855983357745]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03258363105915128		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.03258363105915128 | validation: 0.018352050400127565]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03193434770093521		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.03193434770093521 | validation: 0.023702963598587798]
	TIME [epoch: 11.4 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03480989059742208		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.03480989059742208 | validation: 0.027548443187564407]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03296371193990402		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.03296371193990402 | validation: 0.036112392396223374]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035450358223210354		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.035450358223210354 | validation: 0.02401197478613022]
	TIME [epoch: 11.4 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0344962487738152		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.0344962487738152 | validation: 0.027317943347102837]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03211066450218268		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.03211066450218268 | validation: 0.023147376325787547]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028599822590308056		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.028599822590308056 | validation: 0.025701850134192322]
	TIME [epoch: 11.4 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03120975095160265		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.03120975095160265 | validation: 0.020816225372076468]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030053261153149213		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.030053261153149213 | validation: 0.02355465212298055]
	TIME [epoch: 11.4 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03284243823871052		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.03284243823871052 | validation: 0.023684747632632473]
	TIME [epoch: 11.4 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03170640304386922		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.03170640304386922 | validation: 0.027681722488069535]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030967848587340058		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.030967848587340058 | validation: 0.027483789309184044]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03340155580993781		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.03340155580993781 | validation: 0.01833547790529191]
	TIME [epoch: 11.4 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03050041303491011		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.03050041303491011 | validation: 0.02219192658174281]
	TIME [epoch: 11.4 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03250161261259658		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.03250161261259658 | validation: 0.021816784005466338]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0291857975429124		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.0291857975429124 | validation: 0.018715652366849852]
	TIME [epoch: 11.4 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030807134439179453		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.030807134439179453 | validation: 0.018716130839638332]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03054196213694466		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.03054196213694466 | validation: 0.021359678006618827]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030913280367524075		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.030913280367524075 | validation: 0.018955081618299178]
	TIME [epoch: 11.4 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02783185763655492		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.02783185763655492 | validation: 0.02982214593263443]
	TIME [epoch: 11.4 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02552897148868715		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.02552897148868715 | validation: 0.016770099092280305]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03051693497370491		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.03051693497370491 | validation: 0.02142222287126681]
	TIME [epoch: 11.4 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02882813601391169		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.02882813601391169 | validation: 0.02291065185077577]
	TIME [epoch: 11.4 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031953268586507946		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.031953268586507946 | validation: 0.03346672796003932]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029609580331060238		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.029609580331060238 | validation: 0.01910228523356776]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030346044365850335		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.030346044365850335 | validation: 0.02263812006536284]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028834425160611014		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.028834425160611014 | validation: 0.020805827627904405]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031174592887749212		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.031174592887749212 | validation: 0.03007411929497355]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029076785547548483		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.029076785547548483 | validation: 0.01816615000303506]
	TIME [epoch: 11.4 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027652780395963975		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.027652780395963975 | validation: 0.031093741792801277]
	TIME [epoch: 11.4 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03166171123845521		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.03166171123845521 | validation: 0.0282014294070094]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027067994963951097		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.027067994963951097 | validation: 0.03550364207868668]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028764412489744956		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.028764412489744956 | validation: 0.03029540081305983]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03219945309560919		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.03219945309560919 | validation: 0.028016437452661958]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03417096540731468		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.03417096540731468 | validation: 0.029610426444806392]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03131390302957988		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.03131390302957988 | validation: 0.03137654807992699]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03025885766575341		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.03025885766575341 | validation: 0.027677098791631823]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029356921371939394		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.029356921371939394 | validation: 0.029974105042946297]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029442021025170982		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.029442021025170982 | validation: 0.01840573691121205]
	TIME [epoch: 11.4 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032129078225029736		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.032129078225029736 | validation: 0.03190447347876572]
	TIME [epoch: 11.4 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029164564260699636		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.029164564260699636 | validation: 0.024739443504854436]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030304525655451928		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.030304525655451928 | validation: 0.019463102454020508]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029896208294256973		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.029896208294256973 | validation: 0.020748078985415627]
	TIME [epoch: 11.4 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02961549632809203		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.02961549632809203 | validation: 0.019432397973466523]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026616235275987887		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.026616235275987887 | validation: 0.02701429975281932]
	TIME [epoch: 11.4 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03193195365081506		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.03193195365081506 | validation: 0.020282954468598256]
	TIME [epoch: 11.4 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030652258377399995		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.030652258377399995 | validation: 0.028165218220864287]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03455892754968973		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.03455892754968973 | validation: 0.03441191634706015]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032981541010056584		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.032981541010056584 | validation: 0.022070450799885014]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03082190286531971		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.03082190286531971 | validation: 0.026700251702994313]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030000454651801116		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.030000454651801116 | validation: 0.02734459230683686]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028803759205382556		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.028803759205382556 | validation: 0.02282088457697841]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03292037525596908		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.03292037525596908 | validation: 0.025665943862346392]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02920039907380121		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.02920039907380121 | validation: 0.020639013259639995]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027179717783105874		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.027179717783105874 | validation: 0.02849749895648685]
	TIME [epoch: 11.4 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029509159396745553		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.029509159396745553 | validation: 0.023972527795837802]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030723116232236992		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.030723116232236992 | validation: 0.012770933454294737]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032060628519573225		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.032060628519573225 | validation: 0.021779309204512015]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030936504119576252		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.030936504119576252 | validation: 0.02400678874761974]
	TIME [epoch: 11.4 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03166564517561121		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.03166564517561121 | validation: 0.029001665567740365]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029011078245257442		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.029011078245257442 | validation: 0.02904086178151437]
	TIME [epoch: 11.4 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029358137574635262		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.029358137574635262 | validation: 0.029356216250441627]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030770706838880224		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.030770706838880224 | validation: 0.024277413012391804]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02723543666464452		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.02723543666464452 | validation: 0.020124414335869648]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030047485482121293		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.030047485482121293 | validation: 0.023344523280152588]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02966248875636086		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.02966248875636086 | validation: 0.02239738090343961]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02848610817495919		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.02848610817495919 | validation: 0.02062557377149001]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032416912880470425		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.032416912880470425 | validation: 0.022862366019538054]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029569747835128616		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.029569747835128616 | validation: 0.018598296111625594]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028312184015514972		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.028312184015514972 | validation: 0.03436694889706381]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03218501841469574		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.03218501841469574 | validation: 0.02113952086786775]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02784419340804559		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.02784419340804559 | validation: 0.03350859007573529]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029041703063410397		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.029041703063410397 | validation: 0.02844562572304651]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0308514071693332		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.0308514071693332 | validation: 0.027098025366747668]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03399944158644397		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.03399944158644397 | validation: 0.015921677388437964]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029184564831036503		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.029184564831036503 | validation: 0.02506002600549444]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033712344918288034		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.033712344918288034 | validation: 0.02450153362368326]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02933078536974027		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.02933078536974027 | validation: 0.0204297582345894]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03266581971885997		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.03266581971885997 | validation: 0.029095759857305583]
	TIME [epoch: 11.4 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03135908943886632		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.03135908943886632 | validation: 0.028381297278104692]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03263916094153562		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.03263916094153562 | validation: 0.031201872435713433]
	TIME [epoch: 11.4 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027940857113563866		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.027940857113563866 | validation: 0.028398509496226337]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02935298406885549		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.02935298406885549 | validation: 0.028841942579060042]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03381146521827375		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.03381146521827375 | validation: 0.027018039364408022]
	TIME [epoch: 11.4 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03258170139193249		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.03258170139193249 | validation: 0.033952543678553736]
	TIME [epoch: 11.4 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03244458755972715		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.03244458755972715 | validation: 0.02855999243683669]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030231722421770076		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.030231722421770076 | validation: 0.031815122343596604]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030144543646677888		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.030144543646677888 | validation: 0.027097616598162528]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030300446785822915		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.030300446785822915 | validation: 0.027058178220963]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030360069999612417		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.030360069999612417 | validation: 0.024098564699481163]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03076480948200097		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.03076480948200097 | validation: 0.03647993308023438]
	TIME [epoch: 11.4 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03345912493996933		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.03345912493996933 | validation: 0.024082096219422887]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03191309893501955		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.03191309893501955 | validation: 0.03154733524588723]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029023082302932553		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.029023082302932553 | validation: 0.02706223114939368]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034443218353361366		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.034443218353361366 | validation: 0.033019645720209045]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03055736284192683		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.03055736284192683 | validation: 0.027245858559073445]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02873473755839124		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.02873473755839124 | validation: 0.02720312699332615]
	TIME [epoch: 11.4 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03365664329920841		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.03365664329920841 | validation: 0.03164842628878429]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03229786174227834		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.03229786174227834 | validation: 0.03312478214398138]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029227874285609842		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.029227874285609842 | validation: 0.024414382325727853]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03130546362613379		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.03130546362613379 | validation: 0.02473925556682182]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027921988843453496		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.027921988843453496 | validation: 0.017710207239065398]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031547042839861046		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.031547042839861046 | validation: 0.014787387943524648]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027776999660752408		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.027776999660752408 | validation: 0.030743814987091115]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02910902460810319		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.02910902460810319 | validation: 0.030866111228345358]
	TIME [epoch: 11.4 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030748233788733075		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.030748233788733075 | validation: 0.01930718704925578]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028978495165836265		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.028978495165836265 | validation: 0.025936027082678243]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03114807058064465		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.03114807058064465 | validation: 0.021558362080785577]
	TIME [epoch: 11.4 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02834625158578597		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.02834625158578597 | validation: 0.0311610345530045]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027487869145607885		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.027487869145607885 | validation: 0.0229495218380674]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02508389337482987		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.02508389337482987 | validation: 0.024658034216651022]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029504765939453628		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.029504765939453628 | validation: 0.030580518233131626]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02766662410022932		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.02766662410022932 | validation: 0.029077789991134705]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029695694960254294		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.029695694960254294 | validation: 0.028191832007009945]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032556485734622644		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.032556485734622644 | validation: 0.02016468659814231]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025986025767437203		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.025986025767437203 | validation: 0.02776777050069284]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0268003521576363		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.0268003521576363 | validation: 0.02164492426858336]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03241320791807649		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.03241320791807649 | validation: 0.024898834816595473]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025868343483656638		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.025868343483656638 | validation: 0.02257389864863127]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031732757647802985		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.031732757647802985 | validation: 0.02505436405843339]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027044525755365922		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.027044525755365922 | validation: 0.01893235706136901]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02865931622616623		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.02865931622616623 | validation: 0.016359221870954614]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02920493622179799		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.02920493622179799 | validation: 0.026808696410951266]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025306879865123838		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.025306879865123838 | validation: 0.014680054274043787]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02793012071563159		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.02793012071563159 | validation: 0.02657269258625208]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02906537564738422		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.02906537564738422 | validation: 0.02652674811431026]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03157435900450067		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.03157435900450067 | validation: 0.021530215512998666]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02885093305434158		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.02885093305434158 | validation: 0.022742298441500445]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027875524084222014		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.027875524084222014 | validation: 0.014511903130299809]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026824678703918258		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.026824678703918258 | validation: 0.022563235787330216]
	TIME [epoch: 11.4 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027900551394136615		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.027900551394136615 | validation: 0.023970455577098204]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02578616682060783		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.02578616682060783 | validation: 0.026325769311027383]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02558893867834052		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.02558893867834052 | validation: 0.025384232244491347]
	TIME [epoch: 11.4 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03168452511232392		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.03168452511232392 | validation: 0.02038719606639531]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03223569290743218		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.03223569290743218 | validation: 0.02057913090351889]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025856869195409755		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.025856869195409755 | validation: 0.02281994941389845]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03105874576573588		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.03105874576573588 | validation: 0.02838093555119238]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02886898240197408		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.02886898240197408 | validation: 0.02558964281339252]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03245247420264121		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.03245247420264121 | validation: 0.030865579757086013]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02796057962897276		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.02796057962897276 | validation: 0.01929968527436497]
	TIME [epoch: 11.4 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02785192324308293		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.02785192324308293 | validation: 0.021441997359282632]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027453757746701443		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.027453757746701443 | validation: 0.02343042247810842]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027739280926803382		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.027739280926803382 | validation: 0.02513277297713488]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028465646592784624		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.028465646592784624 | validation: 0.028988130316976553]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029311602396423123		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.029311602396423123 | validation: 0.023338914076864347]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02934358584534696		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.02934358584534696 | validation: 0.022046117875708888]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030683232203094168		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.030683232203094168 | validation: 0.0245477374639147]
	TIME [epoch: 11.4 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029054706134295928		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.029054706134295928 | validation: 0.01967742634206111]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027040615937121676		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.027040615937121676 | validation: 0.0195615161356227]
	TIME [epoch: 11.4 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032418803164482576		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.032418803164482576 | validation: 0.028453762968425847]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027713861314462913		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.027713861314462913 | validation: 0.020172899024987156]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028408636043637213		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.028408636043637213 | validation: 0.02519060077772111]
	TIME [epoch: 11.4 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025681290066126686		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.025681290066126686 | validation: 0.021123780979906963]
	TIME [epoch: 11.4 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02760421484739359		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.02760421484739359 | validation: 0.018021246302946936]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027054744409282572		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.027054744409282572 | validation: 0.027790233736278473]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03021550047584884		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.03021550047584884 | validation: 0.027153609228527293]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028583486520609405		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.028583486520609405 | validation: 0.027470232853209774]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028818400887532097		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.028818400887532097 | validation: 0.02763599405780681]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028313116758164968		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.028313116758164968 | validation: 0.01958116994435907]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029640424567024582		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.029640424567024582 | validation: 0.028677966894165696]
	TIME [epoch: 11.4 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03160397046644724		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.03160397046644724 | validation: 0.027683036832985397]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031062020136352182		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.031062020136352182 | validation: 0.024347726369511883]
	TIME [epoch: 11.4 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02992580342737394		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.02992580342737394 | validation: 0.03085289801853015]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029744587456520703		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.029744587456520703 | validation: 0.032107236881415355]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03083194196232731		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.03083194196232731 | validation: 0.01668189371272893]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028012623599002247		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.028012623599002247 | validation: 0.0218822074174034]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313643354918461		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.03313643354918461 | validation: 0.022492531957318648]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0299746156138503		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.0299746156138503 | validation: 0.021209908073765583]
	TIME [epoch: 11.4 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031512383962193		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.031512383962193 | validation: 0.021983481839212487]
	TIME [epoch: 11.4 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03255780552157028		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.03255780552157028 | validation: 0.015279343718711607]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03281016111203696		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.03281016111203696 | validation: 0.024268144682763865]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028981523203394456		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.028981523203394456 | validation: 0.022753602139525632]
	TIME [epoch: 11.4 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031077626772118276		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.031077626772118276 | validation: 0.024999187910805496]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030865673062185153		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.030865673062185153 | validation: 0.025027237536942765]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028808769198494625		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.028808769198494625 | validation: 0.013134556581829509]
	TIME [epoch: 11.4 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03147701887586094		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.03147701887586094 | validation: 0.02254643661483932]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032957802380517105		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.032957802380517105 | validation: 0.020470795517963047]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029428015976158933		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.029428015976158933 | validation: 0.030002521600972942]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029029422948112678		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.029029422948112678 | validation: 0.028248435680622994]
	TIME [epoch: 11.4 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02806264334050047		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.02806264334050047 | validation: 0.02650942045322121]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03061841223795001		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.03061841223795001 | validation: 0.027107236890534486]
	TIME [epoch: 11.4 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028118054589899036		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.028118054589899036 | validation: 0.028093212419843906]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031631787087038975		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.031631787087038975 | validation: 0.0280142234323906]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02893534927117105		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.02893534927117105 | validation: 0.03144927190136151]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028842365113077105		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.028842365113077105 | validation: 0.02477663900361873]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028301457225781035		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.028301457225781035 | validation: 0.027362835121674128]
	TIME [epoch: 11.4 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029407586378149962		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.029407586378149962 | validation: 0.023405002095208665]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0276747510183616		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.0276747510183616 | validation: 0.024215067092516307]
	TIME [epoch: 11.4 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030966634217397208		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.030966634217397208 | validation: 0.03273390070952898]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034611226214541366		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.034611226214541366 | validation: 0.026609124362622253]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03133988084913911		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.03133988084913911 | validation: 0.026476605841045935]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03051756109751206		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.03051756109751206 | validation: 0.02465954159964694]
	TIME [epoch: 11.4 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027321168615230183		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.027321168615230183 | validation: 0.033548453768967985]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031041349490703005		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.031041349490703005 | validation: 0.027356028348482025]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033961483039071975		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.033961483039071975 | validation: 0.029518943721931645]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03017110122326073		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.03017110122326073 | validation: 0.019361080839431763]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02725850099747915		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.02725850099747915 | validation: 0.02259197482178424]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031282446050056326		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.031282446050056326 | validation: 0.025761094043776994]
	TIME [epoch: 11.4 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029815695995463465		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.029815695995463465 | validation: 0.0248506762445584]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030425979749418436		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.030425979749418436 | validation: 0.02844270616177975]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035518365970912874		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.035518365970912874 | validation: 0.020791194412933686]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031784348738380465		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.031784348738380465 | validation: 0.022379641924793067]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028508695146173525		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.028508695146173525 | validation: 0.028248667791071397]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031218680415702575		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.031218680415702575 | validation: 0.029008279837408647]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03215624313466306		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.03215624313466306 | validation: 0.02156788295254481]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0274624259002002		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.0274624259002002 | validation: 0.029240475230668705]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02913985447335904		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.02913985447335904 | validation: 0.022795976458982715]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029709463029593628		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.029709463029593628 | validation: 0.013418239057024588]
	TIME [epoch: 11.4 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030484987864150846		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.030484987864150846 | validation: 0.024794442487435002]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03239518970209		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.03239518970209 | validation: 0.023358678014782787]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030913498062681885		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.030913498062681885 | validation: 0.0314437532174548]
	TIME [epoch: 11.4 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03106348592878539		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.03106348592878539 | validation: 0.019598595633952467]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03292222546666811		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.03292222546666811 | validation: 0.023899942800978496]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027820092070282864		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.027820092070282864 | validation: 0.027044410922556796]
	TIME [epoch: 11.4 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03136058034401196		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.03136058034401196 | validation: 0.031847705828377315]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026327432931990705		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.026327432931990705 | validation: 0.027269918976851902]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029747061112758183		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.029747061112758183 | validation: 0.021927876481075578]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03348058407534029		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.03348058407534029 | validation: 0.025842357094669324]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028386538197353928		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.028386538197353928 | validation: 0.031145450602460448]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02966780929152748		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.02966780929152748 | validation: 0.024203562447667495]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03069013576463455		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.03069013576463455 | validation: 0.02493608282522332]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03052215264945926		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.03052215264945926 | validation: 0.02989730375481159]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03344712387090074		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.03344712387090074 | validation: 0.02809856876245682]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030424902723228685		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.030424902723228685 | validation: 0.02795073299960006]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03497506381673705		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.03497506381673705 | validation: 0.030469444151373874]
	TIME [epoch: 11.4 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331695103597182		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.0331695103597182 | validation: 0.023785377728938656]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029392590449724677		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.029392590449724677 | validation: 0.02407222610193121]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03043708299029027		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.03043708299029027 | validation: 0.025692871472709794]
	TIME [epoch: 11.4 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379457905427882		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.03379457905427882 | validation: 0.028424319001535327]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03263772280555339		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.03263772280555339 | validation: 0.0251033092205888]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029231379402159967		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.029231379402159967 | validation: 0.017533141761593426]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029870387234338103		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.029870387234338103 | validation: 0.023254429454105593]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027643634243645812		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.027643634243645812 | validation: 0.03188285641684626]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030329155213961644		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.030329155213961644 | validation: 0.02780824578955765]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026254709075531228		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.026254709075531228 | validation: 0.020859668709166716]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02379419666799998		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.02379419666799998 | validation: 0.031169775196111457]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03348618151821564		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.03348618151821564 | validation: 0.023893385588098507]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02873174404684783		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.02873174404684783 | validation: 0.023736916107664534]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03556852423645336		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.03556852423645336 | validation: 0.026121961742882196]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030898683165047534		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.030898683165047534 | validation: 0.024246618855207784]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029633322833203992		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.029633322833203992 | validation: 0.03367395921562601]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03218169118161336		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.03218169118161336 | validation: 0.024105074384950458]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03019788631287366		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.03019788631287366 | validation: 0.029337111825875076]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028302742583698425		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.028302742583698425 | validation: 0.02152791958881671]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03159636195906675		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.03159636195906675 | validation: 0.03339125234210572]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029898449051645563		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.029898449051645563 | validation: 0.021411799368052466]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02673135283688333		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.02673135283688333 | validation: 0.025263299035251943]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028193024977959124		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.028193024977959124 | validation: 0.03462308286836599]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031180451442602418		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.031180451442602418 | validation: 0.03037665032281731]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03164418305209068		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.03164418305209068 | validation: 0.029268143517481908]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030472380971450386		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.030472380971450386 | validation: 0.021592551960448573]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02777520242175468		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.02777520242175468 | validation: 0.026310822157871255]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02919932916793117		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.02919932916793117 | validation: 0.016205215913606658]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03159821098617892		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.03159821098617892 | validation: 0.02212298129703587]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028909483819598975		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.028909483819598975 | validation: 0.017548791991372763]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029741162712338044		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.029741162712338044 | validation: 0.016859596556164168]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03231190384471634		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.03231190384471634 | validation: 0.029369662693224774]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027429687388394897		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.027429687388394897 | validation: 0.022658065509221278]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031938709769916904		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.031938709769916904 | validation: 0.026517103166230495]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029465600881559473		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.029465600881559473 | validation: 0.029323243768534454]
	TIME [epoch: 11.4 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02518251622682264		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.02518251622682264 | validation: 0.02971710190886289]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030520847123872534		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.030520847123872534 | validation: 0.02994967113134889]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030995033281393948		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.030995033281393948 | validation: 0.027118417819151554]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0270170162998893		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.0270170162998893 | validation: 0.016973756081678976]
	TIME [epoch: 11.4 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03063765050004003		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.03063765050004003 | validation: 0.02091198138567482]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027968209880648458		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.027968209880648458 | validation: 0.027938740354165964]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030731619176527225		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.030731619176527225 | validation: 0.023825797706381262]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02977904954984955		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.02977904954984955 | validation: 0.024656703632657796]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029622147122900844		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.029622147122900844 | validation: 0.024216262414238736]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03148750455862441		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.03148750455862441 | validation: 0.03647736317595663]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02837421723869924		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.02837421723869924 | validation: 0.03013487343481839]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030560688820240177		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.030560688820240177 | validation: 0.01805020061562717]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028317087867738837		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.028317087867738837 | validation: 0.03049784155049096]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02903600538468519		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.02903600538468519 | validation: 0.028963124320271573]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02755512156123703		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.02755512156123703 | validation: 0.03046605736492065]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03236819247904398		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.03236819247904398 | validation: 0.02664014368806715]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029271709203373485		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.029271709203373485 | validation: 0.023749755436860493]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02960055109735264		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.02960055109735264 | validation: 0.022378473204770318]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03229310627054567		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.03229310627054567 | validation: 0.023259576430881692]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02637239251485699		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.02637239251485699 | validation: 0.023030386367894194]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029672727697210213		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.029672727697210213 | validation: 0.029807050871219758]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027362735448944		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.027362735448944 | validation: 0.03236406932918446]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030280514730398975		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.030280514730398975 | validation: 0.03059820746038844]
	TIME [epoch: 11.4 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02820931322023252		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.02820931322023252 | validation: 0.02894752413957039]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032836695133319965		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.032836695133319965 | validation: 0.025687571604203964]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03254266477342131		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.03254266477342131 | validation: 0.014111469546511981]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03260647299152852		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.03260647299152852 | validation: 0.017013625968256826]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03078367111673155		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.03078367111673155 | validation: 0.022087246796650528]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028599591929808356		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.028599591929808356 | validation: 0.02085241886779897]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025206839431203623		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.025206839431203623 | validation: 0.02735857669997631]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02839895073564718		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.02839895073564718 | validation: 0.026059691374301888]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02770660584319223		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.02770660584319223 | validation: 0.02806682978078645]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029694016936006068		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.029694016936006068 | validation: 0.02741414014970955]
	TIME [epoch: 11.4 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03218217045634306		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.03218217045634306 | validation: 0.023126108846615125]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029031037973477766		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.029031037973477766 | validation: 0.02278315010900876]
	TIME [epoch: 11.4 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025410793418974235		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.025410793418974235 | validation: 0.02346815658161483]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027106375007671275		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.027106375007671275 | validation: 0.02617014666264589]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025628665564876762		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.025628665564876762 | validation: 0.021387393682625554]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029755175434540176		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.029755175434540176 | validation: 0.02252034879908095]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02781886278996561		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.02781886278996561 | validation: 0.017654066757863768]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02955868047728544		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.02955868047728544 | validation: 0.018937573348709446]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02968494989028827		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.02968494989028827 | validation: 0.0247129344757605]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025775900155105697		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.025775900155105697 | validation: 0.0258094566095287]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03129685608683898		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.03129685608683898 | validation: 0.025538531929258725]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029083826550271842		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.029083826550271842 | validation: 0.018060698318418673]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02798331563564417		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.02798331563564417 | validation: 0.024604924404155872]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028529837029511642		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.028529837029511642 | validation: 0.01676158940562847]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02678330277514941		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.02678330277514941 | validation: 0.023658789198075764]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02775961428586797		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.02775961428586797 | validation: 0.030476155717542405]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03017483157679534		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.03017483157679534 | validation: 0.018977239010289675]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0292039311925121		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.0292039311925121 | validation: 0.017438186528836247]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030249201609842756		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.030249201609842756 | validation: 0.02249281677429261]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02895112552685035		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.02895112552685035 | validation: 0.021751179956128734]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03320079403130985		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.03320079403130985 | validation: 0.02319321056336737]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027284151052734087		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.027284151052734087 | validation: 0.014695402821536679]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024843110692323693		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.024843110692323693 | validation: 0.01838738074347229]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026107115630595916		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.026107115630595916 | validation: 0.018666684903558023]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029061954588603493		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.029061954588603493 | validation: 0.03201630707240945]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027662372656597413		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.027662372656597413 | validation: 0.023050825508079808]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028065029296430698		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.028065029296430698 | validation: 0.020128360558884655]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03093729587876831		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.03093729587876831 | validation: 0.025534268214519193]
	TIME [epoch: 11.4 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029569137537024087		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.029569137537024087 | validation: 0.023264524345325305]
	TIME [epoch: 11.4 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029627803007285944		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.029627803007285944 | validation: 0.02057949535673369]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030507696339624947		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.030507696339624947 | validation: 0.029499495118206882]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028634782181198335		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.028634782181198335 | validation: 0.024638771525827764]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02807575705221559		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.02807575705221559 | validation: 0.030637365903237023]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025393295142627604		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.025393295142627604 | validation: 0.02090808750386161]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028109951011929805		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.028109951011929805 | validation: 0.020658393310745263]
	TIME [epoch: 11.4 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029000215684329235		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.029000215684329235 | validation: 0.025021263648484223]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027177450340732833		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.027177450340732833 | validation: 0.027142869020501923]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030147331588295644		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.030147331588295644 | validation: 0.02515139358783633]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027720944611884624		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.027720944611884624 | validation: 0.027031491702424196]
	TIME [epoch: 11.5 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030568805611579652		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.030568805611579652 | validation: 0.023641030383104084]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03219190418482133		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.03219190418482133 | validation: 0.021893975021105766]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02660187627795478		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.02660187627795478 | validation: 0.02561495281211224]
	TIME [epoch: 11.4 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028913274327499093		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.028913274327499093 | validation: 0.023431237822111442]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026949336416032046		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.026949336416032046 | validation: 0.027818865464381847]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025666016757639024		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.025666016757639024 | validation: 0.022686127218102925]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026715101713926628		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.026715101713926628 | validation: 0.030046075469665513]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02704759314209728		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.02704759314209728 | validation: 0.021591284323343975]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027855236937916254		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.027855236937916254 | validation: 0.021522485848967543]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026675159538140973		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.026675159538140973 | validation: 0.031118472485965328]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027320383476810383		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.027320383476810383 | validation: 0.02954802892662871]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024648700651526263		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.024648700651526263 | validation: 0.02635055307680606]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030664000082620557		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.030664000082620557 | validation: 0.026469614729741724]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02820049300938393		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.02820049300938393 | validation: 0.02101770466501463]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033122893028621335		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.033122893028621335 | validation: 0.027995560977008713]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027800552372410088		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.027800552372410088 | validation: 0.02985267555639262]
	TIME [epoch: 11.4 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03012033942408133		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.03012033942408133 | validation: 0.02694338305957568]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0281720690029063		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.0281720690029063 | validation: 0.02880348319946145]
	TIME [epoch: 11.4 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025820636167156595		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.025820636167156595 | validation: 0.02336015963289782]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02964315632765162		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.02964315632765162 | validation: 0.026151541270742432]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030708619273990476		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.030708619273990476 | validation: 0.024626644912159018]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03003078707304071		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.03003078707304071 | validation: 0.02438206932025394]
	TIME [epoch: 11.4 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027443852914333263		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.027443852914333263 | validation: 0.030097772809456292]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024114194473609865		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.024114194473609865 | validation: 0.025774588625845904]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028234159071958788		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.028234159071958788 | validation: 0.02086219150356833]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027078199875534947		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.027078199875534947 | validation: 0.025450185214484274]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028196683318218		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.028196683318218 | validation: 0.023258852664778434]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028946460872612077		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.028946460872612077 | validation: 0.024913402373951152]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029735943625291604		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.029735943625291604 | validation: 0.029369159999026385]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029717820933131574		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.029717820933131574 | validation: 0.020474512729517124]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029544379741138226		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.029544379741138226 | validation: 0.026685871114033637]
	TIME [epoch: 11.4 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027671793292039122		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.027671793292039122 | validation: 0.02663562320262412]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02797005816331092		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.02797005816331092 | validation: 0.021280700153724807]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030513950075522878		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.030513950075522878 | validation: 0.030305195383151465]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027654618376792416		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.027654618376792416 | validation: 0.01479238398950081]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030771268019528085		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.030771268019528085 | validation: 0.02576260783022729]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02745459728107365		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.02745459728107365 | validation: 0.01117964974391988]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026361455909565096		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.026361455909565096 | validation: 0.0181366119759071]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02628998583549661		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.02628998583549661 | validation: 0.022629522606991585]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027241930934034615		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.027241930934034615 | validation: 0.01816853418815511]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028920152476596683		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.028920152476596683 | validation: 0.023433956502586648]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026334772037477368		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.026334772037477368 | validation: 0.0178774888165145]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025719212880208966		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.025719212880208966 | validation: 0.024268801377983013]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02959782607834011		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.02959782607834011 | validation: 0.028256098735363264]
	TIME [epoch: 11.4 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030099519099805093		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.030099519099805093 | validation: 0.037069375697448226]
	TIME [epoch: 11.4 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029804548078983438		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.029804548078983438 | validation: 0.023841562765452053]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026971029179158005		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.026971029179158005 | validation: 0.025527729960393663]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027325697442894085		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.027325697442894085 | validation: 0.018793930346052447]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029490222099663833		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.029490222099663833 | validation: 0.02475724573862788]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02941444754643498		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.02941444754643498 | validation: 0.024568549595510927]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028173638085080617		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.028173638085080617 | validation: 0.011902305691428233]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030333019770636536		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.030333019770636536 | validation: 0.023962921798746657]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02895645309373339		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.02895645309373339 | validation: 0.023608505837685846]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028244252844295163		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.028244252844295163 | validation: 0.0271804288466118]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02878109184766131		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.02878109184766131 | validation: 0.023375643587963096]
	TIME [epoch: 11.4 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030489448510951048		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.030489448510951048 | validation: 0.024584071882199812]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031079062936069636		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.031079062936069636 | validation: 0.016022083792918945]
	TIME [epoch: 11.4 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0276958458952678		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.0276958458952678 | validation: 0.029673214010638414]
	TIME [epoch: 11.4 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02895684833754932		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.02895684833754932 | validation: 0.024379921258648737]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027108983686406574		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.027108983686406574 | validation: 0.020955429686619616]
	TIME [epoch: 11.4 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030477605250231757		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.030477605250231757 | validation: 0.0216046103137255]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029208612113251892		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.029208612113251892 | validation: 0.024543336947829755]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02746201036061427		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.02746201036061427 | validation: 0.025228442839520242]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02800020317761782		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.02800020317761782 | validation: 0.024841360144558036]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029597063983364116		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.029597063983364116 | validation: 0.026013417807749937]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02916667855729866		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.02916667855729866 | validation: 0.025468908141465928]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030767091947110116		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.030767091947110116 | validation: 0.02571257650195128]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032131273075292274		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.032131273075292274 | validation: 0.02591445809329554]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029464824246549122		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.029464824246549122 | validation: 0.0201565352363647]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02403668107644461		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.02403668107644461 | validation: 0.01519781065941837]
	TIME [epoch: 11.4 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028971655866274648		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.028971655866274648 | validation: 0.019529274950582213]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03395915956390606		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.03395915956390606 | validation: 0.023688089999884428]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026341398416888054		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.026341398416888054 | validation: 0.02731597452306278]
	TIME [epoch: 11.4 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02879440749215586		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.02879440749215586 | validation: 0.018279734045132764]
	TIME [epoch: 11.4 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030205891250194208		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.030205891250194208 | validation: 0.019399949647690297]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02727332357771526		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.02727332357771526 | validation: 0.02219936229124465]
	TIME [epoch: 11.4 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030022541758066422		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.030022541758066422 | validation: 0.030724857143228666]
	TIME [epoch: 11.4 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02732485593955656		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.02732485593955656 | validation: 0.025347979573155932]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029488122786437844		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.029488122786437844 | validation: 0.015860940828296553]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02765498256296868		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.02765498256296868 | validation: 0.020640067420319534]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029177363484391573		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.029177363484391573 | validation: 0.020772715046318772]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023427486894925114		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.023427486894925114 | validation: 0.015923373089819885]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027067153280317283		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.027067153280317283 | validation: 0.02115177423342835]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02638333616937942		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.02638333616937942 | validation: 0.02196115851034219]
	TIME [epoch: 11.4 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029923134936940675		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.029923134936940675 | validation: 0.025050379975531722]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0322264990972141		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.0322264990972141 | validation: 0.024136618583704507]
	TIME [epoch: 11.4 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02639527986851225		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.02639527986851225 | validation: 0.02785258422113979]
	TIME [epoch: 11.4 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03089532706040642		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.03089532706040642 | validation: 0.024896817323225774]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029337442343288663		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.029337442343288663 | validation: 0.028851740463156975]
	TIME [epoch: 11.4 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02695417897533496		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.02695417897533496 | validation: 0.022661497892796617]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0279703239136341		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.0279703239136341 | validation: 0.02109467959692619]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026808373082318385		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.026808373082318385 | validation: 0.022585948957061612]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02710580421387723		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.02710580421387723 | validation: 0.020535788228607636]
	TIME [epoch: 11.4 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02932587670364677		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.02932587670364677 | validation: 0.017254580355814605]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029412938190405483		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.029412938190405483 | validation: 0.021716657609394008]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027203896107070902		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.027203896107070902 | validation: 0.025507416251624684]
	TIME [epoch: 11.4 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02935882073804434		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.02935882073804434 | validation: 0.02772375396858381]
	TIME [epoch: 11.4 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031095379479845774		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.031095379479845774 | validation: 0.016305723820396464]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02762817853705886		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.02762817853705886 | validation: 0.024876555981774472]
	TIME [epoch: 11.4 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029949979701352412		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.029949979701352412 | validation: 0.019692087452267328]
	TIME [epoch: 11.4 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02787774421456029		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.02787774421456029 | validation: 0.017081253203357613]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027776332366249684		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.027776332366249684 | validation: 0.025861824764427728]
	TIME [epoch: 11.4 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027742289729717696		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.027742289729717696 | validation: 0.01971650477773866]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029364519473122637		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.029364519473122637 | validation: 0.023451816961982175]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02517405228957855		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.02517405228957855 | validation: 0.02032559319837738]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02804303952001881		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.02804303952001881 | validation: 0.024137791435989913]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02732167083348254		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.02732167083348254 | validation: 0.03128798111149178]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0275165516498425		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.0275165516498425 | validation: 0.02650486637053244]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025246874135016778		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.025246874135016778 | validation: 0.02321577284270764]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02643348531029966		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.02643348531029966 | validation: 0.021780085722082187]
	TIME [epoch: 11.4 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029263217967601493		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.029263217967601493 | validation: 0.026158642258251073]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030025502977533314		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.030025502977533314 | validation: 0.015071682768214205]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02682391009457902		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.02682391009457902 | validation: 0.019404657972589938]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026325497798563056		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.026325497798563056 | validation: 0.02391338940189524]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028056754180934555		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.028056754180934555 | validation: 0.019351499688692837]
	TIME [epoch: 11.4 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02517051958900815		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.02517051958900815 | validation: 0.021301041175891364]
	TIME [epoch: 11.4 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025490507982097805		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.025490507982097805 | validation: 0.020116617705237764]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024737640254248412		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.024737640254248412 | validation: 0.0225169733205499]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027459419590102254		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.027459419590102254 | validation: 0.019633518301934525]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025430399893929454		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.025430399893929454 | validation: 0.025565613891076394]
	TIME [epoch: 11.4 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03086505811095764		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.03086505811095764 | validation: 0.02270121229326213]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03314943770251573		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.03314943770251573 | validation: 0.02291524241122122]
	TIME [epoch: 11.5 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027453785731270525		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.027453785731270525 | validation: 0.02173923386907666]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028402672350663138		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.028402672350663138 | validation: 0.03023461842084916]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029963093836510083		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.029963093836510083 | validation: 0.022695215096324627]
	TIME [epoch: 11.5 sec]
EPOCH 1893/2000:
	Training over batches...
