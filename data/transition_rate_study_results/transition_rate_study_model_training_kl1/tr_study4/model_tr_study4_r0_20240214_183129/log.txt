Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r0', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3002982523

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/10] avg loss: 7.067036722123815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.067036722123815 | validation: 6.088010196517356]
	TIME [epoch: 48.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/10] avg loss: 5.518794621325107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.518794621325107 | validation: 6.003307901948877]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/10] avg loss: 5.0215247927539375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0215247927539375 | validation: 6.222263479329854]
	TIME [epoch: 9.07 sec]
EPOCH 4/500:
	Training over batches...
		[batch 10/10] avg loss: 4.65459832472859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.65459832472859 | validation: 5.074813700448821]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/10] avg loss: 4.171510371480883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.171510371480883 | validation: 5.556172448032736]
	TIME [epoch: 9.01 sec]
EPOCH 6/500:
	Training over batches...
		[batch 10/10] avg loss: 4.204831708999414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.204831708999414 | validation: 4.7171181246754905]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/10] avg loss: 3.7483537192288323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7483537192288323 | validation: 3.990115125504615]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 10/10] avg loss: 4.145351042756529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.145351042756529 | validation: 3.7840836474938264]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 10/10] avg loss: 3.1813320084793606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1813320084793606 | validation: 3.2345047652665295]
	TIME [epoch: 9.04 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 10/10] avg loss: 2.855970860735584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.855970860735584 | validation: 3.279297335905193]
	TIME [epoch: 9.06 sec]
EPOCH 11/500:
	Training over batches...
		[batch 10/10] avg loss: 2.840188715540587		[learning rate: 0.0099578]
	Learning Rate: 0.0099578
	LOSS [training: 2.840188715540587 | validation: 2.7832366405941387]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 10/10] avg loss: 2.8225977137139155		[learning rate: 0.0099111]
	Learning Rate: 0.00991111
	LOSS [training: 2.8225977137139155 | validation: 2.582136858391152]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 10/10] avg loss: 2.530547065216923		[learning rate: 0.0098646]
	Learning Rate: 0.00986465
	LOSS [training: 2.530547065216923 | validation: 2.863141103959065]
	TIME [epoch: 9.05 sec]
EPOCH 14/500:
	Training over batches...
		[batch 10/10] avg loss: 2.5912189948674715		[learning rate: 0.0098184]
	Learning Rate: 0.0098184
	LOSS [training: 2.5912189948674715 | validation: 3.9107281755765073]
	TIME [epoch: 9.07 sec]
EPOCH 15/500:
	Training over batches...
		[batch 10/10] avg loss: 2.7931961651601993		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 2.7931961651601993 | validation: 2.3544184109476065]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 10/10] avg loss: 2.1425547796430897		[learning rate: 0.0097266]
	Learning Rate: 0.00972656
	LOSS [training: 2.1425547796430897 | validation: 2.1219625076210793]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0788625475324767		[learning rate: 0.009681]
	Learning Rate: 0.00968096
	LOSS [training: 2.0788625475324767 | validation: 2.447848314330339]
	TIME [epoch: 9.03 sec]
EPOCH 18/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0974587302303926		[learning rate: 0.0096356]
	Learning Rate: 0.00963557
	LOSS [training: 2.0974587302303926 | validation: 2.260469232699039]
	TIME [epoch: 9.02 sec]
EPOCH 19/500:
	Training over batches...
		[batch 10/10] avg loss: 1.8770808747629133		[learning rate: 0.0095904]
	Learning Rate: 0.0095904
	LOSS [training: 1.8770808747629133 | validation: 2.0721173042937164]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6642652254421186		[learning rate: 0.0095454]
	Learning Rate: 0.00954544
	LOSS [training: 1.6642652254421186 | validation: 2.0209186781186546]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7033552694989822		[learning rate: 0.0095007]
	Learning Rate: 0.00950069
	LOSS [training: 1.7033552694989822 | validation: 1.9331095095130946]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6533782892524393		[learning rate: 0.0094561]
	Learning Rate: 0.00945615
	LOSS [training: 1.6533782892524393 | validation: 1.904212030616863]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7191304594439836		[learning rate: 0.0094118]
	Learning Rate: 0.00941182
	LOSS [training: 1.7191304594439836 | validation: 1.672569444118592]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5874354531158137		[learning rate: 0.0093677]
	Learning Rate: 0.00936769
	LOSS [training: 1.5874354531158137 | validation: 3.2582273368810464]
	TIME [epoch: 9.05 sec]
EPOCH 25/500:
	Training over batches...
		[batch 10/10] avg loss: 1.619581686247141		[learning rate: 0.0093238]
	Learning Rate: 0.00932378
	LOSS [training: 1.619581686247141 | validation: 1.5609485775765781]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4103738589844017		[learning rate: 0.0092801]
	Learning Rate: 0.00928007
	LOSS [training: 1.4103738589844017 | validation: 1.352609819637939]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3622108812119538		[learning rate: 0.0092366]
	Learning Rate: 0.00923656
	LOSS [training: 1.3622108812119538 | validation: 1.5004652929873505]
	TIME [epoch: 9.06 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2248529750154553		[learning rate: 0.0091933]
	Learning Rate: 0.00919326
	LOSS [training: 1.2248529750154553 | validation: 1.1078644554026242]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1318860811032936		[learning rate: 0.0091502]
	Learning Rate: 0.00915016
	LOSS [training: 1.1318860811032936 | validation: 4.359103348470834]
	TIME [epoch: 9.04 sec]
EPOCH 30/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5177252777116474		[learning rate: 0.0091073]
	Learning Rate: 0.00910726
	LOSS [training: 1.5177252777116474 | validation: 1.3895000356752902]
	TIME [epoch: 9.08 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0519491929982638		[learning rate: 0.0090646]
	Learning Rate: 0.00906456
	LOSS [training: 1.0519491929982638 | validation: 1.0129289945647948]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9416926703592037		[learning rate: 0.0090221]
	Learning Rate: 0.00902207
	LOSS [training: 0.9416926703592037 | validation: 0.9791100741859663]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9597131219800941		[learning rate: 0.0089798]
	Learning Rate: 0.00897977
	LOSS [training: 0.9597131219800941 | validation: 0.8251075285394411]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 10/10] avg loss: 0.834795691884152		[learning rate: 0.0089377]
	Learning Rate: 0.00893767
	LOSS [training: 0.834795691884152 | validation: 0.8627633346846284]
	TIME [epoch: 9.06 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/10] avg loss: 0.98665117382851		[learning rate: 0.0088958]
	Learning Rate: 0.00889577
	LOSS [training: 0.98665117382851 | validation: 1.4966432652244301]
	TIME [epoch: 9.06 sec]
EPOCH 36/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8008290361949033		[learning rate: 0.0088541]
	Learning Rate: 0.00885407
	LOSS [training: 0.8008290361949033 | validation: 1.0610545097609658]
	TIME [epoch: 9.07 sec]
EPOCH 37/500:
	Training over batches...
		[batch 10/10] avg loss: 0.73981066255868		[learning rate: 0.0088126]
	Learning Rate: 0.00881256
	LOSS [training: 0.73981066255868 | validation: 0.9221289570186713]
	TIME [epoch: 9.06 sec]
EPOCH 38/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6970317705072577		[learning rate: 0.0087712]
	Learning Rate: 0.00877124
	LOSS [training: 0.6970317705072577 | validation: 0.6349219632835039]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6420616051462271		[learning rate: 0.0087301]
	Learning Rate: 0.00873012
	LOSS [training: 0.6420616051462271 | validation: 0.6280252037192641]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5691100753354693		[learning rate: 0.0086892]
	Learning Rate: 0.00868919
	LOSS [training: 0.5691100753354693 | validation: 1.0718987709990695]
	TIME [epoch: 9.09 sec]
EPOCH 41/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6117598269981139		[learning rate: 0.0086485]
	Learning Rate: 0.00864846
	LOSS [training: 0.6117598269981139 | validation: 0.5229807476495891]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_41.pth
	Model improved!!!
EPOCH 42/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6621366016076664		[learning rate: 0.0086079]
	Learning Rate: 0.00860791
	LOSS [training: 0.6621366016076664 | validation: 0.5128055651753072]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 10/10] avg loss: 0.553940140100333		[learning rate: 0.0085676]
	Learning Rate: 0.00856756
	LOSS [training: 0.553940140100333 | validation: 0.6938865999953343]
	TIME [epoch: 9.1 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7224044905571496		[learning rate: 0.0085274]
	Learning Rate: 0.00852739
	LOSS [training: 0.7224044905571496 | validation: 0.6266243541629761]
	TIME [epoch: 9.09 sec]
EPOCH 45/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5770028870161754		[learning rate: 0.0084874]
	Learning Rate: 0.00848742
	LOSS [training: 0.5770028870161754 | validation: 0.4234084120418514]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6173170881589589		[learning rate: 0.0084476]
	Learning Rate: 0.00844763
	LOSS [training: 0.6173170881589589 | validation: 2.184645651417977]
	TIME [epoch: 9.11 sec]
EPOCH 47/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9019331156801178		[learning rate: 0.008408]
	Learning Rate: 0.00840802
	LOSS [training: 0.9019331156801178 | validation: 0.6256363515133998]
	TIME [epoch: 9.16 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5458240454990065		[learning rate: 0.0083686]
	Learning Rate: 0.0083686
	LOSS [training: 0.5458240454990065 | validation: 0.5393102497843054]
	TIME [epoch: 9.09 sec]
EPOCH 49/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47101022970603845		[learning rate: 0.0083294]
	Learning Rate: 0.00832937
	LOSS [training: 0.47101022970603845 | validation: 0.5990587022102565]
	TIME [epoch: 9.1 sec]
EPOCH 50/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5995719457208848		[learning rate: 0.0082903]
	Learning Rate: 0.00829032
	LOSS [training: 0.5995719457208848 | validation: 1.2078020663433928]
	TIME [epoch: 9.13 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6580972024011243		[learning rate: 0.0082515]
	Learning Rate: 0.00825146
	LOSS [training: 0.6580972024011243 | validation: 0.5027706872527847]
	TIME [epoch: 9.1 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5597980776114939		[learning rate: 0.0082128]
	Learning Rate: 0.00821277
	LOSS [training: 0.5597980776114939 | validation: 0.4732031505055323]
	TIME [epoch: 9.07 sec]
EPOCH 53/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4497940628381161		[learning rate: 0.0081743]
	Learning Rate: 0.00817427
	LOSS [training: 0.4497940628381161 | validation: 0.49330124184500523]
	TIME [epoch: 9.1 sec]
EPOCH 54/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7448973098038586		[learning rate: 0.0081359]
	Learning Rate: 0.00813595
	LOSS [training: 0.7448973098038586 | validation: 0.6730189184071407]
	TIME [epoch: 9.08 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4707795732164848		[learning rate: 0.0080978]
	Learning Rate: 0.00809781
	LOSS [training: 0.4707795732164848 | validation: 0.5732785018449623]
	TIME [epoch: 9.13 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5479037907734936		[learning rate: 0.0080598]
	Learning Rate: 0.00805984
	LOSS [training: 0.5479037907734936 | validation: 0.4437791346877912]
	TIME [epoch: 9.11 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5369518174642091		[learning rate: 0.0080221]
	Learning Rate: 0.00802206
	LOSS [training: 0.5369518174642091 | validation: 0.46196552069509056]
	TIME [epoch: 9.16 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4670029053297746		[learning rate: 0.0079844]
	Learning Rate: 0.00798445
	LOSS [training: 0.4670029053297746 | validation: 0.43714966831779767]
	TIME [epoch: 9.09 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47022352522372		[learning rate: 0.007947]
	Learning Rate: 0.00794702
	LOSS [training: 0.47022352522372 | validation: 0.46542439988158807]
	TIME [epoch: 9.1 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0667760467807046		[learning rate: 0.0079098]
	Learning Rate: 0.00790976
	LOSS [training: 2.0667760467807046 | validation: 0.7170903354037224]
	TIME [epoch: 9.11 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5137966299213957		[learning rate: 0.0078727]
	Learning Rate: 0.00787268
	LOSS [training: 0.5137966299213957 | validation: 0.6646823592521083]
	TIME [epoch: 9.12 sec]
EPOCH 62/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4620726689547173		[learning rate: 0.0078358]
	Learning Rate: 0.00783577
	LOSS [training: 0.4620726689547173 | validation: 0.6403708304963818]
	TIME [epoch: 9.09 sec]
EPOCH 63/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45680399086821566		[learning rate: 0.007799]
	Learning Rate: 0.00779903
	LOSS [training: 0.45680399086821566 | validation: 0.8774235910159459]
	TIME [epoch: 9.1 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5715094567048957		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 0.5715094567048957 | validation: 0.4114306176467405]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_64.pth
	Model improved!!!
EPOCH 65/500:
	Training over batches...
		[batch 10/10] avg loss: 0.617340276759635		[learning rate: 0.0077261]
	Learning Rate: 0.00772608
	LOSS [training: 0.617340276759635 | validation: 0.6148832371956412]
	TIME [epoch: 9.17 sec]
EPOCH 66/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5361588727810522		[learning rate: 0.0076899]
	Learning Rate: 0.00768986
	LOSS [training: 0.5361588727810522 | validation: 1.2026921095746839]
	TIME [epoch: 9.14 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5676786198360044		[learning rate: 0.0076538]
	Learning Rate: 0.00765381
	LOSS [training: 0.5676786198360044 | validation: 0.45566260462613906]
	TIME [epoch: 9.15 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4845724034510974		[learning rate: 0.0076179]
	Learning Rate: 0.00761793
	LOSS [training: 0.4845724034510974 | validation: 0.3803233566168281]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_68.pth
	Model improved!!!
EPOCH 69/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4847744718094513		[learning rate: 0.0075822]
	Learning Rate: 0.00758221
	LOSS [training: 0.4847744718094513 | validation: 0.9684590013545042]
	TIME [epoch: 9.12 sec]
EPOCH 70/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5168463854326173		[learning rate: 0.0075467]
	Learning Rate: 0.00754667
	LOSS [training: 0.5168463854326173 | validation: 0.3888068910687157]
	TIME [epoch: 9.14 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/10] avg loss: 0.46651119271018776		[learning rate: 0.0075113]
	Learning Rate: 0.00751129
	LOSS [training: 0.46651119271018776 | validation: 0.45776093634423265]
	TIME [epoch: 9.13 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4520533732246331		[learning rate: 0.0074761]
	Learning Rate: 0.00747607
	LOSS [training: 0.4520533732246331 | validation: 0.38611948876939584]
	TIME [epoch: 9.12 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3827223990574601		[learning rate: 0.007441]
	Learning Rate: 0.00744102
	LOSS [training: 0.3827223990574601 | validation: 0.4385216951795091]
	TIME [epoch: 9.1 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5439846257774543		[learning rate: 0.0074061]
	Learning Rate: 0.00740614
	LOSS [training: 0.5439846257774543 | validation: 0.824519576690695]
	TIME [epoch: 9.12 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4049051049997045		[learning rate: 0.0073714]
	Learning Rate: 0.00737142
	LOSS [training: 0.4049051049997045 | validation: 0.33176058181566087]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_75.pth
	Model improved!!!
EPOCH 76/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41853627857662296		[learning rate: 0.0073369]
	Learning Rate: 0.00733686
	LOSS [training: 0.41853627857662296 | validation: 0.5593106125443534]
	TIME [epoch: 9.08 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4041502477030038		[learning rate: 0.0073025]
	Learning Rate: 0.00730246
	LOSS [training: 0.4041502477030038 | validation: 0.36013832193395356]
	TIME [epoch: 9.06 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3654457365153485		[learning rate: 0.0072682]
	Learning Rate: 0.00726823
	LOSS [training: 0.3654457365153485 | validation: 0.361250484865387]
	TIME [epoch: 9.06 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37937645800032593		[learning rate: 0.0072342]
	Learning Rate: 0.00723415
	LOSS [training: 0.37937645800032593 | validation: 0.3080736016769444]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_79.pth
	Model improved!!!
EPOCH 80/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3234895483329661		[learning rate: 0.0072002]
	Learning Rate: 0.00720024
	LOSS [training: 0.3234895483329661 | validation: 0.7669250417984389]
	TIME [epoch: 9.08 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5408275807960186		[learning rate: 0.0071665]
	Learning Rate: 0.00716648
	LOSS [training: 0.5408275807960186 | validation: 0.38105954337772535]
	TIME [epoch: 9.06 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4367689685589552		[learning rate: 0.0071329]
	Learning Rate: 0.00713289
	LOSS [training: 0.4367689685589552 | validation: 0.36739114737596446]
	TIME [epoch: 9.06 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38353000120616987		[learning rate: 0.0070994]
	Learning Rate: 0.00709945
	LOSS [training: 0.38353000120616987 | validation: 0.30138033577746604]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_83.pth
	Model improved!!!
EPOCH 84/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37261173350131865		[learning rate: 0.0070662]
	Learning Rate: 0.00706616
	LOSS [training: 0.37261173350131865 | validation: 0.3740280559029462]
	TIME [epoch: 9.09 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4053124503561289		[learning rate: 0.007033]
	Learning Rate: 0.00703304
	LOSS [training: 0.4053124503561289 | validation: 0.34584117914849344]
	TIME [epoch: 9.07 sec]
EPOCH 86/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39362184146969637		[learning rate: 0.0070001]
	Learning Rate: 0.00700006
	LOSS [training: 0.39362184146969637 | validation: 0.3364612421454131]
	TIME [epoch: 9.06 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32538317942995926		[learning rate: 0.0069672]
	Learning Rate: 0.00696725
	LOSS [training: 0.32538317942995926 | validation: 0.2923507070399584]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_87.pth
	Model improved!!!
EPOCH 88/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32428195281226396		[learning rate: 0.0069346]
	Learning Rate: 0.00693458
	LOSS [training: 0.32428195281226396 | validation: 0.3018528896448349]
	TIME [epoch: 9.07 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6184145643278947		[learning rate: 0.0069021]
	Learning Rate: 0.00690207
	LOSS [training: 0.6184145643278947 | validation: 0.39299206245642093]
	TIME [epoch: 9.1 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36105402979983114		[learning rate: 0.0068697]
	Learning Rate: 0.00686972
	LOSS [training: 0.36105402979983114 | validation: 0.47457006822304915]
	TIME [epoch: 9.08 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3325627279384853		[learning rate: 0.0068375]
	Learning Rate: 0.00683751
	LOSS [training: 0.3325627279384853 | validation: 0.27836318229935036]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_91.pth
	Model improved!!!
EPOCH 92/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35898476773422006		[learning rate: 0.0068055]
	Learning Rate: 0.00680545
	LOSS [training: 0.35898476773422006 | validation: 0.723410069298017]
	TIME [epoch: 9.06 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3695822582156225		[learning rate: 0.0067735]
	Learning Rate: 0.00677355
	LOSS [training: 0.3695822582156225 | validation: 0.29406658158748533]
	TIME [epoch: 9.07 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3190744251721602		[learning rate: 0.0067418]
	Learning Rate: 0.00674179
	LOSS [training: 0.3190744251721602 | validation: 0.332562172843471]
	TIME [epoch: 9.1 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26693640298711163		[learning rate: 0.0067102]
	Learning Rate: 0.00671019
	LOSS [training: 0.26693640298711163 | validation: 0.26254307748351446]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_95.pth
	Model improved!!!
EPOCH 96/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31187085461541214		[learning rate: 0.0066787]
	Learning Rate: 0.00667873
	LOSS [training: 0.31187085461541214 | validation: 1.0293570742073876]
	TIME [epoch: 9.06 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3406704108073946		[learning rate: 0.0066474]
	Learning Rate: 0.00664742
	LOSS [training: 0.3406704108073946 | validation: 0.45824800802895027]
	TIME [epoch: 9.06 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36395261544941826		[learning rate: 0.0066163]
	Learning Rate: 0.00661625
	LOSS [training: 0.36395261544941826 | validation: 0.2287413173264347]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_98.pth
	Model improved!!!
EPOCH 99/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26373728024972043		[learning rate: 0.0065852]
	Learning Rate: 0.00658524
	LOSS [training: 0.26373728024972043 | validation: 0.32453154552159735]
	TIME [epoch: 9.09 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3191019648435979		[learning rate: 0.0065544]
	Learning Rate: 0.00655436
	LOSS [training: 0.3191019648435979 | validation: 0.38251837469885525]
	TIME [epoch: 9.1 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6023860398877822		[learning rate: 0.0065236]
	Learning Rate: 0.00652364
	LOSS [training: 0.6023860398877822 | validation: 0.5452482575445534]
	TIME [epoch: 9.1 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/10] avg loss: 0.428822196036866		[learning rate: 0.0064931]
	Learning Rate: 0.00649305
	LOSS [training: 0.428822196036866 | validation: 0.32778668915838216]
	TIME [epoch: 9.1 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29694790472742855		[learning rate: 0.0064626]
	Learning Rate: 0.00646261
	LOSS [training: 0.29694790472742855 | validation: 0.2608068783588995]
	TIME [epoch: 9.09 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2606670722467662		[learning rate: 0.0064323]
	Learning Rate: 0.00643232
	LOSS [training: 0.2606670722467662 | validation: 0.26248746695181324]
	TIME [epoch: 9.1 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5143741443786627		[learning rate: 0.0064022]
	Learning Rate: 0.00640216
	LOSS [training: 0.5143741443786627 | validation: 0.3126692590974442]
	TIME [epoch: 9.1 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3910844283629461		[learning rate: 0.0063721]
	Learning Rate: 0.00637215
	LOSS [training: 0.3910844283629461 | validation: 0.3670617842877485]
	TIME [epoch: 9.11 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29381241492888527		[learning rate: 0.0063423]
	Learning Rate: 0.00634227
	LOSS [training: 0.29381241492888527 | validation: 0.2962573256041897]
	TIME [epoch: 9.12 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2801793482363147		[learning rate: 0.0063125]
	Learning Rate: 0.00631254
	LOSS [training: 0.2801793482363147 | validation: 0.18605070906764698]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_108.pth
	Model improved!!!
EPOCH 109/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3321990139682875		[learning rate: 0.0062829]
	Learning Rate: 0.00628295
	LOSS [training: 0.3321990139682875 | validation: 0.26545076707789556]
	TIME [epoch: 9.07 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29649137284609045		[learning rate: 0.0062535]
	Learning Rate: 0.00625349
	LOSS [training: 0.29649137284609045 | validation: 0.5141152951009378]
	TIME [epoch: 9.06 sec]
EPOCH 111/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35032012295981685		[learning rate: 0.0062242]
	Learning Rate: 0.00622417
	LOSS [training: 0.35032012295981685 | validation: 0.37294388321550087]
	TIME [epoch: 9.07 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25729678248189713		[learning rate: 0.006195]
	Learning Rate: 0.00619499
	LOSS [training: 0.25729678248189713 | validation: 0.295056485057991]
	TIME [epoch: 9.05 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2788186578826055		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 0.2788186578826055 | validation: 0.3855421830576117]
	TIME [epoch: 9.08 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2764634707765543		[learning rate: 0.006137]
	Learning Rate: 0.00613704
	LOSS [training: 0.2764634707765543 | validation: 0.25916283517706695]
	TIME [epoch: 9.1 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35918126979977905		[learning rate: 0.0061083]
	Learning Rate: 0.00610827
	LOSS [training: 0.35918126979977905 | validation: 0.360088606571921]
	TIME [epoch: 9.11 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28196760105328833		[learning rate: 0.0060796]
	Learning Rate: 0.00607964
	LOSS [training: 0.28196760105328833 | validation: 0.32190918154205117]
	TIME [epoch: 9.06 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2611473910378769		[learning rate: 0.0060511]
	Learning Rate: 0.00605113
	LOSS [training: 0.2611473910378769 | validation: 0.19462679375808417]
	TIME [epoch: 9.08 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23690140669013263		[learning rate: 0.0060228]
	Learning Rate: 0.00602276
	LOSS [training: 0.23690140669013263 | validation: 0.2587400217952203]
	TIME [epoch: 9.1 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3320309070329585		[learning rate: 0.0059945]
	Learning Rate: 0.00599453
	LOSS [training: 0.3320309070329585 | validation: 0.34119483482720087]
	TIME [epoch: 9.1 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3817862730944993		[learning rate: 0.0059664]
	Learning Rate: 0.00596643
	LOSS [training: 0.3817862730944993 | validation: 0.3053122585429792]
	TIME [epoch: 9.1 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31154575887065417		[learning rate: 0.0059385]
	Learning Rate: 0.00593845
	LOSS [training: 0.31154575887065417 | validation: 0.3266266534580477]
	TIME [epoch: 9.09 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3223929242378053		[learning rate: 0.0059106]
	Learning Rate: 0.00591061
	LOSS [training: 0.3223929242378053 | validation: 0.3323560909424473]
	TIME [epoch: 9.11 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29370888081122387		[learning rate: 0.0058829]
	Learning Rate: 0.0058829
	LOSS [training: 0.29370888081122387 | validation: 0.3942948575033404]
	TIME [epoch: 9.08 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34585125798893906		[learning rate: 0.0058553]
	Learning Rate: 0.00585532
	LOSS [training: 0.34585125798893906 | validation: 0.32874037027638403]
	TIME [epoch: 9.1 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3146698420571892		[learning rate: 0.0058279]
	Learning Rate: 0.00582787
	LOSS [training: 0.3146698420571892 | validation: 0.2890518366374282]
	TIME [epoch: 9.1 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2690115378064985		[learning rate: 0.0058006]
	Learning Rate: 0.00580055
	LOSS [training: 0.2690115378064985 | validation: 0.2445407348928349]
	TIME [epoch: 9.11 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2541702331709544		[learning rate: 0.0057734]
	Learning Rate: 0.00577336
	LOSS [training: 0.2541702331709544 | validation: 0.33095179350860493]
	TIME [epoch: 9.1 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25352659471217953		[learning rate: 0.0057463]
	Learning Rate: 0.00574629
	LOSS [training: 0.25352659471217953 | validation: 0.569477953734622]
	TIME [epoch: 9.1 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3681802883384907		[learning rate: 0.0057194]
	Learning Rate: 0.00571935
	LOSS [training: 0.3681802883384907 | validation: 0.4652128994778939]
	TIME [epoch: 9.11 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/10] avg loss: 0.336430284242285		[learning rate: 0.0056925]
	Learning Rate: 0.00569254
	LOSS [training: 0.336430284242285 | validation: 0.2547230292062809]
	TIME [epoch: 9.09 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/10] avg loss: 0.44741863948445976		[learning rate: 0.0056659]
	Learning Rate: 0.00566585
	LOSS [training: 0.44741863948445976 | validation: 0.4101741350850645]
	TIME [epoch: 9.1 sec]
EPOCH 132/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33046039680249323		[learning rate: 0.0056393]
	Learning Rate: 0.00563929
	LOSS [training: 0.33046039680249323 | validation: 0.2612031400417276]
	TIME [epoch: 9.1 sec]
EPOCH 133/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26535574697084596		[learning rate: 0.0056129]
	Learning Rate: 0.00561285
	LOSS [training: 0.26535574697084596 | validation: 0.33675533391388024]
	TIME [epoch: 9.08 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32326336273806905		[learning rate: 0.0055865]
	Learning Rate: 0.00558654
	LOSS [training: 0.32326336273806905 | validation: 0.4152779838728603]
	TIME [epoch: 9.14 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30289466195834175		[learning rate: 0.0055603]
	Learning Rate: 0.00556035
	LOSS [training: 0.30289466195834175 | validation: 0.3467328383256956]
	TIME [epoch: 9.11 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3253630193024539		[learning rate: 0.0055343]
	Learning Rate: 0.00553428
	LOSS [training: 0.3253630193024539 | validation: 0.29862708211745204]
	TIME [epoch: 9.1 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2792774361971566		[learning rate: 0.0055083]
	Learning Rate: 0.00550834
	LOSS [training: 0.2792774361971566 | validation: 0.2782775703374414]
	TIME [epoch: 9.09 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5487202252806161		[learning rate: 0.0054825]
	Learning Rate: 0.00548251
	LOSS [training: 0.5487202252806161 | validation: 0.42732721654182504]
	TIME [epoch: 9.1 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3172505931086373		[learning rate: 0.0054568]
	Learning Rate: 0.00545681
	LOSS [training: 0.3172505931086373 | validation: 0.30961510341128395]
	TIME [epoch: 9.12 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2917273184060328		[learning rate: 0.0054312]
	Learning Rate: 0.00543123
	LOSS [training: 0.2917273184060328 | validation: 0.8682537868030258]
	TIME [epoch: 9.12 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3942192086399791		[learning rate: 0.0054058]
	Learning Rate: 0.00540576
	LOSS [training: 0.3942192086399791 | validation: 0.25700402503254133]
	TIME [epoch: 9.09 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2127269200704792		[learning rate: 0.0053804]
	Learning Rate: 0.00538042
	LOSS [training: 0.2127269200704792 | validation: 0.2563597665970657]
	TIME [epoch: 9.1 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28211447697213865		[learning rate: 0.0053552]
	Learning Rate: 0.0053552
	LOSS [training: 0.28211447697213865 | validation: 0.20302590038126628]
	TIME [epoch: 9.09 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24422583771703393		[learning rate: 0.0053301]
	Learning Rate: 0.00533009
	LOSS [training: 0.24422583771703393 | validation: 0.2230830435680542]
	TIME [epoch: 9.12 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24823351293877063		[learning rate: 0.0053051]
	Learning Rate: 0.0053051
	LOSS [training: 0.24823351293877063 | validation: 0.2230108681309756]
	TIME [epoch: 9.08 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2770259613570464		[learning rate: 0.0052802]
	Learning Rate: 0.00528023
	LOSS [training: 0.2770259613570464 | validation: 0.3196947483967628]
	TIME [epoch: 9.1 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2226500590013878		[learning rate: 0.0052555]
	Learning Rate: 0.00525548
	LOSS [training: 0.2226500590013878 | validation: 0.23951694803608053]
	TIME [epoch: 9.07 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22772698160486016		[learning rate: 0.0052308]
	Learning Rate: 0.00523084
	LOSS [training: 0.22772698160486016 | validation: 0.4849132268565417]
	TIME [epoch: 9.08 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33091678301835514		[learning rate: 0.0052063]
	Learning Rate: 0.00520632
	LOSS [training: 0.33091678301835514 | validation: 0.3185323320458245]
	TIME [epoch: 9.09 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2817254076020402		[learning rate: 0.0051819]
	Learning Rate: 0.00518191
	LOSS [training: 0.2817254076020402 | validation: 0.22427909638637566]
	TIME [epoch: 9.08 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27197547774829073		[learning rate: 0.0051576]
	Learning Rate: 0.00515762
	LOSS [training: 0.27197547774829073 | validation: 0.3171997379556434]
	TIME [epoch: 9.07 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33700196011748573		[learning rate: 0.0051334]
	Learning Rate: 0.00513344
	LOSS [training: 0.33700196011748573 | validation: 0.321625938922389]
	TIME [epoch: 9.07 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30215712944480033		[learning rate: 0.0051094]
	Learning Rate: 0.00510937
	LOSS [training: 0.30215712944480033 | validation: 0.2736662024373679]
	TIME [epoch: 9.08 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21396248431351977		[learning rate: 0.0050854]
	Learning Rate: 0.00508542
	LOSS [training: 0.21396248431351977 | validation: 0.19910707675984646]
	TIME [epoch: 9.08 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24907341518164325		[learning rate: 0.0050616]
	Learning Rate: 0.00506158
	LOSS [training: 0.24907341518164325 | validation: 0.2598403906765232]
	TIME [epoch: 9.08 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24599729436765339		[learning rate: 0.0050378]
	Learning Rate: 0.00503785
	LOSS [training: 0.24599729436765339 | validation: 0.283678104084356]
	TIME [epoch: 9.07 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2630376336718362		[learning rate: 0.0050142]
	Learning Rate: 0.00501423
	LOSS [training: 0.2630376336718362 | validation: 0.34953194626599804]
	TIME [epoch: 9.06 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2568668480406441		[learning rate: 0.0049907]
	Learning Rate: 0.00499072
	LOSS [training: 0.2568668480406441 | validation: 0.2593597695489655]
	TIME [epoch: 9.06 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2973094659984782		[learning rate: 0.0049673]
	Learning Rate: 0.00496732
	LOSS [training: 0.2973094659984782 | validation: 0.2810038022016664]
	TIME [epoch: 9.11 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26143160179388264		[learning rate: 0.004944]
	Learning Rate: 0.00494404
	LOSS [training: 0.26143160179388264 | validation: 0.19474748203763015]
	TIME [epoch: 9.07 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1851172628665108		[learning rate: 0.0049209]
	Learning Rate: 0.00492086
	LOSS [training: 0.1851172628665108 | validation: 0.20088469115454005]
	TIME [epoch: 9.08 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19318210205385222		[learning rate: 0.0048978]
	Learning Rate: 0.00489779
	LOSS [training: 0.19318210205385222 | validation: 0.32282860482211995]
	TIME [epoch: 9.1 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23976331491023956		[learning rate: 0.0048748]
	Learning Rate: 0.00487483
	LOSS [training: 0.23976331491023956 | validation: 0.295713192231975]
	TIME [epoch: 9.06 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18954561712828227		[learning rate: 0.004852]
	Learning Rate: 0.00485197
	LOSS [training: 0.18954561712828227 | validation: 0.310383064051601]
	TIME [epoch: 9.08 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2558091007299523		[learning rate: 0.0048292]
	Learning Rate: 0.00482923
	LOSS [training: 0.2558091007299523 | validation: 0.26998043511536796]
	TIME [epoch: 9.06 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19691970625497598		[learning rate: 0.0048066]
	Learning Rate: 0.00480659
	LOSS [training: 0.19691970625497598 | validation: 0.23560150862543047]
	TIME [epoch: 9.07 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1952500100847137		[learning rate: 0.0047841]
	Learning Rate: 0.00478405
	LOSS [training: 0.1952500100847137 | validation: 0.2630832054812283]
	TIME [epoch: 9.06 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15128252024250435		[learning rate: 0.0047616]
	Learning Rate: 0.00476162
	LOSS [training: 0.15128252024250435 | validation: 0.16044032274909378]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_168.pth
	Model improved!!!
EPOCH 169/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1799065556508781		[learning rate: 0.0047393]
	Learning Rate: 0.0047393
	LOSS [training: 0.1799065556508781 | validation: 0.2514494569810244]
	TIME [epoch: 9.09 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2549125662488231		[learning rate: 0.0047171]
	Learning Rate: 0.00471708
	LOSS [training: 0.2549125662488231 | validation: 0.1631094011435456]
	TIME [epoch: 9.09 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17028149396188183		[learning rate: 0.004695]
	Learning Rate: 0.00469497
	LOSS [training: 0.17028149396188183 | validation: 0.2595058699614948]
	TIME [epoch: 9.09 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31697720418782394		[learning rate: 0.004673]
	Learning Rate: 0.00467296
	LOSS [training: 0.31697720418782394 | validation: 0.2782127089547146]
	TIME [epoch: 9.09 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26411491569443485		[learning rate: 0.0046511]
	Learning Rate: 0.00465105
	LOSS [training: 0.26411491569443485 | validation: 0.24282133372550685]
	TIME [epoch: 9.08 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21150450235459894		[learning rate: 0.0046292]
	Learning Rate: 0.00462925
	LOSS [training: 0.21150450235459894 | validation: 0.2568189102629851]
	TIME [epoch: 9.1 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1941181088461932		[learning rate: 0.0046075]
	Learning Rate: 0.00460754
	LOSS [training: 0.1941181088461932 | validation: 0.4897571784703537]
	TIME [epoch: 9.09 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29365860422201523		[learning rate: 0.0045859]
	Learning Rate: 0.00458594
	LOSS [training: 0.29365860422201523 | validation: 0.10053646079714071]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_176.pth
	Model improved!!!
EPOCH 177/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1904529799115871		[learning rate: 0.0045644]
	Learning Rate: 0.00456444
	LOSS [training: 0.1904529799115871 | validation: 0.20499933993323116]
	TIME [epoch: 9.11 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18181158940240655		[learning rate: 0.004543]
	Learning Rate: 0.00454304
	LOSS [training: 0.18181158940240655 | validation: 0.4206946333830922]
	TIME [epoch: 9.09 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19168360253621464		[learning rate: 0.0045217]
	Learning Rate: 0.00452175
	LOSS [training: 0.19168360253621464 | validation: 0.16731870292375672]
	TIME [epoch: 9.11 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16849606549633123		[learning rate: 0.0045005]
	Learning Rate: 0.00450055
	LOSS [training: 0.16849606549633123 | validation: 0.12628983273415872]
	TIME [epoch: 9.09 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2427937531805952		[learning rate: 0.0044794]
	Learning Rate: 0.00447945
	LOSS [training: 0.2427937531805952 | validation: 0.23190298512276752]
	TIME [epoch: 9.11 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17491656525875268		[learning rate: 0.0044584]
	Learning Rate: 0.00445845
	LOSS [training: 0.17491656525875268 | validation: 0.17255871768791625]
	TIME [epoch: 9.09 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19142906938446053		[learning rate: 0.0044375]
	Learning Rate: 0.00443755
	LOSS [training: 0.19142906938446053 | validation: 0.19156042195600426]
	TIME [epoch: 9.09 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25494733808015313		[learning rate: 0.0044167]
	Learning Rate: 0.00441674
	LOSS [training: 0.25494733808015313 | validation: 0.2401213141148519]
	TIME [epoch: 9.13 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1695344082769336		[learning rate: 0.004396]
	Learning Rate: 0.00439604
	LOSS [training: 0.1695344082769336 | validation: 0.15525251052280115]
	TIME [epoch: 9.12 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1832219514346666		[learning rate: 0.0043754]
	Learning Rate: 0.00437543
	LOSS [training: 0.1832219514346666 | validation: 0.2641447454814005]
	TIME [epoch: 9.08 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2363130789001934		[learning rate: 0.0043549]
	Learning Rate: 0.00435491
	LOSS [training: 0.2363130789001934 | validation: 0.24006992082673814]
	TIME [epoch: 9.08 sec]
EPOCH 188/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2650491086884574		[learning rate: 0.0043345]
	Learning Rate: 0.0043345
	LOSS [training: 0.2650491086884574 | validation: 0.20796644083952268]
	TIME [epoch: 9.08 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2229407607247457		[learning rate: 0.0043142]
	Learning Rate: 0.00431418
	LOSS [training: 0.2229407607247457 | validation: 0.22021396090020523]
	TIME [epoch: 9.1 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2259706420832555		[learning rate: 0.004294]
	Learning Rate: 0.00429395
	LOSS [training: 0.2259706420832555 | validation: 0.2101715503832559]
	TIME [epoch: 9.08 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21475530090471268		[learning rate: 0.0042738]
	Learning Rate: 0.00427382
	LOSS [training: 0.21475530090471268 | validation: 0.2844798080470664]
	TIME [epoch: 9.08 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1882356544804357		[learning rate: 0.0042538]
	Learning Rate: 0.00425378
	LOSS [training: 0.1882356544804357 | validation: 0.1456817414132191]
	TIME [epoch: 9.09 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18216935666636538		[learning rate: 0.0042338]
	Learning Rate: 0.00423384
	LOSS [training: 0.18216935666636538 | validation: 0.1997350737114549]
	TIME [epoch: 9.1 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17456602215454015		[learning rate: 0.004214]
	Learning Rate: 0.00421399
	LOSS [training: 0.17456602215454015 | validation: 0.27564148530838245]
	TIME [epoch: 9.11 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21263317681186425		[learning rate: 0.0041942]
	Learning Rate: 0.00419424
	LOSS [training: 0.21263317681186425 | validation: 0.11783908258689342]
	TIME [epoch: 9.09 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15749414423303223		[learning rate: 0.0041746]
	Learning Rate: 0.00417457
	LOSS [training: 0.15749414423303223 | validation: 0.19570412876781457]
	TIME [epoch: 9.09 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16989145659267452		[learning rate: 0.004155]
	Learning Rate: 0.004155
	LOSS [training: 0.16989145659267452 | validation: 0.20752538829222833]
	TIME [epoch: 9.08 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20664367888257812		[learning rate: 0.0041355]
	Learning Rate: 0.00413552
	LOSS [training: 0.20664367888257812 | validation: 0.17513013147906104]
	TIME [epoch: 9.1 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22046549840924073		[learning rate: 0.0041161]
	Learning Rate: 0.00411614
	LOSS [training: 0.22046549840924073 | validation: 0.29223338299341983]
	TIME [epoch: 9.12 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2270148871129903		[learning rate: 0.0040968]
	Learning Rate: 0.00409684
	LOSS [training: 0.2270148871129903 | validation: 0.13291910815540373]
	TIME [epoch: 9.1 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14243734920338352		[learning rate: 0.0040776]
	Learning Rate: 0.00407763
	LOSS [training: 0.14243734920338352 | validation: 0.15879292963679337]
	TIME [epoch: 9.1 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19353940671247488		[learning rate: 0.0040585]
	Learning Rate: 0.00405852
	LOSS [training: 0.19353940671247488 | validation: 0.45309760362084306]
	TIME [epoch: 9.12 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29609755093645185		[learning rate: 0.0040395]
	Learning Rate: 0.00403949
	LOSS [training: 0.29609755093645185 | validation: 0.19367108232707164]
	TIME [epoch: 9.11 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25382302888590985		[learning rate: 0.0040206]
	Learning Rate: 0.00402055
	LOSS [training: 0.25382302888590985 | validation: 0.3515954374228008]
	TIME [epoch: 9.13 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34870240972177685		[learning rate: 0.0040017]
	Learning Rate: 0.0040017
	LOSS [training: 0.34870240972177685 | validation: 0.29220760800727974]
	TIME [epoch: 9.11 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32033397043205036		[learning rate: 0.0039829]
	Learning Rate: 0.00398294
	LOSS [training: 0.32033397043205036 | validation: 0.22114619136057026]
	TIME [epoch: 9.1 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1974580716884659		[learning rate: 0.0039643]
	Learning Rate: 0.00396427
	LOSS [training: 0.1974580716884659 | validation: 0.17072279792216966]
	TIME [epoch: 9.11 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2428028097200996		[learning rate: 0.0039457]
	Learning Rate: 0.00394569
	LOSS [training: 0.2428028097200996 | validation: 0.16547084533686812]
	TIME [epoch: 9.09 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2454354031621419		[learning rate: 0.0039272]
	Learning Rate: 0.00392719
	LOSS [training: 0.2454354031621419 | validation: 0.25593745039622307]
	TIME [epoch: 9.11 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17086069324871175		[learning rate: 0.0039088]
	Learning Rate: 0.00390878
	LOSS [training: 0.17086069324871175 | validation: 0.20390185374155229]
	TIME [epoch: 9.09 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16299402797403847		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.16299402797403847 | validation: 0.24034583619481104]
	TIME [epoch: 9.1 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28374252078973167		[learning rate: 0.0038722]
	Learning Rate: 0.00387221
	LOSS [training: 0.28374252078973167 | validation: 0.27438557975310895]
	TIME [epoch: 9.09 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21938125587211257		[learning rate: 0.0038541]
	Learning Rate: 0.00385406
	LOSS [training: 0.21938125587211257 | validation: 0.25230939821416654]
	TIME [epoch: 9.1 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/10] avg loss: 0.230429838999917		[learning rate: 0.003836]
	Learning Rate: 0.00383599
	LOSS [training: 0.230429838999917 | validation: 0.18403419809934024]
	TIME [epoch: 9.12 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2630400800867507		[learning rate: 0.003818]
	Learning Rate: 0.00381801
	LOSS [training: 0.2630400800867507 | validation: 0.2533281730598666]
	TIME [epoch: 9.09 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2266111219706389		[learning rate: 0.0038001]
	Learning Rate: 0.00380011
	LOSS [training: 0.2266111219706389 | validation: 0.23176785937703795]
	TIME [epoch: 9.1 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2039681591444355		[learning rate: 0.0037823]
	Learning Rate: 0.00378229
	LOSS [training: 0.2039681591444355 | validation: 0.18742081427348473]
	TIME [epoch: 9.12 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22618676212532937		[learning rate: 0.0037646]
	Learning Rate: 0.00376456
	LOSS [training: 0.22618676212532937 | validation: 0.18954914492495117]
	TIME [epoch: 9.1 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17328893259439687		[learning rate: 0.0037469]
	Learning Rate: 0.00374691
	LOSS [training: 0.17328893259439687 | validation: 0.290661547912811]
	TIME [epoch: 9.12 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17529756076397196		[learning rate: 0.0037293]
	Learning Rate: 0.00372935
	LOSS [training: 0.17529756076397196 | validation: 0.27545786611898726]
	TIME [epoch: 9.11 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18103058503599231		[learning rate: 0.0037119]
	Learning Rate: 0.00371186
	LOSS [training: 0.18103058503599231 | validation: 0.32721951031303576]
	TIME [epoch: 9.09 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23947018749034096		[learning rate: 0.0036945]
	Learning Rate: 0.00369446
	LOSS [training: 0.23947018749034096 | validation: 0.2889149387858561]
	TIME [epoch: 9.1 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23026330005324228		[learning rate: 0.0036771]
	Learning Rate: 0.00367714
	LOSS [training: 0.23026330005324228 | validation: 0.3658444699529563]
	TIME [epoch: 9.09 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2320222732315186		[learning rate: 0.0036599]
	Learning Rate: 0.0036599
	LOSS [training: 0.2320222732315186 | validation: 0.28379033531222553]
	TIME [epoch: 9.13 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14504517986366866		[learning rate: 0.0036427]
	Learning Rate: 0.00364274
	LOSS [training: 0.14504517986366866 | validation: 0.16528931126649804]
	TIME [epoch: 9.1 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20362474957601723		[learning rate: 0.0036257]
	Learning Rate: 0.00362567
	LOSS [training: 0.20362474957601723 | validation: 0.2437558622337979]
	TIME [epoch: 9.12 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16200260257899987		[learning rate: 0.0036087]
	Learning Rate: 0.00360867
	LOSS [training: 0.16200260257899987 | validation: 0.17496591239108272]
	TIME [epoch: 9.1 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17038950419053736		[learning rate: 0.0035918]
	Learning Rate: 0.00359175
	LOSS [training: 0.17038950419053736 | validation: 0.20688046187283538]
	TIME [epoch: 9.1 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18137814857345763		[learning rate: 0.0035749]
	Learning Rate: 0.00357491
	LOSS [training: 0.18137814857345763 | validation: 0.15328708959841847]
	TIME [epoch: 9.1 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11190415110557043		[learning rate: 0.0035582]
	Learning Rate: 0.00355815
	LOSS [training: 0.11190415110557043 | validation: 0.1595365085274955]
	TIME [epoch: 9.09 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12947048976646192		[learning rate: 0.0035415]
	Learning Rate: 0.00354147
	LOSS [training: 0.12947048976646192 | validation: 0.1394979300019079]
	TIME [epoch: 9.08 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16362832831093205		[learning rate: 0.0035249]
	Learning Rate: 0.00352487
	LOSS [training: 0.16362832831093205 | validation: 0.2511860391067037]
	TIME [epoch: 9.07 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1573734845107128		[learning rate: 0.0035083]
	Learning Rate: 0.00350834
	LOSS [training: 0.1573734845107128 | validation: 0.12071503308192655]
	TIME [epoch: 9.09 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11692921758648603		[learning rate: 0.0034919]
	Learning Rate: 0.0034919
	LOSS [training: 0.11692921758648603 | validation: 0.14054954079912546]
	TIME [epoch: 9.1 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12671546383732374		[learning rate: 0.0034755]
	Learning Rate: 0.00347552
	LOSS [training: 0.12671546383732374 | validation: 0.17598908301736058]
	TIME [epoch: 9.09 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12405831189320662		[learning rate: 0.0034592]
	Learning Rate: 0.00345923
	LOSS [training: 0.12405831189320662 | validation: 0.17328659446107247]
	TIME [epoch: 9.1 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13537202153801264		[learning rate: 0.003443]
	Learning Rate: 0.00344301
	LOSS [training: 0.13537202153801264 | validation: 0.11596637284741931]
	TIME [epoch: 9.09 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13671241305498813		[learning rate: 0.0034269]
	Learning Rate: 0.00342687
	LOSS [training: 0.13671241305498813 | validation: 0.36189288459404567]
	TIME [epoch: 9.09 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19117576752667162		[learning rate: 0.0034108]
	Learning Rate: 0.00341081
	LOSS [training: 0.19117576752667162 | validation: 0.16522627617417912]
	TIME [epoch: 9.12 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13758768878353794		[learning rate: 0.0033948]
	Learning Rate: 0.00339482
	LOSS [training: 0.13758768878353794 | validation: 0.1506490349110639]
	TIME [epoch: 9.1 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10297324012373617		[learning rate: 0.0033789]
	Learning Rate: 0.0033789
	LOSS [training: 0.10297324012373617 | validation: 0.15555051842821901]
	TIME [epoch: 9.08 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14554095167758135		[learning rate: 0.0033631]
	Learning Rate: 0.00336306
	LOSS [training: 0.14554095167758135 | validation: 0.1452499627197881]
	TIME [epoch: 9.11 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12294787909641332		[learning rate: 0.0033473]
	Learning Rate: 0.00334729
	LOSS [training: 0.12294787909641332 | validation: 0.13732955907906746]
	TIME [epoch: 9.11 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1663151400061973		[learning rate: 0.0033316]
	Learning Rate: 0.0033316
	LOSS [training: 0.1663151400061973 | validation: 0.24430451830687447]
	TIME [epoch: 9.11 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1950391750152219		[learning rate: 0.003316]
	Learning Rate: 0.00331598
	LOSS [training: 0.1950391750152219 | validation: 0.17082217789036203]
	TIME [epoch: 9.09 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14854052443737492		[learning rate: 0.0033004]
	Learning Rate: 0.00330044
	LOSS [training: 0.14854052443737492 | validation: 0.199328468748944]
	TIME [epoch: 9.09 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20420666413474273		[learning rate: 0.003285]
	Learning Rate: 0.00328496
	LOSS [training: 0.20420666413474273 | validation: 0.14269125501894048]
	TIME [epoch: 9.1 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10977761324406414		[learning rate: 0.0032696]
	Learning Rate: 0.00326956
	LOSS [training: 0.10977761324406414 | validation: 0.15800308807801175]
	TIME [epoch: 9.11 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17761925293338998		[learning rate: 0.0032542]
	Learning Rate: 0.00325424
	LOSS [training: 0.17761925293338998 | validation: 0.12865582425960742]
	TIME [epoch: 9.12 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11624531096522266		[learning rate: 0.003239]
	Learning Rate: 0.00323898
	LOSS [training: 0.11624531096522266 | validation: 0.09669152173323387]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_250.pth
	Model improved!!!
EPOCH 251/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08959498654417272		[learning rate: 0.0032238]
	Learning Rate: 0.00322379
	LOSS [training: 0.08959498654417272 | validation: 0.08091502710337944]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_251.pth
	Model improved!!!
EPOCH 252/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10949856545189211		[learning rate: 0.0032087]
	Learning Rate: 0.00320868
	LOSS [training: 0.10949856545189211 | validation: 0.1376157166077277]
	TIME [epoch: 9.11 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1266551906606292		[learning rate: 0.0031936]
	Learning Rate: 0.00319364
	LOSS [training: 0.1266551906606292 | validation: 0.16622339227920352]
	TIME [epoch: 9.12 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11612986304445783		[learning rate: 0.0031787]
	Learning Rate: 0.00317867
	LOSS [training: 0.11612986304445783 | validation: 0.1088542574637442]
	TIME [epoch: 9.13 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14570118906167245		[learning rate: 0.0031638]
	Learning Rate: 0.00316376
	LOSS [training: 0.14570118906167245 | validation: 0.31865556608802226]
	TIME [epoch: 9.12 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1988193661437504		[learning rate: 0.0031489]
	Learning Rate: 0.00314893
	LOSS [training: 0.1988193661437504 | validation: 0.16074437058712157]
	TIME [epoch: 9.11 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13070878100364453		[learning rate: 0.0031342]
	Learning Rate: 0.00313417
	LOSS [training: 0.13070878100364453 | validation: 0.4605539952799772]
	TIME [epoch: 9.11 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1711274589214027		[learning rate: 0.0031195]
	Learning Rate: 0.00311948
	LOSS [training: 0.1711274589214027 | validation: 0.08936081382400962]
	TIME [epoch: 9.13 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09814225758185176		[learning rate: 0.0031049]
	Learning Rate: 0.00310485
	LOSS [training: 0.09814225758185176 | validation: 0.48912945590374235]
	TIME [epoch: 9.13 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21938925788075442		[learning rate: 0.0030903]
	Learning Rate: 0.0030903
	LOSS [training: 0.21938925788075442 | validation: 0.22170327396008144]
	TIME [epoch: 9.12 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13584932014878023		[learning rate: 0.0030758]
	Learning Rate: 0.00307581
	LOSS [training: 0.13584932014878023 | validation: 0.11001964886408584]
	TIME [epoch: 9.11 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13152464890073906		[learning rate: 0.0030614]
	Learning Rate: 0.00306139
	LOSS [training: 0.13152464890073906 | validation: 0.2870893719970201]
	TIME [epoch: 9.1 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16651626778737214		[learning rate: 0.003047]
	Learning Rate: 0.00304704
	LOSS [training: 0.16651626778737214 | validation: 0.12233603857204375]
	TIME [epoch: 9.13 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09599744140510172		[learning rate: 0.0030328]
	Learning Rate: 0.00303275
	LOSS [training: 0.09599744140510172 | validation: 0.1954921168570562]
	TIME [epoch: 9.14 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18132551717572115		[learning rate: 0.0030185]
	Learning Rate: 0.00301853
	LOSS [training: 0.18132551717572115 | validation: 0.22393733588958117]
	TIME [epoch: 9.12 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14190806736253478		[learning rate: 0.0030044]
	Learning Rate: 0.00300438
	LOSS [training: 0.14190806736253478 | validation: 0.17514282797842567]
	TIME [epoch: 9.12 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11370735669876197		[learning rate: 0.0029903]
	Learning Rate: 0.0029903
	LOSS [training: 0.11370735669876197 | validation: 0.12070444155920813]
	TIME [epoch: 9.12 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1364280346629343		[learning rate: 0.0029763]
	Learning Rate: 0.00297628
	LOSS [training: 0.1364280346629343 | validation: 0.1276128283103214]
	TIME [epoch: 9.1 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14767800419603014		[learning rate: 0.0029623]
	Learning Rate: 0.00296232
	LOSS [training: 0.14767800419603014 | validation: 0.17892239281360278]
	TIME [epoch: 9.13 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15302357293690366		[learning rate: 0.0029484]
	Learning Rate: 0.00294844
	LOSS [training: 0.15302357293690366 | validation: 0.2188742829176713]
	TIME [epoch: 9.12 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14017167981221118		[learning rate: 0.0029346]
	Learning Rate: 0.00293461
	LOSS [training: 0.14017167981221118 | validation: 0.14149227130812336]
	TIME [epoch: 9.12 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/10] avg loss: 0.137566437265522		[learning rate: 0.0029209]
	Learning Rate: 0.00292086
	LOSS [training: 0.137566437265522 | validation: 0.10985041247636818]
	TIME [epoch: 9.12 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12555701049805618		[learning rate: 0.0029072]
	Learning Rate: 0.00290716
	LOSS [training: 0.12555701049805618 | validation: 0.13118969597437488]
	TIME [epoch: 9.12 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1174247681896597		[learning rate: 0.0028935]
	Learning Rate: 0.00289353
	LOSS [training: 0.1174247681896597 | validation: 0.19182147543821526]
	TIME [epoch: 9.18 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15707036950705958		[learning rate: 0.00288]
	Learning Rate: 0.00287997
	LOSS [training: 0.15707036950705958 | validation: 0.28853944146987454]
	TIME [epoch: 9.14 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10325735644865601		[learning rate: 0.0028665]
	Learning Rate: 0.00286647
	LOSS [training: 0.10325735644865601 | validation: 0.10182518898742557]
	TIME [epoch: 9.12 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13742246993719276		[learning rate: 0.002853]
	Learning Rate: 0.00285303
	LOSS [training: 0.13742246993719276 | validation: 0.09010535120767164]
	TIME [epoch: 9.12 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16099326103745773		[learning rate: 0.0028397]
	Learning Rate: 0.00283965
	LOSS [training: 0.16099326103745773 | validation: 0.12688336765766595]
	TIME [epoch: 9.13 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1292753356364067		[learning rate: 0.0028263]
	Learning Rate: 0.00282634
	LOSS [training: 0.1292753356364067 | validation: 0.23915360837228508]
	TIME [epoch: 9.16 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11438995721207554		[learning rate: 0.0028131]
	Learning Rate: 0.00281309
	LOSS [training: 0.11438995721207554 | validation: 0.22723140712381285]
	TIME [epoch: 9.14 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24971411773465518		[learning rate: 0.0027999]
	Learning Rate: 0.0027999
	LOSS [training: 0.24971411773465518 | validation: 0.20219131843621985]
	TIME [epoch: 9.13 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1586846609946076		[learning rate: 0.0027868]
	Learning Rate: 0.00278678
	LOSS [training: 0.1586846609946076 | validation: 0.10293943609977546]
	TIME [epoch: 9.13 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10771135020899139		[learning rate: 0.0027737]
	Learning Rate: 0.00277371
	LOSS [training: 0.10771135020899139 | validation: 0.09932129108385096]
	TIME [epoch: 9.12 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/10] avg loss: 0.145587852175395		[learning rate: 0.0027607]
	Learning Rate: 0.00276071
	LOSS [training: 0.145587852175395 | validation: 0.17049782230184296]
	TIME [epoch: 9.16 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16230385416850512		[learning rate: 0.0027478]
	Learning Rate: 0.00274776
	LOSS [training: 0.16230385416850512 | validation: 0.11675903102355398]
	TIME [epoch: 9.12 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1083891665495375		[learning rate: 0.0027349]
	Learning Rate: 0.00273488
	LOSS [training: 0.1083891665495375 | validation: 0.12767042489203378]
	TIME [epoch: 9.13 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10465967237101297		[learning rate: 0.0027221]
	Learning Rate: 0.00272206
	LOSS [training: 0.10465967237101297 | validation: 0.1557820146985941]
	TIME [epoch: 9.11 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1576216742823195		[learning rate: 0.0027093]
	Learning Rate: 0.0027093
	LOSS [training: 0.1576216742823195 | validation: 0.11238559297465708]
	TIME [epoch: 9.12 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12838010210815393		[learning rate: 0.0026966]
	Learning Rate: 0.0026966
	LOSS [training: 0.12838010210815393 | validation: 0.22604106571831004]
	TIME [epoch: 9.14 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/10] avg loss: 0.136431692961754		[learning rate: 0.002684]
	Learning Rate: 0.00268396
	LOSS [training: 0.136431692961754 | validation: 0.1824468270682253]
	TIME [epoch: 9.11 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15533932398890093		[learning rate: 0.0026714]
	Learning Rate: 0.00267137
	LOSS [training: 0.15533932398890093 | validation: 0.15899119833128703]
	TIME [epoch: 9.1 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14274364951304114		[learning rate: 0.0026589]
	Learning Rate: 0.00265885
	LOSS [training: 0.14274364951304114 | validation: 0.1592516019835007]
	TIME [epoch: 9.12 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11521223217025904		[learning rate: 0.0026464]
	Learning Rate: 0.00264639
	LOSS [training: 0.11521223217025904 | validation: 0.18495474221147418]
	TIME [epoch: 9.11 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/10] avg loss: 0.142548853726003		[learning rate: 0.002634]
	Learning Rate: 0.00263398
	LOSS [training: 0.142548853726003 | validation: 0.10824830650490408]
	TIME [epoch: 9.16 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12428688323250936		[learning rate: 0.0026216]
	Learning Rate: 0.00262163
	LOSS [training: 0.12428688323250936 | validation: 0.15726902073679894]
	TIME [epoch: 9.11 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12667810185629694		[learning rate: 0.0026093]
	Learning Rate: 0.00260934
	LOSS [training: 0.12667810185629694 | validation: 0.13029322337602176]
	TIME [epoch: 9.11 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09966869521897496		[learning rate: 0.0025971]
	Learning Rate: 0.00259711
	LOSS [training: 0.09966869521897496 | validation: 0.14464862049202393]
	TIME [epoch: 9.13 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12193005349961043		[learning rate: 0.0025849]
	Learning Rate: 0.00258493
	LOSS [training: 0.12193005349961043 | validation: 0.1425060602127528]
	TIME [epoch: 9.12 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/10] avg loss: 0.152587371527415		[learning rate: 0.0025728]
	Learning Rate: 0.00257281
	LOSS [training: 0.152587371527415 | validation: 0.108157173930721]
	TIME [epoch: 9.14 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17337039278314414		[learning rate: 0.0025608]
	Learning Rate: 0.00256075
	LOSS [training: 0.17337039278314414 | validation: 0.13036647976837057]
	TIME [epoch: 9.11 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13677691309414972		[learning rate: 0.0025487]
	Learning Rate: 0.00254875
	LOSS [training: 0.13677691309414972 | validation: 0.15724191239403676]
	TIME [epoch: 9.09 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13074595953110071		[learning rate: 0.0025368]
	Learning Rate: 0.0025368
	LOSS [training: 0.13074595953110071 | validation: 0.14461996181005599]
	TIME [epoch: 9.12 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10420796205745497		[learning rate: 0.0025249]
	Learning Rate: 0.0025249
	LOSS [training: 0.10420796205745497 | validation: 0.1153595726388475]
	TIME [epoch: 9.11 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1258327409265009		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.1258327409265009 | validation: 0.2557631627174135]
	TIME [epoch: 9.14 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32066270041741507		[learning rate: 0.0025013]
	Learning Rate: 0.00250129
	LOSS [training: 0.32066270041741507 | validation: 0.1763803801712634]
	TIME [epoch: 9.1 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1112314220850837		[learning rate: 0.0024896]
	Learning Rate: 0.00248956
	LOSS [training: 0.1112314220850837 | validation: 0.1103089276761596]
	TIME [epoch: 9.11 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11438368963788678		[learning rate: 0.0024779]
	Learning Rate: 0.00247789
	LOSS [training: 0.11438368963788678 | validation: 0.18901433120707611]
	TIME [epoch: 9.11 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11880979148351165		[learning rate: 0.0024663]
	Learning Rate: 0.00246627
	LOSS [training: 0.11880979148351165 | validation: 0.22358190672566403]
	TIME [epoch: 9.12 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10444570979390902		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.10444570979390902 | validation: 0.1557531088892164]
	TIME [epoch: 9.14 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1139266044284986		[learning rate: 0.0024432]
	Learning Rate: 0.0024432
	LOSS [training: 0.1139266044284986 | validation: 0.10165030119226276]
	TIME [epoch: 9.13 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0925061241884999		[learning rate: 0.0024317]
	Learning Rate: 0.00243175
	LOSS [training: 0.0925061241884999 | validation: 0.2483706774569896]
	TIME [epoch: 9.12 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1413269739837653		[learning rate: 0.0024203]
	Learning Rate: 0.00242035
	LOSS [training: 0.1413269739837653 | validation: 0.1501533140529398]
	TIME [epoch: 9.13 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12241041940415516		[learning rate: 0.002409]
	Learning Rate: 0.002409
	LOSS [training: 0.12241041940415516 | validation: 0.1120521896773286]
	TIME [epoch: 9.12 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10243229334798602		[learning rate: 0.0023977]
	Learning Rate: 0.00239771
	LOSS [training: 0.10243229334798602 | validation: 0.08876908309047044]
	TIME [epoch: 9.16 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10492233537912063		[learning rate: 0.0023865]
	Learning Rate: 0.00238647
	LOSS [training: 0.10492233537912063 | validation: 0.11303278127201453]
	TIME [epoch: 9.11 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10156912564184084		[learning rate: 0.0023753]
	Learning Rate: 0.00237528
	LOSS [training: 0.10156912564184084 | validation: 0.09301563505388334]
	TIME [epoch: 9.11 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10333229084180813		[learning rate: 0.0023641]
	Learning Rate: 0.00236414
	LOSS [training: 0.10333229084180813 | validation: 0.0742004761658683]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_317.pth
	Model improved!!!
EPOCH 318/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0838418789085884		[learning rate: 0.0023531]
	Learning Rate: 0.00235306
	LOSS [training: 0.0838418789085884 | validation: 0.14721933345217614]
	TIME [epoch: 9.09 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09257786629979949		[learning rate: 0.002342]
	Learning Rate: 0.00234203
	LOSS [training: 0.09257786629979949 | validation: 0.10660289074494103]
	TIME [epoch: 9.13 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10797793439791478		[learning rate: 0.002331]
	Learning Rate: 0.00233105
	LOSS [training: 0.10797793439791478 | validation: 0.16943690666180217]
	TIME [epoch: 9.11 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13547719681961465		[learning rate: 0.0023201]
	Learning Rate: 0.00232012
	LOSS [training: 0.13547719681961465 | validation: 0.1564437062203739]
	TIME [epoch: 9.11 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12204649615164635		[learning rate: 0.0023092]
	Learning Rate: 0.00230924
	LOSS [training: 0.12204649615164635 | validation: 0.10898498829905819]
	TIME [epoch: 9.1 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09332517829551237		[learning rate: 0.0022984]
	Learning Rate: 0.00229842
	LOSS [training: 0.09332517829551237 | validation: 0.2050361959862631]
	TIME [epoch: 9.12 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12456090986370257		[learning rate: 0.0022876]
	Learning Rate: 0.00228764
	LOSS [training: 0.12456090986370257 | validation: 0.11979844794678818]
	TIME [epoch: 9.13 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10004481003965504		[learning rate: 0.0022769]
	Learning Rate: 0.00227692
	LOSS [training: 0.10004481003965504 | validation: 0.09891883856422665]
	TIME [epoch: 9.1 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11778125885476884		[learning rate: 0.0022662]
	Learning Rate: 0.00226624
	LOSS [training: 0.11778125885476884 | validation: 0.13884973386620977]
	TIME [epoch: 9.11 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09415468465385038		[learning rate: 0.0022556]
	Learning Rate: 0.00225562
	LOSS [training: 0.09415468465385038 | validation: 0.12230923640806146]
	TIME [epoch: 9.13 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11241313960234571		[learning rate: 0.002245]
	Learning Rate: 0.00224504
	LOSS [training: 0.11241313960234571 | validation: 0.12381875215814314]
	TIME [epoch: 9.13 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1208666031458973		[learning rate: 0.0022345]
	Learning Rate: 0.00223452
	LOSS [training: 0.1208666031458973 | validation: 0.08038864178609242]
	TIME [epoch: 9.15 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0990087833939235		[learning rate: 0.002224]
	Learning Rate: 0.00222404
	LOSS [training: 0.0990087833939235 | validation: 0.1321302348265795]
	TIME [epoch: 9.13 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10650958815815133		[learning rate: 0.0022136]
	Learning Rate: 0.00221361
	LOSS [training: 0.10650958815815133 | validation: 0.08490520046494399]
	TIME [epoch: 9.13 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09992662220763922		[learning rate: 0.0022032]
	Learning Rate: 0.00220324
	LOSS [training: 0.09992662220763922 | validation: 0.11572933448910663]
	TIME [epoch: 9.13 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09067480462543241		[learning rate: 0.0021929]
	Learning Rate: 0.00219291
	LOSS [training: 0.09067480462543241 | validation: 0.15701201833299927]
	TIME [epoch: 9.14 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08353776295515326		[learning rate: 0.0021826]
	Learning Rate: 0.00218263
	LOSS [training: 0.08353776295515326 | validation: 0.06283113706920027]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_334.pth
	Model improved!!!
EPOCH 335/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08907030044641359		[learning rate: 0.0021724]
	Learning Rate: 0.00217239
	LOSS [training: 0.08907030044641359 | validation: 0.09596391112905289]
	TIME [epoch: 9.12 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06407083786456026		[learning rate: 0.0021622]
	Learning Rate: 0.00216221
	LOSS [training: 0.06407083786456026 | validation: 0.1341093436511696]
	TIME [epoch: 9.14 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07675829068919889		[learning rate: 0.0021521]
	Learning Rate: 0.00215207
	LOSS [training: 0.07675829068919889 | validation: 0.084785928652089]
	TIME [epoch: 9.16 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06129522640855184		[learning rate: 0.002142]
	Learning Rate: 0.00214198
	LOSS [training: 0.06129522640855184 | validation: 0.16810298656068057]
	TIME [epoch: 9.16 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09746629099949541		[learning rate: 0.0021319]
	Learning Rate: 0.00213194
	LOSS [training: 0.09746629099949541 | validation: 0.12160945501003148]
	TIME [epoch: 9.16 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1497206742121147		[learning rate: 0.0021219]
	Learning Rate: 0.00212195
	LOSS [training: 0.1497206742121147 | validation: 0.14304152264552183]
	TIME [epoch: 9.13 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15136204405991127		[learning rate: 0.002112]
	Learning Rate: 0.002112
	LOSS [training: 0.15136204405991127 | validation: 0.10956399219382318]
	TIME [epoch: 9.14 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15287321297973905		[learning rate: 0.0021021]
	Learning Rate: 0.0021021
	LOSS [training: 0.15287321297973905 | validation: 0.1910597883508205]
	TIME [epoch: 9.14 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10639986757476834		[learning rate: 0.0020922]
	Learning Rate: 0.00209224
	LOSS [training: 0.10639986757476834 | validation: 0.10868668918223998]
	TIME [epoch: 9.14 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1160701159101271		[learning rate: 0.0020824]
	Learning Rate: 0.00208243
	LOSS [training: 0.1160701159101271 | validation: 0.19928656507482156]
	TIME [epoch: 9.16 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11390076455684131		[learning rate: 0.0020727]
	Learning Rate: 0.00207267
	LOSS [training: 0.11390076455684131 | validation: 0.07391280940349534]
	TIME [epoch: 9.14 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05979094225791507		[learning rate: 0.002063]
	Learning Rate: 0.00206295
	LOSS [training: 0.05979094225791507 | validation: 0.1304636456655689]
	TIME [epoch: 9.13 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06895183018234534		[learning rate: 0.0020533]
	Learning Rate: 0.00205328
	LOSS [training: 0.06895183018234534 | validation: 0.07340364406418487]
	TIME [epoch: 9.12 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/10] avg loss: 0.114411072332565		[learning rate: 0.0020437]
	Learning Rate: 0.00204366
	LOSS [training: 0.114411072332565 | validation: 0.12812872592464103]
	TIME [epoch: 9.14 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1620464446469781		[learning rate: 0.0020341]
	Learning Rate: 0.00203408
	LOSS [training: 0.1620464446469781 | validation: 0.14891952515362067]
	TIME [epoch: 9.15 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12147431292487487		[learning rate: 0.0020245]
	Learning Rate: 0.00202454
	LOSS [training: 0.12147431292487487 | validation: 0.1521921110310157]
	TIME [epoch: 9.1 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10844408251951745		[learning rate: 0.002015]
	Learning Rate: 0.00201505
	LOSS [training: 0.10844408251951745 | validation: 0.08139638096171589]
	TIME [epoch: 9.12 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07311661284469358		[learning rate: 0.0020056]
	Learning Rate: 0.0020056
	LOSS [training: 0.07311661284469358 | validation: 0.0818629977596771]
	TIME [epoch: 9.11 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10850508530893928		[learning rate: 0.0019962]
	Learning Rate: 0.0019962
	LOSS [training: 0.10850508530893928 | validation: 0.11767863865895628]
	TIME [epoch: 9.14 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10905210955026305		[learning rate: 0.0019868]
	Learning Rate: 0.00198684
	LOSS [training: 0.10905210955026305 | validation: 0.18503742660268446]
	TIME [epoch: 9.11 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12300347335053148		[learning rate: 0.0019775]
	Learning Rate: 0.00197753
	LOSS [training: 0.12300347335053148 | validation: 0.09234723185846572]
	TIME [epoch: 9.1 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08124281263182422		[learning rate: 0.0019683]
	Learning Rate: 0.00196826
	LOSS [training: 0.08124281263182422 | validation: 0.103522743886855]
	TIME [epoch: 9.12 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07912897243321425		[learning rate: 0.001959]
	Learning Rate: 0.00195903
	LOSS [training: 0.07912897243321425 | validation: 0.08064876205487545]
	TIME [epoch: 9.14 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0833314046818467		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.0833314046818467 | validation: 0.05773720768622945]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_358.pth
	Model improved!!!
EPOCH 359/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07019504525182324		[learning rate: 0.0019407]
	Learning Rate: 0.0019407
	LOSS [training: 0.07019504525182324 | validation: 0.09353602453721785]
	TIME [epoch: 9.08 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06952520680926856		[learning rate: 0.0019316]
	Learning Rate: 0.00193161
	LOSS [training: 0.06952520680926856 | validation: 0.08759929764716984]
	TIME [epoch: 9.1 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05892055222123617		[learning rate: 0.0019225]
	Learning Rate: 0.00192255
	LOSS [training: 0.05892055222123617 | validation: 0.07055535163232118]
	TIME [epoch: 9.12 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07943451220101896		[learning rate: 0.0019135]
	Learning Rate: 0.00191354
	LOSS [training: 0.07943451220101896 | validation: 0.054001300992734216]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_362.pth
	Model improved!!!
EPOCH 363/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06184924252206603		[learning rate: 0.0019046]
	Learning Rate: 0.00190457
	LOSS [training: 0.06184924252206603 | validation: 0.08556539502169186]
	TIME [epoch: 9.15 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1040732080857413		[learning rate: 0.0018956]
	Learning Rate: 0.00189564
	LOSS [training: 0.1040732080857413 | validation: 0.04731494470568093]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_364.pth
	Model improved!!!
EPOCH 365/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10315874646352521		[learning rate: 0.0018867]
	Learning Rate: 0.00188675
	LOSS [training: 0.10315874646352521 | validation: 0.1081592970828808]
	TIME [epoch: 9.15 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10120688316230894		[learning rate: 0.0018779]
	Learning Rate: 0.0018779
	LOSS [training: 0.10120688316230894 | validation: 0.25632583251579893]
	TIME [epoch: 9.14 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1830346352156785		[learning rate: 0.0018691]
	Learning Rate: 0.0018691
	LOSS [training: 0.1830346352156785 | validation: 0.09458424198660698]
	TIME [epoch: 9.15 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07403708034148426		[learning rate: 0.0018603]
	Learning Rate: 0.00186034
	LOSS [training: 0.07403708034148426 | validation: 0.11475449732260232]
	TIME [epoch: 9.16 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08023022330868387		[learning rate: 0.0018516]
	Learning Rate: 0.00185162
	LOSS [training: 0.08023022330868387 | validation: 0.05620462284467986]
	TIME [epoch: 9.14 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26625909259579517		[learning rate: 0.0018429]
	Learning Rate: 0.00184294
	LOSS [training: 0.26625909259579517 | validation: 0.1489847157674999]
	TIME [epoch: 9.13 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09032354885997515		[learning rate: 0.0018343]
	Learning Rate: 0.0018343
	LOSS [training: 0.09032354885997515 | validation: 0.16660256056511533]
	TIME [epoch: 9.14 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08099825047398557		[learning rate: 0.0018257]
	Learning Rate: 0.0018257
	LOSS [training: 0.08099825047398557 | validation: 0.05067096833577335]
	TIME [epoch: 9.15 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05171137136996677		[learning rate: 0.0018171]
	Learning Rate: 0.00181714
	LOSS [training: 0.05171137136996677 | validation: 0.13556254226437897]
	TIME [epoch: 9.17 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10130547674123044		[learning rate: 0.0018086]
	Learning Rate: 0.00180862
	LOSS [training: 0.10130547674123044 | validation: 0.21227987863063078]
	TIME [epoch: 9.16 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09657766098399215		[learning rate: 0.0018001]
	Learning Rate: 0.00180014
	LOSS [training: 0.09657766098399215 | validation: 0.18089249532016471]
	TIME [epoch: 9.16 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10029341411751383		[learning rate: 0.0017917]
	Learning Rate: 0.0017917
	LOSS [training: 0.10029341411751383 | validation: 0.16350509889604545]
	TIME [epoch: 9.15 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07048388925582595		[learning rate: 0.0017833]
	Learning Rate: 0.0017833
	LOSS [training: 0.07048388925582595 | validation: 0.08794699600343366]
	TIME [epoch: 9.16 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08176401701676082		[learning rate: 0.0017749]
	Learning Rate: 0.00177494
	LOSS [training: 0.08176401701676082 | validation: 0.0785413756407125]
	TIME [epoch: 9.18 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13531383720891418		[learning rate: 0.0017666]
	Learning Rate: 0.00176662
	LOSS [training: 0.13531383720891418 | validation: 0.1143878911161869]
	TIME [epoch: 9.16 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06367154697862876		[learning rate: 0.0017583]
	Learning Rate: 0.00175834
	LOSS [training: 0.06367154697862876 | validation: 0.14838340631503677]
	TIME [epoch: 9.15 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10697579657798191		[learning rate: 0.0017501]
	Learning Rate: 0.00175009
	LOSS [training: 0.10697579657798191 | validation: 0.050407383628360676]
	TIME [epoch: 9.15 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06522403134480073		[learning rate: 0.0017419]
	Learning Rate: 0.00174189
	LOSS [training: 0.06522403134480073 | validation: 0.1716967272344589]
	TIME [epoch: 9.14 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06905252851183624		[learning rate: 0.0017337]
	Learning Rate: 0.00173372
	LOSS [training: 0.06905252851183624 | validation: 0.07826470425403503]
	TIME [epoch: 9.17 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05141448531451272		[learning rate: 0.0017256]
	Learning Rate: 0.00172559
	LOSS [training: 0.05141448531451272 | validation: 0.06456789542821736]
	TIME [epoch: 9.14 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07875859317949736		[learning rate: 0.0017175]
	Learning Rate: 0.0017175
	LOSS [training: 0.07875859317949736 | validation: 0.12846401072655853]
	TIME [epoch: 9.15 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08006965514812936		[learning rate: 0.0017095]
	Learning Rate: 0.00170945
	LOSS [training: 0.08006965514812936 | validation: 0.06631239614208836]
	TIME [epoch: 9.14 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13337095035877317		[learning rate: 0.0017014]
	Learning Rate: 0.00170144
	LOSS [training: 0.13337095035877317 | validation: 0.19611100422577205]
	TIME [epoch: 9.15 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10942022513781309		[learning rate: 0.0016935]
	Learning Rate: 0.00169346
	LOSS [training: 0.10942022513781309 | validation: 0.10151814417448607]
	TIME [epoch: 9.17 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04803385290089264		[learning rate: 0.0016855]
	Learning Rate: 0.00168552
	LOSS [training: 0.04803385290089264 | validation: 0.0445626187964063]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_389.pth
	Model improved!!!
EPOCH 390/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08039498384718131		[learning rate: 0.0016776]
	Learning Rate: 0.00167762
	LOSS [training: 0.08039498384718131 | validation: 0.10338455508350591]
	TIME [epoch: 9.14 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09142788149968727		[learning rate: 0.0016698]
	Learning Rate: 0.00166976
	LOSS [training: 0.09142788149968727 | validation: 0.13968519873332086]
	TIME [epoch: 9.17 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08042635701720491		[learning rate: 0.0016619]
	Learning Rate: 0.00166193
	LOSS [training: 0.08042635701720491 | validation: 0.17122027063306672]
	TIME [epoch: 9.13 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08016723283390034		[learning rate: 0.0016541]
	Learning Rate: 0.00165414
	LOSS [training: 0.08016723283390034 | validation: 0.05023892447373557]
	TIME [epoch: 9.15 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/10] avg loss: 0.044149992052844096		[learning rate: 0.0016464]
	Learning Rate: 0.00164638
	LOSS [training: 0.044149992052844096 | validation: 0.05827281844912018]
	TIME [epoch: 9.14 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/10] avg loss: 0.12912178105393018		[learning rate: 0.0016387]
	Learning Rate: 0.00163866
	LOSS [training: 0.12912178105393018 | validation: 0.05695604262703717]
	TIME [epoch: 9.13 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10941988208867452		[learning rate: 0.001631]
	Learning Rate: 0.00163098
	LOSS [training: 0.10941988208867452 | validation: 0.09969296432850025]
	TIME [epoch: 9.14 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13623279081626036		[learning rate: 0.0016233]
	Learning Rate: 0.00162333
	LOSS [training: 0.13623279081626036 | validation: 0.13777047783757443]
	TIME [epoch: 9.15 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10186432711430041		[learning rate: 0.0016157]
	Learning Rate: 0.00161572
	LOSS [training: 0.10186432711430041 | validation: 0.1343636789795853]
	TIME [epoch: 9.16 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0702894360615665		[learning rate: 0.0016081]
	Learning Rate: 0.00160815
	LOSS [training: 0.0702894360615665 | validation: 0.062046509491435295]
	TIME [epoch: 9.13 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/10] avg loss: 0.10149425392600461		[learning rate: 0.0016006]
	Learning Rate: 0.00160061
	LOSS [training: 0.10149425392600461 | validation: 0.11737164629808314]
	TIME [epoch: 9.12 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1075720604410026		[learning rate: 0.0015931]
	Learning Rate: 0.00159311
	LOSS [training: 0.1075720604410026 | validation: 0.10280081389816717]
	TIME [epoch: 9.14 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06439704159891621		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.06439704159891621 | validation: 0.06616211071887339]
	TIME [epoch: 9.13 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05286581565372983		[learning rate: 0.0015782]
	Learning Rate: 0.0015782
	LOSS [training: 0.05286581565372983 | validation: 0.0780434903083046]
	TIME [epoch: 9.16 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04313695172747144		[learning rate: 0.0015708]
	Learning Rate: 0.00157081
	LOSS [training: 0.04313695172747144 | validation: 0.04607184435440287]
	TIME [epoch: 9.14 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06574181475065825		[learning rate: 0.0015634]
	Learning Rate: 0.00156344
	LOSS [training: 0.06574181475065825 | validation: 0.06624895045033256]
	TIME [epoch: 9.13 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07116931289429741		[learning rate: 0.0015561]
	Learning Rate: 0.00155611
	LOSS [training: 0.07116931289429741 | validation: 0.08398283090076863]
	TIME [epoch: 9.14 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06795355048073562		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.06795355048073562 | validation: 0.07486567711361006]
	TIME [epoch: 9.12 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07754570781864224		[learning rate: 0.0015416]
	Learning Rate: 0.00154156
	LOSS [training: 0.07754570781864224 | validation: 0.13689776143558352]
	TIME [epoch: 9.16 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09093384795016288		[learning rate: 0.0015343]
	Learning Rate: 0.00153433
	LOSS [training: 0.09093384795016288 | validation: 0.06929744268137183]
	TIME [epoch: 9.11 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08212800412903173		[learning rate: 0.0015271]
	Learning Rate: 0.00152714
	LOSS [training: 0.08212800412903173 | validation: 0.07156124016841751]
	TIME [epoch: 9.12 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09417317728450783		[learning rate: 0.00152]
	Learning Rate: 0.00151998
	LOSS [training: 0.09417317728450783 | validation: 0.3121086587464461]
	TIME [epoch: 9.13 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1233504603921641		[learning rate: 0.0015129]
	Learning Rate: 0.00151285
	LOSS [training: 0.1233504603921641 | validation: 0.09383997613397184]
	TIME [epoch: 9.12 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06308491271995943		[learning rate: 0.0015058]
	Learning Rate: 0.00150576
	LOSS [training: 0.06308491271995943 | validation: 0.03891387880224967]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_413.pth
	Model improved!!!
EPOCH 414/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05187563696330625		[learning rate: 0.0014987]
	Learning Rate: 0.0014987
	LOSS [training: 0.05187563696330625 | validation: 0.04468327843554483]
	TIME [epoch: 9.13 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06034002266052853		[learning rate: 0.0014917]
	Learning Rate: 0.00149167
	LOSS [training: 0.06034002266052853 | validation: 0.3072482667008426]
	TIME [epoch: 9.13 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/10] avg loss: 0.14611704329134162		[learning rate: 0.0014847]
	Learning Rate: 0.00148468
	LOSS [training: 0.14611704329134162 | validation: 0.16153370727284277]
	TIME [epoch: 9.14 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08995758649641775		[learning rate: 0.0014777]
	Learning Rate: 0.00147772
	LOSS [training: 0.08995758649641775 | validation: 0.12524893319442454]
	TIME [epoch: 9.14 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15077572254624666		[learning rate: 0.0014708]
	Learning Rate: 0.00147079
	LOSS [training: 0.15077572254624666 | validation: 0.06057831610262282]
	TIME [epoch: 9.18 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08715644813682032		[learning rate: 0.0014639]
	Learning Rate: 0.0014639
	LOSS [training: 0.08715644813682032 | validation: 0.10514116256464937]
	TIME [epoch: 9.13 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09034889927757293		[learning rate: 0.001457]
	Learning Rate: 0.00145703
	LOSS [training: 0.09034889927757293 | validation: 0.05585716563990549]
	TIME [epoch: 9.13 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07301004455574223		[learning rate: 0.0014502]
	Learning Rate: 0.0014502
	LOSS [training: 0.07301004455574223 | validation: 0.075398593858169]
	TIME [epoch: 9.13 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07515310958093627		[learning rate: 0.0014434]
	Learning Rate: 0.0014434
	LOSS [training: 0.07515310958093627 | validation: 0.15805348667173785]
	TIME [epoch: 9.14 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0905161200779807		[learning rate: 0.0014366]
	Learning Rate: 0.00143664
	LOSS [training: 0.0905161200779807 | validation: 0.054587211058290536]
	TIME [epoch: 9.16 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05486136239188834		[learning rate: 0.0014299]
	Learning Rate: 0.0014299
	LOSS [training: 0.05486136239188834 | validation: 0.06716181186018044]
	TIME [epoch: 9.15 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05249783487275261		[learning rate: 0.0014232]
	Learning Rate: 0.0014232
	LOSS [training: 0.05249783487275261 | validation: 0.07312796120196434]
	TIME [epoch: 9.18 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06132740253391058		[learning rate: 0.0014165]
	Learning Rate: 0.00141653
	LOSS [training: 0.06132740253391058 | validation: 0.05186255417385165]
	TIME [epoch: 9.17 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0366045335249825		[learning rate: 0.0014099]
	Learning Rate: 0.00140989
	LOSS [training: 0.0366045335249825 | validation: 0.1061314705423802]
	TIME [epoch: 9.16 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1018253763413873		[learning rate: 0.0014033]
	Learning Rate: 0.00140328
	LOSS [training: 0.1018253763413873 | validation: 0.06639991906729642]
	TIME [epoch: 9.15 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/10] avg loss: 0.054657952666668584		[learning rate: 0.0013967]
	Learning Rate: 0.0013967
	LOSS [training: 0.054657952666668584 | validation: 0.08503789006608332]
	TIME [epoch: 9.15 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1450854800829552		[learning rate: 0.0013901]
	Learning Rate: 0.00139015
	LOSS [training: 0.1450854800829552 | validation: 0.08450022607929923]
	TIME [epoch: 9.14 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05866953381030462		[learning rate: 0.0013836]
	Learning Rate: 0.00138363
	LOSS [training: 0.05866953381030462 | validation: 0.06192107306056033]
	TIME [epoch: 9.14 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07263995128822218		[learning rate: 0.0013771]
	Learning Rate: 0.00137714
	LOSS [training: 0.07263995128822218 | validation: 0.12115860085379518]
	TIME [epoch: 9.15 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0902539328493904		[learning rate: 0.0013707]
	Learning Rate: 0.00137069
	LOSS [training: 0.0902539328493904 | validation: 0.1424200561778206]
	TIME [epoch: 9.16 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/10] avg loss: 0.08787496450207691		[learning rate: 0.0013643]
	Learning Rate: 0.00136426
	LOSS [training: 0.08787496450207691 | validation: 0.09033629961018307]
	TIME [epoch: 9.15 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/10] avg loss: 0.059557080059123677		[learning rate: 0.0013579]
	Learning Rate: 0.00135787
	LOSS [training: 0.059557080059123677 | validation: 0.04037340935846764]
	TIME [epoch: 9.15 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04006401667829355		[learning rate: 0.0013515]
	Learning Rate: 0.0013515
	LOSS [training: 0.04006401667829355 | validation: 0.160797428866918]
	TIME [epoch: 9.16 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06687118093509703		[learning rate: 0.0013452]
	Learning Rate: 0.00134516
	LOSS [training: 0.06687118093509703 | validation: 0.036312282709044824]
	TIME [epoch: 9.17 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240214_183129/states/model_tr_study4_437.pth
	Model improved!!!
EPOCH 438/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05509566648246285		[learning rate: 0.0013389]
	Learning Rate: 0.00133886
	LOSS [training: 0.05509566648246285 | validation: 0.08580176478052044]
	TIME [epoch: 9.15 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04163530514328505		[learning rate: 0.0013326]
	Learning Rate: 0.00133258
	LOSS [training: 0.04163530514328505 | validation: 0.044924288391768576]
	TIME [epoch: 9.12 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/10] avg loss: 0.038141336928830614		[learning rate: 0.0013263]
	Learning Rate: 0.00132633
	LOSS [training: 0.038141336928830614 | validation: 0.06085507089576162]
	TIME [epoch: 9.16 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09547627357098128		[learning rate: 0.0013201]
	Learning Rate: 0.00132012
	LOSS [training: 0.09547627357098128 | validation: 0.0727521372768199]
	TIME [epoch: 9.14 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07147181658292259		[learning rate: 0.0013139]
	Learning Rate: 0.00131393
	LOSS [training: 0.07147181658292259 | validation: 0.048583959864177684]
	TIME [epoch: 9.17 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04949142593108589		[learning rate: 0.0013078]
	Learning Rate: 0.00130777
	LOSS [training: 0.04949142593108589 | validation: 0.06838542764761507]
	TIME [epoch: 9.13 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0467990162423262		[learning rate: 0.0013016]
	Learning Rate: 0.00130164
	LOSS [training: 0.0467990162423262 | validation: 0.055292040319012296]
	TIME [epoch: 9.1 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/10] avg loss: 0.056020450560094456		[learning rate: 0.0012955]
	Learning Rate: 0.00129553
	LOSS [training: 0.056020450560094456 | validation: 0.16665810963452554]
	TIME [epoch: 9.11 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/10] avg loss: 0.13188057393138958		[learning rate: 0.0012895]
	Learning Rate: 0.00128946
	LOSS [training: 0.13188057393138958 | validation: 0.1184822933784287]
	TIME [epoch: 9.12 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05361257112847077		[learning rate: 0.0012834]
	Learning Rate: 0.00128342
	LOSS [training: 0.05361257112847077 | validation: 0.06114106498037644]
	TIME [epoch: 9.13 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07493661384645747		[learning rate: 0.0012774]
	Learning Rate: 0.0012774
	LOSS [training: 0.07493661384645747 | validation: 0.135200467466363]
	TIME [epoch: 9.13 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11405068109430253		[learning rate: 0.0012714]
	Learning Rate: 0.00127141
	LOSS [training: 0.11405068109430253 | validation: 0.19034078977711322]
	TIME [epoch: 9.15 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07776433949596613		[learning rate: 0.0012654]
	Learning Rate: 0.00126545
	LOSS [training: 0.07776433949596613 | validation: 0.04799466594690206]
	TIME [epoch: 9.12 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06876406299844423		[learning rate: 0.0012595]
	Learning Rate: 0.00125952
	LOSS [training: 0.06876406299844423 | validation: 0.05170764391760087]
	TIME [epoch: 9.12 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04713783392206219		[learning rate: 0.0012536]
	Learning Rate: 0.00125361
	LOSS [training: 0.04713783392206219 | validation: 0.15546977693788203]
	TIME [epoch: 9.15 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07745499227021593		[learning rate: 0.0012477]
	Learning Rate: 0.00124774
	LOSS [training: 0.07745499227021593 | validation: 0.04798647604959978]
	TIME [epoch: 9.15 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04675266570369104		[learning rate: 0.0012419]
	Learning Rate: 0.00124189
	LOSS [training: 0.04675266570369104 | validation: 0.04905652091661204]
	TIME [epoch: 9.16 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06093261469105891		[learning rate: 0.0012361]
	Learning Rate: 0.00123606
	LOSS [training: 0.06093261469105891 | validation: 0.053258589556254676]
	TIME [epoch: 9.14 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/10] avg loss: 0.052248951417196085		[learning rate: 0.0012303]
	Learning Rate: 0.00123027
	LOSS [training: 0.052248951417196085 | validation: 0.06414451982904622]
	TIME [epoch: 9.14 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/10] avg loss: 0.041067898103769075		[learning rate: 0.0012245]
	Learning Rate: 0.0012245
	LOSS [training: 0.041067898103769075 | validation: 0.09406630340711011]
	TIME [epoch: 9.16 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05344336393933454		[learning rate: 0.0012188]
	Learning Rate: 0.00121876
	LOSS [training: 0.05344336393933454 | validation: 0.09788804416907915]
	TIME [epoch: 9.15 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09380311929810255		[learning rate: 0.001213]
	Learning Rate: 0.00121305
	LOSS [training: 0.09380311929810255 | validation: 0.08568836651648211]
	TIME [epoch: 9.15 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06291709211483612		[learning rate: 0.0012074]
	Learning Rate: 0.00120736
	LOSS [training: 0.06291709211483612 | validation: 0.0841408498281214]
	TIME [epoch: 9.14 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0655272960280752		[learning rate: 0.0012017]
	Learning Rate: 0.0012017
	LOSS [training: 0.0655272960280752 | validation: 0.05910487054491584]
	TIME [epoch: 9.15 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07179960782939929		[learning rate: 0.0011961]
	Learning Rate: 0.00119607
	LOSS [training: 0.07179960782939929 | validation: 0.09589316932053765]
	TIME [epoch: 9.16 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07622477833826173		[learning rate: 0.0011905]
	Learning Rate: 0.00119046
	LOSS [training: 0.07622477833826173 | validation: 0.07596597943489997]
	TIME [epoch: 9.14 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06033362822288111		[learning rate: 0.0011849]
	Learning Rate: 0.00118488
	LOSS [training: 0.06033362822288111 | validation: 0.06705919833734891]
	TIME [epoch: 9.14 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05596869230183147		[learning rate: 0.0011793]
	Learning Rate: 0.00117932
	LOSS [training: 0.05596869230183147 | validation: 0.05493536893271403]
	TIME [epoch: 9.13 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05690405579383776		[learning rate: 0.0011738]
	Learning Rate: 0.00117379
	LOSS [training: 0.05690405579383776 | validation: 0.10837590311078571]
	TIME [epoch: 9.14 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1231361295059235		[learning rate: 0.0011683]
	Learning Rate: 0.00116829
	LOSS [training: 0.1231361295059235 | validation: 0.09025557718282862]
	TIME [epoch: 9.15 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03989748728768734		[learning rate: 0.0011628]
	Learning Rate: 0.00116281
	LOSS [training: 0.03989748728768734 | validation: 0.037469976779205424]
	TIME [epoch: 9.16 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04892813001992024		[learning rate: 0.0011574]
	Learning Rate: 0.00115736
	LOSS [training: 0.04892813001992024 | validation: 0.055011557254573684]
	TIME [epoch: 9.13 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04555196734619582		[learning rate: 0.0011519]
	Learning Rate: 0.00115194
	LOSS [training: 0.04555196734619582 | validation: 0.0965849396031172]
	TIME [epoch: 9.12 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0792185357482757		[learning rate: 0.0011465]
	Learning Rate: 0.00114654
	LOSS [training: 0.0792185357482757 | validation: 0.11037008432698203]
	TIME [epoch: 9.11 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/10] avg loss: 0.056504829668796754		[learning rate: 0.0011412]
	Learning Rate: 0.00114116
	LOSS [training: 0.056504829668796754 | validation: 0.06252989329208344]
	TIME [epoch: 9.16 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/10] avg loss: 0.050864301286884406		[learning rate: 0.0011358]
	Learning Rate: 0.00113581
	LOSS [training: 0.050864301286884406 | validation: 0.06905568327194121]
	TIME [epoch: 9.13 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0492442063788842		[learning rate: 0.0011305]
	Learning Rate: 0.00113049
	LOSS [training: 0.0492442063788842 | validation: 0.08283741415806958]
	TIME [epoch: 9.14 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/10] avg loss: 0.15027578326108926		[learning rate: 0.0011252]
	Learning Rate: 0.00112519
	LOSS [training: 0.15027578326108926 | validation: 0.10831733492299855]
	TIME [epoch: 9.14 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09986745774971591		[learning rate: 0.0011199]
	Learning Rate: 0.00111991
	LOSS [training: 0.09986745774971591 | validation: 0.05980098915165115]
	TIME [epoch: 9.15 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/10] avg loss: 0.032507081118206244		[learning rate: 0.0011147]
	Learning Rate: 0.00111466
	LOSS [training: 0.032507081118206244 | validation: 0.10305234682922407]
	TIME [epoch: 9.15 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0720418773683386		[learning rate: 0.0011094]
	Learning Rate: 0.00110944
	LOSS [training: 0.0720418773683386 | validation: 0.10967891433042536]
	TIME [epoch: 9.14 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1410034923847177		[learning rate: 0.0011042]
	Learning Rate: 0.00110423
	LOSS [training: 0.1410034923847177 | validation: 0.0665745752282052]
	TIME [epoch: 9.15 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05179254386656753		[learning rate: 0.0010991]
	Learning Rate: 0.00109906
	LOSS [training: 0.05179254386656753 | validation: 0.09597661367818536]
	TIME [epoch: 9.13 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04857441066004084		[learning rate: 0.0010939]
	Learning Rate: 0.0010939
	LOSS [training: 0.04857441066004084 | validation: 0.039762373987688074]
	TIME [epoch: 9.14 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03262687447231918		[learning rate: 0.0010888]
	Learning Rate: 0.00108878
	LOSS [training: 0.03262687447231918 | validation: 0.06082702578391977]
	TIME [epoch: 9.14 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04448954653445409		[learning rate: 0.0010837]
	Learning Rate: 0.00108367
	LOSS [training: 0.04448954653445409 | validation: 0.04415277970097971]
	TIME [epoch: 9.11 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/10] avg loss: 0.060393469418045166		[learning rate: 0.0010786]
	Learning Rate: 0.00107859
	LOSS [training: 0.060393469418045166 | validation: 0.12945598577053483]
	TIME [epoch: 9.12 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05748917289450765		[learning rate: 0.0010735]
	Learning Rate: 0.00107354
	LOSS [training: 0.05748917289450765 | validation: 0.049900314403000856]
	TIME [epoch: 9.14 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/10] avg loss: 0.03678690404291422		[learning rate: 0.0010685]
	Learning Rate: 0.0010685
	LOSS [training: 0.03678690404291422 | validation: 0.07057140181500236]
	TIME [epoch: 9.12 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/10] avg loss: 0.05076976438846335		[learning rate: 0.0010635]
	Learning Rate: 0.00106349
	LOSS [training: 0.05076976438846335 | validation: 0.15347831227263786]
	TIME [epoch: 9.17 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0948743457501938		[learning rate: 0.0010585]
	Learning Rate: 0.00105851
	LOSS [training: 0.0948743457501938 | validation: 0.059437944020210035]
	TIME [epoch: 9.16 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04262378793960805		[learning rate: 0.0010535]
	Learning Rate: 0.00105354
	LOSS [training: 0.04262378793960805 | validation: 0.05714268179195908]
	TIME [epoch: 9.15 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07439041783179978		[learning rate: 0.0010486]
	Learning Rate: 0.00104861
	LOSS [training: 0.07439041783179978 | validation: 0.23121201263856808]
	TIME [epoch: 9.16 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1293488744020581		[learning rate: 0.0010437]
	Learning Rate: 0.00104369
	LOSS [training: 0.1293488744020581 | validation: 0.10231565644031326]
	TIME [epoch: 9.14 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07700955209457597		[learning rate: 0.0010388]
	Learning Rate: 0.0010388
	LOSS [training: 0.07700955209457597 | validation: 0.06963670141904313]
	TIME [epoch: 9.17 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/10] avg loss: 0.056323923086131454		[learning rate: 0.0010339]
	Learning Rate: 0.00103393
	LOSS [training: 0.056323923086131454 | validation: 0.06921736494768513]
	TIME [epoch: 9.15 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/10] avg loss: 0.04146247021060266		[learning rate: 0.0010291]
	Learning Rate: 0.00102908
	LOSS [training: 0.04146247021060266 | validation: 0.12921657237192716]
	TIME [epoch: 9.13 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/10] avg loss: 0.09462566384004814		[learning rate: 0.0010243]
	Learning Rate: 0.00102426
	LOSS [training: 0.09462566384004814 | validation: 0.09435432722574369]
	TIME [epoch: 9.16 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/10] avg loss: 0.07450265327414783		[learning rate: 0.0010195]
	Learning Rate: 0.00101945
	LOSS [training: 0.07450265327414783 | validation: 0.07840636790320987]
	TIME [epoch: 9.14 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/10] avg loss: 0.06367257962760252		[learning rate: 0.0010147]
	Learning Rate: 0.00101467
	LOSS [training: 0.06367257962760252 | validation: 0.07076489713758057]
	TIME [epoch: 9.18 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/10] avg loss: 0.11123144028699672		[learning rate: 0.0010099]
	Learning Rate: 0.00100992
	LOSS [training: 0.11123144028699672 | validation: 0.3319283144659541]
	TIME [epoch: 9.16 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1620639073868124		[learning rate: 0.0010052]
	Learning Rate: 0.00100518
	LOSS [training: 0.1620639073868124 | validation: 0.08446310296157389]
	TIME [epoch: 9.15 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/10] avg loss: 0.0643540203550754		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.0643540203550754 | validation: 0.14314833607236116]
	TIME [epoch: 9.16 sec]
Finished training in 4619.508 seconds.
