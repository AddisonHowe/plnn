Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r5', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3535096631

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.47761811829091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.47761811829091 | validation: 9.333980146242675]
	TIME [epoch: 48.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.791921039012953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.791921039012953 | validation: 8.763625969591693]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.00242226970987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.00242226970987 | validation: 8.602149696406556]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.647559959387581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.647559959387581 | validation: 7.853033874027931]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.116908915338582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.116908915338582 | validation: 7.597993206667922]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.861700709780598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.861700709780598 | validation: 7.317050591502106]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.68078843733136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.68078843733136 | validation: 7.045329885093709]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.58842681322203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.58842681322203 | validation: 4.648010899521481]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6128992892929426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6128992892929426 | validation: 2.7080127643975884]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.984253632036592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.984253632036592 | validation: 2.6224394684093966]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1643605144632145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1643605144632145 | validation: 2.8653757048343245]
	TIME [epoch: 9.11 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.542173602382367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.542173602382367 | validation: 2.4708449174377782]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7183339825636805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7183339825636805 | validation: 2.577603273701653]
	TIME [epoch: 9.08 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3141928550503916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3141928550503916 | validation: 2.4206463675311767]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9013456814452507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9013456814452507 | validation: 1.6403732171966285]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0756077884276847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0756077884276847 | validation: 1.7089891412202534]
	TIME [epoch: 9.11 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5217531683854306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5217531683854306 | validation: 1.540912506201245]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.470231051990053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.470231051990053 | validation: 1.2833627018615157]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2531352350274847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2531352350274847 | validation: 1.0853584246191055]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2172334477642566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2172334477642566 | validation: 0.9657760926935275]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0599702004462601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0599702004462601 | validation: 1.0233361956799127]
	TIME [epoch: 9.11 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2649000434450994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2649000434450994 | validation: 1.0328644750374423]
	TIME [epoch: 9.08 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0056850880614085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0056850880614085 | validation: 1.0874271381294571]
	TIME [epoch: 9.08 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1028860476117228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1028860476117228 | validation: 0.8296611396756826]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0949657884473836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0949657884473836 | validation: 0.7878033214253386]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8904576731419895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8904576731419895 | validation: 0.8570853821054134]
	TIME [epoch: 9.07 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0056169635843317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0056169635843317 | validation: 0.8737218508513052]
	TIME [epoch: 9.07 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8467491378578529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8467491378578529 | validation: 1.219555425138763]
	TIME [epoch: 9.07 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0054979105217738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0054979105217738 | validation: 0.9730235037072252]
	TIME [epoch: 9.08 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9397035026088343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9397035026088343 | validation: 0.8942810475428893]
	TIME [epoch: 9.08 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9533725195028978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9533725195028978 | validation: 0.8384390529012429]
	TIME [epoch: 9.06 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8057884249220736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8057884249220736 | validation: 0.6959203314736935]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.811100838237639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.811100838237639 | validation: 0.8915516962732284]
	TIME [epoch: 9.05 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7307144986512634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7307144986512634 | validation: 0.5914692242887187]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.143334080827033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.143334080827033 | validation: 0.7041938681087333]
	TIME [epoch: 9.08 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.79067880879251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.79067880879251 | validation: 1.0777856702658832]
	TIME [epoch: 9.07 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0007659141186407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0007659141186407 | validation: 1.0637060608056665]
	TIME [epoch: 9.07 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.913458246580843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.913458246580843 | validation: 0.7007422018717745]
	TIME [epoch: 9.08 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9465532305077453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9465532305077453 | validation: 0.8349942351800402]
	TIME [epoch: 9.07 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7216750800744031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7216750800744031 | validation: 0.584009583143462]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7926274176364637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7926274176364637 | validation: 1.0380404105935215]
	TIME [epoch: 9.05 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0079712589651888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0079712589651888 | validation: 0.6770749138367764]
	TIME [epoch: 9.07 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7806476369772362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7806476369772362 | validation: 0.7293124173758991]
	TIME [epoch: 9.09 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6700333598989754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6700333598989754 | validation: 0.5596404163032433]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6071345569845545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6071345569845545 | validation: 0.5374456294272498]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5963203116994149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5963203116994149 | validation: 0.5518377924814637]
	TIME [epoch: 9.07 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5769540833837363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5769540833837363 | validation: 1.7726510857703506]
	TIME [epoch: 9.09 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1577508323741974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1577508323741974 | validation: 0.46430754757284987]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5161770349036654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5161770349036654 | validation: 0.4577286741608326]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5136926920091434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5136926920091434 | validation: 0.5219963589332467]
	TIME [epoch: 9.1 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6162243602937155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6162243602937155 | validation: 0.4650648719256438]
	TIME [epoch: 9.09 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5524547297510338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5524547297510338 | validation: 0.5150252669205644]
	TIME [epoch: 9.1 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6321050829596112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6321050829596112 | validation: 0.6170823710220485]
	TIME [epoch: 9.09 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7011769914828528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7011769914828528 | validation: 0.5703173467931899]
	TIME [epoch: 9.08 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.860152157732499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.860152157732499 | validation: 0.549793019310917]
	TIME [epoch: 9.09 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5327450035560141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5327450035560141 | validation: 0.4679549168639452]
	TIME [epoch: 9.1 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8422469828139061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8422469828139061 | validation: 1.133090991322875]
	TIME [epoch: 9.09 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7650899828878409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7650899828878409 | validation: 0.5866473574678801]
	TIME [epoch: 9.08 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7389375209226771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7389375209226771 | validation: 0.7576635564677288]
	TIME [epoch: 9.08 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5050664391584637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5050664391584637 | validation: 0.44255947352840375]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5329771882363021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5329771882363021 | validation: 0.8537745057256076]
	TIME [epoch: 9.11 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6196104213454585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6196104213454585 | validation: 0.6036168578959988]
	TIME [epoch: 9.09 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5683472518233958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5683472518233958 | validation: 1.4748358391758154]
	TIME [epoch: 9.09 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6546092392309922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6546092392309922 | validation: 0.5524693457263201]
	TIME [epoch: 9.09 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6671543221891162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6671543221891162 | validation: 0.45124703852257675]
	TIME [epoch: 9.1 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5163848059531653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5163848059531653 | validation: 0.40709363893476225]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6138188131611374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6138188131611374 | validation: 0.6216915303809851]
	TIME [epoch: 9.08 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5708660818968022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5708660818968022 | validation: 0.4384352679024165]
	TIME [epoch: 9.08 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7318662811727024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7318662811727024 | validation: 0.9725298516189947]
	TIME [epoch: 9.09 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6588770332256197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6588770332256197 | validation: 0.7362733398662901]
	TIME [epoch: 9.11 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6108197165702609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6108197165702609 | validation: 0.4775330769912863]
	TIME [epoch: 9.09 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5551389322310657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5551389322310657 | validation: 0.4556923363696149]
	TIME [epoch: 9.09 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6863718718438988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6863718718438988 | validation: 0.576977171563017]
	TIME [epoch: 9.09 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5823852319446934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5823852319446934 | validation: 0.6529357547851138]
	TIME [epoch: 9.08 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5445629289483279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5445629289483279 | validation: 0.3621976931252426]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5910203203128994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5910203203128994 | validation: 0.7658234123877197]
	TIME [epoch: 9.09 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6054315104535176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6054315104535176 | validation: 0.40361036105278336]
	TIME [epoch: 9.09 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5056028290907608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5056028290907608 | validation: 0.43581601793742575]
	TIME [epoch: 9.08 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5427836955346957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5427836955346957 | validation: 0.42884039711951594]
	TIME [epoch: 9.09 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5544371178075145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5544371178075145 | validation: 0.47071923142839844]
	TIME [epoch: 9.08 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.485518981139666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.485518981139666 | validation: 0.4518108816598976]
	TIME [epoch: 9.07 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5216379506032501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5216379506032501 | validation: 0.7839017080170093]
	TIME [epoch: 9.08 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5604003855587836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5604003855587836 | validation: 0.609997790959445]
	TIME [epoch: 9.08 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4778154119769956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4778154119769956 | validation: 0.5855451587547907]
	TIME [epoch: 9.09 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4990566557309979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4990566557309979 | validation: 0.4555127745918828]
	TIME [epoch: 9.08 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5435843561386313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5435843561386313 | validation: 0.6410658807618423]
	TIME [epoch: 9.08 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5020513403178152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5020513403178152 | validation: 0.35676363810031025]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4331217124970574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4331217124970574 | validation: 0.49316546372336934]
	TIME [epoch: 9.09 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4624491145721138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4624491145721138 | validation: 0.5430688568108202]
	TIME [epoch: 9.09 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5647118144807275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5647118144807275 | validation: 0.4156741770997149]
	TIME [epoch: 9.08 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5198232278260045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5198232278260045 | validation: 0.5373455233133304]
	TIME [epoch: 9.08 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5244719710922903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5244719710922903 | validation: 0.47926138279709196]
	TIME [epoch: 9.08 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5480678056603263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5480678056603263 | validation: 0.39766564487008166]
	TIME [epoch: 9.09 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48617588462014244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48617588462014244 | validation: 0.35477869157787123]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48934631512427884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48934631512427884 | validation: 0.46277690709924113]
	TIME [epoch: 9.08 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5264550651104163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5264550651104163 | validation: 0.48516891610296703]
	TIME [epoch: 9.08 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0027725144917747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0027725144917747 | validation: 0.3425688779045705]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5718393681762902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5718393681762902 | validation: 0.5337984191314022]
	TIME [epoch: 9.08 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4740943617382607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4740943617382607 | validation: 0.5619959644471948]
	TIME [epoch: 9.07 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4683275453343311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4683275453343311 | validation: 0.3584569038327021]
	TIME [epoch: 9.06 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47575855207374235		[learning rate: 0.0099782]
	Learning Rate: 0.00997821
	LOSS [training: 0.47575855207374235 | validation: 0.3831538023113719]
	TIME [epoch: 9.08 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6736218417242663		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 0.6736218417242663 | validation: 2.4402984598040383]
	TIME [epoch: 9.1 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.730830291113167		[learning rate: 0.00993]
	Learning Rate: 0.00992996
	LOSS [training: 1.730830291113167 | validation: 0.7129222158232487]
	TIME [epoch: 9.08 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5887105382768054		[learning rate: 0.0099059]
	Learning Rate: 0.00990592
	LOSS [training: 0.5887105382768054 | validation: 0.7434608328599311]
	TIME [epoch: 9.08 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5879308158133906		[learning rate: 0.0098819]
	Learning Rate: 0.00988194
	LOSS [training: 0.5879308158133906 | validation: 0.500930137143177]
	TIME [epoch: 9.06 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.63962501433808		[learning rate: 0.009858]
	Learning Rate: 0.00985801
	LOSS [training: 0.63962501433808 | validation: 0.8646745803154833]
	TIME [epoch: 9.08 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4510739805330676		[learning rate: 0.0098341]
	Learning Rate: 0.00983415
	LOSS [training: 0.4510739805330676 | validation: 0.43927865479506806]
	TIME [epoch: 9.08 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45035687783447476		[learning rate: 0.0098103]
	Learning Rate: 0.00981034
	LOSS [training: 0.45035687783447476 | validation: 0.5446686281134595]
	TIME [epoch: 9.07 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48774949947011015		[learning rate: 0.0097866]
	Learning Rate: 0.00978659
	LOSS [training: 0.48774949947011015 | validation: 0.5896768540865597]
	TIME [epoch: 9.08 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6406023948608426		[learning rate: 0.0097629]
	Learning Rate: 0.0097629
	LOSS [training: 0.6406023948608426 | validation: 0.47223718719972807]
	TIME [epoch: 9.06 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5599169663296963		[learning rate: 0.0097393]
	Learning Rate: 0.00973927
	LOSS [training: 0.5599169663296963 | validation: 0.4621885689461992]
	TIME [epoch: 9.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5922618350187625		[learning rate: 0.0097157]
	Learning Rate: 0.00971569
	LOSS [training: 0.5922618350187625 | validation: 0.4374737631117994]
	TIME [epoch: 9.09 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6714991171127407		[learning rate: 0.0096922]
	Learning Rate: 0.00969217
	LOSS [training: 0.6714991171127407 | validation: 1.715691594718867]
	TIME [epoch: 9.08 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8692358281695794		[learning rate: 0.0096687]
	Learning Rate: 0.00966871
	LOSS [training: 0.8692358281695794 | validation: 0.41141991495952723]
	TIME [epoch: 9.08 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.550394482645631		[learning rate: 0.0096453]
	Learning Rate: 0.0096453
	LOSS [training: 0.550394482645631 | validation: 0.4555375289016413]
	TIME [epoch: 9.09 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5418231696088462		[learning rate: 0.009622]
	Learning Rate: 0.00962195
	LOSS [training: 0.5418231696088462 | validation: 0.5465215929286467]
	TIME [epoch: 9.1 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7224157003239258		[learning rate: 0.0095987]
	Learning Rate: 0.00959866
	LOSS [training: 0.7224157003239258 | validation: 0.3432752774164688]
	TIME [epoch: 9.08 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6501268233109532		[learning rate: 0.0095754]
	Learning Rate: 0.00957542
	LOSS [training: 0.6501268233109532 | validation: 0.37106777780266675]
	TIME [epoch: 9.07 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43593993809428594		[learning rate: 0.0095522]
	Learning Rate: 0.00955224
	LOSS [training: 0.43593993809428594 | validation: 0.34932270701920076]
	TIME [epoch: 9.08 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45621400625157776		[learning rate: 0.0095291]
	Learning Rate: 0.00952912
	LOSS [training: 0.45621400625157776 | validation: 0.4888050103002344]
	TIME [epoch: 9.09 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5356020334203376		[learning rate: 0.009506]
	Learning Rate: 0.00950605
	LOSS [training: 0.5356020334203376 | validation: 0.45767054054140566]
	TIME [epoch: 9.08 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46887240375191935		[learning rate: 0.009483]
	Learning Rate: 0.00948303
	LOSS [training: 0.46887240375191935 | validation: 0.40743731946962003]
	TIME [epoch: 9.08 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5116934545514373		[learning rate: 0.0094601]
	Learning Rate: 0.00946008
	LOSS [training: 0.5116934545514373 | validation: 0.4335135566675311]
	TIME [epoch: 9.08 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5582761218311935		[learning rate: 0.0094372]
	Learning Rate: 0.00943718
	LOSS [training: 0.5582761218311935 | validation: 0.4219617616260132]
	TIME [epoch: 9.08 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5214940900141801		[learning rate: 0.0094143]
	Learning Rate: 0.00941433
	LOSS [training: 0.5214940900141801 | validation: 0.4863232648838508]
	TIME [epoch: 9.1 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46229052575496227		[learning rate: 0.0093915]
	Learning Rate: 0.00939154
	LOSS [training: 0.46229052575496227 | validation: 0.40346508760056077]
	TIME [epoch: 9.08 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4258639505088029		[learning rate: 0.0093688]
	Learning Rate: 0.00936881
	LOSS [training: 0.4258639505088029 | validation: 0.4260697072242979]
	TIME [epoch: 9.08 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5396662742814919		[learning rate: 0.0093461]
	Learning Rate: 0.00934612
	LOSS [training: 0.5396662742814919 | validation: 0.4185649003346093]
	TIME [epoch: 9.09 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4740119975391778		[learning rate: 0.0093235]
	Learning Rate: 0.0093235
	LOSS [training: 0.4740119975391778 | validation: 0.6260434644155295]
	TIME [epoch: 9.09 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47911940703957157		[learning rate: 0.0093009]
	Learning Rate: 0.00930093
	LOSS [training: 0.47911940703957157 | validation: 0.3254555699747075]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4488991512383773		[learning rate: 0.0092784]
	Learning Rate: 0.00927841
	LOSS [training: 0.4488991512383773 | validation: 0.6191646476158467]
	TIME [epoch: 9.06 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5924308452421225		[learning rate: 0.009256]
	Learning Rate: 0.00925595
	LOSS [training: 0.5924308452421225 | validation: 0.3490070434948108]
	TIME [epoch: 9.07 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.523078422417167		[learning rate: 0.0092335]
	Learning Rate: 0.00923354
	LOSS [training: 0.523078422417167 | validation: 0.44896046837733167]
	TIME [epoch: 9.06 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4464105102806292		[learning rate: 0.0092112]
	Learning Rate: 0.00921119
	LOSS [training: 0.4464105102806292 | validation: 0.39663650792325983]
	TIME [epoch: 9.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46928709032079363		[learning rate: 0.0091889]
	Learning Rate: 0.00918889
	LOSS [training: 0.46928709032079363 | validation: 0.3723796397512107]
	TIME [epoch: 9.07 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46980550908104035		[learning rate: 0.0091666]
	Learning Rate: 0.00916665
	LOSS [training: 0.46980550908104035 | validation: 0.561643190538317]
	TIME [epoch: 9.06 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5895296381737012		[learning rate: 0.0091445]
	Learning Rate: 0.00914446
	LOSS [training: 0.5895296381737012 | validation: 0.5339180834895327]
	TIME [epoch: 9.07 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7539208069661185		[learning rate: 0.0091223]
	Learning Rate: 0.00912232
	LOSS [training: 0.7539208069661185 | validation: 0.6288393877374239]
	TIME [epoch: 9.06 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.457895008940263		[learning rate: 0.0091002]
	Learning Rate: 0.00910024
	LOSS [training: 0.457895008940263 | validation: 0.3341422672526392]
	TIME [epoch: 9.09 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.445971961236644		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 0.445971961236644 | validation: 0.3665176034377309]
	TIME [epoch: 9.07 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6032971963034368		[learning rate: 0.0090562]
	Learning Rate: 0.00905623
	LOSS [training: 0.6032971963034368 | validation: 0.33357192523631285]
	TIME [epoch: 9.08 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4275120377463265		[learning rate: 0.0090343]
	Learning Rate: 0.0090343
	LOSS [training: 0.4275120377463265 | validation: 0.3778561749624801]
	TIME [epoch: 9.08 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47245979999517684		[learning rate: 0.0090124]
	Learning Rate: 0.00901243
	LOSS [training: 0.47245979999517684 | validation: 0.40946385717020606]
	TIME [epoch: 9.09 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5842565445245309		[learning rate: 0.0089906]
	Learning Rate: 0.00899062
	LOSS [training: 0.5842565445245309 | validation: 0.8091335957331357]
	TIME [epoch: 9.09 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5323888888327211		[learning rate: 0.0089689]
	Learning Rate: 0.00896885
	LOSS [training: 0.5323888888327211 | validation: 0.5197853018015587]
	TIME [epoch: 9.07 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6281587044907215		[learning rate: 0.0089471]
	Learning Rate: 0.00894714
	LOSS [training: 0.6281587044907215 | validation: 0.4320598397303579]
	TIME [epoch: 9.07 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46899166473702625		[learning rate: 0.0089255]
	Learning Rate: 0.00892548
	LOSS [training: 0.46899166473702625 | validation: 0.41035006151179276]
	TIME [epoch: 9.06 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45089403944271067		[learning rate: 0.0089039]
	Learning Rate: 0.00890387
	LOSS [training: 0.45089403944271067 | validation: 0.49176594462697143]
	TIME [epoch: 9.07 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.548633168661032		[learning rate: 0.0088823]
	Learning Rate: 0.00888232
	LOSS [training: 0.548633168661032 | validation: 0.4986590080796673]
	TIME [epoch: 9.07 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5794170900153169		[learning rate: 0.0088608]
	Learning Rate: 0.00886082
	LOSS [training: 0.5794170900153169 | validation: 0.421193976255688]
	TIME [epoch: 9.06 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4537046449863967		[learning rate: 0.0088394]
	Learning Rate: 0.00883936
	LOSS [training: 0.4537046449863967 | validation: 0.36526783286935116]
	TIME [epoch: 9.06 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4343049648844213		[learning rate: 0.008818]
	Learning Rate: 0.00881797
	LOSS [training: 0.4343049648844213 | validation: 0.3969507595153049]
	TIME [epoch: 9.09 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3821496804237158		[learning rate: 0.0087966]
	Learning Rate: 0.00879662
	LOSS [training: 0.3821496804237158 | validation: 0.42151166339365187]
	TIME [epoch: 9.07 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4708232471659059		[learning rate: 0.0087753]
	Learning Rate: 0.00877532
	LOSS [training: 0.4708232471659059 | validation: 0.4862113900873314]
	TIME [epoch: 9.07 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6183891296307024		[learning rate: 0.0087541]
	Learning Rate: 0.00875408
	LOSS [training: 0.6183891296307024 | validation: 0.506122955833776]
	TIME [epoch: 9.08 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40451069278105506		[learning rate: 0.0087329]
	Learning Rate: 0.00873289
	LOSS [training: 0.40451069278105506 | validation: 0.6131177174265767]
	TIME [epoch: 9.07 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42588993580031786		[learning rate: 0.0087117]
	Learning Rate: 0.00871175
	LOSS [training: 0.42588993580031786 | validation: 0.548831763991823]
	TIME [epoch: 9.09 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4901806183723507		[learning rate: 0.0086907]
	Learning Rate: 0.00869066
	LOSS [training: 0.4901806183723507 | validation: 0.5538009710493987]
	TIME [epoch: 9.07 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40063565045444066		[learning rate: 0.0086696]
	Learning Rate: 0.00866962
	LOSS [training: 0.40063565045444066 | validation: 0.5210171783851629]
	TIME [epoch: 9.06 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4341413417617943		[learning rate: 0.0086486]
	Learning Rate: 0.00864863
	LOSS [training: 0.4341413417617943 | validation: 0.32740854214785164]
	TIME [epoch: 9.06 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5291626172694602		[learning rate: 0.0086277]
	Learning Rate: 0.00862769
	LOSS [training: 0.5291626172694602 | validation: 0.347374587738412]
	TIME [epoch: 9.07 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.527317848064291		[learning rate: 0.0086068]
	Learning Rate: 0.00860681
	LOSS [training: 0.527317848064291 | validation: 0.3502221885455259]
	TIME [epoch: 9.09 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.452904303703663		[learning rate: 0.008586]
	Learning Rate: 0.00858597
	LOSS [training: 0.452904303703663 | validation: 0.9277814385607566]
	TIME [epoch: 9.07 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5635720477240302		[learning rate: 0.0085652]
	Learning Rate: 0.00856519
	LOSS [training: 0.5635720477240302 | validation: 0.5599177566862283]
	TIME [epoch: 9.06 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4230701032195934		[learning rate: 0.0085445]
	Learning Rate: 0.00854445
	LOSS [training: 0.4230701032195934 | validation: 0.36795314349232566]
	TIME [epoch: 9.06 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4652212094870107		[learning rate: 0.0085238]
	Learning Rate: 0.00852377
	LOSS [training: 0.4652212094870107 | validation: 0.41531853428144494]
	TIME [epoch: 9.08 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4171219857446881		[learning rate: 0.0085031]
	Learning Rate: 0.00850313
	LOSS [training: 0.4171219857446881 | validation: 0.32053257701573434]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4908220568263437		[learning rate: 0.0084825]
	Learning Rate: 0.00848255
	LOSS [training: 0.4908220568263437 | validation: 0.3997092345220813]
	TIME [epoch: 9.06 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42640152419122657		[learning rate: 0.008462]
	Learning Rate: 0.00846201
	LOSS [training: 0.42640152419122657 | validation: 0.42336745949556304]
	TIME [epoch: 9.06 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7042720827645601		[learning rate: 0.0084415]
	Learning Rate: 0.00844153
	LOSS [training: 0.7042720827645601 | validation: 0.7220724411973272]
	TIME [epoch: 9.06 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3280840858525365		[learning rate: 0.0084211]
	Learning Rate: 0.00842109
	LOSS [training: 1.3280840858525365 | validation: 0.5566450555113037]
	TIME [epoch: 9.08 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46609730286833306		[learning rate: 0.0084007]
	Learning Rate: 0.00840071
	LOSS [training: 0.46609730286833306 | validation: 0.39884157490160027]
	TIME [epoch: 9.05 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4339624443681121		[learning rate: 0.0083804]
	Learning Rate: 0.00838037
	LOSS [training: 0.4339624443681121 | validation: 0.6571520612210902]
	TIME [epoch: 9.06 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5600142307860259		[learning rate: 0.0083601]
	Learning Rate: 0.00836008
	LOSS [training: 0.5600142307860259 | validation: 0.9082673654228494]
	TIME [epoch: 9.05 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.676910098099429		[learning rate: 0.0083398]
	Learning Rate: 0.00833984
	LOSS [training: 0.676910098099429 | validation: 0.8778639211842885]
	TIME [epoch: 9.08 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5275346226138368		[learning rate: 0.0083197]
	Learning Rate: 0.00831965
	LOSS [training: 0.5275346226138368 | validation: 0.34360272157222016]
	TIME [epoch: 9.06 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4033934283360871		[learning rate: 0.0082995]
	Learning Rate: 0.00829951
	LOSS [training: 0.4033934283360871 | validation: 0.39444861838196843]
	TIME [epoch: 9.06 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4299089553063887		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.4299089553063887 | validation: 0.6564389738082049]
	TIME [epoch: 9.06 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43560649683244135		[learning rate: 0.0082594]
	Learning Rate: 0.00825938
	LOSS [training: 0.43560649683244135 | validation: 0.33600139558866327]
	TIME [epoch: 9.06 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36675615411500057		[learning rate: 0.0082394]
	Learning Rate: 0.00823938
	LOSS [training: 0.36675615411500057 | validation: 0.37080914852045266]
	TIME [epoch: 9.09 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42283552571035077		[learning rate: 0.0082194]
	Learning Rate: 0.00821944
	LOSS [training: 0.42283552571035077 | validation: 0.43361735606379126]
	TIME [epoch: 9.08 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41992070617916477		[learning rate: 0.0081995]
	Learning Rate: 0.00819954
	LOSS [training: 0.41992070617916477 | validation: 0.35215886130980095]
	TIME [epoch: 9.07 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.524146111075456		[learning rate: 0.0081797]
	Learning Rate: 0.00817969
	LOSS [training: 0.524146111075456 | validation: 0.38952070249875004]
	TIME [epoch: 9.08 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3754569710197102		[learning rate: 0.0081599]
	Learning Rate: 0.00815989
	LOSS [training: 0.3754569710197102 | validation: 0.5040465612429601]
	TIME [epoch: 9.07 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42683234781439683		[learning rate: 0.0081401]
	Learning Rate: 0.00814013
	LOSS [training: 0.42683234781439683 | validation: 0.7373719604694058]
	TIME [epoch: 9.07 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45076508448353725		[learning rate: 0.0081204]
	Learning Rate: 0.00812043
	LOSS [training: 0.45076508448353725 | validation: 0.47405240011004934]
	TIME [epoch: 9.06 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5293882593075407		[learning rate: 0.0081008]
	Learning Rate: 0.00810077
	LOSS [training: 0.5293882593075407 | validation: 0.7078431582099002]
	TIME [epoch: 9.07 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5032299677829386		[learning rate: 0.0080812]
	Learning Rate: 0.00808116
	LOSS [training: 0.5032299677829386 | validation: 0.591219454059198]
	TIME [epoch: 9.06 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5129089836428518		[learning rate: 0.0080616]
	Learning Rate: 0.0080616
	LOSS [training: 0.5129089836428518 | validation: 0.3850724469310524]
	TIME [epoch: 9.08 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47162165641703246		[learning rate: 0.0080421]
	Learning Rate: 0.00804208
	LOSS [training: 0.47162165641703246 | validation: 0.39188309096670015]
	TIME [epoch: 9.07 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44504247655076173		[learning rate: 0.0080226]
	Learning Rate: 0.00802261
	LOSS [training: 0.44504247655076173 | validation: 0.48825554708550084]
	TIME [epoch: 9.06 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5356724992351576		[learning rate: 0.0080032]
	Learning Rate: 0.00800319
	LOSS [training: 0.5356724992351576 | validation: 0.43642681984005993]
	TIME [epoch: 9.06 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43137680794426264		[learning rate: 0.0079838]
	Learning Rate: 0.00798382
	LOSS [training: 0.43137680794426264 | validation: 0.38850971008641716]
	TIME [epoch: 9.07 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36463844051775224		[learning rate: 0.0079645]
	Learning Rate: 0.00796449
	LOSS [training: 0.36463844051775224 | validation: 0.5202136119028202]
	TIME [epoch: 9.1 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5519353153637108		[learning rate: 0.0079452]
	Learning Rate: 0.00794521
	LOSS [training: 0.5519353153637108 | validation: 0.7347416237892048]
	TIME [epoch: 9.06 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.480450728466181		[learning rate: 0.007926]
	Learning Rate: 0.00792597
	LOSS [training: 0.480450728466181 | validation: 0.4475595893265135]
	TIME [epoch: 9.07 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40940182571311984		[learning rate: 0.0079068]
	Learning Rate: 0.00790679
	LOSS [training: 0.40940182571311984 | validation: 0.3923927993414603]
	TIME [epoch: 9.06 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43775059513735054		[learning rate: 0.0078876]
	Learning Rate: 0.00788765
	LOSS [training: 0.43775059513735054 | validation: 0.3346557825912986]
	TIME [epoch: 9.09 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3547252062771171		[learning rate: 0.0078685]
	Learning Rate: 0.00786855
	LOSS [training: 0.3547252062771171 | validation: 0.5803463461948353]
	TIME [epoch: 9.07 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37345404189517206		[learning rate: 0.0078495]
	Learning Rate: 0.0078495
	LOSS [training: 0.37345404189517206 | validation: 0.3501362333479844]
	TIME [epoch: 9.06 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4027218515984329		[learning rate: 0.0078305]
	Learning Rate: 0.0078305
	LOSS [training: 0.4027218515984329 | validation: 0.7191263487545465]
	TIME [epoch: 9.07 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4989686199646334		[learning rate: 0.0078115]
	Learning Rate: 0.00781154
	LOSS [training: 0.4989686199646334 | validation: 0.464384779196433]
	TIME [epoch: 9.07 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4216715348973724		[learning rate: 0.0077926]
	Learning Rate: 0.00779263
	LOSS [training: 0.4216715348973724 | validation: 0.3224427664945222]
	TIME [epoch: 9.09 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38458886550138227		[learning rate: 0.0077738]
	Learning Rate: 0.00777377
	LOSS [training: 0.38458886550138227 | validation: 0.2473106407095029]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.336017458117714		[learning rate: 0.0077549]
	Learning Rate: 0.00775495
	LOSS [training: 0.336017458117714 | validation: 0.4027349267138458]
	TIME [epoch: 9.08 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4519436451254178		[learning rate: 0.0077362]
	Learning Rate: 0.00773618
	LOSS [training: 0.4519436451254178 | validation: 0.3499097612191746]
	TIME [epoch: 9.08 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.409940105394029		[learning rate: 0.0077174]
	Learning Rate: 0.00771745
	LOSS [training: 0.409940105394029 | validation: 0.5043274502501818]
	TIME [epoch: 9.1 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4594533712006369		[learning rate: 0.0076988]
	Learning Rate: 0.00769876
	LOSS [training: 0.4594533712006369 | validation: 0.35378369259871556]
	TIME [epoch: 9.1 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3846887362841445		[learning rate: 0.0076801]
	Learning Rate: 0.00768013
	LOSS [training: 0.3846887362841445 | validation: 0.2957426221916942]
	TIME [epoch: 9.09 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37574316627046417		[learning rate: 0.0076615]
	Learning Rate: 0.00766153
	LOSS [training: 0.37574316627046417 | validation: 0.6054627338435243]
	TIME [epoch: 9.08 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49847865553183013		[learning rate: 0.007643]
	Learning Rate: 0.00764299
	LOSS [training: 0.49847865553183013 | validation: 0.6082837830541333]
	TIME [epoch: 9.08 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5008882747278873		[learning rate: 0.0076245]
	Learning Rate: 0.00762449
	LOSS [training: 0.5008882747278873 | validation: 0.4648398518063642]
	TIME [epoch: 9.1 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7435326016517978		[learning rate: 0.007606]
	Learning Rate: 0.00760603
	LOSS [training: 0.7435326016517978 | validation: 0.3533180870899906]
	TIME [epoch: 9.09 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40632653787928474		[learning rate: 0.0075876]
	Learning Rate: 0.00758761
	LOSS [training: 0.40632653787928474 | validation: 0.506551595550428]
	TIME [epoch: 9.09 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5969165690454495		[learning rate: 0.0075692]
	Learning Rate: 0.00756925
	LOSS [training: 0.5969165690454495 | validation: 0.6715842069519509]
	TIME [epoch: 9.09 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.508857028436451		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 0.508857028436451 | validation: 0.3781952212742361]
	TIME [epoch: 9.1 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6116369735331737		[learning rate: 0.0075326]
	Learning Rate: 0.00753264
	LOSS [training: 0.6116369735331737 | validation: 0.8683381797240383]
	TIME [epoch: 9.09 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4518775314996429		[learning rate: 0.0075144]
	Learning Rate: 0.00751441
	LOSS [training: 0.4518775314996429 | validation: 0.4006323936591682]
	TIME [epoch: 9.09 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40719790370542686		[learning rate: 0.0074962]
	Learning Rate: 0.00749622
	LOSS [training: 0.40719790370542686 | validation: 0.3175768851427432]
	TIME [epoch: 9.09 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.413488126720441		[learning rate: 0.0074781]
	Learning Rate: 0.00747807
	LOSS [training: 0.413488126720441 | validation: 0.31230801993223767]
	TIME [epoch: 9.09 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3778616395893927		[learning rate: 0.00746]
	Learning Rate: 0.00745997
	LOSS [training: 0.3778616395893927 | validation: 0.35575768346702596]
	TIME [epoch: 9.11 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42528774349618326		[learning rate: 0.0074419]
	Learning Rate: 0.00744191
	LOSS [training: 0.42528774349618326 | validation: 0.4228585304856817]
	TIME [epoch: 9.1 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3991972213316855		[learning rate: 0.0074239]
	Learning Rate: 0.00742389
	LOSS [training: 0.3991972213316855 | validation: 0.46881278943907495]
	TIME [epoch: 9.09 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.397524872474783		[learning rate: 0.0074059]
	Learning Rate: 0.00740592
	LOSS [training: 0.397524872474783 | validation: 0.35130935004013386]
	TIME [epoch: 9.08 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37458597516577885		[learning rate: 0.007388]
	Learning Rate: 0.00738799
	LOSS [training: 0.37458597516577885 | validation: 0.45960916029490473]
	TIME [epoch: 9.09 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3563708049666019		[learning rate: 0.0073701]
	Learning Rate: 0.00737011
	LOSS [training: 0.3563708049666019 | validation: 0.40170042755638047]
	TIME [epoch: 9.12 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4933803184887334		[learning rate: 0.0073523]
	Learning Rate: 0.00735226
	LOSS [training: 0.4933803184887334 | validation: 0.574662142871008]
	TIME [epoch: 9.08 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5027872641525727		[learning rate: 0.0073345]
	Learning Rate: 0.00733446
	LOSS [training: 0.5027872641525727 | validation: 0.38830702557368757]
	TIME [epoch: 9.09 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4718889660929794		[learning rate: 0.0073167]
	Learning Rate: 0.00731671
	LOSS [training: 0.4718889660929794 | validation: 0.4205788884076891]
	TIME [epoch: 9.08 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.682759110655751		[learning rate: 0.007299]
	Learning Rate: 0.007299
	LOSS [training: 0.682759110655751 | validation: 3.428727624720612]
	TIME [epoch: 9.1 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5314501918505283		[learning rate: 0.0072813]
	Learning Rate: 0.00728133
	LOSS [training: 1.5314501918505283 | validation: 0.40853051923388384]
	TIME [epoch: 9.09 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46737614640914515		[learning rate: 0.0072637]
	Learning Rate: 0.0072637
	LOSS [training: 0.46737614640914515 | validation: 0.6508825078705424]
	TIME [epoch: 9.08 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48327285344758675		[learning rate: 0.0072461]
	Learning Rate: 0.00724612
	LOSS [training: 0.48327285344758675 | validation: 0.3528167189007416]
	TIME [epoch: 9.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5038885343959313		[learning rate: 0.0072286]
	Learning Rate: 0.00722857
	LOSS [training: 0.5038885343959313 | validation: 1.3005051334201205]
	TIME [epoch: 9.1 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6491278627846899		[learning rate: 0.0072111]
	Learning Rate: 0.00721107
	LOSS [training: 0.6491278627846899 | validation: 0.40711738340345915]
	TIME [epoch: 9.11 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39305897677883295		[learning rate: 0.0071936]
	Learning Rate: 0.00719362
	LOSS [training: 0.39305897677883295 | validation: 0.4860074439987283]
	TIME [epoch: 9.09 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43022151198465775		[learning rate: 0.0071762]
	Learning Rate: 0.0071762
	LOSS [training: 0.43022151198465775 | validation: 0.3579477910423504]
	TIME [epoch: 9.09 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3849257800503464		[learning rate: 0.0071588]
	Learning Rate: 0.00715883
	LOSS [training: 0.3849257800503464 | validation: 0.31972573522329095]
	TIME [epoch: 9.09 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36862521585338465		[learning rate: 0.0071415]
	Learning Rate: 0.0071415
	LOSS [training: 0.36862521585338465 | validation: 0.380583504577478]
	TIME [epoch: 9.11 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3767644837343981		[learning rate: 0.0071242]
	Learning Rate: 0.00712421
	LOSS [training: 0.3767644837343981 | validation: 0.2650336621207973]
	TIME [epoch: 9.09 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3882362234166835		[learning rate: 0.007107]
	Learning Rate: 0.00710696
	LOSS [training: 0.3882362234166835 | validation: 0.33347669704048866]
	TIME [epoch: 9.09 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5548533798381887		[learning rate: 0.0070898]
	Learning Rate: 0.00708976
	LOSS [training: 0.5548533798381887 | validation: 0.8360118612857729]
	TIME [epoch: 9.09 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5107895862196916		[learning rate: 0.0070726]
	Learning Rate: 0.0070726
	LOSS [training: 0.5107895862196916 | validation: 0.35731502582807173]
	TIME [epoch: 9.09 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4224832023530576		[learning rate: 0.0070555]
	Learning Rate: 0.00705548
	LOSS [training: 0.4224832023530576 | validation: 0.5506327960964923]
	TIME [epoch: 9.1 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.443698278712927		[learning rate: 0.0070384]
	Learning Rate: 0.0070384
	LOSS [training: 0.443698278712927 | validation: 0.36862123255533974]
	TIME [epoch: 9.09 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36998444224191873		[learning rate: 0.0070214]
	Learning Rate: 0.00702136
	LOSS [training: 0.36998444224191873 | validation: 0.35816414868408364]
	TIME [epoch: 9.09 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3964312994900171		[learning rate: 0.0070044]
	Learning Rate: 0.00700436
	LOSS [training: 0.3964312994900171 | validation: 0.5100575867212607]
	TIME [epoch: 9.09 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3757505252995802		[learning rate: 0.0069874]
	Learning Rate: 0.0069874
	LOSS [training: 0.3757505252995802 | validation: 0.2923211890570096]
	TIME [epoch: 9.1 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35816602685171106		[learning rate: 0.0069705]
	Learning Rate: 0.00697049
	LOSS [training: 0.35816602685171106 | validation: 0.3238877072506855]
	TIME [epoch: 9.1 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33401549248936907		[learning rate: 0.0069536]
	Learning Rate: 0.00695361
	LOSS [training: 0.33401549248936907 | validation: 0.3566720011628729]
	TIME [epoch: 9.09 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39080385507550924		[learning rate: 0.0069368]
	Learning Rate: 0.00693678
	LOSS [training: 0.39080385507550924 | validation: 0.42408322194596004]
	TIME [epoch: 9.09 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.549760397108477		[learning rate: 0.00692]
	Learning Rate: 0.00691999
	LOSS [training: 0.549760397108477 | validation: 0.4026275840762948]
	TIME [epoch: 9.09 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43349851676388845		[learning rate: 0.0069032]
	Learning Rate: 0.00690323
	LOSS [training: 0.43349851676388845 | validation: 0.307205256723065]
	TIME [epoch: 9.11 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3463910852622898		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 0.3463910852622898 | validation: 0.35743772494896003]
	TIME [epoch: 9.09 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4194529785306097		[learning rate: 0.0068699]
	Learning Rate: 0.00686985
	LOSS [training: 0.4194529785306097 | validation: 0.32720339111007113]
	TIME [epoch: 9.08 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41401387422681213		[learning rate: 0.0068532]
	Learning Rate: 0.00685322
	LOSS [training: 0.41401387422681213 | validation: 0.30537665104065276]
	TIME [epoch: 9.09 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3658467489586129		[learning rate: 0.0068366]
	Learning Rate: 0.00683663
	LOSS [training: 0.3658467489586129 | validation: 0.3227409166759726]
	TIME [epoch: 9.09 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.486679943038481		[learning rate: 0.0068201]
	Learning Rate: 0.00682008
	LOSS [training: 0.486679943038481 | validation: 0.7547342486713782]
	TIME [epoch: 9.11 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.581585246626039		[learning rate: 0.0068036]
	Learning Rate: 0.00680357
	LOSS [training: 0.581585246626039 | validation: 0.4568460816433383]
	TIME [epoch: 9.08 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4537458446944453		[learning rate: 0.0067871]
	Learning Rate: 0.0067871
	LOSS [training: 0.4537458446944453 | validation: 0.49105323786842825]
	TIME [epoch: 9.09 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39532883912287364		[learning rate: 0.0067707]
	Learning Rate: 0.00677067
	LOSS [training: 0.39532883912287364 | validation: 0.5028410910118151]
	TIME [epoch: 9.09 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4346533366901422		[learning rate: 0.0067543]
	Learning Rate: 0.00675428
	LOSS [training: 0.4346533366901422 | validation: 0.3803619318322652]
	TIME [epoch: 9.11 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37707750367620185		[learning rate: 0.0067379]
	Learning Rate: 0.00673793
	LOSS [training: 0.37707750367620185 | validation: 0.5539967295356583]
	TIME [epoch: 9.09 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5256991660354476		[learning rate: 0.0067216]
	Learning Rate: 0.00672162
	LOSS [training: 0.5256991660354476 | validation: 0.5603036228908481]
	TIME [epoch: 9.09 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4669929443053668		[learning rate: 0.0067053]
	Learning Rate: 0.00670534
	LOSS [training: 0.4669929443053668 | validation: 0.48947815297756037]
	TIME [epoch: 9.09 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39942529945471483		[learning rate: 0.0066891]
	Learning Rate: 0.00668911
	LOSS [training: 0.39942529945471483 | validation: 0.4649314084315538]
	TIME [epoch: 9.08 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43456615221097544		[learning rate: 0.0066729]
	Learning Rate: 0.00667292
	LOSS [training: 0.43456615221097544 | validation: 0.360758567887038]
	TIME [epoch: 9.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36780390502902816		[learning rate: 0.0066568]
	Learning Rate: 0.00665676
	LOSS [training: 0.36780390502902816 | validation: 0.3440750154892248]
	TIME [epoch: 9.08 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.363288297787011		[learning rate: 0.0066406]
	Learning Rate: 0.00664065
	LOSS [training: 0.363288297787011 | validation: 0.49636829528775805]
	TIME [epoch: 9.08 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.615419361756062		[learning rate: 0.0066246]
	Learning Rate: 0.00662457
	LOSS [training: 0.615419361756062 | validation: 0.3226680509301338]
	TIME [epoch: 9.08 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3140037567189428		[learning rate: 0.0066085]
	Learning Rate: 0.00660854
	LOSS [training: 0.3140037567189428 | validation: 0.5822555066762297]
	TIME [epoch: 9.11 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6010680145638456		[learning rate: 0.0065925]
	Learning Rate: 0.00659254
	LOSS [training: 0.6010680145638456 | validation: 0.35277567813469013]
	TIME [epoch: 9.09 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3329150024908906		[learning rate: 0.0065766]
	Learning Rate: 0.00657658
	LOSS [training: 0.3329150024908906 | validation: 0.4399100044223832]
	TIME [epoch: 9.09 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4124418375964094		[learning rate: 0.0065607]
	Learning Rate: 0.00656066
	LOSS [training: 0.4124418375964094 | validation: 0.5167970944931126]
	TIME [epoch: 9.09 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40672730126117684		[learning rate: 0.0065448]
	Learning Rate: 0.00654477
	LOSS [training: 0.40672730126117684 | validation: 0.36124378268171986]
	TIME [epoch: 9.08 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5363753571966512		[learning rate: 0.0065289]
	Learning Rate: 0.00652893
	LOSS [training: 0.5363753571966512 | validation: 0.563586051650399]
	TIME [epoch: 9.11 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5107389808003913		[learning rate: 0.0065131]
	Learning Rate: 0.00651313
	LOSS [training: 0.5107389808003913 | validation: 1.1023798866988073]
	TIME [epoch: 9.09 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49442701518953136		[learning rate: 0.0064974]
	Learning Rate: 0.00649736
	LOSS [training: 0.49442701518953136 | validation: 0.36131209354735966]
	TIME [epoch: 9.08 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4272434608594654		[learning rate: 0.0064816]
	Learning Rate: 0.00648163
	LOSS [training: 0.4272434608594654 | validation: 0.7197674213679809]
	TIME [epoch: 9.09 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5322184464797467		[learning rate: 0.0064659]
	Learning Rate: 0.00646594
	LOSS [training: 0.5322184464797467 | validation: 0.4974033173857662]
	TIME [epoch: 9.08 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37099638668639223		[learning rate: 0.0064503]
	Learning Rate: 0.00645029
	LOSS [training: 0.37099638668639223 | validation: 0.30724578728602514]
	TIME [epoch: 9.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5973527581379611		[learning rate: 0.0064347]
	Learning Rate: 0.00643467
	LOSS [training: 0.5973527581379611 | validation: 0.7721006670702829]
	TIME [epoch: 9.09 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47688025355671304		[learning rate: 0.0064191]
	Learning Rate: 0.00641909
	LOSS [training: 0.47688025355671304 | validation: 0.3342815096402855]
	TIME [epoch: 9.09 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36813574542804145		[learning rate: 0.0064036]
	Learning Rate: 0.00640355
	LOSS [training: 0.36813574542804145 | validation: 0.3346237817015794]
	TIME [epoch: 9.08 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4041733265336795		[learning rate: 0.0063881]
	Learning Rate: 0.00638805
	LOSS [training: 0.4041733265336795 | validation: 0.6089931928556168]
	TIME [epoch: 9.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6607778672724903		[learning rate: 0.0063726]
	Learning Rate: 0.00637259
	LOSS [training: 0.6607778672724903 | validation: 0.7969780419261872]
	TIME [epoch: 9.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6967642650380406		[learning rate: 0.0063572]
	Learning Rate: 0.00635716
	LOSS [training: 0.6967642650380406 | validation: 0.2987704253906065]
	TIME [epoch: 9.09 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42623470716362527		[learning rate: 0.0063418]
	Learning Rate: 0.00634177
	LOSS [training: 0.42623470716362527 | validation: 0.3748935650863461]
	TIME [epoch: 9.09 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41504008844418844		[learning rate: 0.0063264]
	Learning Rate: 0.00632642
	LOSS [training: 0.41504008844418844 | validation: 0.5450196009721026]
	TIME [epoch: 9.09 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5200822512797237		[learning rate: 0.0063111]
	Learning Rate: 0.0063111
	LOSS [training: 0.5200822512797237 | validation: 0.6138991806916454]
	TIME [epoch: 9.11 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.697899213542056		[learning rate: 0.0062958]
	Learning Rate: 0.00629582
	LOSS [training: 0.697899213542056 | validation: 0.6604330892643078]
	TIME [epoch: 9.09 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48909709652593064		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.48909709652593064 | validation: 0.33894942168295017]
	TIME [epoch: 9.09 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4044127451106817		[learning rate: 0.0062654]
	Learning Rate: 0.00626538
	LOSS [training: 0.4044127451106817 | validation: 0.4316201835564537]
	TIME [epoch: 9.09 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48085820662933		[learning rate: 0.0062502]
	Learning Rate: 0.00625021
	LOSS [training: 0.48085820662933 | validation: 0.9155145090678722]
	TIME [epoch: 9.11 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5119537276989774		[learning rate: 0.0062351]
	Learning Rate: 0.00623508
	LOSS [training: 0.5119537276989774 | validation: 0.38494422420636526]
	TIME [epoch: 9.09 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3684457819696799		[learning rate: 0.00622]
	Learning Rate: 0.00621999
	LOSS [training: 0.3684457819696799 | validation: 0.34364094719401694]
	TIME [epoch: 9.09 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5143932256477843		[learning rate: 0.0062049]
	Learning Rate: 0.00620493
	LOSS [training: 0.5143932256477843 | validation: 0.8220930138352174]
	TIME [epoch: 9.09 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4426154545986578		[learning rate: 0.0061899]
	Learning Rate: 0.00618991
	LOSS [training: 0.4426154545986578 | validation: 0.29032428300675495]
	TIME [epoch: 9.09 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3411746491762047		[learning rate: 0.0061749]
	Learning Rate: 0.00617492
	LOSS [training: 0.3411746491762047 | validation: 0.33078157319447743]
	TIME [epoch: 9.11 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3506410381846144		[learning rate: 0.00616]
	Learning Rate: 0.00615997
	LOSS [training: 0.3506410381846144 | validation: 0.46355192888040697]
	TIME [epoch: 9.09 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3438211575212463		[learning rate: 0.0061451]
	Learning Rate: 0.00614506
	LOSS [training: 0.3438211575212463 | validation: 0.2832189300934015]
	TIME [epoch: 9.09 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4295716383582219		[learning rate: 0.0061302]
	Learning Rate: 0.00613019
	LOSS [training: 0.4295716383582219 | validation: 0.5716788328172197]
	TIME [epoch: 9.09 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43654577698976604		[learning rate: 0.0061153]
	Learning Rate: 0.00611535
	LOSS [training: 0.43654577698976604 | validation: 0.4325236610527604]
	TIME [epoch: 9.11 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3660323182246681		[learning rate: 0.0061005]
	Learning Rate: 0.00610054
	LOSS [training: 0.3660323182246681 | validation: 0.39520528827004653]
	TIME [epoch: 9.11 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36103391923944284		[learning rate: 0.0060858]
	Learning Rate: 0.00608577
	LOSS [training: 0.36103391923944284 | validation: 0.3156869055630367]
	TIME [epoch: 9.09 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38105556254698314		[learning rate: 0.006071]
	Learning Rate: 0.00607104
	LOSS [training: 0.38105556254698314 | validation: 0.5448458058209127]
	TIME [epoch: 9.09 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45302422412079013		[learning rate: 0.0060563]
	Learning Rate: 0.00605634
	LOSS [training: 0.45302422412079013 | validation: 0.4261886088910459]
	TIME [epoch: 9.09 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.357159490783917		[learning rate: 0.0060417]
	Learning Rate: 0.00604168
	LOSS [training: 0.357159490783917 | validation: 0.5025694632971012]
	TIME [epoch: 9.1 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34703641685888514		[learning rate: 0.0060271]
	Learning Rate: 0.00602706
	LOSS [training: 0.34703641685888514 | validation: 0.399452582630495]
	TIME [epoch: 9.09 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41608708899246577		[learning rate: 0.0060125]
	Learning Rate: 0.00601247
	LOSS [training: 0.41608708899246577 | validation: 0.3001930778007066]
	TIME [epoch: 9.08 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3911477932640029		[learning rate: 0.0059979]
	Learning Rate: 0.00599791
	LOSS [training: 0.3911477932640029 | validation: 0.33792409869081963]
	TIME [epoch: 9.08 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33788725711894046		[learning rate: 0.0059834]
	Learning Rate: 0.00598339
	LOSS [training: 0.33788725711894046 | validation: 0.3804936545306087]
	TIME [epoch: 9.09 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34930723314527057		[learning rate: 0.0059689]
	Learning Rate: 0.00596891
	LOSS [training: 0.34930723314527057 | validation: 0.3661959996396873]
	TIME [epoch: 9.12 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40647156426521286		[learning rate: 0.0059545]
	Learning Rate: 0.00595446
	LOSS [training: 0.40647156426521286 | validation: 0.3964444371994889]
	TIME [epoch: 9.09 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39455914740585457		[learning rate: 0.00594]
	Learning Rate: 0.00594004
	LOSS [training: 0.39455914740585457 | validation: 0.46982937866386837]
	TIME [epoch: 9.09 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3918288323488679		[learning rate: 0.0059257]
	Learning Rate: 0.00592566
	LOSS [training: 0.3918288323488679 | validation: 0.4851417650690429]
	TIME [epoch: 9.08 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4148187449754409		[learning rate: 0.0059113]
	Learning Rate: 0.00591132
	LOSS [training: 0.4148187449754409 | validation: 0.451107637594419]
	TIME [epoch: 9.11 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4128373312757245		[learning rate: 0.005897]
	Learning Rate: 0.00589701
	LOSS [training: 0.4128373312757245 | validation: 0.31196737558193854]
	TIME [epoch: 9.09 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39174371779194284		[learning rate: 0.0058827]
	Learning Rate: 0.00588273
	LOSS [training: 0.39174371779194284 | validation: 0.31830654582554707]
	TIME [epoch: 9.08 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3810769675523387		[learning rate: 0.0058685]
	Learning Rate: 0.00586849
	LOSS [training: 0.3810769675523387 | validation: 0.34858407723660745]
	TIME [epoch: 9.09 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3374986814751283		[learning rate: 0.0058543]
	Learning Rate: 0.00585428
	LOSS [training: 0.3374986814751283 | validation: 0.501450021808511]
	TIME [epoch: 9.08 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4409121839034066		[learning rate: 0.0058401]
	Learning Rate: 0.00584011
	LOSS [training: 0.4409121839034066 | validation: 0.8267048352835371]
	TIME [epoch: 9.11 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4532943881532859		[learning rate: 0.005826]
	Learning Rate: 0.00582597
	LOSS [training: 0.4532943881532859 | validation: 0.29635281939529096]
	TIME [epoch: 9.09 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38810043092047825		[learning rate: 0.0058119]
	Learning Rate: 0.00581187
	LOSS [training: 0.38810043092047825 | validation: 0.3769275706461911]
	TIME [epoch: 9.08 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32803703923089367		[learning rate: 0.0057978]
	Learning Rate: 0.0057978
	LOSS [training: 0.32803703923089367 | validation: 0.34481794230607765]
	TIME [epoch: 9.09 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3169643529667107		[learning rate: 0.0057838]
	Learning Rate: 0.00578376
	LOSS [training: 0.3169643529667107 | validation: 0.27401652913177504]
	TIME [epoch: 9.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3398691207577494		[learning rate: 0.0057698]
	Learning Rate: 0.00576976
	LOSS [training: 0.3398691207577494 | validation: 0.36780137244795896]
	TIME [epoch: 9.09 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3630085073681263		[learning rate: 0.0057558]
	Learning Rate: 0.00575579
	LOSS [training: 0.3630085073681263 | validation: 0.28384322577964705]
	TIME [epoch: 9.08 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3387039876509248		[learning rate: 0.0057419]
	Learning Rate: 0.00574186
	LOSS [training: 0.3387039876509248 | validation: 0.30979700134608606]
	TIME [epoch: 9.08 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4122329378386523		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.4122329378386523 | validation: 0.4224047070791661]
	TIME [epoch: 9.09 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4137540440577022		[learning rate: 0.0057141]
	Learning Rate: 0.00571409
	LOSS [training: 0.4137540440577022 | validation: 0.40099184450587344]
	TIME [epoch: 9.1 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4834953410117522		[learning rate: 0.0057003]
	Learning Rate: 0.00570026
	LOSS [training: 0.4834953410117522 | validation: 0.7450874816609344]
	TIME [epoch: 9.08 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.20243760980718		[learning rate: 0.0056865]
	Learning Rate: 0.00568646
	LOSS [training: 1.20243760980718 | validation: 0.45892799784064386]
	TIME [epoch: 9.08 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3967308718804213		[learning rate: 0.0056727]
	Learning Rate: 0.0056727
	LOSS [training: 0.3967308718804213 | validation: 0.38019503698207224]
	TIME [epoch: 9.08 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6747193116467699		[learning rate: 0.005659]
	Learning Rate: 0.00565896
	LOSS [training: 0.6747193116467699 | validation: 0.30909214533894624]
	TIME [epoch: 9.09 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44297487673859337		[learning rate: 0.0056453]
	Learning Rate: 0.00564526
	LOSS [training: 0.44297487673859337 | validation: 0.4684720430279279]
	TIME [epoch: 9.09 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3444554820064018		[learning rate: 0.0056316]
	Learning Rate: 0.0056316
	LOSS [training: 0.3444554820064018 | validation: 0.3551276844061335]
	TIME [epoch: 9.08 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3621158693052834		[learning rate: 0.005618]
	Learning Rate: 0.00561796
	LOSS [training: 0.3621158693052834 | validation: 0.5656778146892784]
	TIME [epoch: 9.08 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42851399477867813		[learning rate: 0.0056044]
	Learning Rate: 0.00560436
	LOSS [training: 0.42851399477867813 | validation: 0.27735768996345667]
	TIME [epoch: 9.08 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33010564269431264		[learning rate: 0.0055908]
	Learning Rate: 0.0055908
	LOSS [training: 0.33010564269431264 | validation: 0.6288439321266532]
	TIME [epoch: 9.12 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45887383188243575		[learning rate: 0.0055773]
	Learning Rate: 0.00557726
	LOSS [training: 0.45887383188243575 | validation: 0.440583840136748]
	TIME [epoch: 9.08 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4231554094875293		[learning rate: 0.0055638]
	Learning Rate: 0.00556376
	LOSS [training: 0.4231554094875293 | validation: 0.48175513130157366]
	TIME [epoch: 9.08 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4457993184121863		[learning rate: 0.0055503]
	Learning Rate: 0.00555029
	LOSS [training: 0.4457993184121863 | validation: 0.5395639221483259]
	TIME [epoch: 9.08 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3689628400176759		[learning rate: 0.0055369]
	Learning Rate: 0.00553685
	LOSS [training: 0.3689628400176759 | validation: 0.3930926003001622]
	TIME [epoch: 9.07 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32913559960934713		[learning rate: 0.0055235]
	Learning Rate: 0.00552345
	LOSS [training: 0.32913559960934713 | validation: 0.3352335531356698]
	TIME [epoch: 9.11 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3061815090923668		[learning rate: 0.0055101]
	Learning Rate: 0.00551008
	LOSS [training: 0.3061815090923668 | validation: 0.25703583407297326]
	TIME [epoch: 9.08 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34096034775665396		[learning rate: 0.0054967]
	Learning Rate: 0.00549674
	LOSS [training: 0.34096034775665396 | validation: 0.42697116745634955]
	TIME [epoch: 9.08 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37436692815525097		[learning rate: 0.0054834]
	Learning Rate: 0.00548343
	LOSS [training: 0.37436692815525097 | validation: 0.4944858227546739]
	TIME [epoch: 9.08 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38319455221954124		[learning rate: 0.0054702]
	Learning Rate: 0.00547016
	LOSS [training: 0.38319455221954124 | validation: 0.40254404701944624]
	TIME [epoch: 9.09 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37790735639022327		[learning rate: 0.0054569]
	Learning Rate: 0.00545692
	LOSS [training: 0.37790735639022327 | validation: 0.5323008373625738]
	TIME [epoch: 9.09 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5176361318932392		[learning rate: 0.0054437]
	Learning Rate: 0.00544371
	LOSS [training: 0.5176361318932392 | validation: 0.444365756629874]
	TIME [epoch: 9.08 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4956497447112544		[learning rate: 0.0054305]
	Learning Rate: 0.00543053
	LOSS [training: 0.4956497447112544 | validation: 0.4543300955152362]
	TIME [epoch: 9.08 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3979499427759221		[learning rate: 0.0054174]
	Learning Rate: 0.00541738
	LOSS [training: 0.3979499427759221 | validation: 0.46352323377022886]
	TIME [epoch: 9.09 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4094161284587649		[learning rate: 0.0054043]
	Learning Rate: 0.00540427
	LOSS [training: 0.4094161284587649 | validation: 0.2704910310460784]
	TIME [epoch: 9.1 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36999637760551063		[learning rate: 0.0053912]
	Learning Rate: 0.00539118
	LOSS [training: 0.36999637760551063 | validation: 0.29088663194339714]
	TIME [epoch: 9.08 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36365748612064286		[learning rate: 0.0053781]
	Learning Rate: 0.00537813
	LOSS [training: 0.36365748612064286 | validation: 0.4584935903849213]
	TIME [epoch: 9.08 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4380849791409852		[learning rate: 0.0053651]
	Learning Rate: 0.00536511
	LOSS [training: 0.4380849791409852 | validation: 0.22951597298033458]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30966070330708567		[learning rate: 0.0053521]
	Learning Rate: 0.00535213
	LOSS [training: 0.30966070330708567 | validation: 0.37831096043095425]
	TIME [epoch: 9.09 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9226808916051213		[learning rate: 0.0053392]
	Learning Rate: 0.00533917
	LOSS [training: 0.9226808916051213 | validation: 0.4495737431459438]
	TIME [epoch: 9.07 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7866610730322348		[learning rate: 0.0053262]
	Learning Rate: 0.00532624
	LOSS [training: 0.7866610730322348 | validation: 1.0401138367050038]
	TIME [epoch: 9.08 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8745272682467204		[learning rate: 0.0053133]
	Learning Rate: 0.00531335
	LOSS [training: 2.8745272682467204 | validation: 1.6478896728598325]
	TIME [epoch: 9.08 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6811975949952518		[learning rate: 0.0053005]
	Learning Rate: 0.00530049
	LOSS [training: 1.6811975949952518 | validation: 0.5318084124234953]
	TIME [epoch: 9.07 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5330822261100093		[learning rate: 0.0052877]
	Learning Rate: 0.00528766
	LOSS [training: 0.5330822261100093 | validation: 0.5246735880014997]
	TIME [epoch: 9.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4866924334702091		[learning rate: 0.0052749]
	Learning Rate: 0.00527485
	LOSS [training: 0.4866924334702091 | validation: 0.39826132769346567]
	TIME [epoch: 9.08 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5389319514316159		[learning rate: 0.0052621]
	Learning Rate: 0.00526209
	LOSS [training: 0.5389319514316159 | validation: 0.40885536564971714]
	TIME [epoch: 9.07 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0706537745558538		[learning rate: 0.0052493]
	Learning Rate: 0.00524935
	LOSS [training: 2.0706537745558538 | validation: 2.337608511516237]
	TIME [epoch: 9.08 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9114595057859409		[learning rate: 0.0052366]
	Learning Rate: 0.00523664
	LOSS [training: 0.9114595057859409 | validation: 0.3628288468085732]
	TIME [epoch: 9.09 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5727727774205641		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.5727727774205641 | validation: 0.2959504382878587]
	TIME [epoch: 9.09 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4573435008815655		[learning rate: 0.0052113]
	Learning Rate: 0.00521132
	LOSS [training: 0.4573435008815655 | validation: 0.35638338414206777]
	TIME [epoch: 9.08 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4191118721300796		[learning rate: 0.0051987]
	Learning Rate: 0.0051987
	LOSS [training: 0.4191118721300796 | validation: 0.37032706721470743]
	TIME [epoch: 9.08 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3918191536179288		[learning rate: 0.0051861]
	Learning Rate: 0.00518611
	LOSS [training: 0.3918191536179288 | validation: 0.3165952289161227]
	TIME [epoch: 9.08 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40237166508719546		[learning rate: 0.0051736]
	Learning Rate: 0.00517356
	LOSS [training: 0.40237166508719546 | validation: 0.32335423495940013]
	TIME [epoch: 9.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41091939141292666		[learning rate: 0.005161]
	Learning Rate: 0.00516104
	LOSS [training: 0.41091939141292666 | validation: 0.6146546336778506]
	TIME [epoch: 9.09 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5159588718470021		[learning rate: 0.0051485]
	Learning Rate: 0.00514854
	LOSS [training: 0.5159588718470021 | validation: 0.3017577899777183]
	TIME [epoch: 9.07 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3794634097303146		[learning rate: 0.0051361]
	Learning Rate: 0.00513608
	LOSS [training: 0.3794634097303146 | validation: 0.4043885674799088]
	TIME [epoch: 9.07 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35455237375017534		[learning rate: 0.0051236]
	Learning Rate: 0.00512364
	LOSS [training: 0.35455237375017534 | validation: 0.4341377922895875]
	TIME [epoch: 9.07 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37477826475960974		[learning rate: 0.0051112]
	Learning Rate: 0.00511124
	LOSS [training: 0.37477826475960974 | validation: 0.29499511081120233]
	TIME [epoch: 9.09 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3246359398002344		[learning rate: 0.0050989]
	Learning Rate: 0.00509887
	LOSS [training: 0.3246359398002344 | validation: 0.35711612414911]
	TIME [epoch: 9.08 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3158640883876046		[learning rate: 0.0050865]
	Learning Rate: 0.00508652
	LOSS [training: 0.3158640883876046 | validation: 0.3163853125140381]
	TIME [epoch: 9.08 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3942919229060251		[learning rate: 0.0050742]
	Learning Rate: 0.00507421
	LOSS [training: 0.3942919229060251 | validation: 0.3418137313117509]
	TIME [epoch: 9.08 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41076440433987377		[learning rate: 0.0050619]
	Learning Rate: 0.00506193
	LOSS [training: 0.41076440433987377 | validation: 0.42059409633388456]
	TIME [epoch: 9.09 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4731726935208055		[learning rate: 0.0050497]
	Learning Rate: 0.00504967
	LOSS [training: 0.4731726935208055 | validation: 0.30848392720614715]
	TIME [epoch: 9.07 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45436112451783417		[learning rate: 0.0050374]
	Learning Rate: 0.00503745
	LOSS [training: 0.45436112451783417 | validation: 0.4197679269507744]
	TIME [epoch: 9.07 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5119541350109575		[learning rate: 0.0050253]
	Learning Rate: 0.00502525
	LOSS [training: 0.5119541350109575 | validation: 0.45292373332392594]
	TIME [epoch: 9.07 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3925399870505576		[learning rate: 0.0050131]
	Learning Rate: 0.00501309
	LOSS [training: 0.3925399870505576 | validation: 0.312724723263365]
	TIME [epoch: 9.08 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35047249286383214		[learning rate: 0.005001]
	Learning Rate: 0.00500095
	LOSS [training: 0.35047249286383214 | validation: 0.4573541583448978]
	TIME [epoch: 9.09 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4067104915116489		[learning rate: 0.0049888]
	Learning Rate: 0.00498884
	LOSS [training: 0.4067104915116489 | validation: 0.3136034440393781]
	TIME [epoch: 9.07 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37609578399512483		[learning rate: 0.0049768]
	Learning Rate: 0.00497677
	LOSS [training: 0.37609578399512483 | validation: 0.32498558808723776]
	TIME [epoch: 9.07 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3918878616729997		[learning rate: 0.0049647]
	Learning Rate: 0.00496472
	LOSS [training: 0.3918878616729997 | validation: 0.43492830213752576]
	TIME [epoch: 9.07 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46751783732277374		[learning rate: 0.0049527]
	Learning Rate: 0.0049527
	LOSS [training: 0.46751783732277374 | validation: 0.4695988258205911]
	TIME [epoch: 9.07 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6607622457727687		[learning rate: 0.0049407]
	Learning Rate: 0.00494071
	LOSS [training: 0.6607622457727687 | validation: 0.356642812221882]
	TIME [epoch: 9.09 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4011943277739388		[learning rate: 0.0049288]
	Learning Rate: 0.00492875
	LOSS [training: 0.4011943277739388 | validation: 0.43585944512879227]
	TIME [epoch: 9.08 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3996991309998853		[learning rate: 0.0049168]
	Learning Rate: 0.00491682
	LOSS [training: 0.3996991309998853 | validation: 0.2767368460548152]
	TIME [epoch: 9.07 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4251710361387908		[learning rate: 0.0049049]
	Learning Rate: 0.00490492
	LOSS [training: 0.4251710361387908 | validation: 0.3463541049775716]
	TIME [epoch: 9.07 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48637327424726784		[learning rate: 0.004893]
	Learning Rate: 0.00489304
	LOSS [training: 0.48637327424726784 | validation: 0.35589002553585997]
	TIME [epoch: 9.09 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3798672088491493		[learning rate: 0.0048812]
	Learning Rate: 0.0048812
	LOSS [training: 0.3798672088491493 | validation: 0.28340152897357396]
	TIME [epoch: 9.07 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3298492693688714		[learning rate: 0.0048694]
	Learning Rate: 0.00486938
	LOSS [training: 0.3298492693688714 | validation: 0.3263725673512644]
	TIME [epoch: 9.07 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3823748479047572		[learning rate: 0.0048576]
	Learning Rate: 0.00485759
	LOSS [training: 0.3823748479047572 | validation: 0.32151745448923186]
	TIME [epoch: 9.07 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3493007577951789		[learning rate: 0.0048458]
	Learning Rate: 0.00484583
	LOSS [training: 0.3493007577951789 | validation: 0.2940704951194148]
	TIME [epoch: 9.08 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4109464708961575		[learning rate: 0.0048341]
	Learning Rate: 0.0048341
	LOSS [training: 0.4109464708961575 | validation: 0.2772293002551294]
	TIME [epoch: 9.1 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.333243910058923		[learning rate: 0.0048224]
	Learning Rate: 0.0048224
	LOSS [training: 0.333243910058923 | validation: 0.30774865298728715]
	TIME [epoch: 9.08 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33731811805526557		[learning rate: 0.0048107]
	Learning Rate: 0.00481072
	LOSS [training: 0.33731811805526557 | validation: 0.298041412423442]
	TIME [epoch: 9.08 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3758288624900175		[learning rate: 0.0047991]
	Learning Rate: 0.00479908
	LOSS [training: 0.3758288624900175 | validation: 0.2800971275041032]
	TIME [epoch: 9.07 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5173079174066783		[learning rate: 0.0047875]
	Learning Rate: 0.00478746
	LOSS [training: 0.5173079174066783 | validation: 0.394073368611759]
	TIME [epoch: 9.09 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5303127536612687		[learning rate: 0.0047759]
	Learning Rate: 0.00477587
	LOSS [training: 0.5303127536612687 | validation: 0.36010187538713023]
	TIME [epoch: 9.09 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35261805235483434		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.35261805235483434 | validation: 0.355568356098712]
	TIME [epoch: 9.08 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35108623707384046		[learning rate: 0.0047528]
	Learning Rate: 0.00475278
	LOSS [training: 0.35108623707384046 | validation: 0.2546693891124024]
	TIME [epoch: 9.08 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36406404769369394		[learning rate: 0.0047413]
	Learning Rate: 0.00474127
	LOSS [training: 0.36406404769369394 | validation: 0.36046721075793214]
	TIME [epoch: 9.07 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32173580152111586		[learning rate: 0.0047298]
	Learning Rate: 0.00472979
	LOSS [training: 0.32173580152111586 | validation: 0.32244119844862407]
	TIME [epoch: 9.1 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31986495011208943		[learning rate: 0.0047183]
	Learning Rate: 0.00471834
	LOSS [training: 0.31986495011208943 | validation: 0.26871113903038313]
	TIME [epoch: 9.07 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3225739493458143		[learning rate: 0.0047069]
	Learning Rate: 0.00470692
	LOSS [training: 0.3225739493458143 | validation: 0.2772442649357868]
	TIME [epoch: 9.08 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33160784778730473		[learning rate: 0.0046955]
	Learning Rate: 0.00469553
	LOSS [training: 0.33160784778730473 | validation: 0.2932566975977293]
	TIME [epoch: 9.08 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5567608632101071		[learning rate: 0.0046842]
	Learning Rate: 0.00468416
	LOSS [training: 0.5567608632101071 | validation: 0.7188934506605378]
	TIME [epoch: 9.09 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4894662247565017		[learning rate: 0.0046728]
	Learning Rate: 0.00467282
	LOSS [training: 0.4894662247565017 | validation: 0.44261124374033695]
	TIME [epoch: 9.08 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3619584539379991		[learning rate: 0.0046615]
	Learning Rate: 0.00466151
	LOSS [training: 0.3619584539379991 | validation: 0.2770788772789287]
	TIME [epoch: 9.07 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33058443941482013		[learning rate: 0.0046502]
	Learning Rate: 0.00465022
	LOSS [training: 0.33058443941482013 | validation: 0.3586013055008547]
	TIME [epoch: 9.07 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31355817255592194		[learning rate: 0.004639]
	Learning Rate: 0.00463896
	LOSS [training: 0.31355817255592194 | validation: 0.34515320476888506]
	TIME [epoch: 9.07 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3232409358148344		[learning rate: 0.0046277]
	Learning Rate: 0.00462773
	LOSS [training: 0.3232409358148344 | validation: 0.29105013539872887]
	TIME [epoch: 9.09 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.339382739313787		[learning rate: 0.0046165]
	Learning Rate: 0.00461653
	LOSS [training: 0.339382739313787 | validation: 0.3405223071141897]
	TIME [epoch: 9.09 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3451923315276327		[learning rate: 0.0046054]
	Learning Rate: 0.00460536
	LOSS [training: 0.3451923315276327 | validation: 0.30653250392810993]
	TIME [epoch: 9.08 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4287662370225026		[learning rate: 0.0045942]
	Learning Rate: 0.00459421
	LOSS [training: 0.4287662370225026 | validation: 0.6121499384864231]
	TIME [epoch: 9.07 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5062805555498704		[learning rate: 0.0045831]
	Learning Rate: 0.00458308
	LOSS [training: 0.5062805555498704 | validation: 0.3448887655472569]
	TIME [epoch: 9.09 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4240368669984818		[learning rate: 0.004572]
	Learning Rate: 0.00457199
	LOSS [training: 0.4240368669984818 | validation: 0.4368070274897661]
	TIME [epoch: 9.09 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5367003767832973		[learning rate: 0.0045609]
	Learning Rate: 0.00456092
	LOSS [training: 0.5367003767832973 | validation: 0.9467176547512914]
	TIME [epoch: 9.07 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6639329720894107		[learning rate: 0.0045499]
	Learning Rate: 0.00454988
	LOSS [training: 0.6639329720894107 | validation: 0.44406734492148814]
	TIME [epoch: 9.07 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48069918333162337		[learning rate: 0.0045389]
	Learning Rate: 0.00453887
	LOSS [training: 0.48069918333162337 | validation: 0.4356555431057438]
	TIME [epoch: 9.07 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43663243037322125		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.43663243037322125 | validation: 0.29448494570885]
	TIME [epoch: 9.09 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4066183820183594		[learning rate: 0.0045169]
	Learning Rate: 0.00451692
	LOSS [training: 0.4066183820183594 | validation: 0.3137218971726579]
	TIME [epoch: 9.07 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41553480498581824		[learning rate: 0.004506]
	Learning Rate: 0.00450598
	LOSS [training: 0.41553480498581824 | validation: 0.337110307917008]
	TIME [epoch: 9.07 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3947888648252238		[learning rate: 0.0044951]
	Learning Rate: 0.00449507
	LOSS [training: 0.3947888648252238 | validation: 0.2873906196447388]
	TIME [epoch: 9.07 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3666723483776066		[learning rate: 0.0044842]
	Learning Rate: 0.00448419
	LOSS [training: 0.3666723483776066 | validation: 0.29009847209476264]
	TIME [epoch: 9.06 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35470674684522485		[learning rate: 0.0044733]
	Learning Rate: 0.00447334
	LOSS [training: 0.35470674684522485 | validation: 0.32043944241357686]
	TIME [epoch: 9.1 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3696318620588917		[learning rate: 0.0044625]
	Learning Rate: 0.00446251
	LOSS [training: 0.3696318620588917 | validation: 0.26891880752531216]
	TIME [epoch: 9.07 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34253428052551266		[learning rate: 0.0044517]
	Learning Rate: 0.0044517
	LOSS [training: 0.34253428052551266 | validation: 0.3228012943537277]
	TIME [epoch: 9.08 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39589749285347914		[learning rate: 0.0044409]
	Learning Rate: 0.00444093
	LOSS [training: 0.39589749285347914 | validation: 0.30336290160596413]
	TIME [epoch: 9.07 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38356049931392244		[learning rate: 0.0044302]
	Learning Rate: 0.00443018
	LOSS [training: 0.38356049931392244 | validation: 0.2880161516777726]
	TIME [epoch: 9.08 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3773341675804261		[learning rate: 0.0044195]
	Learning Rate: 0.00441945
	LOSS [training: 0.3773341675804261 | validation: 0.28073699794874374]
	TIME [epoch: 9.08 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3912388145846828		[learning rate: 0.0044088]
	Learning Rate: 0.00440875
	LOSS [training: 0.3912388145846828 | validation: 0.3862075443285913]
	TIME [epoch: 9.07 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31816752711332497		[learning rate: 0.0043981]
	Learning Rate: 0.00439808
	LOSS [training: 0.31816752711332497 | validation: 0.2866062055146547]
	TIME [epoch: 9.07 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3436111188171816		[learning rate: 0.0043874]
	Learning Rate: 0.00438743
	LOSS [training: 0.3436111188171816 | validation: 0.2973088384576693]
	TIME [epoch: 9.07 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3496141673305725		[learning rate: 0.0043768]
	Learning Rate: 0.00437681
	LOSS [training: 0.3496141673305725 | validation: 0.2780363237082837]
	TIME [epoch: 9.09 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29963764649831226		[learning rate: 0.0043662]
	Learning Rate: 0.00436622
	LOSS [training: 0.29963764649831226 | validation: 0.2694501209373429]
	TIME [epoch: 9.07 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29065650619558275		[learning rate: 0.0043556]
	Learning Rate: 0.00435565
	LOSS [training: 0.29065650619558275 | validation: 0.2921561043274188]
	TIME [epoch: 9.06 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38087932414095044		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.38087932414095044 | validation: 0.2844298569495395]
	TIME [epoch: 9.07 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3066350199783079		[learning rate: 0.0043346]
	Learning Rate: 0.00433458
	LOSS [training: 0.3066350199783079 | validation: 0.2479658062786178]
	TIME [epoch: 9.09 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2910856968475444		[learning rate: 0.0043241]
	Learning Rate: 0.00432409
	LOSS [training: 0.2910856968475444 | validation: 0.3025724855106458]
	TIME [epoch: 9.09 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29521361679998803		[learning rate: 0.0043136]
	Learning Rate: 0.00431362
	LOSS [training: 0.29521361679998803 | validation: 0.2969212772474178]
	TIME [epoch: 9.08 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3287805491358356		[learning rate: 0.0043032]
	Learning Rate: 0.00430318
	LOSS [training: 0.3287805491358356 | validation: 0.5691675632140791]
	TIME [epoch: 9.07 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4404190620968487		[learning rate: 0.0042928]
	Learning Rate: 0.00429276
	LOSS [training: 0.4404190620968487 | validation: 0.25923072002672976]
	TIME [epoch: 9.07 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32700589735916874		[learning rate: 0.0042824]
	Learning Rate: 0.00428237
	LOSS [training: 0.32700589735916874 | validation: 0.29294437005032314]
	TIME [epoch: 9.09 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2861702962539151		[learning rate: 0.004272]
	Learning Rate: 0.004272
	LOSS [training: 0.2861702962539151 | validation: 0.35543251223905803]
	TIME [epoch: 9.07 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30343249915991366		[learning rate: 0.0042617]
	Learning Rate: 0.00426166
	LOSS [training: 0.30343249915991366 | validation: 0.2842746094645947]
	TIME [epoch: 9.07 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.300463753537665		[learning rate: 0.0042513]
	Learning Rate: 0.00425134
	LOSS [training: 0.300463753537665 | validation: 0.32762315380230184]
	TIME [epoch: 9.07 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5561174013531047		[learning rate: 0.0042411]
	Learning Rate: 0.00424105
	LOSS [training: 0.5561174013531047 | validation: 0.4885923151868604]
	TIME [epoch: 9.07 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4047125823906993		[learning rate: 0.0042308]
	Learning Rate: 0.00423079
	LOSS [training: 0.4047125823906993 | validation: 0.5584825953302709]
	TIME [epoch: 9.1 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4343697698916338		[learning rate: 0.0042205]
	Learning Rate: 0.00422054
	LOSS [training: 0.4343697698916338 | validation: 0.3568326932380784]
	TIME [epoch: 9.07 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33169763787090245		[learning rate: 0.0042103]
	Learning Rate: 0.00421033
	LOSS [training: 0.33169763787090245 | validation: 0.25537514917689]
	TIME [epoch: 9.07 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29203034002075523		[learning rate: 0.0042001]
	Learning Rate: 0.00420013
	LOSS [training: 0.29203034002075523 | validation: 0.3126571888894234]
	TIME [epoch: 9.08 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37826433382477337		[learning rate: 0.00419]
	Learning Rate: 0.00418997
	LOSS [training: 0.37826433382477337 | validation: 0.41492745870330705]
	TIME [epoch: 9.1 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40644080808397076		[learning rate: 0.0041798]
	Learning Rate: 0.00417982
	LOSS [training: 0.40644080808397076 | validation: 0.2976246335340277]
	TIME [epoch: 9.08 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.316485044795118		[learning rate: 0.0041697]
	Learning Rate: 0.0041697
	LOSS [training: 0.316485044795118 | validation: 0.2785964310560824]
	TIME [epoch: 9.06 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.302998836755933		[learning rate: 0.0041596]
	Learning Rate: 0.00415961
	LOSS [training: 0.302998836755933 | validation: 0.2904717192740772]
	TIME [epoch: 9.08 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3448668245995935		[learning rate: 0.0041495]
	Learning Rate: 0.00414954
	LOSS [training: 0.3448668245995935 | validation: 0.42293113632821144]
	TIME [epoch: 9.07 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4572985813819126		[learning rate: 0.0041395]
	Learning Rate: 0.0041395
	LOSS [training: 0.4572985813819126 | validation: 0.3319862370859088]
	TIME [epoch: 9.08 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3737805567349509		[learning rate: 0.0041295]
	Learning Rate: 0.00412947
	LOSS [training: 0.3737805567349509 | validation: 0.32629861839108454]
	TIME [epoch: 9.07 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33680562149271215		[learning rate: 0.0041195]
	Learning Rate: 0.00411948
	LOSS [training: 0.33680562149271215 | validation: 0.3100235938581454]
	TIME [epoch: 9.07 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2645654710853152		[learning rate: 0.0041095]
	Learning Rate: 0.0041095
	LOSS [training: 0.2645654710853152 | validation: 0.26857947438875235]
	TIME [epoch: 9.07 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27994331301929376		[learning rate: 0.0040996]
	Learning Rate: 0.00409956
	LOSS [training: 0.27994331301929376 | validation: 0.30908188782065427]
	TIME [epoch: 9.08 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33869329162545236		[learning rate: 0.0040896]
	Learning Rate: 0.00408963
	LOSS [training: 0.33869329162545236 | validation: 0.33901905309568336]
	TIME [epoch: 9.06 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.383940089626168		[learning rate: 0.0040797]
	Learning Rate: 0.00407973
	LOSS [training: 0.383940089626168 | validation: 0.38106549825859976]
	TIME [epoch: 9.07 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32106091479323917		[learning rate: 0.0040699]
	Learning Rate: 0.00406985
	LOSS [training: 0.32106091479323917 | validation: 0.3843173189358886]
	TIME [epoch: 9.08 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2992271499955081		[learning rate: 0.00406]
	Learning Rate: 0.00406
	LOSS [training: 0.2992271499955081 | validation: 0.2875891935795418]
	TIME [epoch: 9.08 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2531651468264391		[learning rate: 0.0040502]
	Learning Rate: 0.00405017
	LOSS [training: 0.2531651468264391 | validation: 0.23552285586842456]
	TIME [epoch: 9.1 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2818397610649132		[learning rate: 0.0040404]
	Learning Rate: 0.00404037
	LOSS [training: 0.2818397610649132 | validation: 0.3453611244544671]
	TIME [epoch: 9.08 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39572338343480296		[learning rate: 0.0040306]
	Learning Rate: 0.00403059
	LOSS [training: 0.39572338343480296 | validation: 0.2620610546343346]
	TIME [epoch: 9.07 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34506468516804506		[learning rate: 0.0040208]
	Learning Rate: 0.00402083
	LOSS [training: 0.34506468516804506 | validation: 0.2684622988533091]
	TIME [epoch: 9.07 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32062696288993403		[learning rate: 0.0040111]
	Learning Rate: 0.0040111
	LOSS [training: 0.32062696288993403 | validation: 0.27111202655453503]
	TIME [epoch: 9.08 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2961696626539122		[learning rate: 0.0040014]
	Learning Rate: 0.00400139
	LOSS [training: 0.2961696626539122 | validation: 0.29523327100801816]
	TIME [epoch: 9.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31159391694833827		[learning rate: 0.0039917]
	Learning Rate: 0.0039917
	LOSS [training: 0.31159391694833827 | validation: 1.0140641593295345]
	TIME [epoch: 9.08 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5510645832521167		[learning rate: 0.003982]
	Learning Rate: 0.00398204
	LOSS [training: 0.5510645832521167 | validation: 0.29305499154016573]
	TIME [epoch: 9.07 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2742317634264545		[learning rate: 0.0039724]
	Learning Rate: 0.0039724
	LOSS [training: 0.2742317634264545 | validation: 0.24587478092820247]
	TIME [epoch: 9.06 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37847268264377276		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.37847268264377276 | validation: 0.7587557603305335]
	TIME [epoch: 9.09 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4439274465332816		[learning rate: 0.0039532]
	Learning Rate: 0.00395319
	LOSS [training: 0.4439274465332816 | validation: 0.5216825032918183]
	TIME [epoch: 9.09 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43447380182240736		[learning rate: 0.0039436]
	Learning Rate: 0.00394362
	LOSS [training: 0.43447380182240736 | validation: 0.45047572146705805]
	TIME [epoch: 9.08 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.296398490216472		[learning rate: 0.0039341]
	Learning Rate: 0.00393407
	LOSS [training: 0.296398490216472 | validation: 0.27979969281198874]
	TIME [epoch: 9.08 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.268714992167277		[learning rate: 0.0039245]
	Learning Rate: 0.00392455
	LOSS [training: 0.268714992167277 | validation: 0.24911902465614763]
	TIME [epoch: 9.08 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2916062684934291		[learning rate: 0.003915]
	Learning Rate: 0.00391505
	LOSS [training: 0.2916062684934291 | validation: 0.2602264399535172]
	TIME [epoch: 9.09 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30746033772410825		[learning rate: 0.0039056]
	Learning Rate: 0.00390557
	LOSS [training: 0.30746033772410825 | validation: 0.24113576288342664]
	TIME [epoch: 9.08 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29912088277139		[learning rate: 0.0038961]
	Learning Rate: 0.00389611
	LOSS [training: 0.29912088277139 | validation: 0.28216067405578915]
	TIME [epoch: 9.07 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3009667155973487		[learning rate: 0.0038867]
	Learning Rate: 0.00388668
	LOSS [training: 0.3009667155973487 | validation: 0.27366787270117393]
	TIME [epoch: 9.07 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26422627111790326		[learning rate: 0.0038773]
	Learning Rate: 0.00387727
	LOSS [training: 0.26422627111790326 | validation: 0.302542700987543]
	TIME [epoch: 9.08 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27166058042759444		[learning rate: 0.0038679]
	Learning Rate: 0.00386789
	LOSS [training: 0.27166058042759444 | validation: 0.22111968053733905]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_492.pth
	Model improved!!!
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25971427196845964		[learning rate: 0.0038585]
	Learning Rate: 0.00385852
	LOSS [training: 0.25971427196845964 | validation: 0.3264967167456869]
	TIME [epoch: 9.07 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.314507105689235		[learning rate: 0.0038492]
	Learning Rate: 0.00384918
	LOSS [training: 0.314507105689235 | validation: 0.4025881531075304]
	TIME [epoch: 9.06 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36517912539877956		[learning rate: 0.0038399]
	Learning Rate: 0.00383986
	LOSS [training: 0.36517912539877956 | validation: 0.3035799339096573]
	TIME [epoch: 9.06 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35232721061776157		[learning rate: 0.0038306]
	Learning Rate: 0.00383057
	LOSS [training: 0.35232721061776157 | validation: 0.4518756805776968]
	TIME [epoch: 9.08 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30819716202312025		[learning rate: 0.0038213]
	Learning Rate: 0.00382129
	LOSS [training: 0.30819716202312025 | validation: 0.29514693758686394]
	TIME [epoch: 9.08 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3040872911943055		[learning rate: 0.003812]
	Learning Rate: 0.00381204
	LOSS [training: 0.3040872911943055 | validation: 0.2882960726621586]
	TIME [epoch: 9.09 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30867053003473377		[learning rate: 0.0038028]
	Learning Rate: 0.00380282
	LOSS [training: 0.30867053003473377 | validation: 0.4117758404263912]
	TIME [epoch: 9.07 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3517237797668978		[learning rate: 0.0037936]
	Learning Rate: 0.00379361
	LOSS [training: 0.3517237797668978 | validation: 0.2790594999207662]
	TIME [epoch: 9.08 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2764607513139238		[learning rate: 0.0037844]
	Learning Rate: 0.00378443
	LOSS [training: 0.2764607513139238 | validation: 0.26879914062059873]
	TIME [epoch: 9.08 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31329008110940837		[learning rate: 0.0037753]
	Learning Rate: 0.00377526
	LOSS [training: 0.31329008110940837 | validation: 0.2633113464055443]
	TIME [epoch: 9.06 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2996512072520611		[learning rate: 0.0037661]
	Learning Rate: 0.00376613
	LOSS [training: 0.2996512072520611 | validation: 0.34343357986771317]
	TIME [epoch: 9.06 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3172119374027088		[learning rate: 0.003757]
	Learning Rate: 0.00375701
	LOSS [training: 0.3172119374027088 | validation: 0.2795547105354692]
	TIME [epoch: 9.07 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29309370173688476		[learning rate: 0.0037479]
	Learning Rate: 0.00374791
	LOSS [training: 0.29309370173688476 | validation: 0.260519995196309]
	TIME [epoch: 9.09 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3117914188892939		[learning rate: 0.0037388]
	Learning Rate: 0.00373884
	LOSS [training: 0.3117914188892939 | validation: 0.5257663510155295]
	TIME [epoch: 9.08 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33184441285788746		[learning rate: 0.0037298]
	Learning Rate: 0.00372979
	LOSS [training: 0.33184441285788746 | validation: 0.26860686364775976]
	TIME [epoch: 9.07 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3054068740776733		[learning rate: 0.0037208]
	Learning Rate: 0.00372076
	LOSS [training: 0.3054068740776733 | validation: 0.2574764916577758]
	TIME [epoch: 9.06 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26023124269785214		[learning rate: 0.0037118]
	Learning Rate: 0.00371175
	LOSS [training: 0.26023124269785214 | validation: 0.2765486455865985]
	TIME [epoch: 9.06 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2634894957539356		[learning rate: 0.0037028]
	Learning Rate: 0.00370277
	LOSS [training: 0.2634894957539356 | validation: 0.22486066951620554]
	TIME [epoch: 9.09 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3020700456729185		[learning rate: 0.0036938]
	Learning Rate: 0.0036938
	LOSS [training: 0.3020700456729185 | validation: 0.2684049123911669]
	TIME [epoch: 9.07 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45424894595225196		[learning rate: 0.0036849]
	Learning Rate: 0.00368486
	LOSS [training: 0.45424894595225196 | validation: 0.2754770118538625]
	TIME [epoch: 9.07 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3026195742816945		[learning rate: 0.0036759]
	Learning Rate: 0.00367594
	LOSS [training: 0.3026195742816945 | validation: 0.23689450014271324]
	TIME [epoch: 9.06 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3113236619814261		[learning rate: 0.003667]
	Learning Rate: 0.00366704
	LOSS [training: 0.3113236619814261 | validation: 0.28162265876951376]
	TIME [epoch: 9.08 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28833955470074896		[learning rate: 0.0036582]
	Learning Rate: 0.00365816
	LOSS [training: 0.28833955470074896 | validation: 0.3273619649328973]
	TIME [epoch: 9.06 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26781188514261767		[learning rate: 0.0036493]
	Learning Rate: 0.00364931
	LOSS [training: 0.26781188514261767 | validation: 0.23626636831564568]
	TIME [epoch: 9.06 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2744411754410204		[learning rate: 0.0036405]
	Learning Rate: 0.00364047
	LOSS [training: 0.2744411754410204 | validation: 0.2765960953468755]
	TIME [epoch: 9.06 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35767351249554546		[learning rate: 0.0036317]
	Learning Rate: 0.00363166
	LOSS [training: 0.35767351249554546 | validation: 0.32329345174661617]
	TIME [epoch: 9.07 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6556082966833915		[learning rate: 0.0036229]
	Learning Rate: 0.00362287
	LOSS [training: 0.6556082966833915 | validation: 0.9945413346579529]
	TIME [epoch: 9.09 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8327382982690361		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.8327382982690361 | validation: 0.26791835061204416]
	TIME [epoch: 9.06 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38883230454733986		[learning rate: 0.0036053]
	Learning Rate: 0.00360535
	LOSS [training: 0.38883230454733986 | validation: 0.3100887642994261]
	TIME [epoch: 9.06 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36925752447735066		[learning rate: 0.0035966]
	Learning Rate: 0.00359662
	LOSS [training: 0.36925752447735066 | validation: 0.5277435709448625]
	TIME [epoch: 9.06 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48293572892601055		[learning rate: 0.0035879]
	Learning Rate: 0.00358791
	LOSS [training: 0.48293572892601055 | validation: 0.5465921994318502]
	TIME [epoch: 9.08 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5091049854717685		[learning rate: 0.0035792]
	Learning Rate: 0.00357923
	LOSS [training: 0.5091049854717685 | validation: 0.415823955939323]
	TIME [epoch: 9.07 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38574993095960053		[learning rate: 0.0035706]
	Learning Rate: 0.00357056
	LOSS [training: 0.38574993095960053 | validation: 0.3336872841909593]
	TIME [epoch: 9.07 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3963292402798754		[learning rate: 0.0035619]
	Learning Rate: 0.00356192
	LOSS [training: 0.3963292402798754 | validation: 0.3116579230395695]
	TIME [epoch: 9.08 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40795313389077315		[learning rate: 0.0035533]
	Learning Rate: 0.0035533
	LOSS [training: 0.40795313389077315 | validation: 0.40009676503500147]
	TIME [epoch: 9.07 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4039910364448505		[learning rate: 0.0035447]
	Learning Rate: 0.0035447
	LOSS [training: 0.4039910364448505 | validation: 0.23902388839993693]
	TIME [epoch: 9.09 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29200987774544696		[learning rate: 0.0035361]
	Learning Rate: 0.00353611
	LOSS [training: 0.29200987774544696 | validation: 0.28038846843953047]
	TIME [epoch: 9.07 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30451947314469446		[learning rate: 0.0035276]
	Learning Rate: 0.00352755
	LOSS [training: 0.30451947314469446 | validation: 0.24850815867799025]
	TIME [epoch: 9.06 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2811056318180203		[learning rate: 0.003519]
	Learning Rate: 0.00351901
	LOSS [training: 0.2811056318180203 | validation: 0.28695723149578595]
	TIME [epoch: 9.07 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3417318026427207		[learning rate: 0.0035105]
	Learning Rate: 0.0035105
	LOSS [training: 0.3417318026427207 | validation: 0.39620535985445976]
	TIME [epoch: 9.07 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39829897993590885		[learning rate: 0.003502]
	Learning Rate: 0.003502
	LOSS [training: 0.39829897993590885 | validation: 0.5448929794153107]
	TIME [epoch: 9.09 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5325857347569467		[learning rate: 0.0034935]
	Learning Rate: 0.00349352
	LOSS [training: 0.5325857347569467 | validation: 0.373003223690509]
	TIME [epoch: 9.07 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38921751755239586		[learning rate: 0.0034851]
	Learning Rate: 0.00348506
	LOSS [training: 0.38921751755239586 | validation: 0.3020550195701635]
	TIME [epoch: 9.06 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3097744002506123		[learning rate: 0.0034766]
	Learning Rate: 0.00347663
	LOSS [training: 0.3097744002506123 | validation: 0.24846647516943018]
	TIME [epoch: 9.07 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3452268063246009		[learning rate: 0.0034682]
	Learning Rate: 0.00346821
	LOSS [training: 0.3452268063246009 | validation: 0.30876799720998016]
	TIME [epoch: 9.09 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2912986916300568		[learning rate: 0.0034598]
	Learning Rate: 0.00345981
	LOSS [training: 0.2912986916300568 | validation: 0.31506271078195863]
	TIME [epoch: 9.09 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2352875079979631		[learning rate: 0.0034514]
	Learning Rate: 0.00345144
	LOSS [training: 0.2352875079979631 | validation: 0.2381519798013363]
	TIME [epoch: 9.07 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2683111649559441		[learning rate: 0.0034431]
	Learning Rate: 0.00344308
	LOSS [training: 0.2683111649559441 | validation: 0.2566682109937818]
	TIME [epoch: 9.07 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29480085643546544		[learning rate: 0.0034347]
	Learning Rate: 0.00343475
	LOSS [training: 0.29480085643546544 | validation: 0.30299456769167377]
	TIME [epoch: 9.06 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28641531457271213		[learning rate: 0.0034264]
	Learning Rate: 0.00342643
	LOSS [training: 0.28641531457271213 | validation: 0.24454647001675833]
	TIME [epoch: 9.09 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26182342567682937		[learning rate: 0.0034181]
	Learning Rate: 0.00341814
	LOSS [training: 0.26182342567682937 | validation: 0.3124363116404353]
	TIME [epoch: 9.07 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3132849083880525		[learning rate: 0.0034099]
	Learning Rate: 0.00340986
	LOSS [training: 0.3132849083880525 | validation: 0.3227059580686079]
	TIME [epoch: 9.08 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3339686917121161		[learning rate: 0.0034016]
	Learning Rate: 0.00340161
	LOSS [training: 0.3339686917121161 | validation: 0.34928919468152964]
	TIME [epoch: 9.07 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44548990900550417		[learning rate: 0.0033934]
	Learning Rate: 0.00339337
	LOSS [training: 0.44548990900550417 | validation: 0.280111432586001]
	TIME [epoch: 9.09 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30000835083759625		[learning rate: 0.0033852]
	Learning Rate: 0.00338516
	LOSS [training: 0.30000835083759625 | validation: 0.35033230004599547]
	TIME [epoch: 9.07 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28139196216796203		[learning rate: 0.003377]
	Learning Rate: 0.00337696
	LOSS [training: 0.28139196216796203 | validation: 0.3044757568488766]
	TIME [epoch: 9.08 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3390650483839554		[learning rate: 0.0033688]
	Learning Rate: 0.00336879
	LOSS [training: 0.3390650483839554 | validation: 0.2913563237989911]
	TIME [epoch: 9.06 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3067316180075376		[learning rate: 0.0033606]
	Learning Rate: 0.00336063
	LOSS [training: 0.3067316180075376 | validation: 0.4011732989664072]
	TIME [epoch: 9.08 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4159327094933848		[learning rate: 0.0033525]
	Learning Rate: 0.0033525
	LOSS [training: 0.4159327094933848 | validation: 0.3729238612780618]
	TIME [epoch: 9.1 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3150329181854511		[learning rate: 0.0033444]
	Learning Rate: 0.00334438
	LOSS [training: 0.3150329181854511 | validation: 0.32046469046648707]
	TIME [epoch: 9.08 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4009809566412844		[learning rate: 0.0033363]
	Learning Rate: 0.00333629
	LOSS [training: 0.4009809566412844 | validation: 0.3520679921321845]
	TIME [epoch: 9.07 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32776669819275495		[learning rate: 0.0033282]
	Learning Rate: 0.00332821
	LOSS [training: 0.32776669819275495 | validation: 0.29322500127457296]
	TIME [epoch: 9.06 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25750199164822896		[learning rate: 0.0033202]
	Learning Rate: 0.00332015
	LOSS [training: 0.25750199164822896 | validation: 0.250239971987417]
	TIME [epoch: 9.08 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2667450904449354		[learning rate: 0.0033121]
	Learning Rate: 0.00331211
	LOSS [training: 0.2667450904449354 | validation: 0.2500029659257338]
	TIME [epoch: 9.09 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24395829223848228		[learning rate: 0.0033041]
	Learning Rate: 0.0033041
	LOSS [training: 0.24395829223848228 | validation: 0.2530553248842462]
	TIME [epoch: 9.08 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.325288931227487		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.325288931227487 | validation: 0.2887474436953678]
	TIME [epoch: 9.08 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33904912765090345		[learning rate: 0.0032881]
	Learning Rate: 0.00328812
	LOSS [training: 0.33904912765090345 | validation: 0.38534358436872984]
	TIME [epoch: 9.08 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6720493680247926		[learning rate: 0.0032802]
	Learning Rate: 0.00328016
	LOSS [training: 0.6720493680247926 | validation: 0.49379627422208244]
	TIME [epoch: 9.09 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4369391755180928		[learning rate: 0.0032722]
	Learning Rate: 0.00327222
	LOSS [training: 0.4369391755180928 | validation: 0.34234578701847573]
	TIME [epoch: 9.07 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.292861634176628		[learning rate: 0.0032643]
	Learning Rate: 0.0032643
	LOSS [training: 0.292861634176628 | validation: 0.3289650093484315]
	TIME [epoch: 9.07 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3192829025027815		[learning rate: 0.0032564]
	Learning Rate: 0.00325639
	LOSS [training: 0.3192829025027815 | validation: 0.25965402467212195]
	TIME [epoch: 9.08 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3006282024569912		[learning rate: 0.0032485]
	Learning Rate: 0.00324851
	LOSS [training: 0.3006282024569912 | validation: 0.22184549744642484]
	TIME [epoch: 9.08 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.308464631743443		[learning rate: 0.0032406]
	Learning Rate: 0.00324065
	LOSS [training: 0.308464631743443 | validation: 0.3168762197384563]
	TIME [epoch: 9.1 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2960427644865404		[learning rate: 0.0032328]
	Learning Rate: 0.0032328
	LOSS [training: 0.2960427644865404 | validation: 0.3752708491041847]
	TIME [epoch: 9.07 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2991686458806714		[learning rate: 0.003225]
	Learning Rate: 0.00322497
	LOSS [training: 0.2991686458806714 | validation: 0.23221405167726444]
	TIME [epoch: 9.07 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2976278239550455		[learning rate: 0.0032172]
	Learning Rate: 0.00321717
	LOSS [training: 0.2976278239550455 | validation: 0.23202036131410056]
	TIME [epoch: 9.08 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26643420443174143		[learning rate: 0.0032094]
	Learning Rate: 0.00320938
	LOSS [training: 0.26643420443174143 | validation: 0.3128757281955937]
	TIME [epoch: 9.09 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24833848646608714		[learning rate: 0.0032016]
	Learning Rate: 0.00320161
	LOSS [training: 0.24833848646608714 | validation: 0.3294558394751623]
	TIME [epoch: 9.06 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31053671389793147		[learning rate: 0.0031939]
	Learning Rate: 0.00319386
	LOSS [training: 0.31053671389793147 | validation: 0.2536846403130472]
	TIME [epoch: 9.06 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2875816203612658		[learning rate: 0.0031861]
	Learning Rate: 0.00318613
	LOSS [training: 0.2875816203612658 | validation: 0.29800467036708356]
	TIME [epoch: 9.06 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30227770068595294		[learning rate: 0.0031784]
	Learning Rate: 0.00317841
	LOSS [training: 0.30227770068595294 | validation: 0.21339043968147092]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_573.pth
	Model improved!!!
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29723953862746494		[learning rate: 0.0031707]
	Learning Rate: 0.00317072
	LOSS [training: 0.29723953862746494 | validation: 0.26492214663721714]
	TIME [epoch: 9.08 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3257839810489552		[learning rate: 0.003163]
	Learning Rate: 0.00316304
	LOSS [training: 0.3257839810489552 | validation: 0.28141550488919487]
	TIME [epoch: 9.06 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31481212956762317		[learning rate: 0.0031554]
	Learning Rate: 0.00315539
	LOSS [training: 0.31481212956762317 | validation: 0.336586027927258]
	TIME [epoch: 9.05 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29801541881845156		[learning rate: 0.0031477]
	Learning Rate: 0.00314775
	LOSS [training: 0.29801541881845156 | validation: 0.22865469422917983]
	TIME [epoch: 9.05 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3324646884337035		[learning rate: 0.0031401]
	Learning Rate: 0.00314013
	LOSS [training: 0.3324646884337035 | validation: 0.3862173655747901]
	TIME [epoch: 9.06 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4036692869291262		[learning rate: 0.0031325]
	Learning Rate: 0.00313253
	LOSS [training: 0.4036692869291262 | validation: 0.3440884362390009]
	TIME [epoch: 9.06 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3624777695173833		[learning rate: 0.0031249]
	Learning Rate: 0.00312494
	LOSS [training: 0.3624777695173833 | validation: 0.24245394011087118]
	TIME [epoch: 9.05 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2874532218041079		[learning rate: 0.0031174]
	Learning Rate: 0.00311738
	LOSS [training: 0.2874532218041079 | validation: 0.306198719989799]
	TIME [epoch: 9.06 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30894470663754786		[learning rate: 0.0031098]
	Learning Rate: 0.00310983
	LOSS [training: 0.30894470663754786 | validation: 0.32309255249006347]
	TIME [epoch: 9.06 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25423779032715477		[learning rate: 0.0031023]
	Learning Rate: 0.0031023
	LOSS [training: 0.25423779032715477 | validation: 0.2561196140053913]
	TIME [epoch: 9.08 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28747256325473025		[learning rate: 0.0030948]
	Learning Rate: 0.00309479
	LOSS [training: 0.28747256325473025 | validation: 0.25115058350802133]
	TIME [epoch: 9.07 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26382425435680446		[learning rate: 0.0030873]
	Learning Rate: 0.0030873
	LOSS [training: 0.26382425435680446 | validation: 0.2967459167094387]
	TIME [epoch: 9.06 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25712866428843856		[learning rate: 0.0030798]
	Learning Rate: 0.00307983
	LOSS [training: 0.25712866428843856 | validation: 0.24884138089620106]
	TIME [epoch: 9.05 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29416483434219665		[learning rate: 0.0030724]
	Learning Rate: 0.00307237
	LOSS [training: 0.29416483434219665 | validation: 0.25379960133161467]
	TIME [epoch: 9.07 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29145727405729893		[learning rate: 0.0030649]
	Learning Rate: 0.00306493
	LOSS [training: 0.29145727405729893 | validation: 0.3690274480670862]
	TIME [epoch: 9.07 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30306981386116294		[learning rate: 0.0030575]
	Learning Rate: 0.00305751
	LOSS [training: 0.30306981386116294 | validation: 0.2513280149846841]
	TIME [epoch: 9.07 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27557763200848784		[learning rate: 0.0030501]
	Learning Rate: 0.00305011
	LOSS [training: 0.27557763200848784 | validation: 0.32300383659945064]
	TIME [epoch: 9.07 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25446722737871447		[learning rate: 0.0030427]
	Learning Rate: 0.00304273
	LOSS [training: 0.25446722737871447 | validation: 0.28004264283160984]
	TIME [epoch: 9.06 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3398347922266971		[learning rate: 0.0030354]
	Learning Rate: 0.00303536
	LOSS [training: 0.3398347922266971 | validation: 0.3081271242917212]
	TIME [epoch: 9.08 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2748799718463437		[learning rate: 0.003028]
	Learning Rate: 0.00302801
	LOSS [training: 0.2748799718463437 | validation: 0.2412243882243252]
	TIME [epoch: 9.06 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2551926936591852		[learning rate: 0.0030207]
	Learning Rate: 0.00302068
	LOSS [training: 0.2551926936591852 | validation: 0.2353163184748751]
	TIME [epoch: 9.06 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25219587345625843		[learning rate: 0.0030134]
	Learning Rate: 0.00301337
	LOSS [training: 0.25219587345625843 | validation: 0.27975831622361746]
	TIME [epoch: 9.06 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26142342290136583		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.26142342290136583 | validation: 0.23066066666506985]
	TIME [epoch: 9.06 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28229951934641206		[learning rate: 0.0029988]
	Learning Rate: 0.0029988
	LOSS [training: 0.28229951934641206 | validation: 0.3199846073378262]
	TIME [epoch: 9.08 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37244417460356016		[learning rate: 0.0029915]
	Learning Rate: 0.00299154
	LOSS [training: 0.37244417460356016 | validation: 0.4265360028272025]
	TIME [epoch: 9.06 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34673708384986346		[learning rate: 0.0029843]
	Learning Rate: 0.0029843
	LOSS [training: 0.34673708384986346 | validation: 0.262763493490433]
	TIME [epoch: 9.06 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3093662934981533		[learning rate: 0.0029771]
	Learning Rate: 0.00297707
	LOSS [training: 0.3093662934981533 | validation: 0.35936598913998996]
	TIME [epoch: 9.05 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29690656614269945		[learning rate: 0.0029699]
	Learning Rate: 0.00296987
	LOSS [training: 0.29690656614269945 | validation: 0.2973159215307534]
	TIME [epoch: 9.08 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3106440081681845		[learning rate: 0.0029627]
	Learning Rate: 0.00296268
	LOSS [training: 0.3106440081681845 | validation: 0.31225455200913504]
	TIME [epoch: 9.08 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2978644642510541		[learning rate: 0.0029555]
	Learning Rate: 0.0029555
	LOSS [training: 0.2978644642510541 | validation: 0.2861928301612052]
	TIME [epoch: 9.07 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2588151097246856		[learning rate: 0.0029483]
	Learning Rate: 0.00294835
	LOSS [training: 0.2588151097246856 | validation: 0.24102132869572657]
	TIME [epoch: 9.07 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26377801399210077		[learning rate: 0.0029412]
	Learning Rate: 0.00294121
	LOSS [training: 0.26377801399210077 | validation: 0.2688146965940752]
	TIME [epoch: 9.08 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28358720549416877		[learning rate: 0.0029341]
	Learning Rate: 0.00293409
	LOSS [training: 0.28358720549416877 | validation: 0.278321142173339]
	TIME [epoch: 9.08 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26963667911450806		[learning rate: 0.002927]
	Learning Rate: 0.00292699
	LOSS [training: 0.26963667911450806 | validation: 0.264218066813602]
	TIME [epoch: 9.07 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2604890616637493		[learning rate: 0.0029199]
	Learning Rate: 0.0029199
	LOSS [training: 0.2604890616637493 | validation: 0.2496304385795835]
	TIME [epoch: 9.06 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2647816053420238		[learning rate: 0.0029128]
	Learning Rate: 0.00291283
	LOSS [training: 0.2647816053420238 | validation: 0.2653503406384362]
	TIME [epoch: 9.06 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2870514971202654		[learning rate: 0.0029058]
	Learning Rate: 0.00290578
	LOSS [training: 0.2870514971202654 | validation: 0.24570028122184717]
	TIME [epoch: 9.08 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25331393464753804		[learning rate: 0.0028987]
	Learning Rate: 0.00289875
	LOSS [training: 0.25331393464753804 | validation: 0.2286528525796271]
	TIME [epoch: 9.07 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2998780650005994		[learning rate: 0.0028917]
	Learning Rate: 0.00289173
	LOSS [training: 0.2998780650005994 | validation: 0.3498442360443025]
	TIME [epoch: 9.06 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3343910120036916		[learning rate: 0.0028847]
	Learning Rate: 0.00288473
	LOSS [training: 0.3343910120036916 | validation: 0.28203880579119645]
	TIME [epoch: 9.06 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3098620404148561		[learning rate: 0.0028777]
	Learning Rate: 0.00287775
	LOSS [training: 0.3098620404148561 | validation: 0.32286922468326873]
	TIME [epoch: 9.06 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32929158926476054		[learning rate: 0.0028708]
	Learning Rate: 0.00287078
	LOSS [training: 0.32929158926476054 | validation: 0.3788261098623661]
	TIME [epoch: 9.09 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27422713462765214		[learning rate: 0.0028638]
	Learning Rate: 0.00286383
	LOSS [training: 0.27422713462765214 | validation: 0.23621074682860696]
	TIME [epoch: 9.06 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2573831919954891		[learning rate: 0.0028569]
	Learning Rate: 0.0028569
	LOSS [training: 0.2573831919954891 | validation: 0.23629831082534064]
	TIME [epoch: 9.07 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26105936476377967		[learning rate: 0.00285]
	Learning Rate: 0.00284998
	LOSS [training: 0.26105936476377967 | validation: 0.3031018230218103]
	TIME [epoch: 9.07 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25099964891905835		[learning rate: 0.0028431]
	Learning Rate: 0.00284308
	LOSS [training: 0.25099964891905835 | validation: 0.24550202393550485]
	TIME [epoch: 9.06 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33280456710304585		[learning rate: 0.0028362]
	Learning Rate: 0.0028362
	LOSS [training: 0.33280456710304585 | validation: 0.4325627810266758]
	TIME [epoch: 9.08 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39932646691479123		[learning rate: 0.0028293]
	Learning Rate: 0.00282933
	LOSS [training: 0.39932646691479123 | validation: 0.42200423917106866]
	TIME [epoch: 9.06 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30771355982642856		[learning rate: 0.0028225]
	Learning Rate: 0.00282248
	LOSS [training: 0.30771355982642856 | validation: 0.33377677500758096]
	TIME [epoch: 9.05 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27836798209896424		[learning rate: 0.0028157]
	Learning Rate: 0.00281565
	LOSS [training: 0.27836798209896424 | validation: 0.3646059637475513]
	TIME [epoch: 9.06 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2816486388070517		[learning rate: 0.0028088]
	Learning Rate: 0.00280884
	LOSS [training: 0.2816486388070517 | validation: 0.30987326320421965]
	TIME [epoch: 9.09 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2922811114960348		[learning rate: 0.002802]
	Learning Rate: 0.00280204
	LOSS [training: 0.2922811114960348 | validation: 0.28385117943310945]
	TIME [epoch: 9.07 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2687664437921493		[learning rate: 0.0027953]
	Learning Rate: 0.00279525
	LOSS [training: 0.2687664437921493 | validation: 0.26085614082420105]
	TIME [epoch: 9.05 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2665586451178032		[learning rate: 0.0027885]
	Learning Rate: 0.00278849
	LOSS [training: 0.2665586451178032 | validation: 0.2612218025235239]
	TIME [epoch: 9.05 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2737457759963212		[learning rate: 0.0027817]
	Learning Rate: 0.00278174
	LOSS [training: 0.2737457759963212 | validation: 0.26603056296404315]
	TIME [epoch: 9.06 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2771525505990395		[learning rate: 0.002775]
	Learning Rate: 0.002775
	LOSS [training: 0.2771525505990395 | validation: 0.2591312629355914]
	TIME [epoch: 9.09 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2865841282609326		[learning rate: 0.0027683]
	Learning Rate: 0.00276828
	LOSS [training: 0.2865841282609326 | validation: 0.2584874633676395]
	TIME [epoch: 9.06 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2759433857949331		[learning rate: 0.0027616]
	Learning Rate: 0.00276158
	LOSS [training: 0.2759433857949331 | validation: 0.29236606172062723]
	TIME [epoch: 9.06 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31555389226611336		[learning rate: 0.0027549]
	Learning Rate: 0.0027549
	LOSS [training: 0.31555389226611336 | validation: 0.24879610273909183]
	TIME [epoch: 9.06 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29951525506387344		[learning rate: 0.0027482]
	Learning Rate: 0.00274823
	LOSS [training: 0.29951525506387344 | validation: 0.291291974992585]
	TIME [epoch: 9.06 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30187577930054477		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.30187577930054477 | validation: 0.4039824396371128]
	TIME [epoch: 9.06 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3522340283002282		[learning rate: 0.0027349]
	Learning Rate: 0.00273494
	LOSS [training: 0.3522340283002282 | validation: 0.2906129383256987]
	TIME [epoch: 9.07 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2840135106981801		[learning rate: 0.0027283]
	Learning Rate: 0.00272832
	LOSS [training: 0.2840135106981801 | validation: 0.24071952271184988]
	TIME [epoch: 9.06 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2797397654351091		[learning rate: 0.0027217]
	Learning Rate: 0.00272171
	LOSS [training: 0.2797397654351091 | validation: 0.20641972511175927]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24030752205029424		[learning rate: 0.0027151]
	Learning Rate: 0.00271512
	LOSS [training: 0.24030752205029424 | validation: 0.2703065666980606]
	TIME [epoch: 9.09 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25722240504847715		[learning rate: 0.0027086]
	Learning Rate: 0.00270855
	LOSS [training: 0.25722240504847715 | validation: 0.2526312690795514]
	TIME [epoch: 9.05 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36906215930450686		[learning rate: 0.002702]
	Learning Rate: 0.00270199
	LOSS [training: 0.36906215930450686 | validation: 0.4005772438657307]
	TIME [epoch: 9.07 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2838796092262733		[learning rate: 0.0026955]
	Learning Rate: 0.00269545
	LOSS [training: 0.2838796092262733 | validation: 0.2351790452140149]
	TIME [epoch: 9.06 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2547241895239133		[learning rate: 0.0026889]
	Learning Rate: 0.00268893
	LOSS [training: 0.2547241895239133 | validation: 0.28575765935625136]
	TIME [epoch: 9.06 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23542939436794103		[learning rate: 0.0026824]
	Learning Rate: 0.00268242
	LOSS [training: 0.23542939436794103 | validation: 0.20316962291585133]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_643.pth
	Model improved!!!
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25661344343276193		[learning rate: 0.0026759]
	Learning Rate: 0.00267592
	LOSS [training: 0.25661344343276193 | validation: 0.24712225904129648]
	TIME [epoch: 9.06 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2456998093945467		[learning rate: 0.0026694]
	Learning Rate: 0.00266945
	LOSS [training: 0.2456998093945467 | validation: 0.25879488038133946]
	TIME [epoch: 9.06 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2689474377503165		[learning rate: 0.002663]
	Learning Rate: 0.00266298
	LOSS [training: 0.2689474377503165 | validation: 0.21454712707943557]
	TIME [epoch: 9.05 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2547133754000229		[learning rate: 0.0026565]
	Learning Rate: 0.00265654
	LOSS [training: 0.2547133754000229 | validation: 0.2718475252752569]
	TIME [epoch: 9.07 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2611474546807897		[learning rate: 0.0026501]
	Learning Rate: 0.00265011
	LOSS [training: 0.2611474546807897 | validation: 0.2062520776049327]
	TIME [epoch: 9.07 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2685567964063701		[learning rate: 0.0026437]
	Learning Rate: 0.00264369
	LOSS [training: 0.2685567964063701 | validation: 0.2848454994949264]
	TIME [epoch: 9.05 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2902379853651764		[learning rate: 0.0026373]
	Learning Rate: 0.00263729
	LOSS [training: 0.2902379853651764 | validation: 0.2747628615214067]
	TIME [epoch: 9.05 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28084886044172896		[learning rate: 0.0026309]
	Learning Rate: 0.00263091
	LOSS [training: 0.28084886044172896 | validation: 0.273974470399304]
	TIME [epoch: 9.05 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28230959162657016		[learning rate: 0.0026245]
	Learning Rate: 0.00262454
	LOSS [training: 0.28230959162657016 | validation: 0.26831861229974513]
	TIME [epoch: 9.08 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25070420319205045		[learning rate: 0.0026182]
	Learning Rate: 0.00261818
	LOSS [training: 0.25070420319205045 | validation: 0.2195303078586377]
	TIME [epoch: 9.06 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2405589863891633		[learning rate: 0.0026118]
	Learning Rate: 0.00261184
	LOSS [training: 0.2405589863891633 | validation: 0.19827532190531502]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_654.pth
	Model improved!!!
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25325440451769876		[learning rate: 0.0026055]
	Learning Rate: 0.00260552
	LOSS [training: 0.25325440451769876 | validation: 0.2508910778893111]
	TIME [epoch: 9.07 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2617608622625044		[learning rate: 0.0025992]
	Learning Rate: 0.00259921
	LOSS [training: 0.2617608622625044 | validation: 0.20947565797360834]
	TIME [epoch: 9.09 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.306061644608436		[learning rate: 0.0025929]
	Learning Rate: 0.00259292
	LOSS [training: 0.306061644608436 | validation: 0.5061097583203777]
	TIME [epoch: 9.07 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.464726446287008		[learning rate: 0.0025866]
	Learning Rate: 0.00258664
	LOSS [training: 0.464726446287008 | validation: 0.4417196828336494]
	TIME [epoch: 9.06 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33064990908277025		[learning rate: 0.0025804]
	Learning Rate: 0.00258038
	LOSS [training: 0.33064990908277025 | validation: 0.3725576132372144]
	TIME [epoch: 9.06 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3919956407709415		[learning rate: 0.0025741]
	Learning Rate: 0.00257414
	LOSS [training: 0.3919956407709415 | validation: 0.33865254826238733]
	TIME [epoch: 9.05 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34193968822321646		[learning rate: 0.0025679]
	Learning Rate: 0.0025679
	LOSS [training: 0.34193968822321646 | validation: 0.2771172006531335]
	TIME [epoch: 9.07 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31357010029266946		[learning rate: 0.0025617]
	Learning Rate: 0.00256169
	LOSS [training: 0.31357010029266946 | validation: 0.2239013879321643]
	TIME [epoch: 9.06 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24739120903988146		[learning rate: 0.0025555]
	Learning Rate: 0.00255549
	LOSS [training: 0.24739120903988146 | validation: 0.23888585507535165]
	TIME [epoch: 9.05 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27973690037634086		[learning rate: 0.0025493]
	Learning Rate: 0.0025493
	LOSS [training: 0.27973690037634086 | validation: 0.3855116367402256]
	TIME [epoch: 9.07 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30345393682136634		[learning rate: 0.0025431]
	Learning Rate: 0.00254313
	LOSS [training: 0.30345393682136634 | validation: 0.3037829481484966]
	TIME [epoch: 9.08 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3276064144680554		[learning rate: 0.002537]
	Learning Rate: 0.00253697
	LOSS [training: 0.3276064144680554 | validation: 0.3970947149424645]
	TIME [epoch: 9.06 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.360822353635761		[learning rate: 0.0025308]
	Learning Rate: 0.00253083
	LOSS [training: 0.360822353635761 | validation: 0.42926193568709176]
	TIME [epoch: 9.07 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45426416781748513		[learning rate: 0.0025247]
	Learning Rate: 0.0025247
	LOSS [training: 0.45426416781748513 | validation: 0.5446090492851643]
	TIME [epoch: 9.06 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3823675986905907		[learning rate: 0.0025186]
	Learning Rate: 0.00251859
	LOSS [training: 0.3823675986905907 | validation: 0.3342750399426782]
	TIME [epoch: 9.06 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30747431122099733		[learning rate: 0.0025125]
	Learning Rate: 0.0025125
	LOSS [training: 0.30747431122099733 | validation: 0.2476286474327034]
	TIME [epoch: 9.09 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2700168022194789		[learning rate: 0.0025064]
	Learning Rate: 0.00250641
	LOSS [training: 0.2700168022194789 | validation: 0.2541682917324877]
	TIME [epoch: 9.08 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2441336995073279		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.2441336995073279 | validation: 0.2679687957528688]
	TIME [epoch: 9.07 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2563518708657689		[learning rate: 0.0024943]
	Learning Rate: 0.00249429
	LOSS [training: 0.2563518708657689 | validation: 0.28504763630179064]
	TIME [epoch: 9.07 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2428056626849448		[learning rate: 0.0024883]
	Learning Rate: 0.00248825
	LOSS [training: 0.2428056626849448 | validation: 0.21426773476633143]
	TIME [epoch: 9.07 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24347753040956074		[learning rate: 0.0024822]
	Learning Rate: 0.00248223
	LOSS [training: 0.24347753040956074 | validation: 0.2574343355947354]
	TIME [epoch: 9.09 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2506134039983684		[learning rate: 0.0024762]
	Learning Rate: 0.00247622
	LOSS [training: 0.2506134039983684 | validation: 0.24350009175838583]
	TIME [epoch: 9.07 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24148612224258975		[learning rate: 0.0024702]
	Learning Rate: 0.00247023
	LOSS [training: 0.24148612224258975 | validation: 0.24425393863766764]
	TIME [epoch: 9.07 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24678269996289828		[learning rate: 0.0024642]
	Learning Rate: 0.00246425
	LOSS [training: 0.24678269996289828 | validation: 0.27673996650650695]
	TIME [epoch: 9.07 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27271546627287563		[learning rate: 0.0024583]
	Learning Rate: 0.00245828
	LOSS [training: 0.27271546627287563 | validation: 0.25007092221454796]
	TIME [epoch: 9.08 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24299922875716287		[learning rate: 0.0024523]
	Learning Rate: 0.00245233
	LOSS [training: 0.24299922875716287 | validation: 0.24672208687758052]
	TIME [epoch: 9.07 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24425577293452388		[learning rate: 0.0024464]
	Learning Rate: 0.00244639
	LOSS [training: 0.24425577293452388 | validation: 0.26137473076186646]
	TIME [epoch: 9.07 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2659369486194578		[learning rate: 0.0024405]
	Learning Rate: 0.00244047
	LOSS [training: 0.2659369486194578 | validation: 0.20556084524342533]
	TIME [epoch: 9.07 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24716705557171323		[learning rate: 0.0024346]
	Learning Rate: 0.00243456
	LOSS [training: 0.24716705557171323 | validation: 0.2519182850856916]
	TIME [epoch: 9.07 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24518244656583105		[learning rate: 0.0024287]
	Learning Rate: 0.00242867
	LOSS [training: 0.24518244656583105 | validation: 0.2309181486900771]
	TIME [epoch: 9.09 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24178734681577257		[learning rate: 0.0024228]
	Learning Rate: 0.00242279
	LOSS [training: 0.24178734681577257 | validation: 0.2052990064807501]
	TIME [epoch: 9.07 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2580336918938782		[learning rate: 0.0024169]
	Learning Rate: 0.00241693
	LOSS [training: 0.2580336918938782 | validation: 0.2751212818873636]
	TIME [epoch: 9.06 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26842716118717647		[learning rate: 0.0024111]
	Learning Rate: 0.00241107
	LOSS [training: 0.26842716118717647 | validation: 0.2394796136562095]
	TIME [epoch: 9.06 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24555122401339807		[learning rate: 0.0024052]
	Learning Rate: 0.00240524
	LOSS [training: 0.24555122401339807 | validation: 0.23626727612228843]
	TIME [epoch: 9.09 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2784769073282517		[learning rate: 0.0023994]
	Learning Rate: 0.00239941
	LOSS [training: 0.2784769073282517 | validation: 0.3302416920836876]
	TIME [epoch: 9.07 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30445936087587483		[learning rate: 0.0023936]
	Learning Rate: 0.00239361
	LOSS [training: 0.30445936087587483 | validation: 0.25602863658206715]
	TIME [epoch: 9.06 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2544442498495011		[learning rate: 0.0023878]
	Learning Rate: 0.00238781
	LOSS [training: 0.2544442498495011 | validation: 0.251351010514013]
	TIME [epoch: 9.07 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25004574970996823		[learning rate: 0.002382]
	Learning Rate: 0.00238203
	LOSS [training: 0.25004574970996823 | validation: 0.23842323232546359]
	TIME [epoch: 9.06 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2449357914102531		[learning rate: 0.0023763]
	Learning Rate: 0.00237626
	LOSS [training: 0.2449357914102531 | validation: 0.29781327937467983]
	TIME [epoch: 9.1 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25286645789374607		[learning rate: 0.0023705]
	Learning Rate: 0.00237051
	LOSS [training: 0.25286645789374607 | validation: 0.2207090017532353]
	TIME [epoch: 9.08 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2761442884351455		[learning rate: 0.0023648]
	Learning Rate: 0.00236477
	LOSS [training: 0.2761442884351455 | validation: 0.2601964121706222]
	TIME [epoch: 9.07 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25180383060042905		[learning rate: 0.002359]
	Learning Rate: 0.00235905
	LOSS [training: 0.25180383060042905 | validation: 0.23129235319324817]
	TIME [epoch: 9.07 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.253945382071114		[learning rate: 0.0023533]
	Learning Rate: 0.00235334
	LOSS [training: 0.253945382071114 | validation: 0.22328565145154428]
	TIME [epoch: 9.08 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2521911233389412		[learning rate: 0.0023476]
	Learning Rate: 0.00234764
	LOSS [training: 0.2521911233389412 | validation: 0.2454320273067691]
	TIME [epoch: 9.09 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25492888886036336		[learning rate: 0.002342]
	Learning Rate: 0.00234196
	LOSS [training: 0.25492888886036336 | validation: 0.22509573942140354]
	TIME [epoch: 9.07 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.285451686890696		[learning rate: 0.0023363]
	Learning Rate: 0.00233629
	LOSS [training: 0.285451686890696 | validation: 0.24801725162184862]
	TIME [epoch: 9.07 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26182985110022455		[learning rate: 0.0023306]
	Learning Rate: 0.00233063
	LOSS [training: 0.26182985110022455 | validation: 0.2366516345374457]
	TIME [epoch: 9.07 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24617218206839678		[learning rate: 0.002325]
	Learning Rate: 0.00232499
	LOSS [training: 0.24617218206839678 | validation: 0.20261279296253057]
	TIME [epoch: 9.09 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.236413004253495		[learning rate: 0.0023194]
	Learning Rate: 0.00231936
	LOSS [training: 0.236413004253495 | validation: 0.2697686811350379]
	TIME [epoch: 9.07 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2615629877024173		[learning rate: 0.0023137]
	Learning Rate: 0.00231375
	LOSS [training: 0.2615629877024173 | validation: 0.23997959205392794]
	TIME [epoch: 9.07 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27302489881316483		[learning rate: 0.0023081]
	Learning Rate: 0.00230815
	LOSS [training: 0.27302489881316483 | validation: 0.277655886643446]
	TIME [epoch: 9.06 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3325819124567108		[learning rate: 0.0023026]
	Learning Rate: 0.00230256
	LOSS [training: 0.3325819124567108 | validation: 0.38005484050500526]
	TIME [epoch: 9.06 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28937433773023624		[learning rate: 0.002297]
	Learning Rate: 0.00229698
	LOSS [training: 0.28937433773023624 | validation: 0.29220628873512444]
	TIME [epoch: 9.09 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30623478143316896		[learning rate: 0.0022914]
	Learning Rate: 0.00229142
	LOSS [training: 0.30623478143316896 | validation: 0.2712961328860153]
	TIME [epoch: 9.07 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26823577412175825		[learning rate: 0.0022859]
	Learning Rate: 0.00228588
	LOSS [training: 0.26823577412175825 | validation: 0.2308285238733035]
	TIME [epoch: 9.08 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2619880419702448		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.2619880419702448 | validation: 0.2386881041107432]
	TIME [epoch: 9.08 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25727083614121055		[learning rate: 0.0022748]
	Learning Rate: 0.00227482
	LOSS [training: 0.25727083614121055 | validation: 0.3048392142088451]
	TIME [epoch: 9.09 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25514573008840447		[learning rate: 0.0022693]
	Learning Rate: 0.00226931
	LOSS [training: 0.25514573008840447 | validation: 0.2061659585226753]
	TIME [epoch: 9.08 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23491381588040888		[learning rate: 0.0022638]
	Learning Rate: 0.00226382
	LOSS [training: 0.23491381588040888 | validation: 0.24553357869583647]
	TIME [epoch: 9.06 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2577772489534889		[learning rate: 0.0022583]
	Learning Rate: 0.00225834
	LOSS [training: 0.2577772489534889 | validation: 0.25840893641053037]
	TIME [epoch: 9.07 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2595314651722978		[learning rate: 0.0022529]
	Learning Rate: 0.00225287
	LOSS [training: 0.2595314651722978 | validation: 0.2771729158281535]
	TIME [epoch: 9.06 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2642761989393165		[learning rate: 0.0022474]
	Learning Rate: 0.00224742
	LOSS [training: 0.2642761989393165 | validation: 0.2886666435030686]
	TIME [epoch: 9.09 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2729312447519592		[learning rate: 0.002242]
	Learning Rate: 0.00224198
	LOSS [training: 0.2729312447519592 | validation: 0.2706736098304495]
	TIME [epoch: 9.07 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2739531116492728		[learning rate: 0.0022366]
	Learning Rate: 0.00223655
	LOSS [training: 0.2739531116492728 | validation: 0.25311748328862604]
	TIME [epoch: 9.07 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29118919837182394		[learning rate: 0.0022311]
	Learning Rate: 0.00223114
	LOSS [training: 0.29118919837182394 | validation: 0.3229475465083975]
	TIME [epoch: 9.07 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28352067568446904		[learning rate: 0.0022257]
	Learning Rate: 0.00222574
	LOSS [training: 0.28352067568446904 | validation: 0.2967453259350781]
	TIME [epoch: 9.09 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3415712492326249		[learning rate: 0.0022203]
	Learning Rate: 0.00222035
	LOSS [training: 0.3415712492326249 | validation: 0.30272662731101085]
	TIME [epoch: 9.08 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2894919135078995		[learning rate: 0.002215]
	Learning Rate: 0.00221497
	LOSS [training: 0.2894919135078995 | validation: 0.2669238460763746]
	TIME [epoch: 9.08 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29127640516797637		[learning rate: 0.0022096]
	Learning Rate: 0.00220961
	LOSS [training: 0.29127640516797637 | validation: 0.3102233547831441]
	TIME [epoch: 9.07 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2844900654093937		[learning rate: 0.0022043]
	Learning Rate: 0.00220426
	LOSS [training: 0.2844900654093937 | validation: 0.26940303047350306]
	TIME [epoch: 9.08 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31760961409285987		[learning rate: 0.0021989]
	Learning Rate: 0.00219893
	LOSS [training: 0.31760961409285987 | validation: 0.24427417798104317]
	TIME [epoch: 9.08 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27633427507415464		[learning rate: 0.0021936]
	Learning Rate: 0.0021936
	LOSS [training: 0.27633427507415464 | validation: 0.2698913052748787]
	TIME [epoch: 9.07 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30068867424429835		[learning rate: 0.0021883]
	Learning Rate: 0.00218829
	LOSS [training: 0.30068867424429835 | validation: 0.2167154796664491]
	TIME [epoch: 9.07 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3615088187684605		[learning rate: 0.002183]
	Learning Rate: 0.00218299
	LOSS [training: 0.3615088187684605 | validation: 0.513877697055339]
	TIME [epoch: 9.06 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4019874440334178		[learning rate: 0.0021777]
	Learning Rate: 0.00217771
	LOSS [training: 0.4019874440334178 | validation: 0.2701250717057306]
	TIME [epoch: 9.06 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2969295300943163		[learning rate: 0.0021724]
	Learning Rate: 0.00217244
	LOSS [training: 0.2969295300943163 | validation: 0.291945194940061]
	TIME [epoch: 9.09 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2995263567058046		[learning rate: 0.0021672]
	Learning Rate: 0.00216718
	LOSS [training: 0.2995263567058046 | validation: 0.2861141429851249]
	TIME [epoch: 9.06 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2861277101039355		[learning rate: 0.0021619]
	Learning Rate: 0.00216193
	LOSS [training: 0.2861277101039355 | validation: 0.26624380207502374]
	TIME [epoch: 9.07 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3070285968584757		[learning rate: 0.0021567]
	Learning Rate: 0.0021567
	LOSS [training: 0.3070285968584757 | validation: 0.2531139284059325]
	TIME [epoch: 9.05 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26963092479031053		[learning rate: 0.0021515]
	Learning Rate: 0.00215148
	LOSS [training: 0.26963092479031053 | validation: 0.2595454706271205]
	TIME [epoch: 9.08 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2960595478001822		[learning rate: 0.0021463]
	Learning Rate: 0.00214627
	LOSS [training: 0.2960595478001822 | validation: 0.3731995874203031]
	TIME [epoch: 9.08 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35846083995610967		[learning rate: 0.0021411]
	Learning Rate: 0.00214107
	LOSS [training: 0.35846083995610967 | validation: 0.399693179119087]
	TIME [epoch: 9.08 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40115366053739365		[learning rate: 0.0021359]
	Learning Rate: 0.00213589
	LOSS [training: 0.40115366053739365 | validation: 0.3728933997847207]
	TIME [epoch: 9.08 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32011035772937513		[learning rate: 0.0021307]
	Learning Rate: 0.00213072
	LOSS [training: 0.32011035772937513 | validation: 0.26661343111321617]
	TIME [epoch: 9.06 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29168419087929787		[learning rate: 0.0021256]
	Learning Rate: 0.00212556
	LOSS [training: 0.29168419087929787 | validation: 0.30552337343945385]
	TIME [epoch: 9.08 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26486523224849423		[learning rate: 0.0021204]
	Learning Rate: 0.00212042
	LOSS [training: 0.26486523224849423 | validation: 0.23450275335274295]
	TIME [epoch: 9.07 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25908265642402584		[learning rate: 0.0021153]
	Learning Rate: 0.00211528
	LOSS [training: 0.25908265642402584 | validation: 0.23341678003442956]
	TIME [epoch: 9.06 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24473932271039783		[learning rate: 0.0021102]
	Learning Rate: 0.00211016
	LOSS [training: 0.24473932271039783 | validation: 0.23253651475254347]
	TIME [epoch: 9.06 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24041676229826772		[learning rate: 0.0021051]
	Learning Rate: 0.00210505
	LOSS [training: 0.24041676229826772 | validation: 0.23959145612897778]
	TIME [epoch: 9.08 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24691194962673974		[learning rate: 0.0021]
	Learning Rate: 0.00209996
	LOSS [training: 0.24691194962673974 | validation: 0.21010383556657922]
	TIME [epoch: 9.06 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2259554234920104		[learning rate: 0.0020949]
	Learning Rate: 0.00209487
	LOSS [training: 0.2259554234920104 | validation: 0.24233620601601996]
	TIME [epoch: 9.07 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24400092834826062		[learning rate: 0.0020898]
	Learning Rate: 0.0020898
	LOSS [training: 0.24400092834826062 | validation: 0.2923690664751999]
	TIME [epoch: 9.06 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.252720414519208		[learning rate: 0.0020847]
	Learning Rate: 0.00208474
	LOSS [training: 0.252720414519208 | validation: 0.21349443029825133]
	TIME [epoch: 9.07 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23503305312061476		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.23503305312061476 | validation: 0.20563197853638887]
	TIME [epoch: 9.07 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2293180459852505		[learning rate: 0.0020747]
	Learning Rate: 0.00207466
	LOSS [training: 0.2293180459852505 | validation: 0.22862884592398003]
	TIME [epoch: 9.07 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25260809716254623		[learning rate: 0.0020696]
	Learning Rate: 0.00206964
	LOSS [training: 0.25260809716254623 | validation: 0.24882667427367952]
	TIME [epoch: 9.07 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.246209492838212		[learning rate: 0.0020646]
	Learning Rate: 0.00206463
	LOSS [training: 0.246209492838212 | validation: 0.3203567077460149]
	TIME [epoch: 9.07 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26807950949498427		[learning rate: 0.0020596]
	Learning Rate: 0.00205963
	LOSS [training: 0.26807950949498427 | validation: 0.21575985064141961]
	TIME [epoch: 9.07 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23481104998038288		[learning rate: 0.0020546]
	Learning Rate: 0.00205465
	LOSS [training: 0.23481104998038288 | validation: 0.2307377424073047]
	TIME [epoch: 9.07 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2161934418422157		[learning rate: 0.0020497]
	Learning Rate: 0.00204967
	LOSS [training: 0.2161934418422157 | validation: 0.2082931957540723]
	TIME [epoch: 9.06 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2349940383884948		[learning rate: 0.0020447]
	Learning Rate: 0.00204471
	LOSS [training: 0.2349940383884948 | validation: 0.24803639973171826]
	TIME [epoch: 9.06 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24659406658044852		[learning rate: 0.0020398]
	Learning Rate: 0.00203976
	LOSS [training: 0.24659406658044852 | validation: 0.22858991617858332]
	TIME [epoch: 9.06 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22161398702765642		[learning rate: 0.0020348]
	Learning Rate: 0.00203482
	LOSS [training: 0.22161398702765642 | validation: 0.21710258515474695]
	TIME [epoch: 9.09 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24497144755840491		[learning rate: 0.0020299]
	Learning Rate: 0.0020299
	LOSS [training: 0.24497144755840491 | validation: 0.2500666311340527]
	TIME [epoch: 9.06 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27256201209207537		[learning rate: 0.002025]
	Learning Rate: 0.00202498
	LOSS [training: 0.27256201209207537 | validation: 0.29842118913478377]
	TIME [epoch: 9.07 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2600243421765223		[learning rate: 0.0020201]
	Learning Rate: 0.00202008
	LOSS [training: 0.2600243421765223 | validation: 0.22780337934256195]
	TIME [epoch: 9.06 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25026434699244243		[learning rate: 0.0020152]
	Learning Rate: 0.00201519
	LOSS [training: 0.25026434699244243 | validation: 0.24131174098781494]
	TIME [epoch: 9.07 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2601320135599055		[learning rate: 0.0020103]
	Learning Rate: 0.00201031
	LOSS [training: 0.2601320135599055 | validation: 0.2614422512916555]
	TIME [epoch: 9.09 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2924022067314035		[learning rate: 0.0020054]
	Learning Rate: 0.00200544
	LOSS [training: 0.2924022067314035 | validation: 0.3152686297092778]
	TIME [epoch: 9.06 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.264009747289729		[learning rate: 0.0020006]
	Learning Rate: 0.00200059
	LOSS [training: 0.264009747289729 | validation: 0.24696842962023396]
	TIME [epoch: 9.06 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2811492385937734		[learning rate: 0.0019957]
	Learning Rate: 0.00199575
	LOSS [training: 0.2811492385937734 | validation: 0.2205668474219279]
	TIME [epoch: 9.06 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2460724514679909		[learning rate: 0.0019909]
	Learning Rate: 0.00199091
	LOSS [training: 0.2460724514679909 | validation: 0.21991285630665497]
	TIME [epoch: 9.08 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2516656573185546		[learning rate: 0.0019861]
	Learning Rate: 0.00198609
	LOSS [training: 0.2516656573185546 | validation: 0.2299729856232347]
	TIME [epoch: 9.07 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23337995893091495		[learning rate: 0.0019813]
	Learning Rate: 0.00198129
	LOSS [training: 0.23337995893091495 | validation: 0.25968605309321274]
	TIME [epoch: 9.06 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24928382318474634		[learning rate: 0.0019765]
	Learning Rate: 0.00197649
	LOSS [training: 0.24928382318474634 | validation: 0.2602098163877984]
	TIME [epoch: 9.08 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27526746126352225		[learning rate: 0.0019717]
	Learning Rate: 0.00197171
	LOSS [training: 0.27526746126352225 | validation: 0.30230089914327307]
	TIME [epoch: 9.07 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2720368014346428		[learning rate: 0.0019669]
	Learning Rate: 0.00196693
	LOSS [training: 0.2720368014346428 | validation: 0.2451687603250581]
	TIME [epoch: 9.07 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24490174747308546		[learning rate: 0.0019622]
	Learning Rate: 0.00196217
	LOSS [training: 0.24490174747308546 | validation: 0.21186401035293223]
	TIME [epoch: 9.07 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.241598507596056		[learning rate: 0.0019574]
	Learning Rate: 0.00195742
	LOSS [training: 0.241598507596056 | validation: 0.21330248760378437]
	TIME [epoch: 9.06 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22135998218039635		[learning rate: 0.0019527]
	Learning Rate: 0.00195268
	LOSS [training: 0.22135998218039635 | validation: 0.2363587531723551]
	TIME [epoch: 9.07 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2598641653621201		[learning rate: 0.001948]
	Learning Rate: 0.00194796
	LOSS [training: 0.2598641653621201 | validation: 0.23386585476015534]
	TIME [epoch: 9.08 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2575412119352276		[learning rate: 0.0019432]
	Learning Rate: 0.00194324
	LOSS [training: 0.2575412119352276 | validation: 0.23690867322869946]
	TIME [epoch: 9.08 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24370248772394182		[learning rate: 0.0019385]
	Learning Rate: 0.00193854
	LOSS [training: 0.24370248772394182 | validation: 0.22288132443732012]
	TIME [epoch: 9.07 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23072343349689656		[learning rate: 0.0019338]
	Learning Rate: 0.00193384
	LOSS [training: 0.23072343349689656 | validation: 0.20207511301802888]
	TIME [epoch: 9.06 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22844781349910606		[learning rate: 0.0019292]
	Learning Rate: 0.00192916
	LOSS [training: 0.22844781349910606 | validation: 0.21257073874990662]
	TIME [epoch: 9.06 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21114034570710416		[learning rate: 0.0019245]
	Learning Rate: 0.00192449
	LOSS [training: 0.21114034570710416 | validation: 0.245687289245783]
	TIME [epoch: 9.08 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22618158268952498		[learning rate: 0.0019198]
	Learning Rate: 0.00191983
	LOSS [training: 0.22618158268952498 | validation: 0.23695698421215744]
	TIME [epoch: 9.06 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22351471794465666		[learning rate: 0.0019152]
	Learning Rate: 0.00191518
	LOSS [training: 0.22351471794465666 | validation: 0.20389313966995906]
	TIME [epoch: 9.06 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22025387070982377		[learning rate: 0.0019105]
	Learning Rate: 0.00191055
	LOSS [training: 0.22025387070982377 | validation: 0.22636029292911566]
	TIME [epoch: 9.06 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3755600923489997		[learning rate: 0.0019059]
	Learning Rate: 0.00190592
	LOSS [training: 0.3755600923489997 | validation: 0.4704975900595057]
	TIME [epoch: 9.06 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35522216525961753		[learning rate: 0.0019013]
	Learning Rate: 0.00190131
	LOSS [training: 0.35522216525961753 | validation: 0.21407655374294393]
	TIME [epoch: 9.08 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2234019204534392		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.2234019204534392 | validation: 0.21740573324102203]
	TIME [epoch: 9.07 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21503411251204452		[learning rate: 0.0018921]
	Learning Rate: 0.00189211
	LOSS [training: 0.21503411251204452 | validation: 0.22535386387945783]
	TIME [epoch: 9.07 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23146980516672352		[learning rate: 0.0018875]
	Learning Rate: 0.00188753
	LOSS [training: 0.23146980516672352 | validation: 0.2039843213714272]
	TIME [epoch: 9.07 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22380627736799222		[learning rate: 0.001883]
	Learning Rate: 0.00188296
	LOSS [training: 0.22380627736799222 | validation: 0.21135972468054787]
	TIME [epoch: 9.09 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2440883416863159		[learning rate: 0.0018784]
	Learning Rate: 0.00187841
	LOSS [training: 0.2440883416863159 | validation: 0.26627231619028613]
	TIME [epoch: 9.08 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22874842707117837		[learning rate: 0.0018739]
	Learning Rate: 0.00187386
	LOSS [training: 0.22874842707117837 | validation: 0.21984038983789672]
	TIME [epoch: 9.06 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23916770916660104		[learning rate: 0.0018693]
	Learning Rate: 0.00186932
	LOSS [training: 0.23916770916660104 | validation: 0.21027237220406922]
	TIME [epoch: 9.07 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23038573370972334		[learning rate: 0.0018648]
	Learning Rate: 0.0018648
	LOSS [training: 0.23038573370972334 | validation: 0.22465935001277235]
	TIME [epoch: 9.06 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21351274059619446		[learning rate: 0.0018603]
	Learning Rate: 0.00186028
	LOSS [training: 0.21351274059619446 | validation: 0.21710412606030466]
	TIME [epoch: 9.08 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22906960418420347		[learning rate: 0.0018558]
	Learning Rate: 0.00185578
	LOSS [training: 0.22906960418420347 | validation: 0.21648161881592112]
	TIME [epoch: 9.07 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.225286901985569		[learning rate: 0.0018513]
	Learning Rate: 0.00185129
	LOSS [training: 0.225286901985569 | validation: 0.24074196963477193]
	TIME [epoch: 9.06 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23479887802194663		[learning rate: 0.0018468]
	Learning Rate: 0.0018468
	LOSS [training: 0.23479887802194663 | validation: 0.24819368190586086]
	TIME [epoch: 9.07 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23414777977745355		[learning rate: 0.0018423]
	Learning Rate: 0.00184233
	LOSS [training: 0.23414777977745355 | validation: 0.27707652978959263]
	TIME [epoch: 9.09 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25564504123750553		[learning rate: 0.0018379]
	Learning Rate: 0.00183787
	LOSS [training: 0.25564504123750553 | validation: 0.3054118504927827]
	TIME [epoch: 9.07 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24655062963805402		[learning rate: 0.0018334]
	Learning Rate: 0.00183343
	LOSS [training: 0.24655062963805402 | validation: 0.29852921097032503]
	TIME [epoch: 9.07 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28060227681581157		[learning rate: 0.001829]
	Learning Rate: 0.00182899
	LOSS [training: 0.28060227681581157 | validation: 0.28997700614868693]
	TIME [epoch: 9.07 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26651504002767273		[learning rate: 0.0018246]
	Learning Rate: 0.00182456
	LOSS [training: 0.26651504002767273 | validation: 0.26513277907002053]
	TIME [epoch: 9.08 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2546647301314836		[learning rate: 0.0018201]
	Learning Rate: 0.00182014
	LOSS [training: 0.2546647301314836 | validation: 0.281678928088419]
	TIME [epoch: 9.09 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3042580034386879		[learning rate: 0.0018157]
	Learning Rate: 0.00181574
	LOSS [training: 0.3042580034386879 | validation: 0.33173723590702775]
	TIME [epoch: 9.07 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27654979978290123		[learning rate: 0.0018113]
	Learning Rate: 0.00181134
	LOSS [training: 0.27654979978290123 | validation: 0.2697948602426845]
	TIME [epoch: 9.07 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24663060627465985		[learning rate: 0.001807]
	Learning Rate: 0.00180696
	LOSS [training: 0.24663060627465985 | validation: 0.3050968605161529]
	TIME [epoch: 9.07 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2556476488115478		[learning rate: 0.0018026]
	Learning Rate: 0.00180258
	LOSS [training: 0.2556476488115478 | validation: 0.23336800139842478]
	TIME [epoch: 9.06 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22371455273025848		[learning rate: 0.0017982]
	Learning Rate: 0.00179822
	LOSS [training: 0.22371455273025848 | validation: 0.2339429582153107]
	TIME [epoch: 9.08 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24061529316213986		[learning rate: 0.0017939]
	Learning Rate: 0.00179386
	LOSS [training: 0.24061529316213986 | validation: 0.25166310810451237]
	TIME [epoch: 9.06 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26630904567007974		[learning rate: 0.0017895]
	Learning Rate: 0.00178952
	LOSS [training: 0.26630904567007974 | validation: 0.3603376131641477]
	TIME [epoch: 9.07 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2956097466113015		[learning rate: 0.0017852]
	Learning Rate: 0.00178519
	LOSS [training: 0.2956097466113015 | validation: 0.34563501638815164]
	TIME [epoch: 9.06 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2711436510977348		[learning rate: 0.0017809]
	Learning Rate: 0.00178087
	LOSS [training: 0.2711436510977348 | validation: 0.2361013969459081]
	TIME [epoch: 9.08 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23067656752159169		[learning rate: 0.0017766]
	Learning Rate: 0.00177656
	LOSS [training: 0.23067656752159169 | validation: 0.2069912670199444]
	TIME [epoch: 9.07 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22748676076734559		[learning rate: 0.0017723]
	Learning Rate: 0.00177226
	LOSS [training: 0.22748676076734559 | validation: 0.19479762531707143]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_814.pth
	Model improved!!!
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22412556209291315		[learning rate: 0.001768]
	Learning Rate: 0.00176797
	LOSS [training: 0.22412556209291315 | validation: 0.3180680988603123]
	TIME [epoch: 9.08 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24911749748898737		[learning rate: 0.0017637]
	Learning Rate: 0.00176369
	LOSS [training: 0.24911749748898737 | validation: 0.25097181568083904]
	TIME [epoch: 9.07 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2120210200745809		[learning rate: 0.0017594]
	Learning Rate: 0.00175942
	LOSS [training: 0.2120210200745809 | validation: 0.2048877771205212]
	TIME [epoch: 9.08 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21418703116906154		[learning rate: 0.0017552]
	Learning Rate: 0.00175516
	LOSS [training: 0.21418703116906154 | validation: 0.20533420201967245]
	TIME [epoch: 9.06 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22029846841593712		[learning rate: 0.0017509]
	Learning Rate: 0.00175091
	LOSS [training: 0.22029846841593712 | validation: 0.20708155287421437]
	TIME [epoch: 9.05 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20806133954893952		[learning rate: 0.0017467]
	Learning Rate: 0.00174667
	LOSS [training: 0.20806133954893952 | validation: 0.19764926092172885]
	TIME [epoch: 9.06 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23044196144331064		[learning rate: 0.0017424]
	Learning Rate: 0.00174244
	LOSS [training: 0.23044196144331064 | validation: 0.29259291095991097]
	TIME [epoch: 9.08 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31276944713243743		[learning rate: 0.0017382]
	Learning Rate: 0.00173822
	LOSS [training: 0.31276944713243743 | validation: 0.22738441014168842]
	TIME [epoch: 9.06 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26746128986551343		[learning rate: 0.001734]
	Learning Rate: 0.00173401
	LOSS [training: 0.26746128986551343 | validation: 0.25643173098645294]
	TIME [epoch: 9.06 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42883415811167797		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.42883415811167797 | validation: 0.31291076524221306]
	TIME [epoch: 9.04 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3528019694370967		[learning rate: 0.0017256]
	Learning Rate: 0.00172563
	LOSS [training: 0.3528019694370967 | validation: 0.2505846392150008]
	TIME [epoch: 9.06 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28716992113487183		[learning rate: 0.0017215]
	Learning Rate: 0.00172145
	LOSS [training: 0.28716992113487183 | validation: 0.2668236962291305]
	TIME [epoch: 9.07 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36373133763629856		[learning rate: 0.0017173]
	Learning Rate: 0.00171728
	LOSS [training: 0.36373133763629856 | validation: 0.3221174613696923]
	TIME [epoch: 9.06 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29682353011490503		[learning rate: 0.0017131]
	Learning Rate: 0.00171313
	LOSS [training: 0.29682353011490503 | validation: 0.241699607955619]
	TIME [epoch: 9.06 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24633081267601892		[learning rate: 0.001709]
	Learning Rate: 0.00170898
	LOSS [training: 0.24633081267601892 | validation: 0.21343205912691757]
	TIME [epoch: 9.06 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26053153941266827		[learning rate: 0.0017048]
	Learning Rate: 0.00170484
	LOSS [training: 0.26053153941266827 | validation: 0.29265003524818123]
	TIME [epoch: 9.07 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3610960661629853		[learning rate: 0.0017007]
	Learning Rate: 0.00170072
	LOSS [training: 0.3610960661629853 | validation: 0.3228725322214495]
	TIME [epoch: 9.07 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39246620702251633		[learning rate: 0.0016966]
	Learning Rate: 0.0016966
	LOSS [training: 0.39246620702251633 | validation: 0.24639408783665262]
	TIME [epoch: 9.05 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3160160467588204		[learning rate: 0.0016925]
	Learning Rate: 0.00169249
	LOSS [training: 0.3160160467588204 | validation: 0.4002456697271522]
	TIME [epoch: 9.06 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4195341973793785		[learning rate: 0.0016884]
	Learning Rate: 0.00168839
	LOSS [training: 0.4195341973793785 | validation: 0.2505463717846207]
	TIME [epoch: 9.06 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2910550958699395		[learning rate: 0.0016843]
	Learning Rate: 0.00168431
	LOSS [training: 0.2910550958699395 | validation: 0.23513376837849415]
	TIME [epoch: 9.08 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3433778414338129		[learning rate: 0.0016802]
	Learning Rate: 0.00168023
	LOSS [training: 0.3433778414338129 | validation: 0.37137136568306717]
	TIME [epoch: 9.07 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36308188089992294		[learning rate: 0.0016762]
	Learning Rate: 0.00167616
	LOSS [training: 0.36308188089992294 | validation: 0.329362254195366]
	TIME [epoch: 9.06 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31878216101512924		[learning rate: 0.0016721]
	Learning Rate: 0.0016721
	LOSS [training: 0.31878216101512924 | validation: 0.249668293871243]
	TIME [epoch: 9.06 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28015966864391567		[learning rate: 0.0016681]
	Learning Rate: 0.00166806
	LOSS [training: 0.28015966864391567 | validation: 0.23687547336383963]
	TIME [epoch: 9.05 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2695132141066118		[learning rate: 0.001664]
	Learning Rate: 0.00166402
	LOSS [training: 0.2695132141066118 | validation: 0.24997709265228618]
	TIME [epoch: 9.08 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2625426757916366		[learning rate: 0.00166]
	Learning Rate: 0.00165999
	LOSS [training: 0.2625426757916366 | validation: 0.2353813300938632]
	TIME [epoch: 9.07 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25367475352737456		[learning rate: 0.001656]
	Learning Rate: 0.00165597
	LOSS [training: 0.25367475352737456 | validation: 0.25442005170948767]
	TIME [epoch: 9.06 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42463722343080484		[learning rate: 0.001652]
	Learning Rate: 0.00165196
	LOSS [training: 0.42463722343080484 | validation: 0.4908516763139656]
	TIME [epoch: 9.06 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4533856432166997		[learning rate: 0.001648]
	Learning Rate: 0.00164796
	LOSS [training: 0.4533856432166997 | validation: 0.26366392466463884]
	TIME [epoch: 9.08 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32258373696696346		[learning rate: 0.001644]
	Learning Rate: 0.00164397
	LOSS [training: 0.32258373696696346 | validation: 0.2548762340548666]
	TIME [epoch: 9.06 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3398675027423614		[learning rate: 0.00164]
	Learning Rate: 0.00163999
	LOSS [training: 0.3398675027423614 | validation: 0.32221711513522244]
	TIME [epoch: 9.07 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3187373050998049		[learning rate: 0.001636]
	Learning Rate: 0.00163602
	LOSS [training: 0.3187373050998049 | validation: 0.2182744711559934]
	TIME [epoch: 9.07 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26329777129580734		[learning rate: 0.0016321]
	Learning Rate: 0.00163206
	LOSS [training: 0.26329777129580734 | validation: 0.22112921839107313]
	TIME [epoch: 9.07 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25508327052319774		[learning rate: 0.0016281]
	Learning Rate: 0.00162811
	LOSS [training: 0.25508327052319774 | validation: 0.265179505839074]
	TIME [epoch: 9.08 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3014168410396669		[learning rate: 0.0016242]
	Learning Rate: 0.00162417
	LOSS [training: 0.3014168410396669 | validation: 0.28640708998442826]
	TIME [epoch: 9.07 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32024902065297833		[learning rate: 0.0016202]
	Learning Rate: 0.00162024
	LOSS [training: 0.32024902065297833 | validation: 0.30366742234748584]
	TIME [epoch: 9.06 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30435528236143505		[learning rate: 0.0016163]
	Learning Rate: 0.00161632
	LOSS [training: 0.30435528236143505 | validation: 0.2513608494302835]
	TIME [epoch: 9.07 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26764839751896374		[learning rate: 0.0016124]
	Learning Rate: 0.0016124
	LOSS [training: 0.26764839751896374 | validation: 0.2452713141237811]
	TIME [epoch: 9.08 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2978887107328654		[learning rate: 0.0016085]
	Learning Rate: 0.0016085
	LOSS [training: 0.2978887107328654 | validation: 0.28243654130952794]
	TIME [epoch: 9.07 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32243526646430665		[learning rate: 0.0016046]
	Learning Rate: 0.00160461
	LOSS [training: 0.32243526646430665 | validation: 0.24921302857457409]
	TIME [epoch: 9.06 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2788359988309951		[learning rate: 0.0016007]
	Learning Rate: 0.00160072
	LOSS [training: 0.2788359988309951 | validation: 0.26074360766617577]
	TIME [epoch: 9.07 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26218898992797185		[learning rate: 0.0015968]
	Learning Rate: 0.00159685
	LOSS [training: 0.26218898992797185 | validation: 0.27264326849868326]
	TIME [epoch: 9.06 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31784363834451296		[learning rate: 0.001593]
	Learning Rate: 0.00159298
	LOSS [training: 0.31784363834451296 | validation: 0.2839538386681266]
	TIME [epoch: 9.08 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2795217314891873		[learning rate: 0.0015891]
	Learning Rate: 0.00158912
	LOSS [training: 0.2795217314891873 | validation: 0.3008717108608956]
	TIME [epoch: 9.06 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2760077305009811		[learning rate: 0.0015853]
	Learning Rate: 0.00158528
	LOSS [training: 0.2760077305009811 | validation: 0.24731298156316675]
	TIME [epoch: 9.07 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28254821226914595		[learning rate: 0.0015814]
	Learning Rate: 0.00158144
	LOSS [training: 0.28254821226914595 | validation: 0.2481165673554455]
	TIME [epoch: 9.06 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24974710318924243		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.24974710318924243 | validation: 0.22299253124812074]
	TIME [epoch: 9.06 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22391577555990608		[learning rate: 0.0015738]
	Learning Rate: 0.00157379
	LOSS [training: 0.22391577555990608 | validation: 0.2181103429847622]
	TIME [epoch: 9.08 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22500473282637895		[learning rate: 0.00157]
	Learning Rate: 0.00156998
	LOSS [training: 0.22500473282637895 | validation: 0.2191297036384392]
	TIME [epoch: 9.07 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24055750497611444		[learning rate: 0.0015662]
	Learning Rate: 0.00156618
	LOSS [training: 0.24055750497611444 | validation: 0.28965566045062396]
	TIME [epoch: 9.07 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23530626108167416		[learning rate: 0.0015624]
	Learning Rate: 0.00156239
	LOSS [training: 0.23530626108167416 | validation: 0.2004853042275378]
	TIME [epoch: 9.07 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22459012790194327		[learning rate: 0.0015586]
	Learning Rate: 0.00155861
	LOSS [training: 0.22459012790194327 | validation: 0.2294667359343291]
	TIME [epoch: 9.09 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2254059478053981		[learning rate: 0.0015548]
	Learning Rate: 0.00155483
	LOSS [training: 0.2254059478053981 | validation: 0.2587003347237422]
	TIME [epoch: 9.09 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23414724772109646		[learning rate: 0.0015511]
	Learning Rate: 0.00155107
	LOSS [training: 0.23414724772109646 | validation: 0.22423890891786047]
	TIME [epoch: 9.08 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22715038034771742		[learning rate: 0.0015473]
	Learning Rate: 0.00154732
	LOSS [training: 0.22715038034771742 | validation: 0.21431840606275232]
	TIME [epoch: 9.06 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23267259577019975		[learning rate: 0.0015436]
	Learning Rate: 0.00154357
	LOSS [training: 0.23267259577019975 | validation: 0.19794300801520426]
	TIME [epoch: 9.06 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22843745999814974		[learning rate: 0.0015398]
	Learning Rate: 0.00153983
	LOSS [training: 0.22843745999814974 | validation: 0.23608898647204157]
	TIME [epoch: 9.08 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2415403032492524		[learning rate: 0.0015361]
	Learning Rate: 0.00153611
	LOSS [training: 0.2415403032492524 | validation: 0.1978025812152096]
	TIME [epoch: 9.07 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23090417651203782		[learning rate: 0.0015324]
	Learning Rate: 0.00153239
	LOSS [training: 0.23090417651203782 | validation: 0.22182115680171643]
	TIME [epoch: 9.07 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24919589314170168		[learning rate: 0.0015287]
	Learning Rate: 0.00152868
	LOSS [training: 0.24919589314170168 | validation: 0.24211872725122086]
	TIME [epoch: 9.06 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.299317938997794		[learning rate: 0.001525]
	Learning Rate: 0.00152498
	LOSS [training: 0.299317938997794 | validation: 0.23645045335439158]
	TIME [epoch: 9.08 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26655591435061626		[learning rate: 0.0015213]
	Learning Rate: 0.00152128
	LOSS [training: 0.26655591435061626 | validation: 0.2858230962683038]
	TIME [epoch: 9.06 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.273992902125618		[learning rate: 0.0015176]
	Learning Rate: 0.0015176
	LOSS [training: 0.273992902125618 | validation: 0.23478656455894598]
	TIME [epoch: 9.06 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25597020975632556		[learning rate: 0.0015139]
	Learning Rate: 0.00151393
	LOSS [training: 0.25597020975632556 | validation: 0.24221613373497639]
	TIME [epoch: 9.07 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27752440447135807		[learning rate: 0.0015103]
	Learning Rate: 0.00151026
	LOSS [training: 0.27752440447135807 | validation: 0.2801828505435948]
	TIME [epoch: 9.06 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24345202786167386		[learning rate: 0.0015066]
	Learning Rate: 0.00150661
	LOSS [training: 0.24345202786167386 | validation: 0.28824686960714646]
	TIME [epoch: 9.09 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23766749930721248		[learning rate: 0.001503]
	Learning Rate: 0.00150296
	LOSS [training: 0.23766749930721248 | validation: 0.2238363236093511]
	TIME [epoch: 9.07 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2438095846450125		[learning rate: 0.0014993]
	Learning Rate: 0.00149932
	LOSS [training: 0.2438095846450125 | validation: 0.20105752032518112]
	TIME [epoch: 9.06 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23560933359021652		[learning rate: 0.0014957]
	Learning Rate: 0.00149569
	LOSS [training: 0.23560933359021652 | validation: 0.20137156972226988]
	TIME [epoch: 9.06 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2348511248805094		[learning rate: 0.0014921]
	Learning Rate: 0.00149207
	LOSS [training: 0.2348511248805094 | validation: 0.23407631381793126]
	TIME [epoch: 9.07 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.205993494795872		[learning rate: 0.0014885]
	Learning Rate: 0.00148846
	LOSS [training: 0.205993494795872 | validation: 0.20033929295821945]
	TIME [epoch: 9.07 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21882150254695804		[learning rate: 0.0014849]
	Learning Rate: 0.00148486
	LOSS [training: 0.21882150254695804 | validation: 0.20456723642646782]
	TIME [epoch: 9.06 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24046726747380043		[learning rate: 0.0014813]
	Learning Rate: 0.00148126
	LOSS [training: 0.24046726747380043 | validation: 0.36118922930340747]
	TIME [epoch: 9.06 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25296726446069356		[learning rate: 0.0014777]
	Learning Rate: 0.00147768
	LOSS [training: 0.25296726446069356 | validation: 0.2505988932293804]
	TIME [epoch: 9.06 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2587380803489524		[learning rate: 0.0014741]
	Learning Rate: 0.0014741
	LOSS [training: 0.2587380803489524 | validation: 0.220816359861453]
	TIME [epoch: 9.07 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22773531426843965		[learning rate: 0.0014705]
	Learning Rate: 0.00147053
	LOSS [training: 0.22773531426843965 | validation: 0.29649554905677855]
	TIME [epoch: 9.06 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2365953395950739		[learning rate: 0.001467]
	Learning Rate: 0.00146697
	LOSS [training: 0.2365953395950739 | validation: 0.23756839909037353]
	TIME [epoch: 9.05 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2481413677456918		[learning rate: 0.0014634]
	Learning Rate: 0.00146342
	LOSS [training: 0.2481413677456918 | validation: 0.25150492020490645]
	TIME [epoch: 9.05 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23778717730024912		[learning rate: 0.0014599]
	Learning Rate: 0.00145988
	LOSS [training: 0.23778717730024912 | validation: 0.1962801055417865]
	TIME [epoch: 9.06 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2598019576675384		[learning rate: 0.0014563]
	Learning Rate: 0.00145634
	LOSS [training: 0.2598019576675384 | validation: 0.20749182644921488]
	TIME [epoch: 9.08 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2414047286992525		[learning rate: 0.0014528]
	Learning Rate: 0.00145282
	LOSS [training: 0.2414047286992525 | validation: 0.20682742567035306]
	TIME [epoch: 9.06 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2499976761025886		[learning rate: 0.0014493]
	Learning Rate: 0.0014493
	LOSS [training: 0.2499976761025886 | validation: 0.2168581914873901]
	TIME [epoch: 9.05 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22408171113261002		[learning rate: 0.0014458]
	Learning Rate: 0.00144579
	LOSS [training: 0.22408171113261002 | validation: 0.21185909534183364]
	TIME [epoch: 9.06 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21944168598953806		[learning rate: 0.0014423]
	Learning Rate: 0.00144229
	LOSS [training: 0.21944168598953806 | validation: 0.20225255066879444]
	TIME [epoch: 9.07 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21912648075769306		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.21912648075769306 | validation: 0.2306390302505269]
	TIME [epoch: 9.06 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23514514062148262		[learning rate: 0.0014353]
	Learning Rate: 0.00143532
	LOSS [training: 0.23514514062148262 | validation: 0.20896475091414113]
	TIME [epoch: 9.05 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2475235553515577		[learning rate: 0.0014318]
	Learning Rate: 0.00143184
	LOSS [training: 0.2475235553515577 | validation: 0.20169655644867612]
	TIME [epoch: 9.05 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22454169267155177		[learning rate: 0.0014284]
	Learning Rate: 0.00142837
	LOSS [training: 0.22454169267155177 | validation: 0.20900848968199626]
	TIME [epoch: 9.05 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2347024770269306		[learning rate: 0.0014249]
	Learning Rate: 0.00142492
	LOSS [training: 0.2347024770269306 | validation: 0.20400501123438944]
	TIME [epoch: 9.07 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21297459422838244		[learning rate: 0.0014215]
	Learning Rate: 0.00142147
	LOSS [training: 0.21297459422838244 | validation: 0.2104586033215523]
	TIME [epoch: 9.06 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23153691357914408		[learning rate: 0.001418]
	Learning Rate: 0.00141803
	LOSS [training: 0.23153691357914408 | validation: 0.20958452616840934]
	TIME [epoch: 9.06 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2295739094085396		[learning rate: 0.0014146]
	Learning Rate: 0.00141459
	LOSS [training: 0.2295739094085396 | validation: 0.2347077268683961]
	TIME [epoch: 9.06 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2305938787870808		[learning rate: 0.0014112]
	Learning Rate: 0.00141117
	LOSS [training: 0.2305938787870808 | validation: 0.20464882725552103]
	TIME [epoch: 9.07 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26218430449847147		[learning rate: 0.0014078]
	Learning Rate: 0.00140775
	LOSS [training: 0.26218430449847147 | validation: 0.2778732381083112]
	TIME [epoch: 9.07 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2343865755757483		[learning rate: 0.0014043]
	Learning Rate: 0.00140434
	LOSS [training: 0.2343865755757483 | validation: 0.2048819565150874]
	TIME [epoch: 9.05 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22508000303906325		[learning rate: 0.0014009]
	Learning Rate: 0.00140094
	LOSS [training: 0.22508000303906325 | validation: 0.2042171642303982]
	TIME [epoch: 9.05 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2381026199202302		[learning rate: 0.0013976]
	Learning Rate: 0.00139755
	LOSS [training: 0.2381026199202302 | validation: 0.23167221670025728]
	TIME [epoch: 9.06 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24274114038392608		[learning rate: 0.0013942]
	Learning Rate: 0.00139417
	LOSS [training: 0.24274114038392608 | validation: 0.21915266346249151]
	TIME [epoch: 9.08 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2552070367755087		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.2552070367755087 | validation: 0.2643685672703726]
	TIME [epoch: 9.06 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2577237085901868		[learning rate: 0.0013874]
	Learning Rate: 0.00138743
	LOSS [training: 0.2577237085901868 | validation: 0.2474813458673703]
	TIME [epoch: 9.05 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25545537562960646		[learning rate: 0.0013841]
	Learning Rate: 0.00138407
	LOSS [training: 0.25545537562960646 | validation: 0.26313969859624553]
	TIME [epoch: 9.05 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28398401858354105		[learning rate: 0.0013807]
	Learning Rate: 0.00138072
	LOSS [training: 0.28398401858354105 | validation: 0.25071467119218255]
	TIME [epoch: 9.06 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2896551620409302		[learning rate: 0.0013774]
	Learning Rate: 0.00137738
	LOSS [training: 0.2896551620409302 | validation: 0.21756758909746626]
	TIME [epoch: 9.08 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2508893372275692		[learning rate: 0.001374]
	Learning Rate: 0.00137404
	LOSS [training: 0.2508893372275692 | validation: 0.22317332275267365]
	TIME [epoch: 9.05 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24401129799896487		[learning rate: 0.0013707]
	Learning Rate: 0.00137072
	LOSS [training: 0.24401129799896487 | validation: 0.20328135492019048]
	TIME [epoch: 9.06 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2449329348697699		[learning rate: 0.0013674]
	Learning Rate: 0.0013674
	LOSS [training: 0.2449329348697699 | validation: 0.21029001060747576]
	TIME [epoch: 9.06 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23797132817175815		[learning rate: 0.0013641]
	Learning Rate: 0.00136409
	LOSS [training: 0.23797132817175815 | validation: 0.25219079684255125]
	TIME [epoch: 9.07 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25261654300697484		[learning rate: 0.0013608]
	Learning Rate: 0.00136078
	LOSS [training: 0.25261654300697484 | validation: 0.2512833968270354]
	TIME [epoch: 9.05 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24821645938229414		[learning rate: 0.0013575]
	Learning Rate: 0.00135749
	LOSS [training: 0.24821645938229414 | validation: 0.19874975695003677]
	TIME [epoch: 9.05 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23621850042542264		[learning rate: 0.0013542]
	Learning Rate: 0.0013542
	LOSS [training: 0.23621850042542264 | validation: 0.19616394228292472]
	TIME [epoch: 9.06 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23554587231249574		[learning rate: 0.0013509]
	Learning Rate: 0.00135093
	LOSS [training: 0.23554587231249574 | validation: 0.21308677722808728]
	TIME [epoch: 9.06 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23310588871627574		[learning rate: 0.0013477]
	Learning Rate: 0.00134766
	LOSS [training: 0.23310588871627574 | validation: 0.20294917544242624]
	TIME [epoch: 9.07 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2237064092662043		[learning rate: 0.0013444]
	Learning Rate: 0.00134439
	LOSS [training: 0.2237064092662043 | validation: 0.18240330959986156]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_928.pth
	Model improved!!!
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2150427231542928		[learning rate: 0.0013411]
	Learning Rate: 0.00134114
	LOSS [training: 0.2150427231542928 | validation: 0.21775837287773575]
	TIME [epoch: 9.06 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21121678190207982		[learning rate: 0.0013379]
	Learning Rate: 0.00133789
	LOSS [training: 0.21121678190207982 | validation: 0.18625665595293786]
	TIME [epoch: 9.07 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2119323183666244		[learning rate: 0.0013347]
	Learning Rate: 0.00133465
	LOSS [training: 0.2119323183666244 | validation: 0.21922407215792103]
	TIME [epoch: 9.07 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21259200065071102		[learning rate: 0.0013314]
	Learning Rate: 0.00133142
	LOSS [training: 0.21259200065071102 | validation: 0.22437572411885864]
	TIME [epoch: 9.07 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22278739604801565		[learning rate: 0.0013282]
	Learning Rate: 0.0013282
	LOSS [training: 0.22278739604801565 | validation: 0.213540399059297]
	TIME [epoch: 9.07 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21799130192738256		[learning rate: 0.001325]
	Learning Rate: 0.00132498
	LOSS [training: 0.21799130192738256 | validation: 0.2405194778121626]
	TIME [epoch: 9.07 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22138761925915365		[learning rate: 0.0013218]
	Learning Rate: 0.00132178
	LOSS [training: 0.22138761925915365 | validation: 0.23128596745255894]
	TIME [epoch: 9.07 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22466290458010696		[learning rate: 0.0013186]
	Learning Rate: 0.00131858
	LOSS [training: 0.22466290458010696 | validation: 0.202317226506324]
	TIME [epoch: 9.08 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23415120141155216		[learning rate: 0.0013154]
	Learning Rate: 0.00131538
	LOSS [training: 0.23415120141155216 | validation: 0.21693147181439004]
	TIME [epoch: 9.06 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21543390771851115		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.21543390771851115 | validation: 0.20235860143860007]
	TIME [epoch: 9.06 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2206690833216533		[learning rate: 0.001309]
	Learning Rate: 0.00130902
	LOSS [training: 0.2206690833216533 | validation: 0.2181790854106394]
	TIME [epoch: 9.06 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20609088021483868		[learning rate: 0.0013059]
	Learning Rate: 0.00130585
	LOSS [training: 0.20609088021483868 | validation: 0.19706078633373675]
	TIME [epoch: 9.07 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22934880525457985		[learning rate: 0.0013027]
	Learning Rate: 0.00130269
	LOSS [training: 0.22934880525457985 | validation: 0.21096836659891965]
	TIME [epoch: 9.07 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23240028633307253		[learning rate: 0.0012995]
	Learning Rate: 0.00129954
	LOSS [training: 0.23240028633307253 | validation: 0.26585692570277575]
	TIME [epoch: 9.06 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2618436679701862		[learning rate: 0.0012964]
	Learning Rate: 0.00129639
	LOSS [training: 0.2618436679701862 | validation: 0.2963045994993486]
	TIME [epoch: 9.06 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28350589115157177		[learning rate: 0.0012933]
	Learning Rate: 0.00129326
	LOSS [training: 0.28350589115157177 | validation: 0.296145362409043]
	TIME [epoch: 9.05 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.270972827696989		[learning rate: 0.0012901]
	Learning Rate: 0.00129012
	LOSS [training: 0.270972827696989 | validation: 0.28673230197340627]
	TIME [epoch: 9.09 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2451484587693033		[learning rate: 0.001287]
	Learning Rate: 0.001287
	LOSS [training: 0.2451484587693033 | validation: 0.24611932431657962]
	TIME [epoch: 9.07 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23480158680400504		[learning rate: 0.0012839]
	Learning Rate: 0.00128389
	LOSS [training: 0.23480158680400504 | validation: 0.21479568912056884]
	TIME [epoch: 9.07 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22385684113184653		[learning rate: 0.0012808]
	Learning Rate: 0.00128078
	LOSS [training: 0.22385684113184653 | validation: 0.1936119726766768]
	TIME [epoch: 9.06 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20868516202478796		[learning rate: 0.0012777]
	Learning Rate: 0.00127768
	LOSS [training: 0.20868516202478796 | validation: 0.22355740887618858]
	TIME [epoch: 9.06 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21463959904526977		[learning rate: 0.0012746]
	Learning Rate: 0.00127458
	LOSS [training: 0.21463959904526977 | validation: 0.18880565958716755]
	TIME [epoch: 9.07 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21335004741662308		[learning rate: 0.0012715]
	Learning Rate: 0.0012715
	LOSS [training: 0.21335004741662308 | validation: 0.18505555472092572]
	TIME [epoch: 9.05 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21126352007632304		[learning rate: 0.0012684]
	Learning Rate: 0.00126842
	LOSS [training: 0.21126352007632304 | validation: 0.20260802063685576]
	TIME [epoch: 9.06 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21875675515807994		[learning rate: 0.0012653]
	Learning Rate: 0.00126535
	LOSS [training: 0.21875675515807994 | validation: 0.19997656807626155]
	TIME [epoch: 9.06 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22744553898942416		[learning rate: 0.0012623]
	Learning Rate: 0.00126229
	LOSS [training: 0.22744553898942416 | validation: 0.1886434650114895]
	TIME [epoch: 9.08 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21753535864607493		[learning rate: 0.0012592]
	Learning Rate: 0.00125923
	LOSS [training: 0.21753535864607493 | validation: 0.22736061948758968]
	TIME [epoch: 9.06 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2642902398469725		[learning rate: 0.0012562]
	Learning Rate: 0.00125618
	LOSS [training: 0.2642902398469725 | validation: 0.22880823635955133]
	TIME [epoch: 9.05 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.252948892684211		[learning rate: 0.0012531]
	Learning Rate: 0.00125314
	LOSS [training: 0.252948892684211 | validation: 0.22477788068092416]
	TIME [epoch: 9.06 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22077780010493572		[learning rate: 0.0012501]
	Learning Rate: 0.00125011
	LOSS [training: 0.22077780010493572 | validation: 0.19753895250437473]
	TIME [epoch: 9.06 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21808045839747625		[learning rate: 0.0012471]
	Learning Rate: 0.00124708
	LOSS [training: 0.21808045839747625 | validation: 0.21347071410223006]
	TIME [epoch: 9.08 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24303616764026909		[learning rate: 0.0012441]
	Learning Rate: 0.00124406
	LOSS [training: 0.24303616764026909 | validation: 0.19405563577823245]
	TIME [epoch: 9.07 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22217510862183154		[learning rate: 0.0012411]
	Learning Rate: 0.00124105
	LOSS [training: 0.22217510862183154 | validation: 0.20958315175659115]
	TIME [epoch: 9.05 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22435464472153305		[learning rate: 0.001238]
	Learning Rate: 0.00123805
	LOSS [training: 0.22435464472153305 | validation: 0.21838797693320397]
	TIME [epoch: 9.06 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21246233936904155		[learning rate: 0.001235]
	Learning Rate: 0.00123505
	LOSS [training: 0.21246233936904155 | validation: 0.1919837055268533]
	TIME [epoch: 9.07 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2210200440796053		[learning rate: 0.0012321]
	Learning Rate: 0.00123206
	LOSS [training: 0.2210200440796053 | validation: 0.20559393762184672]
	TIME [epoch: 9.07 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21424060112295998		[learning rate: 0.0012291]
	Learning Rate: 0.00122908
	LOSS [training: 0.21424060112295998 | validation: 0.18943147325144954]
	TIME [epoch: 9.06 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22403715699816215		[learning rate: 0.0012261]
	Learning Rate: 0.0012261
	LOSS [training: 0.22403715699816215 | validation: 0.2249523971744783]
	TIME [epoch: 9.05 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21428353247004533		[learning rate: 0.0012231]
	Learning Rate: 0.00122313
	LOSS [training: 0.21428353247004533 | validation: 0.21348132512299553]
	TIME [epoch: 9.05 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23298129455023447		[learning rate: 0.0012202]
	Learning Rate: 0.00122017
	LOSS [training: 0.23298129455023447 | validation: 0.22816696357197314]
	TIME [epoch: 9.08 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21770565929650032		[learning rate: 0.0012172]
	Learning Rate: 0.00121722
	LOSS [training: 0.21770565929650032 | validation: 0.2152960945401785]
	TIME [epoch: 9.06 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2096351482079691		[learning rate: 0.0012143]
	Learning Rate: 0.00121427
	LOSS [training: 0.2096351482079691 | validation: 0.19410267423175148]
	TIME [epoch: 9.06 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21546451442958015		[learning rate: 0.0012113]
	Learning Rate: 0.00121133
	LOSS [training: 0.21546451442958015 | validation: 0.19552183158922343]
	TIME [epoch: 9.06 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22412710192731428		[learning rate: 0.0012084]
	Learning Rate: 0.0012084
	LOSS [training: 0.22412710192731428 | validation: 0.24020522985203943]
	TIME [epoch: 9.07 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22305783889167158		[learning rate: 0.0012055]
	Learning Rate: 0.00120547
	LOSS [training: 0.22305783889167158 | validation: 0.2209082383829022]
	TIME [epoch: 9.08 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20237345476910198		[learning rate: 0.0012026]
	Learning Rate: 0.00120256
	LOSS [training: 0.20237345476910198 | validation: 0.21413305302787072]
	TIME [epoch: 9.06 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19817465734678436		[learning rate: 0.0011996]
	Learning Rate: 0.00119964
	LOSS [training: 0.19817465734678436 | validation: 0.19885784625652772]
	TIME [epoch: 9.06 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2037961843915645		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.2037961843915645 | validation: 0.1835743110825998]
	TIME [epoch: 9.06 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20113531890680997		[learning rate: 0.0011938]
	Learning Rate: 0.00119384
	LOSS [training: 0.20113531890680997 | validation: 0.19715135987878457]
	TIME [epoch: 9.07 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20181114666862693		[learning rate: 0.001191]
	Learning Rate: 0.00119095
	LOSS [training: 0.20181114666862693 | validation: 0.19227122444484557]
	TIME [epoch: 9.07 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20497310777133443		[learning rate: 0.0011881]
	Learning Rate: 0.00118807
	LOSS [training: 0.20497310777133443 | validation: 0.21754688896159297]
	TIME [epoch: 9.06 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21240102996596014		[learning rate: 0.0011852]
	Learning Rate: 0.00118519
	LOSS [training: 0.21240102996596014 | validation: 0.2092119150654146]
	TIME [epoch: 9.07 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21209412588878535		[learning rate: 0.0011823]
	Learning Rate: 0.00118232
	LOSS [training: 0.21209412588878535 | validation: 0.22103803100873354]
	TIME [epoch: 9.06 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2082263316763205		[learning rate: 0.0011795]
	Learning Rate: 0.00117946
	LOSS [training: 0.2082263316763205 | validation: 0.23030250267294047]
	TIME [epoch: 9.08 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21082391987456406		[learning rate: 0.0011766]
	Learning Rate: 0.00117661
	LOSS [training: 0.21082391987456406 | validation: 0.19523791200755178]
	TIME [epoch: 9.06 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20792895277531392		[learning rate: 0.0011738]
	Learning Rate: 0.00117376
	LOSS [training: 0.20792895277531392 | validation: 0.21656789044911734]
	TIME [epoch: 9.05 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22167798756745838		[learning rate: 0.0011709]
	Learning Rate: 0.00117092
	LOSS [training: 0.22167798756745838 | validation: 0.19904298744565047]
	TIME [epoch: 9.07 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20865958765110873		[learning rate: 0.0011681]
	Learning Rate: 0.00116808
	LOSS [training: 0.20865958765110873 | validation: 0.2179454607339976]
	TIME [epoch: 9.09 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22161606047089566		[learning rate: 0.0011653]
	Learning Rate: 0.00116526
	LOSS [training: 0.22161606047089566 | validation: 0.18651117908184206]
	TIME [epoch: 9.06 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21086390040483546		[learning rate: 0.0011624]
	Learning Rate: 0.00116243
	LOSS [training: 0.21086390040483546 | validation: 0.2204637110301268]
	TIME [epoch: 9.06 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2273169415979736		[learning rate: 0.0011596]
	Learning Rate: 0.00115962
	LOSS [training: 0.2273169415979736 | validation: 0.24227130321532753]
	TIME [epoch: 9.06 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2900435670954447		[learning rate: 0.0011568]
	Learning Rate: 0.00115681
	LOSS [training: 0.2900435670954447 | validation: 0.3104760382943259]
	TIME [epoch: 9.06 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2634570155816845		[learning rate: 0.001154]
	Learning Rate: 0.00115401
	LOSS [training: 0.2634570155816845 | validation: 0.22850906475495886]
	TIME [epoch: 9.07 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2282987352858404		[learning rate: 0.0011512]
	Learning Rate: 0.00115122
	LOSS [training: 0.2282987352858404 | validation: 0.21796835642497606]
	TIME [epoch: 9.06 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21983430131519235		[learning rate: 0.0011484]
	Learning Rate: 0.00114843
	LOSS [training: 0.21983430131519235 | validation: 0.19426096180611285]
	TIME [epoch: 9.07 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20569149662941438		[learning rate: 0.0011457]
	Learning Rate: 0.00114565
	LOSS [training: 0.20569149662941438 | validation: 0.23936498186075095]
	TIME [epoch: 9.06 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22036227489981858		[learning rate: 0.0011429]
	Learning Rate: 0.00114288
	LOSS [training: 0.22036227489981858 | validation: 0.19412836848637322]
	TIME [epoch: 9.06 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20653417934232726		[learning rate: 0.0011401]
	Learning Rate: 0.00114011
	LOSS [training: 0.20653417934232726 | validation: 0.2398150524412166]
	TIME [epoch: 9.35 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22884730128137343		[learning rate: 0.0011374]
	Learning Rate: 0.00113735
	LOSS [training: 0.22884730128137343 | validation: 0.20012470086221826]
	TIME [epoch: 9.08 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20750065975562976		[learning rate: 0.0011346]
	Learning Rate: 0.0011346
	LOSS [training: 0.20750065975562976 | validation: 0.23146816262117303]
	TIME [epoch: 9.08 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22052800952713011		[learning rate: 0.0011319]
	Learning Rate: 0.00113185
	LOSS [training: 0.22052800952713011 | validation: 0.2100996813869963]
	TIME [epoch: 9.08 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23176929790573655		[learning rate: 0.0011291]
	Learning Rate: 0.00112911
	LOSS [training: 0.23176929790573655 | validation: 0.23547513644271617]
	TIME [epoch: 9.1 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23679605987360103		[learning rate: 0.0011264]
	Learning Rate: 0.00112638
	LOSS [training: 0.23679605987360103 | validation: 0.24266485092362197]
	TIME [epoch: 9.08 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23401635024191852		[learning rate: 0.0011237]
	Learning Rate: 0.00112365
	LOSS [training: 0.23401635024191852 | validation: 0.20163895652346625]
	TIME [epoch: 9.07 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2185896622986753		[learning rate: 0.0011209]
	Learning Rate: 0.00112093
	LOSS [training: 0.2185896622986753 | validation: 0.2088777897982787]
	TIME [epoch: 9.08 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2445900260929897		[learning rate: 0.0011182]
	Learning Rate: 0.00111822
	LOSS [training: 0.2445900260929897 | validation: 0.2149314397009387]
	TIME [epoch: 9.08 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22575373231591161		[learning rate: 0.0011155]
	Learning Rate: 0.00111551
	LOSS [training: 0.22575373231591161 | validation: 0.22913894269228402]
	TIME [epoch: 9.1 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23482558381643764		[learning rate: 0.0011128]
	Learning Rate: 0.00111281
	LOSS [training: 0.23482558381643764 | validation: 0.22468061260345085]
	TIME [epoch: 9.08 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22839800596804602		[learning rate: 0.0011101]
	Learning Rate: 0.00111012
	LOSS [training: 0.22839800596804602 | validation: 0.22058268926740987]
	TIME [epoch: 9.07 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23306981980667696		[learning rate: 0.0011074]
	Learning Rate: 0.00110743
	LOSS [training: 0.23306981980667696 | validation: 0.2546636604252187]
	TIME [epoch: 9.07 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24035976460076752		[learning rate: 0.0011047]
	Learning Rate: 0.00110475
	LOSS [training: 0.24035976460076752 | validation: 0.20937033809489222]
	TIME [epoch: 9.09 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2132241622289066		[learning rate: 0.0011021]
	Learning Rate: 0.00110207
	LOSS [training: 0.2132241622289066 | validation: 0.22771103201953546]
	TIME [epoch: 9.08 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25821861781883904		[learning rate: 0.0010994]
	Learning Rate: 0.00109941
	LOSS [training: 0.25821861781883904 | validation: 0.22461338086249108]
	TIME [epoch: 9.08 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2357915125710473		[learning rate: 0.0010967]
	Learning Rate: 0.00109674
	LOSS [training: 0.2357915125710473 | validation: 0.27321134624322296]
	TIME [epoch: 9.08 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24098315057893335		[learning rate: 0.0010941]
	Learning Rate: 0.00109409
	LOSS [training: 0.24098315057893335 | validation: 0.21015795092843176]
	TIME [epoch: 9.09 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23357291011347545		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.23357291011347545 | validation: 0.22771661173638308]
	TIME [epoch: 9.1 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22942313009438292		[learning rate: 0.0010888]
	Learning Rate: 0.0010888
	LOSS [training: 0.22942313009438292 | validation: 0.21642034791072423]
	TIME [epoch: 9.07 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2339396010477417		[learning rate: 0.0010862]
	Learning Rate: 0.00108616
	LOSS [training: 0.2339396010477417 | validation: 0.23575439630108105]
	TIME [epoch: 9.08 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23688110072662125		[learning rate: 0.0010835]
	Learning Rate: 0.00108353
	LOSS [training: 0.23688110072662125 | validation: 0.199731770247411]
	TIME [epoch: 9.08 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1995656110851986		[learning rate: 0.0010809]
	Learning Rate: 0.00108091
	LOSS [training: 0.1995656110851986 | validation: 0.2055727458251459]
	TIME [epoch: 9.09 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20166400688716563		[learning rate: 0.0010783]
	Learning Rate: 0.00107829
	LOSS [training: 0.20166400688716563 | validation: 0.21348167077875077]
	TIME [epoch: 9.08 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24872733640645098		[learning rate: 0.0010757]
	Learning Rate: 0.00107568
	LOSS [training: 0.24872733640645098 | validation: 0.2655679748597405]
	TIME [epoch: 9.06 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2711110155040882		[learning rate: 0.0010731]
	Learning Rate: 0.00107308
	LOSS [training: 0.2711110155040882 | validation: 0.24197351827248995]
	TIME [epoch: 9.08 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22861818829900446		[learning rate: 0.0010705]
	Learning Rate: 0.00107048
	LOSS [training: 0.22861818829900446 | validation: 0.22535430538355422]
	TIME [epoch: 9.06 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22575625883542588		[learning rate: 0.0010679]
	Learning Rate: 0.00106789
	LOSS [training: 0.22575625883542588 | validation: 0.19230511915745585]
	TIME [epoch: 9.09 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2134184108259957		[learning rate: 0.0010653]
	Learning Rate: 0.0010653
	LOSS [training: 0.2134184108259957 | validation: 0.19471345988525823]
	TIME [epoch: 9.08 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21462374758975694		[learning rate: 0.0010627]
	Learning Rate: 0.00106273
	LOSS [training: 0.21462374758975694 | validation: 0.23158601257991343]
	TIME [epoch: 9.09 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23424729546950473		[learning rate: 0.0010602]
	Learning Rate: 0.00106015
	LOSS [training: 0.23424729546950473 | validation: 0.2292267909683054]
	TIME [epoch: 9.08 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22560104964858735		[learning rate: 0.0010576]
	Learning Rate: 0.00105759
	LOSS [training: 0.22560104964858735 | validation: 0.24262988058046692]
	TIME [epoch: 9.09 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2167537559618861		[learning rate: 0.001055]
	Learning Rate: 0.00105503
	LOSS [training: 0.2167537559618861 | validation: 0.2087970399691313]
	TIME [epoch: 9.09 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22990290664408372		[learning rate: 0.0010525]
	Learning Rate: 0.00105247
	LOSS [training: 0.22990290664408372 | validation: 0.2525210556956454]
	TIME [epoch: 9.07 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23484163547963943		[learning rate: 0.0010499]
	Learning Rate: 0.00104992
	LOSS [training: 0.23484163547963943 | validation: 0.23121391974278305]
	TIME [epoch: 9.08 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23925070026739653		[learning rate: 0.0010474]
	Learning Rate: 0.00104738
	LOSS [training: 0.23925070026739653 | validation: 0.24734944205187803]
	TIME [epoch: 9.08 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2360299056077292		[learning rate: 0.0010448]
	Learning Rate: 0.00104485
	LOSS [training: 0.2360299056077292 | validation: 0.23335376025839588]
	TIME [epoch: 9.09 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22405067364201475		[learning rate: 0.0010423]
	Learning Rate: 0.00104232
	LOSS [training: 0.22405067364201475 | validation: 0.22477649672857364]
	TIME [epoch: 9.08 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.223435672050113		[learning rate: 0.0010398]
	Learning Rate: 0.00103979
	LOSS [training: 0.223435672050113 | validation: 0.21685506880980102]
	TIME [epoch: 9.07 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20951268358603362		[learning rate: 0.0010373]
	Learning Rate: 0.00103728
	LOSS [training: 0.20951268358603362 | validation: 0.21707031806197788]
	TIME [epoch: 9.08 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23196791290671434		[learning rate: 0.0010348]
	Learning Rate: 0.00103477
	LOSS [training: 0.23196791290671434 | validation: 0.269961456180454]
	TIME [epoch: 9.08 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2258313373216328		[learning rate: 0.0010323]
	Learning Rate: 0.00103226
	LOSS [training: 0.2258313373216328 | validation: 0.22679532050018752]
	TIME [epoch: 9.1 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25750570260567784		[learning rate: 0.0010298]
	Learning Rate: 0.00102976
	LOSS [training: 0.25750570260567784 | validation: 0.30164141124006144]
	TIME [epoch: 9.09 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27192241049327376		[learning rate: 0.0010273]
	Learning Rate: 0.00102727
	LOSS [training: 0.27192241049327376 | validation: 0.25227625048497215]
	TIME [epoch: 9.08 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23189705154536858		[learning rate: 0.0010248]
	Learning Rate: 0.00102478
	LOSS [training: 0.23189705154536858 | validation: 0.23795405374083795]
	TIME [epoch: 9.08 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2155012341980102		[learning rate: 0.0010223]
	Learning Rate: 0.0010223
	LOSS [training: 0.2155012341980102 | validation: 0.2218703914735542]
	TIME [epoch: 9.09 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20622344832444175		[learning rate: 0.0010198]
	Learning Rate: 0.00101983
	LOSS [training: 0.20622344832444175 | validation: 0.1950957543319436]
	TIME [epoch: 9.08 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20320062204412953		[learning rate: 0.0010174]
	Learning Rate: 0.00101736
	LOSS [training: 0.20320062204412953 | validation: 0.19025582462712898]
	TIME [epoch: 9.07 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2045129211025468		[learning rate: 0.0010149]
	Learning Rate: 0.00101489
	LOSS [training: 0.2045129211025468 | validation: 0.21541817543547434]
	TIME [epoch: 9.07 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20407070929040289		[learning rate: 0.0010124]
	Learning Rate: 0.00101244
	LOSS [training: 0.20407070929040289 | validation: 0.21370639446686024]
	TIME [epoch: 9.06 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22452803801729243		[learning rate: 0.00101]
	Learning Rate: 0.00100999
	LOSS [training: 0.22452803801729243 | validation: 0.19651816716205311]
	TIME [epoch: 9.09 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20403796724906922		[learning rate: 0.0010075]
	Learning Rate: 0.00100754
	LOSS [training: 0.20403796724906922 | validation: 0.18861078743972198]
	TIME [epoch: 9.07 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20654274344615892		[learning rate: 0.0010051]
	Learning Rate: 0.0010051
	LOSS [training: 0.20654274344615892 | validation: 0.19642955352124603]
	TIME [epoch: 9.07 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20699200589859212		[learning rate: 0.0010027]
	Learning Rate: 0.00100267
	LOSS [training: 0.20699200589859212 | validation: 0.1992659070523381]
	TIME [epoch: 9.06 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21356448282525076		[learning rate: 0.0010002]
	Learning Rate: 0.00100024
	LOSS [training: 0.21356448282525076 | validation: 0.22574977016304681]
	TIME [epoch: 9.07 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21871607498362247		[learning rate: 0.00099782]
	Learning Rate: 0.000997821
	LOSS [training: 0.21871607498362247 | validation: 0.19549092064999746]
	TIME [epoch: 9.08 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19777606843144419		[learning rate: 0.00099541]
	Learning Rate: 0.000995405
	LOSS [training: 0.19777606843144419 | validation: 0.20032709577740682]
	TIME [epoch: 9.08 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2111738810434451		[learning rate: 0.000993]
	Learning Rate: 0.000992996
	LOSS [training: 0.2111738810434451 | validation: 0.20968041774116858]
	TIME [epoch: 9.07 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2166201156027126		[learning rate: 0.00099059]
	Learning Rate: 0.000990592
	LOSS [training: 0.2166201156027126 | validation: 0.2059415749058417]
	TIME [epoch: 9.08 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20793494585165714		[learning rate: 0.00098819]
	Learning Rate: 0.000988194
	LOSS [training: 0.20793494585165714 | validation: 0.1881174068489718]
	TIME [epoch: 9.09 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21558936027184247		[learning rate: 0.0009858]
	Learning Rate: 0.000985801
	LOSS [training: 0.21558936027184247 | validation: 0.21758531429435995]
	TIME [epoch: 9.08 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21533022525317813		[learning rate: 0.00098341]
	Learning Rate: 0.000983415
	LOSS [training: 0.21533022525317813 | validation: 0.19928890304170338]
	TIME [epoch: 9.07 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21093818137906717		[learning rate: 0.00098103]
	Learning Rate: 0.000981034
	LOSS [training: 0.21093818137906717 | validation: 0.22696231444859477]
	TIME [epoch: 9.07 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21142306374666262		[learning rate: 0.00097866]
	Learning Rate: 0.000978659
	LOSS [training: 0.21142306374666262 | validation: 0.19892764412277963]
	TIME [epoch: 9.07 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21687284147768088		[learning rate: 0.00097629]
	Learning Rate: 0.00097629
	LOSS [training: 0.21687284147768088 | validation: 0.22333274712639156]
	TIME [epoch: 9.09 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21511289504918177		[learning rate: 0.00097393]
	Learning Rate: 0.000973927
	LOSS [training: 0.21511289504918177 | validation: 0.2208941686153596]
	TIME [epoch: 9.06 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21121958430376483		[learning rate: 0.00097157]
	Learning Rate: 0.000971569
	LOSS [training: 0.21121958430376483 | validation: 0.23742668771060427]
	TIME [epoch: 9.07 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21176771228273433		[learning rate: 0.00096922]
	Learning Rate: 0.000969217
	LOSS [training: 0.21176771228273433 | validation: 0.21733758943686654]
	TIME [epoch: 9.07 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2132603868282205		[learning rate: 0.00096687]
	Learning Rate: 0.000966871
	LOSS [training: 0.2132603868282205 | validation: 0.23488704440435018]
	TIME [epoch: 9.11 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22247934174131903		[learning rate: 0.00096453]
	Learning Rate: 0.00096453
	LOSS [training: 0.22247934174131903 | validation: 0.21550393718841165]
	TIME [epoch: 9.09 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21649628411914645		[learning rate: 0.00096219]
	Learning Rate: 0.000962195
	LOSS [training: 0.21649628411914645 | validation: 0.21936407989753487]
	TIME [epoch: 9.08 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2185730994546961		[learning rate: 0.00095987]
	Learning Rate: 0.000959866
	LOSS [training: 0.2185730994546961 | validation: 0.20793408206896968]
	TIME [epoch: 9.08 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21619055501630272		[learning rate: 0.00095754]
	Learning Rate: 0.000957542
	LOSS [training: 0.21619055501630272 | validation: 0.21295967364658402]
	TIME [epoch: 9.07 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21701138391028457		[learning rate: 0.00095522]
	Learning Rate: 0.000955224
	LOSS [training: 0.21701138391028457 | validation: 0.20658375564637377]
	TIME [epoch: 9.09 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22248208508407963		[learning rate: 0.00095291]
	Learning Rate: 0.000952912
	LOSS [training: 0.22248208508407963 | validation: 0.23856511444144396]
	TIME [epoch: 9.08 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22083190422895949		[learning rate: 0.0009506]
	Learning Rate: 0.000950605
	LOSS [training: 0.22083190422895949 | validation: 0.21276663422566414]
	TIME [epoch: 9.07 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22466296412551343		[learning rate: 0.0009483]
	Learning Rate: 0.000948304
	LOSS [training: 0.22466296412551343 | validation: 0.20048579900255137]
	TIME [epoch: 9.08 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21991872605299703		[learning rate: 0.00094601]
	Learning Rate: 0.000946008
	LOSS [training: 0.21991872605299703 | validation: 0.20400860429405787]
	TIME [epoch: 9.09 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20811497453288239		[learning rate: 0.00094372]
	Learning Rate: 0.000943718
	LOSS [training: 0.20811497453288239 | validation: 0.20921395406115728]
	TIME [epoch: 9.09 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21863115600850863		[learning rate: 0.00094143]
	Learning Rate: 0.000941433
	LOSS [training: 0.21863115600850863 | validation: 0.1991661933582185]
	TIME [epoch: 9.08 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20577757086396847		[learning rate: 0.00093915]
	Learning Rate: 0.000939154
	LOSS [training: 0.20577757086396847 | validation: 0.21993816180694362]
	TIME [epoch: 9.07 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21666965279557332		[learning rate: 0.00093688]
	Learning Rate: 0.00093688
	LOSS [training: 0.21666965279557332 | validation: 0.20671721223241796]
	TIME [epoch: 9.08 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20427623539219883		[learning rate: 0.00093461]
	Learning Rate: 0.000934613
	LOSS [training: 0.20427623539219883 | validation: 0.19131035186936124]
	TIME [epoch: 9.09 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21929898239209805		[learning rate: 0.00093235]
	Learning Rate: 0.00093235
	LOSS [training: 0.21929898239209805 | validation: 0.21205052805323105]
	TIME [epoch: 9.08 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22556753305593555		[learning rate: 0.00093009]
	Learning Rate: 0.000930093
	LOSS [training: 0.22556753305593555 | validation: 0.25900177268859687]
	TIME [epoch: 9.09 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23579484622550084		[learning rate: 0.00092784]
	Learning Rate: 0.000927841
	LOSS [training: 0.23579484622550084 | validation: 0.20628517023931522]
	TIME [epoch: 9.07 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21587062173631805		[learning rate: 0.0009256]
	Learning Rate: 0.000925595
	LOSS [training: 0.21587062173631805 | validation: 0.19734616519034748]
	TIME [epoch: 9.08 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21618824831974934		[learning rate: 0.00092335]
	Learning Rate: 0.000923354
	LOSS [training: 0.21618824831974934 | validation: 0.20476093694364544]
	TIME [epoch: 9.07 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2205884722945763		[learning rate: 0.00092112]
	Learning Rate: 0.000921119
	LOSS [training: 0.2205884722945763 | validation: 0.21457529646668155]
	TIME [epoch: 9.07 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23085200751937623		[learning rate: 0.00091889]
	Learning Rate: 0.000918889
	LOSS [training: 0.23085200751937623 | validation: 0.2306313348141616]
	TIME [epoch: 9.07 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24264432286164167		[learning rate: 0.00091666]
	Learning Rate: 0.000916665
	LOSS [training: 0.24264432286164167 | validation: 0.2397248184480532]
	TIME [epoch: 9.07 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22133448345043885		[learning rate: 0.00091445]
	Learning Rate: 0.000914446
	LOSS [training: 0.22133448345043885 | validation: 0.2236699656205865]
	TIME [epoch: 9.09 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21161003606715054		[learning rate: 0.00091223]
	Learning Rate: 0.000912232
	LOSS [training: 0.21161003606715054 | validation: 0.2018998917252387]
	TIME [epoch: 9.08 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2080313569829355		[learning rate: 0.00091002]
	Learning Rate: 0.000910024
	LOSS [training: 0.2080313569829355 | validation: 0.19266380908457154]
	TIME [epoch: 9.07 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20833562311574072		[learning rate: 0.00090782]
	Learning Rate: 0.000907821
	LOSS [training: 0.20833562311574072 | validation: 0.2082328365744197]
	TIME [epoch: 9.08 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20909268864445535		[learning rate: 0.00090562]
	Learning Rate: 0.000905623
	LOSS [training: 0.20909268864445535 | validation: 0.21674324192069955]
	TIME [epoch: 9.07 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21865634748391746		[learning rate: 0.00090343]
	Learning Rate: 0.00090343
	LOSS [training: 0.21865634748391746 | validation: 0.2065010088988297]
	TIME [epoch: 9.1 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20976263737158626		[learning rate: 0.00090124]
	Learning Rate: 0.000901243
	LOSS [training: 0.20976263737158626 | validation: 0.20468588336985782]
	TIME [epoch: 9.08 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21668056242277783		[learning rate: 0.00089906]
	Learning Rate: 0.000899062
	LOSS [training: 0.21668056242277783 | validation: 0.19402067975347886]
	TIME [epoch: 9.08 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21359741004676933		[learning rate: 0.00089689]
	Learning Rate: 0.000896885
	LOSS [training: 0.21359741004676933 | validation: 0.23817485896083562]
	TIME [epoch: 9.07 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26439557389017715		[learning rate: 0.00089471]
	Learning Rate: 0.000894714
	LOSS [training: 0.26439557389017715 | validation: 0.2798033830299339]
	TIME [epoch: 9.09 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2591470318250046		[learning rate: 0.00089255]
	Learning Rate: 0.000892548
	LOSS [training: 0.2591470318250046 | validation: 0.2850554887411504]
	TIME [epoch: 9.09 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27321033224752456		[learning rate: 0.00089039]
	Learning Rate: 0.000890387
	LOSS [training: 0.27321033224752456 | validation: 0.31572847396646064]
	TIME [epoch: 9.07 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2814541330012263		[learning rate: 0.00088823]
	Learning Rate: 0.000888232
	LOSS [training: 0.2814541330012263 | validation: 0.32123484813629877]
	TIME [epoch: 9.08 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2946691883927498		[learning rate: 0.00088608]
	Learning Rate: 0.000886081
	LOSS [training: 0.2946691883927498 | validation: 0.32946525050875575]
	TIME [epoch: 9.08 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32848842013328117		[learning rate: 0.00088394]
	Learning Rate: 0.000883936
	LOSS [training: 0.32848842013328117 | validation: 0.3184351121811081]
	TIME [epoch: 9.09 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2686835648576369		[learning rate: 0.0008818]
	Learning Rate: 0.000881797
	LOSS [training: 0.2686835648576369 | validation: 0.2707593527864884]
	TIME [epoch: 9.07 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23136649812287535		[learning rate: 0.00087966]
	Learning Rate: 0.000879662
	LOSS [training: 0.23136649812287535 | validation: 0.23971398865188304]
	TIME [epoch: 9.08 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23365052970816916		[learning rate: 0.00087753]
	Learning Rate: 0.000877532
	LOSS [training: 0.23365052970816916 | validation: 0.27884668900246223]
	TIME [epoch: 9.09 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24523791908120698		[learning rate: 0.00087541]
	Learning Rate: 0.000875408
	LOSS [training: 0.24523791908120698 | validation: 0.2704762459191877]
	TIME [epoch: 9.1 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2675723528234553		[learning rate: 0.00087329]
	Learning Rate: 0.000873289
	LOSS [training: 0.2675723528234553 | validation: 0.27385939188678177]
	TIME [epoch: 9.08 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2516328103501926		[learning rate: 0.00087117]
	Learning Rate: 0.000871175
	LOSS [training: 0.2516328103501926 | validation: 0.2348295615742197]
	TIME [epoch: 9.08 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22562964474016106		[learning rate: 0.00086907]
	Learning Rate: 0.000869066
	LOSS [training: 0.22562964474016106 | validation: 0.2184083610086526]
	TIME [epoch: 9.08 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2252934755565744		[learning rate: 0.00086696]
	Learning Rate: 0.000866962
	LOSS [training: 0.2252934755565744 | validation: 0.2352541812866577]
	TIME [epoch: 9.08 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23072389880296215		[learning rate: 0.00086486]
	Learning Rate: 0.000864863
	LOSS [training: 0.23072389880296215 | validation: 0.23479745775115582]
	TIME [epoch: 9.09 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21803441180939392		[learning rate: 0.00086277]
	Learning Rate: 0.000862769
	LOSS [training: 0.21803441180939392 | validation: 0.22617616030732668]
	TIME [epoch: 9.08 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2193803128119131		[learning rate: 0.00086068]
	Learning Rate: 0.000860681
	LOSS [training: 0.2193803128119131 | validation: 0.2079848390105442]
	TIME [epoch: 9.08 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21055255632640818		[learning rate: 0.0008586]
	Learning Rate: 0.000858597
	LOSS [training: 0.21055255632640818 | validation: 0.23083720066145397]
	TIME [epoch: 9.07 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22229007534786377		[learning rate: 0.00085652]
	Learning Rate: 0.000856519
	LOSS [training: 0.22229007534786377 | validation: 0.2100239482605939]
	TIME [epoch: 9.07 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22372301123569177		[learning rate: 0.00085445]
	Learning Rate: 0.000854445
	LOSS [training: 0.22372301123569177 | validation: 0.24009664973296185]
	TIME [epoch: 9.08 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23182487777233907		[learning rate: 0.00085238]
	Learning Rate: 0.000852377
	LOSS [training: 0.23182487777233907 | validation: 0.2602560139754202]
	TIME [epoch: 9.07 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2363403385523525		[learning rate: 0.00085031]
	Learning Rate: 0.000850313
	LOSS [training: 0.2363403385523525 | validation: 0.22268895693324037]
	TIME [epoch: 9.08 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21263606887819314		[learning rate: 0.00084825]
	Learning Rate: 0.000848255
	LOSS [training: 0.21263606887819314 | validation: 0.20153964883128783]
	TIME [epoch: 9.08 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20710877326588362		[learning rate: 0.0008462]
	Learning Rate: 0.000846201
	LOSS [training: 0.20710877326588362 | validation: 0.2025323521317569]
	TIME [epoch: 9.1 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2026172068936761		[learning rate: 0.00084415]
	Learning Rate: 0.000844153
	LOSS [training: 0.2026172068936761 | validation: 0.19691653219074073]
	TIME [epoch: 9.08 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20137622827190432		[learning rate: 0.00084211]
	Learning Rate: 0.000842109
	LOSS [training: 0.20137622827190432 | validation: 0.20297451954793966]
	TIME [epoch: 9.08 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21549612395122392		[learning rate: 0.00084007]
	Learning Rate: 0.000840071
	LOSS [training: 0.21549612395122392 | validation: 0.20189167432377392]
	TIME [epoch: 9.08 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20700523495805784		[learning rate: 0.00083804]
	Learning Rate: 0.000838037
	LOSS [training: 0.20700523495805784 | validation: 0.22613268056753744]
	TIME [epoch: 9.07 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2088544174261679		[learning rate: 0.00083601]
	Learning Rate: 0.000836008
	LOSS [training: 0.2088544174261679 | validation: 0.22170328301670253]
	TIME [epoch: 9.1 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21569038486958184		[learning rate: 0.00083398]
	Learning Rate: 0.000833984
	LOSS [training: 0.21569038486958184 | validation: 0.22121623607963414]
	TIME [epoch: 9.08 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22076507242217716		[learning rate: 0.00083197]
	Learning Rate: 0.000831965
	LOSS [training: 0.22076507242217716 | validation: 0.19773065672129791]
	TIME [epoch: 9.08 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.206484635740018		[learning rate: 0.00082995]
	Learning Rate: 0.000829951
	LOSS [training: 0.206484635740018 | validation: 0.20893054221337692]
	TIME [epoch: 9.07 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21338898599307105		[learning rate: 0.00082794]
	Learning Rate: 0.000827942
	LOSS [training: 0.21338898599307105 | validation: 0.20812098167182136]
	TIME [epoch: 9.09 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2172431279560331		[learning rate: 0.00082594]
	Learning Rate: 0.000825938
	LOSS [training: 0.2172431279560331 | validation: 0.21668162209472147]
	TIME [epoch: 9.07 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2116190921403859		[learning rate: 0.00082394]
	Learning Rate: 0.000823938
	LOSS [training: 0.2116190921403859 | validation: 0.1980120813302662]
	TIME [epoch: 9.08 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20028829862962616		[learning rate: 0.00082194]
	Learning Rate: 0.000821944
	LOSS [training: 0.20028829862962616 | validation: 0.1999760311987468]
	TIME [epoch: 9.08 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22018354630831344		[learning rate: 0.00081995]
	Learning Rate: 0.000819954
	LOSS [training: 0.22018354630831344 | validation: 0.22489298188559764]
	TIME [epoch: 9.09 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21077981003494167		[learning rate: 0.00081797]
	Learning Rate: 0.000817969
	LOSS [training: 0.21077981003494167 | validation: 0.20621884467791243]
	TIME [epoch: 9.09 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21471077348262885		[learning rate: 0.00081599]
	Learning Rate: 0.000815989
	LOSS [training: 0.21471077348262885 | validation: 0.20731628491165155]
	TIME [epoch: 9.07 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21045574550805038		[learning rate: 0.00081401]
	Learning Rate: 0.000814014
	LOSS [training: 0.21045574550805038 | validation: 0.20441531466847673]
	TIME [epoch: 9.07 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22803518269509762		[learning rate: 0.00081204]
	Learning Rate: 0.000812043
	LOSS [training: 0.22803518269509762 | validation: 0.20277333402770248]
	TIME [epoch: 9.07 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22092509758109996		[learning rate: 0.00081008]
	Learning Rate: 0.000810077
	LOSS [training: 0.22092509758109996 | validation: 0.19664257193086498]
	TIME [epoch: 9.09 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20301442378072512		[learning rate: 0.00080812]
	Learning Rate: 0.000808116
	LOSS [training: 0.20301442378072512 | validation: 0.2155923145333598]
	TIME [epoch: 9.08 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20780366428165897		[learning rate: 0.00080616]
	Learning Rate: 0.00080616
	LOSS [training: 0.20780366428165897 | validation: 0.20075358470506233]
	TIME [epoch: 9.07 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20091478341034136		[learning rate: 0.00080421]
	Learning Rate: 0.000804208
	LOSS [training: 0.20091478341034136 | validation: 0.2043886493144123]
	TIME [epoch: 9.08 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2082167752509918		[learning rate: 0.00080226]
	Learning Rate: 0.000802261
	LOSS [training: 0.2082167752509918 | validation: 0.1987266019591814]
	TIME [epoch: 9.08 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20933139050788713		[learning rate: 0.00080032]
	Learning Rate: 0.000800319
	LOSS [training: 0.20933139050788713 | validation: 0.20582883195492865]
	TIME [epoch: 9.09 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20543586422158766		[learning rate: 0.00079838]
	Learning Rate: 0.000798382
	LOSS [training: 0.20543586422158766 | validation: 0.19524379195090213]
	TIME [epoch: 9.08 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2161136036166255		[learning rate: 0.00079645]
	Learning Rate: 0.000796449
	LOSS [training: 0.2161136036166255 | validation: 0.216096930287261]
	TIME [epoch: 9.08 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2182947940322904		[learning rate: 0.00079452]
	Learning Rate: 0.000794521
	LOSS [training: 0.2182947940322904 | validation: 0.1935156693690162]
	TIME [epoch: 9.08 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20762108780450247		[learning rate: 0.0007926]
	Learning Rate: 0.000792597
	LOSS [training: 0.20762108780450247 | validation: 0.18977437109602457]
	TIME [epoch: 9.08 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20800544129035145		[learning rate: 0.00079068]
	Learning Rate: 0.000790679
	LOSS [training: 0.20800544129035145 | validation: 0.21055831578442769]
	TIME [epoch: 9.09 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21501112207278866		[learning rate: 0.00078876]
	Learning Rate: 0.000788765
	LOSS [training: 0.21501112207278866 | validation: 0.22691901965024053]
	TIME [epoch: 9.07 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2291090678861051		[learning rate: 0.00078686]
	Learning Rate: 0.000786855
	LOSS [training: 0.2291090678861051 | validation: 0.216208070565709]
	TIME [epoch: 9.07 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21417923818205464		[learning rate: 0.00078495]
	Learning Rate: 0.00078495
	LOSS [training: 0.21417923818205464 | validation: 0.21498307315426748]
	TIME [epoch: 9.07 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22539173776040947		[learning rate: 0.00078305]
	Learning Rate: 0.00078305
	LOSS [training: 0.22539173776040947 | validation: 0.2013776840876076]
	TIME [epoch: 9.1 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21168431457345172		[learning rate: 0.00078115]
	Learning Rate: 0.000781154
	LOSS [training: 0.21168431457345172 | validation: 0.19864958930280147]
	TIME [epoch: 9.08 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2221285768552735		[learning rate: 0.00077926]
	Learning Rate: 0.000779263
	LOSS [training: 0.2221285768552735 | validation: 0.23234881410225505]
	TIME [epoch: 9.07 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24013442555689637		[learning rate: 0.00077738]
	Learning Rate: 0.000777377
	LOSS [training: 0.24013442555689637 | validation: 0.25318661135240483]
	TIME [epoch: 9.08 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2542520886670282		[learning rate: 0.00077549]
	Learning Rate: 0.000775495
	LOSS [training: 0.2542520886670282 | validation: 0.25048337171824075]
	TIME [epoch: 9.07 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23337527571752212		[learning rate: 0.00077362]
	Learning Rate: 0.000773618
	LOSS [training: 0.23337527571752212 | validation: 0.22386526903171197]
	TIME [epoch: 9.1 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22227842507659937		[learning rate: 0.00077174]
	Learning Rate: 0.000771745
	LOSS [training: 0.22227842507659937 | validation: 0.238315223823453]
	TIME [epoch: 9.08 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2550261669935425		[learning rate: 0.00076988]
	Learning Rate: 0.000769877
	LOSS [training: 0.2550261669935425 | validation: 0.23068599858319636]
	TIME [epoch: 9.08 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2280267466367619		[learning rate: 0.00076801]
	Learning Rate: 0.000768013
	LOSS [training: 0.2280267466367619 | validation: 0.23597576222967098]
	TIME [epoch: 9.08 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2370126225972582		[learning rate: 0.00076615]
	Learning Rate: 0.000766154
	LOSS [training: 0.2370126225972582 | validation: 0.22588305195835426]
	TIME [epoch: 9.09 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23381405414751816		[learning rate: 0.0007643]
	Learning Rate: 0.000764299
	LOSS [training: 0.23381405414751816 | validation: 0.2307498872344742]
	TIME [epoch: 9.08 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23415157415390345		[learning rate: 0.00076245]
	Learning Rate: 0.000762448
	LOSS [training: 0.23415157415390345 | validation: 0.2559940385356765]
	TIME [epoch: 9.08 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23110889205689628		[learning rate: 0.0007606]
	Learning Rate: 0.000760603
	LOSS [training: 0.23110889205689628 | validation: 0.21399469284300782]
	TIME [epoch: 9.08 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21915982196954706		[learning rate: 0.00075876]
	Learning Rate: 0.000758761
	LOSS [training: 0.21915982196954706 | validation: 0.22573192822576404]
	TIME [epoch: 9.08 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22638555592763154		[learning rate: 0.00075692]
	Learning Rate: 0.000756925
	LOSS [training: 0.22638555592763154 | validation: 0.21492814779150216]
	TIME [epoch: 9.09 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22001097655142302		[learning rate: 0.00075509]
	Learning Rate: 0.000755092
	LOSS [training: 0.22001097655142302 | validation: 0.21578732662078629]
	TIME [epoch: 9.08 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23187562711204057		[learning rate: 0.00075326]
	Learning Rate: 0.000753264
	LOSS [training: 0.23187562711204057 | validation: 0.19439592849146958]
	TIME [epoch: 9.07 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21401751533098948		[learning rate: 0.00075144]
	Learning Rate: 0.000751441
	LOSS [training: 0.21401751533098948 | validation: 0.2000471321923743]
	TIME [epoch: 9.08 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2209699142011483		[learning rate: 0.00074962]
	Learning Rate: 0.000749622
	LOSS [training: 0.2209699142011483 | validation: 0.21152192741264808]
	TIME [epoch: 9.08 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21679543710159638		[learning rate: 0.00074781]
	Learning Rate: 0.000747807
	LOSS [training: 0.21679543710159638 | validation: 0.20472933588390607]
	TIME [epoch: 9.09 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22835682642427385		[learning rate: 0.000746]
	Learning Rate: 0.000745997
	LOSS [training: 0.22835682642427385 | validation: 0.25039055879140965]
	TIME [epoch: 9.08 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24183264277301136		[learning rate: 0.00074419]
	Learning Rate: 0.000744191
	LOSS [training: 0.24183264277301136 | validation: 0.2194823200446092]
	TIME [epoch: 9.08 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22420255036405065		[learning rate: 0.00074239]
	Learning Rate: 0.000742389
	LOSS [training: 0.22420255036405065 | validation: 0.21861920979413907]
	TIME [epoch: 9.07 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22223540724473426		[learning rate: 0.00074059]
	Learning Rate: 0.000740592
	LOSS [training: 0.22223540724473426 | validation: 0.1970950275931571]
	TIME [epoch: 9.09 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.215366633420343		[learning rate: 0.0007388]
	Learning Rate: 0.000738799
	LOSS [training: 0.215366633420343 | validation: 0.2102731095663994]
	TIME [epoch: 9.07 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21007553749809285		[learning rate: 0.00073701]
	Learning Rate: 0.000737011
	LOSS [training: 0.21007553749809285 | validation: 0.2061878348345484]
	TIME [epoch: 9.08 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2127796064889435		[learning rate: 0.00073523]
	Learning Rate: 0.000735226
	LOSS [training: 0.2127796064889435 | validation: 0.22687794206580697]
	TIME [epoch: 9.08 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21752845516547498		[learning rate: 0.00073345]
	Learning Rate: 0.000733446
	LOSS [training: 0.21752845516547498 | validation: 0.18911473706319062]
	TIME [epoch: 9.08 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21860929832060266		[learning rate: 0.00073167]
	Learning Rate: 0.000731671
	LOSS [training: 0.21860929832060266 | validation: 0.21234536116105757]
	TIME [epoch: 9.09 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22236755405241054		[learning rate: 0.0007299]
	Learning Rate: 0.0007299
	LOSS [training: 0.22236755405241054 | validation: 0.21593401935483825]
	TIME [epoch: 9.08 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22208883153007486		[learning rate: 0.00072813]
	Learning Rate: 0.000728133
	LOSS [training: 0.22208883153007486 | validation: 0.21026460583221568]
	TIME [epoch: 9.08 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21964099093421194		[learning rate: 0.00072637]
	Learning Rate: 0.00072637
	LOSS [training: 0.21964099093421194 | validation: 0.2021272016745312]
	TIME [epoch: 9.08 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23209318536386453		[learning rate: 0.00072461]
	Learning Rate: 0.000724612
	LOSS [training: 0.23209318536386453 | validation: 0.24546109889216208]
	TIME [epoch: 9.1 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23227976800656563		[learning rate: 0.00072286]
	Learning Rate: 0.000722857
	LOSS [training: 0.23227976800656563 | validation: 0.21806219502906832]
	TIME [epoch: 9.08 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2146078222162222		[learning rate: 0.00072111]
	Learning Rate: 0.000721107
	LOSS [training: 0.2146078222162222 | validation: 0.1998275161210677]
	TIME [epoch: 9.08 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21046903268230924		[learning rate: 0.00071936]
	Learning Rate: 0.000719362
	LOSS [training: 0.21046903268230924 | validation: 0.2108816761586935]
	TIME [epoch: 9.08 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20555202107529014		[learning rate: 0.00071762]
	Learning Rate: 0.00071762
	LOSS [training: 0.20555202107529014 | validation: 0.2000507381996941]
	TIME [epoch: 9.07 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2000830122701016		[learning rate: 0.00071588]
	Learning Rate: 0.000715883
	LOSS [training: 0.2000830122701016 | validation: 0.19919496014163043]
	TIME [epoch: 9.09 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22666372491016684		[learning rate: 0.00071415]
	Learning Rate: 0.00071415
	LOSS [training: 0.22666372491016684 | validation: 0.22350430086543677]
	TIME [epoch: 9.08 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22879692245973332		[learning rate: 0.00071242]
	Learning Rate: 0.000712421
	LOSS [training: 0.22879692245973332 | validation: 0.22165359660404094]
	TIME [epoch: 9.07 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21299488674846642		[learning rate: 0.0007107]
	Learning Rate: 0.000710697
	LOSS [training: 0.21299488674846642 | validation: 0.20919932648372846]
	TIME [epoch: 9.07 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22186180936596395		[learning rate: 0.00070898]
	Learning Rate: 0.000708976
	LOSS [training: 0.22186180936596395 | validation: 0.19501847251111187]
	TIME [epoch: 9.09 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21137249336836658		[learning rate: 0.00070726]
	Learning Rate: 0.00070726
	LOSS [training: 0.21137249336836658 | validation: 0.20083031974605015]
	TIME [epoch: 9.08 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20154750485512837		[learning rate: 0.00070555]
	Learning Rate: 0.000705548
	LOSS [training: 0.20154750485512837 | validation: 0.21592691768323263]
	TIME [epoch: 9.07 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2160153763277969		[learning rate: 0.00070384]
	Learning Rate: 0.00070384
	LOSS [training: 0.2160153763277969 | validation: 0.1815304939422528]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_1195.pth
	Model improved!!!
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19448919656252758		[learning rate: 0.00070214]
	Learning Rate: 0.000702136
	LOSS [training: 0.19448919656252758 | validation: 0.19016537221832783]
	TIME [epoch: 9.07 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2027298411560745		[learning rate: 0.00070044]
	Learning Rate: 0.000700436
	LOSS [training: 0.2027298411560745 | validation: 0.19400539424453223]
	TIME [epoch: 9.09 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2123479806782051		[learning rate: 0.00069874]
	Learning Rate: 0.00069874
	LOSS [training: 0.2123479806782051 | validation: 0.19919784163380727]
	TIME [epoch: 9.08 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20322500194144943		[learning rate: 0.00069705]
	Learning Rate: 0.000697049
	LOSS [training: 0.20322500194144943 | validation: 0.19962135686817906]
	TIME [epoch: 9.07 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20539073773844088		[learning rate: 0.00069536]
	Learning Rate: 0.000695361
	LOSS [training: 0.20539073773844088 | validation: 0.20321353638010564]
	TIME [epoch: 9.06 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19827397465114358		[learning rate: 0.00069368]
	Learning Rate: 0.000693678
	LOSS [training: 0.19827397465114358 | validation: 0.18783886171280526]
	TIME [epoch: 9.07 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20721628477688436		[learning rate: 0.000692]
	Learning Rate: 0.000691999
	LOSS [training: 0.20721628477688436 | validation: 0.20347132076684749]
	TIME [epoch: 9.07 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20514834875960677		[learning rate: 0.00069032]
	Learning Rate: 0.000690324
	LOSS [training: 0.20514834875960677 | validation: 0.199663341388729]
	TIME [epoch: 9.07 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19730653708578225		[learning rate: 0.00068865]
	Learning Rate: 0.000688652
	LOSS [training: 0.19730653708578225 | validation: 0.2021555816790878]
	TIME [epoch: 9.06 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19725795375173033		[learning rate: 0.00068699]
	Learning Rate: 0.000686985
	LOSS [training: 0.19725795375173033 | validation: 0.19343540380185997]
	TIME [epoch: 9.07 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20533180645070512		[learning rate: 0.00068532]
	Learning Rate: 0.000685322
	LOSS [training: 0.20533180645070512 | validation: 0.22953944202582732]
	TIME [epoch: 9.09 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22828660934874107		[learning rate: 0.00068366]
	Learning Rate: 0.000683663
	LOSS [training: 0.22828660934874107 | validation: 0.19751078405217937]
	TIME [epoch: 9.08 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2118344585653542		[learning rate: 0.00068201]
	Learning Rate: 0.000682008
	LOSS [training: 0.2118344585653542 | validation: 0.2011960270248942]
	TIME [epoch: 9.07 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21309397786866713		[learning rate: 0.00068036]
	Learning Rate: 0.000680357
	LOSS [training: 0.21309397786866713 | validation: 0.22202114122305228]
	TIME [epoch: 9.08 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23394181996842106		[learning rate: 0.00067871]
	Learning Rate: 0.00067871
	LOSS [training: 0.23394181996842106 | validation: 0.2196468998816316]
	TIME [epoch: 9.07 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2383545774020702		[learning rate: 0.00067707]
	Learning Rate: 0.000677067
	LOSS [training: 0.2383545774020702 | validation: 0.23199022703275976]
	TIME [epoch: 9.1 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24923095432908776		[learning rate: 0.00067543]
	Learning Rate: 0.000675428
	LOSS [training: 0.24923095432908776 | validation: 0.22346479860581392]
	TIME [epoch: 9.08 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2483794722532784		[learning rate: 0.00067379]
	Learning Rate: 0.000673793
	LOSS [training: 0.2483794722532784 | validation: 0.22158861146397307]
	TIME [epoch: 9.07 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25257848082175466		[learning rate: 0.00067216]
	Learning Rate: 0.000672162
	LOSS [training: 0.25257848082175466 | validation: 0.21889474686787966]
	TIME [epoch: 9.07 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24342196132284002		[learning rate: 0.00067053]
	Learning Rate: 0.000670534
	LOSS [training: 0.24342196132284002 | validation: 0.25727064850026116]
	TIME [epoch: 9.08 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2404580863351537		[learning rate: 0.00066891]
	Learning Rate: 0.000668911
	LOSS [training: 0.2404580863351537 | validation: 0.20101421524622537]
	TIME [epoch: 9.06 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21698354927518104		[learning rate: 0.00066729]
	Learning Rate: 0.000667292
	LOSS [training: 0.21698354927518104 | validation: 0.21808097629266487]
	TIME [epoch: 9.06 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2174520145284647		[learning rate: 0.00066568]
	Learning Rate: 0.000665676
	LOSS [training: 0.2174520145284647 | validation: 0.20438281207799872]
	TIME [epoch: 9.07 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21791956288290523		[learning rate: 0.00066406]
	Learning Rate: 0.000664065
	LOSS [training: 0.21791956288290523 | validation: 0.19318486619805755]
	TIME [epoch: 9.07 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21372445037695137		[learning rate: 0.00066246]
	Learning Rate: 0.000662457
	LOSS [training: 0.21372445037695137 | validation: 0.2113710111546556]
	TIME [epoch: 9.09 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21156699599618017		[learning rate: 0.00066085]
	Learning Rate: 0.000660854
	LOSS [training: 0.21156699599618017 | validation: 0.18689832855456]
	TIME [epoch: 9.07 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20525144887993027		[learning rate: 0.00065925]
	Learning Rate: 0.000659254
	LOSS [training: 0.20525144887993027 | validation: 0.2047902870705845]
	TIME [epoch: 9.07 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20912031736160638		[learning rate: 0.00065766]
	Learning Rate: 0.000657658
	LOSS [training: 0.20912031736160638 | validation: 0.22118657258930463]
	TIME [epoch: 9.07 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2172292182851349		[learning rate: 0.00065607]
	Learning Rate: 0.000656066
	LOSS [training: 0.2172292182851349 | validation: 0.20017412746831234]
	TIME [epoch: 9.08 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21060871962269928		[learning rate: 0.00065448]
	Learning Rate: 0.000654478
	LOSS [training: 0.21060871962269928 | validation: 0.17898373896282785]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_1225.pth
	Model improved!!!
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19633343544755236		[learning rate: 0.00065289]
	Learning Rate: 0.000652893
	LOSS [training: 0.19633343544755236 | validation: 0.1897239680437205]
	TIME [epoch: 9.06 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2040542940296186		[learning rate: 0.00065131]
	Learning Rate: 0.000651313
	LOSS [training: 0.2040542940296186 | validation: 0.22178290312784915]
	TIME [epoch: 9.06 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.222249070878724		[learning rate: 0.00064974]
	Learning Rate: 0.000649736
	LOSS [training: 0.222249070878724 | validation: 0.19277037900460486]
	TIME [epoch: 9.06 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21445500771762638		[learning rate: 0.00064816]
	Learning Rate: 0.000648163
	LOSS [training: 0.21445500771762638 | validation: 0.2078153573864825]
	TIME [epoch: 9.09 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2140433247959989		[learning rate: 0.00064659]
	Learning Rate: 0.000646594
	LOSS [training: 0.2140433247959989 | validation: 0.19815327925780646]
	TIME [epoch: 9.07 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2065936380506194		[learning rate: 0.00064503]
	Learning Rate: 0.000645029
	LOSS [training: 0.2065936380506194 | validation: 0.19992523067030726]
	TIME [epoch: 9.07 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20611902161302872		[learning rate: 0.00064347]
	Learning Rate: 0.000643467
	LOSS [training: 0.20611902161302872 | validation: 0.2049820712283145]
	TIME [epoch: 9.07 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21700456481295832		[learning rate: 0.00064191]
	Learning Rate: 0.000641909
	LOSS [training: 0.21700456481295832 | validation: 0.2068154419161355]
	TIME [epoch: 9.08 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20389675527904436		[learning rate: 0.00064036]
	Learning Rate: 0.000640355
	LOSS [training: 0.20389675527904436 | validation: 0.1787634339463619]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_1234.pth
	Model improved!!!
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20149337584160015		[learning rate: 0.00063881]
	Learning Rate: 0.000638805
	LOSS [training: 0.20149337584160015 | validation: 0.20445771552000458]
	TIME [epoch: 9.07 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21353470669164656		[learning rate: 0.00063726]
	Learning Rate: 0.000637259
	LOSS [training: 0.21353470669164656 | validation: 0.20237796241004713]
	TIME [epoch: 9.07 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21661686265000765		[learning rate: 0.00063572]
	Learning Rate: 0.000635716
	LOSS [training: 0.21661686265000765 | validation: 0.231731803674883]
	TIME [epoch: 9.07 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23088668476491314		[learning rate: 0.00063418]
	Learning Rate: 0.000634177
	LOSS [training: 0.23088668476491314 | validation: 0.23521159876763112]
	TIME [epoch: 9.09 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2123547931209408		[learning rate: 0.00063264]
	Learning Rate: 0.000632642
	LOSS [training: 0.2123547931209408 | validation: 0.21671064293276743]
	TIME [epoch: 9.07 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21027075829930458		[learning rate: 0.00063111]
	Learning Rate: 0.00063111
	LOSS [training: 0.21027075829930458 | validation: 0.24783006965600987]
	TIME [epoch: 9.07 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22910465232799182		[learning rate: 0.00062958]
	Learning Rate: 0.000629582
	LOSS [training: 0.22910465232799182 | validation: 0.24134273888836488]
	TIME [epoch: 9.07 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2541341163378962		[learning rate: 0.00062806]
	Learning Rate: 0.000628058
	LOSS [training: 0.2541341163378962 | validation: 0.25516979584653926]
	TIME [epoch: 9.07 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24406638384271834		[learning rate: 0.00062654]
	Learning Rate: 0.000626538
	LOSS [training: 0.24406638384271834 | validation: 0.23453118261258857]
	TIME [epoch: 9.09 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22096970461192603		[learning rate: 0.00062502]
	Learning Rate: 0.000625021
	LOSS [training: 0.22096970461192603 | validation: 0.1973712799167833]
	TIME [epoch: 9.07 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20175454100575707		[learning rate: 0.00062351]
	Learning Rate: 0.000623508
	LOSS [training: 0.20175454100575707 | validation: 0.21484029293359683]
	TIME [epoch: 9.07 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2109666200526783		[learning rate: 0.000622]
	Learning Rate: 0.000621999
	LOSS [training: 0.2109666200526783 | validation: 0.19854315718409632]
	TIME [epoch: 9.06 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20538137507233928		[learning rate: 0.00062049]
	Learning Rate: 0.000620493
	LOSS [training: 0.20538137507233928 | validation: 0.2012651562163721]
	TIME [epoch: 9.08 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21442767617510233		[learning rate: 0.00061899]
	Learning Rate: 0.000618991
	LOSS [training: 0.21442767617510233 | validation: 0.21824175039521201]
	TIME [epoch: 9.07 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19882365991001277		[learning rate: 0.00061749]
	Learning Rate: 0.000617492
	LOSS [training: 0.19882365991001277 | validation: 0.18830552837969583]
	TIME [epoch: 9.07 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22556831054472243		[learning rate: 0.000616]
	Learning Rate: 0.000615997
	LOSS [training: 0.22556831054472243 | validation: 0.2477226285600045]
	TIME [epoch: 9.07 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.204589069923446		[learning rate: 0.00061451]
	Learning Rate: 0.000614506
	LOSS [training: 0.204589069923446 | validation: 0.18731239281266046]
	TIME [epoch: 9.08 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20591402979574416		[learning rate: 0.00061302]
	Learning Rate: 0.000613019
	LOSS [training: 0.20591402979574416 | validation: 0.21504971274519735]
	TIME [epoch: 9.08 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20558284016665143		[learning rate: 0.00061153]
	Learning Rate: 0.000611535
	LOSS [training: 0.20558284016665143 | validation: 0.18982170758850864]
	TIME [epoch: 9.06 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19543782604830845		[learning rate: 0.00061005]
	Learning Rate: 0.000610054
	LOSS [training: 0.19543782604830845 | validation: 0.1819592376933457]
	TIME [epoch: 9.06 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.214708707222726		[learning rate: 0.00060858]
	Learning Rate: 0.000608577
	LOSS [training: 0.214708707222726 | validation: 0.20989366339550525]
	TIME [epoch: 9.07 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21217826822544836		[learning rate: 0.0006071]
	Learning Rate: 0.000607104
	LOSS [training: 0.21217826822544836 | validation: 0.21352138816717636]
	TIME [epoch: 9.08 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21037025105325863		[learning rate: 0.00060563]
	Learning Rate: 0.000605634
	LOSS [training: 0.21037025105325863 | validation: 0.209272204234685]
	TIME [epoch: 9.06 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20706336525079064		[learning rate: 0.00060417]
	Learning Rate: 0.000604168
	LOSS [training: 0.20706336525079064 | validation: 0.19712033341874435]
	TIME [epoch: 9.07 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20353854244386566		[learning rate: 0.00060271]
	Learning Rate: 0.000602706
	LOSS [training: 0.20353854244386566 | validation: 0.1885245441035648]
	TIME [epoch: 9.06 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18750873371153126		[learning rate: 0.00060125]
	Learning Rate: 0.000601247
	LOSS [training: 0.18750873371153126 | validation: 0.19067447967915963]
	TIME [epoch: 9.07 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19702342055335303		[learning rate: 0.00059979]
	Learning Rate: 0.000599791
	LOSS [training: 0.19702342055335303 | validation: 0.22303605902033924]
	TIME [epoch: 9.09 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21070679903206688		[learning rate: 0.00059834]
	Learning Rate: 0.000598339
	LOSS [training: 0.21070679903206688 | validation: 0.23266139033098637]
	TIME [epoch: 9.07 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22444245562870863		[learning rate: 0.00059689]
	Learning Rate: 0.000596891
	LOSS [training: 0.22444245562870863 | validation: 0.21844730696224407]
	TIME [epoch: 9.07 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2299118361605264		[learning rate: 0.00059545]
	Learning Rate: 0.000595446
	LOSS [training: 0.2299118361605264 | validation: 0.22179668709422792]
	TIME [epoch: 9.06 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21011609307334891		[learning rate: 0.000594]
	Learning Rate: 0.000594004
	LOSS [training: 0.21011609307334891 | validation: 0.2231520720181558]
	TIME [epoch: 9.08 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21665679197095247		[learning rate: 0.00059257]
	Learning Rate: 0.000592566
	LOSS [training: 0.21665679197095247 | validation: 0.21134875356481045]
	TIME [epoch: 9.07 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1979364413257231		[learning rate: 0.00059113]
	Learning Rate: 0.000591132
	LOSS [training: 0.1979364413257231 | validation: 0.21377696004200625]
	TIME [epoch: 9.06 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2084433308638501		[learning rate: 0.0005897]
	Learning Rate: 0.000589701
	LOSS [training: 0.2084433308638501 | validation: 0.19029604856087473]
	TIME [epoch: 9.06 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19961807594827077		[learning rate: 0.00058827]
	Learning Rate: 0.000588273
	LOSS [training: 0.19961807594827077 | validation: 0.18931710469751234]
	TIME [epoch: 9.07 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19533677748171177		[learning rate: 0.00058685]
	Learning Rate: 0.000586849
	LOSS [training: 0.19533677748171177 | validation: 0.21529869132064006]
	TIME [epoch: 9.09 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20374780399122444		[learning rate: 0.00058543]
	Learning Rate: 0.000585428
	LOSS [training: 0.20374780399122444 | validation: 0.19699077887451644]
	TIME [epoch: 9.07 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20375642993161464		[learning rate: 0.00058401]
	Learning Rate: 0.000584011
	LOSS [training: 0.20375642993161464 | validation: 0.21519602725172718]
	TIME [epoch: 9.06 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21698096007814827		[learning rate: 0.0005826]
	Learning Rate: 0.000582597
	LOSS [training: 0.21698096007814827 | validation: 0.23142125043668227]
	TIME [epoch: 9.06 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22464871097774536		[learning rate: 0.00058119]
	Learning Rate: 0.000581187
	LOSS [training: 0.22464871097774536 | validation: 0.24000247598759833]
	TIME [epoch: 9.06 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21533815078024157		[learning rate: 0.00057978]
	Learning Rate: 0.00057978
	LOSS [training: 0.21533815078024157 | validation: 0.22203957514389544]
	TIME [epoch: 9.08 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2065742258995368		[learning rate: 0.00057838]
	Learning Rate: 0.000578376
	LOSS [training: 0.2065742258995368 | validation: 0.20146769629949168]
	TIME [epoch: 9.07 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20211344225268973		[learning rate: 0.00057698]
	Learning Rate: 0.000576976
	LOSS [training: 0.20211344225268973 | validation: 0.20626877463410626]
	TIME [epoch: 9.07 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20828387977250892		[learning rate: 0.00057558]
	Learning Rate: 0.000575579
	LOSS [training: 0.20828387977250892 | validation: 0.2010649657074295]
	TIME [epoch: 9.07 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2173472164624223		[learning rate: 0.00057419]
	Learning Rate: 0.000574186
	LOSS [training: 0.2173472164624223 | validation: 0.19653614875489778]
	TIME [epoch: 9.08 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19426240391775895		[learning rate: 0.0005728]
	Learning Rate: 0.000572796
	LOSS [training: 0.19426240391775895 | validation: 0.1936518674596174]
	TIME [epoch: 9.06 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1924655753960008		[learning rate: 0.00057141]
	Learning Rate: 0.000571409
	LOSS [training: 0.1924655753960008 | validation: 0.17942814541081598]
	TIME [epoch: 9.07 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20519266273970457		[learning rate: 0.00057003]
	Learning Rate: 0.000570026
	LOSS [training: 0.20519266273970457 | validation: 0.2003353247124512]
	TIME [epoch: 9.07 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2200255412325173		[learning rate: 0.00056865]
	Learning Rate: 0.000568646
	LOSS [training: 0.2200255412325173 | validation: 0.21069663489022553]
	TIME [epoch: 9.07 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21789936574823118		[learning rate: 0.00056727]
	Learning Rate: 0.00056727
	LOSS [training: 0.21789936574823118 | validation: 0.20367815710770962]
	TIME [epoch: 9.09 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22195844511849683		[learning rate: 0.0005659]
	Learning Rate: 0.000565896
	LOSS [training: 0.22195844511849683 | validation: 0.20566503799058689]
	TIME [epoch: 9.07 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20533952483579804		[learning rate: 0.00056453]
	Learning Rate: 0.000564526
	LOSS [training: 0.20533952483579804 | validation: 0.19968890337290818]
	TIME [epoch: 9.07 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2123237510690132		[learning rate: 0.00056316]
	Learning Rate: 0.00056316
	LOSS [training: 0.2123237510690132 | validation: 0.1956023494836105]
	TIME [epoch: 9.06 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21040482509977823		[learning rate: 0.0005618]
	Learning Rate: 0.000561796
	LOSS [training: 0.21040482509977823 | validation: 0.19283319850813324]
	TIME [epoch: 9.08 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21229560928310232		[learning rate: 0.00056044]
	Learning Rate: 0.000560436
	LOSS [training: 0.21229560928310232 | validation: 0.19202116939399838]
	TIME [epoch: 9.08 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2029032595366528		[learning rate: 0.00055908]
	Learning Rate: 0.00055908
	LOSS [training: 0.2029032595366528 | validation: 0.1872856084848153]
	TIME [epoch: 9.07 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19627554231691566		[learning rate: 0.00055773]
	Learning Rate: 0.000557726
	LOSS [training: 0.19627554231691566 | validation: 0.18456470016877408]
	TIME [epoch: 9.07 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19337335956509302		[learning rate: 0.00055638]
	Learning Rate: 0.000556376
	LOSS [training: 0.19337335956509302 | validation: 0.18806905876948402]
	TIME [epoch: 9.06 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19813554299453404		[learning rate: 0.00055503]
	Learning Rate: 0.000555029
	LOSS [training: 0.19813554299453404 | validation: 0.18894450365272142]
	TIME [epoch: 9.08 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19985408989130946		[learning rate: 0.00055369]
	Learning Rate: 0.000553685
	LOSS [training: 0.19985408989130946 | validation: 0.20513615616993328]
	TIME [epoch: 9.06 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1985047981600882		[learning rate: 0.00055235]
	Learning Rate: 0.000552345
	LOSS [training: 0.1985047981600882 | validation: 0.19283060231789428]
	TIME [epoch: 9.07 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19739987106182225		[learning rate: 0.00055101]
	Learning Rate: 0.000551008
	LOSS [training: 0.19739987106182225 | validation: 0.19645104100783295]
	TIME [epoch: 9.07 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21764645561119123		[learning rate: 0.00054967]
	Learning Rate: 0.000549674
	LOSS [training: 0.21764645561119123 | validation: 0.23325424584812138]
	TIME [epoch: 9.06 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20785707446265747		[learning rate: 0.00054834]
	Learning Rate: 0.000548343
	LOSS [training: 0.20785707446265747 | validation: 0.18655925994068523]
	TIME [epoch: 9.08 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20666388331879024		[learning rate: 0.00054702]
	Learning Rate: 0.000547016
	LOSS [training: 0.20666388331879024 | validation: 0.19378123693108396]
	TIME [epoch: 9.06 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20330145998536805		[learning rate: 0.00054569]
	Learning Rate: 0.000545692
	LOSS [training: 0.20330145998536805 | validation: 0.20330277475625735]
	TIME [epoch: 9.06 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20776415407668153		[learning rate: 0.00054437]
	Learning Rate: 0.000544371
	LOSS [training: 0.20776415407668153 | validation: 0.20372630578112058]
	TIME [epoch: 9.07 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19594213362965335		[learning rate: 0.00054305]
	Learning Rate: 0.000543053
	LOSS [training: 0.19594213362965335 | validation: 0.20625834292993972]
	TIME [epoch: 9.09 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19397194704682943		[learning rate: 0.00054174]
	Learning Rate: 0.000541738
	LOSS [training: 0.19397194704682943 | validation: 0.19656046780603353]
	TIME [epoch: 9.08 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19465202346730034		[learning rate: 0.00054043]
	Learning Rate: 0.000540427
	LOSS [training: 0.19465202346730034 | validation: 0.1955711102231344]
	TIME [epoch: 9.06 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20110976074819414		[learning rate: 0.00053912]
	Learning Rate: 0.000539118
	LOSS [training: 0.20110976074819414 | validation: 0.19687677572174578]
	TIME [epoch: 9.06 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19984588469239803		[learning rate: 0.00053781]
	Learning Rate: 0.000537813
	LOSS [training: 0.19984588469239803 | validation: 0.19426980316703807]
	TIME [epoch: 9.07 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19276102113738386		[learning rate: 0.00053651]
	Learning Rate: 0.000536511
	LOSS [training: 0.19276102113738386 | validation: 0.20135473039956106]
	TIME [epoch: 9.08 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19836898798839142		[learning rate: 0.00053521]
	Learning Rate: 0.000535213
	LOSS [training: 0.19836898798839142 | validation: 0.18391568350740503]
	TIME [epoch: 9.06 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19954681661423398		[learning rate: 0.00053392]
	Learning Rate: 0.000533917
	LOSS [training: 0.19954681661423398 | validation: 0.1906267457291776]
	TIME [epoch: 9.06 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19831568552616655		[learning rate: 0.00053262]
	Learning Rate: 0.000532624
	LOSS [training: 0.19831568552616655 | validation: 0.2011274749149322]
	TIME [epoch: 9.06 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20166475259714217		[learning rate: 0.00053134]
	Learning Rate: 0.000531335
	LOSS [training: 0.20166475259714217 | validation: 0.19035541895130279]
	TIME [epoch: 9.08 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1971744248940352		[learning rate: 0.00053005]
	Learning Rate: 0.000530049
	LOSS [training: 0.1971744248940352 | validation: 0.1997991336262675]
	TIME [epoch: 9.07 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20514994799961742		[learning rate: 0.00052877]
	Learning Rate: 0.000528766
	LOSS [training: 0.20514994799961742 | validation: 0.19551301045600905]
	TIME [epoch: 9.05 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21129448651410923		[learning rate: 0.00052749]
	Learning Rate: 0.000527485
	LOSS [training: 0.21129448651410923 | validation: 0.19522735993428297]
	TIME [epoch: 9.06 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1905573496389453		[learning rate: 0.00052621]
	Learning Rate: 0.000526208
	LOSS [training: 0.1905573496389453 | validation: 0.18469699663467248]
	TIME [epoch: 9.06 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19525221169237303		[learning rate: 0.00052493]
	Learning Rate: 0.000524935
	LOSS [training: 0.19525221169237303 | validation: 0.18955014538820367]
	TIME [epoch: 9.1 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19464617332776676		[learning rate: 0.00052366]
	Learning Rate: 0.000523664
	LOSS [training: 0.19464617332776676 | validation: 0.19741142118334148]
	TIME [epoch: 9.07 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20359570353613496		[learning rate: 0.0005224]
	Learning Rate: 0.000522396
	LOSS [training: 0.20359570353613496 | validation: 0.1907701127204628]
	TIME [epoch: 9.05 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20182996306146564		[learning rate: 0.00052113]
	Learning Rate: 0.000521132
	LOSS [training: 0.20182996306146564 | validation: 0.18879816802994842]
	TIME [epoch: 9.05 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20004754178850853		[learning rate: 0.00051987]
	Learning Rate: 0.00051987
	LOSS [training: 0.20004754178850853 | validation: 0.1866903466140107]
	TIME [epoch: 9.06 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19820578717290865		[learning rate: 0.00051861]
	Learning Rate: 0.000518611
	LOSS [training: 0.19820578717290865 | validation: 0.19614604558332854]
	TIME [epoch: 9.07 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19197259718949242		[learning rate: 0.00051736]
	Learning Rate: 0.000517356
	LOSS [training: 0.19197259718949242 | validation: 0.2189605291280314]
	TIME [epoch: 9.06 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2087715208530053		[learning rate: 0.0005161]
	Learning Rate: 0.000516104
	LOSS [training: 0.2087715208530053 | validation: 0.19718235720239255]
	TIME [epoch: 9.06 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20153775584826678		[learning rate: 0.00051485]
	Learning Rate: 0.000514854
	LOSS [training: 0.20153775584826678 | validation: 0.19296681826162215]
	TIME [epoch: 9.06 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2020162195266328		[learning rate: 0.00051361]
	Learning Rate: 0.000513608
	LOSS [training: 0.2020162195266328 | validation: 0.19773432873306854]
	TIME [epoch: 9.07 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20048418635896734		[learning rate: 0.00051236]
	Learning Rate: 0.000512364
	LOSS [training: 0.20048418635896734 | validation: 0.18533627121636315]
	TIME [epoch: 9.06 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18970663487110123		[learning rate: 0.00051112]
	Learning Rate: 0.000511124
	LOSS [training: 0.18970663487110123 | validation: 0.19342796544509433]
	TIME [epoch: 9.06 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19904892497663068		[learning rate: 0.00050989]
	Learning Rate: 0.000509887
	LOSS [training: 0.19904892497663068 | validation: 0.192857955677452]
	TIME [epoch: 9.07 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19943057565090377		[learning rate: 0.00050865]
	Learning Rate: 0.000508652
	LOSS [training: 0.19943057565090377 | validation: 0.20316720681094116]
	TIME [epoch: 9.07 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19819661431627084		[learning rate: 0.00050742]
	Learning Rate: 0.000507421
	LOSS [training: 0.19819661431627084 | validation: 0.1961925074632152]
	TIME [epoch: 9.1 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19527930846873742		[learning rate: 0.00050619]
	Learning Rate: 0.000506193
	LOSS [training: 0.19527930846873742 | validation: 0.18391041056196217]
	TIME [epoch: 9.07 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20614385716424555		[learning rate: 0.00050497]
	Learning Rate: 0.000504967
	LOSS [training: 0.20614385716424555 | validation: 0.18683825702172677]
	TIME [epoch: 9.07 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19721728928981125		[learning rate: 0.00050374]
	Learning Rate: 0.000503745
	LOSS [training: 0.19721728928981125 | validation: 0.18600374443862566]
	TIME [epoch: 9.06 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19802539142634418		[learning rate: 0.00050253]
	Learning Rate: 0.000502525
	LOSS [training: 0.19802539142634418 | validation: 0.217639275695899]
	TIME [epoch: 9.09 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20815803062400243		[learning rate: 0.00050131]
	Learning Rate: 0.000501309
	LOSS [training: 0.20815803062400243 | validation: 0.19078847232298443]
	TIME [epoch: 9.06 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19915113317339148		[learning rate: 0.0005001]
	Learning Rate: 0.000500095
	LOSS [training: 0.19915113317339148 | validation: 0.18519931721447386]
	TIME [epoch: 9.06 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19323847811224745		[learning rate: 0.00049888]
	Learning Rate: 0.000498885
	LOSS [training: 0.19323847811224745 | validation: 0.18812821670644894]
	TIME [epoch: 9.06 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19706425306714287		[learning rate: 0.00049768]
	Learning Rate: 0.000497677
	LOSS [training: 0.19706425306714287 | validation: 0.1971095217196469]
	TIME [epoch: 9.06 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19186310372507484		[learning rate: 0.00049647]
	Learning Rate: 0.000496472
	LOSS [training: 0.19186310372507484 | validation: 0.19184466024377125]
	TIME [epoch: 9.07 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19494824281302797		[learning rate: 0.00049527]
	Learning Rate: 0.00049527
	LOSS [training: 0.19494824281302797 | validation: 0.1761767535890672]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_1340.pth
	Model improved!!!
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19254850652456307		[learning rate: 0.00049407]
	Learning Rate: 0.000494071
	LOSS [training: 0.19254850652456307 | validation: 0.19250211339113216]
	TIME [epoch: 9.05 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1955580490413344		[learning rate: 0.00049288]
	Learning Rate: 0.000492875
	LOSS [training: 0.1955580490413344 | validation: 0.19701560107225954]
	TIME [epoch: 9.06 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1926587254307269		[learning rate: 0.00049168]
	Learning Rate: 0.000491682
	LOSS [training: 0.1926587254307269 | validation: 0.1906708477910471]
	TIME [epoch: 9.08 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18919554008315295		[learning rate: 0.00049049]
	Learning Rate: 0.000490492
	LOSS [training: 0.18919554008315295 | validation: 0.17613598768248628]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_1344.pth
	Model improved!!!
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18785723151224837		[learning rate: 0.0004893]
	Learning Rate: 0.000489304
	LOSS [training: 0.18785723151224837 | validation: 0.18137199133163429]
	TIME [epoch: 9.05 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18817332531193287		[learning rate: 0.00048812]
	Learning Rate: 0.00048812
	LOSS [training: 0.18817332531193287 | validation: 0.17117482487946323]
	TIME [epoch: 9.05 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_1346.pth
	Model improved!!!
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19172437461135147		[learning rate: 0.00048694]
	Learning Rate: 0.000486938
	LOSS [training: 0.19172437461135147 | validation: 0.19085972252846117]
	TIME [epoch: 9.05 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19437741599390207		[learning rate: 0.00048576]
	Learning Rate: 0.000485759
	LOSS [training: 0.19437741599390207 | validation: 0.18928230798617635]
	TIME [epoch: 9.07 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19852406892334154		[learning rate: 0.00048458]
	Learning Rate: 0.000484583
	LOSS [training: 0.19852406892334154 | validation: 0.19450821491097284]
	TIME [epoch: 9.06 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20076598803348525		[learning rate: 0.00048341]
	Learning Rate: 0.00048341
	LOSS [training: 0.20076598803348525 | validation: 0.18357508095329772]
	TIME [epoch: 9.05 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1995069323105237		[learning rate: 0.00048224]
	Learning Rate: 0.00048224
	LOSS [training: 0.1995069323105237 | validation: 0.1997156907529728]
	TIME [epoch: 9.05 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21001106342839546		[learning rate: 0.00048107]
	Learning Rate: 0.000481072
	LOSS [training: 0.21001106342839546 | validation: 0.19918540791451245]
	TIME [epoch: 9.06 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2007855772283988		[learning rate: 0.00047991]
	Learning Rate: 0.000479908
	LOSS [training: 0.2007855772283988 | validation: 0.1927329962004536]
	TIME [epoch: 9.07 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19863395447109763		[learning rate: 0.00047875]
	Learning Rate: 0.000478746
	LOSS [training: 0.19863395447109763 | validation: 0.19629306495373305]
	TIME [epoch: 9.06 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1973967610623787		[learning rate: 0.00047759]
	Learning Rate: 0.000477587
	LOSS [training: 0.1973967610623787 | validation: 0.18516021438652278]
	TIME [epoch: 9.07 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.188765693391998		[learning rate: 0.00047643]
	Learning Rate: 0.000476431
	LOSS [training: 0.188765693391998 | validation: 0.19815500102758837]
	TIME [epoch: 9.06 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19984131911761505		[learning rate: 0.00047528]
	Learning Rate: 0.000475278
	LOSS [training: 0.19984131911761505 | validation: 0.19078525810310332]
	TIME [epoch: 9.08 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19104248123477446		[learning rate: 0.00047413]
	Learning Rate: 0.000474127
	LOSS [training: 0.19104248123477446 | validation: 0.18948324384546825]
	TIME [epoch: 9.06 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20427495246067634		[learning rate: 0.00047298]
	Learning Rate: 0.000472979
	LOSS [training: 0.20427495246067634 | validation: 0.17645794194773523]
	TIME [epoch: 9.06 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1957633134615366		[learning rate: 0.00047183]
	Learning Rate: 0.000471834
	LOSS [training: 0.1957633134615366 | validation: 0.1719128063383159]
	TIME [epoch: 9.07 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18886664196591657		[learning rate: 0.00047069]
	Learning Rate: 0.000470692
	LOSS [training: 0.18886664196591657 | validation: 0.17877646932526836]
	TIME [epoch: 9.05 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1900252049698762		[learning rate: 0.00046955]
	Learning Rate: 0.000469553
	LOSS [training: 0.1900252049698762 | validation: 0.1938849265557773]
	TIME [epoch: 9.08 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19234233164456468		[learning rate: 0.00046842]
	Learning Rate: 0.000468416
	LOSS [training: 0.19234233164456468 | validation: 0.17765498568026397]
	TIME [epoch: 9.06 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18707924785385424		[learning rate: 0.00046728]
	Learning Rate: 0.000467282
	LOSS [training: 0.18707924785385424 | validation: 0.18924538429508958]
	TIME [epoch: 9.06 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19946469596497174		[learning rate: 0.00046615]
	Learning Rate: 0.000466151
	LOSS [training: 0.19946469596497174 | validation: 0.19662629519482117]
	TIME [epoch: 9.06 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2028438475284214		[learning rate: 0.00046502]
	Learning Rate: 0.000465022
	LOSS [training: 0.2028438475284214 | validation: 0.20480240180131606]
	TIME [epoch: 9.08 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2067861243307111		[learning rate: 0.0004639]
	Learning Rate: 0.000463896
	LOSS [training: 0.2067861243307111 | validation: 0.20743263465070272]
	TIME [epoch: 9.07 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1935491288491036		[learning rate: 0.00046277]
	Learning Rate: 0.000462773
	LOSS [training: 0.1935491288491036 | validation: 0.2015127954085284]
	TIME [epoch: 9.07 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21160998381303822		[learning rate: 0.00046165]
	Learning Rate: 0.000461653
	LOSS [training: 0.21160998381303822 | validation: 0.20720807940698224]
	TIME [epoch: 9.07 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20089039016831917		[learning rate: 0.00046054]
	Learning Rate: 0.000460536
	LOSS [training: 0.20089039016831917 | validation: 0.21738546278378185]
	TIME [epoch: 9.06 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20874717085210232		[learning rate: 0.00045942]
	Learning Rate: 0.000459421
	LOSS [training: 0.20874717085210232 | validation: 0.213379660350825]
	TIME [epoch: 9.07 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20325859780998715		[learning rate: 0.00045831]
	Learning Rate: 0.000458309
	LOSS [training: 0.20325859780998715 | validation: 0.21663150610660853]
	TIME [epoch: 9.06 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2052316895291122		[learning rate: 0.0004572]
	Learning Rate: 0.000457199
	LOSS [training: 0.2052316895291122 | validation: 0.20574792221097077]
	TIME [epoch: 9.06 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20561112176999882		[learning rate: 0.00045609]
	Learning Rate: 0.000456092
	LOSS [training: 0.20561112176999882 | validation: 0.22054660663725506]
	TIME [epoch: 9.05 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2114176056643074		[learning rate: 0.00045499]
	Learning Rate: 0.000454988
	LOSS [training: 0.2114176056643074 | validation: 0.20386335661901764]
	TIME [epoch: 9.08 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20531984057131608		[learning rate: 0.00045389]
	Learning Rate: 0.000453887
	LOSS [training: 0.20531984057131608 | validation: 0.19219658581990268]
	TIME [epoch: 9.06 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20461368360474133		[learning rate: 0.00045279]
	Learning Rate: 0.000452788
	LOSS [training: 0.20461368360474133 | validation: 0.21300363814531798]
	TIME [epoch: 9.06 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20526399472661755		[learning rate: 0.00045169]
	Learning Rate: 0.000451692
	LOSS [training: 0.20526399472661755 | validation: 0.20992953632613742]
	TIME [epoch: 9.06 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19977805318046435		[learning rate: 0.0004506]
	Learning Rate: 0.000450598
	LOSS [training: 0.19977805318046435 | validation: 0.20261282110992504]
	TIME [epoch: 9.06 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1997654416931564		[learning rate: 0.00044951]
	Learning Rate: 0.000449507
	LOSS [training: 0.1997654416931564 | validation: 0.19295706418952108]
	TIME [epoch: 9.08 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1899959863051992		[learning rate: 0.00044842]
	Learning Rate: 0.000448419
	LOSS [training: 0.1899959863051992 | validation: 0.18053079946282635]
	TIME [epoch: 9.07 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18759536775630176		[learning rate: 0.00044733]
	Learning Rate: 0.000447334
	LOSS [training: 0.18759536775630176 | validation: 0.1862445187599281]
	TIME [epoch: 9.06 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18802909542661914		[learning rate: 0.00044625]
	Learning Rate: 0.000446251
	LOSS [training: 0.18802909542661914 | validation: 0.20772325513208]
	TIME [epoch: 9.06 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19162275583552707		[learning rate: 0.00044517]
	Learning Rate: 0.00044517
	LOSS [training: 0.19162275583552707 | validation: 0.199543266697837]
	TIME [epoch: 9.05 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1874683938567197		[learning rate: 0.00044409]
	Learning Rate: 0.000444093
	LOSS [training: 0.1874683938567197 | validation: 0.19887844228456908]
	TIME [epoch: 9.08 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19510484032747577		[learning rate: 0.00044302]
	Learning Rate: 0.000443018
	LOSS [training: 0.19510484032747577 | validation: 0.19458592833356192]
	TIME [epoch: 9.05 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19988716916967433		[learning rate: 0.00044195]
	Learning Rate: 0.000441945
	LOSS [training: 0.19988716916967433 | validation: 0.1868261832046969]
	TIME [epoch: 9.06 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20036209053361942		[learning rate: 0.00044088]
	Learning Rate: 0.000440875
	LOSS [training: 0.20036209053361942 | validation: 0.21178992971113575]
	TIME [epoch: 9.06 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20245870608811084		[learning rate: 0.00043981]
	Learning Rate: 0.000439808
	LOSS [training: 0.20245870608811084 | validation: 0.19482189915628423]
	TIME [epoch: 9.07 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20184907694435342		[learning rate: 0.00043874]
	Learning Rate: 0.000438743
	LOSS [training: 0.20184907694435342 | validation: 0.21015590484576335]
	TIME [epoch: 9.06 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21076047070890266		[learning rate: 0.00043768]
	Learning Rate: 0.000437681
	LOSS [training: 0.21076047070890266 | validation: 0.21344539380136054]
	TIME [epoch: 9.05 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19948157604369804		[learning rate: 0.00043662]
	Learning Rate: 0.000436622
	LOSS [training: 0.19948157604369804 | validation: 0.18474817974980107]
	TIME [epoch: 9.06 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19180569428571254		[learning rate: 0.00043556]
	Learning Rate: 0.000435565
	LOSS [training: 0.19180569428571254 | validation: 0.2083338271596451]
	TIME [epoch: 9.06 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19049660201503887		[learning rate: 0.00043451]
	Learning Rate: 0.00043451
	LOSS [training: 0.19049660201503887 | validation: 0.19401042110986294]
	TIME [epoch: 9.08 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1934625521524901		[learning rate: 0.00043346]
	Learning Rate: 0.000433458
	LOSS [training: 0.1934625521524901 | validation: 0.19933067590206416]
	TIME [epoch: 9.07 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19380510540701895		[learning rate: 0.00043241]
	Learning Rate: 0.000432409
	LOSS [training: 0.19380510540701895 | validation: 0.17827956707400777]
	TIME [epoch: 9.06 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19186984162807866		[learning rate: 0.00043136]
	Learning Rate: 0.000431362
	LOSS [training: 0.19186984162807866 | validation: 0.18575932235797926]
	TIME [epoch: 9.06 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19124894944766893		[learning rate: 0.00043032]
	Learning Rate: 0.000430318
	LOSS [training: 0.19124894944766893 | validation: 0.18437893034945443]
	TIME [epoch: 9.07 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1908326489282195		[learning rate: 0.00042928]
	Learning Rate: 0.000429276
	LOSS [training: 0.1908326489282195 | validation: 0.1921040321344302]
	TIME [epoch: 9.05 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1897945247906523		[learning rate: 0.00042824]
	Learning Rate: 0.000428237
	LOSS [training: 0.1897945247906523 | validation: 0.195533160339009]
	TIME [epoch: 9.08 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21220803247999326		[learning rate: 0.0004272]
	Learning Rate: 0.0004272
	LOSS [training: 0.21220803247999326 | validation: 0.23735283853040812]
	TIME [epoch: 9.06 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1946131491858351		[learning rate: 0.00042617]
	Learning Rate: 0.000426166
	LOSS [training: 0.1946131491858351 | validation: 0.21212865481494797]
	TIME [epoch: 9.06 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19794964838519197		[learning rate: 0.00042513]
	Learning Rate: 0.000425134
	LOSS [training: 0.19794964838519197 | validation: 0.19649879469567755]
	TIME [epoch: 9.07 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1986620251648738		[learning rate: 0.00042411]
	Learning Rate: 0.000424105
	LOSS [training: 0.1986620251648738 | validation: 0.21087457053349418]
	TIME [epoch: 9.05 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19974065904925362		[learning rate: 0.00042308]
	Learning Rate: 0.000423079
	LOSS [training: 0.19974065904925362 | validation: 0.20701097046828526]
	TIME [epoch: 9.05 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19844023841351804		[learning rate: 0.00042205]
	Learning Rate: 0.000422054
	LOSS [training: 0.19844023841351804 | validation: 0.2027347164925179]
	TIME [epoch: 9.05 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20460617944440357		[learning rate: 0.00042103]
	Learning Rate: 0.000421033
	LOSS [training: 0.20460617944440357 | validation: 0.2195998777866215]
	TIME [epoch: 9.08 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21802099706453962		[learning rate: 0.00042001]
	Learning Rate: 0.000420013
	LOSS [training: 0.21802099706453962 | validation: 0.22214579178559235]
	TIME [epoch: 9.08 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2148070823497117		[learning rate: 0.000419]
	Learning Rate: 0.000418997
	LOSS [training: 0.2148070823497117 | validation: 0.229788452735805]
	TIME [epoch: 9.07 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20558975353508294		[learning rate: 0.00041798]
	Learning Rate: 0.000417982
	LOSS [training: 0.20558975353508294 | validation: 0.20719108205827078]
	TIME [epoch: 9.06 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20552390025845751		[learning rate: 0.00041697]
	Learning Rate: 0.00041697
	LOSS [training: 0.20552390025845751 | validation: 0.21238946880151477]
	TIME [epoch: 9.06 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22784004495246082		[learning rate: 0.00041596]
	Learning Rate: 0.000415961
	LOSS [training: 0.22784004495246082 | validation: 0.25497513364878244]
	TIME [epoch: 9.06 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22411866268358444		[learning rate: 0.00041495]
	Learning Rate: 0.000414954
	LOSS [training: 0.22411866268358444 | validation: 0.22014622574820977]
	TIME [epoch: 9.06 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20551792337160446		[learning rate: 0.00041395]
	Learning Rate: 0.00041395
	LOSS [training: 0.20551792337160446 | validation: 0.19956474223692927]
	TIME [epoch: 9.06 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1966863197113496		[learning rate: 0.00041295]
	Learning Rate: 0.000412947
	LOSS [training: 0.1966863197113496 | validation: 0.1944311819394034]
	TIME [epoch: 9.06 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.193505087620356		[learning rate: 0.00041195]
	Learning Rate: 0.000411948
	LOSS [training: 0.193505087620356 | validation: 0.18883097359585657]
	TIME [epoch: 9.06 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19345687674413975		[learning rate: 0.00041095]
	Learning Rate: 0.00041095
	LOSS [training: 0.19345687674413975 | validation: 0.19343478904369016]
	TIME [epoch: 9.08 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20203365210541863		[learning rate: 0.00040996]
	Learning Rate: 0.000409956
	LOSS [training: 0.20203365210541863 | validation: 0.2070927333347269]
	TIME [epoch: 9.06 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21387361417817458		[learning rate: 0.00040896]
	Learning Rate: 0.000408963
	LOSS [training: 0.21387361417817458 | validation: 0.21559700804497806]
	TIME [epoch: 9.05 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21065032577784573		[learning rate: 0.00040797]
	Learning Rate: 0.000407973
	LOSS [training: 0.21065032577784573 | validation: 0.21119422564313395]
	TIME [epoch: 9.06 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20175562726660073		[learning rate: 0.00040699]
	Learning Rate: 0.000406986
	LOSS [training: 0.20175562726660073 | validation: 0.2079802670975724]
	TIME [epoch: 9.07 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1949176711532818		[learning rate: 0.000406]
	Learning Rate: 0.000406
	LOSS [training: 0.1949176711532818 | validation: 0.19253530131121127]
	TIME [epoch: 9.07 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19279001894738151		[learning rate: 0.00040502]
	Learning Rate: 0.000405017
	LOSS [training: 0.19279001894738151 | validation: 0.18779418446408247]
	TIME [epoch: 9.06 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1933356761685327		[learning rate: 0.00040404]
	Learning Rate: 0.000404037
	LOSS [training: 0.1933356761685327 | validation: 0.2042658531140611]
	TIME [epoch: 9.06 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1943925643614671		[learning rate: 0.00040306]
	Learning Rate: 0.000403059
	LOSS [training: 0.1943925643614671 | validation: 0.1857736479006883]
	TIME [epoch: 9.05 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20075943681720462		[learning rate: 0.00040208]
	Learning Rate: 0.000402083
	LOSS [training: 0.20075943681720462 | validation: 0.19018704476864667]
	TIME [epoch: 9.07 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19963078698863018		[learning rate: 0.00040111]
	Learning Rate: 0.00040111
	LOSS [training: 0.19963078698863018 | validation: 0.19167284628808035]
	TIME [epoch: 9.06 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20044965922090965		[learning rate: 0.00040014]
	Learning Rate: 0.000400139
	LOSS [training: 0.20044965922090965 | validation: 0.1896391159103742]
	TIME [epoch: 9.05 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20112384975046366		[learning rate: 0.00039917]
	Learning Rate: 0.00039917
	LOSS [training: 0.20112384975046366 | validation: 0.1873472467331147]
	TIME [epoch: 9.05 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19552332562613398		[learning rate: 0.0003982]
	Learning Rate: 0.000398204
	LOSS [training: 0.19552332562613398 | validation: 0.19256106396340844]
	TIME [epoch: 9.07 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20976671481646686		[learning rate: 0.00039724]
	Learning Rate: 0.00039724
	LOSS [training: 0.20976671481646686 | validation: 0.19406787594130606]
	TIME [epoch: 9.05 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20477643390426867		[learning rate: 0.00039628]
	Learning Rate: 0.000396278
	LOSS [training: 0.20477643390426867 | validation: 0.18696540918813967]
	TIME [epoch: 9.05 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1998625411992269		[learning rate: 0.00039532]
	Learning Rate: 0.000395319
	LOSS [training: 0.1998625411992269 | validation: 0.18699190107567315]
	TIME [epoch: 9.06 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19113440173889576		[learning rate: 0.00039436]
	Learning Rate: 0.000394362
	LOSS [training: 0.19113440173889576 | validation: 0.19728664797191564]
	TIME [epoch: 9.06 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20658447603355193		[learning rate: 0.00039341]
	Learning Rate: 0.000393407
	LOSS [training: 0.20658447603355193 | validation: 0.19767817300999624]
	TIME [epoch: 9.07 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19709693551969082		[learning rate: 0.00039245]
	Learning Rate: 0.000392455
	LOSS [training: 0.19709693551969082 | validation: 0.2001725380752391]
	TIME [epoch: 9.06 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1975477912905253		[learning rate: 0.0003915]
	Learning Rate: 0.000391505
	LOSS [training: 0.1975477912905253 | validation: 0.20123281019708958]
	TIME [epoch: 9.05 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19666780697169586		[learning rate: 0.00039056]
	Learning Rate: 0.000390557
	LOSS [training: 0.19666780697169586 | validation: 0.20069136697141599]
	TIME [epoch: 9.05 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19768613420348205		[learning rate: 0.00038961]
	Learning Rate: 0.000389611
	LOSS [training: 0.19768613420348205 | validation: 0.1899283727723622]
	TIME [epoch: 9.06 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19806115989313272		[learning rate: 0.00038867]
	Learning Rate: 0.000388668
	LOSS [training: 0.19806115989313272 | validation: 0.21925685726537636]
	TIME [epoch: 9.07 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2052772925262049		[learning rate: 0.00038773]
	Learning Rate: 0.000387727
	LOSS [training: 0.2052772925262049 | validation: 0.1934799794986208]
	TIME [epoch: 9.05 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20657657311138214		[learning rate: 0.00038679]
	Learning Rate: 0.000386789
	LOSS [training: 0.20657657311138214 | validation: 0.2200899483534086]
	TIME [epoch: 9.05 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20558914924760668		[learning rate: 0.00038585]
	Learning Rate: 0.000385852
	LOSS [training: 0.20558914924760668 | validation: 0.19434765607875917]
	TIME [epoch: 9.05 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19939466161850664		[learning rate: 0.00038492]
	Learning Rate: 0.000384918
	LOSS [training: 0.19939466161850664 | validation: 0.20801627900462016]
	TIME [epoch: 9.08 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2025675555106799		[learning rate: 0.00038399]
	Learning Rate: 0.000383986
	LOSS [training: 0.2025675555106799 | validation: 0.20244854669287402]
	TIME [epoch: 9.05 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20126643176226686		[learning rate: 0.00038306]
	Learning Rate: 0.000383057
	LOSS [training: 0.20126643176226686 | validation: 0.19837725338029288]
	TIME [epoch: 9.05 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1938737273805306		[learning rate: 0.00038213]
	Learning Rate: 0.000382129
	LOSS [training: 0.1938737273805306 | validation: 0.19573294863185473]
	TIME [epoch: 9.06 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19414747172303362		[learning rate: 0.0003812]
	Learning Rate: 0.000381204
	LOSS [training: 0.19414747172303362 | validation: 0.2008849489687748]
	TIME [epoch: 9.06 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19178142463834563		[learning rate: 0.00038028]
	Learning Rate: 0.000380282
	LOSS [training: 0.19178142463834563 | validation: 0.18964141965532255]
	TIME [epoch: 9.08 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1985033083452022		[learning rate: 0.00037936]
	Learning Rate: 0.000379361
	LOSS [training: 0.1985033083452022 | validation: 0.20657126142671794]
	TIME [epoch: 9.05 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19857215028250522		[learning rate: 0.00037844]
	Learning Rate: 0.000378443
	LOSS [training: 0.19857215028250522 | validation: 0.21144184333428734]
	TIME [epoch: 9.05 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20821822569023313		[learning rate: 0.00037753]
	Learning Rate: 0.000377526
	LOSS [training: 0.20821822569023313 | validation: 0.24503745285245024]
	TIME [epoch: 9.05 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23053979478114037		[learning rate: 0.00037661]
	Learning Rate: 0.000376612
	LOSS [training: 0.23053979478114037 | validation: 0.24879806800981663]
	TIME [epoch: 9.06 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2063533011955026		[learning rate: 0.0003757]
	Learning Rate: 0.000375701
	LOSS [training: 0.2063533011955026 | validation: 0.19647155315552803]
	TIME [epoch: 9.06 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2063585037646261		[learning rate: 0.00037479]
	Learning Rate: 0.000374791
	LOSS [training: 0.2063585037646261 | validation: 0.2169095141961235]
	TIME [epoch: 9.06 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2046864480204224		[learning rate: 0.00037388]
	Learning Rate: 0.000373884
	LOSS [training: 0.2046864480204224 | validation: 0.2018741434463547]
	TIME [epoch: 9.05 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20707145596628282		[learning rate: 0.00037298]
	Learning Rate: 0.000372979
	LOSS [training: 0.20707145596628282 | validation: 0.2215915364290922]
	TIME [epoch: 9.06 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20716003942079894		[learning rate: 0.00037208]
	Learning Rate: 0.000372076
	LOSS [training: 0.20716003942079894 | validation: 0.21444362039521883]
	TIME [epoch: 9.07 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2159237487833814		[learning rate: 0.00037118]
	Learning Rate: 0.000371175
	LOSS [training: 0.2159237487833814 | validation: 0.24470866075095538]
	TIME [epoch: 9.05 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21327882255514424		[learning rate: 0.00037028]
	Learning Rate: 0.000370277
	LOSS [training: 0.21327882255514424 | validation: 0.21310638226261705]
	TIME [epoch: 9.06 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20430363341326502		[learning rate: 0.00036938]
	Learning Rate: 0.00036938
	LOSS [training: 0.20430363341326502 | validation: 0.21758557772181775]
	TIME [epoch: 9.05 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19595341288013438		[learning rate: 0.00036849]
	Learning Rate: 0.000368486
	LOSS [training: 0.19595341288013438 | validation: 0.189884895039369]
	TIME [epoch: 9.07 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20368079820764945		[learning rate: 0.00036759]
	Learning Rate: 0.000367594
	LOSS [training: 0.20368079820764945 | validation: 0.2059457961240251]
	TIME [epoch: 9.06 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20688057811408048		[learning rate: 0.0003667]
	Learning Rate: 0.000366704
	LOSS [training: 0.20688057811408048 | validation: 0.20847510032264377]
	TIME [epoch: 9.04 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20658212997561778		[learning rate: 0.00036582]
	Learning Rate: 0.000365816
	LOSS [training: 0.20658212997561778 | validation: 0.20860144126241698]
	TIME [epoch: 9.04 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19430889740609664		[learning rate: 0.00036493]
	Learning Rate: 0.000364931
	LOSS [training: 0.19430889740609664 | validation: 0.19991310306543733]
	TIME [epoch: 9.05 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2028699678518145		[learning rate: 0.00036405]
	Learning Rate: 0.000364047
	LOSS [training: 0.2028699678518145 | validation: 0.20357415690248165]
	TIME [epoch: 9.07 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19880710761731213		[learning rate: 0.00036317]
	Learning Rate: 0.000363166
	LOSS [training: 0.19880710761731213 | validation: 0.21038325342284864]
	TIME [epoch: 9.05 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.206938808906674		[learning rate: 0.00036229]
	Learning Rate: 0.000362287
	LOSS [training: 0.206938808906674 | validation: 0.22111320930154404]
	TIME [epoch: 9.04 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2015901400643038		[learning rate: 0.00036141]
	Learning Rate: 0.00036141
	LOSS [training: 0.2015901400643038 | validation: 0.21198130509350843]
	TIME [epoch: 9.05 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20284560270724178		[learning rate: 0.00036053]
	Learning Rate: 0.000360535
	LOSS [training: 0.20284560270724178 | validation: 0.2191174567393252]
	TIME [epoch: 9.05 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20720334286007097		[learning rate: 0.00035966]
	Learning Rate: 0.000359662
	LOSS [training: 0.20720334286007097 | validation: 0.21988422048361822]
	TIME [epoch: 9.07 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20465538230556451		[learning rate: 0.00035879]
	Learning Rate: 0.000358791
	LOSS [training: 0.20465538230556451 | validation: 0.20938673151827517]
	TIME [epoch: 9.06 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20759037715980116		[learning rate: 0.00035792]
	Learning Rate: 0.000357923
	LOSS [training: 0.20759037715980116 | validation: 0.20736325989130933]
	TIME [epoch: 9.07 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20296750116535756		[learning rate: 0.00035706]
	Learning Rate: 0.000357056
	LOSS [training: 0.20296750116535756 | validation: 0.19778192160167776]
	TIME [epoch: 9.06 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1993886182335972		[learning rate: 0.00035619]
	Learning Rate: 0.000356192
	LOSS [training: 0.1993886182335972 | validation: 0.20444380770104326]
	TIME [epoch: 9.07 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2022313581198127		[learning rate: 0.00035533]
	Learning Rate: 0.00035533
	LOSS [training: 0.2022313581198127 | validation: 0.1992225717207606]
	TIME [epoch: 9.06 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2008160669816526		[learning rate: 0.00035447]
	Learning Rate: 0.00035447
	LOSS [training: 0.2008160669816526 | validation: 0.19473570052691117]
	TIME [epoch: 9.05 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19828304405243996		[learning rate: 0.00035361]
	Learning Rate: 0.000353611
	LOSS [training: 0.19828304405243996 | validation: 0.2072521756573035]
	TIME [epoch: 9.07 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19344033920963646		[learning rate: 0.00035276]
	Learning Rate: 0.000352755
	LOSS [training: 0.19344033920963646 | validation: 0.20177505653521727]
	TIME [epoch: 9.05 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19973701304189131		[learning rate: 0.0003519]
	Learning Rate: 0.000351901
	LOSS [training: 0.19973701304189131 | validation: 0.19190762883276208]
	TIME [epoch: 9.08 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19597212911198109		[learning rate: 0.00035105]
	Learning Rate: 0.00035105
	LOSS [training: 0.19597212911198109 | validation: 0.17949099586079376]
	TIME [epoch: 9.06 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19651674165479208		[learning rate: 0.0003502]
	Learning Rate: 0.0003502
	LOSS [training: 0.19651674165479208 | validation: 0.19777226470638398]
	TIME [epoch: 9.05 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19660353881859102		[learning rate: 0.00034935]
	Learning Rate: 0.000349352
	LOSS [training: 0.19660353881859102 | validation: 0.1952280943699752]
	TIME [epoch: 9.05 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19837456064782905		[learning rate: 0.00034851]
	Learning Rate: 0.000348506
	LOSS [training: 0.19837456064782905 | validation: 0.20270703097909445]
	TIME [epoch: 9.06 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19675683347866418		[learning rate: 0.00034766]
	Learning Rate: 0.000347663
	LOSS [training: 0.19675683347866418 | validation: 0.20429171793412015]
	TIME [epoch: 9.06 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19282347257906965		[learning rate: 0.00034682]
	Learning Rate: 0.000346821
	LOSS [training: 0.19282347257906965 | validation: 0.1953287962220232]
	TIME [epoch: 9.06 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18877562963428954		[learning rate: 0.00034598]
	Learning Rate: 0.000345981
	LOSS [training: 0.18877562963428954 | validation: 0.2024584619621188]
	TIME [epoch: 9.06 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19223928698450038		[learning rate: 0.00034514]
	Learning Rate: 0.000345144
	LOSS [training: 0.19223928698450038 | validation: 0.19979038995577053]
	TIME [epoch: 9.06 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19837992716098532		[learning rate: 0.00034431]
	Learning Rate: 0.000344308
	LOSS [training: 0.19837992716098532 | validation: 0.18377075265323783]
	TIME [epoch: 9.08 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19273442570867946		[learning rate: 0.00034347]
	Learning Rate: 0.000343475
	LOSS [training: 0.19273442570867946 | validation: 0.20332479558092004]
	TIME [epoch: 9.05 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18862692721575156		[learning rate: 0.00034264]
	Learning Rate: 0.000342643
	LOSS [training: 0.18862692721575156 | validation: 0.19539438077005916]
	TIME [epoch: 9.06 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19511536975512148		[learning rate: 0.00034181]
	Learning Rate: 0.000341814
	LOSS [training: 0.19511536975512148 | validation: 0.18676426941592955]
	TIME [epoch: 9.06 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19648633851872913		[learning rate: 0.00034099]
	Learning Rate: 0.000340986
	LOSS [training: 0.19648633851872913 | validation: 0.2036604406742235]
	TIME [epoch: 9.06 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1943281145063287		[learning rate: 0.00034016]
	Learning Rate: 0.000340161
	LOSS [training: 0.1943281145063287 | validation: 0.2053537951188541]
	TIME [epoch: 9.08 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19822030904014065		[learning rate: 0.00033934]
	Learning Rate: 0.000339337
	LOSS [training: 0.19822030904014065 | validation: 0.19425606877233015]
	TIME [epoch: 9.05 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19283181257808207		[learning rate: 0.00033852]
	Learning Rate: 0.000338516
	LOSS [training: 0.19283181257808207 | validation: 0.19125321223916436]
	TIME [epoch: 9.06 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19432504222335473		[learning rate: 0.0003377]
	Learning Rate: 0.000337696
	LOSS [training: 0.19432504222335473 | validation: 0.1961573984213844]
	TIME [epoch: 9.05 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19545601613323055		[learning rate: 0.00033688]
	Learning Rate: 0.000336879
	LOSS [training: 0.19545601613323055 | validation: 0.1853173417108286]
	TIME [epoch: 9.08 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19226656810433343		[learning rate: 0.00033606]
	Learning Rate: 0.000336063
	LOSS [training: 0.19226656810433343 | validation: 0.19996602366770005]
	TIME [epoch: 9.07 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19321641517412153		[learning rate: 0.00033525]
	Learning Rate: 0.00033525
	LOSS [training: 0.19321641517412153 | validation: 0.18368190904541593]
	TIME [epoch: 9.06 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18312688960867443		[learning rate: 0.00033444]
	Learning Rate: 0.000334438
	LOSS [training: 0.18312688960867443 | validation: 0.18500333518800172]
	TIME [epoch: 9.07 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18854973522075075		[learning rate: 0.00033363]
	Learning Rate: 0.000333629
	LOSS [training: 0.18854973522075075 | validation: 0.1889484550181757]
	TIME [epoch: 9.05 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18986964000686818		[learning rate: 0.00033282]
	Learning Rate: 0.000332821
	LOSS [training: 0.18986964000686818 | validation: 0.19147459109252635]
	TIME [epoch: 9.07 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19582190832187285		[learning rate: 0.00033202]
	Learning Rate: 0.000332015
	LOSS [training: 0.19582190832187285 | validation: 0.18569811770530367]
	TIME [epoch: 9.06 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19089700066493062		[learning rate: 0.00033121]
	Learning Rate: 0.000331211
	LOSS [training: 0.19089700066493062 | validation: 0.18537203120791426]
	TIME [epoch: 9.06 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18861054570832603		[learning rate: 0.00033041]
	Learning Rate: 0.00033041
	LOSS [training: 0.18861054570832603 | validation: 0.18441981309672345]
	TIME [epoch: 9.06 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19053505123971576		[learning rate: 0.00032961]
	Learning Rate: 0.00032961
	LOSS [training: 0.19053505123971576 | validation: 0.18492376852195463]
	TIME [epoch: 9.08 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19617448177254296		[learning rate: 0.00032881]
	Learning Rate: 0.000328812
	LOSS [training: 0.19617448177254296 | validation: 0.20009067185184687]
	TIME [epoch: 9.05 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19810447251506583		[learning rate: 0.00032802]
	Learning Rate: 0.000328016
	LOSS [training: 0.19810447251506583 | validation: 0.19470680399433316]
	TIME [epoch: 9.06 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19145705624512596		[learning rate: 0.00032722]
	Learning Rate: 0.000327222
	LOSS [training: 0.19145705624512596 | validation: 0.20183216375770466]
	TIME [epoch: 9.05 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19973763282353502		[learning rate: 0.00032643]
	Learning Rate: 0.00032643
	LOSS [training: 0.19973763282353502 | validation: 0.20625535827938885]
	TIME [epoch: 9.06 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2100075230491456		[learning rate: 0.00032564]
	Learning Rate: 0.000325639
	LOSS [training: 0.2100075230491456 | validation: 0.21040289753424463]
	TIME [epoch: 9.07 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20355742249079728		[learning rate: 0.00032485]
	Learning Rate: 0.000324851
	LOSS [training: 0.20355742249079728 | validation: 0.20223720548108293]
	TIME [epoch: 9.07 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20063918615277898		[learning rate: 0.00032406]
	Learning Rate: 0.000324065
	LOSS [training: 0.20063918615277898 | validation: 0.18350363131566444]
	TIME [epoch: 9.05 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19239002335927768		[learning rate: 0.00032328]
	Learning Rate: 0.00032328
	LOSS [training: 0.19239002335927768 | validation: 0.19138336351196023]
	TIME [epoch: 9.05 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1934053405178512		[learning rate: 0.0003225]
	Learning Rate: 0.000322497
	LOSS [training: 0.1934053405178512 | validation: 0.18906275349001572]
	TIME [epoch: 9.06 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18821488470731715		[learning rate: 0.00032172]
	Learning Rate: 0.000321717
	LOSS [training: 0.18821488470731715 | validation: 0.19388439580937056]
	TIME [epoch: 9.06 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1990272345987772		[learning rate: 0.00032094]
	Learning Rate: 0.000320938
	LOSS [training: 0.1990272345987772 | validation: 0.20320411324352267]
	TIME [epoch: 9.06 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2013670313456218		[learning rate: 0.00032016]
	Learning Rate: 0.000320161
	LOSS [training: 0.2013670313456218 | validation: 0.1946370175837173]
	TIME [epoch: 9.05 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19658506008112694		[learning rate: 0.00031939]
	Learning Rate: 0.000319386
	LOSS [training: 0.19658506008112694 | validation: 0.18797182466673878]
	TIME [epoch: 9.05 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18428744131854619		[learning rate: 0.00031861]
	Learning Rate: 0.000318613
	LOSS [training: 0.18428744131854619 | validation: 0.18608942255899696]
	TIME [epoch: 9.07 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20016771842607609		[learning rate: 0.00031784]
	Learning Rate: 0.000317841
	LOSS [training: 0.20016771842607609 | validation: 0.19050220502141885]
	TIME [epoch: 9.05 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.187410809342946		[learning rate: 0.00031707]
	Learning Rate: 0.000317072
	LOSS [training: 0.187410809342946 | validation: 0.18509898853987036]
	TIME [epoch: 9.05 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18503099535051457		[learning rate: 0.0003163]
	Learning Rate: 0.000316304
	LOSS [training: 0.18503099535051457 | validation: 0.1854665915817914]
	TIME [epoch: 9.05 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19025803802127667		[learning rate: 0.00031554]
	Learning Rate: 0.000315539
	LOSS [training: 0.19025803802127667 | validation: 0.17629506590129326]
	TIME [epoch: 9.06 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18925358663120193		[learning rate: 0.00031477]
	Learning Rate: 0.000314775
	LOSS [training: 0.18925358663120193 | validation: 0.1844635356901405]
	TIME [epoch: 9.09 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18754904250474996		[learning rate: 0.00031401]
	Learning Rate: 0.000314013
	LOSS [training: 0.18754904250474996 | validation: 0.18745043319036653]
	TIME [epoch: 9.07 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17945714676346175		[learning rate: 0.00031325]
	Learning Rate: 0.000313253
	LOSS [training: 0.17945714676346175 | validation: 0.18819322510076442]
	TIME [epoch: 9.06 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18598428552803198		[learning rate: 0.00031249]
	Learning Rate: 0.000312494
	LOSS [training: 0.18598428552803198 | validation: 0.17933069355883038]
	TIME [epoch: 9.06 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1989599730425299		[learning rate: 0.00031174]
	Learning Rate: 0.000311738
	LOSS [training: 0.1989599730425299 | validation: 0.18166086975368761]
	TIME [epoch: 9.07 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19468774033841452		[learning rate: 0.00031098]
	Learning Rate: 0.000310983
	LOSS [training: 0.19468774033841452 | validation: 0.17817815934432696]
	TIME [epoch: 9.06 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19323337666755666		[learning rate: 0.00031023]
	Learning Rate: 0.00031023
	LOSS [training: 0.19323337666755666 | validation: 0.1810838233626565]
	TIME [epoch: 9.07 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19150090635285477		[learning rate: 0.00030948]
	Learning Rate: 0.000309479
	LOSS [training: 0.19150090635285477 | validation: 0.17719604894768365]
	TIME [epoch: 9.05 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1913012699052637		[learning rate: 0.00030873]
	Learning Rate: 0.00030873
	LOSS [training: 0.1913012699052637 | validation: 0.19197845773636613]
	TIME [epoch: 9.06 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18970904548240555		[learning rate: 0.00030798]
	Learning Rate: 0.000307983
	LOSS [training: 0.18970904548240555 | validation: 0.1884960759568806]
	TIME [epoch: 9.08 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19783473216118014		[learning rate: 0.00030724]
	Learning Rate: 0.000307237
	LOSS [training: 0.19783473216118014 | validation: 0.18419283649100732]
	TIME [epoch: 9.06 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19701042900359764		[learning rate: 0.00030649]
	Learning Rate: 0.000306493
	LOSS [training: 0.19701042900359764 | validation: 0.19253236948721542]
	TIME [epoch: 9.05 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19632338404353894		[learning rate: 0.00030575]
	Learning Rate: 0.000305751
	LOSS [training: 0.19632338404353894 | validation: 0.19320567253563253]
	TIME [epoch: 9.06 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20876808914327616		[learning rate: 0.00030501]
	Learning Rate: 0.000305011
	LOSS [training: 0.20876808914327616 | validation: 0.19580273982745725]
	TIME [epoch: 9.08 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19932624390471337		[learning rate: 0.00030427]
	Learning Rate: 0.000304273
	LOSS [training: 0.19932624390471337 | validation: 0.19524697375536976]
	TIME [epoch: 9.07 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20434853650487644		[learning rate: 0.00030354]
	Learning Rate: 0.000303536
	LOSS [training: 0.20434853650487644 | validation: 0.19452645171653934]
	TIME [epoch: 9.06 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20539402734060194		[learning rate: 0.0003028]
	Learning Rate: 0.000302801
	LOSS [training: 0.20539402734060194 | validation: 0.18953200832750727]
	TIME [epoch: 9.05 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19407156403920806		[learning rate: 0.00030207]
	Learning Rate: 0.000302068
	LOSS [training: 0.19407156403920806 | validation: 0.19067205985575947]
	TIME [epoch: 9.05 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21968770566495688		[learning rate: 0.00030134]
	Learning Rate: 0.000301337
	LOSS [training: 0.21968770566495688 | validation: 0.20858529243228585]
	TIME [epoch: 9.07 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21062136568114892		[learning rate: 0.00030061]
	Learning Rate: 0.000300608
	LOSS [training: 0.21062136568114892 | validation: 0.1884381747667277]
	TIME [epoch: 9.06 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20047788235821068		[learning rate: 0.00029988]
	Learning Rate: 0.00029988
	LOSS [training: 0.20047788235821068 | validation: 0.18981971306927456]
	TIME [epoch: 9.05 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20518671519039383		[learning rate: 0.00029915]
	Learning Rate: 0.000299154
	LOSS [training: 0.20518671519039383 | validation: 0.20307149910191263]
	TIME [epoch: 9.06 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2089910312470355		[learning rate: 0.00029843]
	Learning Rate: 0.00029843
	LOSS [training: 0.2089910312470355 | validation: 0.18411055141784577]
	TIME [epoch: 9.05 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1971651861188662		[learning rate: 0.00029771]
	Learning Rate: 0.000297707
	LOSS [training: 0.1971651861188662 | validation: 0.18244633373779195]
	TIME [epoch: 9.07 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19531272862051957		[learning rate: 0.00029699]
	Learning Rate: 0.000296987
	LOSS [training: 0.19531272862051957 | validation: 0.17960308140600575]
	TIME [epoch: 9.05 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18816510012066903		[learning rate: 0.00029627]
	Learning Rate: 0.000296268
	LOSS [training: 0.18816510012066903 | validation: 0.1943445795277186]
	TIME [epoch: 9.06 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19770704847733211		[learning rate: 0.00029555]
	Learning Rate: 0.00029555
	LOSS [training: 0.19770704847733211 | validation: 0.1817743731283328]
	TIME [epoch: 9.06 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18905113563712658		[learning rate: 0.00029483]
	Learning Rate: 0.000294835
	LOSS [training: 0.18905113563712658 | validation: 0.18788015905638716]
	TIME [epoch: 9.07 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19838864524079322		[learning rate: 0.00029412]
	Learning Rate: 0.000294121
	LOSS [training: 0.19838864524079322 | validation: 0.18602194893887816]
	TIME [epoch: 9.06 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1942559839593529		[learning rate: 0.00029341]
	Learning Rate: 0.000293409
	LOSS [training: 0.1942559839593529 | validation: 0.18726953498051607]
	TIME [epoch: 9.06 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19292286335286996		[learning rate: 0.0002927]
	Learning Rate: 0.000292699
	LOSS [training: 0.19292286335286996 | validation: 0.18572888833245652]
	TIME [epoch: 9.06 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19091189898289238		[learning rate: 0.00029199]
	Learning Rate: 0.00029199
	LOSS [training: 0.19091189898289238 | validation: 0.19446395065443117]
	TIME [epoch: 9.06 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19841259894791535		[learning rate: 0.00029128]
	Learning Rate: 0.000291283
	LOSS [training: 0.19841259894791535 | validation: 0.18297160046888497]
	TIME [epoch: 9.07 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20510975986458516		[learning rate: 0.00029058]
	Learning Rate: 0.000290578
	LOSS [training: 0.20510975986458516 | validation: 0.17711983918238647]
	TIME [epoch: 9.07 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20019783730965773		[learning rate: 0.00028987]
	Learning Rate: 0.000289875
	LOSS [training: 0.20019783730965773 | validation: 0.18556765724006946]
	TIME [epoch: 9.06 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1976192053961233		[learning rate: 0.00028917]
	Learning Rate: 0.000289173
	LOSS [training: 0.1976192053961233 | validation: 0.20032855589080584]
	TIME [epoch: 9.06 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2037167235327047		[learning rate: 0.00028847]
	Learning Rate: 0.000288473
	LOSS [training: 0.2037167235327047 | validation: 0.19768880636496244]
	TIME [epoch: 9.08 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19806150149540527		[learning rate: 0.00028777]
	Learning Rate: 0.000287775
	LOSS [training: 0.19806150149540527 | validation: 0.18876961520481067]
	TIME [epoch: 9.06 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19473060332814748		[learning rate: 0.00028708]
	Learning Rate: 0.000287078
	LOSS [training: 0.19473060332814748 | validation: 0.196341955314302]
	TIME [epoch: 9.07 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21148525808843818		[learning rate: 0.00028638]
	Learning Rate: 0.000286383
	LOSS [training: 0.21148525808843818 | validation: 0.191972940905278]
	TIME [epoch: 9.07 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21181857939242618		[learning rate: 0.00028569]
	Learning Rate: 0.00028569
	LOSS [training: 0.21181857939242618 | validation: 0.2006276382599893]
	TIME [epoch: 9.07 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21072224500187625		[learning rate: 0.000285]
	Learning Rate: 0.000284998
	LOSS [training: 0.21072224500187625 | validation: 0.2093998482114533]
	TIME [epoch: 9.08 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2154810454712761		[learning rate: 0.00028431]
	Learning Rate: 0.000284308
	LOSS [training: 0.2154810454712761 | validation: 0.20953899053575964]
	TIME [epoch: 9.05 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21839066152749148		[learning rate: 0.00028362]
	Learning Rate: 0.00028362
	LOSS [training: 0.21839066152749148 | validation: 0.20514224422861926]
	TIME [epoch: 9.06 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21584705393200312		[learning rate: 0.00028293]
	Learning Rate: 0.000282933
	LOSS [training: 0.21584705393200312 | validation: 0.20105294377941804]
	TIME [epoch: 9.06 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21139126352977824		[learning rate: 0.00028225]
	Learning Rate: 0.000282248
	LOSS [training: 0.21139126352977824 | validation: 0.2147903641531292]
	TIME [epoch: 9.07 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21390092030656654		[learning rate: 0.00028157]
	Learning Rate: 0.000281565
	LOSS [training: 0.21390092030656654 | validation: 0.2026433041428161]
	TIME [epoch: 9.07 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.215145280289006		[learning rate: 0.00028088]
	Learning Rate: 0.000280884
	LOSS [training: 0.215145280289006 | validation: 0.21210574910199043]
	TIME [epoch: 9.06 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21653346360999298		[learning rate: 0.0002802]
	Learning Rate: 0.000280204
	LOSS [training: 0.21653346360999298 | validation: 0.21142061024199538]
	TIME [epoch: 9.06 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21195427939281228		[learning rate: 0.00027953]
	Learning Rate: 0.000279525
	LOSS [training: 0.21195427939281228 | validation: 0.1997604250967779]
	TIME [epoch: 9.06 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.214836806640184		[learning rate: 0.00027885]
	Learning Rate: 0.000278849
	LOSS [training: 0.214836806640184 | validation: 0.1990220598664878]
	TIME [epoch: 9.06 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21407440799723113		[learning rate: 0.00027817]
	Learning Rate: 0.000278173
	LOSS [training: 0.21407440799723113 | validation: 0.21313693769702693]
	TIME [epoch: 9.06 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21622697784703365		[learning rate: 0.0002775]
	Learning Rate: 0.0002775
	LOSS [training: 0.21622697784703365 | validation: 0.19739096647044355]
	TIME [epoch: 9.06 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21731061122089557		[learning rate: 0.00027683]
	Learning Rate: 0.000276828
	LOSS [training: 0.21731061122089557 | validation: 0.19385590845992964]
	TIME [epoch: 9.06 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2127140801407303		[learning rate: 0.00027616]
	Learning Rate: 0.000276158
	LOSS [training: 0.2127140801407303 | validation: 0.19977100411876605]
	TIME [epoch: 9.07 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20039479556159567		[learning rate: 0.00027549]
	Learning Rate: 0.00027549
	LOSS [training: 0.20039479556159567 | validation: 0.18387626499303109]
	TIME [epoch: 9.08 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20688433625446478		[learning rate: 0.00027482]
	Learning Rate: 0.000274823
	LOSS [training: 0.20688433625446478 | validation: 0.20069211002161153]
	TIME [epoch: 9.06 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2102482438301168		[learning rate: 0.00027416]
	Learning Rate: 0.000274157
	LOSS [training: 0.2102482438301168 | validation: 0.18340208491582613]
	TIME [epoch: 9.05 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20152754870404638		[learning rate: 0.00027349]
	Learning Rate: 0.000273494
	LOSS [training: 0.20152754870404638 | validation: 0.19055246070169432]
	TIME [epoch: 9.06 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1972243738944685		[learning rate: 0.00027283]
	Learning Rate: 0.000272832
	LOSS [training: 0.1972243738944685 | validation: 0.1852880768072352]
	TIME [epoch: 9.08 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20126826905430076		[learning rate: 0.00027217]
	Learning Rate: 0.000272171
	LOSS [training: 0.20126826905430076 | validation: 0.18855756704578405]
	TIME [epoch: 9.06 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20185420858617342		[learning rate: 0.00027151]
	Learning Rate: 0.000271512
	LOSS [training: 0.20185420858617342 | validation: 0.1915228390901137]
	TIME [epoch: 9.06 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20325880765081544		[learning rate: 0.00027086]
	Learning Rate: 0.000270855
	LOSS [training: 0.20325880765081544 | validation: 0.18333172341099602]
	TIME [epoch: 9.05 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20063146714659869		[learning rate: 0.0002702]
	Learning Rate: 0.000270199
	LOSS [training: 0.20063146714659869 | validation: 0.18747316669181946]
	TIME [epoch: 9.05 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20731595336026137		[learning rate: 0.00026955]
	Learning Rate: 0.000269545
	LOSS [training: 0.20731595336026137 | validation: 0.18057226557247666]
	TIME [epoch: 9.08 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20141942619558031		[learning rate: 0.00026889]
	Learning Rate: 0.000268893
	LOSS [training: 0.20141942619558031 | validation: 0.1920677380725469]
	TIME [epoch: 9.06 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21492139968977675		[learning rate: 0.00026824]
	Learning Rate: 0.000268242
	LOSS [training: 0.21492139968977675 | validation: 0.19041436634038117]
	TIME [epoch: 9.06 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2115093112724316		[learning rate: 0.00026759]
	Learning Rate: 0.000267592
	LOSS [training: 0.2115093112724316 | validation: 0.18536056401111078]
	TIME [epoch: 9.06 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21417196286901627		[learning rate: 0.00026694]
	Learning Rate: 0.000266945
	LOSS [training: 0.21417196286901627 | validation: 0.19772747516436823]
	TIME [epoch: 9.06 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2114996326421584		[learning rate: 0.0002663]
	Learning Rate: 0.000266298
	LOSS [training: 0.2114996326421584 | validation: 0.19600396657483768]
	TIME [epoch: 9.06 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22192777265811228		[learning rate: 0.00026565]
	Learning Rate: 0.000265654
	LOSS [training: 0.22192777265811228 | validation: 0.1931983959281085]
	TIME [epoch: 9.05 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21049082315574275		[learning rate: 0.00026501]
	Learning Rate: 0.000265011
	LOSS [training: 0.21049082315574275 | validation: 0.20140291102634894]
	TIME [epoch: 9.06 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20420375300416907		[learning rate: 0.00026437]
	Learning Rate: 0.000264369
	LOSS [training: 0.20420375300416907 | validation: 0.18146193860527943]
	TIME [epoch: 9.06 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20821610176898614		[learning rate: 0.00026373]
	Learning Rate: 0.000263729
	LOSS [training: 0.20821610176898614 | validation: 0.17936540731020978]
	TIME [epoch: 9.07 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21135376257008076		[learning rate: 0.00026309]
	Learning Rate: 0.000263091
	LOSS [training: 0.21135376257008076 | validation: 0.1878628776597443]
	TIME [epoch: 9.06 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20438591098809483		[learning rate: 0.00026245]
	Learning Rate: 0.000262454
	LOSS [training: 0.20438591098809483 | validation: 0.18964129314304667]
	TIME [epoch: 9.05 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21195467674299154		[learning rate: 0.00026182]
	Learning Rate: 0.000261818
	LOSS [training: 0.21195467674299154 | validation: 0.19694017041042683]
	TIME [epoch: 9.04 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2072787758507951		[learning rate: 0.00026118]
	Learning Rate: 0.000261184
	LOSS [training: 0.2072787758507951 | validation: 0.18422679362582053]
	TIME [epoch: 9.05 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21380604446992363		[learning rate: 0.00026055]
	Learning Rate: 0.000260552
	LOSS [training: 0.21380604446992363 | validation: 0.20376715578168295]
	TIME [epoch: 9.08 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20025110609956767		[learning rate: 0.00025992]
	Learning Rate: 0.000259921
	LOSS [training: 0.20025110609956767 | validation: 0.18571718276362234]
	TIME [epoch: 9.06 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20053698434076228		[learning rate: 0.00025929]
	Learning Rate: 0.000259292
	LOSS [training: 0.20053698434076228 | validation: 0.18813176795495806]
	TIME [epoch: 9.05 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20420306698702592		[learning rate: 0.00025866]
	Learning Rate: 0.000258665
	LOSS [training: 0.20420306698702592 | validation: 0.19966943457627517]
	TIME [epoch: 9.06 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20353114203346118		[learning rate: 0.00025804]
	Learning Rate: 0.000258038
	LOSS [training: 0.20353114203346118 | validation: 0.17937421936489048]
	TIME [epoch: 9.07 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20279004170610201		[learning rate: 0.00025741]
	Learning Rate: 0.000257414
	LOSS [training: 0.20279004170610201 | validation: 0.18818730403023967]
	TIME [epoch: 9.05 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2022422979585837		[learning rate: 0.00025679]
	Learning Rate: 0.00025679
	LOSS [training: 0.2022422979585837 | validation: 0.1964583595197419]
	TIME [epoch: 9.06 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2055347833135804		[learning rate: 0.00025617]
	Learning Rate: 0.000256169
	LOSS [training: 0.2055347833135804 | validation: 0.19005507356270124]
	TIME [epoch: 9.06 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19985081605026925		[learning rate: 0.00025555]
	Learning Rate: 0.000255549
	LOSS [training: 0.19985081605026925 | validation: 0.1869559912797203]
	TIME [epoch: 9.05 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1980945807292364		[learning rate: 0.00025493]
	Learning Rate: 0.00025493
	LOSS [training: 0.1980945807292364 | validation: 0.20107118717246036]
	TIME [epoch: 9.07 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20650863820002355		[learning rate: 0.00025431]
	Learning Rate: 0.000254313
	LOSS [training: 0.20650863820002355 | validation: 0.1892007917692364]
	TIME [epoch: 9.06 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20232055339260083		[learning rate: 0.0002537]
	Learning Rate: 0.000253697
	LOSS [training: 0.20232055339260083 | validation: 0.18531623334268565]
	TIME [epoch: 9.06 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20279902765937577		[learning rate: 0.00025308]
	Learning Rate: 0.000253083
	LOSS [training: 0.20279902765937577 | validation: 0.1833530127668037]
	TIME [epoch: 9.07 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2066105614135106		[learning rate: 0.00025247]
	Learning Rate: 0.00025247
	LOSS [training: 0.2066105614135106 | validation: 0.1887374908413178]
	TIME [epoch: 9.07 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19730376927730942		[learning rate: 0.00025186]
	Learning Rate: 0.000251859
	LOSS [training: 0.19730376927730942 | validation: 0.18686682990332892]
	TIME [epoch: 9.06 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19825050465777394		[learning rate: 0.00025125]
	Learning Rate: 0.00025125
	LOSS [training: 0.19825050465777394 | validation: 0.17734522531726576]
	TIME [epoch: 9.06 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1982879460567179		[learning rate: 0.00025064]
	Learning Rate: 0.000250641
	LOSS [training: 0.1982879460567179 | validation: 0.19152696221455584]
	TIME [epoch: 9.07 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19988204301490867		[learning rate: 0.00025003]
	Learning Rate: 0.000250035
	LOSS [training: 0.19988204301490867 | validation: 0.20067535186938332]
	TIME [epoch: 9.06 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2069441007090657		[learning rate: 0.00024943]
	Learning Rate: 0.000249429
	LOSS [training: 0.2069441007090657 | validation: 0.18304784832675888]
	TIME [epoch: 9.07 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19386855398321096		[learning rate: 0.00024883]
	Learning Rate: 0.000248825
	LOSS [training: 0.19386855398321096 | validation: 0.1892276866368507]
	TIME [epoch: 9.06 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19495504318989634		[learning rate: 0.00024822]
	Learning Rate: 0.000248223
	LOSS [training: 0.19495504318989634 | validation: 0.1829492848000547]
	TIME [epoch: 9.06 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1961995546407665		[learning rate: 0.00024762]
	Learning Rate: 0.000247622
	LOSS [training: 0.1961995546407665 | validation: 0.1791876443897702]
	TIME [epoch: 9.05 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1909646143849926		[learning rate: 0.00024702]
	Learning Rate: 0.000247023
	LOSS [training: 0.1909646143849926 | validation: 0.1823271382842065]
	TIME [epoch: 9.08 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19427110997213198		[learning rate: 0.00024642]
	Learning Rate: 0.000246425
	LOSS [training: 0.19427110997213198 | validation: 0.1755933758581653]
	TIME [epoch: 9.07 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19279931091091812		[learning rate: 0.00024583]
	Learning Rate: 0.000245828
	LOSS [training: 0.19279931091091812 | validation: 0.18364111426389304]
	TIME [epoch: 9.06 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19836679387333292		[learning rate: 0.00024523]
	Learning Rate: 0.000245233
	LOSS [training: 0.19836679387333292 | validation: 0.17987258965725572]
	TIME [epoch: 9.06 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19505318188269707		[learning rate: 0.00024464]
	Learning Rate: 0.000244639
	LOSS [training: 0.19505318188269707 | validation: 0.17110042406163894]
	TIME [epoch: 9.07 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_1631.pth
	Model improved!!!
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18727687557820497		[learning rate: 0.00024405]
	Learning Rate: 0.000244047
	LOSS [training: 0.18727687557820497 | validation: 0.18808203372719356]
	TIME [epoch: 9.08 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19087067153903645		[learning rate: 0.00024346]
	Learning Rate: 0.000243456
	LOSS [training: 0.19087067153903645 | validation: 0.1878041500873055]
	TIME [epoch: 9.06 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19095822311094168		[learning rate: 0.00024287]
	Learning Rate: 0.000242867
	LOSS [training: 0.19095822311094168 | validation: 0.19857476836555513]
	TIME [epoch: 9.06 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1983042344397325		[learning rate: 0.00024228]
	Learning Rate: 0.000242279
	LOSS [training: 0.1983042344397325 | validation: 0.19262745470778403]
	TIME [epoch: 9.05 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20037621811066336		[learning rate: 0.00024169]
	Learning Rate: 0.000241693
	LOSS [training: 0.20037621811066336 | validation: 0.19348764752243935]
	TIME [epoch: 9.05 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19689396699682865		[learning rate: 0.00024111]
	Learning Rate: 0.000241107
	LOSS [training: 0.19689396699682865 | validation: 0.18680892060824777]
	TIME [epoch: 9.08 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1844751058243991		[learning rate: 0.00024052]
	Learning Rate: 0.000240524
	LOSS [training: 0.1844751058243991 | validation: 0.1792596824998544]
	TIME [epoch: 9.05 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19011530671608068		[learning rate: 0.00023994]
	Learning Rate: 0.000239941
	LOSS [training: 0.19011530671608068 | validation: 0.18902692795594098]
	TIME [epoch: 9.06 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1952439604009759		[learning rate: 0.00023936]
	Learning Rate: 0.000239361
	LOSS [training: 0.1952439604009759 | validation: 0.18979976355363165]
	TIME [epoch: 9.06 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1926289681117741		[learning rate: 0.00023878]
	Learning Rate: 0.000238781
	LOSS [training: 0.1926289681117741 | validation: 0.18261219625255248]
	TIME [epoch: 9.07 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1908391428034347		[learning rate: 0.0002382]
	Learning Rate: 0.000238203
	LOSS [training: 0.1908391428034347 | validation: 0.18296606077630584]
	TIME [epoch: 9.05 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18698095392519704		[learning rate: 0.00023763]
	Learning Rate: 0.000237626
	LOSS [training: 0.18698095392519704 | validation: 0.18218000626446867]
	TIME [epoch: 9.04 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18356819002025565		[learning rate: 0.00023705]
	Learning Rate: 0.000237051
	LOSS [training: 0.18356819002025565 | validation: 0.19064823917548496]
	TIME [epoch: 9.05 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18920993166387703		[learning rate: 0.00023648]
	Learning Rate: 0.000236477
	LOSS [training: 0.18920993166387703 | validation: 0.19219386022747845]
	TIME [epoch: 9.06 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18729221204503338		[learning rate: 0.0002359]
	Learning Rate: 0.000235905
	LOSS [training: 0.18729221204503338 | validation: 0.1921946395073627]
	TIME [epoch: 9.07 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19027402595783613		[learning rate: 0.00023533]
	Learning Rate: 0.000235334
	LOSS [training: 0.19027402595783613 | validation: 0.18206613778119596]
	TIME [epoch: 9.06 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1973119706983742		[learning rate: 0.00023476]
	Learning Rate: 0.000234764
	LOSS [training: 0.1973119706983742 | validation: 0.19176795458688786]
	TIME [epoch: 9.05 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19249863704208853		[learning rate: 0.0002342]
	Learning Rate: 0.000234196
	LOSS [training: 0.19249863704208853 | validation: 0.19534772234452774]
	TIME [epoch: 9.05 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18773106480729046		[learning rate: 0.00023363]
	Learning Rate: 0.000233629
	LOSS [training: 0.18773106480729046 | validation: 0.1825011905820068]
	TIME [epoch: 9.08 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1901662111053503		[learning rate: 0.00023306]
	Learning Rate: 0.000233063
	LOSS [training: 0.1901662111053503 | validation: 0.17112994312895344]
	TIME [epoch: 9.07 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1888016245680945		[learning rate: 0.0002325]
	Learning Rate: 0.000232499
	LOSS [training: 0.1888016245680945 | validation: 0.1819299132457509]
	TIME [epoch: 9.06 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18827084138967426		[learning rate: 0.00023194]
	Learning Rate: 0.000231936
	LOSS [training: 0.18827084138967426 | validation: 0.18468312915838814]
	TIME [epoch: 9.05 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18553485517613943		[learning rate: 0.00023137]
	Learning Rate: 0.000231375
	LOSS [training: 0.18553485517613943 | validation: 0.17569386304288287]
	TIME [epoch: 9.06 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18925080230414706		[learning rate: 0.00023081]
	Learning Rate: 0.000230814
	LOSS [training: 0.18925080230414706 | validation: 0.1811606231600847]
	TIME [epoch: 9.08 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1859834334812524		[learning rate: 0.00023026]
	Learning Rate: 0.000230256
	LOSS [training: 0.1859834334812524 | validation: 0.18317351698535003]
	TIME [epoch: 9.06 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18046970740029356		[learning rate: 0.0002297]
	Learning Rate: 0.000229698
	LOSS [training: 0.18046970740029356 | validation: 0.1851454100426495]
	TIME [epoch: 9.07 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19220401716144425		[learning rate: 0.00022914]
	Learning Rate: 0.000229142
	LOSS [training: 0.19220401716144425 | validation: 0.18522276221377681]
	TIME [epoch: 9.07 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19282750839614732		[learning rate: 0.00022859]
	Learning Rate: 0.000228588
	LOSS [training: 0.19282750839614732 | validation: 0.18377628042385546]
	TIME [epoch: 9.06 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18882754680394526		[learning rate: 0.00022803]
	Learning Rate: 0.000228034
	LOSS [training: 0.18882754680394526 | validation: 0.1851215309292415]
	TIME [epoch: 9.08 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1880658944838825		[learning rate: 0.00022748]
	Learning Rate: 0.000227482
	LOSS [training: 0.1880658944838825 | validation: 0.18807436435751967]
	TIME [epoch: 9.05 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1917979297212972		[learning rate: 0.00022693]
	Learning Rate: 0.000226931
	LOSS [training: 0.1917979297212972 | validation: 0.1832575818747698]
	TIME [epoch: 9.06 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19900198428852317		[learning rate: 0.00022638]
	Learning Rate: 0.000226382
	LOSS [training: 0.19900198428852317 | validation: 0.17540561231837692]
	TIME [epoch: 9.06 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18608810500753784		[learning rate: 0.00022583]
	Learning Rate: 0.000225834
	LOSS [training: 0.18608810500753784 | validation: 0.18069776001091753]
	TIME [epoch: 9.08 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19601138863878512		[learning rate: 0.00022529]
	Learning Rate: 0.000225287
	LOSS [training: 0.19601138863878512 | validation: 0.19021727192234994]
	TIME [epoch: 9.06 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20014899059516372		[learning rate: 0.00022474]
	Learning Rate: 0.000224742
	LOSS [training: 0.20014899059516372 | validation: 0.17978886817701978]
	TIME [epoch: 9.06 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19174061820981966		[learning rate: 0.0002242]
	Learning Rate: 0.000224198
	LOSS [training: 0.19174061820981966 | validation: 0.19050115442058532]
	TIME [epoch: 9.07 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19463460431035454		[learning rate: 0.00022366]
	Learning Rate: 0.000223655
	LOSS [training: 0.19463460431035454 | validation: 0.19007299351850182]
	TIME [epoch: 9.06 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20104779478544016		[learning rate: 0.00022311]
	Learning Rate: 0.000223114
	LOSS [training: 0.20104779478544016 | validation: 0.1918462672470313]
	TIME [epoch: 9.08 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18813668133685174		[learning rate: 0.00022257]
	Learning Rate: 0.000222574
	LOSS [training: 0.18813668133685174 | validation: 0.18595736143441594]
	TIME [epoch: 9.06 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18693809652021992		[learning rate: 0.00022203]
	Learning Rate: 0.000222035
	LOSS [training: 0.18693809652021992 | validation: 0.16996615953609617]
	TIME [epoch: 9.06 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_1671.pth
	Model improved!!!
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19427772764319043		[learning rate: 0.0002215]
	Learning Rate: 0.000221497
	LOSS [training: 0.19427772764319043 | validation: 0.17408208467991634]
	TIME [epoch: 9.07 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18225335621662225		[learning rate: 0.00022096]
	Learning Rate: 0.000220961
	LOSS [training: 0.18225335621662225 | validation: 0.1873320324039888]
	TIME [epoch: 9.08 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18610335358768354		[learning rate: 0.00022043]
	Learning Rate: 0.000220426
	LOSS [training: 0.18610335358768354 | validation: 0.17827690949466288]
	TIME [epoch: 9.06 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18916643820452803		[learning rate: 0.00021989]
	Learning Rate: 0.000219893
	LOSS [training: 0.18916643820452803 | validation: 0.18847258676793033]
	TIME [epoch: 9.06 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1908828519195429		[learning rate: 0.00021936]
	Learning Rate: 0.00021936
	LOSS [training: 0.1908828519195429 | validation: 0.18212673474231306]
	TIME [epoch: 9.05 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18590664163662587		[learning rate: 0.00021883]
	Learning Rate: 0.000218829
	LOSS [training: 0.18590664163662587 | validation: 0.18543978880930118]
	TIME [epoch: 9.06 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19446346403705803		[learning rate: 0.0002183]
	Learning Rate: 0.000218299
	LOSS [training: 0.19446346403705803 | validation: 0.2002988078773788]
	TIME [epoch: 9.07 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18612882390430432		[learning rate: 0.00021777]
	Learning Rate: 0.000217771
	LOSS [training: 0.18612882390430432 | validation: 0.18382639240345436]
	TIME [epoch: 9.06 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18575649906040453		[learning rate: 0.00021724]
	Learning Rate: 0.000217244
	LOSS [training: 0.18575649906040453 | validation: 0.1806669959468643]
	TIME [epoch: 9.06 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19230549834958505		[learning rate: 0.00021672]
	Learning Rate: 0.000216718
	LOSS [training: 0.19230549834958505 | validation: 0.17839023692496803]
	TIME [epoch: 9.05 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1861971434274269		[learning rate: 0.00021619]
	Learning Rate: 0.000216193
	LOSS [training: 0.1861971434274269 | validation: 0.18017223867548054]
	TIME [epoch: 9.07 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19022621997758224		[learning rate: 0.00021567]
	Learning Rate: 0.00021567
	LOSS [training: 0.19022621997758224 | validation: 0.18210349927226083]
	TIME [epoch: 9.07 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19043525773037567		[learning rate: 0.00021515]
	Learning Rate: 0.000215148
	LOSS [training: 0.19043525773037567 | validation: 0.1913680289624288]
	TIME [epoch: 9.06 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19601529576421295		[learning rate: 0.00021463]
	Learning Rate: 0.000214627
	LOSS [training: 0.19601529576421295 | validation: 0.20299659383903831]
	TIME [epoch: 9.07 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1888305514235759		[learning rate: 0.00021411]
	Learning Rate: 0.000214107
	LOSS [training: 0.1888305514235759 | validation: 0.19437562775106232]
	TIME [epoch: 9.06 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19006162930986545		[learning rate: 0.00021359]
	Learning Rate: 0.000213589
	LOSS [training: 0.19006162930986545 | validation: 0.19318564645316172]
	TIME [epoch: 9.07 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18657126320367629		[learning rate: 0.00021307]
	Learning Rate: 0.000213072
	LOSS [training: 0.18657126320367629 | validation: 0.182638196342566]
	TIME [epoch: 9.06 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18648936605753094		[learning rate: 0.00021256]
	Learning Rate: 0.000212556
	LOSS [training: 0.18648936605753094 | validation: 0.18371470289204533]
	TIME [epoch: 9.05 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18402629863378		[learning rate: 0.00021204]
	Learning Rate: 0.000212042
	LOSS [training: 0.18402629863378 | validation: 0.18222818873695695]
	TIME [epoch: 9.06 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1852531796162067		[learning rate: 0.00021153]
	Learning Rate: 0.000211528
	LOSS [training: 0.1852531796162067 | validation: 0.18414362233062895]
	TIME [epoch: 9.05 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1884130173065201		[learning rate: 0.00021102]
	Learning Rate: 0.000211016
	LOSS [training: 0.1884130173065201 | validation: 0.187359637560311]
	TIME [epoch: 9.08 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18791714406528864		[learning rate: 0.00021051]
	Learning Rate: 0.000210505
	LOSS [training: 0.18791714406528864 | validation: 0.18105558708351693]
	TIME [epoch: 9.06 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18112719987599687		[learning rate: 0.00021]
	Learning Rate: 0.000209996
	LOSS [training: 0.18112719987599687 | validation: 0.20560522256286884]
	TIME [epoch: 9.06 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18455812941452437		[learning rate: 0.00020949]
	Learning Rate: 0.000209487
	LOSS [training: 0.18455812941452437 | validation: 0.18463235038759665]
	TIME [epoch: 9.06 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1864136095451383		[learning rate: 0.00020898]
	Learning Rate: 0.00020898
	LOSS [training: 0.1864136095451383 | validation: 0.1909338096712216]
	TIME [epoch: 9.08 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1881042717617744		[learning rate: 0.00020847]
	Learning Rate: 0.000208474
	LOSS [training: 0.1881042717617744 | validation: 0.19553094590093986]
	TIME [epoch: 9.07 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19087060707471698		[learning rate: 0.00020797]
	Learning Rate: 0.00020797
	LOSS [training: 0.19087060707471698 | validation: 0.18696650179676522]
	TIME [epoch: 9.07 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18384584633019938		[learning rate: 0.00020747]
	Learning Rate: 0.000207466
	LOSS [training: 0.18384584633019938 | validation: 0.19562630551949525]
	TIME [epoch: 9.06 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18043986777646698		[learning rate: 0.00020696]
	Learning Rate: 0.000206964
	LOSS [training: 0.18043986777646698 | validation: 0.1960887175472917]
	TIME [epoch: 9.06 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18770056484927025		[learning rate: 0.00020646]
	Learning Rate: 0.000206463
	LOSS [training: 0.18770056484927025 | validation: 0.18970186097176608]
	TIME [epoch: 9.07 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18357025937983953		[learning rate: 0.00020596]
	Learning Rate: 0.000205963
	LOSS [training: 0.18357025937983953 | validation: 0.18273974519398792]
	TIME [epoch: 9.06 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18438532041831057		[learning rate: 0.00020546]
	Learning Rate: 0.000205465
	LOSS [training: 0.18438532041831057 | validation: 0.1801496205474213]
	TIME [epoch: 9.05 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19260162610833592		[learning rate: 0.00020497]
	Learning Rate: 0.000204967
	LOSS [training: 0.19260162610833592 | validation: 0.1829237210847882]
	TIME [epoch: 9.05 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18484152621042266		[learning rate: 0.00020447]
	Learning Rate: 0.000204471
	LOSS [training: 0.18484152621042266 | validation: 0.18868910756321974]
	TIME [epoch: 9.08 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1901739438489819		[learning rate: 0.00020398]
	Learning Rate: 0.000203976
	LOSS [training: 0.1901739438489819 | validation: 0.18357706345334399]
	TIME [epoch: 9.07 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19058069906981848		[learning rate: 0.00020348]
	Learning Rate: 0.000203482
	LOSS [training: 0.19058069906981848 | validation: 0.17407501910177364]
	TIME [epoch: 9.06 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18897056596609849		[learning rate: 0.00020299]
	Learning Rate: 0.00020299
	LOSS [training: 0.18897056596609849 | validation: 0.19020676441972456]
	TIME [epoch: 9.06 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18545610219159042		[learning rate: 0.0002025]
	Learning Rate: 0.000202498
	LOSS [training: 0.18545610219159042 | validation: 0.17957355989031046]
	TIME [epoch: 9.05 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18737614474078854		[learning rate: 0.00020201]
	Learning Rate: 0.000202008
	LOSS [training: 0.18737614474078854 | validation: 0.1906920414550961]
	TIME [epoch: 9.08 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19137096269280285		[learning rate: 0.00020152]
	Learning Rate: 0.000201519
	LOSS [training: 0.19137096269280285 | validation: 0.18737002596536262]
	TIME [epoch: 9.07 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1882151353615088		[learning rate: 0.00020103]
	Learning Rate: 0.000201031
	LOSS [training: 0.1882151353615088 | validation: 0.18049609737966288]
	TIME [epoch: 9.06 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19374149101138782		[learning rate: 0.00020054]
	Learning Rate: 0.000200544
	LOSS [training: 0.19374149101138782 | validation: 0.19686332959610073]
	TIME [epoch: 9.05 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19799739704145702		[learning rate: 0.00020006]
	Learning Rate: 0.000200059
	LOSS [training: 0.19799739704145702 | validation: 0.20213194897804515]
	TIME [epoch: 9.06 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20072454534120948		[learning rate: 0.00019957]
	Learning Rate: 0.000199575
	LOSS [training: 0.20072454534120948 | validation: 0.2052780946719636]
	TIME [epoch: 9.06 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20159122268483493		[learning rate: 0.00019909]
	Learning Rate: 0.000199091
	LOSS [training: 0.20159122268483493 | validation: 0.1861652446645977]
	TIME [epoch: 9.06 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19408613429354094		[learning rate: 0.00019861]
	Learning Rate: 0.000198609
	LOSS [training: 0.19408613429354094 | validation: 0.20392862673490247]
	TIME [epoch: 9.06 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19801029375832027		[learning rate: 0.00019813]
	Learning Rate: 0.000198129
	LOSS [training: 0.19801029375832027 | validation: 0.191547820616421]
	TIME [epoch: 9.07 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19842203091653693		[learning rate: 0.00019765]
	Learning Rate: 0.000197649
	LOSS [training: 0.19842203091653693 | validation: 0.1935868838919947]
	TIME [epoch: 9.08 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19720063094744048		[learning rate: 0.00019717]
	Learning Rate: 0.000197171
	LOSS [training: 0.19720063094744048 | validation: 0.1816117280819149]
	TIME [epoch: 9.06 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18965789736708596		[learning rate: 0.00019669]
	Learning Rate: 0.000196693
	LOSS [training: 0.18965789736708596 | validation: 0.20260328747566317]
	TIME [epoch: 9.06 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19521882431832532		[learning rate: 0.00019622]
	Learning Rate: 0.000196217
	LOSS [training: 0.19521882431832532 | validation: 0.19879723670357446]
	TIME [epoch: 9.06 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1925138383448572		[learning rate: 0.00019574]
	Learning Rate: 0.000195742
	LOSS [training: 0.1925138383448572 | validation: 0.18194342173825184]
	TIME [epoch: 9.06 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19504632948639247		[learning rate: 0.00019527]
	Learning Rate: 0.000195268
	LOSS [training: 0.19504632948639247 | validation: 0.19504989819808127]
	TIME [epoch: 9.09 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19186463053909747		[learning rate: 0.0001948]
	Learning Rate: 0.000194796
	LOSS [training: 0.19186463053909747 | validation: 0.17986835718880034]
	TIME [epoch: 9.06 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19075690866460548		[learning rate: 0.00019432]
	Learning Rate: 0.000194324
	LOSS [training: 0.19075690866460548 | validation: 0.17847633363005638]
	TIME [epoch: 9.07 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19490922572629754		[learning rate: 0.00019385]
	Learning Rate: 0.000193853
	LOSS [training: 0.19490922572629754 | validation: 0.18854655203707088]
	TIME [epoch: 9.05 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19061043314567774		[learning rate: 0.00019338]
	Learning Rate: 0.000193384
	LOSS [training: 0.19061043314567774 | validation: 0.17580494266692834]
	TIME [epoch: 9.07 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19016519196608928		[learning rate: 0.00019292]
	Learning Rate: 0.000192916
	LOSS [training: 0.19016519196608928 | validation: 0.20551571661427465]
	TIME [epoch: 9.06 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1890601394089431		[learning rate: 0.00019245]
	Learning Rate: 0.000192449
	LOSS [training: 0.1890601394089431 | validation: 0.17792397677085792]
	TIME [epoch: 9.06 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19080203464929407		[learning rate: 0.00019198]
	Learning Rate: 0.000191983
	LOSS [training: 0.19080203464929407 | validation: 0.18443397889508537]
	TIME [epoch: 9.06 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18996139973331266		[learning rate: 0.00019152]
	Learning Rate: 0.000191518
	LOSS [training: 0.18996139973331266 | validation: 0.18436081136995944]
	TIME [epoch: 9.05 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1937956196735989		[learning rate: 0.00019105]
	Learning Rate: 0.000191055
	LOSS [training: 0.1937956196735989 | validation: 0.19661405483078281]
	TIME [epoch: 9.08 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1940420050318468		[learning rate: 0.00019059]
	Learning Rate: 0.000190592
	LOSS [training: 0.1940420050318468 | validation: 0.20048381769590118]
	TIME [epoch: 9.06 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19682116824164997		[learning rate: 0.00019013]
	Learning Rate: 0.000190131
	LOSS [training: 0.19682116824164997 | validation: 0.18770109842388943]
	TIME [epoch: 9.06 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19453769056004114		[learning rate: 0.00018967]
	Learning Rate: 0.000189671
	LOSS [training: 0.19453769056004114 | validation: 0.19197068300678738]
	TIME [epoch: 9.06 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19373644372966112		[learning rate: 0.00018921]
	Learning Rate: 0.000189211
	LOSS [training: 0.19373644372966112 | validation: 0.18804226938181384]
	TIME [epoch: 9.08 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1894007871348541		[learning rate: 0.00018875]
	Learning Rate: 0.000188753
	LOSS [training: 0.1894007871348541 | validation: 0.1936649405627751]
	TIME [epoch: 9.06 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1978907908421132		[learning rate: 0.0001883]
	Learning Rate: 0.000188296
	LOSS [training: 0.1978907908421132 | validation: 0.18886480047867882]
	TIME [epoch: 9.07 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19294080088282034		[learning rate: 0.00018784]
	Learning Rate: 0.000187841
	LOSS [training: 0.19294080088282034 | validation: 0.19333140059042456]
	TIME [epoch: 9.06 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19386307585207221		[learning rate: 0.00018739]
	Learning Rate: 0.000187386
	LOSS [training: 0.19386307585207221 | validation: 0.19005500685537088]
	TIME [epoch: 9.06 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.197074067588171		[learning rate: 0.00018693]
	Learning Rate: 0.000186932
	LOSS [training: 0.197074067588171 | validation: 0.19465405280323553]
	TIME [epoch: 9.07 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1895281560897612		[learning rate: 0.00018648]
	Learning Rate: 0.00018648
	LOSS [training: 0.1895281560897612 | validation: 0.1800828375593027]
	TIME [epoch: 9.06 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1902261242519907		[learning rate: 0.00018603]
	Learning Rate: 0.000186028
	LOSS [training: 0.1902261242519907 | validation: 0.20024298049515604]
	TIME [epoch: 9.07 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18681108241835653		[learning rate: 0.00018558]
	Learning Rate: 0.000185578
	LOSS [training: 0.18681108241835653 | validation: 0.19091443624328902]
	TIME [epoch: 9.05 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18747276621291561		[learning rate: 0.00018513]
	Learning Rate: 0.000185129
	LOSS [training: 0.18747276621291561 | validation: 0.18871548316347786]
	TIME [epoch: 9.06 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1861330085614073		[learning rate: 0.00018468]
	Learning Rate: 0.00018468
	LOSS [training: 0.1861330085614073 | validation: 0.18608559645157527]
	TIME [epoch: 9.07 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1888012121352109		[learning rate: 0.00018423]
	Learning Rate: 0.000184233
	LOSS [training: 0.1888012121352109 | validation: 0.18471686828863565]
	TIME [epoch: 9.06 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19023097692797047		[learning rate: 0.00018379]
	Learning Rate: 0.000183787
	LOSS [training: 0.19023097692797047 | validation: 0.1824345776093412]
	TIME [epoch: 9.05 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19031081102193786		[learning rate: 0.00018334]
	Learning Rate: 0.000183343
	LOSS [training: 0.19031081102193786 | validation: 0.19409955061470632]
	TIME [epoch: 9.11 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19151932484641218		[learning rate: 0.0001829]
	Learning Rate: 0.000182899
	LOSS [training: 0.19151932484641218 | validation: 0.19593836226681466]
	TIME [epoch: 9.07 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1895091159942956		[learning rate: 0.00018246]
	Learning Rate: 0.000182456
	LOSS [training: 0.1895091159942956 | validation: 0.18436242855793197]
	TIME [epoch: 9.06 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18760952066152758		[learning rate: 0.00018201]
	Learning Rate: 0.000182014
	LOSS [training: 0.18760952066152758 | validation: 0.18540323358249614]
	TIME [epoch: 9.05 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19026213846388246		[learning rate: 0.00018157]
	Learning Rate: 0.000181574
	LOSS [training: 0.19026213846388246 | validation: 0.17719510608020383]
	TIME [epoch: 9.05 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18621754912446695		[learning rate: 0.00018113]
	Learning Rate: 0.000181134
	LOSS [training: 0.18621754912446695 | validation: 0.18450281484689374]
	TIME [epoch: 9.05 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1871131617476036		[learning rate: 0.0001807]
	Learning Rate: 0.000180696
	LOSS [training: 0.1871131617476036 | validation: 0.18430136064027247]
	TIME [epoch: 9.08 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18314762321182326		[learning rate: 0.00018026]
	Learning Rate: 0.000180258
	LOSS [training: 0.18314762321182326 | validation: 0.1841139737298787]
	TIME [epoch: 9.06 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18258366149024202		[learning rate: 0.00017982]
	Learning Rate: 0.000179822
	LOSS [training: 0.18258366149024202 | validation: 0.18558912396890653]
	TIME [epoch: 9.05 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18475562668941317		[learning rate: 0.00017939]
	Learning Rate: 0.000179386
	LOSS [training: 0.18475562668941317 | validation: 0.19053340622139298]
	TIME [epoch: 9.07 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.187659237403306		[learning rate: 0.00017895]
	Learning Rate: 0.000178952
	LOSS [training: 0.187659237403306 | validation: 0.17661353318809866]
	TIME [epoch: 9.07 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18325130663046296		[learning rate: 0.00017852]
	Learning Rate: 0.000178519
	LOSS [training: 0.18325130663046296 | validation: 0.19123128895041874]
	TIME [epoch: 9.05 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18191969191285434		[learning rate: 0.00017809]
	Learning Rate: 0.000178087
	LOSS [training: 0.18191969191285434 | validation: 0.18329347224071146]
	TIME [epoch: 9.06 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18337758967422618		[learning rate: 0.00017766]
	Learning Rate: 0.000177656
	LOSS [training: 0.18337758967422618 | validation: 0.1780664343058313]
	TIME [epoch: 9.06 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17848330967471598		[learning rate: 0.00017723]
	Learning Rate: 0.000177226
	LOSS [training: 0.17848330967471598 | validation: 0.18932904567332381]
	TIME [epoch: 9.07 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18478188806420195		[learning rate: 0.0001768]
	Learning Rate: 0.000176797
	LOSS [training: 0.18478188806420195 | validation: 0.17915668311818322]
	TIME [epoch: 9.07 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1844831449319929		[learning rate: 0.00017637]
	Learning Rate: 0.000176369
	LOSS [training: 0.1844831449319929 | validation: 0.1806754118106073]
	TIME [epoch: 9.06 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18250249505619526		[learning rate: 0.00017594]
	Learning Rate: 0.000175942
	LOSS [training: 0.18250249505619526 | validation: 0.171517305500672]
	TIME [epoch: 9.05 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18215966912240933		[learning rate: 0.00017552]
	Learning Rate: 0.000175516
	LOSS [training: 0.18215966912240933 | validation: 0.1809620706043542]
	TIME [epoch: 9.05 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18146275911089194		[learning rate: 0.00017509]
	Learning Rate: 0.000175091
	LOSS [training: 0.18146275911089194 | validation: 0.1859938855072809]
	TIME [epoch: 9.06 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18495711428864392		[learning rate: 0.00017467]
	Learning Rate: 0.000174667
	LOSS [training: 0.18495711428864392 | validation: 0.18251657581547154]
	TIME [epoch: 9.06 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1816079141824304		[learning rate: 0.00017424]
	Learning Rate: 0.000174244
	LOSS [training: 0.1816079141824304 | validation: 0.17762565194245944]
	TIME [epoch: 9.07 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18120086816595796		[learning rate: 0.00017382]
	Learning Rate: 0.000173822
	LOSS [training: 0.18120086816595796 | validation: 0.18163146827751547]
	TIME [epoch: 9.06 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18385129828614574		[learning rate: 0.0001734]
	Learning Rate: 0.000173401
	LOSS [training: 0.18385129828614574 | validation: 0.18499863243807416]
	TIME [epoch: 9.05 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1870212846803082		[learning rate: 0.00017298]
	Learning Rate: 0.000172982
	LOSS [training: 0.1870212846803082 | validation: 0.175140876617204]
	TIME [epoch: 9.07 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19322151098281823		[learning rate: 0.00017256]
	Learning Rate: 0.000172563
	LOSS [training: 0.19322151098281823 | validation: 0.18752045798380565]
	TIME [epoch: 9.05 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19247356146551442		[learning rate: 0.00017215]
	Learning Rate: 0.000172145
	LOSS [training: 0.19247356146551442 | validation: 0.19012494137408037]
	TIME [epoch: 9.07 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18989558858843258		[learning rate: 0.00017173]
	Learning Rate: 0.000171728
	LOSS [training: 0.18989558858843258 | validation: 0.18928661171025318]
	TIME [epoch: 9.07 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19283554068942876		[learning rate: 0.00017131]
	Learning Rate: 0.000171313
	LOSS [training: 0.19283554068942876 | validation: 0.19206368905690363]
	TIME [epoch: 9.06 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1933509792784997		[learning rate: 0.0001709]
	Learning Rate: 0.000170898
	LOSS [training: 0.1933509792784997 | validation: 0.19384249833961698]
	TIME [epoch: 9.07 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18787703155467314		[learning rate: 0.00017048]
	Learning Rate: 0.000170484
	LOSS [training: 0.18787703155467314 | validation: 0.19019962473856514]
	TIME [epoch: 9.05 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19151579284196457		[learning rate: 0.00017007]
	Learning Rate: 0.000170072
	LOSS [training: 0.19151579284196457 | validation: 0.17963410525516849]
	TIME [epoch: 9.05 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19056459090458336		[learning rate: 0.00016966]
	Learning Rate: 0.00016966
	LOSS [training: 0.19056459090458336 | validation: 0.17717377286192484]
	TIME [epoch: 9.06 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18429809255668927		[learning rate: 0.00016925]
	Learning Rate: 0.000169249
	LOSS [training: 0.18429809255668927 | validation: 0.19012770124804407]
	TIME [epoch: 9.07 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18830103394674574		[learning rate: 0.00016884]
	Learning Rate: 0.000168839
	LOSS [training: 0.18830103394674574 | validation: 0.18097874988859441]
	TIME [epoch: 9.07 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18474126245468822		[learning rate: 0.00016843]
	Learning Rate: 0.000168431
	LOSS [training: 0.18474126245468822 | validation: 0.17428453950271727]
	TIME [epoch: 9.05 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18188971946550847		[learning rate: 0.00016802]
	Learning Rate: 0.000168023
	LOSS [training: 0.18188971946550847 | validation: 0.17861349256844808]
	TIME [epoch: 9.05 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18825967366896657		[learning rate: 0.00016762]
	Learning Rate: 0.000167616
	LOSS [training: 0.18825967366896657 | validation: 0.18533623055743875]
	TIME [epoch: 9.05 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18317541308801022		[learning rate: 0.00016721]
	Learning Rate: 0.00016721
	LOSS [training: 0.18317541308801022 | validation: 0.19177473081472196]
	TIME [epoch: 9.07 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1866182906478034		[learning rate: 0.00016681]
	Learning Rate: 0.000166806
	LOSS [training: 0.1866182906478034 | validation: 0.1807427173919013]
	TIME [epoch: 9.06 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1911231548873266		[learning rate: 0.0001664]
	Learning Rate: 0.000166402
	LOSS [training: 0.1911231548873266 | validation: 0.19147808902817154]
	TIME [epoch: 9.07 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1917833736043485		[learning rate: 0.000166]
	Learning Rate: 0.000165999
	LOSS [training: 0.1917833736043485 | validation: 0.18532967141694678]
	TIME [epoch: 9.06 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18791745951055822		[learning rate: 0.0001656]
	Learning Rate: 0.000165597
	LOSS [training: 0.18791745951055822 | validation: 0.17779876774516878]
	TIME [epoch: 9.09 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1877944544623437		[learning rate: 0.0001652]
	Learning Rate: 0.000165196
	LOSS [training: 0.1877944544623437 | validation: 0.18442595728413336]
	TIME [epoch: 9.05 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18596033420813465		[learning rate: 0.0001648]
	Learning Rate: 0.000164796
	LOSS [training: 0.18596033420813465 | validation: 0.1879856008464988]
	TIME [epoch: 9.06 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1843169304020334		[learning rate: 0.0001644]
	Learning Rate: 0.000164397
	LOSS [training: 0.1843169304020334 | validation: 0.18574960158781828]
	TIME [epoch: 9.05 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19100663600327114		[learning rate: 0.000164]
	Learning Rate: 0.000163999
	LOSS [training: 0.19100663600327114 | validation: 0.1817343171851955]
	TIME [epoch: 9.05 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18408214139442544		[learning rate: 0.0001636]
	Learning Rate: 0.000163602
	LOSS [training: 0.18408214139442544 | validation: 0.17260102869332578]
	TIME [epoch: 9.08 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18103488212541338		[learning rate: 0.00016321]
	Learning Rate: 0.000163206
	LOSS [training: 0.18103488212541338 | validation: 0.1927516060503417]
	TIME [epoch: 9.05 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18613082215330268		[learning rate: 0.00016281]
	Learning Rate: 0.000162811
	LOSS [training: 0.18613082215330268 | validation: 0.18329981393453854]
	TIME [epoch: 9.06 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18750085125053556		[learning rate: 0.00016242]
	Learning Rate: 0.000162417
	LOSS [training: 0.18750085125053556 | validation: 0.18102585362796403]
	TIME [epoch: 9.06 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18887061888010218		[learning rate: 0.00016202]
	Learning Rate: 0.000162024
	LOSS [training: 0.18887061888010218 | validation: 0.18734225329517187]
	TIME [epoch: 9.05 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18407348424169104		[learning rate: 0.00016163]
	Learning Rate: 0.000161632
	LOSS [training: 0.18407348424169104 | validation: 0.18187285500553202]
	TIME [epoch: 9.08 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18176282037740907		[learning rate: 0.00016124]
	Learning Rate: 0.00016124
	LOSS [training: 0.18176282037740907 | validation: 0.1811462752612828]
	TIME [epoch: 9.06 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1817983531437301		[learning rate: 0.00016085]
	Learning Rate: 0.00016085
	LOSS [training: 0.1817983531437301 | validation: 0.1710603695186931]
	TIME [epoch: 9.06 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18242873164689088		[learning rate: 0.00016046]
	Learning Rate: 0.000160461
	LOSS [training: 0.18242873164689088 | validation: 0.18613382451351035]
	TIME [epoch: 9.05 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18983138056472185		[learning rate: 0.00016007]
	Learning Rate: 0.000160072
	LOSS [training: 0.18983138056472185 | validation: 0.1900110732946969]
	TIME [epoch: 9.07 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18340619799226085		[learning rate: 0.00015968]
	Learning Rate: 0.000159685
	LOSS [training: 0.18340619799226085 | validation: 0.1893567865680626]
	TIME [epoch: 9.05 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18819370245203867		[learning rate: 0.0001593]
	Learning Rate: 0.000159298
	LOSS [training: 0.18819370245203867 | validation: 0.1854300150100746]
	TIME [epoch: 9.05 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1838901778786077		[learning rate: 0.00015891]
	Learning Rate: 0.000158912
	LOSS [training: 0.1838901778786077 | validation: 0.19939352871263505]
	TIME [epoch: 9.06 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18607096818718488		[learning rate: 0.00015853]
	Learning Rate: 0.000158528
	LOSS [training: 0.18607096818718488 | validation: 0.17964762521425648]
	TIME [epoch: 9.06 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1768391059988566		[learning rate: 0.00015814]
	Learning Rate: 0.000158144
	LOSS [training: 0.1768391059988566 | validation: 0.18981829847973483]
	TIME [epoch: 9.07 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1843948514298951		[learning rate: 0.00015776]
	Learning Rate: 0.000157761
	LOSS [training: 0.1843948514298951 | validation: 0.1943579259406567]
	TIME [epoch: 9.06 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18978073500617318		[learning rate: 0.00015738]
	Learning Rate: 0.000157379
	LOSS [training: 0.18978073500617318 | validation: 0.1820053868265838]
	TIME [epoch: 9.06 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18413156007440873		[learning rate: 0.000157]
	Learning Rate: 0.000156998
	LOSS [training: 0.18413156007440873 | validation: 0.18083243568243845]
	TIME [epoch: 9.05 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1839349496007243		[learning rate: 0.00015662]
	Learning Rate: 0.000156618
	LOSS [training: 0.1839349496007243 | validation: 0.17549709754185505]
	TIME [epoch: 9.08 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18184147388541017		[learning rate: 0.00015624]
	Learning Rate: 0.000156239
	LOSS [training: 0.18184147388541017 | validation: 0.18582740144121968]
	TIME [epoch: 9.06 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18220035806412418		[learning rate: 0.00015586]
	Learning Rate: 0.000155861
	LOSS [training: 0.18220035806412418 | validation: 0.17973007937885443]
	TIME [epoch: 9.06 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18614084598264896		[learning rate: 0.00015548]
	Learning Rate: 0.000155483
	LOSS [training: 0.18614084598264896 | validation: 0.1886031177412602]
	TIME [epoch: 9.06 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1852099156771155		[learning rate: 0.00015511]
	Learning Rate: 0.000155107
	LOSS [training: 0.1852099156771155 | validation: 0.19791862291176668]
	TIME [epoch: 9.06 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18568414134810066		[learning rate: 0.00015473]
	Learning Rate: 0.000154732
	LOSS [training: 0.18568414134810066 | validation: 0.1776207998795217]
	TIME [epoch: 9.08 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18587659014535088		[learning rate: 0.00015436]
	Learning Rate: 0.000154357
	LOSS [training: 0.18587659014535088 | validation: 0.18486051498420325]
	TIME [epoch: 9.05 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18203152430869737		[learning rate: 0.00015398]
	Learning Rate: 0.000153983
	LOSS [training: 0.18203152430869737 | validation: 0.18381035456205524]
	TIME [epoch: 9.06 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18506123318828108		[learning rate: 0.00015361]
	Learning Rate: 0.000153611
	LOSS [training: 0.18506123318828108 | validation: 0.18925663805721668]
	TIME [epoch: 9.06 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18025589985926643		[learning rate: 0.00015324]
	Learning Rate: 0.000153239
	LOSS [training: 0.18025589985926643 | validation: 0.19007927473672004]
	TIME [epoch: 9.07 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18398572080549014		[learning rate: 0.00015287]
	Learning Rate: 0.000152868
	LOSS [training: 0.18398572080549014 | validation: 0.18267349931528526]
	TIME [epoch: 9.07 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18221052902613066		[learning rate: 0.0001525]
	Learning Rate: 0.000152498
	LOSS [training: 0.18221052902613066 | validation: 0.1927732942406855]
	TIME [epoch: 9.06 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.179383224700988		[learning rate: 0.00015213]
	Learning Rate: 0.000152128
	LOSS [training: 0.179383224700988 | validation: 0.17948725428556866]
	TIME [epoch: 9.06 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.187253405650382		[learning rate: 0.00015176]
	Learning Rate: 0.00015176
	LOSS [training: 0.187253405650382 | validation: 0.19364427372863616]
	TIME [epoch: 9.06 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18584693760340915		[learning rate: 0.00015139]
	Learning Rate: 0.000151393
	LOSS [training: 0.18584693760340915 | validation: 0.18756089159232398]
	TIME [epoch: 9.09 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17988718839575996		[learning rate: 0.00015103]
	Learning Rate: 0.000151026
	LOSS [training: 0.17988718839575996 | validation: 0.18831150698050225]
	TIME [epoch: 9.08 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18733150898692583		[learning rate: 0.00015066]
	Learning Rate: 0.000150661
	LOSS [training: 0.18733150898692583 | validation: 0.18172399475072343]
	TIME [epoch: 9.07 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18422144723922662		[learning rate: 0.0001503]
	Learning Rate: 0.000150296
	LOSS [training: 0.18422144723922662 | validation: 0.1912981553951194]
	TIME [epoch: 9.05 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18243551337040298		[learning rate: 0.00014993]
	Learning Rate: 0.000149932
	LOSS [training: 0.18243551337040298 | validation: 0.19334871305037937]
	TIME [epoch: 9.06 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18810245958954988		[learning rate: 0.00014957]
	Learning Rate: 0.000149569
	LOSS [training: 0.18810245958954988 | validation: 0.18823285234164477]
	TIME [epoch: 9.08 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18124978633146854		[learning rate: 0.00014921]
	Learning Rate: 0.000149207
	LOSS [training: 0.18124978633146854 | validation: 0.1831415940062374]
	TIME [epoch: 9.06 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19094777804801957		[learning rate: 0.00014885]
	Learning Rate: 0.000148846
	LOSS [training: 0.19094777804801957 | validation: 0.18784228849428108]
	TIME [epoch: 9.06 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18345856392069243		[learning rate: 0.00014849]
	Learning Rate: 0.000148486
	LOSS [training: 0.18345856392069243 | validation: 0.1815192312902854]
	TIME [epoch: 9.06 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18431654617915205		[learning rate: 0.00014813]
	Learning Rate: 0.000148126
	LOSS [training: 0.18431654617915205 | validation: 0.17912148803235117]
	TIME [epoch: 9.08 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18115464915661456		[learning rate: 0.00014777]
	Learning Rate: 0.000147768
	LOSS [training: 0.18115464915661456 | validation: 0.18942213160757956]
	TIME [epoch: 9.06 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18161430741677753		[learning rate: 0.00014741]
	Learning Rate: 0.00014741
	LOSS [training: 0.18161430741677753 | validation: 0.18756978937661842]
	TIME [epoch: 9.05 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18680489266299846		[learning rate: 0.00014705]
	Learning Rate: 0.000147053
	LOSS [training: 0.18680489266299846 | validation: 0.18698544450215798]
	TIME [epoch: 9.06 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18280545538643544		[learning rate: 0.0001467]
	Learning Rate: 0.000146697
	LOSS [training: 0.18280545538643544 | validation: 0.1878596617138616]
	TIME [epoch: 9.06 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18282533649132718		[learning rate: 0.00014634]
	Learning Rate: 0.000146342
	LOSS [training: 0.18282533649132718 | validation: 0.1925038678732809]
	TIME [epoch: 9.09 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.183235052473115		[learning rate: 0.00014599]
	Learning Rate: 0.000145988
	LOSS [training: 0.183235052473115 | validation: 0.1776658086888498]
	TIME [epoch: 9.07 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18830489701237627		[learning rate: 0.00014563]
	Learning Rate: 0.000145634
	LOSS [training: 0.18830489701237627 | validation: 0.18859674102084517]
	TIME [epoch: 9.06 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18425604688435834		[learning rate: 0.00014528]
	Learning Rate: 0.000145282
	LOSS [training: 0.18425604688435834 | validation: 0.18941839329263455]
	TIME [epoch: 9.07 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17720114698149		[learning rate: 0.00014493]
	Learning Rate: 0.00014493
	LOSS [training: 0.17720114698149 | validation: 0.18324936925050767]
	TIME [epoch: 9.07 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1826026985111407		[learning rate: 0.00014458]
	Learning Rate: 0.000144579
	LOSS [training: 0.1826026985111407 | validation: 0.19034915506944133]
	TIME [epoch: 9.06 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1888431365322027		[learning rate: 0.00014423]
	Learning Rate: 0.000144229
	LOSS [training: 0.1888431365322027 | validation: 0.19263962604728868]
	TIME [epoch: 9.05 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18444212386130243		[learning rate: 0.00014388]
	Learning Rate: 0.00014388
	LOSS [training: 0.18444212386130243 | validation: 0.1903522801419809]
	TIME [epoch: 9.07 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18242121443427206		[learning rate: 0.00014353]
	Learning Rate: 0.000143532
	LOSS [training: 0.18242121443427206 | validation: 0.186440126516847]
	TIME [epoch: 9.07 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1853940001549225		[learning rate: 0.00014318]
	Learning Rate: 0.000143184
	LOSS [training: 0.1853940001549225 | validation: 0.16856758052599097]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r5_20240219_183142/states/model_tr_study4_1852.pth
	Model improved!!!
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1861568706765437		[learning rate: 0.00014284]
	Learning Rate: 0.000142837
	LOSS [training: 0.1861568706765437 | validation: 0.17693614915963557]
	TIME [epoch: 9.08 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18319447186627813		[learning rate: 0.00014249]
	Learning Rate: 0.000142492
	LOSS [training: 0.18319447186627813 | validation: 0.17703537276079467]
	TIME [epoch: 9.07 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1801315075905119		[learning rate: 0.00014215]
	Learning Rate: 0.000142147
	LOSS [training: 0.1801315075905119 | validation: 0.1851071012259588]
	TIME [epoch: 9.09 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18326206481070767		[learning rate: 0.0001418]
	Learning Rate: 0.000141803
	LOSS [training: 0.18326206481070767 | validation: 0.17061690051547712]
	TIME [epoch: 9.1 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18258318621916506		[learning rate: 0.00014146]
	Learning Rate: 0.000141459
	LOSS [training: 0.18258318621916506 | validation: 0.18582261335125871]
	TIME [epoch: 9.1 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18661345495968398		[learning rate: 0.00014112]
	Learning Rate: 0.000141117
	LOSS [training: 0.18661345495968398 | validation: 0.18659472046067194]
	TIME [epoch: 9.08 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1864656090009222		[learning rate: 0.00014078]
	Learning Rate: 0.000140775
	LOSS [training: 0.1864656090009222 | validation: 0.18004926673991603]
	TIME [epoch: 9.08 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18829373311416395		[learning rate: 0.00014043]
	Learning Rate: 0.000140434
	LOSS [training: 0.18829373311416395 | validation: 0.17416558218251132]
	TIME [epoch: 9.08 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18358484433822092		[learning rate: 0.00014009]
	Learning Rate: 0.000140094
	LOSS [training: 0.18358484433822092 | validation: 0.19444633604379574]
	TIME [epoch: 9.1 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1787028817321487		[learning rate: 0.00013976]
	Learning Rate: 0.000139755
	LOSS [training: 0.1787028817321487 | validation: 0.1758928404469328]
	TIME [epoch: 9.08 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18241269269451288		[learning rate: 0.00013942]
	Learning Rate: 0.000139417
	LOSS [training: 0.18241269269451288 | validation: 0.1819432355364769]
	TIME [epoch: 9.08 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1876710192831096		[learning rate: 0.00013908]
	Learning Rate: 0.00013908
	LOSS [training: 0.1876710192831096 | validation: 0.17838376295461628]
	TIME [epoch: 9.08 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1832027990725753		[learning rate: 0.00013874]
	Learning Rate: 0.000138743
	LOSS [training: 0.1832027990725753 | validation: 0.18241244323932715]
	TIME [epoch: 9.07 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18743996747461458		[learning rate: 0.00013841]
	Learning Rate: 0.000138407
	LOSS [training: 0.18743996747461458 | validation: 0.1845033824230006]
	TIME [epoch: 9.1 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18546303747039158		[learning rate: 0.00013807]
	Learning Rate: 0.000138072
	LOSS [training: 0.18546303747039158 | validation: 0.19552908016821444]
	TIME [epoch: 9.07 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1830776825860458		[learning rate: 0.00013774]
	Learning Rate: 0.000137738
	LOSS [training: 0.1830776825860458 | validation: 0.19273164297994735]
	TIME [epoch: 9.08 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1834911699691914		[learning rate: 0.0001374]
	Learning Rate: 0.000137404
	LOSS [training: 0.1834911699691914 | validation: 0.1910807988128383]
	TIME [epoch: 9.09 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1799927595358584		[learning rate: 0.00013707]
	Learning Rate: 0.000137072
	LOSS [training: 0.1799927595358584 | validation: 0.18671426011260508]
	TIME [epoch: 9.11 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1841359162773067		[learning rate: 0.00013674]
	Learning Rate: 0.00013674
	LOSS [training: 0.1841359162773067 | validation: 0.1875568199349133]
	TIME [epoch: 9.09 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18662658089510473		[learning rate: 0.00013641]
	Learning Rate: 0.000136409
	LOSS [training: 0.18662658089510473 | validation: 0.19471841678820306]
	TIME [epoch: 9.08 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18622322043072112		[learning rate: 0.00013608]
	Learning Rate: 0.000136078
	LOSS [training: 0.18622322043072112 | validation: 0.18157974178428904]
	TIME [epoch: 9.08 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1857549196277793		[learning rate: 0.00013575]
	Learning Rate: 0.000135749
	LOSS [training: 0.1857549196277793 | validation: 0.19193711026714289]
	TIME [epoch: 9.09 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19206897740365636		[learning rate: 0.00013542]
	Learning Rate: 0.00013542
	LOSS [training: 0.19206897740365636 | validation: 0.1801940537834527]
	TIME [epoch: 9.1 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18911104299047732		[learning rate: 0.00013509]
	Learning Rate: 0.000135093
	LOSS [training: 0.18911104299047732 | validation: 0.19226058776452598]
	TIME [epoch: 9.08 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18678938696876876		[learning rate: 0.00013477]
	Learning Rate: 0.000134766
	LOSS [training: 0.18678938696876876 | validation: 0.19313936659209002]
	TIME [epoch: 9.08 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18546122785815994		[learning rate: 0.00013444]
	Learning Rate: 0.000134439
	LOSS [training: 0.18546122785815994 | validation: 0.2001978896825375]
	TIME [epoch: 9.08 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18760291037301385		[learning rate: 0.00013411]
	Learning Rate: 0.000134114
	LOSS [training: 0.18760291037301385 | validation: 0.18380901718402243]
	TIME [epoch: 9.09 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1825653568886201		[learning rate: 0.00013379]
	Learning Rate: 0.000133789
	LOSS [training: 0.1825653568886201 | validation: 0.17958091729836312]
	TIME [epoch: 9.08 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18531274198033829		[learning rate: 0.00013347]
	Learning Rate: 0.000133465
	LOSS [training: 0.18531274198033829 | validation: 0.18776285232986534]
	TIME [epoch: 9.08 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18068497695725022		[learning rate: 0.00013314]
	Learning Rate: 0.000133142
	LOSS [training: 0.18068497695725022 | validation: 0.17888891372788268]
	TIME [epoch: 9.08 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1880685342222494		[learning rate: 0.00013282]
	Learning Rate: 0.00013282
	LOSS [training: 0.1880685342222494 | validation: 0.1832068128151776]
	TIME [epoch: 9.09 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18829940558449848		[learning rate: 0.0001325]
	Learning Rate: 0.000132498
	LOSS [training: 0.18829940558449848 | validation: 0.18530591367271598]
	TIME [epoch: 9.1 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18349746829354335		[learning rate: 0.00013218]
	Learning Rate: 0.000132178
	LOSS [training: 0.18349746829354335 | validation: 0.20255485369672493]
	TIME [epoch: 9.09 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1916253671549932		[learning rate: 0.00013186]
	Learning Rate: 0.000131858
	LOSS [training: 0.1916253671549932 | validation: 0.18838929647512925]
	TIME [epoch: 9.08 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18913073103438488		[learning rate: 0.00013154]
	Learning Rate: 0.000131538
	LOSS [training: 0.18913073103438488 | validation: 0.19060363488397242]
	TIME [epoch: 9.08 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18571562466785324		[learning rate: 0.00013122]
	Learning Rate: 0.00013122
	LOSS [training: 0.18571562466785324 | validation: 0.1901224571300243]
	TIME [epoch: 9.1 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18573155750005377		[learning rate: 0.0001309]
	Learning Rate: 0.000130902
	LOSS [training: 0.18573155750005377 | validation: 0.19127178175664233]
	TIME [epoch: 9.09 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18813391034671062		[learning rate: 0.00013059]
	Learning Rate: 0.000130585
	LOSS [training: 0.18813391034671062 | validation: 0.17336466616271712]
	TIME [epoch: 9.08 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18141725224113012		[learning rate: 0.00013027]
	Learning Rate: 0.000130269
	LOSS [training: 0.18141725224113012 | validation: 0.19472862261829071]
	TIME [epoch: 9.08 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18954026905354188		[learning rate: 0.00012995]
	Learning Rate: 0.000129954
	LOSS [training: 0.18954026905354188 | validation: 0.2069344036680757]
	TIME [epoch: 9.08 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18561120431810438		[learning rate: 0.00012964]
	Learning Rate: 0.000129639
	LOSS [training: 0.18561120431810438 | validation: 0.19157434647118568]
	TIME [epoch: 9.1 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18500012430530138		[learning rate: 0.00012933]
	Learning Rate: 0.000129326
	LOSS [training: 0.18500012430530138 | validation: 0.19610911890315658]
	TIME [epoch: 9.08 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18998249904920098		[learning rate: 0.00012901]
	Learning Rate: 0.000129012
	LOSS [training: 0.18998249904920098 | validation: 0.19223047012809208]
	TIME [epoch: 9.08 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18623478230026083		[learning rate: 0.0001287]
	Learning Rate: 0.0001287
	LOSS [training: 0.18623478230026083 | validation: 0.20191060790514284]
	TIME [epoch: 9.08 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18512693122143742		[learning rate: 0.00012839]
	Learning Rate: 0.000128389
	LOSS [training: 0.18512693122143742 | validation: 0.19456217633515893]
	TIME [epoch: 9.09 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18801573221241802		[learning rate: 0.00012808]
	Learning Rate: 0.000128078
	LOSS [training: 0.18801573221241802 | validation: 0.1903931349066308]
	TIME [epoch: 9.09 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18972093531428685		[learning rate: 0.00012777]
	Learning Rate: 0.000127768
	LOSS [training: 0.18972093531428685 | validation: 0.2098618001505124]
	TIME [epoch: 9.08 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19637165952998234		[learning rate: 0.00012746]
	Learning Rate: 0.000127458
	LOSS [training: 0.19637165952998234 | validation: 0.2018904841620453]
	TIME [epoch: 9.07 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19390134684270816		[learning rate: 0.00012715]
	Learning Rate: 0.00012715
	LOSS [training: 0.19390134684270816 | validation: 0.19636828720708782]
	TIME [epoch: 9.08 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1959000202494977		[learning rate: 0.00012684]
	Learning Rate: 0.000126842
	LOSS [training: 0.1959000202494977 | validation: 0.20672600924137696]
	TIME [epoch: 9.1 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1921178542219664		[learning rate: 0.00012653]
	Learning Rate: 0.000126535
	LOSS [training: 0.1921178542219664 | validation: 0.20642597935487939]
	TIME [epoch: 9.09 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18920766760519825		[learning rate: 0.00012623]
	Learning Rate: 0.000126229
	LOSS [training: 0.18920766760519825 | validation: 0.20541022122978914]
	TIME [epoch: 9.08 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18664411386885316		[learning rate: 0.00012592]
	Learning Rate: 0.000125923
	LOSS [training: 0.18664411386885316 | validation: 0.19843901370566647]
	TIME [epoch: 9.08 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19012545934944577		[learning rate: 0.00012562]
	Learning Rate: 0.000125618
	LOSS [training: 0.19012545934944577 | validation: 0.19620382753964566]
	TIME [epoch: 9.08 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19527679737267634		[learning rate: 0.00012531]
	Learning Rate: 0.000125314
	LOSS [training: 0.19527679737267634 | validation: 0.2008585668612503]
	TIME [epoch: 9.11 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1904318822607488		[learning rate: 0.00012501]
	Learning Rate: 0.000125011
	LOSS [training: 0.1904318822607488 | validation: 0.19022942149060887]
	TIME [epoch: 9.08 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18177624254678756		[learning rate: 0.00012471]
	Learning Rate: 0.000124708
	LOSS [training: 0.18177624254678756 | validation: 0.18901009801577556]
	TIME [epoch: 9.08 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17870225939185105		[learning rate: 0.00012441]
	Learning Rate: 0.000124406
	LOSS [training: 0.17870225939185105 | validation: 0.1889785132868974]
	TIME [epoch: 9.09 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18895894008303488		[learning rate: 0.00012411]
	Learning Rate: 0.000124105
	LOSS [training: 0.18895894008303488 | validation: 0.19147463507946072]
	TIME [epoch: 9.09 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18644767798673462		[learning rate: 0.0001238]
	Learning Rate: 0.000123805
	LOSS [training: 0.18644767798673462 | validation: 0.19459154530086747]
	TIME [epoch: 9.09 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1812635144580655		[learning rate: 0.0001235]
	Learning Rate: 0.000123505
	LOSS [training: 0.1812635144580655 | validation: 0.19906523460991238]
	TIME [epoch: 9.08 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18680883369112206		[learning rate: 0.00012321]
	Learning Rate: 0.000123206
	LOSS [training: 0.18680883369112206 | validation: 0.18954327929698478]
	TIME [epoch: 9.08 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.185876697338161		[learning rate: 0.00012291]
	Learning Rate: 0.000122908
	LOSS [training: 0.185876697338161 | validation: 0.19337134068125786]
	TIME [epoch: 9.08 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1880924929575472		[learning rate: 0.00012261]
	Learning Rate: 0.00012261
	LOSS [training: 0.1880924929575472 | validation: 0.2095941947637982]
	TIME [epoch: 9.09 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18907154421295774		[learning rate: 0.00012231]
	Learning Rate: 0.000122313
	LOSS [training: 0.18907154421295774 | validation: 0.18024827015267647]
	TIME [epoch: 9.08 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19755786286139698		[learning rate: 0.00012202]
	Learning Rate: 0.000122017
	LOSS [training: 0.19755786286139698 | validation: 0.19619061869600024]
	TIME [epoch: 9.08 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18638985536711225		[learning rate: 0.00012172]
	Learning Rate: 0.000121722
	LOSS [training: 0.18638985536711225 | validation: 0.18814487145939846]
	TIME [epoch: 9.07 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18967429340268563		[learning rate: 0.00012143]
	Learning Rate: 0.000121427
	LOSS [training: 0.18967429340268563 | validation: 0.1906476494954632]
	TIME [epoch: 9.09 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1862846268698819		[learning rate: 0.00012113]
	Learning Rate: 0.000121133
	LOSS [training: 0.1862846268698819 | validation: 0.18577271162661912]
	TIME [epoch: 9.09 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1835784900284782		[learning rate: 0.00012084]
	Learning Rate: 0.00012084
	LOSS [training: 0.1835784900284782 | validation: 0.18438773338524642]
	TIME [epoch: 9.09 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1806533090952811		[learning rate: 0.00012055]
	Learning Rate: 0.000120547
	LOSS [training: 0.1806533090952811 | validation: 0.1888281007421379]
	TIME [epoch: 9.08 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1894709993838293		[learning rate: 0.00012026]
	Learning Rate: 0.000120256
	LOSS [training: 0.1894709993838293 | validation: 0.1734800848455746]
	TIME [epoch: 9.08 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.186883808840338		[learning rate: 0.00011996]
	Learning Rate: 0.000119964
	LOSS [training: 0.186883808840338 | validation: 0.19292997131395206]
	TIME [epoch: 9.1 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18700868406982085		[learning rate: 0.00011967]
	Learning Rate: 0.000119674
	LOSS [training: 0.18700868406982085 | validation: 0.19419554630859276]
	TIME [epoch: 9.07 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1861456504424282		[learning rate: 0.00011938]
	Learning Rate: 0.000119384
	LOSS [training: 0.1861456504424282 | validation: 0.1867318486617745]
	TIME [epoch: 9.08 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18489637189098423		[learning rate: 0.0001191]
	Learning Rate: 0.000119095
	LOSS [training: 0.18489637189098423 | validation: 0.19194750196568222]
	TIME [epoch: 9.07 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18517620831384896		[learning rate: 0.00011881]
	Learning Rate: 0.000118807
	LOSS [training: 0.18517620831384896 | validation: 0.19325209203354982]
	TIME [epoch: 9.09 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17779504967352136		[learning rate: 0.00011852]
	Learning Rate: 0.000118519
	LOSS [training: 0.17779504967352136 | validation: 0.17425714500767553]
	TIME [epoch: 9.09 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18616946598659256		[learning rate: 0.00011823]
	Learning Rate: 0.000118232
	LOSS [training: 0.18616946598659256 | validation: 0.18332066005092468]
	TIME [epoch: 9.08 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1866156673348552		[learning rate: 0.00011795]
	Learning Rate: 0.000117946
	LOSS [training: 0.1866156673348552 | validation: 0.18267928159153407]
	TIME [epoch: 9.08 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1816118171350198		[learning rate: 0.00011766]
	Learning Rate: 0.000117661
	LOSS [training: 0.1816118171350198 | validation: 0.18123090569257755]
	TIME [epoch: 9.07 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18444511344917106		[learning rate: 0.00011738]
	Learning Rate: 0.000117376
	LOSS [training: 0.18444511344917106 | validation: 0.18624307658802108]
	TIME [epoch: 9.1 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17710211512140137		[learning rate: 0.00011709]
	Learning Rate: 0.000117092
	LOSS [training: 0.17710211512140137 | validation: 0.17373042514222814]
	TIME [epoch: 9.08 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18061641436810216		[learning rate: 0.00011681]
	Learning Rate: 0.000116808
	LOSS [training: 0.18061641436810216 | validation: 0.19265287941401943]
	TIME [epoch: 9.08 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1840674703408321		[learning rate: 0.00011653]
	Learning Rate: 0.000116526
	LOSS [training: 0.1840674703408321 | validation: 0.17812194685612132]
	TIME [epoch: 9.08 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18484359797361818		[learning rate: 0.00011624]
	Learning Rate: 0.000116243
	LOSS [training: 0.18484359797361818 | validation: 0.18628943199922765]
	TIME [epoch: 9.08 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18413820121738012		[learning rate: 0.00011596]
	Learning Rate: 0.000115962
	LOSS [training: 0.18413820121738012 | validation: 0.17451583666033116]
	TIME [epoch: 9.09 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17873598670999016		[learning rate: 0.00011568]
	Learning Rate: 0.000115681
	LOSS [training: 0.17873598670999016 | validation: 0.1888058004967963]
	TIME [epoch: 9.08 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1836895971716687		[learning rate: 0.0001154]
	Learning Rate: 0.000115401
	LOSS [training: 0.1836895971716687 | validation: 0.18360728257988937]
	TIME [epoch: 9.07 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18229986710973545		[learning rate: 0.00011512]
	Learning Rate: 0.000115122
	LOSS [training: 0.18229986710973545 | validation: 0.18947457706223875]
	TIME [epoch: 9.08 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17904594682027897		[learning rate: 0.00011484]
	Learning Rate: 0.000114843
	LOSS [training: 0.17904594682027897 | validation: 0.17373529008744595]
	TIME [epoch: 9.1 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17929228259967495		[learning rate: 0.00011457]
	Learning Rate: 0.000114565
	LOSS [training: 0.17929228259967495 | validation: 0.18428036433501616]
	TIME [epoch: 9.07 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18136260195565193		[learning rate: 0.00011429]
	Learning Rate: 0.000114288
	LOSS [training: 0.18136260195565193 | validation: 0.1814568435437636]
	TIME [epoch: 9.07 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1861465498576868		[learning rate: 0.00011401]
	Learning Rate: 0.000114011
	LOSS [training: 0.1861465498576868 | validation: 0.18532295248229874]
	TIME [epoch: 9.07 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17905532640442517		[learning rate: 0.00011374]
	Learning Rate: 0.000113735
	LOSS [training: 0.17905532640442517 | validation: 0.1802770062652636]
	TIME [epoch: 9.07 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18314017683486677		[learning rate: 0.00011346]
	Learning Rate: 0.00011346
	LOSS [training: 0.18314017683486677 | validation: 0.1890555443776213]
	TIME [epoch: 9.09 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18255277350612703		[learning rate: 0.00011319]
	Learning Rate: 0.000113185
	LOSS [training: 0.18255277350612703 | validation: 0.1841356961507678]
	TIME [epoch: 9.08 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18094886489638093		[learning rate: 0.00011291]
	Learning Rate: 0.000112911
	LOSS [training: 0.18094886489638093 | validation: 0.18671762518471846]
	TIME [epoch: 9.08 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18409086656161508		[learning rate: 0.00011264]
	Learning Rate: 0.000112638
	LOSS [training: 0.18409086656161508 | validation: 0.17905676234100393]
	TIME [epoch: 9.07 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18436934159112847		[learning rate: 0.00011237]
	Learning Rate: 0.000112365
	LOSS [training: 0.18436934159112847 | validation: 0.19275841898886956]
	TIME [epoch: 9.1 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17806895152739863		[learning rate: 0.00011209]
	Learning Rate: 0.000112093
	LOSS [training: 0.17806895152739863 | validation: 0.17980412452389516]
	TIME [epoch: 9.08 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17696268151106115		[learning rate: 0.00011182]
	Learning Rate: 0.000111822
	LOSS [training: 0.17696268151106115 | validation: 0.18407986974791996]
	TIME [epoch: 9.07 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17938912923639894		[learning rate: 0.00011155]
	Learning Rate: 0.000111551
	LOSS [training: 0.17938912923639894 | validation: 0.17539362266341402]
	TIME [epoch: 9.07 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18356863914108162		[learning rate: 0.00011128]
	Learning Rate: 0.000111281
	LOSS [training: 0.18356863914108162 | validation: 0.18590291740221035]
	TIME [epoch: 9.07 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18399022151878366		[learning rate: 0.00011101]
	Learning Rate: 0.000111012
	LOSS [training: 0.18399022151878366 | validation: 0.16884731332231329]
	TIME [epoch: 9.1 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17834086828305123		[learning rate: 0.00011074]
	Learning Rate: 0.000110743
	LOSS [training: 0.17834086828305123 | validation: 0.17845010902198027]
	TIME [epoch: 9.08 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17976055272610522		[learning rate: 0.00011047]
	Learning Rate: 0.000110475
	LOSS [training: 0.17976055272610522 | validation: 0.17407286746301348]
	TIME [epoch: 9.08 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17939733379764125		[learning rate: 0.00011021]
	Learning Rate: 0.000110207
	LOSS [training: 0.17939733379764125 | validation: 0.18557320013216952]
	TIME [epoch: 9.09 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18313536630489485		[learning rate: 0.00010994]
	Learning Rate: 0.000109941
	LOSS [training: 0.18313536630489485 | validation: 0.1800116213341178]
	TIME [epoch: 9.09 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18002673544434653		[learning rate: 0.00010967]
	Learning Rate: 0.000109674
	LOSS [training: 0.18002673544434653 | validation: 0.17660111615808954]
	TIME [epoch: 9.09 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1806632772407996		[learning rate: 0.00010941]
	Learning Rate: 0.000109409
	LOSS [training: 0.1806632772407996 | validation: 0.18459856208072684]
	TIME [epoch: 9.08 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18143360658411012		[learning rate: 0.00010914]
	Learning Rate: 0.000109144
	LOSS [training: 0.18143360658411012 | validation: 0.179185666267464]
	TIME [epoch: 9.08 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1851908279415116		[learning rate: 0.00010888]
	Learning Rate: 0.00010888
	LOSS [training: 0.1851908279415116 | validation: 0.1816853954780236]
	TIME [epoch: 9.07 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18248173012283037		[learning rate: 0.00010862]
	Learning Rate: 0.000108616
	LOSS [training: 0.18248173012283037 | validation: 0.17674755762031197]
	TIME [epoch: 9.1 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18532353924677084		[learning rate: 0.00010835]
	Learning Rate: 0.000108353
	LOSS [training: 0.18532353924677084 | validation: 0.17916331322123397]
	TIME [epoch: 9.08 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18542805636077697		[learning rate: 0.00010809]
	Learning Rate: 0.000108091
	LOSS [training: 0.18542805636077697 | validation: 0.17711957289719754]
	TIME [epoch: 9.07 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17825384065743521		[learning rate: 0.00010783]
	Learning Rate: 0.000107829
	LOSS [training: 0.17825384065743521 | validation: 0.16917559307174518]
	TIME [epoch: 9.06 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1830979775880749		[learning rate: 0.00010757]
	Learning Rate: 0.000107568
	LOSS [training: 0.1830979775880749 | validation: 0.18610861691729635]
	TIME [epoch: 9.06 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.184990339708051		[learning rate: 0.00010731]
	Learning Rate: 0.000107308
	LOSS [training: 0.184990339708051 | validation: 0.18409193096253795]
	TIME [epoch: 9.09 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1921173223303595		[learning rate: 0.00010705]
	Learning Rate: 0.000107048
	LOSS [training: 0.1921173223303595 | validation: 0.18187374363506148]
	TIME [epoch: 9.06 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18382559776865628		[learning rate: 0.00010679]
	Learning Rate: 0.000106789
	LOSS [training: 0.18382559776865628 | validation: 0.18390313217940207]
	TIME [epoch: 9.08 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1835658358466456		[learning rate: 0.00010653]
	Learning Rate: 0.00010653
	LOSS [training: 0.1835658358466456 | validation: 0.18128780007686235]
	TIME [epoch: 9.08 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17851372779960467		[learning rate: 0.00010627]
	Learning Rate: 0.000106273
	LOSS [training: 0.17851372779960467 | validation: 0.1746223300174054]
	TIME [epoch: 9.09 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18179931196028648		[learning rate: 0.00010602]
	Learning Rate: 0.000106015
	LOSS [training: 0.18179931196028648 | validation: 0.17708674314261208]
	TIME [epoch: 9.08 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18240358212219382		[learning rate: 0.00010576]
	Learning Rate: 0.000105759
	LOSS [training: 0.18240358212219382 | validation: 0.17047152138983118]
	TIME [epoch: 9.06 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18009447400133527		[learning rate: 0.0001055]
	Learning Rate: 0.000105503
	LOSS [training: 0.18009447400133527 | validation: 0.18087690044443522]
	TIME [epoch: 9.07 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1855793332211995		[learning rate: 0.00010525]
	Learning Rate: 0.000105247
	LOSS [training: 0.1855793332211995 | validation: 0.17090831071610327]
	TIME [epoch: 9.06 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18021780651478023		[learning rate: 0.00010499]
	Learning Rate: 0.000104992
	LOSS [training: 0.18021780651478023 | validation: 0.17923345665574145]
	TIME [epoch: 9.09 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18001543705842482		[learning rate: 0.00010474]
	Learning Rate: 0.000104738
	LOSS [training: 0.18001543705842482 | validation: 0.17647942622348528]
	TIME [epoch: 9.08 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17784276325479959		[learning rate: 0.00010448]
	Learning Rate: 0.000104485
	LOSS [training: 0.17784276325479959 | validation: 0.17615483026839768]
	TIME [epoch: 9.07 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18713077663628214		[learning rate: 0.00010423]
	Learning Rate: 0.000104232
	LOSS [training: 0.18713077663628214 | validation: 0.17961754583411293]
	TIME [epoch: 9.07 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1835697533370614		[learning rate: 0.00010398]
	Learning Rate: 0.000103979
	LOSS [training: 0.1835697533370614 | validation: 0.1774803493332175]
	TIME [epoch: 9.08 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18131432308005163		[learning rate: 0.00010373]
	Learning Rate: 0.000103728
	LOSS [training: 0.18131432308005163 | validation: 0.1829160044833307]
	TIME [epoch: 9.07 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1797623072210623		[learning rate: 0.00010348]
	Learning Rate: 0.000103477
	LOSS [training: 0.1797623072210623 | validation: 0.1840008188572772]
	TIME [epoch: 9.07 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17847521843468853		[learning rate: 0.00010323]
	Learning Rate: 0.000103226
	LOSS [training: 0.17847521843468853 | validation: 0.1844326055619101]
	TIME [epoch: 9.08 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1787699610858069		[learning rate: 0.00010298]
	Learning Rate: 0.000102976
	LOSS [training: 0.1787699610858069 | validation: 0.18890758978847277]
	TIME [epoch: 9.08 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17677348660190412		[learning rate: 0.00010273]
	Learning Rate: 0.000102727
	LOSS [training: 0.17677348660190412 | validation: 0.18446225962372548]
	TIME [epoch: 9.1 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17998709765727527		[learning rate: 0.00010248]
	Learning Rate: 0.000102478
	LOSS [training: 0.17998709765727527 | validation: 0.19081893480935164]
	TIME [epoch: 9.07 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18362162575741534		[learning rate: 0.00010223]
	Learning Rate: 0.00010223
	LOSS [training: 0.18362162575741534 | validation: 0.1865861810680699]
	TIME [epoch: 9.07 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18367503771461452		[learning rate: 0.00010198]
	Learning Rate: 0.000101983
	LOSS [training: 0.18367503771461452 | validation: 0.18479339602219885]
	TIME [epoch: 9.06 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18068085341980605		[learning rate: 0.00010174]
	Learning Rate: 0.000101736
	LOSS [training: 0.18068085341980605 | validation: 0.18134747292447342]
	TIME [epoch: 9.07 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18419951486967615		[learning rate: 0.00010149]
	Learning Rate: 0.000101489
	LOSS [training: 0.18419951486967615 | validation: 0.18377523438661958]
	TIME [epoch: 9.09 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18030026633650692		[learning rate: 0.00010124]
	Learning Rate: 0.000101244
	LOSS [training: 0.18030026633650692 | validation: 0.17766396426039663]
	TIME [epoch: 9.06 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17734431599606337		[learning rate: 0.000101]
	Learning Rate: 0.000100999
	LOSS [training: 0.17734431599606337 | validation: 0.18128143448192846]
	TIME [epoch: 9.07 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18574213017346808		[learning rate: 0.00010075]
	Learning Rate: 0.000100754
	LOSS [training: 0.18574213017346808 | validation: 0.17671929126730995]
	TIME [epoch: 9.06 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18401257866346188		[learning rate: 0.00010051]
	Learning Rate: 0.00010051
	LOSS [training: 0.18401257866346188 | validation: 0.18543990684460715]
	TIME [epoch: 9.08 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18534897278155457		[learning rate: 0.00010027]
	Learning Rate: 0.000100267
	LOSS [training: 0.18534897278155457 | validation: 0.19490675332848614]
	TIME [epoch: 9.07 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18780653836466846		[learning rate: 0.00010002]
	Learning Rate: 0.000100024
	LOSS [training: 0.18780653836466846 | validation: 0.19271195649361933]
	TIME [epoch: 9.07 sec]
Finished training in 18258.321 seconds.
