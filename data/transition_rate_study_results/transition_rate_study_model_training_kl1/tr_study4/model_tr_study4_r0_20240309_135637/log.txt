Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r0', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3582695466

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.6429094099603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6429094099603 | validation: 5.142169194351604]
	TIME [epoch: 87.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.067701194958409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.067701194958409 | validation: 4.708746297985565]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.925192022624977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.925192022624977 | validation: 4.351602631433196]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.254032748566434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.254032748566434 | validation: 3.8611893435544893]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.990704755529992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.990704755529992 | validation: 3.927905039408139]
	TIME [epoch: 12.9 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.804005320105751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.804005320105751 | validation: 3.9726808001943277]
	TIME [epoch: 12.9 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6466140347990152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6466140347990152 | validation: 3.716590231005265]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4991770131356073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4991770131356073 | validation: 3.8048814895893632]
	TIME [epoch: 12.9 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4830484738431764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4830484738431764 | validation: 3.4132139286888843]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.253425164651018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.253425164651018 | validation: 3.723464996626639]
	TIME [epoch: 12.9 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.573307502465537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.573307502465537 | validation: 3.272727526238414]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1983048539491845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1983048539491845 | validation: 3.2532999981156308]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1047055917444526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1047055917444526 | validation: 3.298705345474427]
	TIME [epoch: 12.9 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3317528432160466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3317528432160466 | validation: 3.0344509915256923]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.980579176329503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.980579176329503 | validation: 2.89072210431435]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.88679595873316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.88679595873316 | validation: 3.157004259052555]
	TIME [epoch: 12.9 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.496064331420315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.496064331420315 | validation: 3.0098283297420103]
	TIME [epoch: 12.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6779491197740684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6779491197740684 | validation: 2.7248887730706417]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6837477599262742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6837477599262742 | validation: 3.110598812062473]
	TIME [epoch: 12.9 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.651327356537796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.651327356537796 | validation: 3.2411488258318633]
	TIME [epoch: 12.9 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7645236155982933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7645236155982933 | validation: 5.073588753622541]
	TIME [epoch: 12.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5125286160275184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5125286160275184 | validation: 3.169135818592143]
	TIME [epoch: 12.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7477967006973403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7477967006973403 | validation: 2.7809917225245613]
	TIME [epoch: 12.9 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4273126754272054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4273126754272054 | validation: 2.2932774038525223]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.249153637522043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.249153637522043 | validation: 2.2620175839110317]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.095746655242162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.095746655242162 | validation: 2.052886651276397]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.170904763418871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.170904763418871 | validation: 2.537473777756165]
	TIME [epoch: 12.9 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.154984116198142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.154984116198142 | validation: 2.520443338116478]
	TIME [epoch: 12.9 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.006537564555607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.006537564555607 | validation: 1.8113421083740173]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8399893330684038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8399893330684038 | validation: 1.9627210103508679]
	TIME [epoch: 12.9 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.649271223020547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.649271223020547 | validation: 1.509274762225325]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3801241335253418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3801241335253418 | validation: 2.5376361146123965]
	TIME [epoch: 12.9 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5675653025714038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5675653025714038 | validation: 1.3178434917594783]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3643956652034972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3643956652034972 | validation: 1.122312945836205]
	TIME [epoch: 12.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1758709223405905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1758709223405905 | validation: 1.3290442001935545]
	TIME [epoch: 12.9 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4059389056436014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4059389056436014 | validation: 1.0052126427163146]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1969229749422512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1969229749422512 | validation: 1.2239106910980717]
	TIME [epoch: 12.9 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9959563852519056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9959563852519056 | validation: 1.0802448944462293]
	TIME [epoch: 12.9 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.074613221018812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.074613221018812 | validation: 0.8541041301611211]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9771887126225868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9771887126225868 | validation: 0.8600214959586444]
	TIME [epoch: 12.9 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9571419006388311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9571419006388311 | validation: 0.8939503513066757]
	TIME [epoch: 12.9 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9507655096093417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9507655096093417 | validation: 0.9158913607711137]
	TIME [epoch: 12.9 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8916746855792074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8916746855792074 | validation: 0.9704649103210804]
	TIME [epoch: 12.9 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7881794950556964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7881794950556964 | validation: 0.9094748103935376]
	TIME [epoch: 12.9 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7626466391804005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7626466391804005 | validation: 1.4611061497169715]
	TIME [epoch: 12.9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3080785916593531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3080785916593531 | validation: 1.0063456410915577]
	TIME [epoch: 12.9 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8164237060203929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8164237060203929 | validation: 0.7546110659859465]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6578497569105948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6578497569105948 | validation: 0.7892222228036962]
	TIME [epoch: 12.9 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.961416698764713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.961416698764713 | validation: 1.3817532498444205]
	TIME [epoch: 12.9 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0359100529146263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0359100529146263 | validation: 0.6533953425100373]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7724067159159199		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.7724067159159199 | validation: 0.8130802969243799]
	TIME [epoch: 12.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7385588033545222		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.7385588033545222 | validation: 0.6994319533326445]
	TIME [epoch: 12.9 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7437172904354284		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.7437172904354284 | validation: 0.6000447622339484]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9933965217558535		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.9933965217558535 | validation: 0.8505414240390888]
	TIME [epoch: 12.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8895028166299569		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.8895028166299569 | validation: 0.8335896923631811]
	TIME [epoch: 12.9 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6200935618518253		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.6200935618518253 | validation: 1.454504922561193]
	TIME [epoch: 12.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.108118533985479		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.108118533985479 | validation: 1.176264772208823]
	TIME [epoch: 12.9 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213600020265056		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.7213600020265056 | validation: 0.951952683666377]
	TIME [epoch: 12.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.591121051155726		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.591121051155726 | validation: 1.1009540284723338]
	TIME [epoch: 12.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0739912493023172		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.0739912493023172 | validation: 0.7085447490557103]
	TIME [epoch: 12.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.079029043444681		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.079029043444681 | validation: 0.8608506349880364]
	TIME [epoch: 12.9 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9640070718358714		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.9640070718358714 | validation: 0.6927482677970922]
	TIME [epoch: 12.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6594981129334794		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.6594981129334794 | validation: 0.5989936055789109]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8012585252022941		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.8012585252022941 | validation: 1.1399013301106289]
	TIME [epoch: 12.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7561458668463448		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.7561458668463448 | validation: 1.9451231529164779]
	TIME [epoch: 12.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.025726670527979		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.025726670527979 | validation: 1.0442531553645356]
	TIME [epoch: 12.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021101980231835		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.021101980231835 | validation: 1.139651631760307]
	TIME [epoch: 12.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8105287504915788		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.8105287504915788 | validation: 0.7948662428120394]
	TIME [epoch: 12.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7002871593376121		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.7002871593376121 | validation: 0.5820241883961513]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6617698871425759		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.6617698871425759 | validation: 0.7789593079541625]
	TIME [epoch: 12.9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6227435880304235		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.6227435880304235 | validation: 0.7214209275820993]
	TIME [epoch: 12.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0459584297751459		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.0459584297751459 | validation: 0.8187719362223911]
	TIME [epoch: 12.9 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8432528230584617		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.8432528230584617 | validation: 0.6757985050562269]
	TIME [epoch: 12.9 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6748814309508788		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.6748814309508788 | validation: 0.5790245498326835]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5381698019526783		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.5381698019526783 | validation: 0.5915063135650721]
	TIME [epoch: 12.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6738790104818019		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.6738790104818019 | validation: 0.5013867115444883]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.529403165552592		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.529403165552592 | validation: 0.6112544485949973]
	TIME [epoch: 12.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5257665254248556		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.5257665254248556 | validation: 0.6017502801622416]
	TIME [epoch: 13 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4577198761109895		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.4577198761109895 | validation: 3.4309266730232917]
	TIME [epoch: 12.9 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8567393060036705		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.8567393060036705 | validation: 3.3812579598960837]
	TIME [epoch: 12.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2165650093114957		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.2165650093114957 | validation: 0.6460963222526951]
	TIME [epoch: 12.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5632359443474316		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.5632359443474316 | validation: 0.5494015107796264]
	TIME [epoch: 12.9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5383807162467659		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.5383807162467659 | validation: 0.8834231301774914]
	TIME [epoch: 12.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6477099414903503		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.6477099414903503 | validation: 1.3119382601841205]
	TIME [epoch: 12.9 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8238702465610142		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.8238702465610142 | validation: 0.7533974494731109]
	TIME [epoch: 12.9 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1733733473368275		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.1733733473368275 | validation: 0.5235050574135464]
	TIME [epoch: 12.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48704253896433003		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.48704253896433003 | validation: 0.40612971392656483]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5928994806871227		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.5928994806871227 | validation: 0.842511623147897]
	TIME [epoch: 12.9 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6027884434125023		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.6027884434125023 | validation: 0.46827036046243276]
	TIME [epoch: 12.9 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4234810457932321		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.4234810457932321 | validation: 0.459318817615195]
	TIME [epoch: 12.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47657436728120556		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.47657436728120556 | validation: 0.6285202951711287]
	TIME [epoch: 12.9 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.518119335294359		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.518119335294359 | validation: 0.5369222463674251]
	TIME [epoch: 12.9 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5117143585536932		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.5117143585536932 | validation: 0.5073797954260573]
	TIME [epoch: 12.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.667903264713254		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.667903264713254 | validation: 0.6356093767790388]
	TIME [epoch: 12.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5757256344864655		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.5757256344864655 | validation: 0.5167522875265569]
	TIME [epoch: 12.9 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45099226774104456		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.45099226774104456 | validation: 0.5541512056745915]
	TIME [epoch: 12.9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6887808193714869		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.6887808193714869 | validation: 0.41893642575811135]
	TIME [epoch: 12.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43779543105267815		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.43779543105267815 | validation: 0.42814056694361635]
	TIME [epoch: 12.9 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47960662477893307		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.47960662477893307 | validation: 0.37503701768875347]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47602627020135213		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.47602627020135213 | validation: 0.5621609450672572]
	TIME [epoch: 12.9 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9317907701460497		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.9317907701460497 | validation: 0.6473197968425248]
	TIME [epoch: 12.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4700930048486411		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.4700930048486411 | validation: 0.4609779866154831]
	TIME [epoch: 12.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35734212321198555		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.35734212321198555 | validation: 0.36562590467768685]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37099460284551083		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.37099460284551083 | validation: 0.5059228959281553]
	TIME [epoch: 12.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49313130667743477		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.49313130667743477 | validation: 0.45644213087086327]
	TIME [epoch: 12.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6899521424375289		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.6899521424375289 | validation: 0.41067772715987333]
	TIME [epoch: 12.9 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3992557177692888		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.3992557177692888 | validation: 0.47093744829356754]
	TIME [epoch: 12.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42123612957462386		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.42123612957462386 | validation: 0.40931891796884357]
	TIME [epoch: 12.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4359828985732049		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.4359828985732049 | validation: 0.4267147670680642]
	TIME [epoch: 12.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.437866282161532		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.437866282161532 | validation: 0.3920681806758644]
	TIME [epoch: 12.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41571217249136677		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.41571217249136677 | validation: 0.46226820410015296]
	TIME [epoch: 12.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4151379860239322		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.4151379860239322 | validation: 0.37597459515832826]
	TIME [epoch: 12.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39801004639485327		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.39801004639485327 | validation: 0.4842923766254644]
	TIME [epoch: 12.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35343755455396914		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.35343755455396914 | validation: 0.48878816388639623]
	TIME [epoch: 12.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41677773652531513		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.41677773652531513 | validation: 0.3182651329879574]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3236174055319325		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.3236174055319325 | validation: 3.7490346983090106]
	TIME [epoch: 12.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8976198224636955		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.8976198224636955 | validation: 3.6761314466443027]
	TIME [epoch: 12.9 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.109895065675455		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.109895065675455 | validation: 1.017596504725855]
	TIME [epoch: 12.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7530772947053368		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.7530772947053368 | validation: 0.6809582067523544]
	TIME [epoch: 12.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46127486263759976		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.46127486263759976 | validation: 0.45116059060488395]
	TIME [epoch: 12.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40091506069808647		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.40091506069808647 | validation: 0.41808107022321783]
	TIME [epoch: 12.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3433708005652871		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.3433708005652871 | validation: 0.3122021044044432]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4856448928333448		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.4856448928333448 | validation: 0.8655839783487567]
	TIME [epoch: 12.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4940727811236668		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.4940727811236668 | validation: 0.3413517263039076]
	TIME [epoch: 12.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3791803494961468		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3791803494961468 | validation: 0.5357064388319762]
	TIME [epoch: 12.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.388494171195936		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.388494171195936 | validation: 0.32594913131689185]
	TIME [epoch: 12.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7949649820799061		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.7949649820799061 | validation: 0.3859036512576045]
	TIME [epoch: 12.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45600763454859705		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.45600763454859705 | validation: 0.4022114048795667]
	TIME [epoch: 12.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38959499356659755		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.38959499356659755 | validation: 0.35101957802912653]
	TIME [epoch: 12.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1969617665106078		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.1969617665106078 | validation: 0.685625328421652]
	TIME [epoch: 12.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6464110403019951		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.6464110403019951 | validation: 0.4973855440142247]
	TIME [epoch: 12.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5166509722064091		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.5166509722064091 | validation: 1.8033313069589532]
	TIME [epoch: 12.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7974785790964045		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.7974785790964045 | validation: 0.6917320815309705]
	TIME [epoch: 12.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5378553570716884		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.5378553570716884 | validation: 0.38046336310550355]
	TIME [epoch: 12.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33223161308402643		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.33223161308402643 | validation: 0.2850519974630551]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451892573740369		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.5451892573740369 | validation: 0.2994485680857647]
	TIME [epoch: 12.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40701819748456625		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.40701819748456625 | validation: 0.4661477048606446]
	TIME [epoch: 12.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3677868193176594		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.3677868193176594 | validation: 0.4647023782509506]
	TIME [epoch: 12.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44743841358370573		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.44743841358370573 | validation: 0.4613282455512733]
	TIME [epoch: 12.9 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4010023279426417		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.4010023279426417 | validation: 0.30581158321755525]
	TIME [epoch: 12.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35758249440423195		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.35758249440423195 | validation: 0.31683733074191833]
	TIME [epoch: 12.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788874932450637		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.2788874932450637 | validation: 0.31448036730833495]
	TIME [epoch: 12.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28700912886355473		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.28700912886355473 | validation: 1.0699000805585075]
	TIME [epoch: 12.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6093147717910591		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.6093147717910591 | validation: 0.290366580126122]
	TIME [epoch: 12.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25940739834084137		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.25940739834084137 | validation: 0.2515724687442518]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39428868065304234		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.39428868065304234 | validation: 0.31544065015972156]
	TIME [epoch: 12.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36015800978913104		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.36015800978913104 | validation: 0.5610040806466975]
	TIME [epoch: 12.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4973101789668406		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.4973101789668406 | validation: 0.46709235607378363]
	TIME [epoch: 12.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44143090034420934		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.44143090034420934 | validation: 1.2301771387344522]
	TIME [epoch: 12.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.732372068826266		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.732372068826266 | validation: 0.6826127801448212]
	TIME [epoch: 12.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893399066309618		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.6893399066309618 | validation: 0.5644557131397763]
	TIME [epoch: 12.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38495149962408554		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.38495149962408554 | validation: 0.3185173113015926]
	TIME [epoch: 12.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4296457349469205		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.4296457349469205 | validation: 0.3766513304099031]
	TIME [epoch: 12.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7961063379553055		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.7961063379553055 | validation: 1.2878922364533687]
	TIME [epoch: 12.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220349620818549		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.7220349620818549 | validation: 0.3526692064924233]
	TIME [epoch: 12.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3374081345032099		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.3374081345032099 | validation: 0.3339925712314294]
	TIME [epoch: 12.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26668465645295664		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.26668465645295664 | validation: 0.31070390994192487]
	TIME [epoch: 12.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2597236494948354		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.2597236494948354 | validation: 0.27295415655525873]
	TIME [epoch: 12.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24366703847631266		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.24366703847631266 | validation: 0.3820118235269014]
	TIME [epoch: 12.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3150272862920039		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.3150272862920039 | validation: 0.28094795525404626]
	TIME [epoch: 12.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346236834123074		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.5346236834123074 | validation: 0.6326735549267766]
	TIME [epoch: 12.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5253401799835149		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.5253401799835149 | validation: 0.4030339597892923]
	TIME [epoch: 12.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30732473785725534		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.30732473785725534 | validation: 0.3900102178718718]
	TIME [epoch: 12.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2826292933125402		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.2826292933125402 | validation: 0.28431921535063526]
	TIME [epoch: 12.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3513131954129275		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.3513131954129275 | validation: 0.5652703260752353]
	TIME [epoch: 12.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2983392786638178		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.2983392786638178 | validation: 0.2910402379202598]
	TIME [epoch: 12.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2855744524985409		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.2855744524985409 | validation: 0.2345187413800389]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4818495915456906		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.4818495915456906 | validation: 0.2496427477813607]
	TIME [epoch: 12.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3178803852972804		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.3178803852972804 | validation: 0.3088496552074018]
	TIME [epoch: 12.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26371870633298883		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.26371870633298883 | validation: 0.2698012325818971]
	TIME [epoch: 12.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2557802300417856		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.2557802300417856 | validation: 0.2454760592251865]
	TIME [epoch: 13 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2909421344520442		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.2909421344520442 | validation: 0.2934352845109423]
	TIME [epoch: 12.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32898063943483513		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.32898063943483513 | validation: 0.3513789399009522]
	TIME [epoch: 12.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27161264846863264		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.27161264846863264 | validation: 0.33577883659544117]
	TIME [epoch: 13 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27380040868770406		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.27380040868770406 | validation: 0.2299130488045617]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20060431390441874		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.20060431390441874 | validation: 0.25007845550513774]
	TIME [epoch: 12.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32806512363532947		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.32806512363532947 | validation: 0.25946926228265615]
	TIME [epoch: 12.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3320485809271507		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.3320485809271507 | validation: 0.3468217408043185]
	TIME [epoch: 13 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.270415324082913		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.270415324082913 | validation: 0.3291870538378332]
	TIME [epoch: 12.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2916985244363005		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.2916985244363005 | validation: 0.32574150140082353]
	TIME [epoch: 13 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3742605533015023		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.3742605533015023 | validation: 0.43450911643549844]
	TIME [epoch: 12.9 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30996877142422685		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.30996877142422685 | validation: 0.2602018446462588]
	TIME [epoch: 12.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4044119069764896		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.4044119069764896 | validation: 0.3175054344618335]
	TIME [epoch: 12.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5878158348309819		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.5878158348309819 | validation: 0.7877580916112544]
	TIME [epoch: 12.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4293190631229954		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.4293190631229954 | validation: 0.2365305802568265]
	TIME [epoch: 12.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.247982616921129		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.247982616921129 | validation: 0.27429679794442885]
	TIME [epoch: 12.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24152548118932762		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.24152548118932762 | validation: 0.2720025494785887]
	TIME [epoch: 12.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29547107092832103		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.29547107092832103 | validation: 0.3150180172243826]
	TIME [epoch: 12.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22532748818247017		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.22532748818247017 | validation: 0.25650246476411875]
	TIME [epoch: 13 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4592013560454591		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.4592013560454591 | validation: 0.29590435024993667]
	TIME [epoch: 12.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3253219874726258		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.3253219874726258 | validation: 0.34991929869714483]
	TIME [epoch: 12.9 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3151412889387292		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.3151412889387292 | validation: 0.22389562771893495]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37984660803255155		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.37984660803255155 | validation: 0.2342913015613054]
	TIME [epoch: 12.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2736234461308541		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.2736234461308541 | validation: 0.21940654983814306]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27978185619179935		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.27978185619179935 | validation: 0.3343100189558989]
	TIME [epoch: 12.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24208934486371922		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.24208934486371922 | validation: 0.2910274128025018]
	TIME [epoch: 13 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2437505506961922		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.2437505506961922 | validation: 0.2708033589875868]
	TIME [epoch: 12.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23506014550511628		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.23506014550511628 | validation: 0.2733866636458442]
	TIME [epoch: 12.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785743841652168		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.2785743841652168 | validation: 0.2949167848708742]
	TIME [epoch: 12.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3656530278771609		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.3656530278771609 | validation: 0.348232349015733]
	TIME [epoch: 12.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2557810229993219		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.2557810229993219 | validation: 0.3616301285635431]
	TIME [epoch: 12.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26667342793139187		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.26667342793139187 | validation: 0.2541464601305491]
	TIME [epoch: 12.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2676737446584655		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.2676737446584655 | validation: 0.3123816597137371]
	TIME [epoch: 13 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22847827642848662		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.22847827642848662 | validation: 0.2809325985649291]
	TIME [epoch: 13 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20478975150852313		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.20478975150852313 | validation: 0.2590701917815467]
	TIME [epoch: 13 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24396520208382133		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.24396520208382133 | validation: 1.2164889786511535]
	TIME [epoch: 12.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46997323343467723		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.46997323343467723 | validation: 0.40136656311521424]
	TIME [epoch: 12.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33396763108314653		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.33396763108314653 | validation: 0.2511258476370306]
	TIME [epoch: 12.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2629142643369099		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.2629142643369099 | validation: 0.3430874640445111]
	TIME [epoch: 13 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2916150982201818		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.2916150982201818 | validation: 0.36443576021741086]
	TIME [epoch: 13 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2937778259182295		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.2937778259182295 | validation: 0.38308923023941305]
	TIME [epoch: 12.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2606372162531373		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.2606372162531373 | validation: 0.26323469073607714]
	TIME [epoch: 13 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25657043574724125		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.25657043574724125 | validation: 0.3894400446512911]
	TIME [epoch: 12.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2514377479622494		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.2514377479622494 | validation: 0.2293858863179276]
	TIME [epoch: 13 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2517490531276332		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.2517490531276332 | validation: 0.3096410628215857]
	TIME [epoch: 12.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3112554361177982		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.3112554361177982 | validation: 0.22362888368436382]
	TIME [epoch: 12.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2433785432393848		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.2433785432393848 | validation: 0.25296481290113243]
	TIME [epoch: 13 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24874023748515164		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.24874023748515164 | validation: 0.5327607676840882]
	TIME [epoch: 13 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43458166358516354		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.43458166358516354 | validation: 0.2097082316834261]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2531358969749331		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.2531358969749331 | validation: 0.5704354571183463]
	TIME [epoch: 12.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6086476335087012		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.6086476335087012 | validation: 1.0479857101147985]
	TIME [epoch: 12.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7263659926382521		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.7263659926382521 | validation: 0.9185485227094141]
	TIME [epoch: 12.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9561370536912058		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.9561370536912058 | validation: 0.46883159204896546]
	TIME [epoch: 12.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44801196279649785		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.44801196279649785 | validation: 0.2486264713681135]
	TIME [epoch: 12.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19233155133220955		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.19233155133220955 | validation: 0.3366765626460478]
	TIME [epoch: 13 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2849270484458748		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.2849270484458748 | validation: 1.2055982407396308]
	TIME [epoch: 12.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5093213524371736		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.5093213524371736 | validation: 0.4352820383262024]
	TIME [epoch: 12.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46634149086960336		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.46634149086960336 | validation: 1.27499398086484]
	TIME [epoch: 12.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9809970453655342		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.9809970453655342 | validation: 0.4858624700920548]
	TIME [epoch: 12.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40558804010613986		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.40558804010613986 | validation: 0.6080302779446218]
	TIME [epoch: 12.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3248202386992411		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.3248202386992411 | validation: 0.3856166880241413]
	TIME [epoch: 12.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29097824665086003		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.29097824665086003 | validation: 0.7338760563273152]
	TIME [epoch: 13 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367049866517906		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.4367049866517906 | validation: 0.24506040458773864]
	TIME [epoch: 12.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.473721619640983		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.473721619640983 | validation: 0.35146236350150245]
	TIME [epoch: 12.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23722291180589994		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.23722291180589994 | validation: 0.15810961933350118]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532130222336463		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.1532130222336463 | validation: 0.3459643877014949]
	TIME [epoch: 13 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39518911060909506		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.39518911060909506 | validation: 1.500421171125796]
	TIME [epoch: 12.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7900969525140608		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.7900969525140608 | validation: 0.35329699802631254]
	TIME [epoch: 12.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48218810981686877		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.48218810981686877 | validation: 0.4720470110272362]
	TIME [epoch: 13 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2979081388649825		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.2979081388649825 | validation: 0.26687747107224274]
	TIME [epoch: 13 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24593296398525888		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.24593296398525888 | validation: 0.17208708558985905]
	TIME [epoch: 12.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5512810946320207		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.5512810946320207 | validation: 2.3238649859833886]
	TIME [epoch: 12.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0309531496411062		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.0309531496411062 | validation: 0.9984403429465138]
	TIME [epoch: 12.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5984218892171914		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.5984218892171914 | validation: 0.42728668421547555]
	TIME [epoch: 12.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3696384241771001		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.3696384241771001 | validation: 0.36653711868358313]
	TIME [epoch: 12.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25568231042411627		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.25568231042411627 | validation: 0.22250089329052117]
	TIME [epoch: 13 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22599830307878185		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.22599830307878185 | validation: 0.20356793367567386]
	TIME [epoch: 13 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2129147082599496		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.2129147082599496 | validation: 0.17107207608311484]
	TIME [epoch: 12.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18999344758749462		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.18999344758749462 | validation: 0.270038260300314]
	TIME [epoch: 13 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2354787886671198		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.2354787886671198 | validation: 0.2388081357084236]
	TIME [epoch: 12.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21296285365980644		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.21296285365980644 | validation: 0.17727858186041373]
	TIME [epoch: 13 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2153032331236286		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.2153032331236286 | validation: 0.18929889275253167]
	TIME [epoch: 12.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491030630941917		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.3491030630941917 | validation: 1.0533382474656596]
	TIME [epoch: 13 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5029603677881479		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.5029603677881479 | validation: 0.2168790620675955]
	TIME [epoch: 13 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3038896545378738		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.3038896545378738 | validation: 0.3010320131832262]
	TIME [epoch: 12.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24165963045048086		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.24165963045048086 | validation: 0.17990605483994582]
	TIME [epoch: 13 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20715279108315238		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.20715279108315238 | validation: 0.7382867648239091]
	TIME [epoch: 13 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4647693483559514		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.4647693483559514 | validation: 2.701438565540848]
	TIME [epoch: 13 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3839503318316713		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.3839503318316713 | validation: 1.4737004034423484]
	TIME [epoch: 12.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.828577168130283		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.828577168130283 | validation: 0.3571833543644067]
	TIME [epoch: 13 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35282434521627126		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.35282434521627126 | validation: 0.36969059201651433]
	TIME [epoch: 12.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25963322967357655		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.25963322967357655 | validation: 0.35142547552796943]
	TIME [epoch: 12.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24116831157999535		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.24116831157999535 | validation: 0.3760490185916927]
	TIME [epoch: 12.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2927342606850009		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.2927342606850009 | validation: 0.21514524134072927]
	TIME [epoch: 13 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.260310620666344		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.260310620666344 | validation: 0.4268940910836586]
	TIME [epoch: 12.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26408498701591465		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.26408498701591465 | validation: 0.24264392566591272]
	TIME [epoch: 12.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2445495040703799		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.2445495040703799 | validation: 0.22074383745200388]
	TIME [epoch: 13 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2069672915285178		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.2069672915285178 | validation: 0.6533050426152599]
	TIME [epoch: 12.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3436568288253748		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.3436568288253748 | validation: 0.23087688585280325]
	TIME [epoch: 12.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2845650874445482		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.2845650874445482 | validation: 0.2562476740318229]
	TIME [epoch: 12.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21527023657170136		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.21527023657170136 | validation: 0.32419538263138487]
	TIME [epoch: 13 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21032275492910738		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.21032275492910738 | validation: 0.19592371423724508]
	TIME [epoch: 12.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19478848855580447		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.19478848855580447 | validation: 0.19034292936708416]
	TIME [epoch: 13 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19071531870232006		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.19071531870232006 | validation: 0.2960526027889279]
	TIME [epoch: 13 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38318335231339273		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.38318335231339273 | validation: 0.25172446564385814]
	TIME [epoch: 12.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2669412467487703		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.2669412467487703 | validation: 0.26333892585806157]
	TIME [epoch: 12.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.250522512862502		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.250522512862502 | validation: 0.23234487484151467]
	TIME [epoch: 12.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23365866485355488		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.23365866485355488 | validation: 0.21003132731372362]
	TIME [epoch: 13 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023071312037753		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.2023071312037753 | validation: 0.24186498602832138]
	TIME [epoch: 12.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5223309946842325		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.5223309946842325 | validation: 0.590784576497141]
	TIME [epoch: 12.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.369288620813419		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.369288620813419 | validation: 1.7185611615836593]
	TIME [epoch: 12.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6130685695446851		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.6130685695446851 | validation: 0.3521041090924028]
	TIME [epoch: 12.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2326086386642408		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.2326086386642408 | validation: 0.20047210726355275]
	TIME [epoch: 12.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16263018171271565		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.16263018171271565 | validation: 0.5633142306084293]
	TIME [epoch: 13 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26697324779439313		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.26697324779439313 | validation: 0.2864683174376324]
	TIME [epoch: 13 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545836568569516		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.2545836568569516 | validation: 0.2479796266775136]
	TIME [epoch: 12.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18480370700617857		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.18480370700617857 | validation: 0.19431685764143608]
	TIME [epoch: 12.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2564046517321984		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.2564046517321984 | validation: 0.16681069335033047]
	TIME [epoch: 12.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18738667450879962		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.18738667450879962 | validation: 0.22348048649383345]
	TIME [epoch: 13 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20930383900054716		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.20930383900054716 | validation: 0.5346919781600811]
	TIME [epoch: 12.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4466713933918572		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.4466713933918572 | validation: 0.19543840790174333]
	TIME [epoch: 12.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17186901126259832		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.17186901126259832 | validation: 0.21650361118741523]
	TIME [epoch: 13 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1868785522459237		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.1868785522459237 | validation: 0.5528182605513806]
	TIME [epoch: 12.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.353847449882862		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.353847449882862 | validation: 0.20377287447218617]
	TIME [epoch: 12.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.218416615842015		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.218416615842015 | validation: 0.7846033328936517]
	TIME [epoch: 13 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6231313563345638		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.6231313563345638 | validation: 0.5374101331345665]
	TIME [epoch: 12.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5877707945772842		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.5877707945772842 | validation: 0.2868158417766843]
	TIME [epoch: 12.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37045052496177444		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.37045052496177444 | validation: 0.6285038459770775]
	TIME [epoch: 12.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33239113174973484		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.33239113174973484 | validation: 0.14638516474592225]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16763113721330128		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.16763113721330128 | validation: 0.20202868050552297]
	TIME [epoch: 12.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16214360511898482		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.16214360511898482 | validation: 0.15943986132924853]
	TIME [epoch: 13 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14757652871807875		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.14757652871807875 | validation: 0.13634531717267476]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16016041904855413		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.16016041904855413 | validation: 0.38093306763719526]
	TIME [epoch: 13 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2681244698596061		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.2681244698596061 | validation: 0.5345742143723231]
	TIME [epoch: 13.2 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40846488174277895		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.40846488174277895 | validation: 0.37168132403814225]
	TIME [epoch: 12.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3198827999492343		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.3198827999492343 | validation: 0.3562675617180839]
	TIME [epoch: 12.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4382642019655072		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.4382642019655072 | validation: 0.1953200130150262]
	TIME [epoch: 12.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24113356677910344		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.24113356677910344 | validation: 0.23514370680670496]
	TIME [epoch: 12.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19464389418170008		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.19464389418170008 | validation: 0.19772945517523005]
	TIME [epoch: 12.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2689221905900155		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.2689221905900155 | validation: 0.3634840325744494]
	TIME [epoch: 12.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2645762052225658		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.2645762052225658 | validation: 0.6457288795333597]
	TIME [epoch: 12.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7533821913381415		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.7533821913381415 | validation: 0.4284299143157505]
	TIME [epoch: 12.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1994991050045017		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.1994991050045017 | validation: 0.15252444149825184]
	TIME [epoch: 12.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3126337672140482		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.3126337672140482 | validation: 0.1951798684232757]
	TIME [epoch: 12.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1791794209504683		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.1791794209504683 | validation: 0.3575778931325783]
	TIME [epoch: 12.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5021856524714812		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.5021856524714812 | validation: 0.3838218735806602]
	TIME [epoch: 12.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651482905702246		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.2651482905702246 | validation: 0.9202323496315313]
	TIME [epoch: 13 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817866448250813		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.6817866448250813 | validation: 0.4024162484176857]
	TIME [epoch: 12.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28022806779613124		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.28022806779613124 | validation: 0.22940242619616097]
	TIME [epoch: 12.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18180398930310201		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.18180398930310201 | validation: 0.21168284769130324]
	TIME [epoch: 13 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2541403325844575		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.2541403325844575 | validation: 0.5997812507313186]
	TIME [epoch: 13 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31249926508851483		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.31249926508851483 | validation: 0.13961290251634775]
	TIME [epoch: 13 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12809904583444887		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.12809904583444887 | validation: 0.18232261022409904]
	TIME [epoch: 12.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2250512910570942		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.2250512910570942 | validation: 0.15483540552529454]
	TIME [epoch: 13 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13141130258264105		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.13141130258264105 | validation: 0.1887035481846416]
	TIME [epoch: 13 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23656444914061917		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.23656444914061917 | validation: 0.5251368239093265]
	TIME [epoch: 13 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6191540484243453		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.6191540484243453 | validation: 0.34088738906731963]
	TIME [epoch: 12.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4039220412860949		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.4039220412860949 | validation: 0.4545345507418499]
	TIME [epoch: 13 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33325949338012856		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.33325949338012856 | validation: 0.40964662564932963]
	TIME [epoch: 12.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.872796997429331		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.872796997429331 | validation: 1.0678405903662498]
	TIME [epoch: 12.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4730567932427079		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.4730567932427079 | validation: 0.3903367040810752]
	TIME [epoch: 13 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23735303425035392		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.23735303425035392 | validation: 0.18517213307760194]
	TIME [epoch: 13 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22123865842491414		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.22123865842491414 | validation: 0.5881254964637936]
	TIME [epoch: 12.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4142289158888421		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.4142289158888421 | validation: 0.35292467907207226]
	TIME [epoch: 12.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31053686843489736		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.31053686843489736 | validation: 0.3693860207711298]
	TIME [epoch: 13 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29454374568244723		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.29454374568244723 | validation: 0.25187312398537187]
	TIME [epoch: 12.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23152196435622002		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.23152196435622002 | validation: 0.16146300039064979]
	TIME [epoch: 12.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2068604061155675		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.2068604061155675 | validation: 0.19210033791181452]
	TIME [epoch: 12.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2417141551105155		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.2417141551105155 | validation: 0.19216704439197396]
	TIME [epoch: 13 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14577301798623216		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.14577301798623216 | validation: 0.26427399975295696]
	TIME [epoch: 13 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20642272109013635		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.20642272109013635 | validation: 0.19935098355257924]
	TIME [epoch: 13 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29612964180355117		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.29612964180355117 | validation: 0.47499427910057135]
	TIME [epoch: 13 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3061225657462167		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.3061225657462167 | validation: 0.1877026770592321]
	TIME [epoch: 13 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2018655014829498		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.2018655014829498 | validation: 0.18650511546369614]
	TIME [epoch: 13 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19214571707942996		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.19214571707942996 | validation: 0.2881075690627939]
	TIME [epoch: 12.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25765484834138547		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.25765484834138547 | validation: 0.17363057319874373]
	TIME [epoch: 13 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15668194654845785		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.15668194654845785 | validation: 0.231153105642812]
	TIME [epoch: 13 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20437827523204263		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.20437827523204263 | validation: 0.22586500074346513]
	TIME [epoch: 12.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2204406676864666		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.2204406676864666 | validation: 0.16319932968172077]
	TIME [epoch: 13 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17578510641625086		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.17578510641625086 | validation: 0.302795259159311]
	TIME [epoch: 13 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28121342789927334		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.28121342789927334 | validation: 0.4218954532080481]
	TIME [epoch: 12.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2185454705506617		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.2185454705506617 | validation: 0.1855363419909887]
	TIME [epoch: 12.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17447012165501902		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.17447012165501902 | validation: 0.18444434949546634]
	TIME [epoch: 13 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2026842314706408		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.2026842314706408 | validation: 0.22464574697524903]
	TIME [epoch: 12.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1560121168140153		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.1560121168140153 | validation: 0.14996589037324193]
	TIME [epoch: 12.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1560600736885142		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.1560600736885142 | validation: 0.1777492071613129]
	TIME [epoch: 13 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13737487934369721		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.13737487934369721 | validation: 0.23329380316397327]
	TIME [epoch: 13 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1885504889797388		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.1885504889797388 | validation: 0.15297112424500417]
	TIME [epoch: 12.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13820837941600783		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.13820837941600783 | validation: 0.23950157528740357]
	TIME [epoch: 12.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16372958849181984		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.16372958849181984 | validation: 0.15466355941890056]
	TIME [epoch: 13 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20487194202279074		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.20487194202279074 | validation: 0.1980861246827301]
	TIME [epoch: 12.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2417483012721484		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.2417483012721484 | validation: 0.3624044487048586]
	TIME [epoch: 12.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2881737325418939		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.2881737325418939 | validation: 0.29662738028370306]
	TIME [epoch: 12.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20969736060444935		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.20969736060444935 | validation: 0.30429175079576526]
	TIME [epoch: 13 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2701628674361191		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.2701628674361191 | validation: 0.34429402225296346]
	TIME [epoch: 12.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22021828324065906		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.22021828324065906 | validation: 0.1475163803711768]
	TIME [epoch: 12.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2377594794930542		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.2377594794930542 | validation: 0.22653996046950084]
	TIME [epoch: 13 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18900988916313016		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.18900988916313016 | validation: 0.14744003351340365]
	TIME [epoch: 12.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12239813467269754		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.12239813467269754 | validation: 0.16132419158325853]
	TIME [epoch: 12.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520967975397917		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.1520967975397917 | validation: 0.3067844126797745]
	TIME [epoch: 12.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19468721841541858		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.19468721841541858 | validation: 0.2223682036414963]
	TIME [epoch: 13 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15425500018316465		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.15425500018316465 | validation: 0.1418321056015794]
	TIME [epoch: 12.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15183168315452397		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.15183168315452397 | validation: 0.23585312807009579]
	TIME [epoch: 12.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1647232172281809		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.1647232172281809 | validation: 0.15906369053444874]
	TIME [epoch: 13 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2909149848650118		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.2909149848650118 | validation: 0.6628243650222602]
	TIME [epoch: 12.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3018495141797183		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.3018495141797183 | validation: 0.14089002657396354]
	TIME [epoch: 12.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12833943207601362		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.12833943207601362 | validation: 0.17355010735890378]
	TIME [epoch: 12.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14020729734898651		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.14020729734898651 | validation: 0.32765505091495734]
	TIME [epoch: 13 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2283718618007223		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.2283718618007223 | validation: 0.18028812313153558]
	TIME [epoch: 12.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325090178339957		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.1325090178339957 | validation: 0.1341888378171651]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11634025471367254		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.11634025471367254 | validation: 0.10599102384728823]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11115853490004438		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.11115853490004438 | validation: 0.1125456445737886]
	TIME [epoch: 12.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1074180830547884		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.1074180830547884 | validation: 0.14122036528061305]
	TIME [epoch: 12.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12270030296946774		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.12270030296946774 | validation: 0.15353251028302592]
	TIME [epoch: 12.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19775101388270414		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.19775101388270414 | validation: 0.21046618704918288]
	TIME [epoch: 13 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1499464009445929		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.1499464009445929 | validation: 0.14190086494070064]
	TIME [epoch: 13 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14302387125370397		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.14302387125370397 | validation: 0.1459323511118982]
	TIME [epoch: 12.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1475793700982655		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.1475793700982655 | validation: 0.1128889577448105]
	TIME [epoch: 12.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11350074815119543		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.11350074815119543 | validation: 0.15754105875539204]
	TIME [epoch: 13 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13159131615499847		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.13159131615499847 | validation: 0.3502375112409293]
	TIME [epoch: 12.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3056273227812223		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.3056273227812223 | validation: 0.6287955337193796]
	TIME [epoch: 13 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3568501834311828		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.3568501834311828 | validation: 0.46359352982786034]
	TIME [epoch: 13 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46201001382789797		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.46201001382789797 | validation: 0.4907389515729008]
	TIME [epoch: 12.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29678190702471174		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.29678190702471174 | validation: 0.27958709147713273]
	TIME [epoch: 13 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20284255785699867		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.20284255785699867 | validation: 0.2151094862248162]
	TIME [epoch: 12.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16364933161779163		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.16364933161779163 | validation: 0.34922590731839737]
	TIME [epoch: 13 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2941142994989686		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.2941142994989686 | validation: 0.17973757159711454]
	TIME [epoch: 12.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16465390404544372		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.16465390404544372 | validation: 0.19457289639304443]
	TIME [epoch: 13 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20623264683590092		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.20623264683590092 | validation: 0.6151093147630357]
	TIME [epoch: 13 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7782812788983795		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.7782812788983795 | validation: 0.8590280744193808]
	TIME [epoch: 12.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41416735881257466		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.41416735881257466 | validation: 0.21894208403181487]
	TIME [epoch: 13 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16827073662370945		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.16827073662370945 | validation: 0.16602443658480018]
	TIME [epoch: 12.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726949800380161		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.1726949800380161 | validation: 0.12463174404560437]
	TIME [epoch: 13 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14634369282610524		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.14634369282610524 | validation: 0.18646296370948187]
	TIME [epoch: 12.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11291604342802045		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.11291604342802045 | validation: 0.3546910153981209]
	TIME [epoch: 12.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9355608614471449		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.9355608614471449 | validation: 2.1517656957498947]
	TIME [epoch: 13 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2798543788174543		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.2798543788174543 | validation: 0.6569831736607629]
	TIME [epoch: 12.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3837417259564842		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.3837417259564842 | validation: 0.2488918963558791]
	TIME [epoch: 12.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16662165662409661		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.16662165662409661 | validation: 0.14013090920897547]
	TIME [epoch: 13 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10710177199279777		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.10710177199279777 | validation: 0.11833766157686103]
	TIME [epoch: 13 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13635900123775202		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.13635900123775202 | validation: 0.14749054972351322]
	TIME [epoch: 13 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10430797533576742		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.10430797533576742 | validation: 0.11026700343020737]
	TIME [epoch: 12.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11568151720858783		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.11568151720858783 | validation: 0.19959675635813803]
	TIME [epoch: 12.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18324701391254572		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.18324701391254572 | validation: 0.38560321905333617]
	TIME [epoch: 12.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23263310930728337		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.23263310930728337 | validation: 0.16675827188035836]
	TIME [epoch: 12.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13134106646115004		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.13134106646115004 | validation: 0.06535916819288666]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07517237751128572		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.07517237751128572 | validation: 0.08555413675126029]
	TIME [epoch: 13 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1178855400847294		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.1178855400847294 | validation: 0.20013210480217986]
	TIME [epoch: 12.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24361532662627064		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.24361532662627064 | validation: 0.25634366747400267]
	TIME [epoch: 12.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12939372811207855		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.12939372811207855 | validation: 0.19945516289608933]
	TIME [epoch: 12.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15331403725649803		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.15331403725649803 | validation: 0.15465331985318284]
	TIME [epoch: 13 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08857349087567776		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.08857349087567776 | validation: 0.09340799119403503]
	TIME [epoch: 12.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10124592465996256		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.10124592465996256 | validation: 0.15416081485552435]
	TIME [epoch: 12.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08365793266117046		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.08365793266117046 | validation: 0.0654494284327844]
	TIME [epoch: 13 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07055221921827667		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.07055221921827667 | validation: 0.1200531675918751]
	TIME [epoch: 12.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11015847012804297		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.11015847012804297 | validation: 0.25479263540589764]
	TIME [epoch: 12.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15908213938675791		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.15908213938675791 | validation: 0.07353623904185028]
	TIME [epoch: 13 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13967729829177422		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.13967729829177422 | validation: 0.5867298619597895]
	TIME [epoch: 13 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.297636317900393		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.297636317900393 | validation: 0.28337280122050507]
	TIME [epoch: 13 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1704756306068338		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.1704756306068338 | validation: 0.2142654223361384]
	TIME [epoch: 13 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2249955582440561		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.2249955582440561 | validation: 0.35942577154308075]
	TIME [epoch: 13 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20307647855175853		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.20307647855175853 | validation: 0.26501855764368104]
	TIME [epoch: 13 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1565087719555146		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.1565087719555146 | validation: 0.11389900929407226]
	TIME [epoch: 13 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08640352342206087		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.08640352342206087 | validation: 0.10616240083932285]
	TIME [epoch: 13 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07349205916116272		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.07349205916116272 | validation: 0.055619754669764605]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07566854547957087		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.07566854547957087 | validation: 0.1044838604948944]
	TIME [epoch: 13 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1705170286371786		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.1705170286371786 | validation: 0.10059017613769985]
	TIME [epoch: 13 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08599571340635447		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.08599571340635447 | validation: 0.15487409963756574]
	TIME [epoch: 13 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1615927237398146		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.1615927237398146 | validation: 0.07247951333194567]
	TIME [epoch: 13 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11720575869964867		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.11720575869964867 | validation: 0.27397342992896645]
	TIME [epoch: 13 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11229256137879996		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.11229256137879996 | validation: 0.09046589077349187]
	TIME [epoch: 13 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07190009024556365		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.07190009024556365 | validation: 0.05135867576897685]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19647618864716154		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.19647618864716154 | validation: 0.5071597943664564]
	TIME [epoch: 13 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2522008631932663		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.2522008631932663 | validation: 0.15132935589102112]
	TIME [epoch: 13 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13180066209576702		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.13180066209576702 | validation: 0.0851426642894035]
	TIME [epoch: 13 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06403464776097274		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.06403464776097274 | validation: 0.11638571629130069]
	TIME [epoch: 13 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09148464058422999		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.09148464058422999 | validation: 0.05851074803086226]
	TIME [epoch: 12.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06448046614313037		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.06448046614313037 | validation: 0.14811615890408494]
	TIME [epoch: 13 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14467120833124958		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.14467120833124958 | validation: 0.12926550321174335]
	TIME [epoch: 13 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11195299572056484		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.11195299572056484 | validation: 0.10558650196653237]
	TIME [epoch: 12.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336105543784423		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.1336105543784423 | validation: 0.1457717686748831]
	TIME [epoch: 13 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12798615108418393		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.12798615108418393 | validation: 0.14170700603262537]
	TIME [epoch: 12.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526427514263719		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.1526427514263719 | validation: 0.28448561383909104]
	TIME [epoch: 13 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19619734391052862		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.19619734391052862 | validation: 0.22599502204111738]
	TIME [epoch: 12.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14853898484992104		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.14853898484992104 | validation: 0.15084329420717102]
	TIME [epoch: 13 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12355127688732216		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.12355127688732216 | validation: 0.09165960986155551]
	TIME [epoch: 13 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08986124469907435		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.08986124469907435 | validation: 0.08687119963192318]
	TIME [epoch: 12.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16172396250841647		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.16172396250841647 | validation: 0.3204703718794504]
	TIME [epoch: 12.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.209500801981377		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.209500801981377 | validation: 0.16423346185050552]
	TIME [epoch: 12.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08518601239272328		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.08518601239272328 | validation: 0.10995669874005304]
	TIME [epoch: 13 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1451935675152478		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.1451935675152478 | validation: 0.14095684782358922]
	TIME [epoch: 12.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11729715921727231		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.11729715921727231 | validation: 0.15532040326533575]
	TIME [epoch: 13 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14076997525928678		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.14076997525928678 | validation: 0.16856547286563164]
	TIME [epoch: 13 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11754337907237875		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.11754337907237875 | validation: 0.09475727620268608]
	TIME [epoch: 13 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07914000890934209		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.07914000890934209 | validation: 0.09191378073521167]
	TIME [epoch: 12.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09026119626872933		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.09026119626872933 | validation: 0.10100415727679846]
	TIME [epoch: 12.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1187209625764562		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.1187209625764562 | validation: 0.1522753241864761]
	TIME [epoch: 13 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14342174465346694		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.14342174465346694 | validation: 0.2015723271349586]
	TIME [epoch: 12.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1649114326808798		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.1649114326808798 | validation: 0.23115585190398286]
	TIME [epoch: 12.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1870273283746693		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.1870273283746693 | validation: 0.1132569514431717]
	TIME [epoch: 12.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10550178789155037		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.10550178789155037 | validation: 0.14669406211826613]
	TIME [epoch: 13 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11562653286567309		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.11562653286567309 | validation: 0.12730135153585462]
	TIME [epoch: 12.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1069724596084576		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.1069724596084576 | validation: 0.14231707157080017]
	TIME [epoch: 12.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09507086113850624		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.09507086113850624 | validation: 0.10202168123692966]
	TIME [epoch: 13 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10303515418956377		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.10303515418956377 | validation: 0.21162821186023353]
	TIME [epoch: 12.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13637214971266773		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.13637214971266773 | validation: 0.15188663218794335]
	TIME [epoch: 12.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14546677482016265		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.14546677482016265 | validation: 0.2056666219667421]
	TIME [epoch: 12.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18723711166232831		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.18723711166232831 | validation: 0.16409553327135498]
	TIME [epoch: 13 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346131676275088		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.1346131676275088 | validation: 0.13804152676175047]
	TIME [epoch: 12.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13911957698014144		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.13911957698014144 | validation: 0.18966560024901877]
	TIME [epoch: 12.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1694125426708231		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.1694125426708231 | validation: 0.23277376809497027]
	TIME [epoch: 13 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19537427623753947		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.19537427623753947 | validation: 0.22725021814285182]
	TIME [epoch: 12.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14353139336327703		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.14353139336327703 | validation: 0.1399665161291772]
	TIME [epoch: 12.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11665189658387456		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.11665189658387456 | validation: 0.15828783057934467]
	TIME [epoch: 12.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12844829759044218		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.12844829759044218 | validation: 0.14040917814499385]
	TIME [epoch: 13 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18521321142178374		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.18521321142178374 | validation: 0.32222965239181073]
	TIME [epoch: 13 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22764522335680132		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.22764522335680132 | validation: 0.1839392190715993]
	TIME [epoch: 12.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15625403342283317		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.15625403342283317 | validation: 0.19554512021856824]
	TIME [epoch: 13 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16309716856396578		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.16309716856396578 | validation: 0.1688843497505556]
	TIME [epoch: 13 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14439849146840514		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.14439849146840514 | validation: 0.14398420716086555]
	TIME [epoch: 12.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13293601841161387		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.13293601841161387 | validation: 0.1264134095034538]
	TIME [epoch: 13 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11534618510289026		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.11534618510289026 | validation: 0.16523431198627073]
	TIME [epoch: 13 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257657553833468		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.1257657553833468 | validation: 0.16421682408181867]
	TIME [epoch: 12.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13075929825701976		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.13075929825701976 | validation: 0.1596852573070623]
	TIME [epoch: 12.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15396612001383925		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.15396612001383925 | validation: 0.16380293857925957]
	TIME [epoch: 12.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18851514492456123		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.18851514492456123 | validation: 0.3650123432586465]
	TIME [epoch: 13 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20658624862037347		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.20658624862037347 | validation: 0.1416383107904736]
	TIME [epoch: 12.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442506105890741		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.1442506105890741 | validation: 0.169280255845814]
	TIME [epoch: 12.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17056079789498552		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.17056079789498552 | validation: 0.1741544728617218]
	TIME [epoch: 13 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18866965160753696		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.18866965160753696 | validation: 0.1654931595143467]
	TIME [epoch: 12.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16066547550002233		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.16066547550002233 | validation: 0.15589275961739754]
	TIME [epoch: 13 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16811183569170926		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.16811183569170926 | validation: 0.12877837871947262]
	TIME [epoch: 13 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14718211694302635		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.14718211694302635 | validation: 0.11925478920121191]
	TIME [epoch: 13 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10404969147781219		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.10404969147781219 | validation: 0.1253301767191742]
	TIME [epoch: 13 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09926869097016086		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.09926869097016086 | validation: 0.11767756327042793]
	TIME [epoch: 12.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526193767020766		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.1526193767020766 | validation: 0.16269694832673956]
	TIME [epoch: 13 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11793630658880122		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.11793630658880122 | validation: 0.1161133747524292]
	TIME [epoch: 12.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11176314338696197		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.11176314338696197 | validation: 0.13033746373681385]
	TIME [epoch: 13 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13675126444828456		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.13675126444828456 | validation: 0.15756521671708407]
	TIME [epoch: 13 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12877036333175598		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.12877036333175598 | validation: 0.13701292428599143]
	TIME [epoch: 13 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13565454985798833		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.13565454985798833 | validation: 0.14072305609591482]
	TIME [epoch: 12.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11278202055680582		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.11278202055680582 | validation: 0.13017006678240914]
	TIME [epoch: 13 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13743756402459328		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.13743756402459328 | validation: 0.15419229416422386]
	TIME [epoch: 13 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12443864270262421		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.12443864270262421 | validation: 0.1574345151954476]
	TIME [epoch: 12.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13829146722110486		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.13829146722110486 | validation: 0.1622814033271601]
	TIME [epoch: 13 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15351246914748215		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.15351246914748215 | validation: 0.22224210884120574]
	TIME [epoch: 13 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29480454349710594		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.29480454349710594 | validation: 0.16874401871530795]
	TIME [epoch: 13 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15110701216405692		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.15110701216405692 | validation: 0.1728893968901496]
	TIME [epoch: 13 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23082978801840554		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.23082978801840554 | validation: 0.3072852881734848]
	TIME [epoch: 13 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2120000449207724		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.2120000449207724 | validation: 0.1871250678482816]
	TIME [epoch: 13 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17927801918009897		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.17927801918009897 | validation: 0.1723791334783417]
	TIME [epoch: 13 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15627207362940754		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.15627207362940754 | validation: 0.15319149610002072]
	TIME [epoch: 13 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13172656296183632		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.13172656296183632 | validation: 0.21019192741187057]
	TIME [epoch: 13 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14939187899949702		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.14939187899949702 | validation: 0.14072775065349216]
	TIME [epoch: 13 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12606784781917982		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.12606784781917982 | validation: 0.17679386102305106]
	TIME [epoch: 13 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15671122615162641		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.15671122615162641 | validation: 0.15597740862218415]
	TIME [epoch: 12.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14011650860083252		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.14011650860083252 | validation: 0.15050050103255316]
	TIME [epoch: 13 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20783468027313912		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.20783468027313912 | validation: 0.25146816407347905]
	TIME [epoch: 13 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1565483136184662		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.1565483136184662 | validation: 0.19200419148033235]
	TIME [epoch: 13 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14214570201247545		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.14214570201247545 | validation: 0.14678513077033267]
	TIME [epoch: 12.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11450306675406507		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.11450306675406507 | validation: 0.14800065339203877]
	TIME [epoch: 13 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12072678388309076		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.12072678388309076 | validation: 0.13855271156982624]
	TIME [epoch: 13 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332003871293166		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.1332003871293166 | validation: 0.1137886704536966]
	TIME [epoch: 13 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11726864735002993		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.11726864735002993 | validation: 0.1530504739984597]
	TIME [epoch: 13 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1443854429387532		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.1443854429387532 | validation: 0.1705390127358095]
	TIME [epoch: 13 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334779096391308		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.1334779096391308 | validation: 0.1653408718417844]
	TIME [epoch: 13 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13015493143684317		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.13015493143684317 | validation: 0.18717722039840579]
	TIME [epoch: 13 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13245518066689393		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.13245518066689393 | validation: 0.12604339903018769]
	TIME [epoch: 13 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12376468116042799		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.12376468116042799 | validation: 0.14610828763156777]
	TIME [epoch: 13 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10954040778063003		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.10954040778063003 | validation: 0.09855140564182861]
	TIME [epoch: 13 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09910858584675099		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.09910858584675099 | validation: 0.1206862172938478]
	TIME [epoch: 12.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813600443298855		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.0813600443298855 | validation: 0.09571955126950796]
	TIME [epoch: 13 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.089814770636701		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.089814770636701 | validation: 0.11464845045602008]
	TIME [epoch: 12.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11872897079897926		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.11872897079897926 | validation: 0.1444360442924133]
	TIME [epoch: 13 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17101598990182232		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.17101598990182232 | validation: 0.1545089063207884]
	TIME [epoch: 12.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1079255538126288		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.1079255538126288 | validation: 0.10261322735796716]
	TIME [epoch: 13 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10750461142705832		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.10750461142705832 | validation: 0.14157338405793854]
	TIME [epoch: 13 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12268941942230137		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.12268941942230137 | validation: 0.13236175576270276]
	TIME [epoch: 13 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10774886464433847		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.10774886464433847 | validation: 0.12950238501317127]
	TIME [epoch: 13 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10919307051367542		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.10919307051367542 | validation: 0.16567910005638062]
	TIME [epoch: 13 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15133943991191645		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.15133943991191645 | validation: 0.11748746281714403]
	TIME [epoch: 13 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10737930389779336		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.10737930389779336 | validation: 0.12952998248636882]
	TIME [epoch: 12.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10940591844164152		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.10940591844164152 | validation: 0.12748682010394036]
	TIME [epoch: 13 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12065865041632429		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.12065865041632429 | validation: 0.15167084557587665]
	TIME [epoch: 12.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670007933669402		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1670007933669402 | validation: 0.20816526727867135]
	TIME [epoch: 12.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1450710202766372		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.1450710202766372 | validation: 0.16245354243315213]
	TIME [epoch: 13 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13401269584879327		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.13401269584879327 | validation: 0.16951259579033845]
	TIME [epoch: 12.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20151814530939094		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.20151814530939094 | validation: 0.21109912143588688]
	TIME [epoch: 12.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.165417890428701		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.165417890428701 | validation: 0.14640614052744452]
	TIME [epoch: 12.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12477818923677109		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.12477818923677109 | validation: 0.1924511905658312]
	TIME [epoch: 13 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1616793748011078		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.1616793748011078 | validation: 0.16585879752744134]
	TIME [epoch: 12.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12775411162987108		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.12775411162987108 | validation: 0.20513648871742973]
	TIME [epoch: 13 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1700267625865259		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.1700267625865259 | validation: 0.14868421195357534]
	TIME [epoch: 13 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12734458589568018		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.12734458589568018 | validation: 0.19162214218530346]
	TIME [epoch: 12.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13999675325481387		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.13999675325481387 | validation: 0.17068011450617002]
	TIME [epoch: 13 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1469143480839616		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.1469143480839616 | validation: 0.1467494899010971]
	TIME [epoch: 13 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13002544118942974		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.13002544118942974 | validation: 0.21109118312001227]
	TIME [epoch: 13 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2737217773150093		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.2737217773150093 | validation: 0.36764244793988476]
	TIME [epoch: 13 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26289247746612465		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.26289247746612465 | validation: 0.18863334152270114]
	TIME [epoch: 12.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1469505602187211		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.1469505602187211 | validation: 0.15896831360427158]
	TIME [epoch: 13 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13522775947088894		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.13522775947088894 | validation: 0.20563544131762282]
	TIME [epoch: 13 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22421090968822568		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.22421090968822568 | validation: 0.15170190392334656]
	TIME [epoch: 12.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19703792042654183		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.19703792042654183 | validation: 0.19935009398113487]
	TIME [epoch: 13 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15529328781454763		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.15529328781454763 | validation: 0.18262170533137362]
	TIME [epoch: 13 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.150144598645031		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.150144598645031 | validation: 0.18893583012460408]
	TIME [epoch: 13 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1457040527480274		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.1457040527480274 | validation: 0.17658593076849105]
	TIME [epoch: 13 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15429998194318592		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.15429998194318592 | validation: 0.1380577007742477]
	TIME [epoch: 13 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13443447062627076		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.13443447062627076 | validation: 0.1363465479713025]
	TIME [epoch: 13 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12863595424894667		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.12863595424894667 | validation: 0.1454567884402968]
	TIME [epoch: 12.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12412425450853759		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.12412425450853759 | validation: 0.12749366251817468]
	TIME [epoch: 13 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11226171169292927		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.11226171169292927 | validation: 0.15079265188396776]
	TIME [epoch: 13 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13241630503412108		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.13241630503412108 | validation: 0.22454197759196817]
	TIME [epoch: 13 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2317985755345765		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.2317985755345765 | validation: 0.41863316708590637]
	TIME [epoch: 12.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3100729523687939		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.3100729523687939 | validation: 0.13919266175861483]
	TIME [epoch: 12.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11670508500746096		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.11670508500746096 | validation: 0.14790686737375647]
	TIME [epoch: 13 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12178054095096372		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.12178054095096372 | validation: 0.1283681957842696]
	TIME [epoch: 12.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1065017524522557		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.1065017524522557 | validation: 0.12249115164813716]
	TIME [epoch: 12.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09121901279945929		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.09121901279945929 | validation: 0.0770214021637993]
	TIME [epoch: 12.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07988078431724274		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.07988078431724274 | validation: 0.12196227234629974]
	TIME [epoch: 13 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11129798388466394		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.11129798388466394 | validation: 0.11642953317160971]
	TIME [epoch: 12.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08775973304427226		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.08775973304427226 | validation: 0.10861878199722823]
	TIME [epoch: 12.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08423609902015541		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.08423609902015541 | validation: 0.09444318872450001]
	TIME [epoch: 12.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08695727131973503		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.08695727131973503 | validation: 0.12854476868997491]
	TIME [epoch: 12.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09851321012562803		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.09851321012562803 | validation: 0.14256204894466806]
	TIME [epoch: 12.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296085192788127		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.1296085192788127 | validation: 0.1595678376206631]
	TIME [epoch: 12.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10235390142435552		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.10235390142435552 | validation: 0.1330707370648871]
	TIME [epoch: 13 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09952625740416174		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.09952625740416174 | validation: 0.09206170873174467]
	TIME [epoch: 12.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07163360951711265		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.07163360951711265 | validation: 0.12099209266054448]
	TIME [epoch: 12.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0941382818154066		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.0941382818154066 | validation: 0.2930866627558214]
	TIME [epoch: 13 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2966273890540673		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2966273890540673 | validation: 0.28627251725654124]
	TIME [epoch: 12.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16636956717415097		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.16636956717415097 | validation: 0.1791266988856645]
	TIME [epoch: 12.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13483289701177337		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.13483289701177337 | validation: 0.19943541667751644]
	TIME [epoch: 12.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281701481876211		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.1281701481876211 | validation: 0.12812615996728563]
	TIME [epoch: 13 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15947130827959236		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.15947130827959236 | validation: 0.16658330607995114]
	TIME [epoch: 12.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12499581677909635		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.12499581677909635 | validation: 0.11029958985329075]
	TIME [epoch: 13 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09148948283238492		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.09148948283238492 | validation: 0.09730149889969672]
	TIME [epoch: 13 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0884868475242312		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.0884868475242312 | validation: 0.1520270179262632]
	TIME [epoch: 12.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08660519842458343		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.08660519842458343 | validation: 0.05023048778301934]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_608.pth
	Model improved!!!
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05941460171017729		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.05941460171017729 | validation: 0.06984555101953338]
	TIME [epoch: 13 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062032362147399475		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.062032362147399475 | validation: 0.07733573919400125]
	TIME [epoch: 13 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06414750756338577		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.06414750756338577 | validation: 0.08214530210532212]
	TIME [epoch: 12.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05308553390043043		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.05308553390043043 | validation: 0.12292086209833084]
	TIME [epoch: 13 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12190416147986169		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.12190416147986169 | validation: 0.12582736113589818]
	TIME [epoch: 13 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09328150374050603		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.09328150374050603 | validation: 0.08767521979268844]
	TIME [epoch: 13 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07513643590911007		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.07513643590911007 | validation: 0.07714320123210054]
	TIME [epoch: 12.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05898325496806404		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.05898325496806404 | validation: 0.08085913701189294]
	TIME [epoch: 13 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06757547272754678		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.06757547272754678 | validation: 0.082383396385323]
	TIME [epoch: 13 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06522459490473491		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.06522459490473491 | validation: 0.08553894249851585]
	TIME [epoch: 13 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08076603219281799		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.08076603219281799 | validation: 0.09610219434369376]
	TIME [epoch: 12.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08744760758508993		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.08744760758508993 | validation: 0.11971542649088605]
	TIME [epoch: 13 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08642984827091854		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.08642984827091854 | validation: 0.0957743787072275]
	TIME [epoch: 12.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07670093995080535		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.07670093995080535 | validation: 0.09701936499680619]
	TIME [epoch: 13 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1311220861254262		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.1311220861254262 | validation: 0.11396172199214899]
	TIME [epoch: 12.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10998854740363756		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.10998854740363756 | validation: 0.14844674426632937]
	TIME [epoch: 13 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12310252076429261		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.12310252076429261 | validation: 0.17440095722597085]
	TIME [epoch: 12.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.137511478229501		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.137511478229501 | validation: 0.24334965036542813]
	TIME [epoch: 13 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18755939367500846		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.18755939367500846 | validation: 0.205388769348178]
	TIME [epoch: 13 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1246235815248794		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.1246235815248794 | validation: 0.13589131096843451]
	TIME [epoch: 13 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11287287821290096		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.11287287821290096 | validation: 0.15567071831912702]
	TIME [epoch: 12.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11240043937198227		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.11240043937198227 | validation: 0.09718773904547956]
	TIME [epoch: 12.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09623114357026519		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.09623114357026519 | validation: 0.12388355127112839]
	TIME [epoch: 12.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11890066797577062		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.11890066797577062 | validation: 0.15905946603648996]
	TIME [epoch: 12.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11561993300228005		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.11561993300228005 | validation: 0.1176075973707212]
	TIME [epoch: 12.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0938469056636105		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.0938469056636105 | validation: 0.11467051858198236]
	TIME [epoch: 12.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.094803750611013		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.094803750611013 | validation: 0.09276357389492265]
	TIME [epoch: 13 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08277696888279747		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.08277696888279747 | validation: 0.11362366272421022]
	TIME [epoch: 12.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09888328521244352		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.09888328521244352 | validation: 0.11762797486349752]
	TIME [epoch: 13 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09921266757891495		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.09921266757891495 | validation: 0.10887987007174173]
	TIME [epoch: 13 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09240344407506354		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.09240344407506354 | validation: 0.1205484163144014]
	TIME [epoch: 13 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10569585843160476		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.10569585843160476 | validation: 0.14088991884993118]
	TIME [epoch: 13 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11257527693234677		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.11257527693234677 | validation: 0.12014562795045607]
	TIME [epoch: 13 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11944381050378901		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.11944381050378901 | validation: 0.13695067224864896]
	TIME [epoch: 13 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10037366366136106		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.10037366366136106 | validation: 0.09355846076964604]
	TIME [epoch: 12.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08900716692258365		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.08900716692258365 | validation: 0.11513635876959966]
	TIME [epoch: 12.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09676406873589896		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.09676406873589896 | validation: 0.1001962396934577]
	TIME [epoch: 13 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09640022855142841		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.09640022855142841 | validation: 0.12042785816576382]
	TIME [epoch: 13 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09739270947565626		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.09739270947565626 | validation: 0.09857541578582041]
	TIME [epoch: 12.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0884652618475381		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.0884652618475381 | validation: 0.09117657615821394]
	TIME [epoch: 12.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07935813984900467		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.07935813984900467 | validation: 0.09041201099247026]
	TIME [epoch: 13 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06555410473207213		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.06555410473207213 | validation: 0.06278963890792046]
	TIME [epoch: 12.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062188093752149745		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.062188093752149745 | validation: 0.06453464539377275]
	TIME [epoch: 12.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0845379566850995		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.0845379566850995 | validation: 0.1413156996478343]
	TIME [epoch: 13 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09774695235520656		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.09774695235520656 | validation: 0.09469896054964835]
	TIME [epoch: 13 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07005419075445846		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.07005419075445846 | validation: 0.08397465098168076]
	TIME [epoch: 12.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062442963905202986		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.062442963905202986 | validation: 0.07120034307918965]
	TIME [epoch: 13 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06844907541608614		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.06844907541608614 | validation: 0.07636218013099785]
	TIME [epoch: 13 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08005235351688975		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.08005235351688975 | validation: 0.11389369690639038]
	TIME [epoch: 13 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08404915489247197		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.08404915489247197 | validation: 0.10548336732931678]
	TIME [epoch: 12.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07643488252339424		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.07643488252339424 | validation: 0.10346124908858367]
	TIME [epoch: 13 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0823866303776899		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.0823866303776899 | validation: 0.085557245795417]
	TIME [epoch: 13 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06332984147769752		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.06332984147769752 | validation: 0.07534975948995186]
	TIME [epoch: 13 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07146915382648102		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.07146915382648102 | validation: 0.05664196403198608]
	TIME [epoch: 12.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04733564459537484		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.04733564459537484 | validation: 0.06411170326832301]
	TIME [epoch: 13 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05842438290624335		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.05842438290624335 | validation: 0.08507514211872037]
	TIME [epoch: 12.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05811895188918249		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.05811895188918249 | validation: 0.05312123051675943]
	TIME [epoch: 13 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05754445358846991		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.05754445358846991 | validation: 0.05649198440333786]
	TIME [epoch: 12.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05375248444951691		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.05375248444951691 | validation: 0.06759974450449913]
	TIME [epoch: 13 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07811207226234779		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.07811207226234779 | validation: 0.1036787998519921]
	TIME [epoch: 13 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08346701012275178		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.08346701012275178 | validation: 0.0980300574565461]
	TIME [epoch: 13 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09878114180542306		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.09878114180542306 | validation: 0.09699754938057076]
	TIME [epoch: 13 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776950557183555		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.0776950557183555 | validation: 0.08616450486760358]
	TIME [epoch: 13 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07100994009434848		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.07100994009434848 | validation: 0.08065818697654606]
	TIME [epoch: 13 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06702091067183559		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.06702091067183559 | validation: 0.07931176387509185]
	TIME [epoch: 13 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06351381200581366		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.06351381200581366 | validation: 0.11402213303603817]
	TIME [epoch: 13 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1063390998626007		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.1063390998626007 | validation: 0.10576819938814776]
	TIME [epoch: 13 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07915919664994235		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.07915919664994235 | validation: 0.1029827585488409]
	TIME [epoch: 13 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08489415526675076		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.08489415526675076 | validation: 0.11372730131509365]
	TIME [epoch: 13 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09513217666060018		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.09513217666060018 | validation: 0.10415215407870264]
	TIME [epoch: 13 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09766759888026119		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.09766759888026119 | validation: 0.1407071680015355]
	TIME [epoch: 13 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11715685315631758		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.11715685315631758 | validation: 0.14662772169877794]
	TIME [epoch: 13 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11073049703297538		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.11073049703297538 | validation: 0.11811885147973478]
	TIME [epoch: 13 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11182073890503985		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.11182073890503985 | validation: 0.1343601183822327]
	TIME [epoch: 13 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11159826788660458		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.11159826788660458 | validation: 0.1495868307804296]
	TIME [epoch: 13 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10613562118539098		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.10613562118539098 | validation: 0.11768036158606526]
	TIME [epoch: 12.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09356359766911107		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.09356359766911107 | validation: 0.1083033460947386]
	TIME [epoch: 13 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09699135298024995		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.09699135298024995 | validation: 0.13212884935559102]
	TIME [epoch: 12.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11088617716488942		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.11088617716488942 | validation: 0.1133299080668907]
	TIME [epoch: 12.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09215583042309872		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.09215583042309872 | validation: 0.12245589287716953]
	TIME [epoch: 13 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09548545294610053		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.09548545294610053 | validation: 0.09067144113439293]
	TIME [epoch: 13 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.092051437279749		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.092051437279749 | validation: 0.11497009448237423]
	TIME [epoch: 12.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09222735050850407		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.09222735050850407 | validation: 0.10339019947690212]
	TIME [epoch: 13 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09804514305756434		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.09804514305756434 | validation: 0.13334633149404737]
	TIME [epoch: 13 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09662069312345023		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.09662069312345023 | validation: 0.12061622154254636]
	TIME [epoch: 13 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09661836820116743		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.09661836820116743 | validation: 0.11014148153937305]
	TIME [epoch: 13 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09160511162899473		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.09160511162899473 | validation: 0.09231798433119442]
	TIME [epoch: 13 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07944937110808292		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.07944937110808292 | validation: 0.08878973313437342]
	TIME [epoch: 13 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07567160081974189		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.07567160081974189 | validation: 0.10286974075479818]
	TIME [epoch: 13 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1011725785769121		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.1011725785769121 | validation: 0.12171480068303783]
	TIME [epoch: 13 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1207931829212294		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.1207931829212294 | validation: 0.12530753474172415]
	TIME [epoch: 13 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254540646852082		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.1254540646852082 | validation: 0.22786175175135007]
	TIME [epoch: 13 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1649609435238869		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.1649609435238869 | validation: 0.12035651609321052]
	TIME [epoch: 13 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11027939657220924		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.11027939657220924 | validation: 0.1406383133802493]
	TIME [epoch: 13 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11927186752014911		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.11927186752014911 | validation: 0.12651005903437082]
	TIME [epoch: 13 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259978401910622		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.1259978401910622 | validation: 0.13191030604623433]
	TIME [epoch: 13 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.107390346096629		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.107390346096629 | validation: 0.10785670855755396]
	TIME [epoch: 13 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09992782845309486		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.09992782845309486 | validation: 0.12048243791632793]
	TIME [epoch: 13 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11359800137230674		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.11359800137230674 | validation: 0.1122836334618323]
	TIME [epoch: 12.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10055167437039829		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.10055167437039829 | validation: 0.1347958109474613]
	TIME [epoch: 13 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11680561953976483		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.11680561953976483 | validation: 0.12568965297135398]
	TIME [epoch: 13 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10248462544021002		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.10248462544021002 | validation: 0.12196558172113582]
	TIME [epoch: 13 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09979407451776026		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.09979407451776026 | validation: 0.11679111599672044]
	TIME [epoch: 13 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10152591374515042		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.10152591374515042 | validation: 0.12063634308259301]
	TIME [epoch: 13 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1047218931370337		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.1047218931370337 | validation: 0.11259276984188211]
	TIME [epoch: 13 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09327869403441541		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.09327869403441541 | validation: 0.10122106682680994]
	TIME [epoch: 13 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0912808622816903		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.0912808622816903 | validation: 0.12191983314144576]
	TIME [epoch: 13 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10184880182930366		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.10184880182930366 | validation: 0.11662566756201623]
	TIME [epoch: 13 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10184807999422361		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.10184807999422361 | validation: 0.11945489581491298]
	TIME [epoch: 13 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1153936165360608		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.1153936165360608 | validation: 0.13033924498126573]
	TIME [epoch: 12.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11325331377847317		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.11325331377847317 | validation: 0.13393904022914238]
	TIME [epoch: 12.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10837608162885011		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.10837608162885011 | validation: 0.13029358692008294]
	TIME [epoch: 12.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09130023269860368		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.09130023269860368 | validation: 0.10803140115684284]
	TIME [epoch: 12.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08303459125934926		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.08303459125934926 | validation: 0.08320165021321867]
	TIME [epoch: 12.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07102284768930564		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.07102284768930564 | validation: 0.07943845045552823]
	TIME [epoch: 12.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07242912229923376		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.07242912229923376 | validation: 0.07756099091906923]
	TIME [epoch: 13 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07967511007521833		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.07967511007521833 | validation: 0.10049028274945229]
	TIME [epoch: 12.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08432142871424791		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.08432142871424791 | validation: 0.08901122490758473]
	TIME [epoch: 13 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07516187416521702		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.07516187416521702 | validation: 0.08993475935149933]
	TIME [epoch: 13 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06759806094901108		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.06759806094901108 | validation: 0.09030655305789682]
	TIME [epoch: 13 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08828782230375792		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.08828782230375792 | validation: 0.1064830734655723]
	TIME [epoch: 12.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07238108282946469		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.07238108282946469 | validation: 0.08100387474109454]
	TIME [epoch: 12.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08435710894840232		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.08435710894840232 | validation: 0.0960932362988968]
	TIME [epoch: 13 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08864642375423078		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.08864642375423078 | validation: 0.11420982511129495]
	TIME [epoch: 13 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09871568016984321		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.09871568016984321 | validation: 0.09821199695308827]
	TIME [epoch: 13 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09089795165756882		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.09089795165756882 | validation: 0.09742352841554748]
	TIME [epoch: 13 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10652131984777054		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.10652131984777054 | validation: 0.11421268641233301]
	TIME [epoch: 13 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08785703642440298		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.08785703642440298 | validation: 0.1225754852647687]
	TIME [epoch: 12.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09694947709768212		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.09694947709768212 | validation: 0.10900108658731261]
	TIME [epoch: 13 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09123072615227937		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.09123072615227937 | validation: 0.11424131379755885]
	TIME [epoch: 13 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09760988669390469		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.09760988669390469 | validation: 0.12291700566183607]
	TIME [epoch: 13 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11168846892029383		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.11168846892029383 | validation: 0.13849584830874187]
	TIME [epoch: 13 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0948915420578602		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.0948915420578602 | validation: 0.11173284895613014]
	TIME [epoch: 13 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08677278966946614		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.08677278966946614 | validation: 0.10785340197718916]
	TIME [epoch: 13 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08890710859685252		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.08890710859685252 | validation: 0.10200116798454113]
	TIME [epoch: 13 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08441493248157443		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.08441493248157443 | validation: 0.09846321667962026]
	TIME [epoch: 12.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08655023033130954		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.08655023033130954 | validation: 0.10377959727359731]
	TIME [epoch: 13 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824241787659724		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.0824241787659724 | validation: 0.08942455799718645]
	TIME [epoch: 12.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08421263350038996		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.08421263350038996 | validation: 0.06918653478419666]
	TIME [epoch: 13 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07063236254301866		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.07063236254301866 | validation: 0.08438739280202828]
	TIME [epoch: 12.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08241880766326494		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.08241880766326494 | validation: 0.12116534558075519]
	TIME [epoch: 13 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08780022386537939		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.08780022386537939 | validation: 0.07827753202653401]
	TIME [epoch: 13 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06281626592096726		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.06281626592096726 | validation: 0.06495060974445098]
	TIME [epoch: 13 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05359957896787936		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.05359957896787936 | validation: 0.0713016819196565]
	TIME [epoch: 13 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058109653105201414		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.058109653105201414 | validation: 0.08045662689494912]
	TIME [epoch: 13 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06015663520588195		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.06015663520588195 | validation: 0.0748597933348594]
	TIME [epoch: 13 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06260624138102051		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.06260624138102051 | validation: 0.09135649306684926]
	TIME [epoch: 12.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07519569523927658		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.07519569523927658 | validation: 0.10413040163994074]
	TIME [epoch: 13 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08959812050441746		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.08959812050441746 | validation: 0.09236030619217717]
	TIME [epoch: 12.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0796199149157081		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.0796199149157081 | validation: 0.10007894629690368]
	TIME [epoch: 12.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08308760762297676		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.08308760762297676 | validation: 0.09918520123272817]
	TIME [epoch: 12.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07725289132008117		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.07725289132008117 | validation: 0.08286209551398649]
	TIME [epoch: 13 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07517000294036588		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.07517000294036588 | validation: 0.09285526405191152]
	TIME [epoch: 12.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07329124522203193		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.07329124522203193 | validation: 0.09258553041670578]
	TIME [epoch: 13 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07016898705497107		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.07016898705497107 | validation: 0.07998269755639438]
	TIME [epoch: 13 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0746315487639463		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0746315487639463 | validation: 0.0677966940051909]
	TIME [epoch: 12.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06925387739342628		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.06925387739342628 | validation: 0.07110931163212802]
	TIME [epoch: 12.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06628095768860637		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.06628095768860637 | validation: 0.07582007226347075]
	TIME [epoch: 13 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05511512524400736		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.05511512524400736 | validation: 0.0681932550635029]
	TIME [epoch: 13 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06506757805561916		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.06506757805561916 | validation: 0.09335771575732028]
	TIME [epoch: 13 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06241180141413606		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.06241180141413606 | validation: 0.058320127961114854]
	TIME [epoch: 13 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05338288389992461		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.05338288389992461 | validation: 0.0635419926685826]
	TIME [epoch: 13 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05671223353963754		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.05671223353963754 | validation: 0.06363697313217113]
	TIME [epoch: 13 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061507471960554144		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.061507471960554144 | validation: 0.0684454293100059]
	TIME [epoch: 13 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05259190332520188		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.05259190332520188 | validation: 0.06354863146634174]
	TIME [epoch: 13 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05629332556603496		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.05629332556603496 | validation: 0.09401483499638305]
	TIME [epoch: 13 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05719963001136992		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.05719963001136992 | validation: 0.0742853975046658]
	TIME [epoch: 12.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04882553140203709		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.04882553140203709 | validation: 0.08144199259356008]
	TIME [epoch: 12.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05837232985317492		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.05837232985317492 | validation: 0.06952070608263757]
	TIME [epoch: 13 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05727472238144696		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.05727472238144696 | validation: 0.08116649408673922]
	TIME [epoch: 12.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06750136063254149		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.06750136063254149 | validation: 0.0732942663206841]
	TIME [epoch: 12.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05724404020350819		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.05724404020350819 | validation: 0.07022017191719344]
	TIME [epoch: 12.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05612681590484891		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.05612681590484891 | validation: 0.07386872131281293]
	TIME [epoch: 13 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056895462923450026		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.056895462923450026 | validation: 0.07177953207218989]
	TIME [epoch: 12.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06534229920140719		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.06534229920140719 | validation: 0.09515187218946189]
	TIME [epoch: 12.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07607653226029082		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.07607653226029082 | validation: 0.07099911435047472]
	TIME [epoch: 13 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06467518798382439		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.06467518798382439 | validation: 0.07143961384803924]
	TIME [epoch: 13 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07043433460454887		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.07043433460454887 | validation: 0.09319241098020394]
	TIME [epoch: 12.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07475089861189681		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.07475089861189681 | validation: 0.0842315809200093]
	TIME [epoch: 12.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08393709928265068		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.08393709928265068 | validation: 0.10087633735482351]
	TIME [epoch: 13 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07607730753564988		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.07607730753564988 | validation: 0.0979295976126536]
	TIME [epoch: 12.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08210134844332694		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.08210134844332694 | validation: 0.10166436329619565]
	TIME [epoch: 13 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09713429123296854		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.09713429123296854 | validation: 0.10521222083489445]
	TIME [epoch: 13 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0862623367282319		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.0862623367282319 | validation: 0.09353134860386866]
	TIME [epoch: 13 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07986576124496275		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.07986576124496275 | validation: 0.094969175488799]
	TIME [epoch: 13 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07207416357858223		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.07207416357858223 | validation: 0.10655129729508726]
	TIME [epoch: 12.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08919352550693474		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.08919352550693474 | validation: 0.10688851323455505]
	TIME [epoch: 13 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09446912913198227		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.09446912913198227 | validation: 0.12641747007749032]
	TIME [epoch: 13 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10143273783127496		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.10143273783127496 | validation: 0.11328374041230556]
	TIME [epoch: 12.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09587703459383082		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.09587703459383082 | validation: 0.10485705608196319]
	TIME [epoch: 13 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08453572781965688		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.08453572781965688 | validation: 0.09240966265581248]
	TIME [epoch: 13 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07642321304583066		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.07642321304583066 | validation: 0.0938267847042656]
	TIME [epoch: 13 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0737303397589837		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.0737303397589837 | validation: 0.0838427284218282]
	TIME [epoch: 12.9 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0702750931994258		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.0702750931994258 | validation: 0.10829383804293402]
	TIME [epoch: 13 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07461234728141813		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.07461234728141813 | validation: 0.08152441068106153]
	TIME [epoch: 12.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07330475669287069		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.07330475669287069 | validation: 0.13141361905123208]
	TIME [epoch: 13 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13150838693757066		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.13150838693757066 | validation: 0.12359219852072208]
	TIME [epoch: 12.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08692085086170681		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.08692085086170681 | validation: 0.08799560341718893]
	TIME [epoch: 13 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07537869931304703		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.07537869931304703 | validation: 0.08908937219961181]
	TIME [epoch: 12.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06717864327946024		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.06717864327946024 | validation: 0.07879843437171051]
	TIME [epoch: 13 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07240841942766493		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.07240841942766493 | validation: 0.08493200348537255]
	TIME [epoch: 12.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07794658375351161		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.07794658375351161 | validation: 0.09639816772616348]
	TIME [epoch: 13 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06604922621692842		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.06604922621692842 | validation: 0.07538335266030881]
	TIME [epoch: 12.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05661047441217132		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.05661047441217132 | validation: 0.07229922206506177]
	TIME [epoch: 13 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05590259139332743		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.05590259139332743 | validation: 0.07931248746719924]
	TIME [epoch: 13 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057989028520836594		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.057989028520836594 | validation: 0.0774946011298571]
	TIME [epoch: 13 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049217967478166605		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.049217967478166605 | validation: 0.08241938431406882]
	TIME [epoch: 12.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060607840794821274		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.060607840794821274 | validation: 0.06796939154901557]
	TIME [epoch: 13 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06280630113585786		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.06280630113585786 | validation: 0.06488415260686688]
	TIME [epoch: 13 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06143649612151748		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.06143649612151748 | validation: 0.06637271725799025]
	TIME [epoch: 12.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05158240408156565		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.05158240408156565 | validation: 0.06304347065449074]
	TIME [epoch: 13 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05013733361525324		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.05013733361525324 | validation: 0.08157462706941519]
	TIME [epoch: 13 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06652217626297915		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.06652217626297915 | validation: 0.06979023814457244]
	TIME [epoch: 13 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051691154900087626		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.051691154900087626 | validation: 0.0578323251627578]
	TIME [epoch: 13 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048700604401491446		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.048700604401491446 | validation: 0.05651156024462234]
	TIME [epoch: 12.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04521161131737047		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.04521161131737047 | validation: 0.05301177678074627]
	TIME [epoch: 13 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04108882029326871		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.04108882029326871 | validation: 0.07329457247283931]
	TIME [epoch: 12.9 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05626943350635042		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.05626943350635042 | validation: 0.0589710016796079]
	TIME [epoch: 12.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052568834166421725		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.052568834166421725 | validation: 0.06858824513564793]
	TIME [epoch: 13 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04321217466874949		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.04321217466874949 | validation: 0.05253889311857003]
	TIME [epoch: 12.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04345833942371313		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.04345833942371313 | validation: 0.06466553698829094]
	TIME [epoch: 12.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0513926710980839		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.0513926710980839 | validation: 0.055268574723019985]
	TIME [epoch: 13 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04510032485549391		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.04510032485549391 | validation: 0.05633710695241094]
	TIME [epoch: 13 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04695202119906556		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.04695202119906556 | validation: 0.06530769910780838]
	TIME [epoch: 13 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04668158181057157		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.04668158181057157 | validation: 0.06842506720708301]
	TIME [epoch: 12.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06702310811405966		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.06702310811405966 | validation: 0.10410598782607398]
	TIME [epoch: 13 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07119001221004972		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.07119001221004972 | validation: 0.09863230400714916]
	TIME [epoch: 13 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06442269551901388		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.06442269551901388 | validation: 0.07624587291691212]
	TIME [epoch: 13 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05841730253566351		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.05841730253566351 | validation: 0.12019081843073919]
	TIME [epoch: 12.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08406162995526863		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.08406162995526863 | validation: 0.09696662599361126]
	TIME [epoch: 13 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07184125763192183		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.07184125763192183 | validation: 0.07740558365353473]
	TIME [epoch: 13 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243420334830107		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.08243420334830107 | validation: 0.10533760762743415]
	TIME [epoch: 13 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06998474678168294		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.06998474678168294 | validation: 0.10083056946702713]
	TIME [epoch: 12.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07064795616752792		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.07064795616752792 | validation: 0.13991317627688266]
	TIME [epoch: 13 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11745716929749639		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.11745716929749639 | validation: 0.20146978260588064]
	TIME [epoch: 12.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.155528125183112		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.155528125183112 | validation: 0.16293762193752223]
	TIME [epoch: 13 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09781582385967762		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.09781582385967762 | validation: 0.09587262379411492]
	TIME [epoch: 13 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06972213187857687		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.06972213187857687 | validation: 0.07734195089068735]
	TIME [epoch: 13 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06086610465183919		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.06086610465183919 | validation: 0.06975417419816117]
	TIME [epoch: 12.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05376622731708058		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.05376622731708058 | validation: 0.06469382245413467]
	TIME [epoch: 13 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057689604572918635		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.057689604572918635 | validation: 0.06696073930525309]
	TIME [epoch: 13 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049539466457042616		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.049539466457042616 | validation: 0.06185497622471856]
	TIME [epoch: 13 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052314451868960096		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.052314451868960096 | validation: 0.06531356863348683]
	TIME [epoch: 12.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04407219241424591		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.04407219241424591 | validation: 0.045749746961295835]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_852.pth
	Model improved!!!
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03977311675516354		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.03977311675516354 | validation: 0.04691853616324927]
	TIME [epoch: 12.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04029519886292901		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.04029519886292901 | validation: 0.07870134470013143]
	TIME [epoch: 13 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06557000353177908		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.06557000353177908 | validation: 0.08380681877983356]
	TIME [epoch: 12.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057606902920169546		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.057606902920169546 | validation: 0.08554750638964125]
	TIME [epoch: 13 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05561346824647894		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.05561346824647894 | validation: 0.054257059654358473]
	TIME [epoch: 12.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047679636280258515		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.047679636280258515 | validation: 0.06485251339534631]
	TIME [epoch: 12.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05425162794575235		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.05425162794575235 | validation: 0.07401200125774356]
	TIME [epoch: 13 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0475044448989862		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.0475044448989862 | validation: 0.06243293881926352]
	TIME [epoch: 12.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04802208086907324		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.04802208086907324 | validation: 0.08147697758925979]
	TIME [epoch: 12.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061090225513750596		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.061090225513750596 | validation: 0.07603009169101423]
	TIME [epoch: 12.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06700788014833733		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.06700788014833733 | validation: 0.07333643209137074]
	TIME [epoch: 13 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06796230069236368		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.06796230069236368 | validation: 0.08649610483337694]
	TIME [epoch: 12.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06331524544225915		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.06331524544225915 | validation: 0.07886113189639016]
	TIME [epoch: 12.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05587879005400147		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.05587879005400147 | validation: 0.05829274299444509]
	TIME [epoch: 12.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050204987436478		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.050204987436478 | validation: 0.07400136302582849]
	TIME [epoch: 13 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054322046493639656		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.054322046493639656 | validation: 0.06067784477597723]
	TIME [epoch: 12.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04820052366786363		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.04820052366786363 | validation: 0.05866213292518557]
	TIME [epoch: 12.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0446770272764035		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.0446770272764035 | validation: 0.05508201599382554]
	TIME [epoch: 13 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04856790649703088		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.04856790649703088 | validation: 0.06363520044335971]
	TIME [epoch: 13 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04258770090913862		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.04258770090913862 | validation: 0.06057425503943541]
	TIME [epoch: 13 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04831185628817863		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.04831185628817863 | validation: 0.0635603953855993]
	TIME [epoch: 13 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04372896317490455		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.04372896317490455 | validation: 0.053887854306247485]
	TIME [epoch: 13 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04697216467348026		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.04697216467348026 | validation: 0.06542133163662942]
	TIME [epoch: 12.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0457464689230397		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.0457464689230397 | validation: 0.05787062691191406]
	TIME [epoch: 12.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04024593027764093		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.04024593027764093 | validation: 0.04727075878077438]
	TIME [epoch: 13 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03918978950512845		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.03918978950512845 | validation: 0.053405942628094095]
	TIME [epoch: 12.9 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043135912527875526		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.043135912527875526 | validation: 0.0581635576264765]
	TIME [epoch: 12.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04122410736138691		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.04122410736138691 | validation: 0.05542938109380085]
	TIME [epoch: 13 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04494159174125374		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.04494159174125374 | validation: 0.05566478757497084]
	TIME [epoch: 13 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045579562333431536		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.045579562333431536 | validation: 0.05626278837451998]
	TIME [epoch: 12.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0524766698113474		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.0524766698113474 | validation: 0.06666310220739292]
	TIME [epoch: 12.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04288357702460723		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.04288357702460723 | validation: 0.051484723646963264]
	TIME [epoch: 13 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039056592889835894		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.039056592889835894 | validation: 0.05620468228969332]
	TIME [epoch: 12.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041264864840038724		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.041264864840038724 | validation: 0.06601408021586541]
	TIME [epoch: 13 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056703667319481114		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.056703667319481114 | validation: 0.06404297288551486]
	TIME [epoch: 12.9 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05197532457745496		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.05197532457745496 | validation: 0.06558351122721794]
	TIME [epoch: 13 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04197477794098601		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.04197477794098601 | validation: 0.059421547727438837]
	TIME [epoch: 13 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047913299864338475		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.047913299864338475 | validation: 0.0677137950959254]
	TIME [epoch: 13 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05315575310215557		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.05315575310215557 | validation: 0.0638949335971343]
	TIME [epoch: 12.9 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04517371514633501		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.04517371514633501 | validation: 0.05011056027194604]
	TIME [epoch: 13 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045646853421478645		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.045646853421478645 | validation: 0.052551461464311215]
	TIME [epoch: 13 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04343323717851128		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.04343323717851128 | validation: 0.06459552860103747]
	TIME [epoch: 13 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05863345491299095		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.05863345491299095 | validation: 0.08439013951217174]
	TIME [epoch: 13 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04943565709578589		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.04943565709578589 | validation: 0.07094393672999962]
	TIME [epoch: 13 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043400717886701384		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.043400717886701384 | validation: 0.05541281124326885]
	TIME [epoch: 13 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04293572905467872		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.04293572905467872 | validation: 0.05244777343687803]
	TIME [epoch: 13 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03976122433357749		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.03976122433357749 | validation: 0.05948021313666347]
	TIME [epoch: 13 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04441174201464797		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.04441174201464797 | validation: 0.049594875635319224]
	TIME [epoch: 12.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0410066777064288		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.0410066777064288 | validation: 0.06387019935899237]
	TIME [epoch: 13 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04309719671922983		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.04309719671922983 | validation: 0.059319486427274935]
	TIME [epoch: 13 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0451884017324249		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.0451884017324249 | validation: 0.06831410626015769]
	TIME [epoch: 12.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04581893471502775		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.04581893471502775 | validation: 0.06378290869068197]
	TIME [epoch: 12.9 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04902141515216821		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.04902141515216821 | validation: 0.05622855313327298]
	TIME [epoch: 12.9 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039091764944810946		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.039091764944810946 | validation: 0.057961942359612044]
	TIME [epoch: 13 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04809505876202496		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.04809505876202496 | validation: 0.07476529222211738]
	TIME [epoch: 13 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05479607600022734		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.05479607600022734 | validation: 0.06495421781815036]
	TIME [epoch: 13 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044855048473383986		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.044855048473383986 | validation: 0.06260715017482543]
	TIME [epoch: 13 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045715467301799755		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.045715467301799755 | validation: 0.05923272026386273]
	TIME [epoch: 13 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040928633915996306		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.040928633915996306 | validation: 0.047954901145443374]
	TIME [epoch: 12.9 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04328819266453892		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.04328819266453892 | validation: 0.06050071294218906]
	TIME [epoch: 12.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04956485014074175		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.04956485014074175 | validation: 0.06535788571983672]
	TIME [epoch: 13 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052745460102932955		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.052745460102932955 | validation: 0.059596548412840046]
	TIME [epoch: 12.9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043693183054039304		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.043693183054039304 | validation: 0.06916526970756275]
	TIME [epoch: 12.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06237534881477568		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.06237534881477568 | validation: 0.08160806303184685]
	TIME [epoch: 13 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06063145135111238		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.06063145135111238 | validation: 0.07336301707876387]
	TIME [epoch: 13 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054133679101999746		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.054133679101999746 | validation: 0.06644371763488577]
	TIME [epoch: 12.9 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04964297989582204		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.04964297989582204 | validation: 0.06213340593464775]
	TIME [epoch: 12.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04756229837651376		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.04756229837651376 | validation: 0.06320256276908316]
	TIME [epoch: 13 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04541236217881035		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.04541236217881035 | validation: 0.06060808855281484]
	TIME [epoch: 13 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05317053719262567		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.05317053719262567 | validation: 0.07889279156526381]
	TIME [epoch: 13 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06012959489758664		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.06012959489758664 | validation: 0.07245416039956613]
	TIME [epoch: 12.9 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05653267237355749		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.05653267237355749 | validation: 0.08632879048477418]
	TIME [epoch: 13 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05458054108945015		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.05458054108945015 | validation: 0.06804637512671032]
	TIME [epoch: 13 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053420886680875246		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.053420886680875246 | validation: 0.08305751373022881]
	TIME [epoch: 13 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06301905383896636		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.06301905383896636 | validation: 0.0617260405204766]
	TIME [epoch: 13 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04954125132962615		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.04954125132962615 | validation: 0.06176049282261833]
	TIME [epoch: 12.9 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04854410807173512		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.04854410807173512 | validation: 0.06536849628124951]
	TIME [epoch: 12.9 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04524314966557685		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.04524314966557685 | validation: 0.05967559234995846]
	TIME [epoch: 12.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041536422352514354		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.041536422352514354 | validation: 0.05863891921503316]
	TIME [epoch: 13 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04504661787855173		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.04504661787855173 | validation: 0.0678028635294535]
	TIME [epoch: 12.9 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05097085433376147		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.05097085433376147 | validation: 0.06815023147226233]
	TIME [epoch: 13 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049282621510358185		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.049282621510358185 | validation: 0.06373033143398098]
	TIME [epoch: 13 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053586881462490174		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.053586881462490174 | validation: 0.07076263070038197]
	TIME [epoch: 13 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05844518972666156		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.05844518972666156 | validation: 0.09998687055788023]
	TIME [epoch: 12.9 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07507437038131168		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.07507437038131168 | validation: 0.07994413468526086]
	TIME [epoch: 12.9 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05302533741723664		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.05302533741723664 | validation: 0.05080761825039312]
	TIME [epoch: 13 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04032468260508048		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.04032468260508048 | validation: 0.049802202320516575]
	TIME [epoch: 12.9 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03303676435313019		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.03303676435313019 | validation: 0.04230724814002151]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_940.pth
	Model improved!!!
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040539427741263		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.040539427741263 | validation: 0.06506895198786786]
	TIME [epoch: 13 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041344103639580805		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.041344103639580805 | validation: 0.06186218095279224]
	TIME [epoch: 13 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04473660214872705		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.04473660214872705 | validation: 0.06263407025214578]
	TIME [epoch: 12.9 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053323546057853985		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.053323546057853985 | validation: 0.06518508834330092]
	TIME [epoch: 12.9 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04660719564911815		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.04660719564911815 | validation: 0.06379767165925734]
	TIME [epoch: 13 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0557730196711444		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.0557730196711444 | validation: 0.12449854706740716]
	TIME [epoch: 13 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10234022230039648		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.10234022230039648 | validation: 0.12582433078698763]
	TIME [epoch: 13 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09826958209560653		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.09826958209560653 | validation: 0.10486632278989239]
	TIME [epoch: 13 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06787019246721476		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.06787019246721476 | validation: 0.06243793774733428]
	TIME [epoch: 13 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05943801414379507		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.05943801414379507 | validation: 0.11161327316287857]
	TIME [epoch: 13 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09035224903885364		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.09035224903885364 | validation: 0.08650147232260683]
	TIME [epoch: 12.9 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06572636410404424		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.06572636410404424 | validation: 0.07002168323496077]
	TIME [epoch: 13 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05179658626345707		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.05179658626345707 | validation: 0.047926792679827045]
	TIME [epoch: 13 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04072997316821013		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.04072997316821013 | validation: 0.06405504748656339]
	TIME [epoch: 12.9 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04662046150149683		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.04662046150149683 | validation: 0.06871164465438208]
	TIME [epoch: 13 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04552630607481446		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.04552630607481446 | validation: 0.06817715963431319]
	TIME [epoch: 13 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048519186215834606		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.048519186215834606 | validation: 0.05153770283499785]
	TIME [epoch: 13 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045767894434190756		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.045767894434190756 | validation: 0.07057568439813607]
	TIME [epoch: 13 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05424569348802552		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.05424569348802552 | validation: 0.06261292373038618]
	TIME [epoch: 13 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0577230401686657		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.0577230401686657 | validation: 0.0707955898793525]
	TIME [epoch: 13 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05874960909948197		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.05874960909948197 | validation: 0.0737705148433824]
	TIME [epoch: 12.9 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05761282650937427		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.05761282650937427 | validation: 0.07919318672485359]
	TIME [epoch: 13 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05844835499065162		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.05844835499065162 | validation: 0.07753816585306698]
	TIME [epoch: 13 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05543427343384537		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.05543427343384537 | validation: 0.06232678288000621]
	TIME [epoch: 13 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04773048851327673		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.04773048851327673 | validation: 0.05778081182040459]
	TIME [epoch: 12.9 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04380358507757603		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.04380358507757603 | validation: 0.0526462292687226]
	TIME [epoch: 13 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03357637717446355		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.03357637717446355 | validation: 0.047977240632516543]
	TIME [epoch: 13 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02706333267326188		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.02706333267326188 | validation: 0.04285417890160284]
	TIME [epoch: 13 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02817429853505785		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.02817429853505785 | validation: 0.0405075373364617]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_969.pth
	Model improved!!!
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02908512986026389		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.02908512986026389 | validation: 0.04030178925364714]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_970.pth
	Model improved!!!
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03699657717148138		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.03699657717148138 | validation: 0.06172594363518662]
	TIME [epoch: 13 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04267883700733845		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.04267883700733845 | validation: 0.05518985680977829]
	TIME [epoch: 13 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04252098949480055		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.04252098949480055 | validation: 0.04927616350526698]
	TIME [epoch: 13 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03902546462345076		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.03902546462345076 | validation: 0.05222607140435435]
	TIME [epoch: 13 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03884661747562005		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.03884661747562005 | validation: 0.040063357569955674]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_975.pth
	Model improved!!!
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02630033808908737		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.02630033808908737 | validation: 0.03946966763903069]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_976.pth
	Model improved!!!
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03645457910729584		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.03645457910729584 | validation: 0.07482437564315761]
	TIME [epoch: 13 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05098482396516148		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.05098482396516148 | validation: 0.05358970235248593]
	TIME [epoch: 13 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030209736662620064		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.030209736662620064 | validation: 0.03880968463045887]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_979.pth
	Model improved!!!
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025161553607123303		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.025161553607123303 | validation: 0.029432769536495408]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_980.pth
	Model improved!!!
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0242426627615681		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.0242426627615681 | validation: 0.02641050006294582]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_981.pth
	Model improved!!!
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02648022900064232		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.02648022900064232 | validation: 0.04118836866123791]
	TIME [epoch: 13 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03487604520507992		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.03487604520507992 | validation: 0.05167018422919915]
	TIME [epoch: 13 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030476575802101002		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.030476575802101002 | validation: 0.051866342838799116]
	TIME [epoch: 13 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036968817541775834		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.036968817541775834 | validation: 0.059796048752826236]
	TIME [epoch: 13 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047175303511047366		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.047175303511047366 | validation: 0.06633439321267327]
	TIME [epoch: 13 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05051262500246207		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.05051262500246207 | validation: 0.05666981921169503]
	TIME [epoch: 13 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03614663680949563		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.03614663680949563 | validation: 0.05261050547810385]
	TIME [epoch: 13 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04612500369584879		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.04612500369584879 | validation: 0.0566600080897811]
	TIME [epoch: 13 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043146383793168076		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.043146383793168076 | validation: 0.03788171935372536]
	TIME [epoch: 13 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031469683329134024		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.031469683329134024 | validation: 0.04784353734100307]
	TIME [epoch: 13 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04002660760075899		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.04002660760075899 | validation: 0.07511627348682072]
	TIME [epoch: 13 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05111972252911235		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.05111972252911235 | validation: 0.04822694450886713]
	TIME [epoch: 13 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02751435199526837		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.02751435199526837 | validation: 0.03820309664392497]
	TIME [epoch: 13 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028821050317249724		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.028821050317249724 | validation: 0.035642451895553824]
	TIME [epoch: 13 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024412572913253293		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.024412572913253293 | validation: 0.03910501488162095]
	TIME [epoch: 13 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030199937545102223		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.030199937545102223 | validation: 0.04248323228011369]
	TIME [epoch: 13 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03522536604121042		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.03522536604121042 | validation: 0.039353910698741335]
	TIME [epoch: 13 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027109128331138405		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.027109128331138405 | validation: 0.044151331718699484]
	TIME [epoch: 13 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03165294350652566		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.03165294350652566 | validation: 0.053380657893014494]
	TIME [epoch: 13 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03782941743150437		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.03782941743150437 | validation: 0.0446220972507348]
	TIME [epoch: 13 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035375712262446304		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.035375712262446304 | validation: 0.04531558607020426]
	TIME [epoch: 13 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033564793327520936		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.033564793327520936 | validation: 0.06386366988807356]
	TIME [epoch: 13 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03702635203827581		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.03702635203827581 | validation: 0.04064871900021769]
	TIME [epoch: 13 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027988076823247172		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.027988076823247172 | validation: 0.035301259892553415]
	TIME [epoch: 13 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03290451747129549		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.03290451747129549 | validation: 0.0433989887098433]
	TIME [epoch: 13 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03329761404120453		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.03329761404120453 | validation: 0.042285396644284906]
	TIME [epoch: 13 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04123141114368814		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.04123141114368814 | validation: 0.05064084327283407]
	TIME [epoch: 13 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03407563756331113		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.03407563756331113 | validation: 0.04692691913068351]
	TIME [epoch: 13 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03761318974178439		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.03761318974178439 | validation: 0.04829480683344712]
	TIME [epoch: 13 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03541299513676023		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.03541299513676023 | validation: 0.05180447472046766]
	TIME [epoch: 13 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03697597379987408		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.03697597379987408 | validation: 0.04895414519523861]
	TIME [epoch: 13 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03633387485284914		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.03633387485284914 | validation: 0.0386929688018445]
	TIME [epoch: 13 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02757262682300218		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.02757262682300218 | validation: 0.04147484583835513]
	TIME [epoch: 13 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027414327886697645		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.027414327886697645 | validation: 0.0350134733286774]
	TIME [epoch: 13 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03296297547740845		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.03296297547740845 | validation: 0.05367150991843261]
	TIME [epoch: 13 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04241562005271321		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.04241562005271321 | validation: 0.06499662804020374]
	TIME [epoch: 13 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044475472453920716		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.044475472453920716 | validation: 0.04690389992071973]
	TIME [epoch: 13 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02905853407019708		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.02905853407019708 | validation: 0.04001667914804603]
	TIME [epoch: 13 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03306951192456636		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.03306951192456636 | validation: 0.05334313938054063]
	TIME [epoch: 13 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04855216618757047		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.04855216618757047 | validation: 0.08338948236772041]
	TIME [epoch: 13 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050638346323929315		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.050638346323929315 | validation: 0.05724756215261521]
	TIME [epoch: 13 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03361793545332847		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.03361793545332847 | validation: 0.047909964678302386]
	TIME [epoch: 13 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03637561039326493		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.03637561039326493 | validation: 0.044676456912003976]
	TIME [epoch: 13 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03636031956356085		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.03636031956356085 | validation: 0.05539161006082818]
	TIME [epoch: 13 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034098341897739026		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.034098341897739026 | validation: 0.038128679592621555]
	TIME [epoch: 13 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029101798215312162		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.029101798215312162 | validation: 0.03220004528589323]
	TIME [epoch: 13 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023558257632562748		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.023558257632562748 | validation: 0.022401237190915878]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_1028.pth
	Model improved!!!
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028064656903705666		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.028064656903705666 | validation: 0.037839964085273396]
	TIME [epoch: 13 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02848708439219283		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.02848708439219283 | validation: 0.03502267371992776]
	TIME [epoch: 13 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024504117664803995		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.024504117664803995 | validation: 0.03525280238046114]
	TIME [epoch: 12.9 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03013821878091762		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.03013821878091762 | validation: 0.04723814389394059]
	TIME [epoch: 12.9 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03822098511380067		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.03822098511380067 | validation: 0.05092191578915611]
	TIME [epoch: 12.9 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03130531467297108		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.03130531467297108 | validation: 0.03224060313923583]
	TIME [epoch: 13 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026969955770452185		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.026969955770452185 | validation: 0.04279835669221944]
	TIME [epoch: 12.9 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030885045215938333		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.030885045215938333 | validation: 0.038538189895864675]
	TIME [epoch: 13 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026027454848693652		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.026027454848693652 | validation: 0.029317802539280444]
	TIME [epoch: 13 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02640302499262149		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.02640302499262149 | validation: 0.044605795852658295]
	TIME [epoch: 13 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03339730327212133		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.03339730327212133 | validation: 0.03381286499051291]
	TIME [epoch: 12.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025623480253897876		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.025623480253897876 | validation: 0.034031402701448804]
	TIME [epoch: 12.9 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019719993626255258		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.019719993626255258 | validation: 0.02976508735735983]
	TIME [epoch: 13 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025074256159900412		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.025074256159900412 | validation: 0.033090125173797606]
	TIME [epoch: 12.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024210443731081815		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.024210443731081815 | validation: 0.029168498394155834]
	TIME [epoch: 13 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01929438632388511		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.01929438632388511 | validation: 0.029188523704432298]
	TIME [epoch: 13 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020687973929192957		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.020687973929192957 | validation: 0.028136674036542103]
	TIME [epoch: 13 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023537115350385402		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.023537115350385402 | validation: 0.04207080176614206]
	TIME [epoch: 12.9 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03818903777050939		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.03818903777050939 | validation: 0.06264998093858809]
	TIME [epoch: 12.9 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04426402913854216		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.04426402913854216 | validation: 0.059388727349696094]
	TIME [epoch: 13 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04472883486659628		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.04472883486659628 | validation: 0.0496684504207707]
	TIME [epoch: 13 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041893581467806834		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.041893581467806834 | validation: 0.06256468577029432]
	TIME [epoch: 13 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04333642497152148		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.04333642497152148 | validation: 0.051412553100492975]
	TIME [epoch: 13 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03273108935553601		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.03273108935553601 | validation: 0.039580511827921064]
	TIME [epoch: 13 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03374990158275922		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.03374990158275922 | validation: 0.0445665747907106]
	TIME [epoch: 12.9 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02807256055805099		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.02807256055805099 | validation: 0.02444390966006721]
	TIME [epoch: 13 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023315190644346784		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.023315190644346784 | validation: 0.035856101605922314]
	TIME [epoch: 13 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022827028058905956		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.022827028058905956 | validation: 0.047324662167712236]
	TIME [epoch: 13 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02812570496586391		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.02812570496586391 | validation: 0.04996462673596305]
	TIME [epoch: 13 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036403097057848555		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.036403097057848555 | validation: 0.042339642668774935]
	TIME [epoch: 13 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0338499642218177		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.0338499642218177 | validation: 0.04564728439177771]
	TIME [epoch: 13 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029349461253333393		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.029349461253333393 | validation: 0.03477757346732945]
	TIME [epoch: 12.9 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030434067014526982		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.030434067014526982 | validation: 0.03530887588946061]
	TIME [epoch: 13 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03035827697060692		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.03035827697060692 | validation: 0.031090127519817934]
	TIME [epoch: 13 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024226256232444947		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.024226256232444947 | validation: 0.041577121470372506]
	TIME [epoch: 13 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021780336604279034		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.021780336604279034 | validation: 0.0355773534559018]
	TIME [epoch: 12.9 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02979986552420872		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.02979986552420872 | validation: 0.046637477884026286]
	TIME [epoch: 13 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023513346173854054		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.023513346173854054 | validation: 0.02753742224043363]
	TIME [epoch: 13 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023329552726673187		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.023329552726673187 | validation: 0.03194178466749073]
	TIME [epoch: 13 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02281371249388396		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.02281371249388396 | validation: 0.0326467576260333]
	TIME [epoch: 12.9 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027475618226397533		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.027475618226397533 | validation: 0.041078439747204175]
	TIME [epoch: 13 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028831981202781857		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.028831981202781857 | validation: 0.037350642053156836]
	TIME [epoch: 13 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027132575226849087		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.027132575226849087 | validation: 0.038336918517033844]
	TIME [epoch: 13 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027475709531151582		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.027475709531151582 | validation: 0.043036977734549335]
	TIME [epoch: 12.9 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03225542183333384		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.03225542183333384 | validation: 0.047241119923189974]
	TIME [epoch: 13 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02571508595166193		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.02571508595166193 | validation: 0.039914589517631174]
	TIME [epoch: 13 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027804958084667257		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.027804958084667257 | validation: 0.042341638420263575]
	TIME [epoch: 12.9 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02249255296719854		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.02249255296719854 | validation: 0.040088282001674996]
	TIME [epoch: 13 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023582147829475063		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.023582147829475063 | validation: 0.03668907293319542]
	TIME [epoch: 13 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024513035030092143		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.024513035030092143 | validation: 0.03626616546642875]
	TIME [epoch: 13 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019024165996065615		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.019024165996065615 | validation: 0.030527149807138443]
	TIME [epoch: 13 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02961283652065823		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.02961283652065823 | validation: 0.04001158129224489]
	TIME [epoch: 13 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027366202531121927		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.027366202531121927 | validation: 0.03840894616353892]
	TIME [epoch: 13 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025477301133429914		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.025477301133429914 | validation: 0.025343670508220836]
	TIME [epoch: 13 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022077393203642		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.022077393203642 | validation: 0.03529568494261464]
	TIME [epoch: 13 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022761815689715074		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.022761815689715074 | validation: 0.03886311867668462]
	TIME [epoch: 13 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019327634478423516		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.019327634478423516 | validation: 0.039308102055752095]
	TIME [epoch: 13 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02911705403392724		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.02911705403392724 | validation: 0.036479740820047006]
	TIME [epoch: 13 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02502784310093042		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.02502784310093042 | validation: 0.04576064363498105]
	TIME [epoch: 13 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023217366062208433		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.023217366062208433 | validation: 0.027842322769750783]
	TIME [epoch: 13 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018853245671927928		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.018853245671927928 | validation: 0.03263619210101885]
	TIME [epoch: 13 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01853563686669498		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.01853563686669498 | validation: 0.020246998207081996]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_1090.pth
	Model improved!!!
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018368027387923844		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.018368027387923844 | validation: 0.02530319679450889]
	TIME [epoch: 13 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026851561424702398		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.026851561424702398 | validation: 0.03925014507175541]
	TIME [epoch: 12.9 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032497519739335		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.032497519739335 | validation: 0.03160352485612061]
	TIME [epoch: 12.9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03310668573453583		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.03310668573453583 | validation: 0.05684156745579545]
	TIME [epoch: 13 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04651712661641411		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.04651712661641411 | validation: 0.08999478353376636]
	TIME [epoch: 13 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07720910330827824		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.07720910330827824 | validation: 0.13785742207937593]
	TIME [epoch: 12.9 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.097929057994071		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.097929057994071 | validation: 0.12736553785032304]
	TIME [epoch: 13 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09500599849851744		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.09500599849851744 | validation: 0.1311360032965958]
	TIME [epoch: 13 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11191272518774914		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.11191272518774914 | validation: 0.18161378575309997]
	TIME [epoch: 13 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14283706046227204		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.14283706046227204 | validation: 0.1808196763600589]
	TIME [epoch: 12.9 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12260107192429681		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.12260107192429681 | validation: 0.13781301774788465]
	TIME [epoch: 13 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10491119324908013		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.10491119324908013 | validation: 0.12177678940859771]
	TIME [epoch: 12.9 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08819526776746375		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.08819526776746375 | validation: 0.11703683273699568]
	TIME [epoch: 12.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09355128475097838		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.09355128475097838 | validation: 0.14017498116946273]
	TIME [epoch: 12.9 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09982787316390102		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.09982787316390102 | validation: 0.14610219793377394]
	TIME [epoch: 13 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.107000033733416		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.107000033733416 | validation: 0.12273784117924968]
	TIME [epoch: 13 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08497769005594763		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.08497769005594763 | validation: 0.09900669742085626]
	TIME [epoch: 12.9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07744584931748948		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.07744584931748948 | validation: 0.11174208870202541]
	TIME [epoch: 13 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08061948365484768		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.08061948365484768 | validation: 0.08056534469148467]
	TIME [epoch: 13 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06023014631721084		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.06023014631721084 | validation: 0.07685669661266664]
	TIME [epoch: 12.9 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06667730954800595		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.06667730954800595 | validation: 0.0915638293773559]
	TIME [epoch: 12.9 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07493701191422021		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.07493701191422021 | validation: 0.10484978358112415]
	TIME [epoch: 13 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08456639494341173		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.08456639494341173 | validation: 0.11397116225296834]
	TIME [epoch: 12.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08344325096017562		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.08344325096017562 | validation: 0.09538602041382319]
	TIME [epoch: 13 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07409160469699835		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.07409160469699835 | validation: 0.07716547024459613]
	TIME [epoch: 12.9 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0560367294269506		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.0560367294269506 | validation: 0.06755391723881835]
	TIME [epoch: 13 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05199076954808118		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.05199076954808118 | validation: 0.08573788213242438]
	TIME [epoch: 12.9 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060140912305520614		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.060140912305520614 | validation: 0.08341159545374519]
	TIME [epoch: 12.9 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06390339526511166		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.06390339526511166 | validation: 0.07105598890569086]
	TIME [epoch: 13 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053775117919941856		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.053775117919941856 | validation: 0.046905894156747494]
	TIME [epoch: 13 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03772504530446359		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.03772504530446359 | validation: 0.04876701646727252]
	TIME [epoch: 12.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03995426172058801		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.03995426172058801 | validation: 0.054695510528685994]
	TIME [epoch: 13 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042971397840860424		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.042971397840860424 | validation: 0.04763947939214339]
	TIME [epoch: 13 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03844454904209225		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.03844454904209225 | validation: 0.05531537302841578]
	TIME [epoch: 12.9 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0386455769228409		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.0386455769228409 | validation: 0.053671597588274465]
	TIME [epoch: 12.9 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04123472899440033		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.04123472899440033 | validation: 0.04573682254249034]
	TIME [epoch: 12.9 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03318506148275433		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.03318506148275433 | validation: 0.04188309102477179]
	TIME [epoch: 12.9 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03027148061371268		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.03027148061371268 | validation: 0.029867492002742788]
	TIME [epoch: 12.9 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028529554864489378		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.028529554864489378 | validation: 0.045364908221612925]
	TIME [epoch: 12.9 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03467934762250845		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.03467934762250845 | validation: 0.04512002133627563]
	TIME [epoch: 13 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595467971956827		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.03595467971956827 | validation: 0.04053668061535134]
	TIME [epoch: 12.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03387989896648365		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.03387989896648365 | validation: 0.041320735824643615]
	TIME [epoch: 12.9 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03819130555305501		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.03819130555305501 | validation: 0.05451114589412022]
	TIME [epoch: 12.9 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03442898607553301		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.03442898607553301 | validation: 0.042260509698468056]
	TIME [epoch: 13 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03394924455935813		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.03394924455935813 | validation: 0.03535983939868445]
	TIME [epoch: 12.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03579196018725392		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.03579196018725392 | validation: 0.04000541714184663]
	TIME [epoch: 12.9 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038147040214457695		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.038147040214457695 | validation: 0.043032090692376034]
	TIME [epoch: 13 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03107968335076165		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.03107968335076165 | validation: 0.04276487810589284]
	TIME [epoch: 12.9 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02622013043965054		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.02622013043965054 | validation: 0.03128653970643836]
	TIME [epoch: 12.9 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025720178230814295		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.025720178230814295 | validation: 0.03726780394009995]
	TIME [epoch: 12.9 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023937338724790612		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.023937338724790612 | validation: 0.04420310313068322]
	TIME [epoch: 13 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025659580415065858		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.025659580415065858 | validation: 0.039656028862594186]
	TIME [epoch: 12.9 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03027211231159609		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.03027211231159609 | validation: 0.046576028933285996]
	TIME [epoch: 12.9 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028542743199411462		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.028542743199411462 | validation: 0.032106164373683174]
	TIME [epoch: 13 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024954056562823006		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.024954056562823006 | validation: 0.039460025583013404]
	TIME [epoch: 12.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025795195803854015		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.025795195803854015 | validation: 0.045193069868653304]
	TIME [epoch: 12.9 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027610818333698807		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.027610818333698807 | validation: 0.037287801762587586]
	TIME [epoch: 12.9 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02206504678793343		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.02206504678793343 | validation: 0.022145199141473643]
	TIME [epoch: 13 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018543769363588303		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.018543769363588303 | validation: 0.023928995807609845]
	TIME [epoch: 12.9 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020962528411965223		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.020962528411965223 | validation: 0.034337075828222006]
	TIME [epoch: 12.9 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023090633006357147		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.023090633006357147 | validation: 0.02909438650186015]
	TIME [epoch: 13 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018878270466679573		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.018878270466679573 | validation: 0.03911470417899166]
	TIME [epoch: 13 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021148566569207095		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.021148566569207095 | validation: 0.023528045131020754]
	TIME [epoch: 12.9 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022647458139910537		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.022647458139910537 | validation: 0.031717052820048316]
	TIME [epoch: 13 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022737535919592676		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.022737535919592676 | validation: 0.033476039200590176]
	TIME [epoch: 13 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024066202242802905		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.024066202242802905 | validation: 0.03216650170242911]
	TIME [epoch: 13 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021902747947154355		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.021902747947154355 | validation: 0.028700608043261196]
	TIME [epoch: 13 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025796779777992905		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.025796779777992905 | validation: 0.035760887409940684]
	TIME [epoch: 13 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026482363903616468		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.026482363903616468 | validation: 0.039811516607980595]
	TIME [epoch: 13 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023814136794922745		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.023814136794922745 | validation: 0.0319548307623237]
	TIME [epoch: 12.9 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02607534804809815		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.02607534804809815 | validation: 0.03477566252046545]
	TIME [epoch: 13 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02348454906823315		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.02348454906823315 | validation: 0.028562696116586763]
	TIME [epoch: 13 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018365777702767476		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.018365777702767476 | validation: 0.02283483453296256]
	TIME [epoch: 13 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01807604938060158		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.01807604938060158 | validation: 0.027262342962943182]
	TIME [epoch: 13 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014871419892192855		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.014871419892192855 | validation: 0.023115704284380475]
	TIME [epoch: 13 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016275302999649514		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.016275302999649514 | validation: 0.021644633146071054]
	TIME [epoch: 13 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02178650003773039		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.02178650003773039 | validation: 0.029857377508170843]
	TIME [epoch: 13 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0176297270356994		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.0176297270356994 | validation: 0.027418346123584236]
	TIME [epoch: 13 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02174163360081112		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.02174163360081112 | validation: 0.029111931465836405]
	TIME [epoch: 13 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021731214740046623		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.021731214740046623 | validation: 0.0142050538196584]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_1170.pth
	Model improved!!!
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017296455638253345		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.017296455638253345 | validation: 0.025124154321594698]
	TIME [epoch: 13 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017814353038889875		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.017814353038889875 | validation: 0.0162349886026782]
	TIME [epoch: 13 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020547434887969673		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.020547434887969673 | validation: 0.020703480512143563]
	TIME [epoch: 13 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015585180485876772		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.015585180485876772 | validation: 0.02830132014519]
	TIME [epoch: 13 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015084891631012143		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.015084891631012143 | validation: 0.027221816772989106]
	TIME [epoch: 12.9 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015080275375296354		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.015080275375296354 | validation: 0.02474818791814493]
	TIME [epoch: 13 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015076704749013991		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.015076704749013991 | validation: 0.030404322443989284]
	TIME [epoch: 12.9 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01776628040429308		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.01776628040429308 | validation: 0.01717389661459195]
	TIME [epoch: 13 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019325642507802176		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.019325642507802176 | validation: 0.028680641730325203]
	TIME [epoch: 12.9 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017810947625308757		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.017810947625308757 | validation: 0.020898363508585552]
	TIME [epoch: 13 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02154776018608829		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.02154776018608829 | validation: 0.04726856823099952]
	TIME [epoch: 12.9 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029832513653562126		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.029832513653562126 | validation: 0.040637942363896846]
	TIME [epoch: 12.9 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03613409440677781		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.03613409440677781 | validation: 0.03766372853456248]
	TIME [epoch: 13 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029381600668796234		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.029381600668796234 | validation: 0.03293706711603318]
	TIME [epoch: 13 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026901435798639177		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.026901435798639177 | validation: 0.03551146357386207]
	TIME [epoch: 12.9 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021595886342652783		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.021595886342652783 | validation: 0.02876275683108328]
	TIME [epoch: 13 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023313286274932676		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.023313286274932676 | validation: 0.035255777065952065]
	TIME [epoch: 13 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018732043035184245		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.018732043035184245 | validation: 0.02307644899370244]
	TIME [epoch: 12.9 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02237633735435715		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.02237633735435715 | validation: 0.02786938868985339]
	TIME [epoch: 12.9 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018601643272286375		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.018601643272286375 | validation: 0.02964511259094791]
	TIME [epoch: 12.9 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01847973421670745		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.01847973421670745 | validation: 0.03665139165652697]
	TIME [epoch: 13 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015292564146162226		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.015292564146162226 | validation: 0.02381645981128419]
	TIME [epoch: 12.9 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01616600267177864		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.01616600267177864 | validation: 0.02358754599736612]
	TIME [epoch: 12.9 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016107194632563004		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.016107194632563004 | validation: 0.02098073429700193]
	TIME [epoch: 13 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014861607685377087		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.014861607685377087 | validation: 0.011921713647925132]
	TIME [epoch: 12.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_1195.pth
	Model improved!!!
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013251932788670873		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.013251932788670873 | validation: 0.0262272843337822]
	TIME [epoch: 12.9 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013998723250828423		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.013998723250828423 | validation: 0.025311456990954575]
	TIME [epoch: 12.9 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017493019136103648		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.017493019136103648 | validation: 0.03374234809020304]
	TIME [epoch: 13 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015426555863932403		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.015426555863932403 | validation: 0.028005481683412627]
	TIME [epoch: 12.9 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01681978145380634		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.01681978145380634 | validation: 0.020148850707684757]
	TIME [epoch: 12.9 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014857884667026106		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.014857884667026106 | validation: 0.0221883757132747]
	TIME [epoch: 13 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01848618837058744		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.01848618837058744 | validation: 0.02060754246012684]
	TIME [epoch: 12.9 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0160796017624226		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.0160796017624226 | validation: 0.031020933516574093]
	TIME [epoch: 12.9 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016273302194811448		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.016273302194811448 | validation: 0.030581523192617324]
	TIME [epoch: 12.9 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016410057874120407		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.016410057874120407 | validation: 0.02497727375511502]
	TIME [epoch: 13 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017539919424526658		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.017539919424526658 | validation: 0.030230972592830238]
	TIME [epoch: 12.9 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018300097074669376		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.018300097074669376 | validation: 0.02229096810874883]
	TIME [epoch: 12.9 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01556525188868574		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.01556525188868574 | validation: 0.01923264614445203]
	TIME [epoch: 13 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013927812902688148		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.013927812902688148 | validation: 0.023001221640125004]
	TIME [epoch: 12.9 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023042613100817018		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.023042613100817018 | validation: 0.02181918791444635]
	TIME [epoch: 12.9 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019634238226076628		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.019634238226076628 | validation: 0.02709301261901271]
	TIME [epoch: 12.9 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022361967732648938		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.022361967732648938 | validation: 0.027315930988812957]
	TIME [epoch: 13 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016856196478622604		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.016856196478622604 | validation: 0.03290107727954553]
	TIME [epoch: 12.9 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024500447021304043		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.024500447021304043 | validation: 0.030009563227308737]
	TIME [epoch: 12.9 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021390226640522543		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.021390226640522543 | validation: 0.020029677149961733]
	TIME [epoch: 12.9 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016967914120131596		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.016967914120131596 | validation: 0.026396609230915836]
	TIME [epoch: 13 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016347797694831426		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.016347797694831426 | validation: 0.019524691671300293]
	TIME [epoch: 12.9 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020805554796986085		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.020805554796986085 | validation: 0.027919073218986283]
	TIME [epoch: 12.9 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020208014056036474		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.020208014056036474 | validation: 0.029156737308306986]
	TIME [epoch: 13 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023668413098855128		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.023668413098855128 | validation: 0.027877645327106453]
	TIME [epoch: 13 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020239070109279042		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.020239070109279042 | validation: 0.038010105730527974]
	TIME [epoch: 12.9 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019367819193042493		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.019367819193042493 | validation: 0.03414667123489099]
	TIME [epoch: 12.9 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01838565310512881		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.01838565310512881 | validation: 0.028806840516812707]
	TIME [epoch: 13 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017119083313520505		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.017119083313520505 | validation: 0.024695228669218933]
	TIME [epoch: 12.9 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01808198177341193		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.01808198177341193 | validation: 0.022485618634319905]
	TIME [epoch: 12.9 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012965662798878348		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.012965662798878348 | validation: 0.03367246301199814]
	TIME [epoch: 13 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019137212386468788		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.019137212386468788 | validation: 0.03877615820686106]
	TIME [epoch: 12.9 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026144419260557127		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.026144419260557127 | validation: 0.03909652121339872]
	TIME [epoch: 12.9 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0302590538434687		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.0302590538434687 | validation: 0.041174144540841125]
	TIME [epoch: 12.9 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025224128212653133		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.025224128212653133 | validation: 0.03561150335326393]
	TIME [epoch: 13 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0239583257347741		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.0239583257347741 | validation: 0.034001902081756505]
	TIME [epoch: 12.9 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023724867484185865		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.023724867484185865 | validation: 0.04103370589899631]
	TIME [epoch: 12.9 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02525473040681859		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.02525473040681859 | validation: 0.029062110134390088]
	TIME [epoch: 13 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02490988121841327		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.02490988121841327 | validation: 0.026938752309475695]
	TIME [epoch: 12.9 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0210451617186275		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.0210451617186275 | validation: 0.03337538315136099]
	TIME [epoch: 12.9 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01711755330339196		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.01711755330339196 | validation: 0.02456155994282444]
	TIME [epoch: 12.9 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015097256894929464		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.015097256894929464 | validation: 0.020938709642731163]
	TIME [epoch: 13 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018291928879528414		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.018291928879528414 | validation: 0.03231688325033045]
	TIME [epoch: 12.9 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016047573988485064		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.016047573988485064 | validation: 0.02968707073073257]
	TIME [epoch: 12.9 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02120418210409078		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.02120418210409078 | validation: 0.018801434146843564]
	TIME [epoch: 12.9 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021354824365733476		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.021354824365733476 | validation: 0.026958622938494454]
	TIME [epoch: 13 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016207243754926243		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.016207243754926243 | validation: 0.02939965382919554]
	TIME [epoch: 12.9 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021940273885313468		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.021940273885313468 | validation: 0.022866991018198876]
	TIME [epoch: 12.9 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016820600785651476		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.016820600785651476 | validation: 0.02165752074561696]
	TIME [epoch: 13 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020072789778688635		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.020072789778688635 | validation: 0.033906816337667775]
	TIME [epoch: 12.9 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026400355516074937		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.026400355516074937 | validation: 0.03144917173980321]
	TIME [epoch: 12.9 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025332825751228485		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.025332825751228485 | validation: 0.017065187049161126]
	TIME [epoch: 12.9 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018314756265263157		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.018314756265263157 | validation: 0.02469706985315497]
	TIME [epoch: 13 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01592359747096011		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.01592359747096011 | validation: 0.017623848996696757]
	TIME [epoch: 12.9 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016974443016731032		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.016974443016731032 | validation: 0.028717843790986627]
	TIME [epoch: 12.9 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02086130087039323		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.02086130087039323 | validation: 0.02477476342435802]
	TIME [epoch: 13 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018694517641870707		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.018694517641870707 | validation: 0.02039670094891016]
	TIME [epoch: 12.9 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014772562772138561		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.014772562772138561 | validation: 0.03017078966706013]
	TIME [epoch: 12.9 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012112891010132996		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.012112891010132996 | validation: 0.027759875761868384]
	TIME [epoch: 12.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016433480533976738		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.016433480533976738 | validation: 0.03013936370832333]
	TIME [epoch: 13 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01857196771838481		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.01857196771838481 | validation: 0.03821919497938785]
	TIME [epoch: 12.9 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02199524063908786		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.02199524063908786 | validation: 0.02544400498001168]
	TIME [epoch: 12.9 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016809885706612158		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.016809885706612158 | validation: 0.01943257414422495]
	TIME [epoch: 13 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019083362674147838		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.019083362674147838 | validation: 0.03163056597024268]
	TIME [epoch: 12.9 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012435129153780288		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.012435129153780288 | validation: 0.03321117432560972]
	TIME [epoch: 12.9 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017239112380484454		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.017239112380484454 | validation: 0.027149492251742482]
	TIME [epoch: 12.9 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017686731317111015		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.017686731317111015 | validation: 0.028440585448364388]
	TIME [epoch: 13 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015530123386378634		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.015530123386378634 | validation: 0.018607866958627647]
	TIME [epoch: 12.9 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01095517292999136		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.01095517292999136 | validation: 0.026508030423806766]
	TIME [epoch: 12.9 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012920359199281726		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.012920359199281726 | validation: 0.023525515517993055]
	TIME [epoch: 13 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016665722791605334		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.016665722791605334 | validation: 0.027082078677473313]
	TIME [epoch: 13 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02352806610696722		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.02352806610696722 | validation: 0.03907477029736805]
	TIME [epoch: 12.9 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021884810475494537		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.021884810475494537 | validation: 0.03460788517368719]
	TIME [epoch: 12.9 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020093660445214535		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.020093660445214535 | validation: 0.03431833931809414]
	TIME [epoch: 13 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019315330497685773		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.019315330497685773 | validation: 0.03638110070832473]
	TIME [epoch: 12.9 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02544971122766463		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.02544971122766463 | validation: 0.03259668324794966]
	TIME [epoch: 12.9 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028311942424426147		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.028311942424426147 | validation: 0.04644641983851732]
	TIME [epoch: 12.9 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027976674856881947		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.027976674856881947 | validation: 0.03960665619811219]
	TIME [epoch: 13 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024833899957444876		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.024833899957444876 | validation: 0.029585701878870888]
	TIME [epoch: 12.9 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022509855917962573		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.022509855917962573 | validation: 0.03249223900553276]
	TIME [epoch: 12.9 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019289542479066682		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.019289542479066682 | validation: 0.03199429939815676]
	TIME [epoch: 13 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01894975976379833		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.01894975976379833 | validation: 0.025642822857340066]
	TIME [epoch: 12.9 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019150384326665125		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.019150384326665125 | validation: 0.02761547600435804]
	TIME [epoch: 12.9 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016786594471701225		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.016786594471701225 | validation: 0.03243199366761506]
	TIME [epoch: 12.9 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021595616033819712		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.021595616033819712 | validation: 0.02998173707432475]
	TIME [epoch: 13 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021605921320605223		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.021605921320605223 | validation: 0.03503631111256171]
	TIME [epoch: 12.9 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017614955107806127		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.017614955107806127 | validation: 0.03845810661675086]
	TIME [epoch: 12.9 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013751589660256958		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.013751589660256958 | validation: 0.022445154360458377]
	TIME [epoch: 13 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016635659441923294		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.016635659441923294 | validation: 0.01952176343913393]
	TIME [epoch: 12.9 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015155428444790224		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.015155428444790224 | validation: 0.031337724367362]
	TIME [epoch: 12.9 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0204471099971788		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.0204471099971788 | validation: 0.04108268350220388]
	TIME [epoch: 12.9 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02267413040677272		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.02267413040677272 | validation: 0.03529422863790818]
	TIME [epoch: 13 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019547361388381604		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.019547361388381604 | validation: 0.036318212692672554]
	TIME [epoch: 12.9 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019178286669666752		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.019178286669666752 | validation: 0.026733133897268696]
	TIME [epoch: 12.9 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02927402936767068		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.02927402936767068 | validation: 0.04391600662523055]
	TIME [epoch: 13 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02440883100233058		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.02440883100233058 | validation: 0.0329576820848684]
	TIME [epoch: 12.9 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02893756775630875		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.02893756775630875 | validation: 0.03905013662871189]
	TIME [epoch: 12.9 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023392748259757547		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.023392748259757547 | validation: 0.03631910716114989]
	TIME [epoch: 12.9 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027941739339515527		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.027941739339515527 | validation: 0.045111825881775564]
	TIME [epoch: 13 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029266197096994632		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.029266197096994632 | validation: 0.04220145329725548]
	TIME [epoch: 12.9 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03124553584633432		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.03124553584633432 | validation: 0.03975818500579623]
	TIME [epoch: 12.9 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02672638098590385		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.02672638098590385 | validation: 0.03786919552559951]
	TIME [epoch: 12.9 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028291377995189056		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.028291377995189056 | validation: 0.037317220042134204]
	TIME [epoch: 13 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030626369154948523		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.030626369154948523 | validation: 0.039668469445608597]
	TIME [epoch: 12.9 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027722649000827784		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.027722649000827784 | validation: 0.028749432059729314]
	TIME [epoch: 12.9 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024443580401147236		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.024443580401147236 | validation: 0.036221329041194454]
	TIME [epoch: 13 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022316074026189046		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.022316074026189046 | validation: 0.03948612825959611]
	TIME [epoch: 12.9 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02874367543922681		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.02874367543922681 | validation: 0.050035932757678425]
	TIME [epoch: 12.9 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02933194127342862		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.02933194127342862 | validation: 0.04465730823221337]
	TIME [epoch: 12.9 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031794392304309894		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.031794392304309894 | validation: 0.03771273160491076]
	TIME [epoch: 13 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028628445940413902		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.028628445940413902 | validation: 0.03445114922458211]
	TIME [epoch: 12.9 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027178011749827542		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.027178011749827542 | validation: 0.039840793436885805]
	TIME [epoch: 12.9 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025659290427073538		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.025659290427073538 | validation: 0.03244107363296188]
	TIME [epoch: 13 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02181988615808022		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.02181988615808022 | validation: 0.02853816175215881]
	TIME [epoch: 12.9 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017779892998140524		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.017779892998140524 | validation: 0.024871777318552928]
	TIME [epoch: 12.9 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020254154471597438		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.020254154471597438 | validation: 0.028121315875757672]
	TIME [epoch: 12.9 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016730196668394932		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.016730196668394932 | validation: 0.0296721511993472]
	TIME [epoch: 13 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02030142690613266		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.02030142690613266 | validation: 0.037743684890308236]
	TIME [epoch: 12.9 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026160957231249265		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.026160957231249265 | validation: 0.0363639305689581]
	TIME [epoch: 12.9 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029692616336544318		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.029692616336544318 | validation: 0.045324731699273556]
	TIME [epoch: 13 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024927968445990767		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.024927968445990767 | validation: 0.03813347078890285]
	TIME [epoch: 12.9 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0276611323306298		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.0276611323306298 | validation: 0.04124408907947346]
	TIME [epoch: 12.9 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029423153889179918		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.029423153889179918 | validation: 0.04637922083089634]
	TIME [epoch: 12.9 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03305632730801339		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.03305632730801339 | validation: 0.049335820781986735]
	TIME [epoch: 13 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02990775762015154		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.02990775762015154 | validation: 0.039821479648591604]
	TIME [epoch: 12.9 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03093430875302318		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.03093430875302318 | validation: 0.041411369410660655]
	TIME [epoch: 12.9 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030178435664203807		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.030178435664203807 | validation: 0.04454726182645617]
	TIME [epoch: 12.9 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02507479017646375		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.02507479017646375 | validation: 0.03436992169128834]
	TIME [epoch: 13 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02319188275024814		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.02319188275024814 | validation: 0.027522045550450187]
	TIME [epoch: 12.9 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020095215378140515		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.020095215378140515 | validation: 0.03390854229876258]
	TIME [epoch: 12.9 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024047634641360362		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.024047634641360362 | validation: 0.028381747389043876]
	TIME [epoch: 13 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021261591741460587		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.021261591741460587 | validation: 0.018558364327440093]
	TIME [epoch: 13 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015091175470110955		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.015091175470110955 | validation: 0.03063882741341212]
	TIME [epoch: 12.9 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02121328766536621		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.02121328766536621 | validation: 0.025075225889192802]
	TIME [epoch: 12.9 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01903292494982518		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.01903292494982518 | validation: 0.03368952105435319]
	TIME [epoch: 13 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01945017956103178		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.01945017956103178 | validation: 0.015723246436152912]
	TIME [epoch: 12.9 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015982675571685014		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.015982675571685014 | validation: 0.025627911535988514]
	TIME [epoch: 12.9 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016290206556905613		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.016290206556905613 | validation: 0.023105865415982772]
	TIME [epoch: 13 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01753964478683046		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.01753964478683046 | validation: 0.02757782841425303]
	TIME [epoch: 12.9 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016228944916531905		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.016228944916531905 | validation: 0.031030761537331433]
	TIME [epoch: 13 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01817568503962075		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.01817568503962075 | validation: 0.026619559042690345]
	TIME [epoch: 12.9 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02168123261101029		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.02168123261101029 | validation: 0.03276963282138746]
	TIME [epoch: 13 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019252071808504096		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.019252071808504096 | validation: 0.02023861197438234]
	TIME [epoch: 12.9 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014800812097288027		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.014800812097288027 | validation: 0.027939537477256037]
	TIME [epoch: 13 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016186049282432904		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.016186049282432904 | validation: 0.02542719334158134]
	TIME [epoch: 13 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017848683779434393		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.017848683779434393 | validation: 0.020856767352386948]
	TIME [epoch: 12.9 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016810824497433426		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.016810824497433426 | validation: 0.02684899268010389]
	TIME [epoch: 12.9 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01521387409074527		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.01521387409074527 | validation: 0.013660521986512825]
	TIME [epoch: 12.9 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017873492785083725		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.017873492785083725 | validation: 0.036624801211993185]
	TIME [epoch: 13 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018044900801730407		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.018044900801730407 | validation: 0.026139513538915384]
	TIME [epoch: 12.9 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0188664431850744		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.0188664431850744 | validation: 0.030185413946964786]
	TIME [epoch: 13 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018148715150157407		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.018148715150157407 | validation: 0.02802491838313665]
	TIME [epoch: 12.9 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022511706118285204		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.022511706118285204 | validation: 0.030188606955894332]
	TIME [epoch: 13 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020312756112404715		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.020312756112404715 | validation: 0.025247984013601798]
	TIME [epoch: 13 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015359899449671092		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.015359899449671092 | validation: 0.029831521995708602]
	TIME [epoch: 12.9 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020612078802734145		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.020612078802734145 | validation: 0.024503942353680218]
	TIME [epoch: 13 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018714438192158723		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.018714438192158723 | validation: 0.021013138284760917]
	TIME [epoch: 12.9 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016975401416225496		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.016975401416225496 | validation: 0.023461811657554003]
	TIME [epoch: 12.9 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016391434488455217		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.016391434488455217 | validation: 0.019700123179197233]
	TIME [epoch: 12.9 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017713676761784383		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.017713676761784383 | validation: 0.026007046087687308]
	TIME [epoch: 13 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0160553803539038		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.0160553803539038 | validation: 0.024596806216098065]
	TIME [epoch: 12.9 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01615489158442075		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.01615489158442075 | validation: 0.024920677563525388]
	TIME [epoch: 12.9 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017751982257368206		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.017751982257368206 | validation: 0.027209906052893227]
	TIME [epoch: 13 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01840598729194298		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.01840598729194298 | validation: 0.026551928028960118]
	TIME [epoch: 12.9 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014365046671858322		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.014365046671858322 | validation: 0.03525975983766266]
	TIME [epoch: 12.9 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017439502593630356		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.017439502593630356 | validation: 0.013344370765853226]
	TIME [epoch: 12.9 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018522050029658847		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.018522050029658847 | validation: 0.019304814954562873]
	TIME [epoch: 13 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017971141113703574		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.017971141113703574 | validation: 0.03384120988343655]
	TIME [epoch: 12.9 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0146175353093977		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.0146175353093977 | validation: 0.022237292641794932]
	TIME [epoch: 12.9 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019931313506995334		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.019931313506995334 | validation: 0.031776808763689955]
	TIME [epoch: 13 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019049166787182		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.019049166787182 | validation: 0.0222219844406804]
	TIME [epoch: 12.9 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016630463019931783		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.016630463019931783 | validation: 0.03767323279437078]
	TIME [epoch: 12.9 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01982404410182737		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.01982404410182737 | validation: 0.03443278819251502]
	TIME [epoch: 12.9 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017176433795829112		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.017176433795829112 | validation: 0.028477419894779966]
	TIME [epoch: 13 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01681273048410209		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.01681273048410209 | validation: 0.030242579833790587]
	TIME [epoch: 13 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02127579657195986		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.02127579657195986 | validation: 0.02631695302711762]
	TIME [epoch: 12.9 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020966311743514696		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.020966311743514696 | validation: 0.029247284043373904]
	TIME [epoch: 12.9 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0200310403091842		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.0200310403091842 | validation: 0.027918083882722183]
	TIME [epoch: 13 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017505971793003578		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.017505971793003578 | validation: 0.0318109347135686]
	TIME [epoch: 13 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01989073093101104		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.01989073093101104 | validation: 0.031176107153067477]
	TIME [epoch: 12.9 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01684486369888668		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.01684486369888668 | validation: 0.017868373984105915]
	TIME [epoch: 13 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01642498714998094		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.01642498714998094 | validation: 0.024205301938199256]
	TIME [epoch: 13 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018568824566420474		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.018568824566420474 | validation: 0.020828541913667925]
	TIME [epoch: 12.9 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014312131511207249		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.014312131511207249 | validation: 0.02418409996966402]
	TIME [epoch: 13 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01528586218352291		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.01528586218352291 | validation: 0.026332140423767778]
	TIME [epoch: 13 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015620399001923774		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.015620399001923774 | validation: 0.024475742555309078]
	TIME [epoch: 13 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022074326641414274		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.022074326641414274 | validation: 0.024082314636838374]
	TIME [epoch: 13 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014081347126270911		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.014081347126270911 | validation: 0.03036056786175012]
	TIME [epoch: 13 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018931952453096625		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.018931952453096625 | validation: 0.022656425722771857]
	TIME [epoch: 12.9 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01761162804330474		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.01761162804330474 | validation: 0.026288985673116078]
	TIME [epoch: 13 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018305245172291797		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.018305245172291797 | validation: 0.020462886177615224]
	TIME [epoch: 13 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01799509356635131		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.01799509356635131 | validation: 0.028756832859943272]
	TIME [epoch: 13 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020538633399159383		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.020538633399159383 | validation: 0.03722208878152464]
	TIME [epoch: 13 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019338334240056248		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.019338334240056248 | validation: 0.027607092805752673]
	TIME [epoch: 13 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020998302750840487		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.020998302750840487 | validation: 0.03310910343892696]
	TIME [epoch: 13 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022543167256429245		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.022543167256429245 | validation: 0.02793757795268939]
	TIME [epoch: 13 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018845528951823502		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.018845528951823502 | validation: 0.020661342253453643]
	TIME [epoch: 12.9 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021762215670272082		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.021762215670272082 | validation: 0.03241155980381702]
	TIME [epoch: 13 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02107832314612646		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.02107832314612646 | validation: 0.02530244520701319]
	TIME [epoch: 13 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017366710100967346		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.017366710100967346 | validation: 0.028262547601217998]
	TIME [epoch: 12.9 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01636471709075442		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.01636471709075442 | validation: 0.023227947684377394]
	TIME [epoch: 13 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011607982819817831		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.011607982819817831 | validation: 0.020319965840875028]
	TIME [epoch: 13 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01756484567085517		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.01756484567085517 | validation: 0.021993621708208618]
	TIME [epoch: 13 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017398220389352622		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.017398220389352622 | validation: 0.028618478553520604]
	TIME [epoch: 12.9 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014804169649901899		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.014804169649901899 | validation: 0.022019626216955298]
	TIME [epoch: 13 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013723448563952885		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.013723448563952885 | validation: 0.03298163821603679]
	TIME [epoch: 13 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01808682044405848		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.01808682044405848 | validation: 0.01691415083353718]
	TIME [epoch: 13 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0175764150853419		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.0175764150853419 | validation: 0.020409853772022854]
	TIME [epoch: 12.9 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01756375758931615		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.01756375758931615 | validation: 0.025039611718367178]
	TIME [epoch: 13 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01767303479656784		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.01767303479656784 | validation: 0.03530299118788551]
	TIME [epoch: 13 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018980943121252924		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.018980943121252924 | validation: 0.018881824837623663]
	TIME [epoch: 13 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017866101762183388		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.017866101762183388 | validation: 0.024702412769670074]
	TIME [epoch: 12.9 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017410702112145147		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.017410702112145147 | validation: 0.03173770565876371]
	TIME [epoch: 13 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01883748791436151		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.01883748791436151 | validation: 0.03040566857819349]
	TIME [epoch: 12.9 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019845109258823233		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.019845109258823233 | validation: 0.025374178831525835]
	TIME [epoch: 12.9 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020363686608933618		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.020363686608933618 | validation: 0.02836274619377213]
	TIME [epoch: 12.9 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018981135401343094		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.018981135401343094 | validation: 0.02090735125649882]
	TIME [epoch: 13 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0203071295314529		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.0203071295314529 | validation: 0.03015638745909894]
	TIME [epoch: 12.9 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017047626718323307		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.017047626718323307 | validation: 0.022125606898090712]
	TIME [epoch: 12.9 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019080506067622967		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.019080506067622967 | validation: 0.02628926166025613]
	TIME [epoch: 13 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016275241311916468		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.016275241311916468 | validation: 0.025998558616646364]
	TIME [epoch: 12.9 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021070697011713668		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.021070697011713668 | validation: 0.026743988460231096]
	TIME [epoch: 12.9 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01789745595874358		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.01789745595874358 | validation: 0.02753077094196018]
	TIME [epoch: 12.9 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01985816720092852		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.01985816720092852 | validation: 0.02889078097740295]
	TIME [epoch: 13 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021470867729717968		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.021470867729717968 | validation: 0.02442299838715079]
	TIME [epoch: 12.9 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022259890441086415		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.022259890441086415 | validation: 0.041843971591060396]
	TIME [epoch: 12.9 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02528667809527447		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.02528667809527447 | validation: 0.0342974545964412]
	TIME [epoch: 13 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023821537170909138		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.023821537170909138 | validation: 0.028762847794757396]
	TIME [epoch: 12.9 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021415881206531165		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.021415881206531165 | validation: 0.028756338182371444]
	TIME [epoch: 12.9 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020123809650554377		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.020123809650554377 | validation: 0.034871077685069245]
	TIME [epoch: 12.9 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020707544922159878		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.020707544922159878 | validation: 0.030068645223680326]
	TIME [epoch: 13 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01725542687769286		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.01725542687769286 | validation: 0.02594222788877149]
	TIME [epoch: 12.9 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017380216456025274		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.017380216456025274 | validation: 0.033175633370295235]
	TIME [epoch: 12.9 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017094981990341346		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.017094981990341346 | validation: 0.024547157939134628]
	TIME [epoch: 12.9 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019303707799407478		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.019303707799407478 | validation: 0.02704059940282553]
	TIME [epoch: 13 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01501977877637448		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.01501977877637448 | validation: 0.025630336657265357]
	TIME [epoch: 12.9 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01654572048365313		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.01654572048365313 | validation: 0.03160200480137781]
	TIME [epoch: 12.9 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014601564180258517		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.014601564180258517 | validation: 0.02350627702513494]
	TIME [epoch: 13 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012878440503874855		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.012878440503874855 | validation: 0.021146771523681974]
	TIME [epoch: 13 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014676040876247999		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.014676040876247999 | validation: 0.018895917965812307]
	TIME [epoch: 13 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014350902126948064		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.014350902126948064 | validation: 0.02129896918649515]
	TIME [epoch: 12.9 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014935886518849858		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.014935886518849858 | validation: 0.010662264626679699]
	TIME [epoch: 13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240309_135637/states/model_tr_study4_1437.pth
	Model improved!!!
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0161467364941011		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.0161467364941011 | validation: 0.021062427882394617]
	TIME [epoch: 13 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01580367456248876		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.01580367456248876 | validation: 0.024644527975115772]
	TIME [epoch: 12.9 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01314577957771226		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.01314577957771226 | validation: 0.025313415436810295]
	TIME [epoch: 13 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014351121514454649		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.014351121514454649 | validation: 0.024385083074741735]
	TIME [epoch: 12.9 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015243157865891803		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.015243157865891803 | validation: 0.01851583776956681]
	TIME [epoch: 12.9 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014612481832111241		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.014612481832111241 | validation: 0.02006228932763167]
	TIME [epoch: 12.9 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014639195382627567		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.014639195382627567 | validation: 0.019213441748769832]
	TIME [epoch: 13 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011377434099128562		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.011377434099128562 | validation: 0.029914843118393254]
	TIME [epoch: 13 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015214028924826596		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.015214028924826596 | validation: 0.020919428956294252]
	TIME [epoch: 12.9 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012161023673184536		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.012161023673184536 | validation: 0.021691001055711073]
	TIME [epoch: 13 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01544209827103235		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.01544209827103235 | validation: 0.023942915320345017]
	TIME [epoch: 12.9 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015029040964490812		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.015029040964490812 | validation: 0.022945037557936927]
	TIME [epoch: 12.9 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02014827199648887		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.02014827199648887 | validation: 0.02467116885100192]
	TIME [epoch: 12.9 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014516342317611043		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.014516342317611043 | validation: 0.02686571226927481]
	TIME [epoch: 13 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014626791972360578		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.014626791972360578 | validation: 0.023599554635443703]
	TIME [epoch: 12.9 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015026225789682955		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.015026225789682955 | validation: 0.024381640926700934]
	TIME [epoch: 12.9 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013842524392397887		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.013842524392397887 | validation: 0.03533201611549131]
	TIME [epoch: 12.9 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017868431570830658		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.017868431570830658 | validation: 0.028704464859462177]
	TIME [epoch: 12.9 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018719107904101157		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.018719107904101157 | validation: 0.02723498510681231]
	TIME [epoch: 12.9 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017310287835921073		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.017310287835921073 | validation: 0.02957816997633313]
	TIME [epoch: 12.9 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01818559922328741		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.01818559922328741 | validation: 0.027145746065140308]
	TIME [epoch: 13 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018721478862966448		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.018721478862966448 | validation: 0.027725256083204516]
	TIME [epoch: 12.9 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01811527948693848		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.01811527948693848 | validation: 0.03523422720965122]
	TIME [epoch: 12.9 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02175145886428165		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.02175145886428165 | validation: 0.023385145735905406]
	TIME [epoch: 12.9 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020429319414464263		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.020429319414464263 | validation: 0.03164768043509567]
	TIME [epoch: 13 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018457032704209717		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.018457032704209717 | validation: 0.028240765231202686]
	TIME [epoch: 12.9 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014266982532007493		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.014266982532007493 | validation: 0.025048535305706977]
	TIME [epoch: 12.9 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018102613580753185		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.018102613580753185 | validation: 0.03092622733779633]
	TIME [epoch: 13 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016648133959137487		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.016648133959137487 | validation: 0.031760513038189615]
	TIME [epoch: 12.9 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015481528716635603		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.015481528716635603 | validation: 0.031426654563112146]
	TIME [epoch: 12.9 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01681843659897447		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.01681843659897447 | validation: 0.030211638067634147]
	TIME [epoch: 12.9 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01927823420141566		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.01927823420141566 | validation: 0.03475992787264929]
	TIME [epoch: 13 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018577568000479716		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.018577568000479716 | validation: 0.024504953056813862]
	TIME [epoch: 12.9 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022357970026500574		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.022357970026500574 | validation: 0.02682880758317969]
	TIME [epoch: 13 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021007219269491933		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.021007219269491933 | validation: 0.024721985954174252]
	TIME [epoch: 13 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018686370841960592		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.018686370841960592 | validation: 0.01625632489468293]
	TIME [epoch: 12.9 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019932631130865935		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.019932631130865935 | validation: 0.03603448123199543]
	TIME [epoch: 12.9 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01977743511229849		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.01977743511229849 | validation: 0.030367048482370644]
	TIME [epoch: 12.9 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01937277282117682		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.01937277282117682 | validation: 0.030177611570267337]
	TIME [epoch: 13 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018664272604407957		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.018664272604407957 | validation: 0.026054492796748693]
	TIME [epoch: 12.9 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019029252306435773		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.019029252306435773 | validation: 0.029565017283840058]
	TIME [epoch: 12.9 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020433451863649112		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.020433451863649112 | validation: 0.031093655617773077]
	TIME [epoch: 13 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016824363751672483		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.016824363751672483 | validation: 0.031749997016789586]
	TIME [epoch: 12.9 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020561106913638754		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.020561106913638754 | validation: 0.02802648258596049]
	TIME [epoch: 12.9 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019357769653126213		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.019357769653126213 | validation: 0.022028802788956775]
	TIME [epoch: 13 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023429418873110962		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.023429418873110962 | validation: 0.028972619094118024]
	TIME [epoch: 13 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018142758561396466		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.018142758561396466 | validation: 0.023608249482230354]
	TIME [epoch: 12.9 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017945650129524867		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.017945650129524867 | validation: 0.027940250627324394]
	TIME [epoch: 12.9 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01731759975799233		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.01731759975799233 | validation: 0.020591484415053884]
	TIME [epoch: 12.9 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015676623505588086		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.015676623505588086 | validation: 0.0224544179529925]
	TIME [epoch: 13 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017579915553169283		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.017579915553169283 | validation: 0.029239543164502772]
	TIME [epoch: 12.9 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011642903035261654		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.011642903035261654 | validation: 0.023196784634984736]
	TIME [epoch: 13 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016215763196020833		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.016215763196020833 | validation: 0.02026773713323266]
	TIME [epoch: 13 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014734698879696112		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.014734698879696112 | validation: 0.018566512486585526]
	TIME [epoch: 13 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015638255144718435		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.015638255144718435 | validation: 0.025252350994650622]
	TIME [epoch: 13 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01532594541798949		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.01532594541798949 | validation: 0.02772540227054529]
	TIME [epoch: 13 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013530456902315066		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.013530456902315066 | validation: 0.0219995800441251]
	TIME [epoch: 13 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01548107829731501		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.01548107829731501 | validation: 0.02623830381005268]
	TIME [epoch: 12.9 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01325093539709481		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.01325093539709481 | validation: 0.019559269702764275]
	TIME [epoch: 12.9 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014164682726212408		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.014164682726212408 | validation: 0.023487119654666287]
	TIME [epoch: 13 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01285075308506263		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.01285075308506263 | validation: 0.026408802103790607]
	TIME [epoch: 12.9 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015898580472019468		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.015898580472019468 | validation: 0.02087700276160085]
	TIME [epoch: 12.9 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018042395874711355		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.018042395874711355 | validation: 0.032341499444915774]
	TIME [epoch: 12.9 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017197376909541887		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.017197376909541887 | validation: 0.027293398390584075]
	TIME [epoch: 13 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018305397346072443		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.018305397346072443 | validation: 0.03051948319895221]
	TIME [epoch: 12.9 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019410347646972304		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.019410347646972304 | validation: 0.014387978120577087]
	TIME [epoch: 12.9 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018689104130633422		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.018689104130633422 | validation: 0.021792585779917797]
	TIME [epoch: 13 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018397358731782613		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.018397358731782613 | validation: 0.02641109884285705]
	TIME [epoch: 12.9 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0186932044274228		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.0186932044274228 | validation: 0.02045651805760862]
	TIME [epoch: 12.9 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021662225975181054		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.021662225975181054 | validation: 0.01625317116918803]
	TIME [epoch: 12.9 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015709565495197492		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.015709565495197492 | validation: 0.030586488330419208]
	TIME [epoch: 13 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01484593165142185		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.01484593165142185 | validation: 0.026395160740073385]
	TIME [epoch: 12.9 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013845213636917124		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.013845213636917124 | validation: 0.02963531749543637]
	TIME [epoch: 12.9 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015040714207948946		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.015040714207948946 | validation: 0.016937178234842556]
	TIME [epoch: 12.9 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01696395159268304		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.01696395159268304 | validation: 0.023084631897912777]
	TIME [epoch: 13 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016489369241437637		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.016489369241437637 | validation: 0.027959232084244137]
	TIME [epoch: 12.9 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013621094135446968		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.013621094135446968 | validation: 0.02876003722156496]
	TIME [epoch: 12.9 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014821774357186646		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.014821774357186646 | validation: 0.02279535842463131]
	TIME [epoch: 13 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015378465887380934		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.015378465887380934 | validation: 0.027434257363954277]
	TIME [epoch: 12.9 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017990277620733824		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.017990277620733824 | validation: 0.018888662824088662]
	TIME [epoch: 12.9 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017653651906327818		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.017653651906327818 | validation: 0.02331040104472104]
	TIME [epoch: 12.9 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017474278293884687		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.017474278293884687 | validation: 0.023959999729081]
	TIME [epoch: 13 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011370685202862801		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.011370685202862801 | validation: 0.022506715177303373]
	TIME [epoch: 12.9 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01349378421151074		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.01349378421151074 | validation: 0.020983670158630403]
	TIME [epoch: 12.9 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01426339102209131		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.01426339102209131 | validation: 0.02475996139414079]
	TIME [epoch: 13 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015435689912896051		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.015435689912896051 | validation: 0.02683233405182908]
	TIME [epoch: 12.9 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014497927174074162		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.014497927174074162 | validation: 0.014177588521606773]
	TIME [epoch: 12.9 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01327207146310869		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.01327207146310869 | validation: 0.025403156951087066]
	TIME [epoch: 12.9 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01588093662944368		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.01588093662944368 | validation: 0.026092485248170424]
	TIME [epoch: 13 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01506003645027113		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.01506003645027113 | validation: 0.023495190016590166]
	TIME [epoch: 12.9 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02001134070517406		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.02001134070517406 | validation: 0.03320200370658287]
	TIME [epoch: 12.9 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018366550239095822		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.018366550239095822 | validation: 0.025346685183451293]
	TIME [epoch: 12.9 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018644641942179175		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.018644641942179175 | validation: 0.01789472036396483]
	TIME [epoch: 12.9 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018769350973655896		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.018769350973655896 | validation: 0.017928550259132175]
	TIME [epoch: 12.9 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019422897762225888		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.019422897762225888 | validation: 0.02730707245097938]
	TIME [epoch: 13 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014630680699882114		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.014630680699882114 | validation: 0.025288510893991964]
	TIME [epoch: 13 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014364308383352117		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.014364308383352117 | validation: 0.022609707741231402]
	TIME [epoch: 12.9 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017307352052609942		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.017307352052609942 | validation: 0.03374265030031368]
	TIME [epoch: 12.9 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015165183632939581		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.015165183632939581 | validation: 0.02758979344595841]
	TIME [epoch: 12.9 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019483465825755195		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.019483465825755195 | validation: 0.02930761858555692]
	TIME [epoch: 13 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016193108766453627		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.016193108766453627 | validation: 0.02265495717529286]
	TIME [epoch: 12.9 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015230532719119358		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.015230532719119358 | validation: 0.02734066674495198]
	TIME [epoch: 12.9 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016573279358185127		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.016573279358185127 | validation: 0.03227404170774862]
	TIME [epoch: 13 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01768119378077471		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.01768119378077471 | validation: 0.028654285303599654]
	TIME [epoch: 13 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018025835547663592		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.018025835547663592 | validation: 0.021005722632904424]
	TIME [epoch: 13 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014947820147703189		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.014947820147703189 | validation: 0.03170701045069887]
	TIME [epoch: 13 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01771475561074278		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.01771475561074278 | validation: 0.02065120142871319]
	TIME [epoch: 13 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018809413419213276		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.018809413419213276 | validation: 0.026249546659896855]
	TIME [epoch: 12.9 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01943853619474483		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.01943853619474483 | validation: 0.028718460430725037]
	TIME [epoch: 13 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01335940681980517		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.01335940681980517 | validation: 0.019128000139274653]
	TIME [epoch: 13 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011904144354599168		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.011904144354599168 | validation: 0.02015662609906343]
	TIME [epoch: 13 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015337614569253692		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.015337614569253692 | validation: 0.027405992571872186]
	TIME [epoch: 12.9 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016413389459007468		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.016413389459007468 | validation: 0.029235167102814926]
	TIME [epoch: 13 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01756359019222649		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.01756359019222649 | validation: 0.018141177332509334]
	TIME [epoch: 13 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013868900007649171		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.013868900007649171 | validation: 0.02563210179263094]
	TIME [epoch: 13 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018369728869088338		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.018369728869088338 | validation: 0.028695585810960572]
	TIME [epoch: 13 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013074024057342024		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.013074024057342024 | validation: 0.03339408454213352]
	TIME [epoch: 13 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010426069509285608		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.010426069509285608 | validation: 0.02672170702714393]
	TIME [epoch: 12.9 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016063022838398226		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.016063022838398226 | validation: 0.023975723288556]
	TIME [epoch: 13 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016986509116858586		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.016986509116858586 | validation: 0.02579496934132725]
	TIME [epoch: 12.9 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01576448504569155		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.01576448504569155 | validation: 0.032874627455012836]
	TIME [epoch: 13 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01589703063789749		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.01589703063789749 | validation: 0.02545298508048003]
	TIME [epoch: 12.9 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023204096099765932		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.023204096099765932 | validation: 0.026898520064371628]
	TIME [epoch: 12.9 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01546473706303941		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.01546473706303941 | validation: 0.028734268464903834]
	TIME [epoch: 13 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018069237793258593		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.018069237793258593 | validation: 0.027936036180163465]
	TIME [epoch: 12.9 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015660099451255727		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.015660099451255727 | validation: 0.028284617263006427]
	TIME [epoch: 12.9 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020828464225109998		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.020828464225109998 | validation: 0.029827362459732776]
	TIME [epoch: 12.9 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020568854629398357		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.020568854629398357 | validation: 0.026771089471467197]
	TIME [epoch: 13 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015494548829888884		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.015494548829888884 | validation: 0.025499523560641096]
	TIME [epoch: 12.9 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017740364090899786		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.017740364090899786 | validation: 0.02500707026339774]
	TIME [epoch: 13 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015322057282089432		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.015322057282089432 | validation: 0.02548684324459945]
	TIME [epoch: 12.9 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01614585572313407		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.01614585572313407 | validation: 0.03185983224435773]
	TIME [epoch: 13 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015514289038315643		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.015514289038315643 | validation: 0.02884376812635895]
	TIME [epoch: 12.9 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01615208866795415		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.01615208866795415 | validation: 0.023723858814662106]
	TIME [epoch: 12.9 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017689143103637294		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.017689143103637294 | validation: 0.024072190767913292]
	TIME [epoch: 13 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01711405242649163		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.01711405242649163 | validation: 0.02055380696322531]
	TIME [epoch: 12.9 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01568624958787905		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.01568624958787905 | validation: 0.029422884552158524]
	TIME [epoch: 12.9 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017362239223173342		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.017362239223173342 | validation: 0.031552227514745346]
	TIME [epoch: 13 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01592219188277025		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.01592219188277025 | validation: 0.03191368749448676]
	TIME [epoch: 13 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015204135006931338		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.015204135006931338 | validation: 0.025105216396419765]
	TIME [epoch: 13 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017249322367274323		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.017249322367274323 | validation: 0.026623346551423555]
	TIME [epoch: 12.9 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014819900843476647		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.014819900843476647 | validation: 0.02196717443937429]
	TIME [epoch: 13 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014722574590561067		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.014722574590561067 | validation: 0.025943720840140384]
	TIME [epoch: 12.9 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01978450195100353		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.01978450195100353 | validation: 0.02964242055793436]
	TIME [epoch: 13 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014760761346041415		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.014760761346041415 | validation: 0.022918467886742643]
	TIME [epoch: 13 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01819469681540466		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.01819469681540466 | validation: 0.028267270400356974]
	TIME [epoch: 13 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018187801817495644		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.018187801817495644 | validation: 0.030731699032620814]
	TIME [epoch: 12.9 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019122455073638002		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.019122455073638002 | validation: 0.03163044002825498]
	TIME [epoch: 12.9 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015319784766261923		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.015319784766261923 | validation: 0.02241753265207673]
	TIME [epoch: 13 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014322095559295377		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.014322095559295377 | validation: 0.02682666072287745]
	TIME [epoch: 12.9 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015342715761332143		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.015342715761332143 | validation: 0.02580421473492356]
	TIME [epoch: 12.9 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018281290978813612		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.018281290978813612 | validation: 0.021037292987310288]
	TIME [epoch: 12.9 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01370705804428096		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.01370705804428096 | validation: 0.023434843843999974]
	TIME [epoch: 13 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020008480640198372		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.020008480640198372 | validation: 0.03065289506469723]
	TIME [epoch: 13 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015762936065904967		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.015762936065904967 | validation: 0.025223676358124576]
	TIME [epoch: 12.9 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01653732694536526		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.01653732694536526 | validation: 0.027284406894405616]
	TIME [epoch: 12.9 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018496258443979455		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.018496258443979455 | validation: 0.02615922352820462]
	TIME [epoch: 13 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017861392311021112		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.017861392311021112 | validation: 0.02461683787569045]
	TIME [epoch: 12.9 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0155057628481007		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.0155057628481007 | validation: 0.02401829748178874]
	TIME [epoch: 13 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014327721946100533		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.014327721946100533 | validation: 0.013446802354651979]
	TIME [epoch: 13 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015612859296814708		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.015612859296814708 | validation: 0.02241547886387407]
	TIME [epoch: 12.9 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01597455679003686		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.01597455679003686 | validation: 0.022078499092783872]
	TIME [epoch: 12.9 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014842021778058944		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.014842021778058944 | validation: 0.019102556683240426]
	TIME [epoch: 13 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015574755883036338		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.015574755883036338 | validation: 0.02195721473363898]
	TIME [epoch: 13 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01600646344219429		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.01600646344219429 | validation: 0.023145611260477584]
	TIME [epoch: 12.9 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015286250890563942		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.015286250890563942 | validation: 0.023579946166204513]
	TIME [epoch: 12.9 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015967544623882484		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.015967544623882484 | validation: 0.021810535382516746]
	TIME [epoch: 13 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017166718700343263		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.017166718700343263 | validation: 0.030923956771590717]
	TIME [epoch: 13 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01477439489375481		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.01477439489375481 | validation: 0.021094477188811658]
	TIME [epoch: 13 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01336285371244271		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.01336285371244271 | validation: 0.010964584002213259]
	TIME [epoch: 12.9 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01716426580710252		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.01716426580710252 | validation: 0.03300965449928779]
	TIME [epoch: 13 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011838063190179224		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.011838063190179224 | validation: 0.03064990898890699]
	TIME [epoch: 13 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01663582962853881		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.01663582962853881 | validation: 0.028578681790871245]
	TIME [epoch: 13 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013641686054778921		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.013641686054778921 | validation: 0.03235033122388613]
	TIME [epoch: 13 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01490238468476953		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.01490238468476953 | validation: 0.029953394679430253]
	TIME [epoch: 12.9 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014038183163612786		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.014038183163612786 | validation: 0.014798037239062851]
	TIME [epoch: 12.9 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014695732082645987		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.014695732082645987 | validation: 0.025545269119291076]
	TIME [epoch: 12.9 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01645357671960911		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.01645357671960911 | validation: 0.02622057964895901]
	TIME [epoch: 13 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017106354292305906		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.017106354292305906 | validation: 0.0331532540606562]
	TIME [epoch: 13 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016352542012712804		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.016352542012712804 | validation: 0.035274976754081325]
	TIME [epoch: 13 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01816067037865319		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.01816067037865319 | validation: 0.0253562940308053]
	TIME [epoch: 13 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018386608416595396		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.018386608416595396 | validation: 0.03562675571434303]
	TIME [epoch: 13 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014471338144349548		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.014471338144349548 | validation: 0.033521515534896976]
	TIME [epoch: 13 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019214195422008418		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.019214195422008418 | validation: 0.03592263025709462]
	TIME [epoch: 13 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015984035436347507		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.015984035436347507 | validation: 0.02863911878233303]
	TIME [epoch: 13 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01999082118676592		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.01999082118676592 | validation: 0.025126401202908204]
	TIME [epoch: 13 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02259979663852244		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.02259979663852244 | validation: 0.029789477924483068]
	TIME [epoch: 13 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017656455600571212		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.017656455600571212 | validation: 0.031211891729459307]
	TIME [epoch: 13 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016036731717009988		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.016036731717009988 | validation: 0.025631300871062544]
	TIME [epoch: 13 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016901674660189638		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.016901674660189638 | validation: 0.03340708805202536]
	TIME [epoch: 12.9 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019321221720813787		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.019321221720813787 | validation: 0.02348009030036118]
	TIME [epoch: 13 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017309225264335114		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.017309225264335114 | validation: 0.022604587125265647]
	TIME [epoch: 13 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017464439248447435		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.017464439248447435 | validation: 0.026908818174621988]
	TIME [epoch: 13 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01842309461908129		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.01842309461908129 | validation: 0.029858226651834335]
	TIME [epoch: 12.9 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020252549644886073		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.020252549644886073 | validation: 0.029980565291070835]
	TIME [epoch: 13 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014653079300111366		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.014653079300111366 | validation: 0.02597351047059479]
	TIME [epoch: 13 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018052043696956337		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.018052043696956337 | validation: 0.03650829955962548]
	TIME [epoch: 13 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021956569113552375		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.021956569113552375 | validation: 0.03363499309803753]
	TIME [epoch: 13 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02056100904164804		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.02056100904164804 | validation: 0.02975347733951715]
	TIME [epoch: 13 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02043814620166747		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.02043814620166747 | validation: 0.03320488277879123]
	TIME [epoch: 13 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01626220217256923		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.01626220217256923 | validation: 0.02759868837128071]
	TIME [epoch: 13 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016681731596401288		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.016681731596401288 | validation: 0.030960433473280622]
	TIME [epoch: 12.9 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021042259297049642		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.021042259297049642 | validation: 0.03340756652127933]
	TIME [epoch: 13 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0164838399792889		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.0164838399792889 | validation: 0.028424435198106727]
	TIME [epoch: 13 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017274605244162126		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.017274605244162126 | validation: 0.02464739311994662]
	TIME [epoch: 13 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01597941048455612		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.01597941048455612 | validation: 0.02495504730468193]
	TIME [epoch: 13 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014949363184155663		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.014949363184155663 | validation: 0.028617829491499727]
	TIME [epoch: 12.9 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017020976637378865		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.017020976637378865 | validation: 0.018571074414862058]
	TIME [epoch: 12.9 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01879326047169826		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.01879326047169826 | validation: 0.0319772135497822]
	TIME [epoch: 12.9 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015913926955048775		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.015913926955048775 | validation: 0.02492667498210336]
	TIME [epoch: 13 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012432229518597317		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.012432229518597317 | validation: 0.01925199588922669]
	TIME [epoch: 12.9 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015112543116444593		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.015112543116444593 | validation: 0.026370255859892455]
	TIME [epoch: 12.9 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012576268531340425		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.012576268531340425 | validation: 0.028162470393724652]
	TIME [epoch: 12.9 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016554699970363684		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.016554699970363684 | validation: 0.024946519847450267]
	TIME [epoch: 13 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015540711718894514		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.015540711718894514 | validation: 0.02966058931075267]
	TIME [epoch: 12.9 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016330943275678928		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.016330943275678928 | validation: 0.029949676807662105]
	TIME [epoch: 12.9 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01718370131387613		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.01718370131387613 | validation: 0.026608708316565765]
	TIME [epoch: 13 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017001229976968627		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.017001229976968627 | validation: 0.018570526176551385]
	TIME [epoch: 12.9 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01617562254024291		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.01617562254024291 | validation: 0.031711321562251746]
	TIME [epoch: 13 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016281173455981037		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.016281173455981037 | validation: 0.024793961399258175]
	TIME [epoch: 12.9 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01930144165102696		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.01930144165102696 | validation: 0.01828319020072861]
	TIME [epoch: 13 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014281817658415451		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.014281817658415451 | validation: 0.02726747005818359]
	TIME [epoch: 12.9 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01848120685535478		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.01848120685535478 | validation: 0.02767486851697089]
	TIME [epoch: 12.9 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017569318267358032		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.017569318267358032 | validation: 0.019424807575573008]
	TIME [epoch: 13 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014049162391993227		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.014049162391993227 | validation: 0.023209029371148226]
	TIME [epoch: 13 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016175755558176172		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.016175755558176172 | validation: 0.02370992966319672]
	TIME [epoch: 13 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015605458714097117		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.015605458714097117 | validation: 0.026336484374608966]
	TIME [epoch: 13 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017417262560317913		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.017417262560317913 | validation: 0.03323924615156229]
	TIME [epoch: 13 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01566265731567172		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.01566265731567172 | validation: 0.017713926583211463]
	TIME [epoch: 13 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015149012439885017		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.015149012439885017 | validation: 0.020890132780423884]
	TIME [epoch: 13 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010156816226544943		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.010156816226544943 | validation: 0.02733593653957374]
	TIME [epoch: 13 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014946540040659904		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.014946540040659904 | validation: 0.022150721162290825]
	TIME [epoch: 13 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016270148673002676		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.016270148673002676 | validation: 0.020689479961686876]
	TIME [epoch: 13 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01607608167026672		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.01607608167026672 | validation: 0.021740034165281447]
	TIME [epoch: 13 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017761865439926854		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.017761865439926854 | validation: 0.026746597221409932]
	TIME [epoch: 13 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014221502747839546		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.014221502747839546 | validation: 0.022692954520372437]
	TIME [epoch: 13 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014943178676338336		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.014943178676338336 | validation: 0.02119659837979582]
	TIME [epoch: 12.9 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016441615781829778		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.016441615781829778 | validation: 0.028828493456012648]
	TIME [epoch: 13 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013932468797147159		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.013932468797147159 | validation: 0.025287298788168253]
	TIME [epoch: 13 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01648562214452878		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.01648562214452878 | validation: 0.025056153540513507]
	TIME [epoch: 13 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015221926845502073		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.015221926845502073 | validation: 0.018735069213954455]
	TIME [epoch: 12.9 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014967485429850479		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.014967485429850479 | validation: 0.028760753464592594]
	TIME [epoch: 13 sec]
EPOCH 1680/2000:
	Training over batches...
