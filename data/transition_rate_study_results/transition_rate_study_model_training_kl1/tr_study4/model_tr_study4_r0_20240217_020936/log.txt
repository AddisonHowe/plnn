Args:
Namespace(name='model_tr_study4', outdir='out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0', training_data='data/transition_rate_studies/tr_study4/tr_study4_training/r0', validation_data='data/transition_rate_studies/tr_study4/tr_study4_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=500, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1617407546

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.463478413242797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.463478413242797 | validation: 8.559065767830997]
	TIME [epoch: 48.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.428439930766697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.428439930766697 | validation: 8.027117491397346]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.926912116055466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.926912116055466 | validation: 7.576483759254353]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.445207483911595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.445207483911595 | validation: 7.837628775404925]
	TIME [epoch: 9.13 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.205795865315364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.205795865315364 | validation: 6.928778688809047]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.958106290686075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.958106290686075 | validation: 6.695372960340549]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.74100665658128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.74100665658128 | validation: 6.536812777500732]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.69292922250923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.69292922250923 | validation: 6.422340351802465]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.163240448341181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.163240448341181 | validation: 6.28641109085939]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.260282539783147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.260282539783147 | validation: 3.3269616941949884]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4269682832573998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4269682832573998 | validation: 3.0725961026223496]
	TIME [epoch: 9.15 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.401570507402539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.401570507402539 | validation: 2.805003395663557]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.467395735856185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.467395735856185 | validation: 3.357900387958993]
	TIME [epoch: 9.12 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5595452067191147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5595452067191147 | validation: 2.957358445536408]
	TIME [epoch: 9.12 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.360987672590673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.360987672590673 | validation: 2.9110841951769415]
	TIME [epoch: 9.15 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1119374564612783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1119374564612783 | validation: 2.681152846634058]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.006248093802972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.006248093802972 | validation: 2.729126671280078]
	TIME [epoch: 9.14 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4061320032396445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4061320032396445 | validation: 2.9169376873435597]
	TIME [epoch: 9.13 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.161191003767872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.161191003767872 | validation: 2.9695683096651564]
	TIME [epoch: 9.15 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.043995967077903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.043995967077903 | validation: 4.901884466176403]
	TIME [epoch: 9.13 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.509761397385691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.509761397385691 | validation: 3.663003320505333]
	TIME [epoch: 9.13 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.697504210348795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.697504210348795 | validation: 3.7069745550198876]
	TIME [epoch: 9.14 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.59594120041524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.59594120041524 | validation: 3.868553374136653]
	TIME [epoch: 9.16 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4933576606606946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4933576606606946 | validation: 3.267074941912536]
	TIME [epoch: 9.15 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3855271096455324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3855271096455324 | validation: 4.0299132126997685]
	TIME [epoch: 9.13 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.532606221888276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.532606221888276 | validation: 3.3760561673562544]
	TIME [epoch: 9.13 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9752619184918445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9752619184918445 | validation: 3.3469954804392956]
	TIME [epoch: 9.14 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7161392594789353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7161392594789353 | validation: 3.1442441115783906]
	TIME [epoch: 9.15 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.637262439538666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.637262439538666 | validation: 2.526518936082784]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7478805142890543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7478805142890543 | validation: 5.065800960397995]
	TIME [epoch: 9.13 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.378736077418698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.378736077418698 | validation: 2.8262789872643417]
	TIME [epoch: 9.13 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.492999697723565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.492999697723565 | validation: 2.409638380444362]
	TIME [epoch: 9.16 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1598637587659972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1598637587659972 | validation: 2.1372263481467195]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8576150013105868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8576150013105868 | validation: 3.4854426276130157]
	TIME [epoch: 9.14 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.885665451334076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.885665451334076 | validation: 5.534018202359068]
	TIME [epoch: 9.12 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9538800315842764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9538800315842764 | validation: 3.2743756114401963]
	TIME [epoch: 9.14 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6396850500796987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6396850500796987 | validation: 2.0783239030502583]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9949167547060622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9949167547060622 | validation: 1.7586232322900446]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6770940904626201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6770940904626201 | validation: 1.4977609554474158]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4576184971984663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4576184971984663 | validation: 1.3020762657772535]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.093869494153256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.093869494153256 | validation: 0.7879906933079932]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.831372886371638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.831372886371638 | validation: 0.6760139717385809]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.039256706793369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.039256706793369 | validation: 0.9331619415072772]
	TIME [epoch: 9.12 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.796254236044061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.796254236044061 | validation: 0.8258804348370699]
	TIME [epoch: 9.14 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9281477007686746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9281477007686746 | validation: 0.8595748749517906]
	TIME [epoch: 9.12 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7726734564615628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7726734564615628 | validation: 0.7272250743524422]
	TIME [epoch: 9.12 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6695428540409977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6695428540409977 | validation: 0.5194126440614926]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6764767787375352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6764767787375352 | validation: 0.49253615965967323]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7324682645960312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7324682645960312 | validation: 0.7214545193730681]
	TIME [epoch: 9.11 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.831269186054217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.831269186054217 | validation: 3.630418734324368]
	TIME [epoch: 9.11 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6363836613396234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6363836613396234 | validation: 0.5765296488251446]
	TIME [epoch: 9.1 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5485730630852412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5485730630852412 | validation: 0.5990371010217808]
	TIME [epoch: 9.13 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6873481264755522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6873481264755522 | validation: 0.903021153892558]
	TIME [epoch: 9.12 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5525784552718982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5525784552718982 | validation: 0.4644459003354985]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9265947744484053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9265947744484053 | validation: 0.5268185905749172]
	TIME [epoch: 9.11 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0315633373371098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0315633373371098 | validation: 0.5953744252735802]
	TIME [epoch: 9.12 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6491651364910115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6491651364910115 | validation: 0.4945894767831135]
	TIME [epoch: 9.13 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6144256843993064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6144256843993064 | validation: 0.5256882864573256]
	TIME [epoch: 9.1 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.578311920461099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.578311920461099 | validation: 0.6738069028167915]
	TIME [epoch: 9.11 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.72401158945889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.72401158945889 | validation: 3.401119109050186]
	TIME [epoch: 9.11 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.443855703808828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.443855703808828 | validation: 6.344213113432073]
	TIME [epoch: 9.12 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.4839523892395565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4839523892395565 | validation: 6.3556112043835284]
	TIME [epoch: 9.1 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.418044172642065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.418044172642065 | validation: 6.143263030507606]
	TIME [epoch: 9.1 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.472475071763564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.472475071763564 | validation: 1.4647876690635526]
	TIME [epoch: 9.11 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9449505975756267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9449505975756267 | validation: 0.7231118685328045]
	TIME [epoch: 9.12 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6617830662905467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6617830662905467 | validation: 0.5099894211802216]
	TIME [epoch: 9.1 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.590144176005503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.590144176005503 | validation: 0.5802593007298056]
	TIME [epoch: 9.11 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6115700610040181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6115700610040181 | validation: 0.6056955783820676]
	TIME [epoch: 9.1 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5001340478451264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5001340478451264 | validation: 0.42704500336150275]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.068292872365397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.068292872365397 | validation: 0.5089440746847731]
	TIME [epoch: 9.13 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48725093047655454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48725093047655454 | validation: 0.5329826923460217]
	TIME [epoch: 9.11 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4458779176106561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4458779176106561 | validation: 0.3848006992022904]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47584356767368063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47584356767368063 | validation: 0.49922301873764585]
	TIME [epoch: 9.14 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3059749516861614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3059749516861614 | validation: 3.543603123218138]
	TIME [epoch: 9.11 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7533502031880013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7533502031880013 | validation: 0.45770665710796954]
	TIME [epoch: 9.11 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0265176690308029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0265176690308029 | validation: 0.8295449715050606]
	TIME [epoch: 9.11 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7232334734570054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7232334734570054 | validation: 0.45231914065767187]
	TIME [epoch: 9.12 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.694960822006354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.694960822006354 | validation: 0.8899273843108589]
	TIME [epoch: 9.13 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5607287532724545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5607287532724545 | validation: 0.46589683662198256]
	TIME [epoch: 9.11 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45257340565530413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45257340565530413 | validation: 0.6467877293145126]
	TIME [epoch: 9.11 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42849826871618807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42849826871618807 | validation: 0.37446371958666064]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41892686311256694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41892686311256694 | validation: 0.4784735194539065]
	TIME [epoch: 9.13 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6580345521791076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6580345521791076 | validation: 0.4017226177976789]
	TIME [epoch: 9.11 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8935933333324796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8935933333324796 | validation: 0.5218631915944909]
	TIME [epoch: 9.11 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.519402258800887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.519402258800887 | validation: 0.3630940738522867]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42554852445316077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42554852445316077 | validation: 0.3964288414334598]
	TIME [epoch: 9.13 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36390811485360525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36390811485360525 | validation: 0.39355426625810475]
	TIME [epoch: 9.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5419502449956481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5419502449956481 | validation: 0.5398508408053062]
	TIME [epoch: 9.1 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3948167082308399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3948167082308399 | validation: 0.4217825465330034]
	TIME [epoch: 9.1 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5327922544502053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5327922544502053 | validation: 0.6471256257323384]
	TIME [epoch: 9.09 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4711902047152547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4711902047152547 | validation: 0.37007799001930775]
	TIME [epoch: 9.12 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4063835723445517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4063835723445517 | validation: 0.3647325569294235]
	TIME [epoch: 9.1 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5520551469276083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5520551469276083 | validation: 0.6425252374610865]
	TIME [epoch: 9.09 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43825127946802506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43825127946802506 | validation: 0.3702271017508857]
	TIME [epoch: 9.1 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3892945497966176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3892945497966176 | validation: 0.43036246504845566]
	TIME [epoch: 9.12 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5190722491530673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5190722491530673 | validation: 0.5041209581264792]
	TIME [epoch: 9.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.576204532804141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.576204532804141 | validation: 3.480851471978573]
	TIME [epoch: 9.09 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.684182883427858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.684182883427858 | validation: 3.367610761055418]
	TIME [epoch: 9.09 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5907577995069495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5907577995069495 | validation: 3.382312881190306]
	TIME [epoch: 9.12 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6392239485181537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6392239485181537 | validation: 3.3324603271157276]
	TIME [epoch: 9.1 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6390795179771898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6390795179771898 | validation: 3.4367177156452513]
	TIME [epoch: 9.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.615164727324017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.615164727324017 | validation: 3.2664856731605534]
	TIME [epoch: 9.1 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.679501887147121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.679501887147121 | validation: 3.4238698721328964]
	TIME [epoch: 9.12 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6314726824117587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6314726824117587 | validation: 3.5435424981093653]
	TIME [epoch: 9.1 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6083275660174783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6083275660174783 | validation: 3.4105321783428293]
	TIME [epoch: 9.1 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5234167472156885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5234167472156885 | validation: 3.445941414068132]
	TIME [epoch: 9.1 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.592231203904445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.592231203904445 | validation: 3.3068205745725425]
	TIME [epoch: 9.11 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5125340827140326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5125340827140326 | validation: 3.288359435333147]
	TIME [epoch: 9.11 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3960005430638285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3960005430638285 | validation: 0.5012137767033237]
	TIME [epoch: 9.1 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.521413968792688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.521413968792688 | validation: 0.6758806707686595]
	TIME [epoch: 9.1 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5021143318869323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5021143318869323 | validation: 0.41907190550059115]
	TIME [epoch: 9.11 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42572138611684257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42572138611684257 | validation: 0.41999150478161407]
	TIME [epoch: 9.12 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8095429968163099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8095429968163099 | validation: 3.5218928184463003]
	TIME [epoch: 9.12 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3829870524790884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3829870524790884 | validation: 0.49735697491598574]
	TIME [epoch: 9.11 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6246440174940264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6246440174940264 | validation: 0.3788297430209282]
	TIME [epoch: 9.09 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3525776278183895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3525776278183895 | validation: 0.3128155020738033]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9510867275445598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9510867275445598 | validation: 0.3587311321480858]
	TIME [epoch: 9.11 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34787389983400596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34787389983400596 | validation: 0.3476716203412383]
	TIME [epoch: 9.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3802838393775307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3802838393775307 | validation: 0.2546541297642575]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.013432760557124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.013432760557124 | validation: 3.2459965550097367]
	TIME [epoch: 9.13 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.881854600922998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.881854600922998 | validation: 2.2936989405276327]
	TIME [epoch: 9.1 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5113894395923855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5113894395923855 | validation: 2.183088900220877]
	TIME [epoch: 9.11 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2226545104315218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2226545104315218 | validation: 1.4007161696707304]
	TIME [epoch: 9.1 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.927229907911373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.927229907911373 | validation: 0.7970289869001934]
	TIME [epoch: 9.11 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0848867081718203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0848867081718203 | validation: 0.6621288781287338]
	TIME [epoch: 9.12 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49900948299914366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49900948299914366 | validation: 0.3803874554065171]
	TIME [epoch: 9.1 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40325518623617623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40325518623617623 | validation: 0.46914981667849254]
	TIME [epoch: 9.1 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49049388380761083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49049388380761083 | validation: 0.36047469232845153]
	TIME [epoch: 9.11 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3675206994502129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3675206994502129 | validation: 0.6938477632431175]
	TIME [epoch: 9.11 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3861846448481963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3861846448481963 | validation: 0.6726503620598151]
	TIME [epoch: 9.09 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41579083172870596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41579083172870596 | validation: 0.40348808846392914]
	TIME [epoch: 9.1 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3363053128531538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3363053128531538 | validation: 0.3032377109983164]
	TIME [epoch: 9.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5009578347536798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5009578347536798 | validation: 0.4985197597084937]
	TIME [epoch: 9.12 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3864841195500882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3864841195500882 | validation: 0.39673931004632057]
	TIME [epoch: 9.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.605020544240797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.605020544240797 | validation: 0.5652035578036998]
	TIME [epoch: 9.08 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3306955130067528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3306955130067528 | validation: 0.31180352953077495]
	TIME [epoch: 9.09 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5512644621473166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5512644621473166 | validation: 0.31371218195840667]
	TIME [epoch: 9.12 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4565890565339516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4565890565339516 | validation: 0.40730197316848904]
	TIME [epoch: 9.12 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5717794572196657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5717794572196657 | validation: 0.30351138561431934]
	TIME [epoch: 9.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46149930644551657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46149930644551657 | validation: 0.3798170896379439]
	TIME [epoch: 9.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45166935061293734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45166935061293734 | validation: 1.8597845707446892]
	TIME [epoch: 9.11 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.651968779311401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.651968779311401 | validation: 0.4372551188651087]
	TIME [epoch: 9.11 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5483483984730133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5483483984730133 | validation: 1.4989343992955668]
	TIME [epoch: 9.1 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2382259239453353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2382259239453353 | validation: 1.216674076012707]
	TIME [epoch: 9.09 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7259795903993636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7259795903993636 | validation: 0.4578184444139365]
	TIME [epoch: 9.12 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.591315573996605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.591315573996605 | validation: 0.37600102162367344]
	TIME [epoch: 9.1 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30788239187491534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30788239187491534 | validation: 0.2723103673031765]
	TIME [epoch: 9.09 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.542442937430673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.542442937430673 | validation: 0.4495569525454287]
	TIME [epoch: 9.09 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3757060967357573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3757060967357573 | validation: 0.5557417537210518]
	TIME [epoch: 9.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.383432320798606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.383432320798606 | validation: 0.28069085930411486]
	TIME [epoch: 9.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31587713708940945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31587713708940945 | validation: 0.3836059127128557]
	TIME [epoch: 9.09 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6372655468951212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6372655468951212 | validation: 0.8061551102776938]
	TIME [epoch: 9.09 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5044932454449271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5044932454449271 | validation: 0.6616425324720425]
	TIME [epoch: 9.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8578906026216814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8578906026216814 | validation: 0.531442370449879]
	TIME [epoch: 9.11 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40161233025668164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40161233025668164 | validation: 0.3423566130821409]
	TIME [epoch: 9.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37239207441023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37239207441023 | validation: 0.3157308888407912]
	TIME [epoch: 9.09 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3645291561069075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3645291561069075 | validation: 0.24894817191964014]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34228569620133065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34228569620133065 | validation: 0.3719151355523658]
	TIME [epoch: 9.15 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32443628498885785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32443628498885785 | validation: 0.5460102400641211]
	TIME [epoch: 9.13 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4784090081593927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4784090081593927 | validation: 0.45118724647327424]
	TIME [epoch: 9.13 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32308231311890356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32308231311890356 | validation: 0.32488866855037685]
	TIME [epoch: 9.13 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4192628895432948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4192628895432948 | validation: 0.34142653222537384]
	TIME [epoch: 9.15 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35596949792278576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35596949792278576 | validation: 0.3898752258255853]
	TIME [epoch: 9.14 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3486228961216059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3486228961216059 | validation: 0.48021225813223345]
	TIME [epoch: 9.13 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7033378349776138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7033378349776138 | validation: 0.8654728631539366]
	TIME [epoch: 9.13 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6381977808111627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6381977808111627 | validation: 0.7169186037110318]
	TIME [epoch: 9.14 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48056628862311035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48056628862311035 | validation: 0.23454056690290215]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8023380112920085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8023380112920085 | validation: 0.31958027766726665]
	TIME [epoch: 9.12 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32431006564217907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32431006564217907 | validation: 0.29857268919742064]
	TIME [epoch: 9.13 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2479956630170367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2479956630170367 | validation: 0.17991267499528046]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.302049576764974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.302049576764974 | validation: 1.0177753878142253]
	TIME [epoch: 9.15 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.496902478475851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.496902478475851 | validation: 0.3135889996484028]
	TIME [epoch: 9.13 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2935407577642487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2935407577642487 | validation: 0.33496127927314817]
	TIME [epoch: 9.13 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2942001310782227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2942001310782227 | validation: 0.37571477568386047]
	TIME [epoch: 9.13 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3442658588539844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3442658588539844 | validation: 0.26286057094954934]
	TIME [epoch: 9.15 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2836240580829589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2836240580829589 | validation: 0.44471176760990994]
	TIME [epoch: 9.13 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3017241092098404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3017241092098404 | validation: 0.20664086813885946]
	TIME [epoch: 9.12 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2828489305600302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2828489305600302 | validation: 0.2212107945438432]
	TIME [epoch: 9.12 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2581072810200131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2581072810200131 | validation: 1.854810644297394]
	TIME [epoch: 9.15 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42584308234615464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42584308234615464 | validation: 0.2692874352683079]
	TIME [epoch: 9.12 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2534899270899492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2534899270899492 | validation: 0.6857037609109038]
	TIME [epoch: 9.12 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33300316260637086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33300316260637086 | validation: 0.28290847467204105]
	TIME [epoch: 9.12 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.44613225649807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.44613225649807 | validation: 0.4226384443409098]
	TIME [epoch: 9.14 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26786317038001306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26786317038001306 | validation: 0.18446559529472994]
	TIME [epoch: 9.18 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24019371848708473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24019371848708473 | validation: 0.20076615175223786]
	TIME [epoch: 9.14 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23789424592486333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23789424592486333 | validation: 0.33496283263671967]
	TIME [epoch: 9.14 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28526367311365114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28526367311365114 | validation: 0.2160742776354369]
	TIME [epoch: 9.14 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5421746049367477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5421746049367477 | validation: 0.22574054860891335]
	TIME [epoch: 9.15 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44680645242356876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44680645242356876 | validation: 2.2342833320625015]
	TIME [epoch: 9.15 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6356362953355496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6356362953355496 | validation: 0.5511021312463292]
	TIME [epoch: 9.14 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8956807044898468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8956807044898468 | validation: 1.9475679485635942]
	TIME [epoch: 9.12 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6521279130704417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6521279130704417 | validation: 0.45239443009871905]
	TIME [epoch: 9.14 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5946301305567385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5946301305567385 | validation: 0.3694686360854937]
	TIME [epoch: 9.12 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.84906496212302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.84906496212302 | validation: 0.39422061394101615]
	TIME [epoch: 9.12 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4518142392305712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4518142392305712 | validation: 1.9489780277255262]
	TIME [epoch: 9.12 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5892761764520971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5892761764520971 | validation: 0.18813868954104646]
	TIME [epoch: 9.15 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4148125775054252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4148125775054252 | validation: 0.16611936248318793]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5210793347428928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5210793347428928 | validation: 1.3015457688075984]
	TIME [epoch: 9.12 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5406412528360207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5406412528360207 | validation: 0.3403466266206853]
	TIME [epoch: 9.12 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2743914395423731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2743914395423731 | validation: 0.2371958355613229]
	TIME [epoch: 9.14 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8690213632812833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8690213632812833 | validation: 0.355001989712147]
	TIME [epoch: 9.12 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38206402768252967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38206402768252967 | validation: 0.31239646478694205]
	TIME [epoch: 9.12 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5403186183624278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5403186183624278 | validation: 0.24906334727283547]
	TIME [epoch: 9.12 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5539998914837346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5539998914837346 | validation: 0.18091073425058735]
	TIME [epoch: 9.13 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2627794668520473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2627794668520473 | validation: 0.2407200674148684]
	TIME [epoch: 9.14 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.59225925975973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.59225925975973 | validation: 0.4400765592020742]
	TIME [epoch: 9.12 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5449028705093197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5449028705093197 | validation: 0.47647136576609483]
	TIME [epoch: 9.12 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2751226558496258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2751226558496258 | validation: 0.27832260864677155]
	TIME [epoch: 9.13 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21835701567761454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21835701567761454 | validation: 0.21029022292835486]
	TIME [epoch: 9.15 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3985295709091782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3985295709091782 | validation: 0.3078515862415245]
	TIME [epoch: 9.12 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22793438727612209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22793438727612209 | validation: 0.3705597799999769]
	TIME [epoch: 9.12 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2704870198303873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2704870198303873 | validation: 0.24924829097485723]
	TIME [epoch: 9.12 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3567789776134466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3567789776134466 | validation: 0.7929547203182549]
	TIME [epoch: 9.15 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6086979821485707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6086979821485707 | validation: 0.20912334538263655]
	TIME [epoch: 9.12 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35050264620372507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35050264620372507 | validation: 0.29879651168337334]
	TIME [epoch: 9.12 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5282262738519894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5282262738519894 | validation: 0.2378896033628089]
	TIME [epoch: 9.12 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5808385947945269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5808385947945269 | validation: 0.30720008018832445]
	TIME [epoch: 9.14 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24254447096263215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24254447096263215 | validation: 0.38663553006285656]
	TIME [epoch: 9.12 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2560900267762404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2560900267762404 | validation: 0.24678170047863401]
	TIME [epoch: 9.11 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39402972045212614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39402972045212614 | validation: 0.23212335999040318]
	TIME [epoch: 9.12 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2676166141749103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2676166141749103 | validation: 0.2601097225728522]
	TIME [epoch: 9.14 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24745929925569948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24745929925569948 | validation: 0.23366621228979484]
	TIME [epoch: 9.12 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33853997972437466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33853997972437466 | validation: 0.49136426264821315]
	TIME [epoch: 9.12 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.660760697423267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.660760697423267 | validation: 0.2369414929108522]
	TIME [epoch: 9.12 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3175248063194187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3175248063194187 | validation: 1.3538628288716246]
	TIME [epoch: 9.14 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6390862232894433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6390862232894433 | validation: 0.2172985719827334]
	TIME [epoch: 9.12 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5889795903995351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5889795903995351 | validation: 0.8671412588231777]
	TIME [epoch: 9.12 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.430337046338228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.430337046338228 | validation: 0.2514880350929878]
	TIME [epoch: 9.11 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2195272596259532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2195272596259532 | validation: 0.30816811099077424]
	TIME [epoch: 9.13 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24346573637184116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24346573637184116 | validation: 1.0475230068102304]
	TIME [epoch: 9.13 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6564052221453075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6564052221453075 | validation: 0.2614862026600514]
	TIME [epoch: 9.11 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6380712174086558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6380712174086558 | validation: 0.3125785565216209]
	TIME [epoch: 9.12 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27102935718126847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27102935718126847 | validation: 0.20459568404283557]
	TIME [epoch: 9.12 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22179579118056045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22179579118056045 | validation: 0.2874643203540853]
	TIME [epoch: 9.13 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2970872563327865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2970872563327865 | validation: 0.6286417311594472]
	TIME [epoch: 9.11 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3076505754239549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3076505754239549 | validation: 0.21354693262292526]
	TIME [epoch: 9.11 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7677880462983419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7677880462983419 | validation: 0.3097592458096046]
	TIME [epoch: 9.12 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41676922261416915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41676922261416915 | validation: 0.2780084289798969]
	TIME [epoch: 9.13 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24034276613758987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24034276613758987 | validation: 0.1914995229407502]
	TIME [epoch: 9.11 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9034830167585015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9034830167585015 | validation: 1.5675910212342181]
	TIME [epoch: 9.11 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4805990711410793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4805990711410793 | validation: 0.29346735468248764]
	TIME [epoch: 9.12 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21968673367125718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21968673367125718 | validation: 0.20550605751173928]
	TIME [epoch: 9.14 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21961440995466433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21961440995466433 | validation: 0.21975314761407522]
	TIME [epoch: 9.11 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3058074820087584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3058074820087584 | validation: 0.872450240893857]
	TIME [epoch: 9.11 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3288744072797609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3288744072797609 | validation: 0.22198665247228816]
	TIME [epoch: 9.11 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25721696410145756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25721696410145756 | validation: 0.3601042703418137]
	TIME [epoch: 9.14 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3185455516600809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3185455516600809 | validation: 0.2126044204692354]
	TIME [epoch: 9.12 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34943970896188614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34943970896188614 | validation: 0.5229081907271862]
	TIME [epoch: 9.11 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30876658103014476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30876658103014476 | validation: 0.18600863658513483]
	TIME [epoch: 9.11 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2216941039484131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2216941039484131 | validation: 0.3066594657554135]
	TIME [epoch: 9.14 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5771464291696273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5771464291696273 | validation: 1.902279732028699]
	TIME [epoch: 9.12 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.546530741205253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.546530741205253 | validation: 0.2304044173507261]
	TIME [epoch: 9.11 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34097312850984296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34097312850984296 | validation: 0.25078850860326773]
	TIME [epoch: 9.11 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4933752962402389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4933752962402389 | validation: 0.5910731384472411]
	TIME [epoch: 9.12 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37956214283248124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37956214283248124 | validation: 0.41745005714351746]
	TIME [epoch: 9.13 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3086680114001422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3086680114001422 | validation: 0.2618757221625406]
	TIME [epoch: 9.11 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3804365896460383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3804365896460383 | validation: 0.652121183600316]
	TIME [epoch: 9.11 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3769345761713957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3769345761713957 | validation: 0.19943119545437582]
	TIME [epoch: 9.12 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20709545382015643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20709545382015643 | validation: 0.2037194414391031]
	TIME [epoch: 9.13 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3084511416335874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3084511416335874 | validation: 0.25543564431571464]
	TIME [epoch: 9.12 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3846197758783118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3846197758783118 | validation: 0.28660336502972134]
	TIME [epoch: 9.12 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46989714612878003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46989714612878003 | validation: 0.47168156652345195]
	TIME [epoch: 9.12 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.270663294177693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.270663294177693 | validation: 0.227674373939745]
	TIME [epoch: 9.14 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40783254946285724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40783254946285724 | validation: 0.3592401429032307]
	TIME [epoch: 9.12 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33942215641595147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33942215641595147 | validation: 0.30712078190155767]
	TIME [epoch: 9.12 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2593025713165727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2593025713165727 | validation: 0.3411965508829332]
	TIME [epoch: 9.12 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3960346052148046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3960346052148046 | validation: 0.49361415528698205]
	TIME [epoch: 9.14 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45638939594331085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45638939594331085 | validation: 0.24865611293199347]
	TIME [epoch: 9.12 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25783715190377127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25783715190377127 | validation: 0.22216360624741488]
	TIME [epoch: 9.12 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24767180757919594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24767180757919594 | validation: 0.7939625250961395]
	TIME [epoch: 9.12 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5432612651054785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5432612651054785 | validation: 0.43181899961410297]
	TIME [epoch: 9.14 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22574466766882173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22574466766882173 | validation: 0.21070846836788923]
	TIME [epoch: 9.12 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37209823485663174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37209823485663174 | validation: 0.3875316895245788]
	TIME [epoch: 9.12 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25524275306084226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25524275306084226 | validation: 0.3423206700643958]
	TIME [epoch: 9.11 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23891973244210174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23891973244210174 | validation: 0.23895794490216665]
	TIME [epoch: 9.14 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5087518651378963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5087518651378963 | validation: 0.2487040603611166]
	TIME [epoch: 9.12 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5121365409094304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5121365409094304 | validation: 1.044673764478834]
	TIME [epoch: 9.12 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46885821664418365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46885821664418365 | validation: 1.6476296468811316]
	TIME [epoch: 9.11 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4265827177996261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4265827177996261 | validation: 0.3142338689418491]
	TIME [epoch: 9.13 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22327135032006523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22327135032006523 | validation: 0.5178621235234755]
	TIME [epoch: 9.11 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3469330251232975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3469330251232975 | validation: 0.26947511451926637]
	TIME [epoch: 9.11 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2071958936045623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2071958936045623 | validation: 0.29427611216316235]
	TIME [epoch: 9.11 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26591665330515235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26591665330515235 | validation: 0.3160090784921523]
	TIME [epoch: 9.12 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2741090869990773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2741090869990773 | validation: 0.4185826760867527]
	TIME [epoch: 9.13 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3086530402034571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3086530402034571 | validation: 0.3998707333708089]
	TIME [epoch: 9.11 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3129920607524764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3129920607524764 | validation: 0.3328291949121732]
	TIME [epoch: 9.11 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31221172372386635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31221172372386635 | validation: 0.20998903140545688]
	TIME [epoch: 9.12 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32687837045236245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32687837045236245 | validation: 0.3100229903618741]
	TIME [epoch: 9.13 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4331455057945228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4331455057945228 | validation: 0.7736136293208411]
	TIME [epoch: 9.11 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47157427989544687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47157427989544687 | validation: 0.8851181640216724]
	TIME [epoch: 9.11 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31485324679596094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31485324679596094 | validation: 0.26533897152923536]
	TIME [epoch: 9.11 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3157489817901748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3157489817901748 | validation: 0.3244925054390314]
	TIME [epoch: 9.13 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25710993364867246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25710993364867246 | validation: 0.24916487044509264]
	TIME [epoch: 9.11 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18065831302806346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18065831302806346 | validation: 0.1622343196623376]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3573078956880056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3573078956880056 | validation: 0.2659499805724818]
	TIME [epoch: 9.11 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24530008304305456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24530008304305456 | validation: 0.23245692585113628]
	TIME [epoch: 9.14 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.265111506191524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.265111506191524 | validation: 0.24193957427621954]
	TIME [epoch: 9.11 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27105519008538637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27105519008538637 | validation: 0.2502690966276217]
	TIME [epoch: 9.11 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30162837461831293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30162837461831293 | validation: 0.34287002420108015]
	TIME [epoch: 9.11 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28524985394873903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28524985394873903 | validation: 0.28943609477394794]
	TIME [epoch: 9.12 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29843584140002777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29843584140002777 | validation: 0.711019840481941]
	TIME [epoch: 9.12 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3258957748091209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3258957748091209 | validation: 0.299241099290618]
	TIME [epoch: 9.11 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19466910270885382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19466910270885382 | validation: 0.2752859463890569]
	TIME [epoch: 9.11 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28918963781008233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28918963781008233 | validation: 0.23314209382724327]
	TIME [epoch: 9.12 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22003713739969516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22003713739969516 | validation: 0.2203637864769711]
	TIME [epoch: 9.13 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25179623471804263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25179623471804263 | validation: 0.8527455336699361]
	TIME [epoch: 9.12 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5012843946986563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5012843946986563 | validation: 0.38013009892234517]
	TIME [epoch: 9.11 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29614764879716693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29614764879716693 | validation: 0.2823414430070359]
	TIME [epoch: 9.12 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25834077395239713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25834077395239713 | validation: 0.6803421996432817]
	TIME [epoch: 9.14 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8833356619107849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8833356619107849 | validation: 0.9242780061491709]
	TIME [epoch: 9.11 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.036910051326966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.036910051326966 | validation: 2.6005574608120847]
	TIME [epoch: 9.11 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0856835166839374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0856835166839374 | validation: 0.7647400497007738]
	TIME [epoch: 9.11 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5246806227475068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5246806227475068 | validation: 0.6721340072645151]
	TIME [epoch: 9.14 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.003510616416351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.003510616416351 | validation: 0.4653291993611273]
	TIME [epoch: 9.12 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23309675092519963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23309675092519963 | validation: 0.2810531166888951]
	TIME [epoch: 9.11 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26419326074007016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26419326074007016 | validation: 0.2368888319064811]
	TIME [epoch: 9.12 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7503197544741984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7503197544741984 | validation: 0.6363995459756807]
	TIME [epoch: 9.14 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5305982277382768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5305982277382768 | validation: 0.5335026468383555]
	TIME [epoch: 9.11 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.533518819400365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.533518819400365 | validation: 0.6597241774991693]
	TIME [epoch: 9.11 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.492707055062694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.492707055062694 | validation: 0.2147674226295907]
	TIME [epoch: 9.12 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31771873843689546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31771873843689546 | validation: 0.5151769018211014]
	TIME [epoch: 9.14 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7760498533357681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7760498533357681 | validation: 0.3351144619299472]
	TIME [epoch: 9.12 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38726960203817284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38726960203817284 | validation: 0.5199160125727698]
	TIME [epoch: 9.11 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3986942227105987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3986942227105987 | validation: 0.8208357457643165]
	TIME [epoch: 9.11 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46884447478694036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46884447478694036 | validation: 2.0097701728539965]
	TIME [epoch: 9.12 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8231650506379076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8231650506379076 | validation: 2.0289848374009294]
	TIME [epoch: 9.13 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8879048727277586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8879048727277586 | validation: 0.8888340597268829]
	TIME [epoch: 9.12 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8872739369462277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8872739369462277 | validation: 3.1674813632870746]
	TIME [epoch: 9.11 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.31810885438453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.31810885438453 | validation: 2.503171741509619]
	TIME [epoch: 9.13 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1764120503863174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1764120503863174 | validation: 0.9821536731521021]
	TIME [epoch: 9.13 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9661614147645792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9661614147645792 | validation: 3.1764340708337544]
	TIME [epoch: 9.11 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.198980905845225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.198980905845225 | validation: 1.6207192421956957]
	TIME [epoch: 9.11 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.922193580870068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.922193580870068 | validation: 0.7272137961905542]
	TIME [epoch: 9.11 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8839274238303767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8839274238303767 | validation: 1.9985575411263592]
	TIME [epoch: 9.14 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8781309476423524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8781309476423524 | validation: 1.321015357925413]
	TIME [epoch: 9.12 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5479499988329712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5479499988329712 | validation: 0.42946187848644046]
	TIME [epoch: 9.11 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8593000536844746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8593000536844746 | validation: 0.32476792440681246]
	TIME [epoch: 9.11 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3798087835861364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3798087835861364 | validation: 0.6667648594629785]
	TIME [epoch: 9.14 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6100686386622058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6100686386622058 | validation: 0.26744005720419745]
	TIME [epoch: 9.11 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3325340614456949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3325340614456949 | validation: 0.3109472855487875]
	TIME [epoch: 9.11 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27619847622254345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27619847622254345 | validation: 0.39981309944299087]
	TIME [epoch: 9.11 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27749526252591455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27749526252591455 | validation: 0.23476412054819545]
	TIME [epoch: 9.14 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2472918626614101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2472918626614101 | validation: 0.21719045535511844]
	TIME [epoch: 9.11 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2860593203616014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2860593203616014 | validation: 0.27838736581871504]
	TIME [epoch: 9.12 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22247901285211494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22247901285211494 | validation: 0.24326217463555316]
	TIME [epoch: 9.11 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21562372406437738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21562372406437738 | validation: 0.19221553604723235]
	TIME [epoch: 9.13 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20564451443597043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20564451443597043 | validation: 0.16146192823316755]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_347.pth
	Model improved!!!
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22359718824525507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22359718824525507 | validation: 0.15919282663723724]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24181402449113815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24181402449113815 | validation: 0.2046678170593714]
	TIME [epoch: 9.12 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22191269874928973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22191269874928973 | validation: 0.34465978185902835]
	TIME [epoch: 9.14 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3329417651796369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3329417651796369 | validation: 0.22410262180740145]
	TIME [epoch: 9.12 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18655977181601052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18655977181601052 | validation: 0.2225125845316996]
	TIME [epoch: 9.12 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21646470482706434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21646470482706434 | validation: 0.23692289359601132]
	TIME [epoch: 9.12 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19653556399433597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19653556399433597 | validation: 0.22823523071612667]
	TIME [epoch: 9.11 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2697897294226681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2697897294226681 | validation: 0.25349413964192535]
	TIME [epoch: 9.14 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2060780124392385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2060780124392385 | validation: 0.28639474420921457]
	TIME [epoch: 9.11 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5024355205022781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5024355205022781 | validation: 0.6740081936877358]
	TIME [epoch: 9.12 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26629103333892956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26629103333892956 | validation: 0.2550083226465507]
	TIME [epoch: 9.11 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21677090290660933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21677090290660933 | validation: 0.20165231075050163]
	TIME [epoch: 9.13 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1703689595693981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1703689595693981 | validation: 0.15373497283592935]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18387001456298507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18387001456298507 | validation: 0.2526120510788399]
	TIME [epoch: 9.11 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21983670226892257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21983670226892257 | validation: 0.16527149580365474]
	TIME [epoch: 9.11 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2122357626597339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2122357626597339 | validation: 0.28228009606918675]
	TIME [epoch: 9.13 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20623270378373615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20623270378373615 | validation: 0.20668586212434129]
	TIME [epoch: 9.11 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3423320394708184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3423320394708184 | validation: 0.23020879635842828]
	TIME [epoch: 9.1 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2451209314321569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2451209314321569 | validation: 0.25414141796503836]
	TIME [epoch: 9.11 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20442301605466168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20442301605466168 | validation: 0.2345669314800254]
	TIME [epoch: 9.11 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22958766738453082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22958766738453082 | validation: 0.21345781328707536]
	TIME [epoch: 9.13 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17225285659166858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17225285659166858 | validation: 0.25553400452581954]
	TIME [epoch: 9.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2063926147921887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2063926147921887 | validation: 0.20425929102550353]
	TIME [epoch: 9.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2517491143238969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2517491143238969 | validation: 0.23229636055657765]
	TIME [epoch: 9.11 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2066743375154035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2066743375154035 | validation: 0.4737806478601697]
	TIME [epoch: 9.13 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27395923066155514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27395923066155514 | validation: 0.19714259861051847]
	TIME [epoch: 9.11 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5070468598110444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5070468598110444 | validation: 0.3416975763529031]
	TIME [epoch: 9.11 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22085210520646165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22085210520646165 | validation: 0.16693706670906078]
	TIME [epoch: 9.11 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18242185056156193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18242185056156193 | validation: 0.4005746073038183]
	TIME [epoch: 9.13 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29694274625583683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29694274625583683 | validation: 0.3454981476580734]
	TIME [epoch: 9.11 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2277646574105145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2277646574105145 | validation: 0.1788044858284915]
	TIME [epoch: 9.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.321032701310704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.321032701310704 | validation: 0.2996959216856758]
	TIME [epoch: 9.11 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23247508661749489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23247508661749489 | validation: 0.7280665680540825]
	TIME [epoch: 9.13 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2501553114047879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2501553114047879 | validation: 0.2244098861823256]
	TIME [epoch: 9.11 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2095753426922679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2095753426922679 | validation: 0.19100845340236627]
	TIME [epoch: 9.11 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1868125123647611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1868125123647611 | validation: 0.26901666343984026]
	TIME [epoch: 9.11 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24162289889868466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24162289889868466 | validation: 0.27421772562539337]
	TIME [epoch: 9.12 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2809423022022262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2809423022022262 | validation: 0.6144517798958395]
	TIME [epoch: 9.12 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30985827647197917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30985827647197917 | validation: 0.20956628480363318]
	TIME [epoch: 9.11 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2347712213831361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2347712213831361 | validation: 0.20555070901561012]
	TIME [epoch: 9.11 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.226857712724693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.226857712724693 | validation: 0.18695388852563696]
	TIME [epoch: 9.12 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2603669094050599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2603669094050599 | validation: 0.23496418597840849]
	TIME [epoch: 9.12 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1891155159886468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1891155159886468 | validation: 0.1899179120627803]
	TIME [epoch: 9.11 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19629260852880254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19629260852880254 | validation: 0.23398130515070908]
	TIME [epoch: 9.11 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19976623755809025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19976623755809025 | validation: 0.2527751087253627]
	TIME [epoch: 9.12 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19629008726673244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19629008726673244 | validation: 0.18410957399142608]
	TIME [epoch: 9.13 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3695582277695729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3695582277695729 | validation: 1.1780352581077844]
	TIME [epoch: 9.11 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5310087034484947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5310087034484947 | validation: 0.3921488147446802]
	TIME [epoch: 9.11 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.206540095816933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.206540095816933 | validation: 0.22935440179782485]
	TIME [epoch: 9.11 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5671200466945177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5671200466945177 | validation: 0.6265988286175808]
	TIME [epoch: 9.14 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2885258597446506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2885258597446506 | validation: 0.22542821229563093]
	TIME [epoch: 9.11 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2966517693385259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2966517693385259 | validation: 1.0950359253839086]
	TIME [epoch: 9.11 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3057960068289109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3057960068289109 | validation: 0.30062143614552184]
	TIME [epoch: 9.11 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17756897211089953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17756897211089953 | validation: 0.16211250833247148]
	TIME [epoch: 9.13 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3164906113017018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3164906113017018 | validation: 0.30579673294500836]
	TIME [epoch: 9.11 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3110744378608691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3110744378608691 | validation: 0.2606250230619245]
	TIME [epoch: 9.11 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1633893217716213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1633893217716213 | validation: 0.16640327546308042]
	TIME [epoch: 9.11 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17897406344438288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17897406344438288 | validation: 0.17877561738471462]
	TIME [epoch: 9.13 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13120325764028037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13120325764028037 | validation: 0.173511418051037]
	TIME [epoch: 9.12 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37452061404638504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37452061404638504 | validation: 0.7803172826452746]
	TIME [epoch: 9.11 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32043714839290444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32043714839290444 | validation: 0.5073540243549131]
	TIME [epoch: 9.11 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30612354768874395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30612354768874395 | validation: 0.1275907713728165]
	TIME [epoch: 9.13 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_409.pth
	Model improved!!!
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2635097587917153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2635097587917153 | validation: 0.28567851080950124]
	TIME [epoch: 9.12 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31240630552906057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31240630552906057 | validation: 0.24740732793736286]
	TIME [epoch: 9.11 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2671638858725748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2671638858725748 | validation: 0.1800182444507603]
	TIME [epoch: 9.11 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19057931225345598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19057931225345598 | validation: 0.2906882357282476]
	TIME [epoch: 9.11 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1990339531842291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1990339531842291 | validation: 0.22133880404099301]
	TIME [epoch: 9.14 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17806488583277477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17806488583277477 | validation: 0.1634873867627466]
	TIME [epoch: 9.11 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0908509517189409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0908509517189409 | validation: 2.74880800037057]
	TIME [epoch: 9.11 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6120327804841237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6120327804841237 | validation: 0.24796930778015944]
	TIME [epoch: 9.1 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49787636048173073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49787636048173073 | validation: 0.22854696471427421]
	TIME [epoch: 9.13 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3150480810947144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3150480810947144 | validation: 0.2607207892488803]
	TIME [epoch: 9.11 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2679179579727709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2679179579727709 | validation: 0.22705479598574713]
	TIME [epoch: 9.11 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24827658418708878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24827658418708878 | validation: 0.190627128259699]
	TIME [epoch: 9.11 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2457906742631042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2457906742631042 | validation: 0.353702829449325]
	TIME [epoch: 9.13 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2563706297823183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2563706297823183 | validation: 0.1700133409358821]
	TIME [epoch: 9.11 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18677322632440735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18677322632440735 | validation: 0.17474223278681247]
	TIME [epoch: 9.11 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21243790233650034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21243790233650034 | validation: 0.15903633534269587]
	TIME [epoch: 9.11 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23116887205275832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23116887205275832 | validation: 0.17004413950981445]
	TIME [epoch: 9.13 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2296645563617646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2296645563617646 | validation: 0.2219615171760243]
	TIME [epoch: 9.12 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2080433310400803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2080433310400803 | validation: 0.15142094018766966]
	TIME [epoch: 9.11 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16412386014139793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16412386014139793 | validation: 0.18543265384454982]
	TIME [epoch: 9.11 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18569251826380537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18569251826380537 | validation: 0.17017938092571233]
	TIME [epoch: 9.12 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19492562230349353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19492562230349353 | validation: 0.21604515646224165]
	TIME [epoch: 9.13 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21120642391872457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21120642391872457 | validation: 0.13776928560305113]
	TIME [epoch: 9.11 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18143481312464835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18143481312464835 | validation: 0.5022538116665964]
	TIME [epoch: 9.11 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2123829280013439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2123829280013439 | validation: 0.19744103249700534]
	TIME [epoch: 9.12 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20537589140332763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20537589140332763 | validation: 0.18030814038295195]
	TIME [epoch: 9.13 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14949173163705826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14949173163705826 | validation: 0.12715458083320347]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3830156986046312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3830156986046312 | validation: 0.2851408002569574]
	TIME [epoch: 9.11 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3634523116649865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3634523116649865 | validation: 0.25632955912649524]
	TIME [epoch: 9.1 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24356549383442064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24356549383442064 | validation: 0.2715829825931908]
	TIME [epoch: 9.12 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17710136705871782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17710136705871782 | validation: 0.2223081515531324]
	TIME [epoch: 9.1 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16073797228304637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16073797228304637 | validation: 0.3212194293769556]
	TIME [epoch: 9.1 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25371385835824667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25371385835824667 | validation: 0.243419808882575]
	TIME [epoch: 9.1 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2340703738021747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2340703738021747 | validation: 0.21266359833531873]
	TIME [epoch: 9.12 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2554001072925925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2554001072925925 | validation: 0.44131430741197186]
	TIME [epoch: 9.11 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2284309518353922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2284309518353922 | validation: 0.20157840018947498]
	TIME [epoch: 9.1 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24950852460295433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24950852460295433 | validation: 0.18405139535297182]
	TIME [epoch: 9.09 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20843423024995728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20843423024995728 | validation: 0.23705899779803785]
	TIME [epoch: 9.1 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30826313048355847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30826313048355847 | validation: 0.36323260437981664]
	TIME [epoch: 9.11 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2648256206652692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2648256206652692 | validation: 0.4048527904101646]
	TIME [epoch: 9.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2322646421588769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2322646421588769 | validation: 0.19499818015887554]
	TIME [epoch: 9.1 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2476922468530459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2476922468530459 | validation: 0.23445664885765793]
	TIME [epoch: 9.11 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2576851429009163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2576851429009163 | validation: 0.22270436520695835]
	TIME [epoch: 9.11 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2369889768144386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2369889768144386 | validation: 0.3006702103358081]
	TIME [epoch: 9.1 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2447055022443226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2447055022443226 | validation: 0.28356321081735536]
	TIME [epoch: 9.1 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3273163393240954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3273163393240954 | validation: 0.7250351111090643]
	TIME [epoch: 9.1 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.763883479636322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.763883479636322 | validation: 0.7518701906651326]
	TIME [epoch: 9.13 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26205625779997554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26205625779997554 | validation: 0.1703846893612934]
	TIME [epoch: 9.11 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24481487979954522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24481487979954522 | validation: 0.3233045683189246]
	TIME [epoch: 9.1 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21347350768550832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21347350768550832 | validation: 0.29581800162300276]
	TIME [epoch: 9.1 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34325883567772225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34325883567772225 | validation: 0.22525083850951916]
	TIME [epoch: 9.13 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27219061632458297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27219061632458297 | validation: 0.2295369863871412]
	TIME [epoch: 9.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17517289533682204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17517289533682204 | validation: 0.16903507363853834]
	TIME [epoch: 9.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19640675241100342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19640675241100342 | validation: 0.25180994946822255]
	TIME [epoch: 9.1 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2326264793634949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2326264793634949 | validation: 0.19902020489088296]
	TIME [epoch: 9.12 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22419490203630082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22419490203630082 | validation: 0.23877779298716278]
	TIME [epoch: 9.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27995560649440965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27995560649440965 | validation: 0.23883098806280123]
	TIME [epoch: 9.1 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18639819707282568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18639819707282568 | validation: 0.18973657801853056]
	TIME [epoch: 9.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21347352069494555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21347352069494555 | validation: 0.22739628107390375]
	TIME [epoch: 9.12 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21041035231067645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21041035231067645 | validation: 0.23721020710114465]
	TIME [epoch: 9.1 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19457916068385375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19457916068385375 | validation: 0.18507412157458542]
	TIME [epoch: 9.1 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18967500156010336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18967500156010336 | validation: 0.18595805039737143]
	TIME [epoch: 9.1 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17130646931154994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17130646931154994 | validation: 0.2525275892407055]
	TIME [epoch: 9.11 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2382077117039259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2382077117039259 | validation: 0.48619701023025075]
	TIME [epoch: 9.12 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37999132989430384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37999132989430384 | validation: 0.26746141786123145]
	TIME [epoch: 9.11 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2263146936867726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2263146936867726 | validation: 0.24812576333129888]
	TIME [epoch: 9.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20485408344591147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20485408344591147 | validation: 0.2619229487075098]
	TIME [epoch: 9.11 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23613485631711773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23613485631711773 | validation: 0.881871234093873]
	TIME [epoch: 9.12 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37335914069588305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37335914069588305 | validation: 0.24415477442888503]
	TIME [epoch: 9.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23428964514923037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23428964514923037 | validation: 0.3676256063223956]
	TIME [epoch: 9.09 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39747337598155974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39747337598155974 | validation: 0.4082140520160965]
	TIME [epoch: 9.1 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3320151217694191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3320151217694191 | validation: 0.1529128699904822]
	TIME [epoch: 9.12 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4147525453705353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4147525453705353 | validation: 0.5230816722893701]
	TIME [epoch: 9.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2869611895698464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2869611895698464 | validation: 0.5459117408671097]
	TIME [epoch: 9.12 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4110311128782568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4110311128782568 | validation: 0.22965536655771981]
	TIME [epoch: 9.12 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18955277203095097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18955277203095097 | validation: 0.23405590836631657]
	TIME [epoch: 9.14 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23440415010989762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23440415010989762 | validation: 0.1557184921297543]
	TIME [epoch: 9.11 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20274053937858105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20274053937858105 | validation: 0.3788468953313159]
	TIME [epoch: 9.12 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2180319607741658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2180319607741658 | validation: 0.31581775173358173]
	TIME [epoch: 9.12 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37078588205089497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37078588205089497 | validation: 1.1187342684235597]
	TIME [epoch: 9.14 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5802507641098912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5802507641098912 | validation: 0.3141260965143342]
	TIME [epoch: 9.12 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2191138186098769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2191138186098769 | validation: 0.26484167496790095]
	TIME [epoch: 9.11 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1909234626745364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1909234626745364 | validation: 0.27175104608346184]
	TIME [epoch: 9.11 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24303570372598632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24303570372598632 | validation: 0.24248998022061946]
	TIME [epoch: 9.12 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21779469691179437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21779469691179437 | validation: 0.26185312599870925]
	TIME [epoch: 9.11 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1704184354172748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1704184354172748 | validation: 0.2079124037504187]
	TIME [epoch: 9.11 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24231829105404148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24231829105404148 | validation: 0.21511224851042213]
	TIME [epoch: 9.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5956087721120051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5956087721120051 | validation: 0.17925313016733274]
	TIME [epoch: 9.12 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24739190404586076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24739190404586076 | validation: 0.19041454319049064]
	TIME [epoch: 9.11 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18622819515971956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18622819515971956 | validation: 0.37403914926432574]
	TIME [epoch: 9.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20918635874243527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20918635874243527 | validation: 0.2922295157771361]
	TIME [epoch: 9.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6633599660535724		[learning rate: 0.0099724]
	Learning Rate: 0.00997241
	LOSS [training: 0.6633599660535724 | validation: 0.49670282804154897]
	TIME [epoch: 9.11 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5839325877941288		[learning rate: 0.0099418]
	Learning Rate: 0.00994184
	LOSS [training: 0.5839325877941288 | validation: 0.6145571661820447]
	TIME [epoch: 9.11 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28384318084723825		[learning rate: 0.0099114]
	Learning Rate: 0.00991136
	LOSS [training: 0.28384318084723825 | validation: 0.3371788422383545]
	TIME [epoch: 9.09 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2811053765509618		[learning rate: 0.009881]
	Learning Rate: 0.00988098
	LOSS [training: 0.2811053765509618 | validation: 0.2655829664069001]
	TIME [epoch: 9.09 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17206469251585654		[learning rate: 0.0098507]
	Learning Rate: 0.00985069
	LOSS [training: 0.17206469251585654 | validation: 0.1630150860173168]
	TIME [epoch: 9.11 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6716266471631369		[learning rate: 0.0098205]
	Learning Rate: 0.00982049
	LOSS [training: 0.6716266471631369 | validation: 0.4943489588102323]
	TIME [epoch: 9.12 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3504429832899763		[learning rate: 0.0097904]
	Learning Rate: 0.00979039
	LOSS [training: 0.3504429832899763 | validation: 0.8676492899868689]
	TIME [epoch: 9.09 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39811577151955363		[learning rate: 0.0097604]
	Learning Rate: 0.00976038
	LOSS [training: 0.39811577151955363 | validation: 0.21059617359458388]
	TIME [epoch: 9.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2072491441994281		[learning rate: 0.0097305]
	Learning Rate: 0.00973046
	LOSS [training: 0.2072491441994281 | validation: 0.27417574753011154]
	TIME [epoch: 9.09 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3014887447791071		[learning rate: 0.0097006]
	Learning Rate: 0.00970063
	LOSS [training: 0.3014887447791071 | validation: 0.42124370175149806]
	TIME [epoch: 9.12 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31252746379210017		[learning rate: 0.0096709]
	Learning Rate: 0.00967089
	LOSS [training: 0.31252746379210017 | validation: 0.18857403729741906]
	TIME [epoch: 9.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26417672282154697		[learning rate: 0.0096412]
	Learning Rate: 0.00964125
	LOSS [training: 0.26417672282154697 | validation: 0.2348472152263913]
	TIME [epoch: 9.11 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16835381567164984		[learning rate: 0.0096117]
	Learning Rate: 0.0096117
	LOSS [training: 0.16835381567164984 | validation: 0.18643565316451616]
	TIME [epoch: 9.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16337697563680809		[learning rate: 0.0095822]
	Learning Rate: 0.00958223
	LOSS [training: 0.16337697563680809 | validation: 0.2308652993619415]
	TIME [epoch: 9.12 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24119232309635827		[learning rate: 0.0095529]
	Learning Rate: 0.00955286
	LOSS [training: 0.24119232309635827 | validation: 0.22214561172937214]
	TIME [epoch: 9.1 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2019641063105512		[learning rate: 0.0095236]
	Learning Rate: 0.00952357
	LOSS [training: 0.2019641063105512 | validation: 0.5555144727501049]
	TIME [epoch: 9.1 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2549004477992546		[learning rate: 0.0094944]
	Learning Rate: 0.00949438
	LOSS [training: 0.2549004477992546 | validation: 0.2416119224689835]
	TIME [epoch: 9.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4002479402098437		[learning rate: 0.0094653]
	Learning Rate: 0.00946528
	LOSS [training: 0.4002479402098437 | validation: 0.25283244303231567]
	TIME [epoch: 9.12 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20541739551411275		[learning rate: 0.0094363]
	Learning Rate: 0.00943626
	LOSS [training: 0.20541739551411275 | validation: 0.2387509937210289]
	TIME [epoch: 9.1 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22639864216577504		[learning rate: 0.0094073]
	Learning Rate: 0.00940734
	LOSS [training: 0.22639864216577504 | validation: 0.3135408081751059]
	TIME [epoch: 9.1 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3667056736106843		[learning rate: 0.0093785]
	Learning Rate: 0.0093785
	LOSS [training: 0.3667056736106843 | validation: 0.31195441438965765]
	TIME [epoch: 9.1 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22838885047127117		[learning rate: 0.0093497]
	Learning Rate: 0.00934975
	LOSS [training: 0.22838885047127117 | validation: 0.3289466982692275]
	TIME [epoch: 9.11 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4345150971839081		[learning rate: 0.0093211]
	Learning Rate: 0.00932109
	LOSS [training: 0.4345150971839081 | validation: 0.7274221955002514]
	TIME [epoch: 9.11 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27072223178276644		[learning rate: 0.0092925]
	Learning Rate: 0.00929252
	LOSS [training: 0.27072223178276644 | validation: 0.17572818021028025]
	TIME [epoch: 9.1 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1829429284432049		[learning rate: 0.009264]
	Learning Rate: 0.00926403
	LOSS [training: 0.1829429284432049 | validation: 0.17199343947039591]
	TIME [epoch: 9.1 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24201390135116307		[learning rate: 0.0092356]
	Learning Rate: 0.00923563
	LOSS [training: 0.24201390135116307 | validation: 0.31930687970535454]
	TIME [epoch: 9.1 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27829919326669295		[learning rate: 0.0092073]
	Learning Rate: 0.00920732
	LOSS [training: 0.27829919326669295 | validation: 0.27883136351376936]
	TIME [epoch: 9.11 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16867623074320612		[learning rate: 0.0091791]
	Learning Rate: 0.0091791
	LOSS [training: 0.16867623074320612 | validation: 0.16537283469079056]
	TIME [epoch: 9.09 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20732244494948157		[learning rate: 0.009151]
	Learning Rate: 0.00915096
	LOSS [training: 0.20732244494948157 | validation: 0.1971244820887344]
	TIME [epoch: 9.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28801746255250277		[learning rate: 0.0091229]
	Learning Rate: 0.00912291
	LOSS [training: 0.28801746255250277 | validation: 0.3920294998732222]
	TIME [epoch: 9.11 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2541582682972978		[learning rate: 0.0090949]
	Learning Rate: 0.00909494
	LOSS [training: 0.2541582682972978 | validation: 0.2597737800011652]
	TIME [epoch: 9.11 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20312955103021962		[learning rate: 0.0090671]
	Learning Rate: 0.00906706
	LOSS [training: 0.20312955103021962 | validation: 0.1981591706902865]
	TIME [epoch: 9.09 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28449913106171615		[learning rate: 0.0090393]
	Learning Rate: 0.00903927
	LOSS [training: 0.28449913106171615 | validation: 0.3892358975627065]
	TIME [epoch: 9.1 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29278251519475706		[learning rate: 0.0090116]
	Learning Rate: 0.00901156
	LOSS [training: 0.29278251519475706 | validation: 0.28184737039988733]
	TIME [epoch: 9.1 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18103918851029221		[learning rate: 0.0089839]
	Learning Rate: 0.00898394
	LOSS [training: 0.18103918851029221 | validation: 0.32009642601812427]
	TIME [epoch: 9.12 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6325335059624974		[learning rate: 0.0089564]
	Learning Rate: 0.0089564
	LOSS [training: 0.6325335059624974 | validation: 0.9325350562934638]
	TIME [epoch: 9.1 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33426523994243307		[learning rate: 0.0089289]
	Learning Rate: 0.00892894
	LOSS [training: 0.33426523994243307 | validation: 0.31924143761470236]
	TIME [epoch: 9.12 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2377553867348446		[learning rate: 0.0089016]
	Learning Rate: 0.00890157
	LOSS [training: 0.2377553867348446 | validation: 0.48141931099252594]
	TIME [epoch: 9.09 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23439246615477055		[learning rate: 0.0088743]
	Learning Rate: 0.00887428
	LOSS [training: 0.23439246615477055 | validation: 0.15486341369473317]
	TIME [epoch: 9.12 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2822601618474565		[learning rate: 0.0088471]
	Learning Rate: 0.00884708
	LOSS [training: 0.2822601618474565 | validation: 0.34268141073256425]
	TIME [epoch: 9.1 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29954333045060483		[learning rate: 0.00882]
	Learning Rate: 0.00881996
	LOSS [training: 0.29954333045060483 | validation: 0.34813698083804745]
	TIME [epoch: 9.1 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27234625053923633		[learning rate: 0.0087929]
	Learning Rate: 0.00879292
	LOSS [training: 0.27234625053923633 | validation: 0.17279889507884988]
	TIME [epoch: 9.09 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2509224028845389		[learning rate: 0.008766]
	Learning Rate: 0.00876597
	LOSS [training: 0.2509224028845389 | validation: 0.18291784424666216]
	TIME [epoch: 9.12 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20345828061965068		[learning rate: 0.0087391]
	Learning Rate: 0.0087391
	LOSS [training: 0.20345828061965068 | validation: 0.3085674226252917]
	TIME [epoch: 9.11 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24231245433033105		[learning rate: 0.0087123]
	Learning Rate: 0.00871231
	LOSS [training: 0.24231245433033105 | validation: 0.29129928645219566]
	TIME [epoch: 9.1 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3089420915618573		[learning rate: 0.0086856]
	Learning Rate: 0.0086856
	LOSS [training: 0.3089420915618573 | validation: 0.3231630707893293]
	TIME [epoch: 9.1 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24657052768752458		[learning rate: 0.008659]
	Learning Rate: 0.00865898
	LOSS [training: 0.24657052768752458 | validation: 0.33820379063112405]
	TIME [epoch: 9.12 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3067564516162974		[learning rate: 0.0086324]
	Learning Rate: 0.00863244
	LOSS [training: 0.3067564516162974 | validation: 2.0907027076561815]
	TIME [epoch: 9.1 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5815140422541083		[learning rate: 0.008606]
	Learning Rate: 0.00860597
	LOSS [training: 0.5815140422541083 | validation: 0.3591494891637709]
	TIME [epoch: 9.1 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27729354317656113		[learning rate: 0.0085796]
	Learning Rate: 0.00857959
	LOSS [training: 0.27729354317656113 | validation: 0.5584299031493194]
	TIME [epoch: 9.1 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4028143909247402		[learning rate: 0.0085533]
	Learning Rate: 0.00855329
	LOSS [training: 0.4028143909247402 | validation: 0.2869879036730686]
	TIME [epoch: 9.11 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.510505420973803		[learning rate: 0.0085271]
	Learning Rate: 0.00852707
	LOSS [training: 0.510505420973803 | validation: 0.40290984786380174]
	TIME [epoch: 9.12 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7960579165926307		[learning rate: 0.0085009]
	Learning Rate: 0.00850093
	LOSS [training: 0.7960579165926307 | validation: 1.1545309128874262]
	TIME [epoch: 9.1 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2853809380233518		[learning rate: 0.0084749]
	Learning Rate: 0.00847488
	LOSS [training: 1.2853809380233518 | validation: 0.3302310858058787]
	TIME [epoch: 9.1 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45469315492155005		[learning rate: 0.0084489]
	Learning Rate: 0.0084489
	LOSS [training: 0.45469315492155005 | validation: 1.0502743670349703]
	TIME [epoch: 9.11 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.74774087862829		[learning rate: 0.008423]
	Learning Rate: 0.008423
	LOSS [training: 5.74774087862829 | validation: 6.364620441861842]
	TIME [epoch: 9.11 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8391184856976015		[learning rate: 0.0083972]
	Learning Rate: 0.00839718
	LOSS [training: 1.8391184856976015 | validation: 0.38746867946635055]
	TIME [epoch: 9.1 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28595558347075445		[learning rate: 0.0083714]
	Learning Rate: 0.00837144
	LOSS [training: 0.28595558347075445 | validation: 0.2833567791706385]
	TIME [epoch: 9.1 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24897734812677141		[learning rate: 0.0083458]
	Learning Rate: 0.00834577
	LOSS [training: 0.24897734812677141 | validation: 0.3751130909240895]
	TIME [epoch: 9.11 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3334067626019412		[learning rate: 0.0083202]
	Learning Rate: 0.00832019
	LOSS [training: 0.3334067626019412 | validation: 0.21740602472395354]
	TIME [epoch: 9.13 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3061909101093159		[learning rate: 0.0082947]
	Learning Rate: 0.00829469
	LOSS [training: 0.3061909101093159 | validation: 0.26745125886696486]
	TIME [epoch: 9.1 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4792557753735033		[learning rate: 0.0082693]
	Learning Rate: 0.00826926
	LOSS [training: 0.4792557753735033 | validation: 0.3940847434199719]
	TIME [epoch: 9.1 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29475691582089586		[learning rate: 0.0082439]
	Learning Rate: 0.00824391
	LOSS [training: 0.29475691582089586 | validation: 0.43631219047885916]
	TIME [epoch: 9.1 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23458274676141005		[learning rate: 0.0082186]
	Learning Rate: 0.00821864
	LOSS [training: 0.23458274676141005 | validation: 0.19534089060407267]
	TIME [epoch: 9.12 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26906524453664027		[learning rate: 0.0081934]
	Learning Rate: 0.00819345
	LOSS [training: 0.26906524453664027 | validation: 0.5505236359543615]
	TIME [epoch: 9.09 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45324375398747047		[learning rate: 0.0081683]
	Learning Rate: 0.00816833
	LOSS [training: 0.45324375398747047 | validation: 0.4928771203752347]
	TIME [epoch: 9.09 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6325333680396372		[learning rate: 0.0081433]
	Learning Rate: 0.00814329
	LOSS [training: 0.6325333680396372 | validation: 0.3521926524335853]
	TIME [epoch: 9.09 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4095739603938152		[learning rate: 0.0081183]
	Learning Rate: 0.00811833
	LOSS [training: 0.4095739603938152 | validation: 0.5433713049483391]
	TIME [epoch: 9.11 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39394789175923106		[learning rate: 0.0080934]
	Learning Rate: 0.00809344
	LOSS [training: 0.39394789175923106 | validation: 0.3591319183443969]
	TIME [epoch: 9.1 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25575639752042456		[learning rate: 0.0080686]
	Learning Rate: 0.00806863
	LOSS [training: 0.25575639752042456 | validation: 0.3037602484763009]
	TIME [epoch: 9.1 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21450455397458718		[learning rate: 0.0080439]
	Learning Rate: 0.0080439
	LOSS [training: 0.21450455397458718 | validation: 0.24446155956841586]
	TIME [epoch: 9.09 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2927214323569409		[learning rate: 0.0080192]
	Learning Rate: 0.00801924
	LOSS [training: 0.2927214323569409 | validation: 0.41741086142714645]
	TIME [epoch: 9.11 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22921590948868792		[learning rate: 0.0079947]
	Learning Rate: 0.00799466
	LOSS [training: 0.22921590948868792 | validation: 0.11586735211677897]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_573.pth
	Model improved!!!
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15155275019738573		[learning rate: 0.0079702]
	Learning Rate: 0.00797015
	LOSS [training: 0.15155275019738573 | validation: 0.19512262113877865]
	TIME [epoch: 9.1 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24982370027485792		[learning rate: 0.0079457]
	Learning Rate: 0.00794572
	LOSS [training: 0.24982370027485792 | validation: 0.38146520257675376]
	TIME [epoch: 9.1 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.467030070197891		[learning rate: 0.0079214]
	Learning Rate: 0.00792136
	LOSS [training: 0.467030070197891 | validation: 0.9664419231874573]
	TIME [epoch: 9.12 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.64200521070214		[learning rate: 0.0078971]
	Learning Rate: 0.00789708
	LOSS [training: 0.64200521070214 | validation: 0.2766536902452996]
	TIME [epoch: 9.1 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3119410277461433		[learning rate: 0.0078729]
	Learning Rate: 0.00787287
	LOSS [training: 0.3119410277461433 | validation: 0.24593148953948055]
	TIME [epoch: 9.1 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20855550438428253		[learning rate: 0.0078487]
	Learning Rate: 0.00784874
	LOSS [training: 0.20855550438428253 | validation: 0.21123298060489018]
	TIME [epoch: 9.1 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21742636153200373		[learning rate: 0.0078247]
	Learning Rate: 0.00782468
	LOSS [training: 0.21742636153200373 | validation: 0.3900809229630688]
	TIME [epoch: 9.09 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2737748532748066		[learning rate: 0.0078007]
	Learning Rate: 0.0078007
	LOSS [training: 0.2737748532748066 | validation: 0.24769543849546033]
	TIME [epoch: 9.12 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18815215978967786		[learning rate: 0.0077768]
	Learning Rate: 0.00777678
	LOSS [training: 0.18815215978967786 | validation: 0.207693544003037]
	TIME [epoch: 9.09 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16508902391186173		[learning rate: 0.0077529]
	Learning Rate: 0.00775294
	LOSS [training: 0.16508902391186173 | validation: 0.20065136804031014]
	TIME [epoch: 9.1 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19160016316324976		[learning rate: 0.0077292]
	Learning Rate: 0.00772918
	LOSS [training: 0.19160016316324976 | validation: 0.3610074182702466]
	TIME [epoch: 9.1 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21372164207163585		[learning rate: 0.0077055]
	Learning Rate: 0.00770548
	LOSS [training: 0.21372164207163585 | validation: 0.3256372106958802]
	TIME [epoch: 9.12 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1920982916356116		[learning rate: 0.0076819]
	Learning Rate: 0.00768186
	LOSS [training: 0.1920982916356116 | validation: 0.27546783514066486]
	TIME [epoch: 9.09 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.171634547310061		[learning rate: 0.0076583]
	Learning Rate: 0.00765832
	LOSS [training: 0.171634547310061 | validation: 0.17314344501114265]
	TIME [epoch: 9.1 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2009143890144335		[learning rate: 0.0076348]
	Learning Rate: 0.00763484
	LOSS [training: 0.2009143890144335 | validation: 0.21766671947499416]
	TIME [epoch: 9.09 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.238550084476509		[learning rate: 0.0076114]
	Learning Rate: 0.00761144
	LOSS [training: 0.238550084476509 | validation: 0.16033706919267102]
	TIME [epoch: 9.12 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2894959838456697		[learning rate: 0.0075881]
	Learning Rate: 0.0075881
	LOSS [training: 0.2894959838456697 | validation: 0.3242991223987792]
	TIME [epoch: 9.1 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3080077887036567		[learning rate: 0.0075648]
	Learning Rate: 0.00756484
	LOSS [training: 0.3080077887036567 | validation: 0.344936065321941]
	TIME [epoch: 9.1 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27457181990946544		[learning rate: 0.0075417]
	Learning Rate: 0.00754165
	LOSS [training: 0.27457181990946544 | validation: 0.17390387099967047]
	TIME [epoch: 9.1 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36740623369835046		[learning rate: 0.0075185]
	Learning Rate: 0.00751854
	LOSS [training: 0.36740623369835046 | validation: 0.6872589099875327]
	TIME [epoch: 9.11 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2235599992929477		[learning rate: 0.0074955]
	Learning Rate: 0.00749549
	LOSS [training: 0.2235599992929477 | validation: 0.19688247173468698]
	TIME [epoch: 9.1 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.244408142867763		[learning rate: 0.0074725]
	Learning Rate: 0.00747251
	LOSS [training: 0.244408142867763 | validation: 0.1244630285402334]
	TIME [epoch: 9.1 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18923158399251666		[learning rate: 0.0074496]
	Learning Rate: 0.00744961
	LOSS [training: 0.18923158399251666 | validation: 0.12990018038483292]
	TIME [epoch: 9.1 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21429111270031442		[learning rate: 0.0074268]
	Learning Rate: 0.00742677
	LOSS [training: 0.21429111270031442 | validation: 0.6567411481965584]
	TIME [epoch: 9.11 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2888856712895776		[learning rate: 0.007404]
	Learning Rate: 0.007404
	LOSS [training: 0.2888856712895776 | validation: 0.22141462423874964]
	TIME [epoch: 9.12 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20843877437137404		[learning rate: 0.0073813]
	Learning Rate: 0.00738131
	LOSS [training: 0.20843877437137404 | validation: 0.15202666057088884]
	TIME [epoch: 9.1 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16651786458769907		[learning rate: 0.0073587]
	Learning Rate: 0.00735868
	LOSS [training: 0.16651786458769907 | validation: 0.5900397933662826]
	TIME [epoch: 9.1 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18556621290731617		[learning rate: 0.0073361]
	Learning Rate: 0.00733612
	LOSS [training: 0.18556621290731617 | validation: 0.1888475845116659]
	TIME [epoch: 9.11 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21546432122861514		[learning rate: 0.0073136]
	Learning Rate: 0.00731364
	LOSS [training: 0.21546432122861514 | validation: 0.20463135935037796]
	TIME [epoch: 9.1 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32804129541546134		[learning rate: 0.0072912]
	Learning Rate: 0.00729122
	LOSS [training: 0.32804129541546134 | validation: 1.8602029644543694]
	TIME [epoch: 9.12 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4825520551905146		[learning rate: 0.0072689]
	Learning Rate: 0.00726887
	LOSS [training: 0.4825520551905146 | validation: 0.18264642256611785]
	TIME [epoch: 9.1 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27371972101292663		[learning rate: 0.0072466]
	Learning Rate: 0.00724658
	LOSS [training: 0.27371972101292663 | validation: 0.2510936858454647]
	TIME [epoch: 9.1 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4187992449322283		[learning rate: 0.0072244]
	Learning Rate: 0.00722437
	LOSS [training: 0.4187992449322283 | validation: 0.5741029166270003]
	TIME [epoch: 9.12 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7929436031317787		[learning rate: 0.0072022]
	Learning Rate: 0.00720222
	LOSS [training: 0.7929436031317787 | validation: 0.5027960543934832]
	TIME [epoch: 9.09 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34681315582409156		[learning rate: 0.0071801]
	Learning Rate: 0.00718015
	LOSS [training: 0.34681315582409156 | validation: 0.5449380815872482]
	TIME [epoch: 9.11 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23911762847552023		[learning rate: 0.0071581]
	Learning Rate: 0.00715814
	LOSS [training: 0.23911762847552023 | validation: 0.21884476870862113]
	TIME [epoch: 9.1 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14963740630160444		[learning rate: 0.0071362]
	Learning Rate: 0.00713619
	LOSS [training: 0.14963740630160444 | validation: 0.14195736897294675]
	TIME [epoch: 9.12 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19116761365615445		[learning rate: 0.0071143]
	Learning Rate: 0.00711432
	LOSS [training: 0.19116761365615445 | validation: 0.20738991387627292]
	TIME [epoch: 9.1 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16246567612857843		[learning rate: 0.0070925]
	Learning Rate: 0.00709251
	LOSS [training: 0.16246567612857843 | validation: 0.22820220716952141]
	TIME [epoch: 9.1 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19546173963765406		[learning rate: 0.0070708]
	Learning Rate: 0.00707077
	LOSS [training: 0.19546173963765406 | validation: 0.1350782279242258]
	TIME [epoch: 9.09 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15323473166071744		[learning rate: 0.0070491]
	Learning Rate: 0.00704909
	LOSS [training: 0.15323473166071744 | validation: 0.1552210509337344]
	TIME [epoch: 9.12 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16263039122232106		[learning rate: 0.0070275]
	Learning Rate: 0.00702749
	LOSS [training: 0.16263039122232106 | validation: 0.1962854896332878]
	TIME [epoch: 9.1 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17649537403124108		[learning rate: 0.0070059]
	Learning Rate: 0.00700594
	LOSS [training: 0.17649537403124108 | validation: 0.2264663749628794]
	TIME [epoch: 9.09 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5947648220809143		[learning rate: 0.0069845]
	Learning Rate: 0.00698447
	LOSS [training: 0.5947648220809143 | validation: 0.6699053346677766]
	TIME [epoch: 9.09 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37052525412531745		[learning rate: 0.0069631]
	Learning Rate: 0.00696306
	LOSS [training: 0.37052525412531745 | validation: 1.0307251612963082]
	TIME [epoch: 9.12 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5571654822819089		[learning rate: 0.0069417]
	Learning Rate: 0.00694171
	LOSS [training: 0.5571654822819089 | validation: 0.7242754927976671]
	TIME [epoch: 9.1 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3600890527201922		[learning rate: 0.0069204]
	Learning Rate: 0.00692043
	LOSS [training: 0.3600890527201922 | validation: 0.352477015603872]
	TIME [epoch: 9.1 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21023592194901833		[learning rate: 0.0068992]
	Learning Rate: 0.00689922
	LOSS [training: 0.21023592194901833 | validation: 0.3071417022440826]
	TIME [epoch: 9.1 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25680095661877045		[learning rate: 0.0068781]
	Learning Rate: 0.00687807
	LOSS [training: 0.25680095661877045 | validation: 0.2725061667023141]
	TIME [epoch: 9.1 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3265085609596742		[learning rate: 0.006857]
	Learning Rate: 0.00685699
	LOSS [training: 0.3265085609596742 | validation: 0.2504552268585936]
	TIME [epoch: 9.11 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27098352151548183		[learning rate: 0.006836]
	Learning Rate: 0.00683597
	LOSS [training: 0.27098352151548183 | validation: 0.2599765756740471]
	TIME [epoch: 9.09 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3661014328811293		[learning rate: 0.006815]
	Learning Rate: 0.00681501
	LOSS [training: 0.3661014328811293 | validation: 0.4370681814007876]
	TIME [epoch: 9.09 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29685116766306036		[learning rate: 0.0067941]
	Learning Rate: 0.00679412
	LOSS [training: 0.29685116766306036 | validation: 0.3106703012719062]
	TIME [epoch: 9.1 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5697595382245371		[learning rate: 0.0067733]
	Learning Rate: 0.00677329
	LOSS [training: 0.5697595382245371 | validation: 0.46168763634242227]
	TIME [epoch: 9.1 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4715104321413922		[learning rate: 0.0067525]
	Learning Rate: 0.00675253
	LOSS [training: 0.4715104321413922 | validation: 0.30111478797315316]
	TIME [epoch: 9.09 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2107147219618078		[learning rate: 0.0067318]
	Learning Rate: 0.00673183
	LOSS [training: 0.2107147219618078 | validation: 0.14682984464911897]
	TIME [epoch: 9.09 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.234335735716488		[learning rate: 0.0067112]
	Learning Rate: 0.0067112
	LOSS [training: 0.234335735716488 | validation: 0.3660900086245691]
	TIME [epoch: 9.1 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22002160127023163		[learning rate: 0.0066906]
	Learning Rate: 0.00669062
	LOSS [training: 0.22002160127023163 | validation: 0.1455397026407411]
	TIME [epoch: 9.12 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24935160970619613		[learning rate: 0.0066701]
	Learning Rate: 0.00667012
	LOSS [training: 0.24935160970619613 | validation: 0.5996513346916348]
	TIME [epoch: 9.09 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5285418341528403		[learning rate: 0.0066497]
	Learning Rate: 0.00664967
	LOSS [training: 0.5285418341528403 | validation: 0.637684697005554]
	TIME [epoch: 9.1 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23721813581608586		[learning rate: 0.0066293]
	Learning Rate: 0.00662928
	LOSS [training: 0.23721813581608586 | validation: 0.12127267468193377]
	TIME [epoch: 9.09 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13883595331576923		[learning rate: 0.006609]
	Learning Rate: 0.00660896
	LOSS [training: 0.13883595331576923 | validation: 0.13149504160386943]
	TIME [epoch: 9.12 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14990558343613886		[learning rate: 0.0065887]
	Learning Rate: 0.0065887
	LOSS [training: 0.14990558343613886 | validation: 0.35256365356122643]
	TIME [epoch: 9.1 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27646933252725875		[learning rate: 0.0065685]
	Learning Rate: 0.00656851
	LOSS [training: 0.27646933252725875 | validation: 0.3079516129897962]
	TIME [epoch: 9.09 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30399502145015467		[learning rate: 0.0065484]
	Learning Rate: 0.00654837
	LOSS [training: 0.30399502145015467 | validation: 0.718044961740645]
	TIME [epoch: 9.1 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27032208968411264		[learning rate: 0.0065283]
	Learning Rate: 0.0065283
	LOSS [training: 0.27032208968411264 | validation: 0.4790242218635371]
	TIME [epoch: 9.12 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4825330673666934		[learning rate: 0.0065083]
	Learning Rate: 0.00650829
	LOSS [training: 0.4825330673666934 | validation: 0.4418051207407617]
	TIME [epoch: 9.1 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2830718623541971		[learning rate: 0.0064883]
	Learning Rate: 0.00648834
	LOSS [training: 0.2830718623541971 | validation: 0.39933998721578723]
	TIME [epoch: 9.09 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17989134828009978		[learning rate: 0.0064684]
	Learning Rate: 0.00646845
	LOSS [training: 0.17989134828009978 | validation: 0.1389387519709263]
	TIME [epoch: 9.09 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1310752145777474		[learning rate: 0.0064486]
	Learning Rate: 0.00644862
	LOSS [training: 0.1310752145777474 | validation: 0.16858164099052514]
	TIME [epoch: 9.11 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3551752491968674		[learning rate: 0.0064289]
	Learning Rate: 0.00642885
	LOSS [training: 0.3551752491968674 | validation: 0.4501399635225224]
	TIME [epoch: 9.1 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2544481039723975		[learning rate: 0.0064091]
	Learning Rate: 0.00640914
	LOSS [training: 0.2544481039723975 | validation: 0.17246324946951025]
	TIME [epoch: 9.09 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13467139848335918		[learning rate: 0.0063895]
	Learning Rate: 0.0063895
	LOSS [training: 0.13467139848335918 | validation: 0.09731747175328012]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_646.pth
	Model improved!!!
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5628509097739618		[learning rate: 0.0063699]
	Learning Rate: 0.00636991
	LOSS [training: 0.5628509097739618 | validation: 0.41051023807288944]
	TIME [epoch: 9.13 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16714837487529		[learning rate: 0.0063504]
	Learning Rate: 0.00635038
	LOSS [training: 0.16714837487529 | validation: 0.13684966613540894]
	TIME [epoch: 9.11 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1453334740109212		[learning rate: 0.0063309]
	Learning Rate: 0.00633092
	LOSS [training: 0.1453334740109212 | validation: 0.2138395007388068]
	TIME [epoch: 9.1 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16267886987267727		[learning rate: 0.0063115]
	Learning Rate: 0.00631151
	LOSS [training: 0.16267886987267727 | validation: 0.18361647016508523]
	TIME [epoch: 9.1 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14083024282571896		[learning rate: 0.0062922]
	Learning Rate: 0.00629216
	LOSS [training: 0.14083024282571896 | validation: 0.6942234298098224]
	TIME [epoch: 9.09 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29216527593771624		[learning rate: 0.0062729]
	Learning Rate: 0.00627288
	LOSS [training: 0.29216527593771624 | validation: 0.14909733491378035]
	TIME [epoch: 9.12 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2073697063828432		[learning rate: 0.0062536]
	Learning Rate: 0.00625365
	LOSS [training: 0.2073697063828432 | validation: 0.21720663784871852]
	TIME [epoch: 9.1 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3449751686475243		[learning rate: 0.0062345]
	Learning Rate: 0.00623448
	LOSS [training: 0.3449751686475243 | validation: 0.8464469707371136]
	TIME [epoch: 9.1 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34549699619549734		[learning rate: 0.0062154]
	Learning Rate: 0.00621536
	LOSS [training: 0.34549699619549734 | validation: 0.6159329366987618]
	TIME [epoch: 9.1 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7846720233731066		[learning rate: 0.0061963]
	Learning Rate: 0.00619631
	LOSS [training: 0.7846720233731066 | validation: 1.7378204828375665]
	TIME [epoch: 9.13 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6347510633358006		[learning rate: 0.0061773]
	Learning Rate: 0.00617732
	LOSS [training: 0.6347510633358006 | validation: 0.31758312238218284]
	TIME [epoch: 9.11 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32712494909379275		[learning rate: 0.0061584]
	Learning Rate: 0.00615838
	LOSS [training: 0.32712494909379275 | validation: 0.5808386550182352]
	TIME [epoch: 9.1 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37540232635534454		[learning rate: 0.0061395]
	Learning Rate: 0.0061395
	LOSS [training: 0.37540232635534454 | validation: 0.7745231253492277]
	TIME [epoch: 9.1 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28036231758813346		[learning rate: 0.0061207]
	Learning Rate: 0.00612068
	LOSS [training: 0.28036231758813346 | validation: 0.12785108530031639]
	TIME [epoch: 9.12 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21226856151647472		[learning rate: 0.0061019]
	Learning Rate: 0.00610192
	LOSS [training: 0.21226856151647472 | validation: 0.16575625985918663]
	TIME [epoch: 9.11 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17568515393044493		[learning rate: 0.0060832]
	Learning Rate: 0.00608322
	LOSS [training: 0.17568515393044493 | validation: 0.3627840614071177]
	TIME [epoch: 9.1 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18531608903248342		[learning rate: 0.0060646]
	Learning Rate: 0.00606457
	LOSS [training: 0.18531608903248342 | validation: 0.31809929120184477]
	TIME [epoch: 9.09 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18831189861805234		[learning rate: 0.006046]
	Learning Rate: 0.00604598
	LOSS [training: 0.18831189861805234 | validation: 0.10084536426749571]
	TIME [epoch: 9.11 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3666074019268068		[learning rate: 0.0060274]
	Learning Rate: 0.00602745
	LOSS [training: 0.3666074019268068 | validation: 0.22453274691042086]
	TIME [epoch: 9.12 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15210793538481945		[learning rate: 0.006009]
	Learning Rate: 0.00600897
	LOSS [training: 0.15210793538481945 | validation: 0.14230799776849676]
	TIME [epoch: 9.1 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49288802791788183		[learning rate: 0.0059905]
	Learning Rate: 0.00599055
	LOSS [training: 0.49288802791788183 | validation: 0.25582467920819313]
	TIME [epoch: 9.11 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2186773353236791		[learning rate: 0.0059722]
	Learning Rate: 0.00597219
	LOSS [training: 0.2186773353236791 | validation: 0.15992999268178276]
	TIME [epoch: 9.1 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26320825971617745		[learning rate: 0.0059539]
	Learning Rate: 0.00595388
	LOSS [training: 0.26320825971617745 | validation: 0.3495512574006058]
	TIME [epoch: 9.11 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2046751617626045		[learning rate: 0.0059356]
	Learning Rate: 0.00593563
	LOSS [training: 0.2046751617626045 | validation: 0.17227882039866071]
	TIME [epoch: 9.09 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19539696031170556		[learning rate: 0.0059174]
	Learning Rate: 0.00591743
	LOSS [training: 0.19539696031170556 | validation: 0.14522135752738036]
	TIME [epoch: 9.1 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14827662616054843		[learning rate: 0.0058993]
	Learning Rate: 0.00589929
	LOSS [training: 0.14827662616054843 | validation: 0.14206534749632704]
	TIME [epoch: 9.09 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1893065297903427		[learning rate: 0.0058812]
	Learning Rate: 0.00588121
	LOSS [training: 0.1893065297903427 | validation: 0.190084327189811]
	TIME [epoch: 9.1 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1547812687501352		[learning rate: 0.0058632]
	Learning Rate: 0.00586318
	LOSS [training: 0.1547812687501352 | validation: 0.16437195834708843]
	TIME [epoch: 9.09 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2030368460642058		[learning rate: 0.0058452]
	Learning Rate: 0.00584521
	LOSS [training: 0.2030368460642058 | validation: 0.2882742076353169]
	TIME [epoch: 9.09 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16931671833353953		[learning rate: 0.0058273]
	Learning Rate: 0.00582729
	LOSS [training: 0.16931671833353953 | validation: 0.2753968340763891]
	TIME [epoch: 9.09 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3039157282899574		[learning rate: 0.0058094]
	Learning Rate: 0.00580943
	LOSS [training: 0.3039157282899574 | validation: 0.14880831379165188]
	TIME [epoch: 9.12 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20234041665848096		[learning rate: 0.0057916]
	Learning Rate: 0.00579162
	LOSS [training: 0.20234041665848096 | validation: 0.48217132641622806]
	TIME [epoch: 9.08 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22369005340157763		[learning rate: 0.0057739]
	Learning Rate: 0.00577387
	LOSS [training: 0.22369005340157763 | validation: 0.16512425229290306]
	TIME [epoch: 9.09 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16134518316959517		[learning rate: 0.0057562]
	Learning Rate: 0.00575617
	LOSS [training: 0.16134518316959517 | validation: 0.1562851472182536]
	TIME [epoch: 9.09 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21038157010514916		[learning rate: 0.0057385]
	Learning Rate: 0.00573852
	LOSS [training: 0.21038157010514916 | validation: 0.4486875584781447]
	TIME [epoch: 9.11 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2425210590250034		[learning rate: 0.0057209]
	Learning Rate: 0.00572093
	LOSS [training: 0.2425210590250034 | validation: 0.21404116944454255]
	TIME [epoch: 9.1 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1587162239313943		[learning rate: 0.0057034]
	Learning Rate: 0.00570339
	LOSS [training: 0.1587162239313943 | validation: 0.23661432179766817]
	TIME [epoch: 9.08 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20638324994466442		[learning rate: 0.0056859]
	Learning Rate: 0.00568591
	LOSS [training: 0.20638324994466442 | validation: 0.17735109152826986]
	TIME [epoch: 9.1 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17313138143699902		[learning rate: 0.0056685]
	Learning Rate: 0.00566848
	LOSS [training: 0.17313138143699902 | validation: 0.156416364320478]
	TIME [epoch: 9.11 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17259156536405756		[learning rate: 0.0056511]
	Learning Rate: 0.0056511
	LOSS [training: 0.17259156536405756 | validation: 0.16522467116466738]
	TIME [epoch: 9.09 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18014847909916737		[learning rate: 0.0056338]
	Learning Rate: 0.00563378
	LOSS [training: 0.18014847909916737 | validation: 0.1668193682900968]
	TIME [epoch: 9.1 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27836511982940515		[learning rate: 0.0056165]
	Learning Rate: 0.00561651
	LOSS [training: 0.27836511982940515 | validation: 0.2417298503076652]
	TIME [epoch: 9.09 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20479776270033095		[learning rate: 0.0055993]
	Learning Rate: 0.00559929
	LOSS [training: 0.20479776270033095 | validation: 0.3806895084160309]
	TIME [epoch: 9.1 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3221719499268409		[learning rate: 0.0055821]
	Learning Rate: 0.00558213
	LOSS [training: 0.3221719499268409 | validation: 0.4489741713786149]
	TIME [epoch: 9.09 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28416468785172666		[learning rate: 0.005565]
	Learning Rate: 0.00556502
	LOSS [training: 0.28416468785172666 | validation: 1.1271130423683633]
	TIME [epoch: 9.09 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41837686578420474		[learning rate: 0.005548]
	Learning Rate: 0.00554796
	LOSS [training: 0.41837686578420474 | validation: 0.20095544678213734]
	TIME [epoch: 9.09 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17229296880788653		[learning rate: 0.005531]
	Learning Rate: 0.00553095
	LOSS [training: 0.17229296880788653 | validation: 0.14077057664253337]
	TIME [epoch: 9.1 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22369859216213098		[learning rate: 0.005514]
	Learning Rate: 0.005514
	LOSS [training: 0.22369859216213098 | validation: 0.9825456977896612]
	TIME [epoch: 9.11 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37255580277234157		[learning rate: 0.0054971]
	Learning Rate: 0.0054971
	LOSS [training: 0.37255580277234157 | validation: 0.18855654912773545]
	TIME [epoch: 9.09 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17654593403001914		[learning rate: 0.0054802]
	Learning Rate: 0.00548025
	LOSS [training: 0.17654593403001914 | validation: 0.3699085496934707]
	TIME [epoch: 9.09 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14434150426652673		[learning rate: 0.0054634]
	Learning Rate: 0.00546345
	LOSS [training: 0.14434150426652673 | validation: 0.37798797627177305]
	TIME [epoch: 9.11 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26845775344121436		[learning rate: 0.0054467]
	Learning Rate: 0.0054467
	LOSS [training: 0.26845775344121436 | validation: 0.2065699344729155]
	TIME [epoch: 9.12 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32464898001163		[learning rate: 0.00543]
	Learning Rate: 0.00543
	LOSS [training: 0.32464898001163 | validation: 0.3577060551662201]
	TIME [epoch: 9.11 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17978991191518526		[learning rate: 0.0054134]
	Learning Rate: 0.00541336
	LOSS [training: 0.17978991191518526 | validation: 0.3279246621767742]
	TIME [epoch: 9.1 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31123713294067273		[learning rate: 0.0053968]
	Learning Rate: 0.00539676
	LOSS [training: 0.31123713294067273 | validation: 0.3139556312263585]
	TIME [epoch: 9.11 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19520190120718506		[learning rate: 0.0053802]
	Learning Rate: 0.00538022
	LOSS [training: 0.19520190120718506 | validation: 0.1360491126915941]
	TIME [epoch: 9.12 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18366652733030514		[learning rate: 0.0053637]
	Learning Rate: 0.00536373
	LOSS [training: 0.18366652733030514 | validation: 0.10461626206118069]
	TIME [epoch: 9.09 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1300774828154472		[learning rate: 0.0053473]
	Learning Rate: 0.00534728
	LOSS [training: 0.1300774828154472 | validation: 0.11899104630340937]
	TIME [epoch: 9.1 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20820361227043643		[learning rate: 0.0053309]
	Learning Rate: 0.00533089
	LOSS [training: 0.20820361227043643 | validation: 0.6868447441571516]
	TIME [epoch: 9.1 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22662175076934918		[learning rate: 0.0053146]
	Learning Rate: 0.00531455
	LOSS [training: 0.22662175076934918 | validation: 0.08273212610390684]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_706.pth
	Model improved!!!
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12739603817244743		[learning rate: 0.0052983]
	Learning Rate: 0.00529826
	LOSS [training: 0.12739603817244743 | validation: 0.08307280014509383]
	TIME [epoch: 9.1 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21551314197663088		[learning rate: 0.005282]
	Learning Rate: 0.00528202
	LOSS [training: 0.21551314197663088 | validation: 0.12301821794660764]
	TIME [epoch: 9.09 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09933555783530945		[learning rate: 0.0052658]
	Learning Rate: 0.00526583
	LOSS [training: 0.09933555783530945 | validation: 0.1709995748147378]
	TIME [epoch: 9.1 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20431052519146378		[learning rate: 0.0052497]
	Learning Rate: 0.00524969
	LOSS [training: 0.20431052519146378 | validation: 0.14530468460744583]
	TIME [epoch: 9.11 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09642919582070916		[learning rate: 0.0052336]
	Learning Rate: 0.00523359
	LOSS [training: 0.09642919582070916 | validation: 0.11718555580225057]
	TIME [epoch: 9.09 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13556076977289716		[learning rate: 0.0052176]
	Learning Rate: 0.00521755
	LOSS [training: 0.13556076977289716 | validation: 0.10040822481546545]
	TIME [epoch: 9.09 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5838011829124943		[learning rate: 0.0052016]
	Learning Rate: 0.00520156
	LOSS [training: 0.5838011829124943 | validation: 0.43195723921347073]
	TIME [epoch: 9.09 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16057739998068457		[learning rate: 0.0051856]
	Learning Rate: 0.00518561
	LOSS [training: 0.16057739998068457 | validation: 0.12422096042089933]
	TIME [epoch: 9.1 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13159729610827192		[learning rate: 0.0051697]
	Learning Rate: 0.00516972
	LOSS [training: 0.13159729610827192 | validation: 0.15996226215551015]
	TIME [epoch: 9.11 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18138609418336737		[learning rate: 0.0051539]
	Learning Rate: 0.00515387
	LOSS [training: 0.18138609418336737 | validation: 0.24496420276440833]
	TIME [epoch: 9.09 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3882260428004366		[learning rate: 0.0051381]
	Learning Rate: 0.00513807
	LOSS [training: 0.3882260428004366 | validation: 0.5182443084154869]
	TIME [epoch: 9.09 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37972417402433495		[learning rate: 0.0051223]
	Learning Rate: 0.00512232
	LOSS [training: 0.37972417402433495 | validation: 0.3242559716356528]
	TIME [epoch: 9.1 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9026059105167086		[learning rate: 0.0051066]
	Learning Rate: 0.00510662
	LOSS [training: 0.9026059105167086 | validation: 0.7360121288750457]
	TIME [epoch: 9.11 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4304227976746101		[learning rate: 0.005091]
	Learning Rate: 0.00509096
	LOSS [training: 0.4304227976746101 | validation: 0.32636193317328527]
	TIME [epoch: 9.1 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32973056186141714		[learning rate: 0.0050754]
	Learning Rate: 0.00507536
	LOSS [training: 0.32973056186141714 | validation: 0.2961490452625619]
	TIME [epoch: 9.09 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19688983536182075		[learning rate: 0.0050598]
	Learning Rate: 0.0050598
	LOSS [training: 0.19688983536182075 | validation: 0.28994631708941965]
	TIME [epoch: 9.1 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24898069427467825		[learning rate: 0.0050443]
	Learning Rate: 0.00504429
	LOSS [training: 0.24898069427467825 | validation: 0.32345801783966815]
	TIME [epoch: 9.12 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2752721617989373		[learning rate: 0.0050288]
	Learning Rate: 0.00502883
	LOSS [training: 0.2752721617989373 | validation: 0.20459965067928843]
	TIME [epoch: 9.09 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3042610028505394		[learning rate: 0.0050134]
	Learning Rate: 0.00501341
	LOSS [training: 0.3042610028505394 | validation: 0.22936513792317834]
	TIME [epoch: 9.1 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2921483528226849		[learning rate: 0.004998]
	Learning Rate: 0.00499804
	LOSS [training: 0.2921483528226849 | validation: 0.40724304523880006]
	TIME [epoch: 9.09 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2819602547355358		[learning rate: 0.0049827]
	Learning Rate: 0.00498272
	LOSS [training: 0.2819602547355358 | validation: 0.16847698119253962]
	TIME [epoch: 9.12 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16618407453972187		[learning rate: 0.0049674]
	Learning Rate: 0.00496745
	LOSS [training: 0.16618407453972187 | validation: 0.17075594333186886]
	TIME [epoch: 9.1 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15171930668591976		[learning rate: 0.0049522]
	Learning Rate: 0.00495222
	LOSS [training: 0.15171930668591976 | validation: 0.2117605247230953]
	TIME [epoch: 9.09 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17673274639198114		[learning rate: 0.004937]
	Learning Rate: 0.00493704
	LOSS [training: 0.17673274639198114 | validation: 0.21678807007563883]
	TIME [epoch: 9.09 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1711858970613464		[learning rate: 0.0049219]
	Learning Rate: 0.00492191
	LOSS [training: 0.1711858970613464 | validation: 0.24052481773436937]
	TIME [epoch: 9.11 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2883299804361674		[learning rate: 0.0049068]
	Learning Rate: 0.00490682
	LOSS [training: 0.2883299804361674 | validation: 0.7437812172448905]
	TIME [epoch: 9.1 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0008339602413368		[learning rate: 0.0048918]
	Learning Rate: 0.00489178
	LOSS [training: 1.0008339602413368 | validation: 0.8450783405779708]
	TIME [epoch: 9.09 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3517445669556528		[learning rate: 0.0048768]
	Learning Rate: 0.00487678
	LOSS [training: 0.3517445669556528 | validation: 0.21931848822130717]
	TIME [epoch: 9.11 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18339599681943472		[learning rate: 0.0048618]
	Learning Rate: 0.00486183
	LOSS [training: 0.18339599681943472 | validation: 0.206868158628121]
	TIME [epoch: 9.11 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19086193152093986		[learning rate: 0.0048469]
	Learning Rate: 0.00484693
	LOSS [training: 0.19086193152093986 | validation: 0.3113828756394591]
	TIME [epoch: 9.12 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18576100608571036		[learning rate: 0.0048321]
	Learning Rate: 0.00483207
	LOSS [training: 0.18576100608571036 | validation: 0.22901161205787035]
	TIME [epoch: 9.09 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16379531368994021		[learning rate: 0.0048173]
	Learning Rate: 0.00481726
	LOSS [training: 0.16379531368994021 | validation: 0.29561642418942174]
	TIME [epoch: 9.1 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16727249622854642		[learning rate: 0.0048025]
	Learning Rate: 0.00480249
	LOSS [training: 0.16727249622854642 | validation: 0.12480504594675612]
	TIME [epoch: 9.11 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1692844626101862		[learning rate: 0.0047878]
	Learning Rate: 0.00478777
	LOSS [training: 0.1692844626101862 | validation: 0.13716193251145986]
	TIME [epoch: 9.11 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12013050934637474		[learning rate: 0.0047731]
	Learning Rate: 0.00477309
	LOSS [training: 0.12013050934637474 | validation: 0.18674006093327317]
	TIME [epoch: 9.09 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13715466741014506		[learning rate: 0.0047585]
	Learning Rate: 0.00475846
	LOSS [training: 0.13715466741014506 | validation: 0.18827139458440795]
	TIME [epoch: 9.1 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15017162303554205		[learning rate: 0.0047439]
	Learning Rate: 0.00474388
	LOSS [training: 0.15017162303554205 | validation: 0.18352510868977073]
	TIME [epoch: 9.1 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14353429616140528		[learning rate: 0.0047293]
	Learning Rate: 0.00472933
	LOSS [training: 0.14353429616140528 | validation: 0.14518825171785701]
	TIME [epoch: 9.11 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13207938975416053		[learning rate: 0.0047148]
	Learning Rate: 0.00471484
	LOSS [training: 0.13207938975416053 | validation: 0.22888898501960414]
	TIME [epoch: 9.1 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15352072413052806		[learning rate: 0.0047004]
	Learning Rate: 0.00470038
	LOSS [training: 0.15352072413052806 | validation: 0.12430122915535786]
	TIME [epoch: 9.08 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1657208905858345		[learning rate: 0.004686]
	Learning Rate: 0.00468598
	LOSS [training: 0.1657208905858345 | validation: 0.23058541039807198]
	TIME [epoch: 9.09 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1601409005487907		[learning rate: 0.0046716]
	Learning Rate: 0.00467161
	LOSS [training: 0.1601409005487907 | validation: 0.16846830698776777]
	TIME [epoch: 9.11 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15222946106257576		[learning rate: 0.0046573]
	Learning Rate: 0.00465729
	LOSS [training: 0.15222946106257576 | validation: 0.15974052715935647]
	TIME [epoch: 9.1 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14212717765440835		[learning rate: 0.004643]
	Learning Rate: 0.00464301
	LOSS [training: 0.14212717765440835 | validation: 0.21726895472598712]
	TIME [epoch: 9.09 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15722645397612817		[learning rate: 0.0046288]
	Learning Rate: 0.00462878
	LOSS [training: 0.15722645397612817 | validation: 0.19632949843937902]
	TIME [epoch: 9.08 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1473875949813399		[learning rate: 0.0046146]
	Learning Rate: 0.00461459
	LOSS [training: 0.1473875949813399 | validation: 0.21029211279137727]
	TIME [epoch: 9.1 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15083948080491932		[learning rate: 0.0046004]
	Learning Rate: 0.00460045
	LOSS [training: 0.15083948080491932 | validation: 0.1659546979277003]
	TIME [epoch: 9.1 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13369513084346243		[learning rate: 0.0045863]
	Learning Rate: 0.00458634
	LOSS [training: 0.13369513084346243 | validation: 0.1736410219374729]
	TIME [epoch: 9.09 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1682724207532945		[learning rate: 0.0045723]
	Learning Rate: 0.00457229
	LOSS [training: 0.1682724207532945 | validation: 0.44831713012259644]
	TIME [epoch: 9.09 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2100615446361326		[learning rate: 0.0045583]
	Learning Rate: 0.00455827
	LOSS [training: 0.2100615446361326 | validation: 0.2275500943361073]
	TIME [epoch: 9.12 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17730031336109695		[learning rate: 0.0045443]
	Learning Rate: 0.0045443
	LOSS [training: 0.17730031336109695 | validation: 0.20154687062720092]
	TIME [epoch: 9.09 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14283756364613193		[learning rate: 0.0045304]
	Learning Rate: 0.00453037
	LOSS [training: 0.14283756364613193 | validation: 0.24258184830572554]
	TIME [epoch: 9.09 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18059899829252812		[learning rate: 0.0045165]
	Learning Rate: 0.00451648
	LOSS [training: 0.18059899829252812 | validation: 0.15036943393613775]
	TIME [epoch: 9.1 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13327771383212897		[learning rate: 0.0045026]
	Learning Rate: 0.00450263
	LOSS [training: 0.13327771383212897 | validation: 0.1389133388326802]
	TIME [epoch: 9.1 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14706166952640806		[learning rate: 0.0044888]
	Learning Rate: 0.00448883
	LOSS [training: 0.14706166952640806 | validation: 0.15372594214516944]
	TIME [epoch: 9.11 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12559186175384446		[learning rate: 0.0044751]
	Learning Rate: 0.00447507
	LOSS [training: 0.12559186175384446 | validation: 0.17958095611914773]
	TIME [epoch: 9.09 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13766445150497247		[learning rate: 0.0044614]
	Learning Rate: 0.00446135
	LOSS [training: 0.13766445150497247 | validation: 0.17309596245595374]
	TIME [epoch: 9.08 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1656595767372232		[learning rate: 0.0044477]
	Learning Rate: 0.00444768
	LOSS [training: 0.1656595767372232 | validation: 0.7286450122162449]
	TIME [epoch: 9.11 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34988849531477506		[learning rate: 0.004434]
	Learning Rate: 0.00443404
	LOSS [training: 0.34988849531477506 | validation: 0.2902912881007129]
	TIME [epoch: 9.11 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14419223838450831		[learning rate: 0.0044205]
	Learning Rate: 0.00442045
	LOSS [training: 0.14419223838450831 | validation: 0.18007240917804845]
	TIME [epoch: 9.1 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16298840869417058		[learning rate: 0.0044069]
	Learning Rate: 0.0044069
	LOSS [training: 0.16298840869417058 | validation: 0.1423358641079326]
	TIME [epoch: 9.09 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12433535958122344		[learning rate: 0.0043934]
	Learning Rate: 0.00439339
	LOSS [training: 0.12433535958122344 | validation: 0.15543025887051837]
	TIME [epoch: 9.1 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1444261056293081		[learning rate: 0.0043799]
	Learning Rate: 0.00437992
	LOSS [training: 0.1444261056293081 | validation: 0.13044660524705098]
	TIME [epoch: 9.12 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13553533367273302		[learning rate: 0.0043665]
	Learning Rate: 0.0043665
	LOSS [training: 0.13553533367273302 | validation: 0.1596143465401516]
	TIME [epoch: 9.09 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27500547639308165		[learning rate: 0.0043531]
	Learning Rate: 0.00435311
	LOSS [training: 0.27500547639308165 | validation: 0.1546944351940091]
	TIME [epoch: 9.11 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16374968660978304		[learning rate: 0.0043398]
	Learning Rate: 0.00433977
	LOSS [training: 0.16374968660978304 | validation: 0.189174238900298]
	TIME [epoch: 9.09 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17503598959071057		[learning rate: 0.0043265]
	Learning Rate: 0.00432647
	LOSS [training: 0.17503598959071057 | validation: 0.16105156319759478]
	TIME [epoch: 9.12 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12368533434714875		[learning rate: 0.0043132]
	Learning Rate: 0.0043132
	LOSS [training: 0.12368533434714875 | validation: 0.16785917871932896]
	TIME [epoch: 9.1 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11208912145653731		[learning rate: 0.0043]
	Learning Rate: 0.00429998
	LOSS [training: 0.11208912145653731 | validation: 0.10695641247966745]
	TIME [epoch: 9.09 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12611687238403593		[learning rate: 0.0042868]
	Learning Rate: 0.0042868
	LOSS [training: 0.12611687238403593 | validation: 0.25032564460871853]
	TIME [epoch: 9.09 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1900553473945892		[learning rate: 0.0042737]
	Learning Rate: 0.00427366
	LOSS [training: 0.1900553473945892 | validation: 0.14515557998630504]
	TIME [epoch: 9.13 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17103078334438687		[learning rate: 0.0042606]
	Learning Rate: 0.00426056
	LOSS [training: 0.17103078334438687 | validation: 0.19746792072036146]
	TIME [epoch: 9.1 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1470237799508359		[learning rate: 0.0042475]
	Learning Rate: 0.0042475
	LOSS [training: 0.1470237799508359 | validation: 0.18237681533668698]
	TIME [epoch: 9.1 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14331134135303586		[learning rate: 0.0042345]
	Learning Rate: 0.00423448
	LOSS [training: 0.14331134135303586 | validation: 0.18319191292606124]
	TIME [epoch: 9.09 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14558517768833915		[learning rate: 0.0042215]
	Learning Rate: 0.0042215
	LOSS [training: 0.14558517768833915 | validation: 0.12345775198748526]
	TIME [epoch: 9.12 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18516464841086325		[learning rate: 0.0042086]
	Learning Rate: 0.00420856
	LOSS [training: 0.18516464841086325 | validation: 0.16531133658579222]
	TIME [epoch: 9.1 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15827019412703186		[learning rate: 0.0041957]
	Learning Rate: 0.00419566
	LOSS [training: 0.15827019412703186 | validation: 0.1554493330790987]
	TIME [epoch: 9.1 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13107080793468412		[learning rate: 0.0041828]
	Learning Rate: 0.0041828
	LOSS [training: 0.13107080793468412 | validation: 0.14468850340895167]
	TIME [epoch: 9.09 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12422780570903172		[learning rate: 0.00417]
	Learning Rate: 0.00416997
	LOSS [training: 0.12422780570903172 | validation: 0.13055947516915373]
	TIME [epoch: 9.11 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14038073781894814		[learning rate: 0.0041572]
	Learning Rate: 0.00415719
	LOSS [training: 0.14038073781894814 | validation: 0.1737726386137066]
	TIME [epoch: 9.1 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13606737337762215		[learning rate: 0.0041444]
	Learning Rate: 0.00414445
	LOSS [training: 0.13606737337762215 | validation: 0.32950103844180123]
	TIME [epoch: 9.09 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16253285647934573		[learning rate: 0.0041317]
	Learning Rate: 0.00413174
	LOSS [training: 0.16253285647934573 | validation: 0.10410101796657985]
	TIME [epoch: 9.1 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12325224033007978		[learning rate: 0.0041191]
	Learning Rate: 0.00411908
	LOSS [training: 0.12325224033007978 | validation: 0.24258201473223948]
	TIME [epoch: 9.11 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17641078542014157		[learning rate: 0.0041065]
	Learning Rate: 0.00410645
	LOSS [training: 0.17641078542014157 | validation: 0.31904838754288734]
	TIME [epoch: 9.11 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25832816106023354		[learning rate: 0.0040939]
	Learning Rate: 0.00409386
	LOSS [training: 0.25832816106023354 | validation: 0.19524613774814786]
	TIME [epoch: 9.1 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18707591901369186		[learning rate: 0.0040813]
	Learning Rate: 0.00408131
	LOSS [training: 0.18707591901369186 | validation: 0.20448850094346138]
	TIME [epoch: 9.08 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5130839430696612		[learning rate: 0.0040688]
	Learning Rate: 0.0040688
	LOSS [training: 0.5130839430696612 | validation: 0.26777452323066575]
	TIME [epoch: 9.11 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1612849104211414		[learning rate: 0.0040563]
	Learning Rate: 0.00405633
	LOSS [training: 0.1612849104211414 | validation: 0.2629946039891654]
	TIME [epoch: 9.1 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17110805802707532		[learning rate: 0.0040439]
	Learning Rate: 0.0040439
	LOSS [training: 0.17110805802707532 | validation: 0.26882794928676756]
	TIME [epoch: 9.09 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24956225733239693		[learning rate: 0.0040315]
	Learning Rate: 0.0040315
	LOSS [training: 0.24956225733239693 | validation: 0.16715234275242613]
	TIME [epoch: 9.09 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17160679413589314		[learning rate: 0.0040191]
	Learning Rate: 0.00401914
	LOSS [training: 0.17160679413589314 | validation: 0.40474881609004343]
	TIME [epoch: 9.09 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12317888558713844		[learning rate: 0.0040068]
	Learning Rate: 0.00400682
	LOSS [training: 0.12317888558713844 | validation: 0.1576359588964984]
	TIME [epoch: 9.11 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12046097647194257		[learning rate: 0.0039945]
	Learning Rate: 0.00399454
	LOSS [training: 0.12046097647194257 | validation: 0.09852542400527367]
	TIME [epoch: 9.1 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25861005706044227		[learning rate: 0.0039823]
	Learning Rate: 0.00398229
	LOSS [training: 0.25861005706044227 | validation: 0.08739381472893033]
	TIME [epoch: 9.09 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11910137108267302		[learning rate: 0.0039701]
	Learning Rate: 0.00397009
	LOSS [training: 0.11910137108267302 | validation: 0.23054739540062913]
	TIME [epoch: 9.09 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15200561959518694		[learning rate: 0.0039579]
	Learning Rate: 0.00395792
	LOSS [training: 0.15200561959518694 | validation: 0.14896383133942956]
	TIME [epoch: 9.11 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18297401187074308		[learning rate: 0.0039458]
	Learning Rate: 0.00394578
	LOSS [training: 0.18297401187074308 | validation: 0.19900076743726658]
	TIME [epoch: 9.09 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12272935118968335		[learning rate: 0.0039337]
	Learning Rate: 0.00393369
	LOSS [training: 0.12272935118968335 | validation: 0.10097431364404433]
	TIME [epoch: 9.08 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09596689549482187		[learning rate: 0.0039216]
	Learning Rate: 0.00392163
	LOSS [training: 0.09596689549482187 | validation: 0.12062942993616677]
	TIME [epoch: 9.09 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13175845192788735		[learning rate: 0.0039096]
	Learning Rate: 0.00390961
	LOSS [training: 0.13175845192788735 | validation: 0.11216696798984517]
	TIME [epoch: 9.11 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0855463526915372		[learning rate: 0.0038976]
	Learning Rate: 0.00389762
	LOSS [training: 0.0855463526915372 | validation: 0.10939697585385663]
	TIME [epoch: 9.09 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12864068445449683		[learning rate: 0.0038857]
	Learning Rate: 0.00388568
	LOSS [training: 0.12864068445449683 | validation: 0.22079533910845744]
	TIME [epoch: 9.09 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1491843992989872		[learning rate: 0.0038738]
	Learning Rate: 0.00387377
	LOSS [training: 0.1491843992989872 | validation: 0.1467551148453608]
	TIME [epoch: 9.1 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15029755722881152		[learning rate: 0.0038619]
	Learning Rate: 0.00386189
	LOSS [training: 0.15029755722881152 | validation: 0.17961125144067694]
	TIME [epoch: 9.11 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12873607172955784		[learning rate: 0.0038501]
	Learning Rate: 0.00385005
	LOSS [training: 0.12873607172955784 | validation: 0.15329263245757113]
	TIME [epoch: 9.1 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09420756320847803		[learning rate: 0.0038383]
	Learning Rate: 0.00383825
	LOSS [training: 0.09420756320847803 | validation: 0.19160764981781836]
	TIME [epoch: 9.09 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1199278063077261		[learning rate: 0.0038265]
	Learning Rate: 0.00382648
	LOSS [training: 0.1199278063077261 | validation: 0.11754865780444643]
	TIME [epoch: 9.09 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10709309077930015		[learning rate: 0.0038148]
	Learning Rate: 0.00381476
	LOSS [training: 0.10709309077930015 | validation: 0.2052832377624172]
	TIME [epoch: 9.1 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13283651888292267		[learning rate: 0.0038031]
	Learning Rate: 0.00380306
	LOSS [training: 0.13283651888292267 | validation: 0.2170518049899039]
	TIME [epoch: 9.11 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.147701537056486		[learning rate: 0.0037914]
	Learning Rate: 0.0037914
	LOSS [training: 0.147701537056486 | validation: 0.3562220177272239]
	TIME [epoch: 9.09 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1713837054416791		[learning rate: 0.0037798]
	Learning Rate: 0.00377978
	LOSS [training: 0.1713837054416791 | validation: 0.3768102118629333]
	TIME [epoch: 9.1 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5081078237882218		[learning rate: 0.0037682]
	Learning Rate: 0.00376819
	LOSS [training: 0.5081078237882218 | validation: 0.21044602854183564]
	TIME [epoch: 9.11 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16053936767412672		[learning rate: 0.0037566]
	Learning Rate: 0.00375664
	LOSS [training: 0.16053936767412672 | validation: 0.13524793131236235]
	TIME [epoch: 9.1 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1292446755035983		[learning rate: 0.0037451]
	Learning Rate: 0.00374513
	LOSS [training: 0.1292446755035983 | validation: 0.23447211664457218]
	TIME [epoch: 9.09 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18684331336845555		[learning rate: 0.0037336]
	Learning Rate: 0.00373365
	LOSS [training: 0.18684331336845555 | validation: 0.10774068552457619]
	TIME [epoch: 9.09 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10883334184216018		[learning rate: 0.0037222]
	Learning Rate: 0.0037222
	LOSS [training: 0.10883334184216018 | validation: 0.2812231018976064]
	TIME [epoch: 9.1 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11068417556124452		[learning rate: 0.0037108]
	Learning Rate: 0.00371079
	LOSS [training: 0.11068417556124452 | validation: 0.18910458890284992]
	TIME [epoch: 9.13 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0993998199006623		[learning rate: 0.0036994]
	Learning Rate: 0.00369942
	LOSS [training: 0.0993998199006623 | validation: 0.18323435698318413]
	TIME [epoch: 9.09 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12557370712849242		[learning rate: 0.0036881]
	Learning Rate: 0.00368808
	LOSS [training: 0.12557370712849242 | validation: 0.18184343611289722]
	TIME [epoch: 9.1 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14819676160867143		[learning rate: 0.0036768]
	Learning Rate: 0.00367677
	LOSS [training: 0.14819676160867143 | validation: 0.10656677270147943]
	TIME [epoch: 9.09 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10796242630448565		[learning rate: 0.0036655]
	Learning Rate: 0.0036655
	LOSS [training: 0.10796242630448565 | validation: 0.33927535144158916]
	TIME [epoch: 9.1 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17716163514102476		[learning rate: 0.0036543]
	Learning Rate: 0.00365426
	LOSS [training: 0.17716163514102476 | validation: 0.26584537572430017]
	TIME [epoch: 9.09 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14932989710470795		[learning rate: 0.0036431]
	Learning Rate: 0.00364306
	LOSS [training: 0.14932989710470795 | validation: 0.28782068887078077]
	TIME [epoch: 9.08 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7443899783668885		[learning rate: 0.0036319]
	Learning Rate: 0.0036319
	LOSS [training: 0.7443899783668885 | validation: 0.27718618367439285]
	TIME [epoch: 9.09 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15889760032628558		[learning rate: 0.0036208]
	Learning Rate: 0.00362076
	LOSS [training: 0.15889760032628558 | validation: 0.121362999653291]
	TIME [epoch: 9.11 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08424311299790582		[learning rate: 0.0036097]
	Learning Rate: 0.00360966
	LOSS [training: 0.08424311299790582 | validation: 0.09622980677172563]
	TIME [epoch: 9.09 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08144440515656895		[learning rate: 0.0035986]
	Learning Rate: 0.0035986
	LOSS [training: 0.08144440515656895 | validation: 0.1541771407600355]
	TIME [epoch: 9.09 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11824203779007643		[learning rate: 0.0035876]
	Learning Rate: 0.00358757
	LOSS [training: 0.11824203779007643 | validation: 0.148455469742092]
	TIME [epoch: 9.08 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11246696651145946		[learning rate: 0.0035766]
	Learning Rate: 0.00357657
	LOSS [training: 0.11246696651145946 | validation: 0.12492844995376412]
	TIME [epoch: 9.11 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07688078613945531		[learning rate: 0.0035656]
	Learning Rate: 0.00356561
	LOSS [training: 0.07688078613945531 | validation: 0.13661077316367945]
	TIME [epoch: 9.1 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09734122689918452		[learning rate: 0.0035547]
	Learning Rate: 0.00355468
	LOSS [training: 0.09734122689918452 | validation: 0.15320065575211772]
	TIME [epoch: 9.09 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07411788070327102		[learning rate: 0.0035438]
	Learning Rate: 0.00354378
	LOSS [training: 0.07411788070327102 | validation: 0.08395017815071171]
	TIME [epoch: 9.09 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31596110792882154		[learning rate: 0.0035329]
	Learning Rate: 0.00353292
	LOSS [training: 0.31596110792882154 | validation: 0.3468461517646201]
	TIME [epoch: 9.1 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16598467491586583		[learning rate: 0.0035221]
	Learning Rate: 0.00352209
	LOSS [training: 0.16598467491586583 | validation: 0.10437214046772146]
	TIME [epoch: 9.1 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14569241382598014		[learning rate: 0.0035113]
	Learning Rate: 0.00351129
	LOSS [training: 0.14569241382598014 | validation: 0.15485852770010872]
	TIME [epoch: 9.09 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1264406183389784		[learning rate: 0.0035005]
	Learning Rate: 0.00350053
	LOSS [training: 0.1264406183389784 | validation: 0.1303015103227524]
	TIME [epoch: 9.1 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10020932389174668		[learning rate: 0.0034898]
	Learning Rate: 0.0034898
	LOSS [training: 0.10020932389174668 | validation: 0.11260958664105128]
	TIME [epoch: 9.1 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1216882334197639		[learning rate: 0.0034791]
	Learning Rate: 0.0034791
	LOSS [training: 0.1216882334197639 | validation: 0.19010875803818386]
	TIME [epoch: 9.1 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2546486575946818		[learning rate: 0.0034684]
	Learning Rate: 0.00346843
	LOSS [training: 0.2546486575946818 | validation: 0.21055398388496924]
	TIME [epoch: 9.09 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18854946804938427		[learning rate: 0.0034578]
	Learning Rate: 0.0034578
	LOSS [training: 0.18854946804938427 | validation: 0.2147312851897681]
	TIME [epoch: 9.09 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1406824180560827		[learning rate: 0.0034472]
	Learning Rate: 0.0034472
	LOSS [training: 0.1406824180560827 | validation: 0.15212636014308284]
	TIME [epoch: 9.09 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11251882653373495		[learning rate: 0.0034366]
	Learning Rate: 0.00343663
	LOSS [training: 0.11251882653373495 | validation: 0.08862587391199732]
	TIME [epoch: 9.11 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08807607763863075		[learning rate: 0.0034261]
	Learning Rate: 0.0034261
	LOSS [training: 0.08807607763863075 | validation: 0.09007654478887861]
	TIME [epoch: 9.09 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07054860695578091		[learning rate: 0.0034156]
	Learning Rate: 0.0034156
	LOSS [training: 0.07054860695578091 | validation: 0.08249987526235904]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_850.pth
	Model improved!!!
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08244063094711573		[learning rate: 0.0034051]
	Learning Rate: 0.00340513
	LOSS [training: 0.08244063094711573 | validation: 0.06934163569731305]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_851.pth
	Model improved!!!
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08656353834431375		[learning rate: 0.0033947]
	Learning Rate: 0.00339469
	LOSS [training: 0.08656353834431375 | validation: 0.07387014176921865]
	TIME [epoch: 9.12 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11399917933557199		[learning rate: 0.0033843]
	Learning Rate: 0.00338428
	LOSS [training: 0.11399917933557199 | validation: 0.1167554604953992]
	TIME [epoch: 9.09 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10997007225955915		[learning rate: 0.0033739]
	Learning Rate: 0.00337391
	LOSS [training: 0.10997007225955915 | validation: 0.14311955731360865]
	TIME [epoch: 9.1 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1584635212245021		[learning rate: 0.0033636]
	Learning Rate: 0.00336357
	LOSS [training: 0.1584635212245021 | validation: 0.14090302801631727]
	TIME [epoch: 9.08 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11028580165709043		[learning rate: 0.0033533]
	Learning Rate: 0.00335326
	LOSS [training: 0.11028580165709043 | validation: 0.15522663562557656]
	TIME [epoch: 9.1 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1490989169823662		[learning rate: 0.003343]
	Learning Rate: 0.00334298
	LOSS [training: 0.1490989169823662 | validation: 0.15611653625458216]
	TIME [epoch: 9.1 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13358737863101874		[learning rate: 0.0033327]
	Learning Rate: 0.00333273
	LOSS [training: 0.13358737863101874 | validation: 0.12575404239223933]
	TIME [epoch: 9.09 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11368309321864015		[learning rate: 0.0033225]
	Learning Rate: 0.00332251
	LOSS [training: 0.11368309321864015 | validation: 0.12156196835685834]
	TIME [epoch: 9.09 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13600145493663776		[learning rate: 0.0033123]
	Learning Rate: 0.00331233
	LOSS [training: 0.13600145493663776 | validation: 0.13626554066325258]
	TIME [epoch: 9.1 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1289516546355835		[learning rate: 0.0033022]
	Learning Rate: 0.00330217
	LOSS [training: 0.1289516546355835 | validation: 0.18332010352535105]
	TIME [epoch: 9.1 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12554290552865888		[learning rate: 0.0032921]
	Learning Rate: 0.00329205
	LOSS [training: 0.12554290552865888 | validation: 0.1241815040367932]
	TIME [epoch: 9.08 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09013812739062851		[learning rate: 0.003282]
	Learning Rate: 0.00328196
	LOSS [training: 0.09013812739062851 | validation: 0.1135840621433364]
	TIME [epoch: 9.08 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0982767272689731		[learning rate: 0.0032719]
	Learning Rate: 0.0032719
	LOSS [training: 0.0982767272689731 | validation: 0.11956635134864235]
	TIME [epoch: 9.09 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09817950979606378		[learning rate: 0.0032619]
	Learning Rate: 0.00326187
	LOSS [training: 0.09817950979606378 | validation: 0.23976296909397948]
	TIME [epoch: 9.11 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15000393294641723		[learning rate: 0.0032519]
	Learning Rate: 0.00325187
	LOSS [training: 0.15000393294641723 | validation: 0.1062767082998024]
	TIME [epoch: 9.08 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19598705618428097		[learning rate: 0.0032419]
	Learning Rate: 0.0032419
	LOSS [training: 0.19598705618428097 | validation: 0.3171782501240521]
	TIME [epoch: 9.09 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17950257374355516		[learning rate: 0.003232]
	Learning Rate: 0.00323197
	LOSS [training: 0.17950257374355516 | validation: 0.19317525219433038]
	TIME [epoch: 9.09 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2581270228641753		[learning rate: 0.0032221]
	Learning Rate: 0.00322206
	LOSS [training: 0.2581270228641753 | validation: 0.13282544998269458]
	TIME [epoch: 9.11 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12300252441583166		[learning rate: 0.0032122]
	Learning Rate: 0.00321218
	LOSS [training: 0.12300252441583166 | validation: 0.1208734887536973]
	TIME [epoch: 9.09 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11574059196277124		[learning rate: 0.0032023]
	Learning Rate: 0.00320233
	LOSS [training: 0.11574059196277124 | validation: 0.14459022536565472]
	TIME [epoch: 9.09 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1258553005540814		[learning rate: 0.0031925]
	Learning Rate: 0.00319252
	LOSS [training: 0.1258553005540814 | validation: 0.12277800785568879]
	TIME [epoch: 9.09 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10616764495324911		[learning rate: 0.0031827]
	Learning Rate: 0.00318273
	LOSS [training: 0.10616764495324911 | validation: 0.11681092667850183]
	TIME [epoch: 9.11 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09902653957054945		[learning rate: 0.003173]
	Learning Rate: 0.00317297
	LOSS [training: 0.09902653957054945 | validation: 0.11440192563828855]
	TIME [epoch: 9.09 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09502089934775773		[learning rate: 0.0031632]
	Learning Rate: 0.00316325
	LOSS [training: 0.09502089934775773 | validation: 0.11188590674486387]
	TIME [epoch: 9.08 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11064891792241005		[learning rate: 0.0031536]
	Learning Rate: 0.00315355
	LOSS [training: 0.11064891792241005 | validation: 0.13846439120871473]
	TIME [epoch: 9.09 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11947205217608778		[learning rate: 0.0031439]
	Learning Rate: 0.00314389
	LOSS [training: 0.11947205217608778 | validation: 0.11164018472256877]
	TIME [epoch: 9.11 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10910455134405894		[learning rate: 0.0031342]
	Learning Rate: 0.00313425
	LOSS [training: 0.10910455134405894 | validation: 0.12370692216155216]
	TIME [epoch: 9.09 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1276041200094205		[learning rate: 0.0031246]
	Learning Rate: 0.00312464
	LOSS [training: 0.1276041200094205 | validation: 0.16740240663209338]
	TIME [epoch: 9.09 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1297323495351385		[learning rate: 0.0031151]
	Learning Rate: 0.00311506
	LOSS [training: 0.1297323495351385 | validation: 0.1684682608832252]
	TIME [epoch: 9.09 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.125604643357151		[learning rate: 0.0031055]
	Learning Rate: 0.00310551
	LOSS [training: 0.125604643357151 | validation: 0.09640533092860398]
	TIME [epoch: 9.11 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1020768661099573		[learning rate: 0.003096]
	Learning Rate: 0.00309599
	LOSS [training: 0.1020768661099573 | validation: 0.1470770047636828]
	TIME [epoch: 9.09 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10192775542076833		[learning rate: 0.0030865]
	Learning Rate: 0.0030865
	LOSS [training: 0.10192775542076833 | validation: 0.1784115270557725]
	TIME [epoch: 9.12 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14340398051204795		[learning rate: 0.003077]
	Learning Rate: 0.00307704
	LOSS [training: 0.14340398051204795 | validation: 0.16315986825156426]
	TIME [epoch: 9.09 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17300323851152438		[learning rate: 0.0030676]
	Learning Rate: 0.00306761
	LOSS [training: 0.17300323851152438 | validation: 0.15350277575681792]
	TIME [epoch: 9.1 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1828346988601183		[learning rate: 0.0030582]
	Learning Rate: 0.00305821
	LOSS [training: 0.1828346988601183 | validation: 0.19768345874858395]
	TIME [epoch: 9.11 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12778236150657343		[learning rate: 0.0030488]
	Learning Rate: 0.00304883
	LOSS [training: 0.12778236150657343 | validation: 0.19745296290894077]
	TIME [epoch: 9.09 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11234979684395945		[learning rate: 0.0030395]
	Learning Rate: 0.00303948
	LOSS [training: 0.11234979684395945 | validation: 0.31926227878118196]
	TIME [epoch: 9.09 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18897857626639938		[learning rate: 0.0030302]
	Learning Rate: 0.00303017
	LOSS [training: 0.18897857626639938 | validation: 0.18279993720643498]
	TIME [epoch: 9.1 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1157436848435538		[learning rate: 0.0030209]
	Learning Rate: 0.00302088
	LOSS [training: 0.1157436848435538 | validation: 0.09022416076453775]
	TIME [epoch: 9.1 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10689736039086614		[learning rate: 0.0030116]
	Learning Rate: 0.00301162
	LOSS [training: 0.10689736039086614 | validation: 0.13148926053333582]
	TIME [epoch: 9.1 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06735259706381327		[learning rate: 0.0030024]
	Learning Rate: 0.00300239
	LOSS [training: 0.06735259706381327 | validation: 0.14480235023434213]
	TIME [epoch: 9.09 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14919868987548984		[learning rate: 0.0029932]
	Learning Rate: 0.00299318
	LOSS [training: 0.14919868987548984 | validation: 0.1677774573498213]
	TIME [epoch: 9.09 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1569384892418504		[learning rate: 0.002984]
	Learning Rate: 0.00298401
	LOSS [training: 0.1569384892418504 | validation: 0.16208891330276665]
	TIME [epoch: 9.12 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21458850153353515		[learning rate: 0.0029749]
	Learning Rate: 0.00297486
	LOSS [training: 0.21458850153353515 | validation: 0.21905049820822264]
	TIME [epoch: 9.09 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13525692013905738		[learning rate: 0.0029657]
	Learning Rate: 0.00296574
	LOSS [training: 0.13525692013905738 | validation: 0.10098833024848405]
	TIME [epoch: 9.1 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1037738149653475		[learning rate: 0.0029567]
	Learning Rate: 0.00295665
	LOSS [training: 0.1037738149653475 | validation: 0.14882826805068866]
	TIME [epoch: 9.09 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10763287162922892		[learning rate: 0.0029476]
	Learning Rate: 0.00294759
	LOSS [training: 0.10763287162922892 | validation: 0.11965203824433299]
	TIME [epoch: 9.11 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09159942161821286		[learning rate: 0.0029386]
	Learning Rate: 0.00293855
	LOSS [training: 0.09159942161821286 | validation: 0.12054498464635441]
	TIME [epoch: 9.09 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09494284473115241		[learning rate: 0.0029295]
	Learning Rate: 0.00292954
	LOSS [training: 0.09494284473115241 | validation: 0.11495069491480003]
	TIME [epoch: 9.09 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08190788761230355		[learning rate: 0.0029206]
	Learning Rate: 0.00292056
	LOSS [training: 0.08190788761230355 | validation: 0.10196010455571197]
	TIME [epoch: 9.09 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11338617923955159		[learning rate: 0.0029116]
	Learning Rate: 0.00291161
	LOSS [training: 0.11338617923955159 | validation: 0.10070004535335736]
	TIME [epoch: 9.11 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09995178682713982		[learning rate: 0.0029027]
	Learning Rate: 0.00290269
	LOSS [training: 0.09995178682713982 | validation: 0.16155401234335592]
	TIME [epoch: 9.1 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12692506937663342		[learning rate: 0.0028938]
	Learning Rate: 0.00289379
	LOSS [training: 0.12692506937663342 | validation: 0.14854208362697435]
	TIME [epoch: 9.09 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0884269837847852		[learning rate: 0.0028849]
	Learning Rate: 0.00288492
	LOSS [training: 0.0884269837847852 | validation: 0.11898682499307837]
	TIME [epoch: 9.09 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12293227934277576		[learning rate: 0.0028761]
	Learning Rate: 0.00287607
	LOSS [training: 0.12293227934277576 | validation: 0.15257586735590287]
	TIME [epoch: 9.12 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12292485406737397		[learning rate: 0.0028673]
	Learning Rate: 0.00286726
	LOSS [training: 0.12292485406737397 | validation: 0.06766656091914482]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_907.pth
	Model improved!!!
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08745576946905517		[learning rate: 0.0028585]
	Learning Rate: 0.00285847
	LOSS [training: 0.08745576946905517 | validation: 0.12657699363826055]
	TIME [epoch: 9.09 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08724196786083308		[learning rate: 0.0028497]
	Learning Rate: 0.00284971
	LOSS [training: 0.08724196786083308 | validation: 0.08144813536641672]
	TIME [epoch: 9.09 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10818515571547904		[learning rate: 0.002841]
	Learning Rate: 0.00284097
	LOSS [training: 0.10818515571547904 | validation: 0.11663725626020824]
	TIME [epoch: 9.11 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07938422140604909		[learning rate: 0.0028323]
	Learning Rate: 0.00283226
	LOSS [training: 0.07938422140604909 | validation: 0.1417668109688771]
	TIME [epoch: 9.11 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07672724554156082		[learning rate: 0.0028236]
	Learning Rate: 0.00282358
	LOSS [training: 0.07672724554156082 | validation: 0.08787864695588421]
	TIME [epoch: 9.09 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08911987637275691		[learning rate: 0.0028149]
	Learning Rate: 0.00281492
	LOSS [training: 0.08911987637275691 | validation: 0.12185032059261458]
	TIME [epoch: 9.09 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07967887125725788		[learning rate: 0.0028063]
	Learning Rate: 0.0028063
	LOSS [training: 0.07967887125725788 | validation: 0.09571683201538848]
	TIME [epoch: 9.09 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09554853903956112		[learning rate: 0.0027977]
	Learning Rate: 0.00279769
	LOSS [training: 0.09554853903956112 | validation: 0.09695407560575181]
	TIME [epoch: 9.12 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09073279008088034		[learning rate: 0.0027891]
	Learning Rate: 0.00278912
	LOSS [training: 0.09073279008088034 | validation: 0.13450390323889133]
	TIME [epoch: 9.1 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22238078725873406		[learning rate: 0.0027806]
	Learning Rate: 0.00278057
	LOSS [training: 0.22238078725873406 | validation: 0.2707019996097887]
	TIME [epoch: 9.08 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17160609344514258		[learning rate: 0.002772]
	Learning Rate: 0.00277204
	LOSS [training: 0.17160609344514258 | validation: 0.16201256603924968]
	TIME [epoch: 9.09 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12426916933586503		[learning rate: 0.0027635]
	Learning Rate: 0.00276355
	LOSS [training: 0.12426916933586503 | validation: 0.12403027729526944]
	TIME [epoch: 9.11 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15154792414996385		[learning rate: 0.0027551]
	Learning Rate: 0.00275507
	LOSS [training: 0.15154792414996385 | validation: 0.15494478587216493]
	TIME [epoch: 9.09 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1547484873963793		[learning rate: 0.0027466]
	Learning Rate: 0.00274663
	LOSS [training: 0.1547484873963793 | validation: 0.21106401069944639]
	TIME [epoch: 9.09 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17294379175286365		[learning rate: 0.0027382]
	Learning Rate: 0.00273821
	LOSS [training: 0.17294379175286365 | validation: 0.19998367046865298]
	TIME [epoch: 9.09 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22592465431889316		[learning rate: 0.0027298]
	Learning Rate: 0.00272982
	LOSS [training: 0.22592465431889316 | validation: 0.1608087300673518]
	TIME [epoch: 9.1 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16519849952037466		[learning rate: 0.0027214]
	Learning Rate: 0.00272145
	LOSS [training: 0.16519849952037466 | validation: 0.1750402129924502]
	TIME [epoch: 9.09 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15844792078301698		[learning rate: 0.0027131]
	Learning Rate: 0.00271311
	LOSS [training: 0.15844792078301698 | validation: 0.2283911045405116]
	TIME [epoch: 9.09 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11655908737434569		[learning rate: 0.0027048]
	Learning Rate: 0.00270479
	LOSS [training: 0.11655908737434569 | validation: 0.1253587028097456]
	TIME [epoch: 9.09 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1364284202558082		[learning rate: 0.0026965]
	Learning Rate: 0.0026965
	LOSS [training: 0.1364284202558082 | validation: 0.18455068135136837]
	TIME [epoch: 9.1 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12369642965644734		[learning rate: 0.0026882]
	Learning Rate: 0.00268823
	LOSS [training: 0.12369642965644734 | validation: 0.16163855964897794]
	TIME [epoch: 9.1 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13540407433237658		[learning rate: 0.00268]
	Learning Rate: 0.00267999
	LOSS [training: 0.13540407433237658 | validation: 0.18686419730764336]
	TIME [epoch: 9.08 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1348245267454844		[learning rate: 0.0026718]
	Learning Rate: 0.00267178
	LOSS [training: 0.1348245267454844 | validation: 0.15113882426743916]
	TIME [epoch: 9.08 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16437533078139954		[learning rate: 0.0026636]
	Learning Rate: 0.00266359
	LOSS [training: 0.16437533078139954 | validation: 0.16365543684789047]
	TIME [epoch: 9.1 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17973005153338018		[learning rate: 0.0026554]
	Learning Rate: 0.00265542
	LOSS [training: 0.17973005153338018 | validation: 0.6247761883892923]
	TIME [epoch: 9.1 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23339870767063792		[learning rate: 0.0026473]
	Learning Rate: 0.00264728
	LOSS [training: 0.23339870767063792 | validation: 0.23840902473216405]
	TIME [epoch: 9.09 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23130569518692295		[learning rate: 0.0026392]
	Learning Rate: 0.00263917
	LOSS [training: 0.23130569518692295 | validation: 0.3094568644637353]
	TIME [epoch: 9.09 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20316747433834795		[learning rate: 0.0026311]
	Learning Rate: 0.00263108
	LOSS [training: 0.20316747433834795 | validation: 0.18708713434694335]
	TIME [epoch: 9.09 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2132113006414924		[learning rate: 0.002623]
	Learning Rate: 0.00262301
	LOSS [training: 0.2132113006414924 | validation: 0.1735563272701065]
	TIME [epoch: 9.11 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15209892243059658		[learning rate: 0.002615]
	Learning Rate: 0.00261497
	LOSS [training: 0.15209892243059658 | validation: 0.16743876569955263]
	TIME [epoch: 9.09 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12983406850508586		[learning rate: 0.002607]
	Learning Rate: 0.00260695
	LOSS [training: 0.12983406850508586 | validation: 0.1718246620257699]
	TIME [epoch: 9.09 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14569870246305983		[learning rate: 0.002599]
	Learning Rate: 0.00259896
	LOSS [training: 0.14569870246305983 | validation: 0.12407036095291697]
	TIME [epoch: 9.08 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13116722026919467		[learning rate: 0.002591]
	Learning Rate: 0.002591
	LOSS [training: 0.13116722026919467 | validation: 0.1267247222028609]
	TIME [epoch: 9.12 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11952040377655795		[learning rate: 0.0025831]
	Learning Rate: 0.00258305
	LOSS [training: 0.11952040377655795 | validation: 0.13524432323506058]
	TIME [epoch: 9.09 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17483141153200138		[learning rate: 0.0025751]
	Learning Rate: 0.00257513
	LOSS [training: 0.17483141153200138 | validation: 0.12143900732968513]
	TIME [epoch: 9.09 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09644809634545308		[learning rate: 0.0025672]
	Learning Rate: 0.00256724
	LOSS [training: 0.09644809634545308 | validation: 0.12563814144238045]
	TIME [epoch: 9.09 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11490879694955254		[learning rate: 0.0025594]
	Learning Rate: 0.00255937
	LOSS [training: 0.11490879694955254 | validation: 0.12528984408892146]
	TIME [epoch: 9.11 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12046623489705695		[learning rate: 0.0025515]
	Learning Rate: 0.00255153
	LOSS [training: 0.12046623489705695 | validation: 0.13242578107319486]
	TIME [epoch: 9.1 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13491817008210433		[learning rate: 0.0025437]
	Learning Rate: 0.0025437
	LOSS [training: 0.13491817008210433 | validation: 0.15606006216531082]
	TIME [epoch: 9.08 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1326127040968854		[learning rate: 0.0025359]
	Learning Rate: 0.00253591
	LOSS [training: 0.1326127040968854 | validation: 0.24542086323366172]
	TIME [epoch: 9.09 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20698664064001107		[learning rate: 0.0025281]
	Learning Rate: 0.00252813
	LOSS [training: 0.20698664064001107 | validation: 0.22332375357170856]
	TIME [epoch: 9.11 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29897167955493037		[learning rate: 0.0025204]
	Learning Rate: 0.00252038
	LOSS [training: 0.29897167955493037 | validation: 0.5311403794282004]
	TIME [epoch: 9.1 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2698178191940392		[learning rate: 0.0025127]
	Learning Rate: 0.00251266
	LOSS [training: 0.2698178191940392 | validation: 0.32297834305150486]
	TIME [epoch: 9.08 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2065631433997571		[learning rate: 0.002505]
	Learning Rate: 0.00250496
	LOSS [training: 0.2065631433997571 | validation: 0.2297976164900714]
	TIME [epoch: 9.08 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2611924548082377		[learning rate: 0.0024973]
	Learning Rate: 0.00249728
	LOSS [training: 0.2611924548082377 | validation: 0.18804618152470254]
	TIME [epoch: 9.1 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1505242101050049		[learning rate: 0.0024896]
	Learning Rate: 0.00248962
	LOSS [training: 0.1505242101050049 | validation: 0.15441520475989687]
	TIME [epoch: 9.1 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15208207233226764		[learning rate: 0.002482]
	Learning Rate: 0.00248199
	LOSS [training: 0.15208207233226764 | validation: 0.16238199345434162]
	TIME [epoch: 9.09 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14679713240710748		[learning rate: 0.0024744]
	Learning Rate: 0.00247438
	LOSS [training: 0.14679713240710748 | validation: 0.16446181288253103]
	TIME [epoch: 9.09 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14439697913141272		[learning rate: 0.0024668]
	Learning Rate: 0.0024668
	LOSS [training: 0.14439697913141272 | validation: 0.21020732901578526]
	TIME [epoch: 9.1 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18058324852664437		[learning rate: 0.0024592]
	Learning Rate: 0.00245923
	LOSS [training: 0.18058324852664437 | validation: 0.2151954130344119]
	TIME [epoch: 9.1 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34984995352305		[learning rate: 0.0024517]
	Learning Rate: 0.0024517
	LOSS [training: 0.34984995352305 | validation: 0.4403131611394947]
	TIME [epoch: 9.11 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3320524994458226		[learning rate: 0.0024442]
	Learning Rate: 0.00244418
	LOSS [training: 0.3320524994458226 | validation: 0.63264915713654]
	TIME [epoch: 9.09 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40635182251778146		[learning rate: 0.0024367]
	Learning Rate: 0.00243669
	LOSS [training: 0.40635182251778146 | validation: 0.3026246968721038]
	TIME [epoch: 9.08 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3994256827895001		[learning rate: 0.0024292]
	Learning Rate: 0.00242922
	LOSS [training: 0.3994256827895001 | validation: 0.42479530379005376]
	TIME [epoch: 9.1 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3080563228792147		[learning rate: 0.0024218]
	Learning Rate: 0.00242177
	LOSS [training: 0.3080563228792147 | validation: 0.31445586734076436]
	TIME [epoch: 9.08 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2116133520606221		[learning rate: 0.0024143]
	Learning Rate: 0.00241435
	LOSS [training: 0.2116133520606221 | validation: 0.16617330897903737]
	TIME [epoch: 9.08 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2124639015696395		[learning rate: 0.0024069]
	Learning Rate: 0.00240695
	LOSS [training: 0.2124639015696395 | validation: 0.17300229832109876]
	TIME [epoch: 9.08 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14259372316551297		[learning rate: 0.0023996]
	Learning Rate: 0.00239957
	LOSS [training: 0.14259372316551297 | validation: 0.14089007406696263]
	TIME [epoch: 9.11 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14663458940291393		[learning rate: 0.0023922]
	Learning Rate: 0.00239221
	LOSS [training: 0.14663458940291393 | validation: 0.27076168863035943]
	TIME [epoch: 9.08 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17134634327812262		[learning rate: 0.0023849]
	Learning Rate: 0.00238488
	LOSS [training: 0.17134634327812262 | validation: 0.1381969696711536]
	TIME [epoch: 9.08 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15293176529842278		[learning rate: 0.0023776]
	Learning Rate: 0.00237757
	LOSS [training: 0.15293176529842278 | validation: 0.16066405129400835]
	TIME [epoch: 9.09 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13574659589233845		[learning rate: 0.0023703]
	Learning Rate: 0.00237028
	LOSS [training: 0.13574659589233845 | validation: 0.15596230178277723]
	TIME [epoch: 9.1 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1141897493958864		[learning rate: 0.002363]
	Learning Rate: 0.00236302
	LOSS [training: 0.1141897493958864 | validation: 0.1359786097696838]
	TIME [epoch: 9.09 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14882643194558723		[learning rate: 0.0023558]
	Learning Rate: 0.00235577
	LOSS [training: 0.14882643194558723 | validation: 0.12270418376935077]
	TIME [epoch: 9.09 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1060807829356755		[learning rate: 0.0023486]
	Learning Rate: 0.00234855
	LOSS [training: 0.1060807829356755 | validation: 0.11566224966040292]
	TIME [epoch: 9.09 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10019196569424312		[learning rate: 0.0023414]
	Learning Rate: 0.00234135
	LOSS [training: 0.10019196569424312 | validation: 0.12779460120103753]
	TIME [epoch: 9.11 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11254304091885066		[learning rate: 0.0023342]
	Learning Rate: 0.00233417
	LOSS [training: 0.11254304091885066 | validation: 0.24053910152382935]
	TIME [epoch: 9.09 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10648997438530565		[learning rate: 0.002327]
	Learning Rate: 0.00232702
	LOSS [training: 0.10648997438530565 | validation: 0.09647230161313222]
	TIME [epoch: 9.08 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0823060242984569		[learning rate: 0.0023199]
	Learning Rate: 0.00231989
	LOSS [training: 0.0823060242984569 | validation: 0.13507268256649294]
	TIME [epoch: 9.09 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11921734242535073		[learning rate: 0.0023128]
	Learning Rate: 0.00231277
	LOSS [training: 0.11921734242535073 | validation: 0.14186286825575292]
	TIME [epoch: 9.1 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12048715267563863		[learning rate: 0.0023057]
	Learning Rate: 0.00230569
	LOSS [training: 0.12048715267563863 | validation: 0.15700298390540204]
	TIME [epoch: 9.09 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1051034558155691		[learning rate: 0.0022986]
	Learning Rate: 0.00229862
	LOSS [training: 0.1051034558155691 | validation: 0.08991885290056197]
	TIME [epoch: 9.08 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10138656010439924		[learning rate: 0.0022916]
	Learning Rate: 0.00229157
	LOSS [training: 0.10138656010439924 | validation: 0.08515153986266491]
	TIME [epoch: 9.08 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09303825532942696		[learning rate: 0.0022845]
	Learning Rate: 0.00228455
	LOSS [training: 0.09303825532942696 | validation: 0.0907111834268303]
	TIME [epoch: 9.09 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0695963502954391		[learning rate: 0.0022775]
	Learning Rate: 0.00227754
	LOSS [training: 0.0695963502954391 | validation: 0.11023609832638086]
	TIME [epoch: 9.1 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08362421162915057		[learning rate: 0.0022706]
	Learning Rate: 0.00227056
	LOSS [training: 0.08362421162915057 | validation: 0.13577440938336488]
	TIME [epoch: 9.08 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08838642735794441		[learning rate: 0.0022636]
	Learning Rate: 0.0022636
	LOSS [training: 0.08838642735794441 | validation: 0.091242943230563]
	TIME [epoch: 9.08 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07111139585387997		[learning rate: 0.0022567]
	Learning Rate: 0.00225666
	LOSS [training: 0.07111139585387997 | validation: 0.0948253554835346]
	TIME [epoch: 9.1 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07970733926751458		[learning rate: 0.0022497]
	Learning Rate: 0.00224975
	LOSS [training: 0.07970733926751458 | validation: 0.09535812533053015]
	TIME [epoch: 9.1 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10947669850087424		[learning rate: 0.0022428]
	Learning Rate: 0.00224285
	LOSS [training: 0.10947669850087424 | validation: 0.1972706524621332]
	TIME [epoch: 9.08 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11754670997456522		[learning rate: 0.002236]
	Learning Rate: 0.00223597
	LOSS [training: 0.11754670997456522 | validation: 0.1341271225552782]
	TIME [epoch: 9.08 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09141167868756254		[learning rate: 0.0022291]
	Learning Rate: 0.00222912
	LOSS [training: 0.09141167868756254 | validation: 0.1335369612141476]
	TIME [epoch: 9.08 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13129968852285684		[learning rate: 0.0022223]
	Learning Rate: 0.00222229
	LOSS [training: 0.13129968852285684 | validation: 0.2801651436422111]
	TIME [epoch: 9.1 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16303397157033478		[learning rate: 0.0022155]
	Learning Rate: 0.00221547
	LOSS [training: 0.16303397157033478 | validation: 0.395692963910917]
	TIME [epoch: 9.08 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18276287888364415		[learning rate: 0.0022087]
	Learning Rate: 0.00220868
	LOSS [training: 0.18276287888364415 | validation: 0.20555239909678702]
	TIME [epoch: 9.07 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16128243707051002		[learning rate: 0.0022019]
	Learning Rate: 0.00220191
	LOSS [training: 0.16128243707051002 | validation: 0.21786212768983332]
	TIME [epoch: 9.08 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16621266195542506		[learning rate: 0.0021952]
	Learning Rate: 0.00219516
	LOSS [training: 0.16621266195542506 | validation: 0.19192493896120874]
	TIME [epoch: 9.1 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10785165813750144		[learning rate: 0.0021884]
	Learning Rate: 0.00218843
	LOSS [training: 0.10785165813750144 | validation: 0.17587978599610182]
	TIME [epoch: 9.09 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36392431298643324		[learning rate: 0.0021817]
	Learning Rate: 0.00218173
	LOSS [training: 0.36392431298643324 | validation: 0.35218829046752576]
	TIME [epoch: 9.08 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31267952069860017		[learning rate: 0.002175]
	Learning Rate: 0.00217504
	LOSS [training: 0.31267952069860017 | validation: 0.2804841520323179]
	TIME [epoch: 9.08 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1816866804766256		[learning rate: 0.0021684]
	Learning Rate: 0.00216837
	LOSS [training: 0.1816866804766256 | validation: 0.17148964711561182]
	TIME [epoch: 9.1 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16506147723001743		[learning rate: 0.0021617]
	Learning Rate: 0.00216172
	LOSS [training: 0.16506147723001743 | validation: 0.2016678261929663]
	TIME [epoch: 9.09 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18477489496504262		[learning rate: 0.0021551]
	Learning Rate: 0.0021551
	LOSS [training: 0.18477489496504262 | validation: 0.40133356107450513]
	TIME [epoch: 9.08 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17504623855724236		[learning rate: 0.0021485]
	Learning Rate: 0.00214849
	LOSS [training: 0.17504623855724236 | validation: 0.23070843980226874]
	TIME [epoch: 9.09 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16968629009675995		[learning rate: 0.0021419]
	Learning Rate: 0.0021419
	LOSS [training: 0.16968629009675995 | validation: 0.19974401257291746]
	TIME [epoch: 9.11 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18417801599421144		[learning rate: 0.0021353]
	Learning Rate: 0.00213534
	LOSS [training: 0.18417801599421144 | validation: 0.2279416481235091]
	TIME [epoch: 9.09 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17092654940738966		[learning rate: 0.0021288]
	Learning Rate: 0.00212879
	LOSS [training: 0.17092654940738966 | validation: 0.19759110513390746]
	TIME [epoch: 9.09 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14037947195100262		[learning rate: 0.0021223]
	Learning Rate: 0.00212227
	LOSS [training: 0.14037947195100262 | validation: 0.2598419156028333]
	TIME [epoch: 9.08 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14525276197486817		[learning rate: 0.0021158]
	Learning Rate: 0.00211576
	LOSS [training: 0.14525276197486817 | validation: 0.13296470188712384]
	TIME [epoch: 9.1 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11833008528756243		[learning rate: 0.0021093]
	Learning Rate: 0.00210928
	LOSS [training: 0.11833008528756243 | validation: 0.16291178025700367]
	TIME [epoch: 9.1 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12353979904676345		[learning rate: 0.0021028]
	Learning Rate: 0.00210281
	LOSS [training: 0.12353979904676345 | validation: 0.12436891079932141]
	TIME [epoch: 9.09 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0873964960743875		[learning rate: 0.0020964]
	Learning Rate: 0.00209636
	LOSS [training: 0.0873964960743875 | validation: 0.1187619697073119]
	TIME [epoch: 9.09 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09340361314090473		[learning rate: 0.0020899]
	Learning Rate: 0.00208994
	LOSS [training: 0.09340361314090473 | validation: 0.08633586073447115]
	TIME [epoch: 9.09 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08873320187421682		[learning rate: 0.0020835]
	Learning Rate: 0.00208353
	LOSS [training: 0.08873320187421682 | validation: 0.14960449447123686]
	TIME [epoch: 9.11 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08683462987182072		[learning rate: 0.0020771]
	Learning Rate: 0.00207714
	LOSS [training: 0.08683462987182072 | validation: 0.10225139888964306]
	TIME [epoch: 9.09 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07453802635486664		[learning rate: 0.0020708]
	Learning Rate: 0.00207078
	LOSS [training: 0.07453802635486664 | validation: 0.09893138624662981]
	TIME [epoch: 9.1 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07844237005406099		[learning rate: 0.0020644]
	Learning Rate: 0.00206443
	LOSS [training: 0.07844237005406099 | validation: 0.08806333894883059]
	TIME [epoch: 9.1 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06132906226798697		[learning rate: 0.0020581]
	Learning Rate: 0.0020581
	LOSS [training: 0.06132906226798697 | validation: 0.09171267928212518]
	TIME [epoch: 9.1 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07431508360129255		[learning rate: 0.0020518]
	Learning Rate: 0.00205179
	LOSS [training: 0.07431508360129255 | validation: 0.07657009790115049]
	TIME [epoch: 9.09 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0867148777283048		[learning rate: 0.0020455]
	Learning Rate: 0.0020455
	LOSS [training: 0.0867148777283048 | validation: 0.07886685495618176]
	TIME [epoch: 9.08 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07930302673264533		[learning rate: 0.0020392]
	Learning Rate: 0.00203923
	LOSS [training: 0.07930302673264533 | validation: 0.10561830728060076]
	TIME [epoch: 9.09 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09087248844635215		[learning rate: 0.002033]
	Learning Rate: 0.00203298
	LOSS [training: 0.09087248844635215 | validation: 0.14528656865709416]
	TIME [epoch: 9.11 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13776501328087226		[learning rate: 0.0020267]
	Learning Rate: 0.00202675
	LOSS [training: 0.13776501328087226 | validation: 0.08182288804413865]
	TIME [epoch: 9.08 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06999802439461471		[learning rate: 0.0020205]
	Learning Rate: 0.00202054
	LOSS [training: 0.06999802439461471 | validation: 0.09486381993281104]
	TIME [epoch: 9.08 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07975760692382818		[learning rate: 0.0020143]
	Learning Rate: 0.00201434
	LOSS [training: 0.07975760692382818 | validation: 0.11916531701080409]
	TIME [epoch: 9.09 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08034795790006805		[learning rate: 0.0020082]
	Learning Rate: 0.00200817
	LOSS [training: 0.08034795790006805 | validation: 0.0907837285183414]
	TIME [epoch: 9.12 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07680696732202409		[learning rate: 0.002002]
	Learning Rate: 0.00200201
	LOSS [training: 0.07680696732202409 | validation: 0.14082497976547081]
	TIME [epoch: 9.1 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13169877711205605		[learning rate: 0.0019959]
	Learning Rate: 0.00199587
	LOSS [training: 0.13169877711205605 | validation: 0.10475002729116259]
	TIME [epoch: 9.09 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0799632666774386		[learning rate: 0.0019898]
	Learning Rate: 0.00198976
	LOSS [training: 0.0799632666774386 | validation: 0.10344923583111679]
	TIME [epoch: 9.1 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07880727393605862		[learning rate: 0.0019837]
	Learning Rate: 0.00198366
	LOSS [training: 0.07880727393605862 | validation: 0.09081720443562039]
	TIME [epoch: 9.12 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06766764058407582		[learning rate: 0.0019776]
	Learning Rate: 0.00197758
	LOSS [training: 0.06766764058407582 | validation: 0.08287871988030132]
	TIME [epoch: 9.1 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06309519718190472		[learning rate: 0.0019715]
	Learning Rate: 0.00197151
	LOSS [training: 0.06309519718190472 | validation: 0.09039082343207681]
	TIME [epoch: 9.1 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07101748612447722		[learning rate: 0.0019655]
	Learning Rate: 0.00196547
	LOSS [training: 0.07101748612447722 | validation: 0.14329057322952066]
	TIME [epoch: 9.09 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.083253597356819		[learning rate: 0.0019594]
	Learning Rate: 0.00195945
	LOSS [training: 0.083253597356819 | validation: 0.06954842438479862]
	TIME [epoch: 9.11 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0716350035530161		[learning rate: 0.0019534]
	Learning Rate: 0.00195344
	LOSS [training: 0.0716350035530161 | validation: 0.06860335488638916]
	TIME [epoch: 9.11 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06495536375044428		[learning rate: 0.0019475]
	Learning Rate: 0.00194745
	LOSS [training: 0.06495536375044428 | validation: 0.07447605986073862]
	TIME [epoch: 9.1 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09165501202664975		[learning rate: 0.0019415]
	Learning Rate: 0.00194148
	LOSS [training: 0.09165501202664975 | validation: 0.12866225534462788]
	TIME [epoch: 9.1 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08806924945228992		[learning rate: 0.0019355]
	Learning Rate: 0.00193553
	LOSS [training: 0.08806924945228992 | validation: 0.10339663822702744]
	TIME [epoch: 9.1 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07235014064933314		[learning rate: 0.0019296]
	Learning Rate: 0.0019296
	LOSS [training: 0.07235014064933314 | validation: 0.08460302653874904]
	TIME [epoch: 9.11 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07928857287831673		[learning rate: 0.0019237]
	Learning Rate: 0.00192368
	LOSS [training: 0.07928857287831673 | validation: 0.10516572441283738]
	TIME [epoch: 9.1 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07290537875074665		[learning rate: 0.0019178]
	Learning Rate: 0.00191779
	LOSS [training: 0.07290537875074665 | validation: 0.094998480396942]
	TIME [epoch: 9.09 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06537085749290243		[learning rate: 0.0019119]
	Learning Rate: 0.00191191
	LOSS [training: 0.06537085749290243 | validation: 0.08370098574039976]
	TIME [epoch: 9.1 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08612215170278442		[learning rate: 0.001906]
	Learning Rate: 0.00190605
	LOSS [training: 0.08612215170278442 | validation: 0.09062699396082102]
	TIME [epoch: 9.11 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08372891220177615		[learning rate: 0.0019002]
	Learning Rate: 0.0019002
	LOSS [training: 0.08372891220177615 | validation: 0.09434558551401996]
	TIME [epoch: 9.09 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06844368883100774		[learning rate: 0.0018944]
	Learning Rate: 0.00189438
	LOSS [training: 0.06844368883100774 | validation: 0.0668299423828619]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1042.pth
	Model improved!!!
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06566226830193853		[learning rate: 0.0018886]
	Learning Rate: 0.00188857
	LOSS [training: 0.06566226830193853 | validation: 0.09194047689344592]
	TIME [epoch: 9.1 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06375314159732356		[learning rate: 0.0018828]
	Learning Rate: 0.00188278
	LOSS [training: 0.06375314159732356 | validation: 0.0719335476156723]
	TIME [epoch: 9.12 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08246158140926368		[learning rate: 0.001877]
	Learning Rate: 0.00187701
	LOSS [training: 0.08246158140926368 | validation: 0.0935072337063855]
	TIME [epoch: 9.09 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06947716753358903		[learning rate: 0.0018713]
	Learning Rate: 0.00187126
	LOSS [training: 0.06947716753358903 | validation: 0.07954086206903546]
	TIME [epoch: 9.1 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07082405472381643		[learning rate: 0.0018655]
	Learning Rate: 0.00186552
	LOSS [training: 0.07082405472381643 | validation: 0.061239882617039776]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1047.pth
	Model improved!!!
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05621303795935513		[learning rate: 0.0018598]
	Learning Rate: 0.0018598
	LOSS [training: 0.05621303795935513 | validation: 0.06495492352476612]
	TIME [epoch: 9.1 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05605052401510842		[learning rate: 0.0018541]
	Learning Rate: 0.0018541
	LOSS [training: 0.05605052401510842 | validation: 0.08690593787049393]
	TIME [epoch: 9.1 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06401476508072368		[learning rate: 0.0018484]
	Learning Rate: 0.00184842
	LOSS [training: 0.06401476508072368 | validation: 0.1100790901611511]
	TIME [epoch: 9.08 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06366546883630175		[learning rate: 0.0018428]
	Learning Rate: 0.00184275
	LOSS [training: 0.06366546883630175 | validation: 0.0775711624418509]
	TIME [epoch: 9.09 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06123503076561906		[learning rate: 0.0018371]
	Learning Rate: 0.0018371
	LOSS [training: 0.06123503076561906 | validation: 0.10561464973409063]
	TIME [epoch: 9.09 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13130453550964846		[learning rate: 0.0018315]
	Learning Rate: 0.00183147
	LOSS [training: 0.13130453550964846 | validation: 0.1988441870901913]
	TIME [epoch: 9.11 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1061089233111258		[learning rate: 0.0018259]
	Learning Rate: 0.00182586
	LOSS [training: 0.1061089233111258 | validation: 0.12823946402851538]
	TIME [epoch: 9.09 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07843932856943879		[learning rate: 0.0018203]
	Learning Rate: 0.00182026
	LOSS [training: 0.07843932856943879 | validation: 0.11072324286604032]
	TIME [epoch: 9.09 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07135105975637286		[learning rate: 0.0018147]
	Learning Rate: 0.00181468
	LOSS [training: 0.07135105975637286 | validation: 0.09172101042075101]
	TIME [epoch: 9.1 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06589667496694532		[learning rate: 0.0018091]
	Learning Rate: 0.00180912
	LOSS [training: 0.06589667496694532 | validation: 0.13604068469507125]
	TIME [epoch: 9.11 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14194193313564094		[learning rate: 0.0018036]
	Learning Rate: 0.00180357
	LOSS [training: 0.14194193313564094 | validation: 0.06294450494044104]
	TIME [epoch: 9.08 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07483109218440445		[learning rate: 0.001798]
	Learning Rate: 0.00179804
	LOSS [training: 0.07483109218440445 | validation: 0.10134664683899827]
	TIME [epoch: 9.09 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08519358055834979		[learning rate: 0.0017925]
	Learning Rate: 0.00179253
	LOSS [training: 0.08519358055834979 | validation: 0.07563950108116375]
	TIME [epoch: 9.09 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0541455227314524		[learning rate: 0.001787]
	Learning Rate: 0.00178704
	LOSS [training: 0.0541455227314524 | validation: 0.0730834424780705]
	TIME [epoch: 9.11 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12897427305140785		[learning rate: 0.0017816]
	Learning Rate: 0.00178156
	LOSS [training: 0.12897427305140785 | validation: 0.27764194433480677]
	TIME [epoch: 9.1 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2319124412529064		[learning rate: 0.0017761]
	Learning Rate: 0.0017761
	LOSS [training: 0.2319124412529064 | validation: 0.28668224808490983]
	TIME [epoch: 9.09 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16018497533357845		[learning rate: 0.0017707]
	Learning Rate: 0.00177065
	LOSS [training: 0.16018497533357845 | validation: 0.17209587820000757]
	TIME [epoch: 9.1 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16579368899428262		[learning rate: 0.0017652]
	Learning Rate: 0.00176522
	LOSS [training: 0.16579368899428262 | validation: 0.19693463471959616]
	TIME [epoch: 9.11 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16636068955810762		[learning rate: 0.0017598]
	Learning Rate: 0.00175981
	LOSS [training: 0.16636068955810762 | validation: 0.3434715367716745]
	TIME [epoch: 9.1 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15431261959704293		[learning rate: 0.0017544]
	Learning Rate: 0.00175442
	LOSS [training: 0.15431261959704293 | validation: 0.12798799009511252]
	TIME [epoch: 9.08 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09426519166723354		[learning rate: 0.001749]
	Learning Rate: 0.00174904
	LOSS [training: 0.09426519166723354 | validation: 0.09895999105311092]
	TIME [epoch: 9.09 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06530182258512278		[learning rate: 0.0017437]
	Learning Rate: 0.00174368
	LOSS [training: 0.06530182258512278 | validation: 0.08532126860935396]
	TIME [epoch: 9.1 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05956707060103965		[learning rate: 0.0017383]
	Learning Rate: 0.00173833
	LOSS [training: 0.05956707060103965 | validation: 0.07927647339983145]
	TIME [epoch: 9.09 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09555771177177672		[learning rate: 0.001733]
	Learning Rate: 0.00173301
	LOSS [training: 0.09555771177177672 | validation: 0.09500012625330734]
	TIME [epoch: 9.08 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07307601601714092		[learning rate: 0.0017277]
	Learning Rate: 0.00172769
	LOSS [training: 0.07307601601714092 | validation: 0.08668709384876085]
	TIME [epoch: 9.08 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0923904348938303		[learning rate: 0.0017224]
	Learning Rate: 0.0017224
	LOSS [training: 0.0923904348938303 | validation: 0.08978335300432472]
	TIME [epoch: 9.08 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06062249639139879		[learning rate: 0.0017171]
	Learning Rate: 0.00171712
	LOSS [training: 0.06062249639139879 | validation: 0.06411536662681494]
	TIME [epoch: 9.1 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05475266863144747		[learning rate: 0.0017119]
	Learning Rate: 0.00171185
	LOSS [training: 0.05475266863144747 | validation: 0.06159831165443456]
	TIME [epoch: 9.08 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04398135685953294		[learning rate: 0.0017066]
	Learning Rate: 0.00170661
	LOSS [training: 0.04398135685953294 | validation: 0.047219572804059584]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1076.pth
	Model improved!!!
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04021616637207413		[learning rate: 0.0017014]
	Learning Rate: 0.00170137
	LOSS [training: 0.04021616637207413 | validation: 0.07216071936352494]
	TIME [epoch: 9.11 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04640786897668728		[learning rate: 0.0016962]
	Learning Rate: 0.00169616
	LOSS [training: 0.04640786897668728 | validation: 0.05188926009977396]
	TIME [epoch: 9.13 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05021018364215283		[learning rate: 0.001691]
	Learning Rate: 0.00169096
	LOSS [training: 0.05021018364215283 | validation: 0.08526363747251717]
	TIME [epoch: 9.1 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0499740678318491		[learning rate: 0.0016858]
	Learning Rate: 0.00168578
	LOSS [training: 0.0499740678318491 | validation: 0.05333233604899052]
	TIME [epoch: 9.1 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05359728566145446		[learning rate: 0.0016806]
	Learning Rate: 0.00168061
	LOSS [training: 0.05359728566145446 | validation: 0.09413695054953919]
	TIME [epoch: 9.1 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06270398342037345		[learning rate: 0.0016755]
	Learning Rate: 0.00167546
	LOSS [training: 0.06270398342037345 | validation: 0.0579788746261163]
	TIME [epoch: 9.11 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03934737460860215		[learning rate: 0.0016703]
	Learning Rate: 0.00167032
	LOSS [training: 0.03934737460860215 | validation: 0.10395261093472635]
	TIME [epoch: 9.11 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05246472387071825		[learning rate: 0.0016652]
	Learning Rate: 0.0016652
	LOSS [training: 0.05246472387071825 | validation: 0.06724064449782226]
	TIME [epoch: 9.1 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05355989372320078		[learning rate: 0.0016601]
	Learning Rate: 0.0016601
	LOSS [training: 0.05355989372320078 | validation: 0.06037305040152845]
	TIME [epoch: 9.1 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04522278316516922		[learning rate: 0.001655]
	Learning Rate: 0.00165501
	LOSS [training: 0.04522278316516922 | validation: 0.07253084236874119]
	TIME [epoch: 9.11 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055290238632711305		[learning rate: 0.0016499]
	Learning Rate: 0.00164993
	LOSS [training: 0.055290238632711305 | validation: 0.0591159397937967]
	TIME [epoch: 9.11 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0529643439661137		[learning rate: 0.0016449]
	Learning Rate: 0.00164488
	LOSS [training: 0.0529643439661137 | validation: 0.06446715319082966]
	TIME [epoch: 9.1 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042842186115797036		[learning rate: 0.0016398]
	Learning Rate: 0.00163983
	LOSS [training: 0.042842186115797036 | validation: 0.11939076391189338]
	TIME [epoch: 9.1 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03891325339887037		[learning rate: 0.0016348]
	Learning Rate: 0.00163481
	LOSS [training: 0.03891325339887037 | validation: 0.04876287356961763]
	TIME [epoch: 9.1 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04933398226916763		[learning rate: 0.0016298]
	Learning Rate: 0.0016298
	LOSS [training: 0.04933398226916763 | validation: 0.04402157113859597]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1091.pth
	Model improved!!!
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0589517503993083		[learning rate: 0.0016248]
	Learning Rate: 0.0016248
	LOSS [training: 0.0589517503993083 | validation: 0.14204729170258115]
	TIME [epoch: 9.1 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054131974519136185		[learning rate: 0.0016198]
	Learning Rate: 0.00161982
	LOSS [training: 0.054131974519136185 | validation: 0.03637381234490192]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1093.pth
	Model improved!!!
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03944705457198537		[learning rate: 0.0016149]
	Learning Rate: 0.00161485
	LOSS [training: 0.03944705457198537 | validation: 0.044191264892599426]
	TIME [epoch: 9.1 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03742114776865712		[learning rate: 0.0016099]
	Learning Rate: 0.0016099
	LOSS [training: 0.03742114776865712 | validation: 0.11951891862447406]
	TIME [epoch: 9.12 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05288164460493838		[learning rate: 0.001605]
	Learning Rate: 0.00160497
	LOSS [training: 0.05288164460493838 | validation: 0.06147616560106929]
	TIME [epoch: 9.1 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059751028714046514		[learning rate: 0.0016]
	Learning Rate: 0.00160005
	LOSS [training: 0.059751028714046514 | validation: 0.050832683814089744]
	TIME [epoch: 9.1 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05148958732297636		[learning rate: 0.0015951]
	Learning Rate: 0.00159514
	LOSS [training: 0.05148958732297636 | validation: 0.11846501612452467]
	TIME [epoch: 9.1 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0721997801115884		[learning rate: 0.0015903]
	Learning Rate: 0.00159025
	LOSS [training: 0.0721997801115884 | validation: 0.10187075174236991]
	TIME [epoch: 9.11 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0829593832653138		[learning rate: 0.0015854]
	Learning Rate: 0.00158538
	LOSS [training: 0.0829593832653138 | validation: 0.08045799947989088]
	TIME [epoch: 9.11 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06981684977260601		[learning rate: 0.0015805]
	Learning Rate: 0.00158052
	LOSS [training: 0.06981684977260601 | validation: 0.08601616341583498]
	TIME [epoch: 9.1 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0778225106015599		[learning rate: 0.0015757]
	Learning Rate: 0.00157568
	LOSS [training: 0.0778225106015599 | validation: 0.12820756858494387]
	TIME [epoch: 9.1 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07256128832091076		[learning rate: 0.0015708]
	Learning Rate: 0.00157084
	LOSS [training: 0.07256128832091076 | validation: 0.1368656696948159]
	TIME [epoch: 9.11 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0588944249588393		[learning rate: 0.001566]
	Learning Rate: 0.00156603
	LOSS [training: 0.0588944249588393 | validation: 0.06971247280568951]
	TIME [epoch: 9.12 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06447730137730476		[learning rate: 0.0015612]
	Learning Rate: 0.00156123
	LOSS [training: 0.06447730137730476 | validation: 0.09953907489667951]
	TIME [epoch: 9.1 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0508165296431641		[learning rate: 0.0015564]
	Learning Rate: 0.00155644
	LOSS [training: 0.0508165296431641 | validation: 0.10888068131709079]
	TIME [epoch: 9.1 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06084979336648445		[learning rate: 0.0015517]
	Learning Rate: 0.00155167
	LOSS [training: 0.06084979336648445 | validation: 0.07898362413456553]
	TIME [epoch: 9.11 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07735498550270008		[learning rate: 0.0015469]
	Learning Rate: 0.00154692
	LOSS [training: 0.07735498550270008 | validation: 0.09310675060837828]
	TIME [epoch: 9.12 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05986947648596212		[learning rate: 0.0015422]
	Learning Rate: 0.00154217
	LOSS [training: 0.05986947648596212 | validation: 0.07204453273880596]
	TIME [epoch: 9.1 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060409916221633365		[learning rate: 0.0015374]
	Learning Rate: 0.00153745
	LOSS [training: 0.060409916221633365 | validation: 0.19814720344454495]
	TIME [epoch: 9.1 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18001811781465119		[learning rate: 0.0015327]
	Learning Rate: 0.00153273
	LOSS [training: 0.18001811781465119 | validation: 0.11755504104378561]
	TIME [epoch: 9.1 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06757400971535746		[learning rate: 0.001528]
	Learning Rate: 0.00152804
	LOSS [training: 0.06757400971535746 | validation: 0.08598256784182268]
	TIME [epoch: 9.13 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04225153104203598		[learning rate: 0.0015234]
	Learning Rate: 0.00152335
	LOSS [training: 0.04225153104203598 | validation: 0.06704549696946543]
	TIME [epoch: 9.1 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049976329031059		[learning rate: 0.0015187]
	Learning Rate: 0.00151868
	LOSS [training: 0.049976329031059 | validation: 0.057578235698161236]
	TIME [epoch: 9.1 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07099317790328229		[learning rate: 0.001514]
	Learning Rate: 0.00151403
	LOSS [training: 0.07099317790328229 | validation: 0.0853667626397023]
	TIME [epoch: 9.1 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05589258820878854		[learning rate: 0.0015094]
	Learning Rate: 0.00150938
	LOSS [training: 0.05589258820878854 | validation: 0.07258557340408098]
	TIME [epoch: 9.12 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05543128404597934		[learning rate: 0.0015048]
	Learning Rate: 0.00150476
	LOSS [training: 0.05543128404597934 | validation: 0.12313078772357752]
	TIME [epoch: 9.1 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049374411657424226		[learning rate: 0.0015001]
	Learning Rate: 0.00150015
	LOSS [training: 0.049374411657424226 | validation: 0.06454612277503238]
	TIME [epoch: 9.1 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06452969280007782		[learning rate: 0.0014955]
	Learning Rate: 0.00149555
	LOSS [training: 0.06452969280007782 | validation: 0.06284401680597174]
	TIME [epoch: 9.1 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029192787737570964		[learning rate: 0.001491]
	Learning Rate: 0.00149096
	LOSS [training: 0.029192787737570964 | validation: 0.04389472010231664]
	TIME [epoch: 9.12 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04941508845931494		[learning rate: 0.0014864]
	Learning Rate: 0.00148639
	LOSS [training: 0.04941508845931494 | validation: 0.057178948158782536]
	TIME [epoch: 9.1 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030461404615086306		[learning rate: 0.0014818]
	Learning Rate: 0.00148184
	LOSS [training: 0.030461404615086306 | validation: 0.03560552130952934]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1122.pth
	Model improved!!!
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03398664478520882		[learning rate: 0.0014773]
	Learning Rate: 0.00147729
	LOSS [training: 0.03398664478520882 | validation: 0.14076389657554436]
	TIME [epoch: 9.09 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06928232815850412		[learning rate: 0.0014728]
	Learning Rate: 0.00147276
	LOSS [training: 0.06928232815850412 | validation: 0.08306420241600049]
	TIME [epoch: 9.11 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06979761461016133		[learning rate: 0.0014682]
	Learning Rate: 0.00146825
	LOSS [training: 0.06979761461016133 | validation: 0.10591815594588289]
	TIME [epoch: 9.09 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1271614863391907		[learning rate: 0.0014637]
	Learning Rate: 0.00146375
	LOSS [training: 0.1271614863391907 | validation: 0.17142244371134815]
	TIME [epoch: 9.09 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11013684759957024		[learning rate: 0.0014593]
	Learning Rate: 0.00145926
	LOSS [training: 0.11013684759957024 | validation: 0.06917249955208613]
	TIME [epoch: 9.09 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04345681134848811		[learning rate: 0.0014548]
	Learning Rate: 0.00145479
	LOSS [training: 0.04345681134848811 | validation: 0.06545664652600604]
	TIME [epoch: 9.09 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040013037866790294		[learning rate: 0.0014503]
	Learning Rate: 0.00145033
	LOSS [training: 0.040013037866790294 | validation: 0.03698873835241628]
	TIME [epoch: 9.12 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04198240647165967		[learning rate: 0.0014459]
	Learning Rate: 0.00144588
	LOSS [training: 0.04198240647165967 | validation: 0.06586596234071626]
	TIME [epoch: 9.09 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03881574841784086		[learning rate: 0.0014415]
	Learning Rate: 0.00144145
	LOSS [training: 0.03881574841784086 | validation: 0.051848366580964124]
	TIME [epoch: 9.09 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044576013941156914		[learning rate: 0.001437]
	Learning Rate: 0.00143703
	LOSS [training: 0.044576013941156914 | validation: 0.07116974513432903]
	TIME [epoch: 9.09 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05041606601161318		[learning rate: 0.0014326]
	Learning Rate: 0.00143263
	LOSS [training: 0.05041606601161318 | validation: 0.037144938071021164]
	TIME [epoch: 9.11 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03449399931319484		[learning rate: 0.0014282]
	Learning Rate: 0.00142824
	LOSS [training: 0.03449399931319484 | validation: 0.045363342233243883]
	TIME [epoch: 9.1 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03458044490143426		[learning rate: 0.0014239]
	Learning Rate: 0.00142386
	LOSS [training: 0.03458044490143426 | validation: 0.03333202404867873]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1135.pth
	Model improved!!!
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028162370716295144		[learning rate: 0.0014195]
	Learning Rate: 0.00141949
	LOSS [training: 0.028162370716295144 | validation: 0.04397162930093771]
	TIME [epoch: 9.1 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02955781436197209		[learning rate: 0.0014151]
	Learning Rate: 0.00141514
	LOSS [training: 0.02955781436197209 | validation: 0.05070044439434257]
	TIME [epoch: 9.12 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02731146270741182		[learning rate: 0.0014108]
	Learning Rate: 0.0014108
	LOSS [training: 0.02731146270741182 | validation: 0.04706009464806426]
	TIME [epoch: 9.1 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030374167762526983		[learning rate: 0.0014065]
	Learning Rate: 0.00140648
	LOSS [training: 0.030374167762526983 | validation: 0.03898962267675207]
	TIME [epoch: 9.1 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03494530842709322		[learning rate: 0.0014022]
	Learning Rate: 0.00140217
	LOSS [training: 0.03494530842709322 | validation: 0.046622517866971976]
	TIME [epoch: 9.09 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03180674065069031		[learning rate: 0.0013979]
	Learning Rate: 0.00139787
	LOSS [training: 0.03180674065069031 | validation: 0.05992557415419397]
	TIME [epoch: 9.1 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035529666572439465		[learning rate: 0.0013936]
	Learning Rate: 0.00139358
	LOSS [training: 0.035529666572439465 | validation: 0.05941618360660182]
	TIME [epoch: 9.11 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04102888036167025		[learning rate: 0.0013893]
	Learning Rate: 0.00138931
	LOSS [training: 0.04102888036167025 | validation: 0.06203101643121835]
	TIME [epoch: 9.09 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05803035058180289		[learning rate: 0.0013851]
	Learning Rate: 0.00138505
	LOSS [training: 0.05803035058180289 | validation: 0.06124125509117315]
	TIME [epoch: 9.09 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03215848214683639		[learning rate: 0.0013808]
	Learning Rate: 0.00138081
	LOSS [training: 0.03215848214683639 | validation: 0.04609229473779497]
	TIME [epoch: 9.1 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036734353690222356		[learning rate: 0.0013766]
	Learning Rate: 0.00137658
	LOSS [training: 0.036734353690222356 | validation: 0.13476670377497024]
	TIME [epoch: 9.12 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045369366817733084		[learning rate: 0.0013724]
	Learning Rate: 0.00137236
	LOSS [training: 0.045369366817733084 | validation: 0.03894347246626766]
	TIME [epoch: 9.09 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02292758716492856		[learning rate: 0.0013681]
	Learning Rate: 0.00136815
	LOSS [training: 0.02292758716492856 | validation: 0.04789687082945905]
	TIME [epoch: 9.09 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04109749978357061		[learning rate: 0.001364]
	Learning Rate: 0.00136395
	LOSS [training: 0.04109749978357061 | validation: 0.03389148804701812]
	TIME [epoch: 9.09 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050225104436040266		[learning rate: 0.0013598]
	Learning Rate: 0.00135977
	LOSS [training: 0.050225104436040266 | validation: 0.08027592440764511]
	TIME [epoch: 9.12 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05249717436968354		[learning rate: 0.0013556]
	Learning Rate: 0.00135561
	LOSS [training: 0.05249717436968354 | validation: 0.05361526243957134]
	TIME [epoch: 9.1 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029586131923342744		[learning rate: 0.0013515]
	Learning Rate: 0.00135145
	LOSS [training: 0.029586131923342744 | validation: 0.06615676950898318]
	TIME [epoch: 9.09 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04046164116908996		[learning rate: 0.0013473]
	Learning Rate: 0.00134731
	LOSS [training: 0.04046164116908996 | validation: 0.05503721361963093]
	TIME [epoch: 9.09 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02752391418010197		[learning rate: 0.0013432]
	Learning Rate: 0.00134318
	LOSS [training: 0.02752391418010197 | validation: 0.04658661722936569]
	TIME [epoch: 9.11 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03143931898505203		[learning rate: 0.0013391]
	Learning Rate: 0.00133906
	LOSS [training: 0.03143931898505203 | validation: 0.052340329942840505]
	TIME [epoch: 9.1 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03669257628225678		[learning rate: 0.001335]
	Learning Rate: 0.00133496
	LOSS [training: 0.03669257628225678 | validation: 0.07245597643364132]
	TIME [epoch: 9.09 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04778032210882		[learning rate: 0.0013309]
	Learning Rate: 0.00133086
	LOSS [training: 0.04778032210882 | validation: 0.0567296968168154]
	TIME [epoch: 9.1 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03081965585354842		[learning rate: 0.0013268]
	Learning Rate: 0.00132678
	LOSS [training: 0.03081965585354842 | validation: 0.03135870588556512]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1158.pth
	Model improved!!!
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027601457024511923		[learning rate: 0.0013227]
	Learning Rate: 0.00132272
	LOSS [training: 0.027601457024511923 | validation: 0.08974541953901552]
	TIME [epoch: 9.09 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06274400315022191		[learning rate: 0.0013187]
	Learning Rate: 0.00131866
	LOSS [training: 0.06274400315022191 | validation: 0.07888488741515895]
	TIME [epoch: 9.09 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05217005256364073		[learning rate: 0.0013146]
	Learning Rate: 0.00131462
	LOSS [training: 0.05217005256364073 | validation: 0.06163387469128197]
	TIME [epoch: 9.08 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04999278179498273		[learning rate: 0.0013106]
	Learning Rate: 0.00131059
	LOSS [training: 0.04999278179498273 | validation: 0.05292024837610441]
	TIME [epoch: 9.08 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05079051542199627		[learning rate: 0.0013066]
	Learning Rate: 0.00130657
	LOSS [training: 0.05079051542199627 | validation: 0.09701055293556356]
	TIME [epoch: 9.11 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0584379678222313		[learning rate: 0.0013026]
	Learning Rate: 0.00130257
	LOSS [training: 0.0584379678222313 | validation: 0.061883340196227724]
	TIME [epoch: 9.09 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047060125165688714		[learning rate: 0.0012986]
	Learning Rate: 0.00129857
	LOSS [training: 0.047060125165688714 | validation: 0.04657715907505175]
	TIME [epoch: 9.09 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058452596280344785		[learning rate: 0.0012946]
	Learning Rate: 0.00129459
	LOSS [training: 0.058452596280344785 | validation: 0.12860485613434663]
	TIME [epoch: 9.09 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06245812064679677		[learning rate: 0.0012906]
	Learning Rate: 0.00129062
	LOSS [training: 0.06245812064679677 | validation: 0.05880636313765544]
	TIME [epoch: 9.11 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06377415316277019		[learning rate: 0.0012867]
	Learning Rate: 0.00128667
	LOSS [training: 0.06377415316277019 | validation: 0.08464363712185849]
	TIME [epoch: 9.09 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05768982522161924		[learning rate: 0.0012827]
	Learning Rate: 0.00128272
	LOSS [training: 0.05768982522161924 | validation: 0.06234776651453553]
	TIME [epoch: 9.09 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05811037940385484		[learning rate: 0.0012788]
	Learning Rate: 0.00127879
	LOSS [training: 0.05811037940385484 | validation: 0.0620397648934774]
	TIME [epoch: 9.08 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04002485681035769		[learning rate: 0.0012749]
	Learning Rate: 0.00127487
	LOSS [training: 0.04002485681035769 | validation: 0.04706809202605604]
	TIME [epoch: 9.1 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03768387956890796		[learning rate: 0.001271]
	Learning Rate: 0.00127096
	LOSS [training: 0.03768387956890796 | validation: 0.05948528456818758]
	TIME [epoch: 9.09 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05777155457044432		[learning rate: 0.0012671]
	Learning Rate: 0.00126707
	LOSS [training: 0.05777155457044432 | validation: 0.10871714833118146]
	TIME [epoch: 9.08 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07915227845712716		[learning rate: 0.0012632]
	Learning Rate: 0.00126318
	LOSS [training: 0.07915227845712716 | validation: 0.06647500002857683]
	TIME [epoch: 9.08 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11206320090814252		[learning rate: 0.0012593]
	Learning Rate: 0.00125931
	LOSS [training: 0.11206320090814252 | validation: 0.23642362964455219]
	TIME [epoch: 9.1 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08958843368735868		[learning rate: 0.0012555]
	Learning Rate: 0.00125545
	LOSS [training: 0.08958843368735868 | validation: 0.07279590513717352]
	TIME [epoch: 9.09 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06077885867127773		[learning rate: 0.0012516]
	Learning Rate: 0.0012516
	LOSS [training: 0.06077885867127773 | validation: 0.09220005970374691]
	TIME [epoch: 9.08 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08422419806069473		[learning rate: 0.0012478]
	Learning Rate: 0.00124777
	LOSS [training: 0.08422419806069473 | validation: 0.08343944953219873]
	TIME [epoch: 9.08 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06631003639383445		[learning rate: 0.0012439]
	Learning Rate: 0.00124394
	LOSS [training: 0.06631003639383445 | validation: 0.1184024419762237]
	TIME [epoch: 9.1 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05445765669233462		[learning rate: 0.0012401]
	Learning Rate: 0.00124013
	LOSS [training: 0.05445765669233462 | validation: 0.06784517775725328]
	TIME [epoch: 9.1 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04363188805440157		[learning rate: 0.0012363]
	Learning Rate: 0.00123633
	LOSS [training: 0.04363188805440157 | validation: 0.05982163732393144]
	TIME [epoch: 9.08 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03179972088176132		[learning rate: 0.0012325]
	Learning Rate: 0.00123254
	LOSS [training: 0.03179972088176132 | validation: 0.04501109859545096]
	TIME [epoch: 9.08 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0317190579555356		[learning rate: 0.0012288]
	Learning Rate: 0.00122876
	LOSS [training: 0.0317190579555356 | validation: 0.05910828720986299]
	TIME [epoch: 9.1 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04673768465288956		[learning rate: 0.001225]
	Learning Rate: 0.00122499
	LOSS [training: 0.04673768465288956 | validation: 0.0762948109790573]
	TIME [epoch: 9.1 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045334790591824554		[learning rate: 0.0012212]
	Learning Rate: 0.00122124
	LOSS [training: 0.045334790591824554 | validation: 0.05722359514441833]
	TIME [epoch: 9.08 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04717853254603981		[learning rate: 0.0012175]
	Learning Rate: 0.00121749
	LOSS [training: 0.04717853254603981 | validation: 0.057367579053599044]
	TIME [epoch: 9.08 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03913934963186812		[learning rate: 0.0012138]
	Learning Rate: 0.00121376
	LOSS [training: 0.03913934963186812 | validation: 0.05593057602167721]
	TIME [epoch: 9.09 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03781934961640185		[learning rate: 0.00121]
	Learning Rate: 0.00121004
	LOSS [training: 0.03781934961640185 | validation: 0.042978262717597145]
	TIME [epoch: 9.1 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03856834972856104		[learning rate: 0.0012063]
	Learning Rate: 0.00120633
	LOSS [training: 0.03856834972856104 | validation: 0.08010549524230504]
	TIME [epoch: 9.09 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03616667896983998		[learning rate: 0.0012026]
	Learning Rate: 0.00120263
	LOSS [training: 0.03616667896983998 | validation: 0.053580990727530246]
	TIME [epoch: 9.08 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04574512853027231		[learning rate: 0.0011989]
	Learning Rate: 0.00119895
	LOSS [training: 0.04574512853027231 | validation: 0.04182846612985536]
	TIME [epoch: 9.08 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03958222419312843		[learning rate: 0.0011953]
	Learning Rate: 0.00119527
	LOSS [training: 0.03958222419312843 | validation: 0.04610898178252312]
	TIME [epoch: 9.1 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04427321671336361		[learning rate: 0.0011916]
	Learning Rate: 0.00119161
	LOSS [training: 0.04427321671336361 | validation: 0.0410312191887265]
	TIME [epoch: 9.09 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049378146217056156		[learning rate: 0.001188]
	Learning Rate: 0.00118795
	LOSS [training: 0.049378146217056156 | validation: 0.06720440290229107]
	TIME [epoch: 9.08 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03342189549496606		[learning rate: 0.0011843]
	Learning Rate: 0.00118431
	LOSS [training: 0.03342189549496606 | validation: 0.04506918778293438]
	TIME [epoch: 9.08 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034478740099643634		[learning rate: 0.0011807]
	Learning Rate: 0.00118068
	LOSS [training: 0.034478740099643634 | validation: 0.052097159011921725]
	TIME [epoch: 9.1 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03723948513254403		[learning rate: 0.0011771]
	Learning Rate: 0.00117706
	LOSS [training: 0.03723948513254403 | validation: 0.10423878811878012]
	TIME [epoch: 9.09 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10213093564215955		[learning rate: 0.0011735]
	Learning Rate: 0.00117346
	LOSS [training: 0.10213093564215955 | validation: 0.09410337479669612]
	TIME [epoch: 9.09 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08646466832174542		[learning rate: 0.0011699]
	Learning Rate: 0.00116986
	LOSS [training: 0.08646466832174542 | validation: 0.06289013334455933]
	TIME [epoch: 9.08 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039187794210136594		[learning rate: 0.0011663]
	Learning Rate: 0.00116627
	LOSS [training: 0.039187794210136594 | validation: 0.03489552925909743]
	TIME [epoch: 9.1 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05082051672556217		[learning rate: 0.0011627]
	Learning Rate: 0.0011627
	LOSS [training: 0.05082051672556217 | validation: 0.10304005128172188]
	TIME [epoch: 9.09 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0491653376520087		[learning rate: 0.0011591]
	Learning Rate: 0.00115913
	LOSS [training: 0.0491653376520087 | validation: 0.054080072414191195]
	TIME [epoch: 9.09 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025267305591930588		[learning rate: 0.0011556]
	Learning Rate: 0.00115558
	LOSS [training: 0.025267305591930588 | validation: 0.03667397868145891]
	TIME [epoch: 9.08 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025051020180138293		[learning rate: 0.001152]
	Learning Rate: 0.00115204
	LOSS [training: 0.025051020180138293 | validation: 0.03110908519824316]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1204.pth
	Model improved!!!
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027704664399676178		[learning rate: 0.0011485]
	Learning Rate: 0.00114851
	LOSS [training: 0.027704664399676178 | validation: 0.045896014477445395]
	TIME [epoch: 9.11 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03715359830700917		[learning rate: 0.001145]
	Learning Rate: 0.00114499
	LOSS [training: 0.03715359830700917 | validation: 0.028043484110468538]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1206.pth
	Model improved!!!
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033477588344505545		[learning rate: 0.0011415]
	Learning Rate: 0.00114148
	LOSS [training: 0.033477588344505545 | validation: 0.08126605621024421]
	TIME [epoch: 9.09 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057155235857314066		[learning rate: 0.001138]
	Learning Rate: 0.00113798
	LOSS [training: 0.057155235857314066 | validation: 0.030660541885907902]
	TIME [epoch: 9.09 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031930329850911966		[learning rate: 0.0011345]
	Learning Rate: 0.00113449
	LOSS [training: 0.031930329850911966 | validation: 0.04236248870051282]
	TIME [epoch: 9.11 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02871263632562756		[learning rate: 0.001131]
	Learning Rate: 0.00113101
	LOSS [training: 0.02871263632562756 | validation: 0.04059230814396365]
	TIME [epoch: 9.09 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024726758245726427		[learning rate: 0.0011275]
	Learning Rate: 0.00112754
	LOSS [training: 0.024726758245726427 | validation: 0.050839012119105915]
	TIME [epoch: 9.09 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02893771876266004		[learning rate: 0.0011241]
	Learning Rate: 0.00112409
	LOSS [training: 0.02893771876266004 | validation: 0.03522399561914341]
	TIME [epoch: 9.09 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10910554865813107		[learning rate: 0.0011206]
	Learning Rate: 0.00112064
	LOSS [training: 0.10910554865813107 | validation: 0.2753775036314727]
	TIME [epoch: 9.1 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12593112549343435		[learning rate: 0.0011172]
	Learning Rate: 0.00111721
	LOSS [training: 0.12593112549343435 | validation: 0.1778151173760329]
	TIME [epoch: 9.1 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10139915872687258		[learning rate: 0.0011138]
	Learning Rate: 0.00111378
	LOSS [training: 0.10139915872687258 | validation: 0.0986918943762912]
	TIME [epoch: 9.09 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056060795645932956		[learning rate: 0.0011104]
	Learning Rate: 0.00111037
	LOSS [training: 0.056060795645932956 | validation: 0.0792764390758316]
	TIME [epoch: 9.08 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08290880525519408		[learning rate: 0.001107]
	Learning Rate: 0.00110696
	LOSS [training: 0.08290880525519408 | validation: 0.0861620256517495]
	TIME [epoch: 9.09 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07998424266148614		[learning rate: 0.0011036]
	Learning Rate: 0.00110357
	LOSS [training: 0.07998424266148614 | validation: 0.1028037932874689]
	TIME [epoch: 9.11 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09992946365835374		[learning rate: 0.0011002]
	Learning Rate: 0.00110019
	LOSS [training: 0.09992946365835374 | validation: 0.09463444020742753]
	TIME [epoch: 9.09 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055366910799399		[learning rate: 0.0010968]
	Learning Rate: 0.00109681
	LOSS [training: 0.055366910799399 | validation: 0.05373484558084539]
	TIME [epoch: 9.08 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0397733157780093		[learning rate: 0.0010935]
	Learning Rate: 0.00109345
	LOSS [training: 0.0397733157780093 | validation: 0.0665956577912809]
	TIME [epoch: 9.09 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04673865429513692		[learning rate: 0.0010901]
	Learning Rate: 0.0010901
	LOSS [training: 0.04673865429513692 | validation: 0.05063952296406676]
	TIME [epoch: 9.11 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032265099156005075		[learning rate: 0.0010868]
	Learning Rate: 0.00108676
	LOSS [training: 0.032265099156005075 | validation: 0.0321100041338562]
	TIME [epoch: 9.1 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02473474509857684		[learning rate: 0.0010834]
	Learning Rate: 0.00108343
	LOSS [training: 0.02473474509857684 | validation: 0.07862458136821966]
	TIME [epoch: 9.09 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0523860052347229		[learning rate: 0.0010801]
	Learning Rate: 0.00108011
	LOSS [training: 0.0523860052347229 | validation: 0.03437694209762489]
	TIME [epoch: 9.09 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029799666366168025		[learning rate: 0.0010768]
	Learning Rate: 0.0010768
	LOSS [training: 0.029799666366168025 | validation: 0.04060554206580198]
	TIME [epoch: 9.11 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021312454002580725		[learning rate: 0.0010735]
	Learning Rate: 0.00107349
	LOSS [training: 0.021312454002580725 | validation: 0.023664668772798048]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1227.pth
	Model improved!!!
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03187961036185042		[learning rate: 0.0010702]
	Learning Rate: 0.0010702
	LOSS [training: 0.03187961036185042 | validation: 0.03717588872253501]
	TIME [epoch: 9.1 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021706699690596798		[learning rate: 0.0010669]
	Learning Rate: 0.00106692
	LOSS [training: 0.021706699690596798 | validation: 0.028661341904097692]
	TIME [epoch: 9.1 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02325171736598084		[learning rate: 0.0010637]
	Learning Rate: 0.00106365
	LOSS [training: 0.02325171736598084 | validation: 0.03169659823810769]
	TIME [epoch: 9.11 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02089520693788715		[learning rate: 0.0010604]
	Learning Rate: 0.00106039
	LOSS [training: 0.02089520693788715 | validation: 0.022865568971203128]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1231.pth
	Model improved!!!
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015523953702231103		[learning rate: 0.0010571]
	Learning Rate: 0.00105714
	LOSS [training: 0.015523953702231103 | validation: 0.019132007183055987]
	TIME [epoch: 9.09 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1232.pth
	Model improved!!!
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045326108314815636		[learning rate: 0.0010539]
	Learning Rate: 0.0010539
	LOSS [training: 0.045326108314815636 | validation: 0.0423511487433058]
	TIME [epoch: 9.09 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026641294367354185		[learning rate: 0.0010507]
	Learning Rate: 0.00105067
	LOSS [training: 0.026641294367354185 | validation: 0.06057913147641364]
	TIME [epoch: 9.1 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07701713233008722		[learning rate: 0.0010475]
	Learning Rate: 0.00104745
	LOSS [training: 0.07701713233008722 | validation: 0.06308578548210261]
	TIME [epoch: 9.1 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02399860285186709		[learning rate: 0.0010442]
	Learning Rate: 0.00104424
	LOSS [training: 0.02399860285186709 | validation: 0.032645187718744494]
	TIME [epoch: 9.09 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02023979761990385		[learning rate: 0.001041]
	Learning Rate: 0.00104104
	LOSS [training: 0.02023979761990385 | validation: 0.03118399030499057]
	TIME [epoch: 9.09 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022892650900646693		[learning rate: 0.0010378]
	Learning Rate: 0.00103785
	LOSS [training: 0.022892650900646693 | validation: 0.02469109178297411]
	TIME [epoch: 9.09 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01962229331233944		[learning rate: 0.0010347]
	Learning Rate: 0.00103467
	LOSS [training: 0.01962229331233944 | validation: 0.05017046077279401]
	TIME [epoch: 9.1 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048875141378619695		[learning rate: 0.0010315]
	Learning Rate: 0.00103149
	LOSS [training: 0.048875141378619695 | validation: 0.02671494099804954]
	TIME [epoch: 9.1 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018257591085279575		[learning rate: 0.0010283]
	Learning Rate: 0.00102833
	LOSS [training: 0.018257591085279575 | validation: 0.03837383654400085]
	TIME [epoch: 9.09 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02706264991080735		[learning rate: 0.0010252]
	Learning Rate: 0.00102518
	LOSS [training: 0.02706264991080735 | validation: 0.0277361239561578]
	TIME [epoch: 9.08 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0214673833564546		[learning rate: 0.001022]
	Learning Rate: 0.00102204
	LOSS [training: 0.0214673833564546 | validation: 0.034084812420682634]
	TIME [epoch: 9.11 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024548877426655923		[learning rate: 0.0010189]
	Learning Rate: 0.0010189
	LOSS [training: 0.024548877426655923 | validation: 0.07206113586962012]
	TIME [epoch: 9.1 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025264410646838015		[learning rate: 0.0010158]
	Learning Rate: 0.00101578
	LOSS [training: 0.025264410646838015 | validation: 0.020631280682806466]
	TIME [epoch: 9.09 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014582016939301237		[learning rate: 0.0010127]
	Learning Rate: 0.00101267
	LOSS [training: 0.014582016939301237 | validation: 0.03908529995140239]
	TIME [epoch: 9.09 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022771230941133407		[learning rate: 0.0010096]
	Learning Rate: 0.00100956
	LOSS [training: 0.022771230941133407 | validation: 0.04266639707984323]
	TIME [epoch: 9.11 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020101261765514484		[learning rate: 0.0010065]
	Learning Rate: 0.00100647
	LOSS [training: 0.020101261765514484 | validation: 0.025147075678598634]
	TIME [epoch: 9.11 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020901274208951468		[learning rate: 0.0010034]
	Learning Rate: 0.00100338
	LOSS [training: 0.020901274208951468 | validation: 0.03846905716296593]
	TIME [epoch: 9.09 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018624520643478214		[learning rate: 0.0010003]
	Learning Rate: 0.00100031
	LOSS [training: 0.018624520643478214 | validation: 0.027681779383821572]
	TIME [epoch: 9.09 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02813110161935643		[learning rate: 0.00099724]
	Learning Rate: 0.000997241
	LOSS [training: 0.02813110161935643 | validation: 0.05325575908292776]
	TIME [epoch: 9.1 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037116836448762694		[learning rate: 0.00099418]
	Learning Rate: 0.000994184
	LOSS [training: 0.037116836448762694 | validation: 0.06139384925629361]
	TIME [epoch: 9.1 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03003932101270986		[learning rate: 0.00099114]
	Learning Rate: 0.000991136
	LOSS [training: 0.03003932101270986 | validation: 0.03248855857412442]
	TIME [epoch: 9.09 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030473150958094036		[learning rate: 0.0009881]
	Learning Rate: 0.000988098
	LOSS [training: 0.030473150958094036 | validation: 0.059392534679000575]
	TIME [epoch: 9.08 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035431294831378427		[learning rate: 0.00098507]
	Learning Rate: 0.000985069
	LOSS [training: 0.035431294831378427 | validation: 0.05381401334570884]
	TIME [epoch: 9.08 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03206585289510604		[learning rate: 0.00098205]
	Learning Rate: 0.00098205
	LOSS [training: 0.03206585289510604 | validation: 0.05824225145073955]
	TIME [epoch: 9.1 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03432053918189199		[learning rate: 0.00097904]
	Learning Rate: 0.000979039
	LOSS [training: 0.03432053918189199 | validation: 0.058362538360966734]
	TIME [epoch: 9.08 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04228049308259184		[learning rate: 0.00097604]
	Learning Rate: 0.000976038
	LOSS [training: 0.04228049308259184 | validation: 0.06445815898464116]
	TIME [epoch: 9.09 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043277566884514077		[learning rate: 0.00097305]
	Learning Rate: 0.000973046
	LOSS [training: 0.043277566884514077 | validation: 0.06991674060556417]
	TIME [epoch: 9.08 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05017465829175758		[learning rate: 0.00097006]
	Learning Rate: 0.000970063
	LOSS [training: 0.05017465829175758 | validation: 0.06810225228247752]
	TIME [epoch: 9.11 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05833492361054571		[learning rate: 0.00096709]
	Learning Rate: 0.000967089
	LOSS [training: 0.05833492361054571 | validation: 0.06077739720695023]
	TIME [epoch: 9.09 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04779303201065009		[learning rate: 0.00096412]
	Learning Rate: 0.000964125
	LOSS [training: 0.04779303201065009 | validation: 0.11004472979955848]
	TIME [epoch: 9.08 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05664537786292527		[learning rate: 0.00096117]
	Learning Rate: 0.00096117
	LOSS [training: 0.05664537786292527 | validation: 0.0857786994804029]
	TIME [epoch: 9.09 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04640073597701199		[learning rate: 0.00095822]
	Learning Rate: 0.000958223
	LOSS [training: 0.04640073597701199 | validation: 0.04799373488672522]
	TIME [epoch: 9.11 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026311890349391808		[learning rate: 0.00095529]
	Learning Rate: 0.000955286
	LOSS [training: 0.026311890349391808 | validation: 0.029378311010494977]
	TIME [epoch: 9.09 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024566792181041484		[learning rate: 0.00095236]
	Learning Rate: 0.000952357
	LOSS [training: 0.024566792181041484 | validation: 0.025570229312659565]
	TIME [epoch: 9.08 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015612564641226623		[learning rate: 0.00094944]
	Learning Rate: 0.000949438
	LOSS [training: 0.015612564641226623 | validation: 0.01836477625189674]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1267.pth
	Model improved!!!
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0305997884063537		[learning rate: 0.00094653]
	Learning Rate: 0.000946528
	LOSS [training: 0.0305997884063537 | validation: 0.09724895755420677]
	TIME [epoch: 9.11 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0636994687534785		[learning rate: 0.00094363]
	Learning Rate: 0.000943626
	LOSS [training: 0.0636994687534785 | validation: 0.071380130363311]
	TIME [epoch: 9.09 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04166930567072838		[learning rate: 0.00094073]
	Learning Rate: 0.000940734
	LOSS [training: 0.04166930567072838 | validation: 0.10920161482029758]
	TIME [epoch: 9.08 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0598637653893168		[learning rate: 0.00093785]
	Learning Rate: 0.00093785
	LOSS [training: 0.0598637653893168 | validation: 0.07326334585719824]
	TIME [epoch: 9.08 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027089913028791452		[learning rate: 0.00093497]
	Learning Rate: 0.000934975
	LOSS [training: 0.027089913028791452 | validation: 0.04008969522839261]
	TIME [epoch: 9.08 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013561861443934037		[learning rate: 0.00093211]
	Learning Rate: 0.000932109
	LOSS [training: 0.013561861443934037 | validation: 0.03781212683247106]
	TIME [epoch: 9.1 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032242662120740825		[learning rate: 0.00092925]
	Learning Rate: 0.000929252
	LOSS [training: 0.032242662120740825 | validation: 0.04345728553571906]
	TIME [epoch: 9.09 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02600621842549658		[learning rate: 0.0009264]
	Learning Rate: 0.000926403
	LOSS [training: 0.02600621842549658 | validation: 0.02286646792425715]
	TIME [epoch: 9.08 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049664511177630835		[learning rate: 0.00092356]
	Learning Rate: 0.000923563
	LOSS [training: 0.049664511177630835 | validation: 0.06280911222925926]
	TIME [epoch: 9.09 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045049150002036034		[learning rate: 0.00092073]
	Learning Rate: 0.000920732
	LOSS [training: 0.045049150002036034 | validation: 0.04408448870216926]
	TIME [epoch: 9.11 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02685295157555659		[learning rate: 0.00091791]
	Learning Rate: 0.00091791
	LOSS [training: 0.02685295157555659 | validation: 0.0204982630170139]
	TIME [epoch: 9.09 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02601862555841452		[learning rate: 0.0009151]
	Learning Rate: 0.000915096
	LOSS [training: 0.02601862555841452 | validation: 0.018138669705471067]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1279.pth
	Model improved!!!
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018534138378619457		[learning rate: 0.00091229]
	Learning Rate: 0.000912291
	LOSS [training: 0.018534138378619457 | validation: 0.026387880593974778]
	TIME [epoch: 9.09 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012001356490168699		[learning rate: 0.00090949]
	Learning Rate: 0.000909494
	LOSS [training: 0.012001356490168699 | validation: 0.020383438840630177]
	TIME [epoch: 9.11 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013953546618329971		[learning rate: 0.00090671]
	Learning Rate: 0.000906706
	LOSS [training: 0.013953546618329971 | validation: 0.03580608883847289]
	TIME [epoch: 9.1 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02239954603418921		[learning rate: 0.00090393]
	Learning Rate: 0.000903927
	LOSS [training: 0.02239954603418921 | validation: 0.04008643862142987]
	TIME [epoch: 9.09 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013180007346427599		[learning rate: 0.00090116]
	Learning Rate: 0.000901156
	LOSS [training: 0.013180007346427599 | validation: 0.023632493943306604]
	TIME [epoch: 9.09 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017237023424350916		[learning rate: 0.00089839]
	Learning Rate: 0.000898394
	LOSS [training: 0.017237023424350916 | validation: 0.0301141942224761]
	TIME [epoch: 9.08 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03403118292162362		[learning rate: 0.00089564]
	Learning Rate: 0.00089564
	LOSS [training: 0.03403118292162362 | validation: 0.06880409464782306]
	TIME [epoch: 9.11 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022083166167641978		[learning rate: 0.00089289]
	Learning Rate: 0.000892894
	LOSS [training: 0.022083166167641978 | validation: 0.026829808039762305]
	TIME [epoch: 9.09 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021990692521137504		[learning rate: 0.00089016]
	Learning Rate: 0.000890157
	LOSS [training: 0.021990692521137504 | validation: 0.025723730839346717]
	TIME [epoch: 9.08 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023426346568165123		[learning rate: 0.00088743]
	Learning Rate: 0.000887428
	LOSS [training: 0.023426346568165123 | validation: 0.028560134081379928]
	TIME [epoch: 9.09 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01631972879939898		[learning rate: 0.00088471]
	Learning Rate: 0.000884708
	LOSS [training: 0.01631972879939898 | validation: 0.02003491490735308]
	TIME [epoch: 9.12 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016653144650892748		[learning rate: 0.000882]
	Learning Rate: 0.000881996
	LOSS [training: 0.016653144650892748 | validation: 0.02592989917260274]
	TIME [epoch: 9.13 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024722905206522382		[learning rate: 0.00087929]
	Learning Rate: 0.000879292
	LOSS [training: 0.024722905206522382 | validation: 0.023768292640841]
	TIME [epoch: 9.08 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011427673334824877		[learning rate: 0.0008766]
	Learning Rate: 0.000876597
	LOSS [training: 0.011427673334824877 | validation: 0.04334761443896855]
	TIME [epoch: 9.08 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025823144900098877		[learning rate: 0.00087391]
	Learning Rate: 0.00087391
	LOSS [training: 0.025823144900098877 | validation: 0.022644421444336888]
	TIME [epoch: 9.11 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0170318042784073		[learning rate: 0.00087123]
	Learning Rate: 0.000871231
	LOSS [training: 0.0170318042784073 | validation: 0.023895589508354673]
	TIME [epoch: 9.09 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022827228065389588		[learning rate: 0.00086856]
	Learning Rate: 0.00086856
	LOSS [training: 0.022827228065389588 | validation: 0.057811912337447445]
	TIME [epoch: 9.09 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04318538007817386		[learning rate: 0.0008659]
	Learning Rate: 0.000865898
	LOSS [training: 0.04318538007817386 | validation: 0.036112730834682416]
	TIME [epoch: 9.08 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01354791958658809		[learning rate: 0.00086324]
	Learning Rate: 0.000863243
	LOSS [training: 0.01354791958658809 | validation: 0.03532012137196474]
	TIME [epoch: 9.11 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02923954052269393		[learning rate: 0.0008606]
	Learning Rate: 0.000860597
	LOSS [training: 0.02923954052269393 | validation: 0.03549866703455077]
	TIME [epoch: 9.09 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014501753975534406		[learning rate: 0.00085796]
	Learning Rate: 0.000857959
	LOSS [training: 0.014501753975534406 | validation: 0.03270820289838403]
	TIME [epoch: 9.09 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02193178127881936		[learning rate: 0.00085533]
	Learning Rate: 0.000855329
	LOSS [training: 0.02193178127881936 | validation: 0.02840593158935194]
	TIME [epoch: 9.09 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031388768761323724		[learning rate: 0.00085271]
	Learning Rate: 0.000852707
	LOSS [training: 0.031388768761323724 | validation: 0.03938513728065386]
	TIME [epoch: 9.11 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025352262011516503		[learning rate: 0.00085009]
	Learning Rate: 0.000850093
	LOSS [training: 0.025352262011516503 | validation: 0.03876393359005709]
	TIME [epoch: 9.09 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034728443206085154		[learning rate: 0.00084749]
	Learning Rate: 0.000847488
	LOSS [training: 0.034728443206085154 | validation: 0.0605602423801702]
	TIME [epoch: 9.08 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035131992264613866		[learning rate: 0.00084489]
	Learning Rate: 0.00084489
	LOSS [training: 0.035131992264613866 | validation: 0.05456606035436591]
	TIME [epoch: 9.09 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043028367974612666		[learning rate: 0.0008423]
	Learning Rate: 0.0008423
	LOSS [training: 0.043028367974612666 | validation: 0.036654995664269975]
	TIME [epoch: 9.09 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027522515070815427		[learning rate: 0.00083972]
	Learning Rate: 0.000839718
	LOSS [training: 0.027522515070815427 | validation: 0.05024675761007429]
	TIME [epoch: 9.1 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05012130777389462		[learning rate: 0.00083714]
	Learning Rate: 0.000837144
	LOSS [training: 0.05012130777389462 | validation: 0.043778586720904025]
	TIME [epoch: 9.09 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024891818825183758		[learning rate: 0.00083458]
	Learning Rate: 0.000834578
	LOSS [training: 0.024891818825183758 | validation: 0.030813587813951923]
	TIME [epoch: 9.09 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018926438312823764		[learning rate: 0.00083202]
	Learning Rate: 0.000832019
	LOSS [training: 0.018926438312823764 | validation: 0.014994294183489257]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1310.pth
	Model improved!!!
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02192537539765689		[learning rate: 0.00082947]
	Learning Rate: 0.000829469
	LOSS [training: 0.02192537539765689 | validation: 0.044524514905909335]
	TIME [epoch: 9.1 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03633579210480928		[learning rate: 0.00082693]
	Learning Rate: 0.000826926
	LOSS [training: 0.03633579210480928 | validation: 0.030731873939280483]
	TIME [epoch: 9.09 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03376569370787507		[learning rate: 0.00082439]
	Learning Rate: 0.000824391
	LOSS [training: 0.03376569370787507 | validation: 0.014552364955468581]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1313.pth
	Model improved!!!
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01593012322388837		[learning rate: 0.00082186]
	Learning Rate: 0.000821864
	LOSS [training: 0.01593012322388837 | validation: 0.018209823004469296]
	TIME [epoch: 9.09 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014121015735796289		[learning rate: 0.00081934]
	Learning Rate: 0.000819345
	LOSS [training: 0.014121015735796289 | validation: 0.027332319379306344]
	TIME [epoch: 9.12 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012201251147338294		[learning rate: 0.00081683]
	Learning Rate: 0.000816833
	LOSS [training: 0.012201251147338294 | validation: 0.027472644108411243]
	TIME [epoch: 9.09 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01956896575162522		[learning rate: 0.00081433]
	Learning Rate: 0.000814329
	LOSS [training: 0.01956896575162522 | validation: 0.026362573499639712]
	TIME [epoch: 9.09 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028337576826700878		[learning rate: 0.00081183]
	Learning Rate: 0.000811833
	LOSS [training: 0.028337576826700878 | validation: 0.05480064983466677]
	TIME [epoch: 9.09 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0359005943073635		[learning rate: 0.00080934]
	Learning Rate: 0.000809344
	LOSS [training: 0.0359005943073635 | validation: 0.0783033598213768]
	TIME [epoch: 9.09 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05350265219767007		[learning rate: 0.00080686]
	Learning Rate: 0.000806863
	LOSS [training: 0.05350265219767007 | validation: 0.08836013276365218]
	TIME [epoch: 9.11 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02721623234964011		[learning rate: 0.00080439]
	Learning Rate: 0.00080439
	LOSS [training: 0.02721623234964011 | validation: 0.014653337441915895]
	TIME [epoch: 9.09 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016749901427509997		[learning rate: 0.00080192]
	Learning Rate: 0.000801924
	LOSS [training: 0.016749901427509997 | validation: 0.016373171636131927]
	TIME [epoch: 9.09 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0202949080925697		[learning rate: 0.00079947]
	Learning Rate: 0.000799466
	LOSS [training: 0.0202949080925697 | validation: 0.0567663644860178]
	TIME [epoch: 9.09 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03341906153439634		[learning rate: 0.00079702]
	Learning Rate: 0.000797015
	LOSS [training: 0.03341906153439634 | validation: 0.03561703309701034]
	TIME [epoch: 9.12 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025110100611377445		[learning rate: 0.00079457]
	Learning Rate: 0.000794572
	LOSS [training: 0.025110100611377445 | validation: 0.03638559262580593]
	TIME [epoch: 9.09 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02172058856245465		[learning rate: 0.00079214]
	Learning Rate: 0.000792136
	LOSS [training: 0.02172058856245465 | validation: 0.024803772416674433]
	TIME [epoch: 9.11 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016122893187712435		[learning rate: 0.00078971]
	Learning Rate: 0.000789708
	LOSS [training: 0.016122893187712435 | validation: 0.01959471525553052]
	TIME [epoch: 9.1 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016641124791505778		[learning rate: 0.00078729]
	Learning Rate: 0.000787287
	LOSS [training: 0.016641124791505778 | validation: 0.023405323670140518]
	TIME [epoch: 9.11 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020736949353270973		[learning rate: 0.00078487]
	Learning Rate: 0.000784874
	LOSS [training: 0.020736949353270973 | validation: 0.01893721925830278]
	TIME [epoch: 9.1 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02109501752810584		[learning rate: 0.00078247]
	Learning Rate: 0.000782468
	LOSS [training: 0.02109501752810584 | validation: 0.030962624926666543]
	TIME [epoch: 9.09 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033953703146126044		[learning rate: 0.00078007]
	Learning Rate: 0.00078007
	LOSS [training: 0.033953703146126044 | validation: 0.042111627149302]
	TIME [epoch: 9.1 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02481611159884218		[learning rate: 0.00077768]
	Learning Rate: 0.000777678
	LOSS [training: 0.02481611159884218 | validation: 0.03203513040316465]
	TIME [epoch: 9.11 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02873401154549684		[learning rate: 0.00077529]
	Learning Rate: 0.000775294
	LOSS [training: 0.02873401154549684 | validation: 0.034929614753573764]
	TIME [epoch: 9.1 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02787126104732584		[learning rate: 0.00077292]
	Learning Rate: 0.000772918
	LOSS [training: 0.02787126104732584 | validation: 0.038880748243637665]
	TIME [epoch: 9.09 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03222844509764764		[learning rate: 0.00077055]
	Learning Rate: 0.000770548
	LOSS [training: 0.03222844509764764 | validation: 0.026450671136931978]
	TIME [epoch: 9.09 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025157764982326893		[learning rate: 0.00076819]
	Learning Rate: 0.000768187
	LOSS [training: 0.025157764982326893 | validation: 0.048761742883248735]
	TIME [epoch: 9.1 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03704119871480296		[learning rate: 0.00076583]
	Learning Rate: 0.000765832
	LOSS [training: 0.03704119871480296 | validation: 0.06464591977142306]
	TIME [epoch: 9.11 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055100690327287635		[learning rate: 0.00076348]
	Learning Rate: 0.000763484
	LOSS [training: 0.055100690327287635 | validation: 0.057168107675766244]
	TIME [epoch: 9.09 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05580372448620917		[learning rate: 0.00076114]
	Learning Rate: 0.000761144
	LOSS [training: 0.05580372448620917 | validation: 0.09338567157233385]
	TIME [epoch: 9.09 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054874824439309064		[learning rate: 0.00075881]
	Learning Rate: 0.00075881
	LOSS [training: 0.054874824439309064 | validation: 0.06025031510995975]
	TIME [epoch: 9.09 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03812759267672311		[learning rate: 0.00075648]
	Learning Rate: 0.000756484
	LOSS [training: 0.03812759267672311 | validation: 0.04450792747572581]
	TIME [epoch: 9.1 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024775401492949736		[learning rate: 0.00075417]
	Learning Rate: 0.000754165
	LOSS [training: 0.024775401492949736 | validation: 0.03483613871709086]
	TIME [epoch: 9.09 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023967533807322864		[learning rate: 0.00075185]
	Learning Rate: 0.000751854
	LOSS [training: 0.023967533807322864 | validation: 0.029729898871677846]
	TIME [epoch: 9.09 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02463293927088483		[learning rate: 0.00074955]
	Learning Rate: 0.000749549
	LOSS [training: 0.02463293927088483 | validation: 0.048877273258263715]
	TIME [epoch: 9.1 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01630553580940468		[learning rate: 0.00074725]
	Learning Rate: 0.000747251
	LOSS [training: 0.01630553580940468 | validation: 0.031402733547558126]
	TIME [epoch: 9.1 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027218427526355247		[learning rate: 0.00074496]
	Learning Rate: 0.000744961
	LOSS [training: 0.027218427526355247 | validation: 0.043111164272860755]
	TIME [epoch: 9.09 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02021515578868419		[learning rate: 0.00074268]
	Learning Rate: 0.000742677
	LOSS [training: 0.02021515578868419 | validation: 0.020495733310412264]
	TIME [epoch: 9.09 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015872522394214515		[learning rate: 0.0007404]
	Learning Rate: 0.0007404
	LOSS [training: 0.015872522394214515 | validation: 0.034072758736677825]
	TIME [epoch: 9.08 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017483479094300133		[learning rate: 0.00073813]
	Learning Rate: 0.000738131
	LOSS [training: 0.017483479094300133 | validation: 0.03160300322601948]
	TIME [epoch: 9.11 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021493685369019345		[learning rate: 0.00073587]
	Learning Rate: 0.000735868
	LOSS [training: 0.021493685369019345 | validation: 0.029535837886486897]
	TIME [epoch: 9.09 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0202690285091828		[learning rate: 0.00073361]
	Learning Rate: 0.000733612
	LOSS [training: 0.0202690285091828 | validation: 0.03541702226840601]
	TIME [epoch: 9.09 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01377990501944063		[learning rate: 0.00073136]
	Learning Rate: 0.000731364
	LOSS [training: 0.01377990501944063 | validation: 0.028540714263139092]
	TIME [epoch: 9.09 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01842768463753191		[learning rate: 0.00072912]
	Learning Rate: 0.000729122
	LOSS [training: 0.01842768463753191 | validation: 0.03455171747032636]
	TIME [epoch: 9.11 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030541688963099372		[learning rate: 0.00072689]
	Learning Rate: 0.000726886
	LOSS [training: 0.030541688963099372 | validation: 0.0643513874639189]
	TIME [epoch: 9.1 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05156392969447776		[learning rate: 0.00072466]
	Learning Rate: 0.000724658
	LOSS [training: 0.05156392969447776 | validation: 0.0754026075983795]
	TIME [epoch: 9.09 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028927234026396863		[learning rate: 0.00072244]
	Learning Rate: 0.000722437
	LOSS [training: 0.028927234026396863 | validation: 0.06097274586370667]
	TIME [epoch: 9.1 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043361461413605806		[learning rate: 0.00072022]
	Learning Rate: 0.000720223
	LOSS [training: 0.043361461413605806 | validation: 0.038551441166120595]
	TIME [epoch: 9.12 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02458675913645301		[learning rate: 0.00071801]
	Learning Rate: 0.000718015
	LOSS [training: 0.02458675913645301 | validation: 0.04157511669719341]
	TIME [epoch: 9.1 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04890938333294585		[learning rate: 0.00071581]
	Learning Rate: 0.000715814
	LOSS [training: 0.04890938333294585 | validation: 0.07664590137699018]
	TIME [epoch: 9.09 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061031809654485736		[learning rate: 0.00071362]
	Learning Rate: 0.000713619
	LOSS [training: 0.061031809654485736 | validation: 0.07302114978265647]
	TIME [epoch: 9.09 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03751222296545724		[learning rate: 0.00071143]
	Learning Rate: 0.000711432
	LOSS [training: 0.03751222296545724 | validation: 0.05087253176128478]
	TIME [epoch: 9.11 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03866942819742239		[learning rate: 0.00070925]
	Learning Rate: 0.000709251
	LOSS [training: 0.03866942819742239 | validation: 0.03310954466489069]
	TIME [epoch: 9.09 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03453836886252612		[learning rate: 0.00070708]
	Learning Rate: 0.000707077
	LOSS [training: 0.03453836886252612 | validation: 0.046665715668780056]
	TIME [epoch: 9.09 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03126208569222377		[learning rate: 0.00070491]
	Learning Rate: 0.00070491
	LOSS [training: 0.03126208569222377 | validation: 0.036199967351480164]
	TIME [epoch: 9.08 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04025351473396187		[learning rate: 0.00070275]
	Learning Rate: 0.000702748
	LOSS [training: 0.04025351473396187 | validation: 0.04076017497014002]
	TIME [epoch: 9.1 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03211304487746973		[learning rate: 0.00070059]
	Learning Rate: 0.000700594
	LOSS [training: 0.03211304487746973 | validation: 0.05724805468445149]
	TIME [epoch: 9.11 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0491670904491409		[learning rate: 0.00069845]
	Learning Rate: 0.000698447
	LOSS [training: 0.0491670904491409 | validation: 0.04850371888315833]
	TIME [epoch: 9.08 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03450791506116449		[learning rate: 0.00069631]
	Learning Rate: 0.000696306
	LOSS [training: 0.03450791506116449 | validation: 0.04829962041638763]
	TIME [epoch: 9.09 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0282740522565621		[learning rate: 0.00069417]
	Learning Rate: 0.000694171
	LOSS [training: 0.0282740522565621 | validation: 0.031037447332171453]
	TIME [epoch: 9.09 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032089311827049084		[learning rate: 0.00069204]
	Learning Rate: 0.000692043
	LOSS [training: 0.032089311827049084 | validation: 0.03258184561823596]
	TIME [epoch: 9.11 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024715690092932334		[learning rate: 0.00068992]
	Learning Rate: 0.000689922
	LOSS [training: 0.024715690092932334 | validation: 0.038573343788612324]
	TIME [epoch: 9.08 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02213555964321114		[learning rate: 0.00068781]
	Learning Rate: 0.000687807
	LOSS [training: 0.02213555964321114 | validation: 0.030836498046165915]
	TIME [epoch: 9.09 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01627440298746716		[learning rate: 0.0006857]
	Learning Rate: 0.000685699
	LOSS [training: 0.01627440298746716 | validation: 0.020371638636554813]
	TIME [epoch: 9.1 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016557889513989316		[learning rate: 0.0006836]
	Learning Rate: 0.000683597
	LOSS [training: 0.016557889513989316 | validation: 0.029805086129948838]
	TIME [epoch: 9.11 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01675861143408392		[learning rate: 0.0006815]
	Learning Rate: 0.000681501
	LOSS [training: 0.01675861143408392 | validation: 0.027709208652525047]
	TIME [epoch: 9.09 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020129488565037434		[learning rate: 0.00067941]
	Learning Rate: 0.000679412
	LOSS [training: 0.020129488565037434 | validation: 0.025924475071522193]
	TIME [epoch: 9.09 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024246675006564827		[learning rate: 0.00067733]
	Learning Rate: 0.000677329
	LOSS [training: 0.024246675006564827 | validation: 0.028798020135792586]
	TIME [epoch: 9.09 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02428939081900215		[learning rate: 0.00067525]
	Learning Rate: 0.000675253
	LOSS [training: 0.02428939081900215 | validation: 0.02963790018639008]
	TIME [epoch: 9.11 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019341380004188533		[learning rate: 0.00067318]
	Learning Rate: 0.000673183
	LOSS [training: 0.019341380004188533 | validation: 0.029989968376324023]
	TIME [epoch: 9.09 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0149079924324544		[learning rate: 0.00067112]
	Learning Rate: 0.00067112
	LOSS [training: 0.0149079924324544 | validation: 0.027913107254335205]
	TIME [epoch: 9.09 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013415356401818925		[learning rate: 0.00066906]
	Learning Rate: 0.000669062
	LOSS [training: 0.013415356401818925 | validation: 0.0373097835693586]
	TIME [epoch: 9.07 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019913051160939534		[learning rate: 0.00066701]
	Learning Rate: 0.000667011
	LOSS [training: 0.019913051160939534 | validation: 0.0388958402141883]
	TIME [epoch: 9.1 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020905331865085898		[learning rate: 0.00066497]
	Learning Rate: 0.000664967
	LOSS [training: 0.020905331865085898 | validation: 0.028928432389114668]
	TIME [epoch: 9.08 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01699140891674757		[learning rate: 0.00066293]
	Learning Rate: 0.000662929
	LOSS [training: 0.01699140891674757 | validation: 0.024634809086004752]
	TIME [epoch: 9.09 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03422925881319724		[learning rate: 0.0006609]
	Learning Rate: 0.000660896
	LOSS [training: 0.03422925881319724 | validation: 0.05791976409700364]
	TIME [epoch: 9.09 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022587301533229687		[learning rate: 0.00065887]
	Learning Rate: 0.00065887
	LOSS [training: 0.022587301533229687 | validation: 0.052750337938078956]
	TIME [epoch: 9.12 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04173444670265644		[learning rate: 0.00065685]
	Learning Rate: 0.000656851
	LOSS [training: 0.04173444670265644 | validation: 0.06398187648837649]
	TIME [epoch: 9.11 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024659102312125238		[learning rate: 0.00065484]
	Learning Rate: 0.000654837
	LOSS [training: 0.024659102312125238 | validation: 0.032622637986414994]
	TIME [epoch: 9.13 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020513854487606748		[learning rate: 0.00065283]
	Learning Rate: 0.00065283
	LOSS [training: 0.020513854487606748 | validation: 0.03354240400184933]
	TIME [epoch: 9.09 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017212002480025287		[learning rate: 0.00065083]
	Learning Rate: 0.000650829
	LOSS [training: 0.017212002480025287 | validation: 0.032679672866496104]
	TIME [epoch: 9.12 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013351598791809452		[learning rate: 0.00064883]
	Learning Rate: 0.000648834
	LOSS [training: 0.013351598791809452 | validation: 0.023010880080863674]
	TIME [epoch: 9.09 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015387841481805869		[learning rate: 0.00064684]
	Learning Rate: 0.000646845
	LOSS [training: 0.015387841481805869 | validation: 0.015313697608135448]
	TIME [epoch: 9.08 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01064949714491549		[learning rate: 0.00064486]
	Learning Rate: 0.000644862
	LOSS [training: 0.01064949714491549 | validation: 0.01785109860106678]
	TIME [epoch: 9.09 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012434634809192425		[learning rate: 0.00064289]
	Learning Rate: 0.000642885
	LOSS [training: 0.012434634809192425 | validation: 0.01251816894543148]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1394.pth
	Model improved!!!
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009576660795933131		[learning rate: 0.00064091]
	Learning Rate: 0.000640914
	LOSS [training: 0.009576660795933131 | validation: 0.011482656620133596]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1395.pth
	Model improved!!!
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011661789351485886		[learning rate: 0.00063895]
	Learning Rate: 0.00063895
	LOSS [training: 0.011661789351485886 | validation: 0.02077328098192715]
	TIME [epoch: 9.09 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03786487017782777		[learning rate: 0.00063699]
	Learning Rate: 0.000636991
	LOSS [training: 0.03786487017782777 | validation: 0.06027912762784082]
	TIME [epoch: 9.08 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027578296476783382		[learning rate: 0.00063504]
	Learning Rate: 0.000635038
	LOSS [training: 0.027578296476783382 | validation: 0.03245303454693347]
	TIME [epoch: 9.09 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020201687625941826		[learning rate: 0.00063309]
	Learning Rate: 0.000633092
	LOSS [training: 0.020201687625941826 | validation: 0.04911549115765414]
	TIME [epoch: 9.11 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023364620779388577		[learning rate: 0.00063115]
	Learning Rate: 0.000631151
	LOSS [training: 0.023364620779388577 | validation: 0.02182805044789251]
	TIME [epoch: 9.09 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011386720605806313		[learning rate: 0.00062922]
	Learning Rate: 0.000629216
	LOSS [training: 0.011386720605806313 | validation: 0.01391062785780648]
	TIME [epoch: 9.08 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01160695125227917		[learning rate: 0.00062729]
	Learning Rate: 0.000627287
	LOSS [training: 0.01160695125227917 | validation: 0.0261478358570716]
	TIME [epoch: 9.08 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024177681223000114		[learning rate: 0.00062536]
	Learning Rate: 0.000625365
	LOSS [training: 0.024177681223000114 | validation: 0.07222051113199295]
	TIME [epoch: 9.1 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025820621893523188		[learning rate: 0.00062345]
	Learning Rate: 0.000623448
	LOSS [training: 0.025820621893523188 | validation: 0.02740757645721527]
	TIME [epoch: 9.1 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013642691737934306		[learning rate: 0.00062154]
	Learning Rate: 0.000621537
	LOSS [training: 0.013642691737934306 | validation: 0.027340374203445175]
	TIME [epoch: 9.09 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025723692526983966		[learning rate: 0.00061963]
	Learning Rate: 0.000619631
	LOSS [training: 0.025723692526983966 | validation: 0.04710566837298541]
	TIME [epoch: 9.09 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03337668550635507		[learning rate: 0.00061773]
	Learning Rate: 0.000617732
	LOSS [training: 0.03337668550635507 | validation: 0.035176388263786856]
	TIME [epoch: 9.09 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021479963500248913		[learning rate: 0.00061584]
	Learning Rate: 0.000615838
	LOSS [training: 0.021479963500248913 | validation: 0.01652881046685394]
	TIME [epoch: 9.11 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015495114040130428		[learning rate: 0.00061395]
	Learning Rate: 0.00061395
	LOSS [training: 0.015495114040130428 | validation: 0.01456548055530045]
	TIME [epoch: 9.09 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014782650729559216		[learning rate: 0.00061207]
	Learning Rate: 0.000612068
	LOSS [training: 0.014782650729559216 | validation: 0.01333179891334623]
	TIME [epoch: 9.09 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0076330788917479365		[learning rate: 0.00061019]
	Learning Rate: 0.000610192
	LOSS [training: 0.0076330788917479365 | validation: 0.008386138594532962]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1411.pth
	Model improved!!!
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005480431295261774		[learning rate: 0.00060832]
	Learning Rate: 0.000608322
	LOSS [training: 0.005480431295261774 | validation: 0.016998989569645503]
	TIME [epoch: 9.11 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013873820037419857		[learning rate: 0.00060646]
	Learning Rate: 0.000606457
	LOSS [training: 0.013873820037419857 | validation: 0.01979982355487706]
	TIME [epoch: 9.08 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015417630699078411		[learning rate: 0.0006046]
	Learning Rate: 0.000604598
	LOSS [training: 0.015417630699078411 | validation: 0.011230143503672553]
	TIME [epoch: 9.09 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007932617244526343		[learning rate: 0.00060274]
	Learning Rate: 0.000602745
	LOSS [training: 0.007932617244526343 | validation: 0.015982749205126427]
	TIME [epoch: 9.09 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008577776819302432		[learning rate: 0.0006009]
	Learning Rate: 0.000600897
	LOSS [training: 0.008577776819302432 | validation: 0.01615938371494393]
	TIME [epoch: 9.09 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008471941006415348		[learning rate: 0.00059905]
	Learning Rate: 0.000599055
	LOSS [training: 0.008471941006415348 | validation: 0.015512541019258298]
	TIME [epoch: 9.09 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007352128736137319		[learning rate: 0.00059722]
	Learning Rate: 0.000597219
	LOSS [training: 0.007352128736137319 | validation: 0.02967002242568994]
	TIME [epoch: 9.08 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02201263222377652		[learning rate: 0.00059539]
	Learning Rate: 0.000595388
	LOSS [training: 0.02201263222377652 | validation: 0.017862200143929467]
	TIME [epoch: 9.08 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036811247869573537		[learning rate: 0.00059356]
	Learning Rate: 0.000593563
	LOSS [training: 0.036811247869573537 | validation: 0.059886747388737276]
	TIME [epoch: 9.09 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022192921306885886		[learning rate: 0.00059174]
	Learning Rate: 0.000591743
	LOSS [training: 0.022192921306885886 | validation: 0.028414016302845922]
	TIME [epoch: 9.1 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012044451592429877		[learning rate: 0.00058993]
	Learning Rate: 0.000589929
	LOSS [training: 0.012044451592429877 | validation: 0.02250225643828735]
	TIME [epoch: 9.08 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006756359395336202		[learning rate: 0.00058812]
	Learning Rate: 0.000588121
	LOSS [training: 0.006756359395336202 | validation: 0.01859289349602148]
	TIME [epoch: 9.08 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022634820543660266		[learning rate: 0.00058632]
	Learning Rate: 0.000586318
	LOSS [training: 0.022634820543660266 | validation: 0.04305010846019208]
	TIME [epoch: 9.09 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014370548886152218		[learning rate: 0.00058452]
	Learning Rate: 0.000584521
	LOSS [training: 0.014370548886152218 | validation: 0.012328515990301705]
	TIME [epoch: 9.11 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0065295657917073995		[learning rate: 0.00058273]
	Learning Rate: 0.000582729
	LOSS [training: 0.0065295657917073995 | validation: 0.008299014792906444]
	TIME [epoch: 9.08 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1426.pth
	Model improved!!!
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006396342484313547		[learning rate: 0.00058094]
	Learning Rate: 0.000580943
	LOSS [training: 0.006396342484313547 | validation: 0.019895512712632256]
	TIME [epoch: 9.09 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011900433073923413		[learning rate: 0.00057916]
	Learning Rate: 0.000579162
	LOSS [training: 0.011900433073923413 | validation: 0.05491918740736511]
	TIME [epoch: 9.09 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02027147350200389		[learning rate: 0.00057739]
	Learning Rate: 0.000577386
	LOSS [training: 0.02027147350200389 | validation: 0.026536360774363422]
	TIME [epoch: 9.1 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01625729668608963		[learning rate: 0.00057562]
	Learning Rate: 0.000575616
	LOSS [training: 0.01625729668608963 | validation: 0.036516386020655794]
	TIME [epoch: 9.09 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02309687019159925		[learning rate: 0.00057385]
	Learning Rate: 0.000573852
	LOSS [training: 0.02309687019159925 | validation: 0.041433436512010674]
	TIME [epoch: 9.08 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024987853481488607		[learning rate: 0.00057209]
	Learning Rate: 0.000572093
	LOSS [training: 0.024987853481488607 | validation: 0.03302667719938178]
	TIME [epoch: 9.09 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02779146030232408		[learning rate: 0.00057034]
	Learning Rate: 0.000570339
	LOSS [training: 0.02779146030232408 | validation: 0.05946853142926921]
	TIME [epoch: 9.09 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03156088022827155		[learning rate: 0.00056859]
	Learning Rate: 0.000568591
	LOSS [training: 0.03156088022827155 | validation: 0.024016115046168643]
	TIME [epoch: 9.09 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015493234886914693		[learning rate: 0.00056685]
	Learning Rate: 0.000566848
	LOSS [training: 0.015493234886914693 | validation: 0.02776205128648528]
	TIME [epoch: 9.08 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025817457010320753		[learning rate: 0.00056511]
	Learning Rate: 0.00056511
	LOSS [training: 0.025817457010320753 | validation: 0.03175591037709739]
	TIME [epoch: 9.08 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02025069053950798		[learning rate: 0.00056338]
	Learning Rate: 0.000563378
	LOSS [training: 0.02025069053950798 | validation: 0.028915290593953057]
	TIME [epoch: 9.08 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03037956903258901		[learning rate: 0.00056165]
	Learning Rate: 0.000561651
	LOSS [training: 0.03037956903258901 | validation: 0.05820815709358425]
	TIME [epoch: 9.1 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026396193345384837		[learning rate: 0.00055993]
	Learning Rate: 0.000559929
	LOSS [training: 0.026396193345384837 | validation: 0.01480601964013169]
	TIME [epoch: 9.09 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011096384045055804		[learning rate: 0.00055821]
	Learning Rate: 0.000558213
	LOSS [training: 0.011096384045055804 | validation: 0.030685511808453823]
	TIME [epoch: 9.09 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022071038067410887		[learning rate: 0.0005565]
	Learning Rate: 0.000556502
	LOSS [training: 0.022071038067410887 | validation: 0.04051564379009509]
	TIME [epoch: 9.09 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018757216492044444		[learning rate: 0.0005548]
	Learning Rate: 0.000554796
	LOSS [training: 0.018757216492044444 | validation: 0.03149350544501014]
	TIME [epoch: 9.1 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018612748156190455		[learning rate: 0.0005531]
	Learning Rate: 0.000553095
	LOSS [training: 0.018612748156190455 | validation: 0.027484403157737813]
	TIME [epoch: 9.08 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01774951086891258		[learning rate: 0.0005514]
	Learning Rate: 0.0005514
	LOSS [training: 0.01774951086891258 | validation: 0.04383826513932825]
	TIME [epoch: 9.09 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024535219633749168		[learning rate: 0.00054971]
	Learning Rate: 0.000549709
	LOSS [training: 0.024535219633749168 | validation: 0.0348524671501041]
	TIME [epoch: 9.08 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020008676593518668		[learning rate: 0.00054802]
	Learning Rate: 0.000548024
	LOSS [training: 0.020008676593518668 | validation: 0.012853040489438345]
	TIME [epoch: 9.11 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013465932251092067		[learning rate: 0.00054634]
	Learning Rate: 0.000546345
	LOSS [training: 0.013465932251092067 | validation: 0.0281972059564677]
	TIME [epoch: 9.09 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017226490760073744		[learning rate: 0.00054467]
	Learning Rate: 0.00054467
	LOSS [training: 0.017226490760073744 | validation: 0.02057523579748]
	TIME [epoch: 9.09 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018690242018471546		[learning rate: 0.000543]
	Learning Rate: 0.000543
	LOSS [training: 0.018690242018471546 | validation: 0.021762864608069456]
	TIME [epoch: 9.09 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021427065422871712		[learning rate: 0.00054134]
	Learning Rate: 0.000541336
	LOSS [training: 0.021427065422871712 | validation: 0.031964614394646276]
	TIME [epoch: 9.09 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025022802622677788		[learning rate: 0.00053968]
	Learning Rate: 0.000539676
	LOSS [training: 0.025022802622677788 | validation: 0.036906982719591364]
	TIME [epoch: 9.09 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020086419106202298		[learning rate: 0.00053802]
	Learning Rate: 0.000538022
	LOSS [training: 0.020086419106202298 | validation: 0.03321464938077438]
	TIME [epoch: 9.08 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01352396181493257		[learning rate: 0.00053637]
	Learning Rate: 0.000536373
	LOSS [training: 0.01352396181493257 | validation: 0.02426174159282181]
	TIME [epoch: 9.08 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025276946345222696		[learning rate: 0.00053473]
	Learning Rate: 0.000534728
	LOSS [training: 0.025276946345222696 | validation: 0.041155612669857705]
	TIME [epoch: 9.1 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02367710765861709		[learning rate: 0.00053309]
	Learning Rate: 0.000533089
	LOSS [training: 0.02367710765861709 | validation: 0.028396776251009323]
	TIME [epoch: 9.09 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018905240006780552		[learning rate: 0.00053146]
	Learning Rate: 0.000531455
	LOSS [training: 0.018905240006780552 | validation: 0.027549341269100417]
	TIME [epoch: 9.08 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017106200872943397		[learning rate: 0.00052983]
	Learning Rate: 0.000529826
	LOSS [training: 0.017106200872943397 | validation: 0.019593792825077106]
	TIME [epoch: 9.09 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020264086305842297		[learning rate: 0.0005282]
	Learning Rate: 0.000528202
	LOSS [training: 0.020264086305842297 | validation: 0.037493687278550514]
	TIME [epoch: 9.1 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026679511305277036		[learning rate: 0.00052658]
	Learning Rate: 0.000526583
	LOSS [training: 0.026679511305277036 | validation: 0.030276306626649693]
	TIME [epoch: 9.1 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026495470176711715		[learning rate: 0.00052497]
	Learning Rate: 0.000524969
	LOSS [training: 0.026495470176711715 | validation: 0.046723970547061025]
	TIME [epoch: 9.08 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037345001713111635		[learning rate: 0.00052336]
	Learning Rate: 0.000523359
	LOSS [training: 0.037345001713111635 | validation: 0.05214264530332201]
	TIME [epoch: 9.09 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03823869231256892		[learning rate: 0.00052176]
	Learning Rate: 0.000521755
	LOSS [training: 0.03823869231256892 | validation: 0.031472908399148944]
	TIME [epoch: 9.09 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023557387803973366		[learning rate: 0.00052016]
	Learning Rate: 0.000520156
	LOSS [training: 0.023557387803973366 | validation: 0.04509773319508105]
	TIME [epoch: 9.1 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02187783366999992		[learning rate: 0.00051856]
	Learning Rate: 0.000518561
	LOSS [training: 0.02187783366999992 | validation: 0.04066777555487831]
	TIME [epoch: 9.09 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02392266481025942		[learning rate: 0.00051697]
	Learning Rate: 0.000516972
	LOSS [training: 0.02392266481025942 | validation: 0.029591252500536173]
	TIME [epoch: 9.09 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030630348078576525		[learning rate: 0.00051539]
	Learning Rate: 0.000515387
	LOSS [training: 0.030630348078576525 | validation: 0.03958748055372393]
	TIME [epoch: 9.09 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02618109688648851		[learning rate: 0.00051381]
	Learning Rate: 0.000513807
	LOSS [training: 0.02618109688648851 | validation: 0.029113529047273136]
	TIME [epoch: 9.1 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01952394311647246		[learning rate: 0.00051223]
	Learning Rate: 0.000512232
	LOSS [training: 0.01952394311647246 | validation: 0.03926993382643343]
	TIME [epoch: 9.08 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026060647346317717		[learning rate: 0.00051066]
	Learning Rate: 0.000510662
	LOSS [training: 0.026060647346317717 | validation: 0.04948229074114688]
	TIME [epoch: 9.09 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021218298643507043		[learning rate: 0.0005091]
	Learning Rate: 0.000509096
	LOSS [training: 0.021218298643507043 | validation: 0.033734868533386204]
	TIME [epoch: 9.08 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0213352123491486		[learning rate: 0.00050754]
	Learning Rate: 0.000507536
	LOSS [training: 0.0213352123491486 | validation: 0.04022636509774903]
	TIME [epoch: 9.1 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025015793069662267		[learning rate: 0.00050598]
	Learning Rate: 0.00050598
	LOSS [training: 0.025015793069662267 | validation: 0.03627381548640292]
	TIME [epoch: 9.09 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02752845836467046		[learning rate: 0.00050443]
	Learning Rate: 0.000504429
	LOSS [training: 0.02752845836467046 | validation: 0.040464583530643465]
	TIME [epoch: 9.08 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02834924204859233		[learning rate: 0.00050288]
	Learning Rate: 0.000502883
	LOSS [training: 0.02834924204859233 | validation: 0.05760356213455746]
	TIME [epoch: 9.09 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02219385436430484		[learning rate: 0.00050134]
	Learning Rate: 0.000501341
	LOSS [training: 0.02219385436430484 | validation: 0.029492211884177187]
	TIME [epoch: 9.1 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01715175225819975		[learning rate: 0.0004998]
	Learning Rate: 0.000499804
	LOSS [training: 0.01715175225819975 | validation: 0.0345123471974462]
	TIME [epoch: 9.09 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016755806904245555		[learning rate: 0.00049827]
	Learning Rate: 0.000498272
	LOSS [training: 0.016755806904245555 | validation: 0.03247989620763568]
	TIME [epoch: 9.08 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021521623188824047		[learning rate: 0.00049674]
	Learning Rate: 0.000496745
	LOSS [training: 0.021521623188824047 | validation: 0.03730177714693019]
	TIME [epoch: 9.08 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03395442742447518		[learning rate: 0.00049522]
	Learning Rate: 0.000495222
	LOSS [training: 0.03395442742447518 | validation: 0.039205534059818796]
	TIME [epoch: 9.1 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028399038069153414		[learning rate: 0.0004937]
	Learning Rate: 0.000493704
	LOSS [training: 0.028399038069153414 | validation: 0.03778482752726868]
	TIME [epoch: 9.09 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029285252175683684		[learning rate: 0.00049219]
	Learning Rate: 0.000492191
	LOSS [training: 0.029285252175683684 | validation: 0.04474933334092389]
	TIME [epoch: 9.09 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044253727051279015		[learning rate: 0.00049068]
	Learning Rate: 0.000490682
	LOSS [training: 0.044253727051279015 | validation: 0.035636701511292425]
	TIME [epoch: 9.09 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03089621197971875		[learning rate: 0.00048918]
	Learning Rate: 0.000489178
	LOSS [training: 0.03089621197971875 | validation: 0.05062543432212448]
	TIME [epoch: 9.1 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03354052213674509		[learning rate: 0.00048768]
	Learning Rate: 0.000487678
	LOSS [training: 0.03354052213674509 | validation: 0.04216965400731373]
	TIME [epoch: 9.1 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028248055115521614		[learning rate: 0.00048618]
	Learning Rate: 0.000486183
	LOSS [training: 0.028248055115521614 | validation: 0.047167784303697724]
	TIME [epoch: 9.08 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029246979791680828		[learning rate: 0.00048469]
	Learning Rate: 0.000484693
	LOSS [training: 0.029246979791680828 | validation: 0.04338161745938414]
	TIME [epoch: 9.08 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026644460133976654		[learning rate: 0.00048321]
	Learning Rate: 0.000483207
	LOSS [training: 0.026644460133976654 | validation: 0.0491720969372352]
	TIME [epoch: 9.09 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031545862246473724		[learning rate: 0.00048173]
	Learning Rate: 0.000481726
	LOSS [training: 0.031545862246473724 | validation: 0.05739616620663963]
	TIME [epoch: 9.1 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030011638488243324		[learning rate: 0.00048025]
	Learning Rate: 0.000480249
	LOSS [training: 0.030011638488243324 | validation: 0.04383871168890176]
	TIME [epoch: 9.08 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03151843677175183		[learning rate: 0.00047878]
	Learning Rate: 0.000478777
	LOSS [training: 0.03151843677175183 | validation: 0.057231496077740376]
	TIME [epoch: 9.09 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040750470037103595		[learning rate: 0.00047731]
	Learning Rate: 0.000477309
	LOSS [training: 0.040750470037103595 | validation: 0.06026996754267718]
	TIME [epoch: 9.09 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033858191497398035		[learning rate: 0.00047585]
	Learning Rate: 0.000475846
	LOSS [training: 0.033858191497398035 | validation: 0.058917377613797284]
	TIME [epoch: 9.1 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03026634616380628		[learning rate: 0.00047439]
	Learning Rate: 0.000474388
	LOSS [training: 0.03026634616380628 | validation: 0.060529370101081545]
	TIME [epoch: 9.1 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03448349192453928		[learning rate: 0.00047293]
	Learning Rate: 0.000472933
	LOSS [training: 0.03448349192453928 | validation: 0.05681065642508806]
	TIME [epoch: 9.09 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0291085395820097		[learning rate: 0.00047148]
	Learning Rate: 0.000471484
	LOSS [training: 0.0291085395820097 | validation: 0.045265927173490345]
	TIME [epoch: 9.1 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031354826787712044		[learning rate: 0.00047004]
	Learning Rate: 0.000470038
	LOSS [training: 0.031354826787712044 | validation: 0.0425388288242419]
	TIME [epoch: 9.11 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03066398289543295		[learning rate: 0.0004686]
	Learning Rate: 0.000468597
	LOSS [training: 0.03066398289543295 | validation: 0.06341150364244001]
	TIME [epoch: 9.09 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04152455210467962		[learning rate: 0.00046716]
	Learning Rate: 0.000467161
	LOSS [training: 0.04152455210467962 | validation: 0.05270239797164045]
	TIME [epoch: 9.09 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02956375595716102		[learning rate: 0.00046573]
	Learning Rate: 0.000465729
	LOSS [training: 0.02956375595716102 | validation: 0.04163024562919479]
	TIME [epoch: 9.09 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028354839706963682		[learning rate: 0.0004643]
	Learning Rate: 0.000464301
	LOSS [training: 0.028354839706963682 | validation: 0.03949791987985257]
	TIME [epoch: 9.12 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02750742159763305		[learning rate: 0.00046288]
	Learning Rate: 0.000462878
	LOSS [training: 0.02750742159763305 | validation: 0.046817430307616634]
	TIME [epoch: 9.09 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026367770588462076		[learning rate: 0.00046146]
	Learning Rate: 0.000461459
	LOSS [training: 0.026367770588462076 | validation: 0.04157511808801184]
	TIME [epoch: 9.09 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02461779479761999		[learning rate: 0.00046004]
	Learning Rate: 0.000460045
	LOSS [training: 0.02461779479761999 | validation: 0.03848771830006584]
	TIME [epoch: 9.09 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03248947217655289		[learning rate: 0.00045863]
	Learning Rate: 0.000458634
	LOSS [training: 0.03248947217655289 | validation: 0.05912030179623956]
	TIME [epoch: 9.11 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04579471236275255		[learning rate: 0.00045723]
	Learning Rate: 0.000457229
	LOSS [training: 0.04579471236275255 | validation: 0.07985488548941475]
	TIME [epoch: 9.09 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03848384230924347		[learning rate: 0.00045583]
	Learning Rate: 0.000455827
	LOSS [training: 0.03848384230924347 | validation: 0.04623330838702625]
	TIME [epoch: 9.09 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025186327282897568		[learning rate: 0.00045443]
	Learning Rate: 0.00045443
	LOSS [training: 0.025186327282897568 | validation: 0.042266596074283826]
	TIME [epoch: 9.09 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03582160713642052		[learning rate: 0.00045304]
	Learning Rate: 0.000453037
	LOSS [training: 0.03582160713642052 | validation: 0.05180865271857895]
	TIME [epoch: 9.11 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031433720600779105		[learning rate: 0.00045165]
	Learning Rate: 0.000451648
	LOSS [training: 0.031433720600779105 | validation: 0.038110540058417325]
	TIME [epoch: 9.09 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029571549497694825		[learning rate: 0.00045026]
	Learning Rate: 0.000450263
	LOSS [training: 0.029571549497694825 | validation: 0.04787466706058984]
	TIME [epoch: 9.09 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033727761161530735		[learning rate: 0.00044888]
	Learning Rate: 0.000448883
	LOSS [training: 0.033727761161530735 | validation: 0.052232931450504165]
	TIME [epoch: 9.09 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031539104827657136		[learning rate: 0.00044751]
	Learning Rate: 0.000447507
	LOSS [training: 0.031539104827657136 | validation: 0.051937982289024874]
	TIME [epoch: 9.1 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030814467392829448		[learning rate: 0.00044614]
	Learning Rate: 0.000446135
	LOSS [training: 0.030814467392829448 | validation: 0.0825020670148022]
	TIME [epoch: 9.1 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051761200266400874		[learning rate: 0.00044477]
	Learning Rate: 0.000444768
	LOSS [training: 0.051761200266400874 | validation: 0.057003751552739415]
	TIME [epoch: 9.09 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031730137809404466		[learning rate: 0.0004434]
	Learning Rate: 0.000443404
	LOSS [training: 0.031730137809404466 | validation: 0.05025729700616831]
	TIME [epoch: 9.09 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025870036681563808		[learning rate: 0.00044205]
	Learning Rate: 0.000442045
	LOSS [training: 0.025870036681563808 | validation: 0.04476572369953653]
	TIME [epoch: 9.1 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029854332037854148		[learning rate: 0.00044069]
	Learning Rate: 0.00044069
	LOSS [training: 0.029854332037854148 | validation: 0.059446466911818825]
	TIME [epoch: 9.11 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05245026026808277		[learning rate: 0.00043934]
	Learning Rate: 0.000439339
	LOSS [training: 0.05245026026808277 | validation: 0.05902388774197603]
	TIME [epoch: 9.09 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03592870083206777		[learning rate: 0.00043799]
	Learning Rate: 0.000437992
	LOSS [training: 0.03592870083206777 | validation: 0.0597046393665418]
	TIME [epoch: 9.09 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03620267627064059		[learning rate: 0.00043665]
	Learning Rate: 0.00043665
	LOSS [training: 0.03620267627064059 | validation: 0.05032617319014919]
	TIME [epoch: 9.09 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04042025049138819		[learning rate: 0.00043531]
	Learning Rate: 0.000435311
	LOSS [training: 0.04042025049138819 | validation: 0.056752866131121946]
	TIME [epoch: 9.11 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027385020376218826		[learning rate: 0.00043398]
	Learning Rate: 0.000433977
	LOSS [training: 0.027385020376218826 | validation: 0.048057641105750844]
	TIME [epoch: 9.09 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03113173529535206		[learning rate: 0.00043265]
	Learning Rate: 0.000432647
	LOSS [training: 0.03113173529535206 | validation: 0.04734544404453771]
	TIME [epoch: 9.09 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02541429105082584		[learning rate: 0.00043132]
	Learning Rate: 0.00043132
	LOSS [training: 0.02541429105082584 | validation: 0.03349494844774538]
	TIME [epoch: 9.08 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01984373109173418		[learning rate: 0.00043]
	Learning Rate: 0.000429998
	LOSS [training: 0.01984373109173418 | validation: 0.035699256553046906]
	TIME [epoch: 9.11 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03187715642506999		[learning rate: 0.00042868]
	Learning Rate: 0.00042868
	LOSS [training: 0.03187715642506999 | validation: 0.04634020473884351]
	TIME [epoch: 9.09 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027745927535765613		[learning rate: 0.00042737]
	Learning Rate: 0.000427366
	LOSS [training: 0.027745927535765613 | validation: 0.03477509934723581]
	TIME [epoch: 9.08 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01680553073541994		[learning rate: 0.00042606]
	Learning Rate: 0.000426056
	LOSS [training: 0.01680553073541994 | validation: 0.028660515579711644]
	TIME [epoch: 9.09 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016864361230073042		[learning rate: 0.00042475]
	Learning Rate: 0.00042475
	LOSS [training: 0.016864361230073042 | validation: 0.03413553584755276]
	TIME [epoch: 9.11 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022748295576312215		[learning rate: 0.00042345]
	Learning Rate: 0.000423448
	LOSS [training: 0.022748295576312215 | validation: 0.039042812789728515]
	TIME [epoch: 9.09 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016312371832210803		[learning rate: 0.00042215]
	Learning Rate: 0.00042215
	LOSS [training: 0.016312371832210803 | validation: 0.038603040790289186]
	TIME [epoch: 9.08 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017934503890601992		[learning rate: 0.00042086]
	Learning Rate: 0.000420856
	LOSS [training: 0.017934503890601992 | validation: 0.02947031325411098]
	TIME [epoch: 9.09 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01617501663125063		[learning rate: 0.00041957]
	Learning Rate: 0.000419566
	LOSS [training: 0.01617501663125063 | validation: 0.02345953733803092]
	TIME [epoch: 9.11 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022154829382293063		[learning rate: 0.00041828]
	Learning Rate: 0.00041828
	LOSS [training: 0.022154829382293063 | validation: 0.03988574556453504]
	TIME [epoch: 9.09 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024245167131675356		[learning rate: 0.000417]
	Learning Rate: 0.000416997
	LOSS [training: 0.024245167131675356 | validation: 0.031484410730019605]
	TIME [epoch: 9.09 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01897874362886966		[learning rate: 0.00041572]
	Learning Rate: 0.000415719
	LOSS [training: 0.01897874362886966 | validation: 0.02756665733878126]
	TIME [epoch: 9.09 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021579016831525837		[learning rate: 0.00041444]
	Learning Rate: 0.000414445
	LOSS [training: 0.021579016831525837 | validation: 0.02585448426666305]
	TIME [epoch: 9.1 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02046337717502681		[learning rate: 0.00041317]
	Learning Rate: 0.000413174
	LOSS [training: 0.02046337717502681 | validation: 0.037951611851484865]
	TIME [epoch: 9.09 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02185535840942558		[learning rate: 0.00041191]
	Learning Rate: 0.000411908
	LOSS [training: 0.02185535840942558 | validation: 0.02689957436891917]
	TIME [epoch: 9.08 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02174686566008533		[learning rate: 0.00041065]
	Learning Rate: 0.000410645
	LOSS [training: 0.02174686566008533 | validation: 0.029548693833566567]
	TIME [epoch: 9.08 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022687988794467023		[learning rate: 0.00040939]
	Learning Rate: 0.000409386
	LOSS [training: 0.022687988794467023 | validation: 0.04458417059841818]
	TIME [epoch: 9.1 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028041576986997174		[learning rate: 0.00040813]
	Learning Rate: 0.000408131
	LOSS [training: 0.028041576986997174 | validation: 0.061120990767019184]
	TIME [epoch: 9.11 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05551749772162266		[learning rate: 0.00040688]
	Learning Rate: 0.00040688
	LOSS [training: 0.05551749772162266 | validation: 0.07343677434313567]
	TIME [epoch: 9.09 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042346550285099725		[learning rate: 0.00040563]
	Learning Rate: 0.000405633
	LOSS [training: 0.042346550285099725 | validation: 0.062448166260723484]
	TIME [epoch: 9.1 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04156144327064497		[learning rate: 0.00040439]
	Learning Rate: 0.00040439
	LOSS [training: 0.04156144327064497 | validation: 0.07479591342985727]
	TIME [epoch: 9.1 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04339344252840853		[learning rate: 0.00040315]
	Learning Rate: 0.00040315
	LOSS [training: 0.04339344252840853 | validation: 0.055970662376530256]
	TIME [epoch: 9.1 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05043007262058756		[learning rate: 0.00040191]
	Learning Rate: 0.000401914
	LOSS [training: 0.05043007262058756 | validation: 0.13839742889283352]
	TIME [epoch: 9.08 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08450389320039839		[learning rate: 0.00040068]
	Learning Rate: 0.000400682
	LOSS [training: 0.08450389320039839 | validation: 0.09403672993631068]
	TIME [epoch: 9.08 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05832198409505894		[learning rate: 0.00039945]
	Learning Rate: 0.000399454
	LOSS [training: 0.05832198409505894 | validation: 0.09460746485338802]
	TIME [epoch: 9.09 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06839703786228989		[learning rate: 0.00039823]
	Learning Rate: 0.000398229
	LOSS [training: 0.06839703786228989 | validation: 0.11073812070266359]
	TIME [epoch: 9.11 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06777869091566882		[learning rate: 0.00039701]
	Learning Rate: 0.000397009
	LOSS [training: 0.06777869091566882 | validation: 0.07074221834820338]
	TIME [epoch: 9.09 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03970941388566624		[learning rate: 0.00039579]
	Learning Rate: 0.000395792
	LOSS [training: 0.03970941388566624 | validation: 0.05829724372695182]
	TIME [epoch: 9.09 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04422044358521303		[learning rate: 0.00039458]
	Learning Rate: 0.000394578
	LOSS [training: 0.04422044358521303 | validation: 0.07220382861778382]
	TIME [epoch: 9.08 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03960979234679426		[learning rate: 0.00039337]
	Learning Rate: 0.000393369
	LOSS [training: 0.03960979234679426 | validation: 0.050738055175629515]
	TIME [epoch: 9.11 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01840126850555816		[learning rate: 0.00039216]
	Learning Rate: 0.000392163
	LOSS [training: 0.01840126850555816 | validation: 0.030312873067427058]
	TIME [epoch: 9.09 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022535624638968667		[learning rate: 0.00039096]
	Learning Rate: 0.000390961
	LOSS [training: 0.022535624638968667 | validation: 0.03412992527741125]
	TIME [epoch: 9.09 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025853861500649		[learning rate: 0.00038976]
	Learning Rate: 0.000389762
	LOSS [training: 0.025853861500649 | validation: 0.03037684244001626]
	TIME [epoch: 9.11 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023148790776642558		[learning rate: 0.00038857]
	Learning Rate: 0.000388568
	LOSS [training: 0.023148790776642558 | validation: 0.035331778025415386]
	TIME [epoch: 9.11 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024134704518414922		[learning rate: 0.00038738]
	Learning Rate: 0.000387377
	LOSS [training: 0.024134704518414922 | validation: 0.03314115509073273]
	TIME [epoch: 9.09 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016424091506975855		[learning rate: 0.00038619]
	Learning Rate: 0.000386189
	LOSS [training: 0.016424091506975855 | validation: 0.034563443293624124]
	TIME [epoch: 9.08 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019562197640029595		[learning rate: 0.00038501]
	Learning Rate: 0.000385005
	LOSS [training: 0.019562197640029595 | validation: 0.026617171129906886]
	TIME [epoch: 9.09 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021748243214374754		[learning rate: 0.00038382]
	Learning Rate: 0.000383825
	LOSS [training: 0.021748243214374754 | validation: 0.032605309259101295]
	TIME [epoch: 9.11 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025855774902333865		[learning rate: 0.00038265]
	Learning Rate: 0.000382649
	LOSS [training: 0.025855774902333865 | validation: 0.03899849369367464]
	TIME [epoch: 9.09 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03373428462741714		[learning rate: 0.00038148]
	Learning Rate: 0.000381476
	LOSS [training: 0.03373428462741714 | validation: 0.038533764001303594]
	TIME [epoch: 9.09 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029318376594548962		[learning rate: 0.00038031]
	Learning Rate: 0.000380306
	LOSS [training: 0.029318376594548962 | validation: 0.04236828251420667]
	TIME [epoch: 9.08 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024464010630947695		[learning rate: 0.00037914]
	Learning Rate: 0.00037914
	LOSS [training: 0.024464010630947695 | validation: 0.03754085942632293]
	TIME [epoch: 9.1 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026173232237630732		[learning rate: 0.00037798]
	Learning Rate: 0.000377978
	LOSS [training: 0.026173232237630732 | validation: 0.039836020474383727]
	TIME [epoch: 9.09 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02574303505204988		[learning rate: 0.00037682]
	Learning Rate: 0.000376819
	LOSS [training: 0.02574303505204988 | validation: 0.029484461635210936]
	TIME [epoch: 9.09 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015352821234756031		[learning rate: 0.00037566]
	Learning Rate: 0.000375664
	LOSS [training: 0.015352821234756031 | validation: 0.03420402203143671]
	TIME [epoch: 9.09 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017602996455365567		[learning rate: 0.00037451]
	Learning Rate: 0.000374513
	LOSS [training: 0.017602996455365567 | validation: 0.03678036231178473]
	TIME [epoch: 9.1 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013213633535359526		[learning rate: 0.00037336]
	Learning Rate: 0.000373365
	LOSS [training: 0.013213633535359526 | validation: 0.026002797572957745]
	TIME [epoch: 9.1 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01785168498571778		[learning rate: 0.00037222]
	Learning Rate: 0.00037222
	LOSS [training: 0.01785168498571778 | validation: 0.0366925650450642]
	TIME [epoch: 9.1 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019140238346503937		[learning rate: 0.00037108]
	Learning Rate: 0.000371079
	LOSS [training: 0.019140238346503937 | validation: 0.03862436279774284]
	TIME [epoch: 9.09 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021738252628577842		[learning rate: 0.00036994]
	Learning Rate: 0.000369942
	LOSS [training: 0.021738252628577842 | validation: 0.026132412421528396]
	TIME [epoch: 9.09 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027231196137576446		[learning rate: 0.00036881]
	Learning Rate: 0.000368808
	LOSS [training: 0.027231196137576446 | validation: 0.03583707919933336]
	TIME [epoch: 9.11 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022396628236978015		[learning rate: 0.00036768]
	Learning Rate: 0.000367677
	LOSS [training: 0.022396628236978015 | validation: 0.035147785494895716]
	TIME [epoch: 9.09 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023755191118369223		[learning rate: 0.00036655]
	Learning Rate: 0.00036655
	LOSS [training: 0.023755191118369223 | validation: 0.037835254283412986]
	TIME [epoch: 9.09 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02522356111139461		[learning rate: 0.00036543]
	Learning Rate: 0.000365426
	LOSS [training: 0.02522356111139461 | validation: 0.03710672582836909]
	TIME [epoch: 9.09 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019059584681787214		[learning rate: 0.00036431]
	Learning Rate: 0.000364306
	LOSS [training: 0.019059584681787214 | validation: 0.031594971300632976]
	TIME [epoch: 9.11 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020864965143626745		[learning rate: 0.00036319]
	Learning Rate: 0.00036319
	LOSS [training: 0.020864965143626745 | validation: 0.04005638257569033]
	TIME [epoch: 9.09 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018160772996627876		[learning rate: 0.00036208]
	Learning Rate: 0.000362076
	LOSS [training: 0.018160772996627876 | validation: 0.023632688008504613]
	TIME [epoch: 9.08 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020961536081735965		[learning rate: 0.00036097]
	Learning Rate: 0.000360966
	LOSS [training: 0.020961536081735965 | validation: 0.02608502029882441]
	TIME [epoch: 9.09 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014310519488504116		[learning rate: 0.00035986]
	Learning Rate: 0.00035986
	LOSS [training: 0.014310519488504116 | validation: 0.025864575805118674]
	TIME [epoch: 9.11 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01725715012301693		[learning rate: 0.00035876]
	Learning Rate: 0.000358757
	LOSS [training: 0.01725715012301693 | validation: 0.025620669950337422]
	TIME [epoch: 9.09 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019760898253022047		[learning rate: 0.00035766]
	Learning Rate: 0.000357657
	LOSS [training: 0.019760898253022047 | validation: 0.03111857816340989]
	TIME [epoch: 9.08 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01196184063571656		[learning rate: 0.00035656]
	Learning Rate: 0.000356561
	LOSS [training: 0.01196184063571656 | validation: 0.018803241271444133]
	TIME [epoch: 9.09 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014470083883613575		[learning rate: 0.00035547]
	Learning Rate: 0.000355468
	LOSS [training: 0.014470083883613575 | validation: 0.032847100168874294]
	TIME [epoch: 9.11 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01337872900346793		[learning rate: 0.00035438]
	Learning Rate: 0.000354378
	LOSS [training: 0.01337872900346793 | validation: 0.02010044477285681]
	TIME [epoch: 9.1 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009094919637860929		[learning rate: 0.00035329]
	Learning Rate: 0.000353292
	LOSS [training: 0.009094919637860929 | validation: 0.015232976294124553]
	TIME [epoch: 9.09 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006973320921658216		[learning rate: 0.00035221]
	Learning Rate: 0.000352209
	LOSS [training: 0.006973320921658216 | validation: 0.030426077093809963]
	TIME [epoch: 9.09 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013801495508896405		[learning rate: 0.00035113]
	Learning Rate: 0.000351129
	LOSS [training: 0.013801495508896405 | validation: 0.03356459982167945]
	TIME [epoch: 9.1 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021749160128039215		[learning rate: 0.00035005]
	Learning Rate: 0.000350053
	LOSS [training: 0.021749160128039215 | validation: 0.03514121393584082]
	TIME [epoch: 9.09 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011758682120561808		[learning rate: 0.00034898]
	Learning Rate: 0.000348979
	LOSS [training: 0.011758682120561808 | validation: 0.012591064841964013]
	TIME [epoch: 9.08 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004997360899254075		[learning rate: 0.00034791]
	Learning Rate: 0.00034791
	LOSS [training: 0.004997360899254075 | validation: 0.01911600963324169]
	TIME [epoch: 9.09 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016532891155839936		[learning rate: 0.00034684]
	Learning Rate: 0.000346843
	LOSS [training: 0.016532891155839936 | validation: 0.054854985480120244]
	TIME [epoch: 9.1 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03741448524091205		[learning rate: 0.00034578]
	Learning Rate: 0.00034578
	LOSS [training: 0.03741448524091205 | validation: 0.0442982484568326]
	TIME [epoch: 9.11 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023740804931295243		[learning rate: 0.00034472]
	Learning Rate: 0.00034472
	LOSS [training: 0.023740804931295243 | validation: 0.02039730276733826]
	TIME [epoch: 9.09 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011830675300819856		[learning rate: 0.00034366]
	Learning Rate: 0.000343663
	LOSS [training: 0.011830675300819856 | validation: 0.02492466738401322]
	TIME [epoch: 9.09 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017715164958345474		[learning rate: 0.00034261]
	Learning Rate: 0.00034261
	LOSS [training: 0.017715164958345474 | validation: 0.02249599022323177]
	TIME [epoch: 9.1 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008216597234993723		[learning rate: 0.00034156]
	Learning Rate: 0.00034156
	LOSS [training: 0.008216597234993723 | validation: 0.010594380453761673]
	TIME [epoch: 9.1 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004143005703302677		[learning rate: 0.00034051]
	Learning Rate: 0.000340513
	LOSS [training: 0.004143005703302677 | validation: 0.019093205554009327]
	TIME [epoch: 9.09 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008153792922961476		[learning rate: 0.00033947]
	Learning Rate: 0.000339469
	LOSS [training: 0.008153792922961476 | validation: 0.019931168910259926]
	TIME [epoch: 9.09 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00896287150217016		[learning rate: 0.00033843]
	Learning Rate: 0.000338428
	LOSS [training: 0.00896287150217016 | validation: 0.013973900458282316]
	TIME [epoch: 9.08 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006103365272788403		[learning rate: 0.00033739]
	Learning Rate: 0.000337391
	LOSS [training: 0.006103365272788403 | validation: 0.01104868059345794]
	TIME [epoch: 9.11 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009115410516891248		[learning rate: 0.00033636]
	Learning Rate: 0.000336357
	LOSS [training: 0.009115410516891248 | validation: 0.008607331162045363]
	TIME [epoch: 9.09 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008229793790409437		[learning rate: 0.00033533]
	Learning Rate: 0.000335326
	LOSS [training: 0.008229793790409437 | validation: 0.022111937638846557]
	TIME [epoch: 9.08 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009795468328769118		[learning rate: 0.0003343]
	Learning Rate: 0.000334298
	LOSS [training: 0.009795468328769118 | validation: 0.022590716984387]
	TIME [epoch: 9.09 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017104858782980483		[learning rate: 0.00033327]
	Learning Rate: 0.000333273
	LOSS [training: 0.017104858782980483 | validation: 0.03330039861596415]
	TIME [epoch: 9.11 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021932735795143064		[learning rate: 0.00033225]
	Learning Rate: 0.000332251
	LOSS [training: 0.021932735795143064 | validation: 0.03810362190630936]
	TIME [epoch: 9.09 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02142786224566715		[learning rate: 0.00033123]
	Learning Rate: 0.000331233
	LOSS [training: 0.02142786224566715 | validation: 0.02330295265314811]
	TIME [epoch: 9.09 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014547502171102239		[learning rate: 0.00033022]
	Learning Rate: 0.000330217
	LOSS [training: 0.014547502171102239 | validation: 0.02171351554800551]
	TIME [epoch: 9.08 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011480797060195145		[learning rate: 0.00032921]
	Learning Rate: 0.000329205
	LOSS [training: 0.011480797060195145 | validation: 0.019683805959976788]
	TIME [epoch: 9.11 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011148628645379572		[learning rate: 0.0003282]
	Learning Rate: 0.000328196
	LOSS [training: 0.011148628645379572 | validation: 0.014816779205334925]
	TIME [epoch: 9.09 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010204304308566618		[learning rate: 0.00032719]
	Learning Rate: 0.00032719
	LOSS [training: 0.010204304308566618 | validation: 0.022846339099987657]
	TIME [epoch: 9.09 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015010653720683203		[learning rate: 0.00032619]
	Learning Rate: 0.000326187
	LOSS [training: 0.015010653720683203 | validation: 0.024033178734798145]
	TIME [epoch: 9.09 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012240141523776048		[learning rate: 0.00032519]
	Learning Rate: 0.000325187
	LOSS [training: 0.012240141523776048 | validation: 0.025231637579562722]
	TIME [epoch: 9.11 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013159557209399667		[learning rate: 0.00032419]
	Learning Rate: 0.00032419
	LOSS [training: 0.013159557209399667 | validation: 0.026632742089005415]
	TIME [epoch: 9.09 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01835323114049054		[learning rate: 0.0003232]
	Learning Rate: 0.000323196
	LOSS [training: 0.01835323114049054 | validation: 0.038948914470045316]
	TIME [epoch: 9.08 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024107731500994208		[learning rate: 0.00032221]
	Learning Rate: 0.000322206
	LOSS [training: 0.024107731500994208 | validation: 0.025489619160058735]
	TIME [epoch: 9.09 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016180029668468758		[learning rate: 0.00032122]
	Learning Rate: 0.000321218
	LOSS [training: 0.016180029668468758 | validation: 0.019936820275832677]
	TIME [epoch: 9.1 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009789874319099742		[learning rate: 0.00032023]
	Learning Rate: 0.000320233
	LOSS [training: 0.009789874319099742 | validation: 0.022584962571656403]
	TIME [epoch: 9.1 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008786176464064502		[learning rate: 0.00031925]
	Learning Rate: 0.000319252
	LOSS [training: 0.008786176464064502 | validation: 0.015811274612367792]
	TIME [epoch: 9.08 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008347721636990399		[learning rate: 0.00031827]
	Learning Rate: 0.000318273
	LOSS [training: 0.008347721636990399 | validation: 0.01580720622699593]
	TIME [epoch: 9.08 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01554535406929888		[learning rate: 0.0003173]
	Learning Rate: 0.000317297
	LOSS [training: 0.01554535406929888 | validation: 0.03061302031188331]
	TIME [epoch: 9.09 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014186815755489699		[learning rate: 0.00031632]
	Learning Rate: 0.000316325
	LOSS [training: 0.014186815755489699 | validation: 0.015657886287151056]
	TIME [epoch: 9.1 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01439111204479509		[learning rate: 0.00031536]
	Learning Rate: 0.000315355
	LOSS [training: 0.01439111204479509 | validation: 0.023573289102090975]
	TIME [epoch: 9.08 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017985218156966173		[learning rate: 0.00031439]
	Learning Rate: 0.000314389
	LOSS [training: 0.017985218156966173 | validation: 0.02872138211324455]
	TIME [epoch: 9.09 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023361598637080327		[learning rate: 0.00031342]
	Learning Rate: 0.000313425
	LOSS [training: 0.023361598637080327 | validation: 0.03129065506687197]
	TIME [epoch: 9.1 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019943599190405045		[learning rate: 0.00031246]
	Learning Rate: 0.000312464
	LOSS [training: 0.019943599190405045 | validation: 0.020751694874915953]
	TIME [epoch: 9.11 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023266436443772326		[learning rate: 0.00031151]
	Learning Rate: 0.000311506
	LOSS [training: 0.023266436443772326 | validation: 0.024770396136114793]
	TIME [epoch: 9.09 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010735843041021001		[learning rate: 0.00031055]
	Learning Rate: 0.000310551
	LOSS [training: 0.010735843041021001 | validation: 0.03153291357276719]
	TIME [epoch: 9.08 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01627188166513214		[learning rate: 0.0003096]
	Learning Rate: 0.000309599
	LOSS [training: 0.01627188166513214 | validation: 0.023808442267651202]
	TIME [epoch: 9.09 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011048048166796635		[learning rate: 0.00030865]
	Learning Rate: 0.00030865
	LOSS [training: 0.011048048166796635 | validation: 0.024702011005638028]
	TIME [epoch: 9.12 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012235508445445124		[learning rate: 0.0003077]
	Learning Rate: 0.000307704
	LOSS [training: 0.012235508445445124 | validation: 0.0184589122310117]
	TIME [epoch: 9.09 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01466074351635292		[learning rate: 0.00030676]
	Learning Rate: 0.000306761
	LOSS [training: 0.01466074351635292 | validation: 0.033809228440734806]
	TIME [epoch: 9.09 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01718117331237508		[learning rate: 0.00030582]
	Learning Rate: 0.00030582
	LOSS [training: 0.01718117331237508 | validation: 0.03241605140078185]
	TIME [epoch: 9.09 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03219909359604356		[learning rate: 0.00030488]
	Learning Rate: 0.000304883
	LOSS [training: 0.03219909359604356 | validation: 0.047846082979661614]
	TIME [epoch: 9.12 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03883770908072388		[learning rate: 0.00030395]
	Learning Rate: 0.000303948
	LOSS [training: 0.03883770908072388 | validation: 0.04843142650736454]
	TIME [epoch: 9.09 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025172449402986068		[learning rate: 0.00030302]
	Learning Rate: 0.000303017
	LOSS [training: 0.025172449402986068 | validation: 0.0328448800810149]
	TIME [epoch: 9.09 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02938688978901762		[learning rate: 0.00030209]
	Learning Rate: 0.000302088
	LOSS [training: 0.02938688978901762 | validation: 0.04461197310432152]
	TIME [epoch: 9.09 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0249442068892697		[learning rate: 0.00030116]
	Learning Rate: 0.000301162
	LOSS [training: 0.0249442068892697 | validation: 0.03121525004829873]
	TIME [epoch: 9.11 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02128995301903349		[learning rate: 0.00030024]
	Learning Rate: 0.000300239
	LOSS [training: 0.02128995301903349 | validation: 0.04427794480536978]
	TIME [epoch: 9.09 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04411837078221183		[learning rate: 0.00029932]
	Learning Rate: 0.000299318
	LOSS [training: 0.04411837078221183 | validation: 0.06616581018069218]
	TIME [epoch: 9.09 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04281959808706359		[learning rate: 0.0002984]
	Learning Rate: 0.000298401
	LOSS [training: 0.04281959808706359 | validation: 0.044819225426171685]
	TIME [epoch: 9.08 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03893942939631397		[learning rate: 0.00029749]
	Learning Rate: 0.000297486
	LOSS [training: 0.03893942939631397 | validation: 0.04893206498407021]
	TIME [epoch: 9.11 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029304026045885983		[learning rate: 0.00029657]
	Learning Rate: 0.000296574
	LOSS [training: 0.029304026045885983 | validation: 0.045164016702484246]
	TIME [epoch: 9.09 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033687910635045185		[learning rate: 0.00029567]
	Learning Rate: 0.000295665
	LOSS [training: 0.033687910635045185 | validation: 0.05842363279595432]
	TIME [epoch: 9.08 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057886415864616715		[learning rate: 0.00029476]
	Learning Rate: 0.000294759
	LOSS [training: 0.057886415864616715 | validation: 0.08621418645263984]
	TIME [epoch: 9.09 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06927761010404633		[learning rate: 0.00029386]
	Learning Rate: 0.000293855
	LOSS [training: 0.06927761010404633 | validation: 0.07592930477402549]
	TIME [epoch: 9.1 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040143150652336576		[learning rate: 0.00029295]
	Learning Rate: 0.000292954
	LOSS [training: 0.040143150652336576 | validation: 0.04889515397638096]
	TIME [epoch: 9.1 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03229383373789839		[learning rate: 0.00029206]
	Learning Rate: 0.000292056
	LOSS [training: 0.03229383373789839 | validation: 0.044082766089177744]
	TIME [epoch: 9.08 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021104077686435078		[learning rate: 0.00029116]
	Learning Rate: 0.000291161
	LOSS [training: 0.021104077686435078 | validation: 0.03036093723529068]
	TIME [epoch: 9.09 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018275152617329104		[learning rate: 0.00029027]
	Learning Rate: 0.000290269
	LOSS [training: 0.018275152617329104 | validation: 0.03105958992786453]
	TIME [epoch: 9.08 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017957708565735978		[learning rate: 0.00028938]
	Learning Rate: 0.000289379
	LOSS [training: 0.017957708565735978 | validation: 0.03001120438896284]
	TIME [epoch: 9.11 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017227610089244207		[learning rate: 0.00028849]
	Learning Rate: 0.000288492
	LOSS [training: 0.017227610089244207 | validation: 0.028834351831927812]
	TIME [epoch: 9.09 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02501078533306157		[learning rate: 0.00028761]
	Learning Rate: 0.000287607
	LOSS [training: 0.02501078533306157 | validation: 0.03746257942815878]
	TIME [epoch: 9.08 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02436825493185861		[learning rate: 0.00028673]
	Learning Rate: 0.000286726
	LOSS [training: 0.02436825493185861 | validation: 0.03246355585378566]
	TIME [epoch: 9.09 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02294228579267431		[learning rate: 0.00028585]
	Learning Rate: 0.000285847
	LOSS [training: 0.02294228579267431 | validation: 0.030247983458993762]
	TIME [epoch: 9.11 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020835388619020068		[learning rate: 0.00028497]
	Learning Rate: 0.000284971
	LOSS [training: 0.020835388619020068 | validation: 0.02527843031963656]
	TIME [epoch: 9.09 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017473177324843932		[learning rate: 0.0002841]
	Learning Rate: 0.000284097
	LOSS [training: 0.017473177324843932 | validation: 0.02781337330636881]
	TIME [epoch: 9.08 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01769270859390453		[learning rate: 0.00028323]
	Learning Rate: 0.000283226
	LOSS [training: 0.01769270859390453 | validation: 0.024194294280124186]
	TIME [epoch: 9.09 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019372993251009375		[learning rate: 0.00028236]
	Learning Rate: 0.000282358
	LOSS [training: 0.019372993251009375 | validation: 0.03525066597970215]
	TIME [epoch: 9.11 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017698008953069538		[learning rate: 0.00028149]
	Learning Rate: 0.000281492
	LOSS [training: 0.017698008953069538 | validation: 0.016657179545874253]
	TIME [epoch: 9.09 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017312836540907907		[learning rate: 0.00028063]
	Learning Rate: 0.000280629
	LOSS [training: 0.017312836540907907 | validation: 0.022065330533225503]
	TIME [epoch: 9.08 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017472823631895805		[learning rate: 0.00027977]
	Learning Rate: 0.000279769
	LOSS [training: 0.017472823631895805 | validation: 0.033624324015565255]
	TIME [epoch: 9.09 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019373974012929958		[learning rate: 0.00027891]
	Learning Rate: 0.000278912
	LOSS [training: 0.019373974012929958 | validation: 0.025583511026988977]
	TIME [epoch: 9.12 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022925691245384065		[learning rate: 0.00027806]
	Learning Rate: 0.000278057
	LOSS [training: 0.022925691245384065 | validation: 0.029436638962037937]
	TIME [epoch: 9.09 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015673906121079616		[learning rate: 0.0002772]
	Learning Rate: 0.000277204
	LOSS [training: 0.015673906121079616 | validation: 0.02057000535754898]
	TIME [epoch: 9.1 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02179963054640784		[learning rate: 0.00027635]
	Learning Rate: 0.000276355
	LOSS [training: 0.02179963054640784 | validation: 0.025916942583685054]
	TIME [epoch: 9.09 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01620570942589159		[learning rate: 0.00027551]
	Learning Rate: 0.000275507
	LOSS [training: 0.01620570942589159 | validation: 0.023658962272098107]
	TIME [epoch: 9.11 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020292286726686173		[learning rate: 0.00027466]
	Learning Rate: 0.000274663
	LOSS [training: 0.020292286726686173 | validation: 0.03211798697578498]
	TIME [epoch: 9.1 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019413151508599315		[learning rate: 0.00027382]
	Learning Rate: 0.000273821
	LOSS [training: 0.019413151508599315 | validation: 0.02886948865825848]
	TIME [epoch: 9.1 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02592982471039424		[learning rate: 0.00027298]
	Learning Rate: 0.000272982
	LOSS [training: 0.02592982471039424 | validation: 0.0242036284296121]
	TIME [epoch: 9.1 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020427832783605368		[learning rate: 0.00027214]
	Learning Rate: 0.000272145
	LOSS [training: 0.020427832783605368 | validation: 0.030628234151554842]
	TIME [epoch: 9.11 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021589823985446073		[learning rate: 0.00027131]
	Learning Rate: 0.000271311
	LOSS [training: 0.021589823985446073 | validation: 0.031240391829614828]
	TIME [epoch: 9.1 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02116291823275081		[learning rate: 0.00027048]
	Learning Rate: 0.000270479
	LOSS [training: 0.02116291823275081 | validation: 0.03350310563751559]
	TIME [epoch: 9.08 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024507462392023678		[learning rate: 0.00026965]
	Learning Rate: 0.00026965
	LOSS [training: 0.024507462392023678 | validation: 0.040841563233305345]
	TIME [epoch: 9.09 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01842035790691247		[learning rate: 0.00026882]
	Learning Rate: 0.000268823
	LOSS [training: 0.01842035790691247 | validation: 0.03687429871082192]
	TIME [epoch: 9.1 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02013688106636434		[learning rate: 0.000268]
	Learning Rate: 0.000267999
	LOSS [training: 0.02013688106636434 | validation: 0.025846300121366947]
	TIME [epoch: 9.1 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013429439280166548		[learning rate: 0.00026718]
	Learning Rate: 0.000267178
	LOSS [training: 0.013429439280166548 | validation: 0.029176985177446414]
	TIME [epoch: 9.09 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02194184576223625		[learning rate: 0.00026636]
	Learning Rate: 0.000266359
	LOSS [training: 0.02194184576223625 | validation: 0.04869899076658111]
	TIME [epoch: 9.09 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027635076020944227		[learning rate: 0.00026554]
	Learning Rate: 0.000265542
	LOSS [training: 0.027635076020944227 | validation: 0.04366616122136642]
	TIME [epoch: 9.1 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02514720247968516		[learning rate: 0.00026473]
	Learning Rate: 0.000264728
	LOSS [training: 0.02514720247968516 | validation: 0.05779610988099459]
	TIME [epoch: 9.1 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02892617097434095		[learning rate: 0.00026392]
	Learning Rate: 0.000263917
	LOSS [training: 0.02892617097434095 | validation: 0.04814851948384616]
	TIME [epoch: 9.09 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04278345952703133		[learning rate: 0.00026311]
	Learning Rate: 0.000263108
	LOSS [training: 0.04278345952703133 | validation: 0.07259708176533763]
	TIME [epoch: 9.09 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043412775505359186		[learning rate: 0.0002623]
	Learning Rate: 0.000262301
	LOSS [training: 0.043412775505359186 | validation: 0.05220185927662466]
	TIME [epoch: 9.09 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029668543799105197		[learning rate: 0.0002615]
	Learning Rate: 0.000261497
	LOSS [training: 0.029668543799105197 | validation: 0.04116063538088941]
	TIME [epoch: 9.12 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020146780001527916		[learning rate: 0.0002607]
	Learning Rate: 0.000260695
	LOSS [training: 0.020146780001527916 | validation: 0.03457575286049952]
	TIME [epoch: 9.08 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023145210367208763		[learning rate: 0.0002599]
	Learning Rate: 0.000259896
	LOSS [training: 0.023145210367208763 | validation: 0.036300197556465956]
	TIME [epoch: 9.09 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023644695617236054		[learning rate: 0.0002591]
	Learning Rate: 0.0002591
	LOSS [training: 0.023644695617236054 | validation: 0.04047614550993534]
	TIME [epoch: 9.08 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023035102669631723		[learning rate: 0.00025831]
	Learning Rate: 0.000258305
	LOSS [training: 0.023035102669631723 | validation: 0.037793596485964406]
	TIME [epoch: 9.11 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018611096160958126		[learning rate: 0.00025751]
	Learning Rate: 0.000257513
	LOSS [training: 0.018611096160958126 | validation: 0.029521976956718043]
	TIME [epoch: 9.09 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019197763507804284		[learning rate: 0.00025672]
	Learning Rate: 0.000256724
	LOSS [training: 0.019197763507804284 | validation: 0.024386308786547375]
	TIME [epoch: 9.09 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02183397665888408		[learning rate: 0.00025594]
	Learning Rate: 0.000255937
	LOSS [training: 0.02183397665888408 | validation: 0.03267387661351788]
	TIME [epoch: 9.09 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019837807095011848		[learning rate: 0.00025515]
	Learning Rate: 0.000255153
	LOSS [training: 0.019837807095011848 | validation: 0.025425398731238696]
	TIME [epoch: 9.1 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01995800926399357		[learning rate: 0.00025437]
	Learning Rate: 0.00025437
	LOSS [training: 0.01995800926399357 | validation: 0.025692927390586047]
	TIME [epoch: 9.09 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012332892390761923		[learning rate: 0.00025359]
	Learning Rate: 0.000253591
	LOSS [training: 0.012332892390761923 | validation: 0.023777100008835407]
	TIME [epoch: 9.08 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01924599731581057		[learning rate: 0.00025281]
	Learning Rate: 0.000252813
	LOSS [training: 0.01924599731581057 | validation: 0.033217999696752196]
	TIME [epoch: 9.09 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02041058648833547		[learning rate: 0.00025204]
	Learning Rate: 0.000252038
	LOSS [training: 0.02041058648833547 | validation: 0.037301305760260986]
	TIME [epoch: 9.1 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021270590496013424		[learning rate: 0.00025127]
	Learning Rate: 0.000251266
	LOSS [training: 0.021270590496013424 | validation: 0.036085139983636674]
	TIME [epoch: 9.1 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012584765526109718		[learning rate: 0.0002505]
	Learning Rate: 0.000250496
	LOSS [training: 0.012584765526109718 | validation: 0.02579765419702544]
	TIME [epoch: 9.08 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021263524861970855		[learning rate: 0.00024973]
	Learning Rate: 0.000249728
	LOSS [training: 0.021263524861970855 | validation: 0.02257779344537668]
	TIME [epoch: 9.09 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017976404395893788		[learning rate: 0.00024896]
	Learning Rate: 0.000248962
	LOSS [training: 0.017976404395893788 | validation: 0.030943371050487247]
	TIME [epoch: 9.1 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014333166393582305		[learning rate: 0.0002482]
	Learning Rate: 0.000248199
	LOSS [training: 0.014333166393582305 | validation: 0.03306189373795422]
	TIME [epoch: 9.1 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016684446111848807		[learning rate: 0.00024744]
	Learning Rate: 0.000247438
	LOSS [training: 0.016684446111848807 | validation: 0.024940295074704036]
	TIME [epoch: 9.08 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009623435267815365		[learning rate: 0.00024668]
	Learning Rate: 0.00024668
	LOSS [training: 0.009623435267815365 | validation: 0.01966517732763313]
	TIME [epoch: 9.09 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015138671414621867		[learning rate: 0.00024592]
	Learning Rate: 0.000245923
	LOSS [training: 0.015138671414621867 | validation: 0.024259873497300608]
	TIME [epoch: 9.1 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016167882469896987		[learning rate: 0.00024517]
	Learning Rate: 0.00024517
	LOSS [training: 0.016167882469896987 | validation: 0.023082496861799986]
	TIME [epoch: 9.1 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01258344125860696		[learning rate: 0.00024442]
	Learning Rate: 0.000244418
	LOSS [training: 0.01258344125860696 | validation: 0.02869033705972976]
	TIME [epoch: 9.09 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011514076425003628		[learning rate: 0.00024367]
	Learning Rate: 0.000243669
	LOSS [training: 0.011514076425003628 | validation: 0.029043329816915507]
	TIME [epoch: 9.08 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012195351904654358		[learning rate: 0.00024292]
	Learning Rate: 0.000242922
	LOSS [training: 0.012195351904654358 | validation: 0.02064638393119117]
	TIME [epoch: 9.08 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021414664092449992		[learning rate: 0.00024218]
	Learning Rate: 0.000242177
	LOSS [training: 0.021414664092449992 | validation: 0.036462969407558984]
	TIME [epoch: 9.1 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020518890037035737		[learning rate: 0.00024143]
	Learning Rate: 0.000241435
	LOSS [training: 0.020518890037035737 | validation: 0.037208326547477875]
	TIME [epoch: 9.09 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016749014322466664		[learning rate: 0.00024069]
	Learning Rate: 0.000240695
	LOSS [training: 0.016749014322466664 | validation: 0.03128575726000375]
	TIME [epoch: 9.09 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017964884842649236		[learning rate: 0.00023996]
	Learning Rate: 0.000239957
	LOSS [training: 0.017964884842649236 | validation: 0.017289692225984088]
	TIME [epoch: 9.09 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009063908673544094		[learning rate: 0.00023922]
	Learning Rate: 0.000239221
	LOSS [training: 0.009063908673544094 | validation: 0.020666636663473376]
	TIME [epoch: 9.11 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014251088364614884		[learning rate: 0.00023849]
	Learning Rate: 0.000238488
	LOSS [training: 0.014251088364614884 | validation: 0.02914280087123406]
	TIME [epoch: 9.1 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010677755434065902		[learning rate: 0.00023776]
	Learning Rate: 0.000237757
	LOSS [training: 0.010677755434065902 | validation: 0.027427840166683627]
	TIME [epoch: 9.09 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01229267248454768		[learning rate: 0.00023703]
	Learning Rate: 0.000237028
	LOSS [training: 0.01229267248454768 | validation: 0.023373255967111997]
	TIME [epoch: 9.09 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010985387094915911		[learning rate: 0.0002363]
	Learning Rate: 0.000236302
	LOSS [training: 0.010985387094915911 | validation: 0.022872520558798643]
	TIME [epoch: 9.12 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011017610235111044		[learning rate: 0.00023558]
	Learning Rate: 0.000235577
	LOSS [training: 0.011017610235111044 | validation: 0.03144344051330217]
	TIME [epoch: 9.09 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010172948455647023		[learning rate: 0.00023486]
	Learning Rate: 0.000234855
	LOSS [training: 0.010172948455647023 | validation: 0.02850184163455539]
	TIME [epoch: 9.1 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01999833035963961		[learning rate: 0.00023414]
	Learning Rate: 0.000234135
	LOSS [training: 0.01999833035963961 | validation: 0.03459822597408986]
	TIME [epoch: 9.09 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021049346914134452		[learning rate: 0.00023342]
	Learning Rate: 0.000233417
	LOSS [training: 0.021049346914134452 | validation: 0.02788712321915359]
	TIME [epoch: 9.11 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01726455578195071		[learning rate: 0.0002327]
	Learning Rate: 0.000232702
	LOSS [training: 0.01726455578195071 | validation: 0.02161399877752921]
	TIME [epoch: 9.09 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014880490471714589		[learning rate: 0.00023199]
	Learning Rate: 0.000231989
	LOSS [training: 0.014880490471714589 | validation: 0.02616662148696297]
	TIME [epoch: 9.08 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013487447280380227		[learning rate: 0.00023128]
	Learning Rate: 0.000231277
	LOSS [training: 0.013487447280380227 | validation: 0.03063022080390767]
	TIME [epoch: 9.09 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01628948442328445		[learning rate: 0.00023057]
	Learning Rate: 0.000230569
	LOSS [training: 0.01628948442328445 | validation: 0.033273749124397844]
	TIME [epoch: 9.1 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01850491903079788		[learning rate: 0.00022986]
	Learning Rate: 0.000229862
	LOSS [training: 0.01850491903079788 | validation: 0.02844637688553719]
	TIME [epoch: 9.11 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01980864057091431		[learning rate: 0.00022916]
	Learning Rate: 0.000229157
	LOSS [training: 0.01980864057091431 | validation: 0.026814577980106134]
	TIME [epoch: 9.09 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026107135847706697		[learning rate: 0.00022845]
	Learning Rate: 0.000228455
	LOSS [training: 0.026107135847706697 | validation: 0.029702048075339334]
	TIME [epoch: 9.08 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023760250842224273		[learning rate: 0.00022775]
	Learning Rate: 0.000227754
	LOSS [training: 0.023760250842224273 | validation: 0.02963814785185312]
	TIME [epoch: 9.1 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02072734177419379		[learning rate: 0.00022706]
	Learning Rate: 0.000227056
	LOSS [training: 0.02072734177419379 | validation: 0.027958140313425542]
	TIME [epoch: 9.1 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016363453222127032		[learning rate: 0.00022636]
	Learning Rate: 0.00022636
	LOSS [training: 0.016363453222127032 | validation: 0.028922373430005328]
	TIME [epoch: 9.09 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015202192794146563		[learning rate: 0.00022567]
	Learning Rate: 0.000225666
	LOSS [training: 0.015202192794146563 | validation: 0.031082510207160324]
	TIME [epoch: 9.09 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01890878080704011		[learning rate: 0.00022497]
	Learning Rate: 0.000224974
	LOSS [training: 0.01890878080704011 | validation: 0.03333504606461339]
	TIME [epoch: 9.1 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013837887101860352		[learning rate: 0.00022428]
	Learning Rate: 0.000224285
	LOSS [training: 0.013837887101860352 | validation: 0.027049224862843575]
	TIME [epoch: 9.11 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014761517651041747		[learning rate: 0.0002236]
	Learning Rate: 0.000223597
	LOSS [training: 0.014761517651041747 | validation: 0.02996736658408089]
	TIME [epoch: 9.09 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022130253004221827		[learning rate: 0.00022291]
	Learning Rate: 0.000222912
	LOSS [training: 0.022130253004221827 | validation: 0.030851751168754132]
	TIME [epoch: 9.09 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022537164932977704		[learning rate: 0.00022223]
	Learning Rate: 0.000222229
	LOSS [training: 0.022537164932977704 | validation: 0.05365260525365435]
	TIME [epoch: 9.09 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042021923848154875		[learning rate: 0.00022155]
	Learning Rate: 0.000221547
	LOSS [training: 0.042021923848154875 | validation: 0.04028275310020192]
	TIME [epoch: 9.11 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025447778091891055		[learning rate: 0.00022087]
	Learning Rate: 0.000220868
	LOSS [training: 0.025447778091891055 | validation: 0.0237325449579888]
	TIME [epoch: 9.09 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016991862720639246		[learning rate: 0.00022019]
	Learning Rate: 0.000220191
	LOSS [training: 0.016991862720639246 | validation: 0.027898338408376157]
	TIME [epoch: 9.09 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01778571339136719		[learning rate: 0.00021952]
	Learning Rate: 0.000219516
	LOSS [training: 0.01778571339136719 | validation: 0.024687795500229575]
	TIME [epoch: 9.08 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012030345789294067		[learning rate: 0.00021884]
	Learning Rate: 0.000218843
	LOSS [training: 0.012030345789294067 | validation: 0.0264938551853285]
	TIME [epoch: 9.12 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012701267782221406		[learning rate: 0.00021817]
	Learning Rate: 0.000218172
	LOSS [training: 0.012701267782221406 | validation: 0.038839545619995544]
	TIME [epoch: 9.1 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014241207522498318		[learning rate: 0.0002175]
	Learning Rate: 0.000217504
	LOSS [training: 0.014241207522498318 | validation: 0.021029501371493925]
	TIME [epoch: 9.09 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012415911877792864		[learning rate: 0.00021684]
	Learning Rate: 0.000216837
	LOSS [training: 0.012415911877792864 | validation: 0.02925844149874493]
	TIME [epoch: 9.1 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012918237904531522		[learning rate: 0.00021617]
	Learning Rate: 0.000216172
	LOSS [training: 0.012918237904531522 | validation: 0.026753669783292883]
	TIME [epoch: 9.13 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015468621993823786		[learning rate: 0.00021551]
	Learning Rate: 0.00021551
	LOSS [training: 0.015468621993823786 | validation: 0.016623297504677736]
	TIME [epoch: 9.1 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009050172490060179		[learning rate: 0.00021485]
	Learning Rate: 0.000214849
	LOSS [training: 0.009050172490060179 | validation: 0.02270190438407533]
	TIME [epoch: 9.08 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012017446738429725		[learning rate: 0.00021419]
	Learning Rate: 0.00021419
	LOSS [training: 0.012017446738429725 | validation: 0.023303688669474347]
	TIME [epoch: 9.08 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015779785755091053		[learning rate: 0.00021353]
	Learning Rate: 0.000213534
	LOSS [training: 0.015779785755091053 | validation: 0.018638817836156216]
	TIME [epoch: 9.11 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017308890147594885		[learning rate: 0.00021288]
	Learning Rate: 0.000212879
	LOSS [training: 0.017308890147594885 | validation: 0.030725847961920256]
	TIME [epoch: 9.09 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01083189278848368		[learning rate: 0.00021223]
	Learning Rate: 0.000212227
	LOSS [training: 0.01083189278848368 | validation: 0.017315610917077895]
	TIME [epoch: 9.08 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01686761931203474		[learning rate: 0.00021158]
	Learning Rate: 0.000211576
	LOSS [training: 0.01686761931203474 | validation: 0.03328870140222191]
	TIME [epoch: 9.07 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01639233117275811		[learning rate: 0.00021093]
	Learning Rate: 0.000210928
	LOSS [training: 0.01639233117275811 | validation: 0.021392236311319337]
	TIME [epoch: 9.09 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019278451509460292		[learning rate: 0.00021028]
	Learning Rate: 0.000210281
	LOSS [training: 0.019278451509460292 | validation: 0.04200545550200351]
	TIME [epoch: 9.1 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029306319843543		[learning rate: 0.00020964]
	Learning Rate: 0.000209636
	LOSS [training: 0.029306319843543 | validation: 0.024635857613193375]
	TIME [epoch: 9.1 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015569214500488685		[learning rate: 0.00020899]
	Learning Rate: 0.000208994
	LOSS [training: 0.015569214500488685 | validation: 0.025833871945514307]
	TIME [epoch: 9.09 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015039698068377919		[learning rate: 0.00020835]
	Learning Rate: 0.000208353
	LOSS [training: 0.015039698068377919 | validation: 0.028486266115356658]
	TIME [epoch: 9.11 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013279003109710063		[learning rate: 0.00020771]
	Learning Rate: 0.000207714
	LOSS [training: 0.013279003109710063 | validation: 0.03170448160949657]
	TIME [epoch: 9.09 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015434738874440527		[learning rate: 0.00020708]
	Learning Rate: 0.000207078
	LOSS [training: 0.015434738874440527 | validation: 0.031991644125354025]
	TIME [epoch: 9.1 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019786145937907482		[learning rate: 0.00020644]
	Learning Rate: 0.000206443
	LOSS [training: 0.019786145937907482 | validation: 0.037030061886518695]
	TIME [epoch: 9.09 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019699092655183638		[learning rate: 0.00020581]
	Learning Rate: 0.00020581
	LOSS [training: 0.019699092655183638 | validation: 0.028471209529846084]
	TIME [epoch: 9.09 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021635702204102242		[learning rate: 0.00020518]
	Learning Rate: 0.000205179
	LOSS [training: 0.021635702204102242 | validation: 0.02885122194022516]
	TIME [epoch: 9.11 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022769495036462573		[learning rate: 0.00020455]
	Learning Rate: 0.00020455
	LOSS [training: 0.022769495036462573 | validation: 0.03623696292656279]
	TIME [epoch: 9.09 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02464704115927937		[learning rate: 0.00020392]
	Learning Rate: 0.000203923
	LOSS [training: 0.02464704115927937 | validation: 0.03298580151346468]
	TIME [epoch: 9.08 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023873170201473552		[learning rate: 0.0002033]
	Learning Rate: 0.000203298
	LOSS [training: 0.023873170201473552 | validation: 0.028039475259517187]
	TIME [epoch: 9.09 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01856491195206657		[learning rate: 0.00020267]
	Learning Rate: 0.000202675
	LOSS [training: 0.01856491195206657 | validation: 0.027266543226356917]
	TIME [epoch: 9.12 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02004574929092577		[learning rate: 0.00020205]
	Learning Rate: 0.000202054
	LOSS [training: 0.02004574929092577 | validation: 0.030719074174394803]
	TIME [epoch: 9.08 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021032854085868948		[learning rate: 0.00020143]
	Learning Rate: 0.000201434
	LOSS [training: 0.021032854085868948 | validation: 0.022815203938744266]
	TIME [epoch: 9.08 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018435959504435436		[learning rate: 0.00020082]
	Learning Rate: 0.000200817
	LOSS [training: 0.018435959504435436 | validation: 0.029603136525371596]
	TIME [epoch: 9.09 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0246986181546221		[learning rate: 0.0002002]
	Learning Rate: 0.000200201
	LOSS [training: 0.0246986181546221 | validation: 0.0353261087192786]
	TIME [epoch: 9.09 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018763519685642768		[learning rate: 0.00019959]
	Learning Rate: 0.000199588
	LOSS [training: 0.018763519685642768 | validation: 0.038625235588738004]
	TIME [epoch: 9.09 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01958564583072221		[learning rate: 0.00019898]
	Learning Rate: 0.000198976
	LOSS [training: 0.01958564583072221 | validation: 0.0204072654451914]
	TIME [epoch: 9.06 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011542869259051023		[learning rate: 0.00019837]
	Learning Rate: 0.000198366
	LOSS [training: 0.011542869259051023 | validation: 0.0274001295211717]
	TIME [epoch: 9.07 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015018928762457612		[learning rate: 0.00019776]
	Learning Rate: 0.000197758
	LOSS [training: 0.015018928762457612 | validation: 0.03013309018707864]
	TIME [epoch: 9.09 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012494524839522738		[learning rate: 0.00019715]
	Learning Rate: 0.000197151
	LOSS [training: 0.012494524839522738 | validation: 0.029828332204624296]
	TIME [epoch: 9.09 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014546805254721292		[learning rate: 0.00019655]
	Learning Rate: 0.000196547
	LOSS [training: 0.014546805254721292 | validation: 0.022281113802139867]
	TIME [epoch: 9.08 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015634355820379583		[learning rate: 0.00019594]
	Learning Rate: 0.000195945
	LOSS [training: 0.015634355820379583 | validation: 0.021346533409728044]
	TIME [epoch: 9.08 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013513692652734268		[learning rate: 0.00019534]
	Learning Rate: 0.000195344
	LOSS [training: 0.013513692652734268 | validation: 0.0267664697694504]
	TIME [epoch: 9.09 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022291454648163116		[learning rate: 0.00019475]
	Learning Rate: 0.000194745
	LOSS [training: 0.022291454648163116 | validation: 0.02659175531874386]
	TIME [epoch: 9.09 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01662843796645979		[learning rate: 0.00019415]
	Learning Rate: 0.000194148
	LOSS [training: 0.01662843796645979 | validation: 0.035991076116040445]
	TIME [epoch: 9.07 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019120869968756046		[learning rate: 0.00019355]
	Learning Rate: 0.000193553
	LOSS [training: 0.019120869968756046 | validation: 0.030466485993658327]
	TIME [epoch: 9.08 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01397161903619532		[learning rate: 0.00019296]
	Learning Rate: 0.00019296
	LOSS [training: 0.01397161903619532 | validation: 0.022248573734633736]
	TIME [epoch: 9.09 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012704369687834583		[learning rate: 0.00019237]
	Learning Rate: 0.000192368
	LOSS [training: 0.012704369687834583 | validation: 0.021585556706019082]
	TIME [epoch: 9.1 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010763674157862304		[learning rate: 0.00019178]
	Learning Rate: 0.000191778
	LOSS [training: 0.010763674157862304 | validation: 0.02550396794079061]
	TIME [epoch: 9.07 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014544890596968818		[learning rate: 0.00019119]
	Learning Rate: 0.000191191
	LOSS [training: 0.014544890596968818 | validation: 0.024940150954806152]
	TIME [epoch: 9.09 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018037342487736467		[learning rate: 0.0001906]
	Learning Rate: 0.000190605
	LOSS [training: 0.018037342487736467 | validation: 0.02018903991306681]
	TIME [epoch: 9.07 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015247326028367324		[learning rate: 0.00019002]
	Learning Rate: 0.00019002
	LOSS [training: 0.015247326028367324 | validation: 0.021325635092786926]
	TIME [epoch: 9.11 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014208718587822753		[learning rate: 0.00018944]
	Learning Rate: 0.000189438
	LOSS [training: 0.014208718587822753 | validation: 0.02342144830185333]
	TIME [epoch: 9.08 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015271554831049219		[learning rate: 0.00018886]
	Learning Rate: 0.000188857
	LOSS [training: 0.015271554831049219 | validation: 0.022733423266177142]
	TIME [epoch: 9.09 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010707978832966994		[learning rate: 0.00018828]
	Learning Rate: 0.000188278
	LOSS [training: 0.010707978832966994 | validation: 0.018955063860841073]
	TIME [epoch: 9.08 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011972211214086804		[learning rate: 0.0001877]
	Learning Rate: 0.000187701
	LOSS [training: 0.011972211214086804 | validation: 0.01817724875983536]
	TIME [epoch: 9.1 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005917578465910638		[learning rate: 0.00018713]
	Learning Rate: 0.000187126
	LOSS [training: 0.005917578465910638 | validation: 0.00962406657434455]
	TIME [epoch: 9.09 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008828593281958275		[learning rate: 0.00018655]
	Learning Rate: 0.000186552
	LOSS [training: 0.008828593281958275 | validation: 0.0184604264001712]
	TIME [epoch: 9.09 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00906633740406856		[learning rate: 0.00018598]
	Learning Rate: 0.00018598
	LOSS [training: 0.00906633740406856 | validation: 0.020334821135020893]
	TIME [epoch: 9.09 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010177586070086914		[learning rate: 0.00018541]
	Learning Rate: 0.00018541
	LOSS [training: 0.010177586070086914 | validation: 0.019621438025282104]
	TIME [epoch: 9.1 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012904860813935345		[learning rate: 0.00018484]
	Learning Rate: 0.000184842
	LOSS [training: 0.012904860813935345 | validation: 0.016239702472172324]
	TIME [epoch: 9.08 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005698881613990326		[learning rate: 0.00018428]
	Learning Rate: 0.000184275
	LOSS [training: 0.005698881613990326 | validation: 0.01597690703064123]
	TIME [epoch: 9.09 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007826795469382437		[learning rate: 0.00018371]
	Learning Rate: 0.00018371
	LOSS [training: 0.007826795469382437 | validation: 0.023894061550282997]
	TIME [epoch: 9.09 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007587428919559447		[learning rate: 0.00018315]
	Learning Rate: 0.000183147
	LOSS [training: 0.007587428919559447 | validation: 0.01901322524325946]
	TIME [epoch: 9.11 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009983276130273071		[learning rate: 0.00018259]
	Learning Rate: 0.000182586
	LOSS [training: 0.009983276130273071 | validation: 0.010612217219013736]
	TIME [epoch: 9.09 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018689678307786562		[learning rate: 0.00018203]
	Learning Rate: 0.000182026
	LOSS [training: 0.0018689678307786562 | validation: 0.012375696139202252]
	TIME [epoch: 9.11 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008319089585066882		[learning rate: 0.00018147]
	Learning Rate: 0.000181468
	LOSS [training: 0.008319089585066882 | validation: 0.027413148387531033]
	TIME [epoch: 9.1 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007779974459502306		[learning rate: 0.00018091]
	Learning Rate: 0.000180912
	LOSS [training: 0.007779974459502306 | validation: 0.019398100944860233]
	TIME [epoch: 9.12 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008713307545218202		[learning rate: 0.00018036]
	Learning Rate: 0.000180357
	LOSS [training: 0.008713307545218202 | validation: 0.02203284507047114]
	TIME [epoch: 9.1 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010125273312072202		[learning rate: 0.0001798]
	Learning Rate: 0.000179804
	LOSS [training: 0.010125273312072202 | validation: 0.015065902435142178]
	TIME [epoch: 9.08 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0063030593906356625		[learning rate: 0.00017925]
	Learning Rate: 0.000179253
	LOSS [training: 0.0063030593906356625 | validation: 0.021084164568825815]
	TIME [epoch: 9.08 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01173218492207027		[learning rate: 0.0001787]
	Learning Rate: 0.000178704
	LOSS [training: 0.01173218492207027 | validation: 0.023533941761935656]
	TIME [epoch: 9.09 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005870062849426006		[learning rate: 0.00017816]
	Learning Rate: 0.000178156
	LOSS [training: 0.005870062849426006 | validation: 0.019055194090826618]
	TIME [epoch: 9.1 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010428626862140893		[learning rate: 0.00017761]
	Learning Rate: 0.00017761
	LOSS [training: 0.010428626862140893 | validation: 0.012030051474378451]
	TIME [epoch: 9.09 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007704515183475769		[learning rate: 0.00017707]
	Learning Rate: 0.000177065
	LOSS [training: 0.007704515183475769 | validation: 0.00788222578690765]
	TIME [epoch: 9.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1814.pth
	Model improved!!!
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007194431112275239		[learning rate: 0.00017652]
	Learning Rate: 0.000176522
	LOSS [training: 0.007194431112275239 | validation: 0.023128919425480943]
	TIME [epoch: 9.09 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011072049491232899		[learning rate: 0.00017598]
	Learning Rate: 0.000175981
	LOSS [training: 0.011072049491232899 | validation: 0.02880917667836331]
	TIME [epoch: 9.09 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019134119883666267		[learning rate: 0.00017544]
	Learning Rate: 0.000175442
	LOSS [training: 0.019134119883666267 | validation: 0.030375870471438218]
	TIME [epoch: 9.08 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014118631773936439		[learning rate: 0.0001749]
	Learning Rate: 0.000174904
	LOSS [training: 0.014118631773936439 | validation: 0.02050214423439726]
	TIME [epoch: 9.08 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014491065569443138		[learning rate: 0.00017437]
	Learning Rate: 0.000174368
	LOSS [training: 0.014491065569443138 | validation: 0.026581572952989033]
	TIME [epoch: 9.08 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019090748187224303		[learning rate: 0.00017383]
	Learning Rate: 0.000173833
	LOSS [training: 0.019090748187224303 | validation: 0.03207064732073585]
	TIME [epoch: 9.1 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015383664346064845		[learning rate: 0.0001733]
	Learning Rate: 0.000173301
	LOSS [training: 0.015383664346064845 | validation: 0.023674904440445198]
	TIME [epoch: 9.09 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01063558881800494		[learning rate: 0.00017277]
	Learning Rate: 0.000172769
	LOSS [training: 0.01063558881800494 | validation: 0.020722852721838086]
	TIME [epoch: 9.08 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012301500505558918		[learning rate: 0.00017224]
	Learning Rate: 0.00017224
	LOSS [training: 0.012301500505558918 | validation: 0.02452001333145549]
	TIME [epoch: 9.08 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01599678135173247		[learning rate: 0.00017171]
	Learning Rate: 0.000171712
	LOSS [training: 0.01599678135173247 | validation: 0.024851455688785884]
	TIME [epoch: 9.11 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014288422294472386		[learning rate: 0.00017119]
	Learning Rate: 0.000171185
	LOSS [training: 0.014288422294472386 | validation: 0.02899491796435704]
	TIME [epoch: 9.1 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011251682483233313		[learning rate: 0.00017066]
	Learning Rate: 0.000170661
	LOSS [training: 0.011251682483233313 | validation: 0.02450585394461244]
	TIME [epoch: 9.08 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015698265575591477		[learning rate: 0.00017014]
	Learning Rate: 0.000170137
	LOSS [training: 0.015698265575591477 | validation: 0.028022572047864194]
	TIME [epoch: 9.08 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012401917168759144		[learning rate: 0.00016962]
	Learning Rate: 0.000169616
	LOSS [training: 0.012401917168759144 | validation: 0.020128242010901617]
	TIME [epoch: 9.09 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006066296992349398		[learning rate: 0.0001691]
	Learning Rate: 0.000169096
	LOSS [training: 0.006066296992349398 | validation: 0.02196307632763963]
	TIME [epoch: 9.09 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005459449231368327		[learning rate: 0.00016858]
	Learning Rate: 0.000168578
	LOSS [training: 0.005459449231368327 | validation: 0.019200674149440728]
	TIME [epoch: 9.08 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007787598019713124		[learning rate: 0.00016806]
	Learning Rate: 0.000168061
	LOSS [training: 0.007787598019713124 | validation: 0.02226150051679508]
	TIME [epoch: 9.08 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008877628404802326		[learning rate: 0.00016755]
	Learning Rate: 0.000167546
	LOSS [training: 0.008877628404802326 | validation: 0.028396397601181952]
	TIME [epoch: 9.09 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007359438594938794		[learning rate: 0.00016703]
	Learning Rate: 0.000167032
	LOSS [training: 0.007359438594938794 | validation: 0.0134500725949834]
	TIME [epoch: 9.09 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01054741045814447		[learning rate: 0.00016652]
	Learning Rate: 0.00016652
	LOSS [training: 0.01054741045814447 | validation: 0.021505161309871665]
	TIME [epoch: 9.08 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0061729671071687935		[learning rate: 0.00016601]
	Learning Rate: 0.00016601
	LOSS [training: 0.0061729671071687935 | validation: 0.02498234323702054]
	TIME [epoch: 9.09 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013097415584663725		[learning rate: 0.0001655]
	Learning Rate: 0.000165501
	LOSS [training: 0.013097415584663725 | validation: 0.014191858778446972]
	TIME [epoch: 9.08 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009175187142528272		[learning rate: 0.00016499]
	Learning Rate: 0.000164993
	LOSS [training: 0.009175187142528272 | validation: 0.022200432580700712]
	TIME [epoch: 9.11 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012023446670468526		[learning rate: 0.00016449]
	Learning Rate: 0.000164488
	LOSS [training: 0.012023446670468526 | validation: 0.028452014599828015]
	TIME [epoch: 9.08 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010770900263187645		[learning rate: 0.00016398]
	Learning Rate: 0.000163983
	LOSS [training: 0.010770900263187645 | validation: 0.028657715232410026]
	TIME [epoch: 9.08 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00781017367181418		[learning rate: 0.00016348]
	Learning Rate: 0.000163481
	LOSS [training: 0.00781017367181418 | validation: 0.019504638850147776]
	TIME [epoch: 9.09 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011523921643941334		[learning rate: 0.00016298]
	Learning Rate: 0.00016298
	LOSS [training: 0.011523921643941334 | validation: 0.02165997612120326]
	TIME [epoch: 9.11 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009825675776933376		[learning rate: 0.00016248]
	Learning Rate: 0.00016248
	LOSS [training: 0.009825675776933376 | validation: 0.018058143517905613]
	TIME [epoch: 9.08 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009843969125023198		[learning rate: 0.00016198]
	Learning Rate: 0.000161982
	LOSS [training: 0.009843969125023198 | validation: 0.021631213803213818]
	TIME [epoch: 9.09 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012735662884693624		[learning rate: 0.00016149]
	Learning Rate: 0.000161485
	LOSS [training: 0.012735662884693624 | validation: 0.020354874495309948]
	TIME [epoch: 9.09 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007639331297589998		[learning rate: 0.00016099]
	Learning Rate: 0.00016099
	LOSS [training: 0.007639331297589998 | validation: 0.018117477371179663]
	TIME [epoch: 9.11 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011604194189543487		[learning rate: 0.0001605]
	Learning Rate: 0.000160497
	LOSS [training: 0.011604194189543487 | validation: 0.024246780848834006]
	TIME [epoch: 9.09 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006136326311007095		[learning rate: 0.00016]
	Learning Rate: 0.000160005
	LOSS [training: 0.006136326311007095 | validation: 0.016718795506416195]
	TIME [epoch: 9.09 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01022295070375151		[learning rate: 0.00015951]
	Learning Rate: 0.000159514
	LOSS [training: 0.01022295070375151 | validation: 0.02195024126033538]
	TIME [epoch: 9.08 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00793533134480565		[learning rate: 0.00015903]
	Learning Rate: 0.000159025
	LOSS [training: 0.00793533134480565 | validation: 0.01772571345668018]
	TIME [epoch: 9.1 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010080328222600134		[learning rate: 0.00015854]
	Learning Rate: 0.000158538
	LOSS [training: 0.010080328222600134 | validation: 0.019958229499378973]
	TIME [epoch: 9.08 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008077055124740619		[learning rate: 0.00015805]
	Learning Rate: 0.000158052
	LOSS [training: 0.008077055124740619 | validation: 0.0355264913323163]
	TIME [epoch: 9.08 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00875851367476522		[learning rate: 0.00015757]
	Learning Rate: 0.000157567
	LOSS [training: 0.00875851367476522 | validation: 0.023393247331182476]
	TIME [epoch: 9.09 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010134867478628668		[learning rate: 0.00015708]
	Learning Rate: 0.000157084
	LOSS [training: 0.010134867478628668 | validation: 0.019611552449291483]
	TIME [epoch: 9.09 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012838530562507902		[learning rate: 0.0001566]
	Learning Rate: 0.000156603
	LOSS [training: 0.012838530562507902 | validation: 0.02533721984288781]
	TIME [epoch: 9.1 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014676482880482178		[learning rate: 0.00015612]
	Learning Rate: 0.000156123
	LOSS [training: 0.014676482880482178 | validation: 0.01899067318423732]
	TIME [epoch: 9.09 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012463762335911373		[learning rate: 0.00015564]
	Learning Rate: 0.000155644
	LOSS [training: 0.012463762335911373 | validation: 0.020450909817339206]
	TIME [epoch: 9.09 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01212289212860317		[learning rate: 0.00015517]
	Learning Rate: 0.000155167
	LOSS [training: 0.01212289212860317 | validation: 0.017694732358704817]
	TIME [epoch: 9.09 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010637187602425555		[learning rate: 0.00015469]
	Learning Rate: 0.000154692
	LOSS [training: 0.010637187602425555 | validation: 0.01985515025497619]
	TIME [epoch: 9.09 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01067934056392141		[learning rate: 0.00015422]
	Learning Rate: 0.000154217
	LOSS [training: 0.01067934056392141 | validation: 0.026558300678589535]
	TIME [epoch: 9.08 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011203469524807077		[learning rate: 0.00015374]
	Learning Rate: 0.000153745
	LOSS [training: 0.011203469524807077 | validation: 0.02708384756384881]
	TIME [epoch: 9.08 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007581705315727572		[learning rate: 0.00015327]
	Learning Rate: 0.000153273
	LOSS [training: 0.007581705315727572 | validation: 0.021692387822272]
	TIME [epoch: 9.08 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004491129647342974		[learning rate: 0.0001528]
	Learning Rate: 0.000152803
	LOSS [training: 0.004491129647342974 | validation: 0.02193333846992247]
	TIME [epoch: 9.1 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01011870952488891		[learning rate: 0.00015234]
	Learning Rate: 0.000152335
	LOSS [training: 0.01011870952488891 | validation: 0.015855118498401696]
	TIME [epoch: 9.08 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00744713476308087		[learning rate: 0.00015187]
	Learning Rate: 0.000151868
	LOSS [training: 0.00744713476308087 | validation: 0.020491334013321885]
	TIME [epoch: 9.08 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009225472253340587		[learning rate: 0.0001514]
	Learning Rate: 0.000151403
	LOSS [training: 0.009225472253340587 | validation: 0.024420029938671494]
	TIME [epoch: 9.08 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008015382947536736		[learning rate: 0.00015094]
	Learning Rate: 0.000150938
	LOSS [training: 0.008015382947536736 | validation: 0.01836888392989428]
	TIME [epoch: 9.1 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0062830182476848895		[learning rate: 0.00015048]
	Learning Rate: 0.000150476
	LOSS [training: 0.0062830182476848895 | validation: 0.014711888454446587]
	TIME [epoch: 9.09 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0058915802287454735		[learning rate: 0.00015001]
	Learning Rate: 0.000150015
	LOSS [training: 0.0058915802287454735 | validation: 0.02425876299200505]
	TIME [epoch: 9.09 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006932786235821128		[learning rate: 0.00014955]
	Learning Rate: 0.000149555
	LOSS [training: 0.006932786235821128 | validation: 0.013802726175005428]
	TIME [epoch: 9.08 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010571699350999768		[learning rate: 0.0001491]
	Learning Rate: 0.000149096
	LOSS [training: 0.010571699350999768 | validation: 0.017516346034531977]
	TIME [epoch: 9.11 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012959369030733633		[learning rate: 0.00014864]
	Learning Rate: 0.000148639
	LOSS [training: 0.012959369030733633 | validation: 0.014872130375196595]
	TIME [epoch: 9.09 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0018452906725866744		[learning rate: 0.00014818]
	Learning Rate: 0.000148184
	LOSS [training: 0.0018452906725866744 | validation: 0.014159558353039167]
	TIME [epoch: 9.08 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012306866361690101		[learning rate: 0.00014773]
	Learning Rate: 0.000147729
	LOSS [training: 0.012306866361690101 | validation: 0.019030578117015595]
	TIME [epoch: 9.08 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011389666021714099		[learning rate: 0.00014728]
	Learning Rate: 0.000147276
	LOSS [training: 0.011389666021714099 | validation: 0.013745152222415262]
	TIME [epoch: 9.1 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011440161718923677		[learning rate: 0.00014682]
	Learning Rate: 0.000146825
	LOSS [training: 0.011440161718923677 | validation: 0.017972493946636678]
	TIME [epoch: 9.07 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008314159834254469		[learning rate: 0.00014637]
	Learning Rate: 0.000146375
	LOSS [training: 0.008314159834254469 | validation: 0.014310357298155217]
	TIME [epoch: 9.07 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005325867730479906		[learning rate: 0.00014593]
	Learning Rate: 0.000145926
	LOSS [training: 0.005325867730479906 | validation: 0.01352126086348534]
	TIME [epoch: 9.07 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007476395351765153		[learning rate: 0.00014548]
	Learning Rate: 0.000145479
	LOSS [training: 0.007476395351765153 | validation: 0.020167357979918824]
	TIME [epoch: 9.09 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007991767285697053		[learning rate: 0.00014503]
	Learning Rate: 0.000145033
	LOSS [training: 0.007991767285697053 | validation: 0.009595306063409328]
	TIME [epoch: 9.07 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004263856228926737		[learning rate: 0.00014459]
	Learning Rate: 0.000144588
	LOSS [training: 0.004263856228926737 | validation: 0.012513733082727501]
	TIME [epoch: 9.07 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006229358775891239		[learning rate: 0.00014415]
	Learning Rate: 0.000144145
	LOSS [training: 0.006229358775891239 | validation: 0.01449431332042933]
	TIME [epoch: 9.07 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009620085452544284		[learning rate: 0.0001437]
	Learning Rate: 0.000143703
	LOSS [training: 0.009620085452544284 | validation: 0.01599945243155829]
	TIME [epoch: 9.08 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006201787054530899		[learning rate: 0.00014326]
	Learning Rate: 0.000143263
	LOSS [training: 0.006201787054530899 | validation: 0.010000768970995461]
	TIME [epoch: 9.1 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007474452848596777		[learning rate: 0.00014282]
	Learning Rate: 0.000142824
	LOSS [training: 0.007474452848596777 | validation: 0.01763542371377389]
	TIME [epoch: 9.08 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007620757904813804		[learning rate: 0.00014239]
	Learning Rate: 0.000142386
	LOSS [training: 0.007620757904813804 | validation: 0.018357257853847925]
	TIME [epoch: 9.08 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007900682994541788		[learning rate: 0.00014195]
	Learning Rate: 0.000141949
	LOSS [training: 0.007900682994541788 | validation: 0.017876568586856968]
	TIME [epoch: 9.09 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006265073615427571		[learning rate: 0.00014151]
	Learning Rate: 0.000141514
	LOSS [training: 0.006265073615427571 | validation: 0.008882402766995253]
	TIME [epoch: 9.09 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005381115255506211		[learning rate: 0.00014108]
	Learning Rate: 0.00014108
	LOSS [training: 0.005381115255506211 | validation: 0.020007392443021972]
	TIME [epoch: 9.09 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004179265030075987		[learning rate: 0.00014065]
	Learning Rate: 0.000140648
	LOSS [training: 0.004179265030075987 | validation: 0.011089834876967184]
	TIME [epoch: 9.09 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0069149356901015025		[learning rate: 0.00014022]
	Learning Rate: 0.000140217
	LOSS [training: 0.0069149356901015025 | validation: 0.016044203361250543]
	TIME [epoch: 9.1 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005993798989822728		[learning rate: 0.00013979]
	Learning Rate: 0.000139787
	LOSS [training: 0.005993798989822728 | validation: 0.01372620663316124]
	TIME [epoch: 9.12 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00828869396894223		[learning rate: 0.00013936]
	Learning Rate: 0.000139358
	LOSS [training: 0.00828869396894223 | validation: 0.015981306518905253]
	TIME [epoch: 9.1 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006468703638081772		[learning rate: 0.00013893]
	Learning Rate: 0.000138931
	LOSS [training: 0.006468703638081772 | validation: 0.01476947071461239]
	TIME [epoch: 9.1 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006583844475858194		[learning rate: 0.00013851]
	Learning Rate: 0.000138505
	LOSS [training: 0.006583844475858194 | validation: 0.014466814996956864]
	TIME [epoch: 9.1 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007750170725799364		[learning rate: 0.00013808]
	Learning Rate: 0.000138081
	LOSS [training: 0.007750170725799364 | validation: 0.02212724954631074]
	TIME [epoch: 9.11 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015250205827849462		[learning rate: 0.00013766]
	Learning Rate: 0.000137658
	LOSS [training: 0.015250205827849462 | validation: 0.018069113749125794]
	TIME [epoch: 9.09 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01173266368835863		[learning rate: 0.00013724]
	Learning Rate: 0.000137236
	LOSS [training: 0.01173266368835863 | validation: 0.01530555074080877]
	TIME [epoch: 9.09 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012885990365082945		[learning rate: 0.00013681]
	Learning Rate: 0.000136815
	LOSS [training: 0.012885990365082945 | validation: 0.035499734256110804]
	TIME [epoch: 9.09 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01807893446889767		[learning rate: 0.0001364]
	Learning Rate: 0.000136395
	LOSS [training: 0.01807893446889767 | validation: 0.02778049400125683]
	TIME [epoch: 9.11 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012191947509318174		[learning rate: 0.00013598]
	Learning Rate: 0.000135977
	LOSS [training: 0.012191947509318174 | validation: 0.012745998358910859]
	TIME [epoch: 9.09 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014341996446914534		[learning rate: 0.00013556]
	Learning Rate: 0.000135561
	LOSS [training: 0.014341996446914534 | validation: 0.022118752077284635]
	TIME [epoch: 9.08 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009524101772708236		[learning rate: 0.00013515]
	Learning Rate: 0.000135145
	LOSS [training: 0.009524101772708236 | validation: 0.017499962277659077]
	TIME [epoch: 9.1 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009083946878459818		[learning rate: 0.00013473]
	Learning Rate: 0.000134731
	LOSS [training: 0.009083946878459818 | validation: 0.022662119640210303]
	TIME [epoch: 9.11 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00863516388357977		[learning rate: 0.00013432]
	Learning Rate: 0.000134318
	LOSS [training: 0.00863516388357977 | validation: 0.014971362229731515]
	TIME [epoch: 9.09 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007093330264677765		[learning rate: 0.00013391]
	Learning Rate: 0.000133906
	LOSS [training: 0.007093330264677765 | validation: 0.019680795150534697]
	TIME [epoch: 9.08 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014917130692092693		[learning rate: 0.0001335]
	Learning Rate: 0.000133496
	LOSS [training: 0.014917130692092693 | validation: 0.026807475718164886]
	TIME [epoch: 9.09 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014855147338203908		[learning rate: 0.00013309]
	Learning Rate: 0.000133086
	LOSS [training: 0.014855147338203908 | validation: 0.022345804994393818]
	TIME [epoch: 9.36 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012379263518685561		[learning rate: 0.00013268]
	Learning Rate: 0.000132678
	LOSS [training: 0.012379263518685561 | validation: 0.023672967545945313]
	TIME [epoch: 9.11 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010568336168801925		[learning rate: 0.00013227]
	Learning Rate: 0.000132272
	LOSS [training: 0.010568336168801925 | validation: 0.018661384088884868]
	TIME [epoch: 9.11 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0074818219207245145		[learning rate: 0.00013187]
	Learning Rate: 0.000131866
	LOSS [training: 0.0074818219207245145 | validation: 0.02932997350334615]
	TIME [epoch: 9.1 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007328130248415873		[learning rate: 0.00013146]
	Learning Rate: 0.000131462
	LOSS [training: 0.007328130248415873 | validation: 0.010040137842771841]
	TIME [epoch: 9.1 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003465198135467455		[learning rate: 0.00013106]
	Learning Rate: 0.000131059
	LOSS [training: 0.003465198135467455 | validation: 0.015479502147204238]
	TIME [epoch: 9.12 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009311054089168639		[learning rate: 0.00013066]
	Learning Rate: 0.000130657
	LOSS [training: 0.009311054089168639 | validation: 0.027679335270352004]
	TIME [epoch: 9.1 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009679601494165736		[learning rate: 0.00013026]
	Learning Rate: 0.000130257
	LOSS [training: 0.009679601494165736 | validation: 0.02211394419612525]
	TIME [epoch: 9.11 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011345242355296044		[learning rate: 0.00012986]
	Learning Rate: 0.000129857
	LOSS [training: 0.011345242355296044 | validation: 0.03061925575629335]
	TIME [epoch: 9.11 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014539371958417263		[learning rate: 0.00012946]
	Learning Rate: 0.000129459
	LOSS [training: 0.014539371958417263 | validation: 0.023043476493034516]
	TIME [epoch: 9.13 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009459301652256114		[learning rate: 0.00012906]
	Learning Rate: 0.000129062
	LOSS [training: 0.009459301652256114 | validation: 0.02876063365551966]
	TIME [epoch: 9.11 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00703871133170534		[learning rate: 0.00012867]
	Learning Rate: 0.000128667
	LOSS [training: 0.00703871133170534 | validation: 0.016670432736976257]
	TIME [epoch: 9.1 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005001574536106904		[learning rate: 0.00012827]
	Learning Rate: 0.000128272
	LOSS [training: 0.005001574536106904 | validation: -0.0002879846762746845]
	TIME [epoch: 9.11 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study4/model_tr_study4_r0_20240217_020936/states/model_tr_study4_1919.pth
	Model improved!!!
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0065656051460681025		[learning rate: 0.00012788]
	Learning Rate: 0.000127879
	LOSS [training: 0.0065656051460681025 | validation: 0.014724206282843866]
	TIME [epoch: 9.13 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029617616440659315		[learning rate: 0.00012749]
	Learning Rate: 0.000127487
	LOSS [training: 0.0029617616440659315 | validation: 0.013457707424822501]
	TIME [epoch: 9.12 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009214516318579832		[learning rate: 0.0001271]
	Learning Rate: 0.000127096
	LOSS [training: 0.009214516318579832 | validation: 0.010603034603676122]
	TIME [epoch: 9.11 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005834500683055392		[learning rate: 0.00012671]
	Learning Rate: 0.000126707
	LOSS [training: 0.005834500683055392 | validation: 0.018375807443832118]
	TIME [epoch: 9.11 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005551944192911126		[learning rate: 0.00012632]
	Learning Rate: 0.000126318
	LOSS [training: 0.005551944192911126 | validation: 0.0024086067531992866]
	TIME [epoch: 9.12 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009858875387433713		[learning rate: 0.00012593]
	Learning Rate: 0.000125931
	LOSS [training: 0.009858875387433713 | validation: 0.01913248768885619]
	TIME [epoch: 9.14 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0051825939312530045		[learning rate: 0.00012555]
	Learning Rate: 0.000125545
	LOSS [training: 0.0051825939312530045 | validation: 0.022194402219112945]
	TIME [epoch: 9.11 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011055360664758993		[learning rate: 0.00012516]
	Learning Rate: 0.00012516
	LOSS [training: 0.011055360664758993 | validation: 0.006248254131844961]
	TIME [epoch: 9.11 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006696738038940922		[learning rate: 0.00012478]
	Learning Rate: 0.000124777
	LOSS [training: 0.006696738038940922 | validation: 0.014403674462503624]
	TIME [epoch: 9.11 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0038727404061248603		[learning rate: 0.00012439]
	Learning Rate: 0.000124394
	LOSS [training: 0.0038727404061248603 | validation: 0.013811210843216562]
	TIME [epoch: 9.14 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008192954156169335		[learning rate: 0.00012401]
	Learning Rate: 0.000124013
	LOSS [training: 0.008192954156169335 | validation: 0.01574680136400812]
	TIME [epoch: 9.11 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0037710609115231206		[learning rate: 0.00012363]
	Learning Rate: 0.000123633
	LOSS [training: 0.0037710609115231206 | validation: 0.011277692948176644]
	TIME [epoch: 9.11 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008259185052326761		[learning rate: 0.00012325]
	Learning Rate: 0.000123254
	LOSS [training: 0.008259185052326761 | validation: 0.009216777435503462]
	TIME [epoch: 9.11 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008485384422314113		[learning rate: 0.00012288]
	Learning Rate: 0.000122876
	LOSS [training: 0.008485384422314113 | validation: 0.01160700018131619]
	TIME [epoch: 9.13 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0026836168511463762		[learning rate: 0.0001225]
	Learning Rate: 0.000122499
	LOSS [training: 0.0026836168511463762 | validation: 0.019339541735081775]
	TIME [epoch: 9.11 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00406079677014055		[learning rate: 0.00012212]
	Learning Rate: 0.000122124
	LOSS [training: 0.00406079677014055 | validation: 0.008578348548748815]
	TIME [epoch: 9.11 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00843555167328696		[learning rate: 0.00012175]
	Learning Rate: 0.000121749
	LOSS [training: 0.00843555167328696 | validation: -0.0002856209254558839]
	TIME [epoch: 9.11 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008514144896740536		[learning rate: 0.00012138]
	Learning Rate: 0.000121376
	LOSS [training: 0.008514144896740536 | validation: 0.0191497888512566]
	TIME [epoch: 9.14 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004694018365596328		[learning rate: 0.000121]
	Learning Rate: 0.000121004
	LOSS [training: 0.004694018365596328 | validation: 0.021869967364053687]
	TIME [epoch: 9.11 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003671244755812284		[learning rate: 0.00012063]
	Learning Rate: 0.000120633
	LOSS [training: 0.003671244755812284 | validation: 0.018532415763425313]
	TIME [epoch: 9.19 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00657871515977444		[learning rate: 0.00012026]
	Learning Rate: 0.000120263
	LOSS [training: 0.00657871515977444 | validation: 0.013992308322578442]
	TIME [epoch: 9.11 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002681760176107515		[learning rate: 0.00011989]
	Learning Rate: 0.000119895
	LOSS [training: 0.002681760176107515 | validation: 0.009074469515122804]
	TIME [epoch: 9.13 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0052588029220415585		[learning rate: 0.00011953]
	Learning Rate: 0.000119527
	LOSS [training: 0.0052588029220415585 | validation: 0.014190699653821743]
	TIME [epoch: 9.11 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0030812201514257885		[learning rate: 0.00011916]
	Learning Rate: 0.000119161
	LOSS [training: 0.0030812201514257885 | validation: 0.020165094079136803]
	TIME [epoch: 9.11 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006475423958818538		[learning rate: 0.0001188]
	Learning Rate: 0.000118795
	LOSS [training: 0.006475423958818538 | validation: 0.014131645243457497]
	TIME [epoch: 9.1 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0033236367321623586		[learning rate: 0.00011843]
	Learning Rate: 0.000118431
	LOSS [training: 0.0033236367321623586 | validation: 0.019225389808789354]
	TIME [epoch: 9.13 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003066596004175078		[learning rate: 0.00011807]
	Learning Rate: 0.000118068
	LOSS [training: 0.003066596004175078 | validation: 0.018263806882248344]
	TIME [epoch: 9.13 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007513771196900866		[learning rate: 0.00011771]
	Learning Rate: 0.000117706
	LOSS [training: 0.007513771196900866 | validation: 0.024442664114168053]
	TIME [epoch: 9.11 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003033567907039244		[learning rate: 0.00011735]
	Learning Rate: 0.000117346
	LOSS [training: 0.003033567907039244 | validation: 0.015879774402414306]
	TIME [epoch: 9.11 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005143095535153658		[learning rate: 0.00011699]
	Learning Rate: 0.000116986
	LOSS [training: 0.005143095535153658 | validation: 0.015571163783738011]
	TIME [epoch: 9.13 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007141568090169611		[learning rate: 0.00011663]
	Learning Rate: 0.000116627
	LOSS [training: 0.007141568090169611 | validation: 0.015470698446422466]
	TIME [epoch: 9.13 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004275065528960808		[learning rate: 0.00011627]
	Learning Rate: 0.00011627
	LOSS [training: 0.004275065528960808 | validation: 0.013919354136046766]
	TIME [epoch: 9.11 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006848333617992297		[learning rate: 0.00011591]
	Learning Rate: 0.000115913
	LOSS [training: 0.006848333617992297 | validation: 0.017122757834494805]
	TIME [epoch: 9.11 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005659772752579721		[learning rate: 0.00011556]
	Learning Rate: 0.000115558
	LOSS [training: 0.005659772752579721 | validation: 0.029189248027092538]
	TIME [epoch: 9.12 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006590728044705413		[learning rate: 0.0001152]
	Learning Rate: 0.000115204
	LOSS [training: 0.006590728044705413 | validation: 0.017273617226146152]
	TIME [epoch: 9.13 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00808106382766987		[learning rate: 0.00011485]
	Learning Rate: 0.000114851
	LOSS [training: 0.00808106382766987 | validation: 0.021628268709644537]
	TIME [epoch: 9.11 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0024388836200767957		[learning rate: 0.0001145]
	Learning Rate: 0.000114499
	LOSS [training: 0.0024388836200767957 | validation: 0.014093391123506946]
	TIME [epoch: 9.11 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006206930531479632		[learning rate: 0.00011415]
	Learning Rate: 0.000114148
	LOSS [training: 0.006206930531479632 | validation: 0.00013195297338212118]
	TIME [epoch: 9.11 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004232504710851471		[learning rate: 0.0001138]
	Learning Rate: 0.000113798
	LOSS [training: 0.004232504710851471 | validation: 0.009995700504872924]
	TIME [epoch: 9.13 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0039659916796352685		[learning rate: 0.00011345]
	Learning Rate: 0.000113449
	LOSS [training: 0.0039659916796352685 | validation: 0.006594269702919316]
	TIME [epoch: 9.12 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006135837764111206		[learning rate: 0.0001131]
	Learning Rate: 0.000113101
	LOSS [training: 0.006135837764111206 | validation: 0.0141056578006679]
	TIME [epoch: 9.12 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005934993069131018		[learning rate: 0.00011275]
	Learning Rate: 0.000112754
	LOSS [training: 0.005934993069131018 | validation: 0.009836879922168333]
	TIME [epoch: 9.11 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006537030400112951		[learning rate: 0.00011241]
	Learning Rate: 0.000112409
	LOSS [training: 0.006537030400112951 | validation: 0.015348377778020906]
	TIME [epoch: 9.14 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.004160579066852907		[learning rate: 0.00011206]
	Learning Rate: 0.000112064
	LOSS [training: 0.004160579066852907 | validation: 0.01216583015795831]
	TIME [epoch: 9.11 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0010896895565854897		[learning rate: 0.00011172]
	Learning Rate: 0.000111721
	LOSS [training: 0.0010896895565854897 | validation: 0.00842074160155472]
	TIME [epoch: 9.11 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006778033421173083		[learning rate: 0.00011138]
	Learning Rate: 0.000111378
	LOSS [training: 0.006778033421173083 | validation: 0.010840358004443832]
	TIME [epoch: 9.11 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008184655705658853		[learning rate: 0.00011104]
	Learning Rate: 0.000111037
	LOSS [training: 0.008184655705658853 | validation: 0.01749638169520858]
	TIME [epoch: 9.14 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0034404838529042475		[learning rate: 0.0001107]
	Learning Rate: 0.000110696
	LOSS [training: 0.0034404838529042475 | validation: 0.013157408724784422]
	TIME [epoch: 9.11 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021369784383108064		[learning rate: 0.00011036]
	Learning Rate: 0.000110357
	LOSS [training: 0.0021369784383108064 | validation: 0.014845153679059562]
	TIME [epoch: 9.11 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006147144058465362		[learning rate: 0.00011002]
	Learning Rate: 0.000110019
	LOSS [training: 0.006147144058465362 | validation: 0.01608872423880972]
	TIME [epoch: 9.11 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005651291340572209		[learning rate: 0.00010968]
	Learning Rate: 0.000109681
	LOSS [training: 0.005651291340572209 | validation: 0.01859561225987877]
	TIME [epoch: 9.13 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00489502943182058		[learning rate: 0.00010935]
	Learning Rate: 0.000109345
	LOSS [training: 0.00489502943182058 | validation: 0.008412901876336172]
	TIME [epoch: 9.11 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0021953289542394937		[learning rate: 0.00010901]
	Learning Rate: 0.00010901
	LOSS [training: 0.0021953289542394937 | validation: 0.020778615383412427]
	TIME [epoch: 9.11 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003429958655171335		[learning rate: 0.00010868]
	Learning Rate: 0.000108676
	LOSS [training: 0.003429958655171335 | validation: 0.02099845218961533]
	TIME [epoch: 9.11 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.003872664102056808		[learning rate: 0.00010834]
	Learning Rate: 0.000108343
	LOSS [training: 0.003872664102056808 | validation: 0.020154554038599996]
	TIME [epoch: 9.12 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0037627287863629955		[learning rate: 0.00010801]
	Learning Rate: 0.000108011
	LOSS [training: 0.0037627287863629955 | validation: 0.020481620698890868]
	TIME [epoch: 9.12 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0045040370080142505		[learning rate: 0.00010768]
	Learning Rate: 0.00010768
	LOSS [training: 0.0045040370080142505 | validation: 0.011511998675203828]
	TIME [epoch: 9.11 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0033997856922449304		[learning rate: 0.00010735]
	Learning Rate: 0.000107349
	LOSS [training: 0.0033997856922449304 | validation: 0.01683399544495283]
	TIME [epoch: 9.1 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.005237818853534857		[learning rate: 0.00010702]
	Learning Rate: 0.00010702
	LOSS [training: 0.005237818853534857 | validation: 0.01123480763396767]
	TIME [epoch: 9.11 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.002522772679448305		[learning rate: 0.00010669]
	Learning Rate: 0.000106692
	LOSS [training: 0.002522772679448305 | validation: 0.01796895723635769]
	TIME [epoch: 9.12 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0027835016172187564		[learning rate: 0.00010637]
	Learning Rate: 0.000106365
	LOSS [training: 0.0027835016172187564 | validation: 0.0126999073582864]
	TIME [epoch: 9.11 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0029629044093687535		[learning rate: 0.00010604]
	Learning Rate: 0.000106039
	LOSS [training: 0.0029629044093687535 | validation: 0.014189538113116119]
	TIME [epoch: 9.11 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006781619762803531		[learning rate: 0.00010571]
	Learning Rate: 0.000105714
	LOSS [training: 0.006781619762803531 | validation: 0.016167757321829783]
	TIME [epoch: 9.12 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007382849840259949		[learning rate: 0.00010539]
	Learning Rate: 0.00010539
	LOSS [training: 0.007382849840259949 | validation: 0.02769366028241449]
	TIME [epoch: 9.12 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0032845852982921137		[learning rate: 0.00010507]
	Learning Rate: 0.000105067
	LOSS [training: 0.0032845852982921137 | validation: 0.021196866485451524]
	TIME [epoch: 9.11 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00565747539486596		[learning rate: 0.00010474]
	Learning Rate: 0.000104745
	LOSS [training: 0.00565747539486596 | validation: 0.02386084670028594]
	TIME [epoch: 9.1 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.006068434835039707		[learning rate: 0.00010442]
	Learning Rate: 0.000104424
	LOSS [training: 0.006068434835039707 | validation: 0.011627272106520026]
	TIME [epoch: 9.11 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00891591484521946		[learning rate: 0.0001041]
	Learning Rate: 0.000104104
	LOSS [training: 0.00891591484521946 | validation: 0.022718879705990874]
	TIME [epoch: 9.13 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009824310981635448		[learning rate: 0.00010378]
	Learning Rate: 0.000103785
	LOSS [training: 0.009824310981635448 | validation: 0.025757917574684503]
	TIME [epoch: 9.11 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.007592806865470721		[learning rate: 0.00010347]
	Learning Rate: 0.000103467
	LOSS [training: 0.007592806865470721 | validation: 0.02602082110897188]
	TIME [epoch: 9.11 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011526910795606481		[learning rate: 0.00010315]
	Learning Rate: 0.000103149
	LOSS [training: 0.011526910795606481 | validation: 0.016069551031944452]
	TIME [epoch: 9.1 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012386469452022649		[learning rate: 0.00010283]
	Learning Rate: 0.000102833
	LOSS [training: 0.012386469452022649 | validation: 0.01886760294955142]
	TIME [epoch: 9.13 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010155617256046957		[learning rate: 0.00010252]
	Learning Rate: 0.000102518
	LOSS [training: 0.010155617256046957 | validation: 0.021299399038598153]
	TIME [epoch: 9.1 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009746441699817716		[learning rate: 0.0001022]
	Learning Rate: 0.000102204
	LOSS [training: 0.009746441699817716 | validation: 0.02622342791651877]
	TIME [epoch: 9.11 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010478520078840547		[learning rate: 0.00010189]
	Learning Rate: 0.00010189
	LOSS [training: 0.010478520078840547 | validation: 0.024344880116704243]
	TIME [epoch: 9.11 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.009379239477209516		[learning rate: 0.00010158]
	Learning Rate: 0.000101578
	LOSS [training: 0.009379239477209516 | validation: 0.014960562734307029]
	TIME [epoch: 9.13 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015425035924445158		[learning rate: 0.00010127]
	Learning Rate: 0.000101267
	LOSS [training: 0.015425035924445158 | validation: 0.02717964064705016]
	TIME [epoch: 9.11 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010980758694365817		[learning rate: 0.00010096]
	Learning Rate: 0.000100956
	LOSS [training: 0.010980758694365817 | validation: 0.025287080052638647]
	TIME [epoch: 9.11 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01719825485148909		[learning rate: 0.00010065]
	Learning Rate: 0.000100647
	LOSS [training: 0.01719825485148909 | validation: 0.017736460135127072]
	TIME [epoch: 9.11 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013794206963019088		[learning rate: 0.00010034]
	Learning Rate: 0.000100338
	LOSS [training: 0.013794206963019088 | validation: 0.01418657978303754]
	TIME [epoch: 9.13 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013542700798067344		[learning rate: 0.00010003]
	Learning Rate: 0.000100031
	LOSS [training: 0.013542700798067344 | validation: 0.02307522430430354]
	TIME [epoch: 9.11 sec]
Finished training in 18339.571 seconds.
